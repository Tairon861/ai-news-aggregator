<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 23 Jan 2026 01:56:50 +0000</lastBuildDate><item><title>Railway secures $100 million to challenge AWS with AI-native cloud infrastructure (AI | VentureBeat)</title><link>https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt;, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.&lt;/p&gt;&lt;p&gt;&lt;a href="https://tq.vc/"&gt;TQ Ventures&lt;/a&gt; led the round, with participation from &lt;a href="https://fpvventures.com/"&gt;FPV Ventures&lt;/a&gt;, &lt;a href="https://www.redpoint.com/"&gt;Redpoint&lt;/a&gt;, and &lt;a href="https://www.unusual.vc/"&gt;Unusual Ventures&lt;/a&gt;. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like &lt;a href="https://aws.amazon.com/"&gt;Amazon Web Services&lt;/a&gt; and &lt;a href="https://cloud.google.com/"&gt;Google Cloud&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&amp;quot; said Jake Cooper, Railway&amp;#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &amp;quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&amp;#x27;t keep up.&amp;quot;&lt;/p&gt;&lt;p&gt;The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a &lt;a href="https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/"&gt;$20 million Series A&lt;/a&gt; from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network ‚Äî metrics that rival far larger and better-funded competitors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why three-minute deploy times have become unacceptable in the age of AI coding assistants&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Railway&amp;#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using &lt;a href="https://station.railway.com/feedback/terraform-provider-954567d7"&gt;Terraform&lt;/a&gt;, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like &lt;a href="https://claude.ai/login"&gt;Claude&lt;/a&gt;, &lt;a href="https://chatgpt.com/"&gt;ChatGPT&lt;/a&gt;, and &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt; can generate working code in seconds.&lt;/p&gt;&lt;p&gt;&amp;quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&amp;quot; Cooper told VentureBeat. &amp;quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&amp;quot;&lt;/p&gt;&lt;p&gt;The company claims its platform delivers deployments in under one second ‚Äî fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.&lt;/p&gt;&lt;p&gt;These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.&lt;/p&gt;&lt;p&gt;&amp;quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&amp;quot; Lobaton said. &amp;quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the controversial decision to abandon Google Cloud and build data centers from scratch&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes &lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; from competitors like &lt;a href="https://render.com/"&gt;Render&lt;/a&gt; and &lt;a href="http://fly.io"&gt;Fly.io&lt;/a&gt; is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &amp;quot;People who are really serious about software should make their own hardware.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;We wanted to design hardware in a way where we could build a differentiated experience,&amp;quot; Cooper said. &amp;quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &amp;#x27;agentic speed&amp;#x27; while staying 100 percent the smoothest ride in town.&amp;quot;&lt;/p&gt;&lt;p&gt;The approach paid dividends during recent &lt;a href="https://restofworld.org/2026/cloud-outages-2025-global-business-impact/"&gt;widespread outages&lt;/a&gt; that affected major cloud providers ‚Äî Railway remained online throughout.&lt;/p&gt;&lt;p&gt;This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines ‚Äî a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.&lt;/p&gt;&lt;p&gt;&amp;quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&amp;quot; Cooper noted. &amp;quot;But when they&amp;#x27;re charging for VMs that usually sit idle in the cloud, and we&amp;#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How 30 employees built a platform generating tens of millions in annual revenue&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue ‚Äî a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.&lt;/p&gt;&lt;p&gt;Cooper emphasized that the fundraise was strategic rather than necessary. &amp;quot;We&amp;#x27;re default alive; there&amp;#x27;s no reason for us to raise money,&amp;quot; he said. &amp;quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&amp;quot;&lt;/p&gt;&lt;p&gt;The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&amp;#x27;s two million users discovered the platform through word of mouth ‚Äî developers telling other developers about a tool that actually works.&lt;/p&gt;&lt;p&gt;&amp;quot;We basically did the standard engineering thing: if you build it, they will come,&amp;quot; Cooper recalled. &amp;quot;And to some degree, they came.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From side projects to Fortune 500 deployments: Railway&amp;#x27;s unlikely corporate expansion&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.&lt;/p&gt;&lt;p&gt;Notable customers include &lt;a href="https://www.biltrewards.com/"&gt;Bilt&lt;/a&gt;, the loyalty program company; Intuit&amp;#x27;s &lt;a href="https://www.goco.io/"&gt;GoCo&lt;/a&gt; subsidiary; TripAdvisor&amp;#x27;s &lt;a href="https://www.cruisecritic.com/"&gt;Cruise Critic&lt;/a&gt;; and &lt;a href="https://www.mgmresorts.com/en.html"&gt;MGM Resorts&lt;/a&gt;. &lt;a href="https://www.ycombinator.com/companies/kernel"&gt;Kernel&lt;/a&gt;, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.&lt;/p&gt;&lt;p&gt;&amp;quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&amp;quot; said Rafael Garcia, Kernel&amp;#x27;s chief technology officer. &amp;quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&amp;quot;&lt;/p&gt;&lt;p&gt;For enterprise customers, &lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&amp;#x27;s existing cloud environment through a &amp;quot;bring your own cloud&amp;quot; configuration.&lt;/p&gt;&lt;p&gt;Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The startup&amp;#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Railway enters a crowded market that includes not only the hyperscale cloud providers‚ÄîAmazon Web Services, Microsoft Azure, and Google Cloud Platform‚Äîbut also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.&lt;/p&gt;&lt;p&gt;Cooper argues that Railway&amp;#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.&lt;/p&gt;&lt;p&gt;&amp;quot;The hyperscalers have two competing systems, and they haven&amp;#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&amp;quot; he observed. &amp;quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&amp;#x27;t really need to?&amp;quot;&lt;/p&gt;&lt;p&gt;Against startup competitors, Railway differentiates by covering the full infrastructure stack. &amp;quot;We&amp;#x27;re not just containers; we&amp;#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&amp;quot; Cooper said. &amp;quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why investors are betting that AI will create a thousand times more software than exists today&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Railway&amp;#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like &lt;a href="https://github.com/features/copilot"&gt;GitHub Copilot&lt;/a&gt;, &lt;a href="https://cursor.com/agents"&gt;Cursor&lt;/a&gt;, and &lt;a href="https://claude.ai/login"&gt;Claude&lt;/a&gt; become standard fixtures in developer workflows, the volume of code being written ‚Äî and the infrastructure needed to run it ‚Äî is expanding dramatically.&lt;/p&gt;&lt;p&gt;&amp;quot;The amount of software that&amp;#x27;s going to come online over the next five years is unfathomable compared to what existed before ‚Äî we&amp;#x27;re talking a thousand times more software,&amp;quot; Cooper predicted. &amp;quot;All of that has to run somewhere.&amp;quot;&lt;/p&gt;&lt;p&gt;The company has already integrated directly with AI systems, building what Cooper calls &amp;quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&amp;quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.&lt;/p&gt;&lt;p&gt;&amp;quot;The notion of a developer is melting before our eyes,&amp;quot; Cooper said. &amp;quot;You don&amp;#x27;t have to be an engineer to engineer things anymore ‚Äî you just need critical thinking and the ability to analyze things in a systems capacity.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Railway plans to do with $100 million and zero marketing experience&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&amp;#x27;s five-year history.&lt;/p&gt;&lt;p&gt;&amp;quot;One of my mentors said you raise money when you can change the trajectory of the business,&amp;quot; Cooper explained. &amp;quot;We&amp;#x27;ve built all the required substrate to scale indefinitely; what&amp;#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&amp;quot;&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s investor roster reads like a who&amp;#x27;s who of developer infrastructure. Angel investors include &lt;a href="https://tom.preston-werner.com/"&gt;Tom Preston-Werner,&lt;/a&gt; co-founder of GitHub; &lt;a href="https://rauchg.com/about"&gt;Guillermo Rauch&lt;/a&gt;, chief executive of Vercel; &lt;a href="https://www.cockroachlabs.com/author/spencer-kimball/"&gt;Spencer Kimball&lt;/a&gt;, chief executive of Cockroach Labs; &lt;a href="https://www.datadoghq.com/about/leadership/"&gt;Olivier Pomel&lt;/a&gt;, chief executive of Datadog; and &lt;a href="https://sequoiacap.com/founder/jori-lallo/"&gt;Jori Lallo&lt;/a&gt;, co-founder of Linear.&lt;/p&gt;&lt;p&gt;The timing of Railway&amp;#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities ‚Äî they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&amp;#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.&lt;/p&gt;&lt;p&gt;Whether &lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at &lt;a href="https://www.wolframalpha.com/"&gt;Wolfram Alpha&lt;/a&gt;, &lt;a href="https://www.bloomberg.com/"&gt;Bloomberg&lt;/a&gt;, and &lt;a href="https://www.uber.com/"&gt;Uber&lt;/a&gt; before founding Railway in 2020, seems unfazed by the scale of his ambition.&lt;/p&gt;&lt;p&gt;&amp;quot;In five years, Railway [will be] the place where software gets created and evolved, period,&amp;quot; he said. &amp;quot;Deploy instantly, scale infinitely, with zero friction. That&amp;#x27;s the prize worth playing for, and there&amp;#x27;s no bigger one on offer.&amp;quot;&lt;/p&gt;&lt;p&gt;For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates ‚Äî no marketing, no sales team, no venture hype‚Äîthe real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt;, a San Francisco-based cloud platform that has quietly amassed two million developers without spending a dollar on marketing, announced Thursday that it raised $100 million in a Series B funding round, as surging demand for artificial intelligence applications exposes the limitations of legacy cloud infrastructure.&lt;/p&gt;&lt;p&gt;&lt;a href="https://tq.vc/"&gt;TQ Ventures&lt;/a&gt; led the round, with participation from &lt;a href="https://fpvventures.com/"&gt;FPV Ventures&lt;/a&gt;, &lt;a href="https://www.redpoint.com/"&gt;Redpoint&lt;/a&gt;, and &lt;a href="https://www.unusual.vc/"&gt;Unusual Ventures&lt;/a&gt;. The investment values Railway as one of the most significant infrastructure startups to emerge during the AI boom, capitalizing on developer frustration with the complexity and cost of traditional platforms like &lt;a href="https://aws.amazon.com/"&gt;Amazon Web Services&lt;/a&gt; and &lt;a href="https://cloud.google.com/"&gt;Google Cloud&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;As AI models get better at writing code, more and more people are asking the age-old question: where, and how, do I run my applications?&amp;quot; said Jake Cooper, Railway&amp;#x27;s 28-year-old founder and chief executive, in an exclusive interview with VentureBeat. &amp;quot;The last generation of cloud primitives were slow and outdated, and now with AI moving everything faster, teams simply can&amp;#x27;t keep up.&amp;quot;&lt;/p&gt;&lt;p&gt;The funding is a dramatic acceleration for a company that has charted an unconventional path through the cloud computing industry. Railway raised just $24 million in total before this round, including a &lt;a href="https://techcrunch.com/2022/05/31/railway-snags-20m-to-streamline-the-process-of-deploying-apps-and-services/"&gt;$20 million Series A&lt;/a&gt; from Redpoint in 2022. The company now processes more than 10 million deployments monthly and handles over one trillion requests through its edge network ‚Äî metrics that rival far larger and better-funded competitors.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why three-minute deploy times have become unacceptable in the age of AI coding assistants&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Railway&amp;#x27;s pitch rests on a simple observation: the tools developers use to deploy and manage software were designed for a slower era. A standard build-and-deploy cycle using &lt;a href="https://station.railway.com/feedback/terraform-provider-954567d7"&gt;Terraform&lt;/a&gt;, the industry-standard infrastructure tool, takes two to three minutes. That delay, once tolerable, has become a critical bottleneck as AI coding assistants like &lt;a href="https://claude.ai/login"&gt;Claude&lt;/a&gt;, &lt;a href="https://chatgpt.com/"&gt;ChatGPT&lt;/a&gt;, and &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt; can generate working code in seconds.&lt;/p&gt;&lt;p&gt;&amp;quot;When godly intelligence is on tap and can solve any problem in three seconds, those amalgamations of systems become bottlenecks,&amp;quot; Cooper told VentureBeat. &amp;quot;What was really cool for humans to deploy in 10 seconds or less is now table stakes for agents.&amp;quot;&lt;/p&gt;&lt;p&gt;The company claims its platform delivers deployments in under one second ‚Äî fast enough to keep pace with AI-generated code. Customers report a tenfold increase in developer velocity and up to 65 percent cost savings compared to traditional cloud providers.&lt;/p&gt;&lt;p&gt;These numbers come directly from enterprise clients, not internal benchmarks. Daniel Lobaton, chief technology officer at G2X, a platform serving 100,000 federal contractors, measured deployment speed improvements of seven times faster and an 87 percent cost reduction after migrating to Railway. His infrastructure bill dropped from $15,000 per month to approximately $1,000.&lt;/p&gt;&lt;p&gt;&amp;quot;The work that used to take me a week on our previous infrastructure, I can do in Railway in like a day,&amp;quot; Lobaton said. &amp;quot;If I want to spin up a new service and test different architectures, it would take so long on our old setup. In Railway I can launch six services in two minutes.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the controversial decision to abandon Google Cloud and build data centers from scratch&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes &lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; from competitors like &lt;a href="https://render.com/"&gt;Render&lt;/a&gt; and &lt;a href="http://fly.io"&gt;Fly.io&lt;/a&gt; is the depth of its vertical integration. In 2024, the company made the unusual decision to abandon Google Cloud entirely and build its own data centers, a move that echoes the famous Alan Kay maxim: &amp;quot;People who are really serious about software should make their own hardware.&amp;quot;&lt;/p&gt;&lt;p&gt;&amp;quot;We wanted to design hardware in a way where we could build a differentiated experience,&amp;quot; Cooper said. &amp;quot;Having full control over the network, compute, and storage layers lets us do really fast build and deploy loops, the kind that allows us to move at &amp;#x27;agentic speed&amp;#x27; while staying 100 percent the smoothest ride in town.&amp;quot;&lt;/p&gt;&lt;p&gt;The approach paid dividends during recent &lt;a href="https://restofworld.org/2026/cloud-outages-2025-global-business-impact/"&gt;widespread outages&lt;/a&gt; that affected major cloud providers ‚Äî Railway remained online throughout.&lt;/p&gt;&lt;p&gt;This soup-to-nuts control enables pricing that undercuts the hyperscalers by roughly 50 percent and newer cloud startups by three to four times. Railway charges by the second for actual compute usage: $0.00000386 per gigabyte-second of memory, $0.00000772 per vCPU-second, and $0.00000006 per gigabyte-second of storage. There are no charges for idle virtual machines ‚Äî a stark contrast to the traditional cloud model where customers pay for provisioned capacity whether they use it or not.&lt;/p&gt;&lt;p&gt;&amp;quot;The conventional wisdom is that the big guys have economies of scale to offer better pricing,&amp;quot; Cooper noted. &amp;quot;But when they&amp;#x27;re charging for VMs that usually sit idle in the cloud, and we&amp;#x27;ve purpose-built everything to fit much more density on these machines, you have a big opportunity.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How 30 employees built a platform generating tens of millions in annual revenue&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; has achieved its scale with a team of just 30 employees generating tens of millions in annual revenue ‚Äî a ratio of revenue per employee that would be exceptional even for established software companies. The company grew revenue 3.5 times last year and continues to expand at 15 percent month-over-month.&lt;/p&gt;&lt;p&gt;Cooper emphasized that the fundraise was strategic rather than necessary. &amp;quot;We&amp;#x27;re default alive; there&amp;#x27;s no reason for us to raise money,&amp;quot; he said. &amp;quot;We raised because we see a massive opportunity to accelerate, not because we needed to survive.&amp;quot;&lt;/p&gt;&lt;p&gt;The company hired its first salesperson only last year and employs just two solutions engineers. Nearly all of Railway&amp;#x27;s two million users discovered the platform through word of mouth ‚Äî developers telling other developers about a tool that actually works.&lt;/p&gt;&lt;p&gt;&amp;quot;We basically did the standard engineering thing: if you build it, they will come,&amp;quot; Cooper recalled. &amp;quot;And to some degree, they came.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From side projects to Fortune 500 deployments: Railway&amp;#x27;s unlikely corporate expansion&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Despite its grassroots developer community, Railway has made significant inroads into large organizations. The company claims that 31 percent of Fortune 500 companies now use its platform, though deployments range from company-wide infrastructure to individual team projects.&lt;/p&gt;&lt;p&gt;Notable customers include &lt;a href="https://www.biltrewards.com/"&gt;Bilt&lt;/a&gt;, the loyalty program company; Intuit&amp;#x27;s &lt;a href="https://www.goco.io/"&gt;GoCo&lt;/a&gt; subsidiary; TripAdvisor&amp;#x27;s &lt;a href="https://www.cruisecritic.com/"&gt;Cruise Critic&lt;/a&gt;; and &lt;a href="https://www.mgmresorts.com/en.html"&gt;MGM Resorts&lt;/a&gt;. &lt;a href="https://www.ycombinator.com/companies/kernel"&gt;Kernel&lt;/a&gt;, a Y Combinator-backed startup providing AI infrastructure to over 1,000 companies, runs its entire customer-facing system on Railway for $444 per month.&lt;/p&gt;&lt;p&gt;&amp;quot;At my previous company Clever, which sold for $500 million, I had six full-time engineers just managing AWS,&amp;quot; said Rafael Garcia, Kernel&amp;#x27;s chief technology officer. &amp;quot;Now I have six engineers total, and they all focus on product. Railway is exactly the tool I wish I had in 2012.&amp;quot;&lt;/p&gt;&lt;p&gt;For enterprise customers, &lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; offers security certifications including SOC 2 Type 2 compliance and HIPAA readiness, with business associate agreements available upon request. The platform provides single sign-on authentication, comprehensive audit logs, and the option to deploy within a customer&amp;#x27;s existing cloud environment through a &amp;quot;bring your own cloud&amp;quot; configuration.&lt;/p&gt;&lt;p&gt;Enterprise pricing starts at custom levels, with specific add-ons for extended log retention ($200 monthly), HIPAA BAAs ($1,000), enterprise support with SLOs ($2,000), and dedicated virtual machines ($10,000).&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The startup&amp;#x27;s bold strategy to take on Amazon, Google, and a new generation of cloud rivals&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Railway enters a crowded market that includes not only the hyperscale cloud providers‚ÄîAmazon Web Services, Microsoft Azure, and Google Cloud Platform‚Äîbut also a growing cohort of developer-focused platforms like Vercel, Render, Fly.io, and Heroku.&lt;/p&gt;&lt;p&gt;Cooper argues that Railway&amp;#x27;s competitors fall into two camps, neither of which has fully committed to the new infrastructure model that AI demands.&lt;/p&gt;&lt;p&gt;&amp;quot;The hyperscalers have two competing systems, and they haven&amp;#x27;t gone all-in on the new model because their legacy revenue stream is still printing money,&amp;quot; he observed. &amp;quot;They have this mammoth pool of cash coming from people who provision a VM, use maybe 10 percent of it, and still pay for the whole thing. To what end are they actually interested in going all the way in on a new experience if they don&amp;#x27;t really need to?&amp;quot;&lt;/p&gt;&lt;p&gt;Against startup competitors, Railway differentiates by covering the full infrastructure stack. &amp;quot;We&amp;#x27;re not just containers; we&amp;#x27;ve got VM primitives, stateful storage, virtual private networking, automated load balancing,&amp;quot; Cooper said. &amp;quot;And we wrap all of this in an absurdly easy-to-use UI, with agentic primitives so agents can move 1,000 times faster.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform supports databases including PostgreSQL, MySQL, MongoDB, and Redis; provides up to 256 terabytes of persistent storage with over 100,000 input/output operations per second; and enables deployment to four global regions spanning the United States, Europe, and Southeast Asia. Enterprise customers can scale to 112 vCPUs and 2 terabytes of RAM per service.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why investors are betting that AI will create a thousand times more software than exists today&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Railway&amp;#x27;s fundraise reflects broader investor enthusiasm for companies positioned to benefit from the AI coding revolution. As tools like &lt;a href="https://github.com/features/copilot"&gt;GitHub Copilot&lt;/a&gt;, &lt;a href="https://cursor.com/agents"&gt;Cursor&lt;/a&gt;, and &lt;a href="https://claude.ai/login"&gt;Claude&lt;/a&gt; become standard fixtures in developer workflows, the volume of code being written ‚Äî and the infrastructure needed to run it ‚Äî is expanding dramatically.&lt;/p&gt;&lt;p&gt;&amp;quot;The amount of software that&amp;#x27;s going to come online over the next five years is unfathomable compared to what existed before ‚Äî we&amp;#x27;re talking a thousand times more software,&amp;quot; Cooper predicted. &amp;quot;All of that has to run somewhere.&amp;quot;&lt;/p&gt;&lt;p&gt;The company has already integrated directly with AI systems, building what Cooper calls &amp;quot;loops where Claude can hook in, call deployments, and analyze infrastructure automatically.&amp;quot; Railway released a Model Context Protocol server in August 2025 that allows AI coding agents to deploy applications and manage infrastructure directly from code editors.&lt;/p&gt;&lt;p&gt;&amp;quot;The notion of a developer is melting before our eyes,&amp;quot; Cooper said. &amp;quot;You don&amp;#x27;t have to be an engineer to engineer things anymore ‚Äî you just need critical thinking and the ability to analyze things in a systems capacity.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Railway plans to do with $100 million and zero marketing experience&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; plans to use the new capital to expand its global data center footprint, grow its team beyond 30 employees, and build what Cooper described as a proper go-to-market operation for the first time in the company&amp;#x27;s five-year history.&lt;/p&gt;&lt;p&gt;&amp;quot;One of my mentors said you raise money when you can change the trajectory of the business,&amp;quot; Cooper explained. &amp;quot;We&amp;#x27;ve built all the required substrate to scale indefinitely; what&amp;#x27;s been holding us back is simply talking about it. 2026 is the year we play on the world stage.&amp;quot;&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s investor roster reads like a who&amp;#x27;s who of developer infrastructure. Angel investors include &lt;a href="https://tom.preston-werner.com/"&gt;Tom Preston-Werner,&lt;/a&gt; co-founder of GitHub; &lt;a href="https://rauchg.com/about"&gt;Guillermo Rauch&lt;/a&gt;, chief executive of Vercel; &lt;a href="https://www.cockroachlabs.com/author/spencer-kimball/"&gt;Spencer Kimball&lt;/a&gt;, chief executive of Cockroach Labs; &lt;a href="https://www.datadoghq.com/about/leadership/"&gt;Olivier Pomel&lt;/a&gt;, chief executive of Datadog; and &lt;a href="https://sequoiacap.com/founder/jori-lallo/"&gt;Jori Lallo&lt;/a&gt;, co-founder of Linear.&lt;/p&gt;&lt;p&gt;The timing of Railway&amp;#x27;s expansion coincides with what many in Silicon Valley view as a fundamental shift in how software gets made. Coding assistants are no longer experimental curiosities ‚Äî they have become essential tools that millions of developers rely on daily. Each line of AI-generated code needs somewhere to run, and the incumbents, by Cooper&amp;#x27;s telling, are too wedded to their existing business models to fully capitalize on the moment.&lt;/p&gt;&lt;p&gt;Whether &lt;a href="https://railway.com/"&gt;Railway&lt;/a&gt; can translate developer enthusiasm into sustained enterprise adoption remains an open question. The cloud infrastructure market is littered with promising startups that failed to break the grip of Amazon, Microsoft, and Google. But Cooper, who previously worked as a software engineer at &lt;a href="https://www.wolframalpha.com/"&gt;Wolfram Alpha&lt;/a&gt;, &lt;a href="https://www.bloomberg.com/"&gt;Bloomberg&lt;/a&gt;, and &lt;a href="https://www.uber.com/"&gt;Uber&lt;/a&gt; before founding Railway in 2020, seems unfazed by the scale of his ambition.&lt;/p&gt;&lt;p&gt;&amp;quot;In five years, Railway [will be] the place where software gets created and evolved, period,&amp;quot; he said. &amp;quot;Deploy instantly, scale infinitely, with zero friction. That&amp;#x27;s the prize worth playing for, and there&amp;#x27;s no bigger one on offer.&amp;quot;&lt;/p&gt;&lt;p&gt;For a company that built a $100 million business by doing the opposite of what conventional startup wisdom dictates ‚Äî no marketing, no sales team, no venture hype‚Äîthe real test begins now. Railway spent five years proving that developers would find a better mousetrap on their own. The next five will determine whether the rest of the world is ready to get on board.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/infrastructure/railway-secures-usd100-million-to-challenge-aws-with-ai-native-cloud</guid><pubDate>Thu, 22 Jan 2026 14:00:00 +0000</pubDate></item><item><title>Flight Controls Are Cleared for Takeoff on GeForce NOW (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/geforce-now-thursday-flight-controls/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The wait is over, pilots. Flight control support ‚Äî one of the most community-requested features for GeForce NOW ‚Äî is live starting today, following its announcement at CES earlier this month.&lt;/p&gt;
&lt;p&gt;Virtual captains can now bring dedicated flight gear into the cloud and feel every roll, yaw and throttle change with even more precision, starting with the Thrustmaster T.Flight HOTAS One.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Time is running out on our  T.Flight Hotas One MSFS Edition + 1 month of @NVIDIAGFN Ultimate giveaway! ‚è∞&lt;/p&gt;
&lt;p&gt;How to enter üëá&lt;br /&gt;1. Follow both @TMThrustmaster and @NVIDIAGFN accounts on social&lt;br /&gt;2. Repost this and share on your feed&lt;/p&gt;
&lt;p&gt;üéÅ 5 winners will be chosen ‚Äì ends 1/24. pic.twitter.com/B89mGwJoNQ&lt;/p&gt;
&lt;p&gt;‚Äî üå©Ô∏è NVIDIA GeForce NOW (@NVIDIAGFN) January 19, 2026&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Remember to enter the giveaway for a chance to score a T.Flight Hotas One MSFS Edition and one month of a GeForce NOW Ultimate membership ‚Äî follow Thrustmaster and GeForce NOW, and repost the giveaway post to enter before Saturday, Jan. 24.&lt;/p&gt;
&lt;p&gt;Also on the horizon, &lt;i&gt;Delta Force&lt;/i&gt; from Team Jade (TiMi Studio Group) is coming soon to GeForce NOW, adding another big-name title to the cloud lineup. Get ready for all the action by streaming the four new games in this cloud this week.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Pilots Wanted&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Members can now jump into their favorite flight and space simulation games with a full stick-and-throttle setup streamed right from the cloud. It‚Äôs all about dialing in that authentic, hands-on flying experience while keeping latency low and gameplay responsive on GeForce NOW.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89331"&gt;&lt;img alt="flight stick row in the app on geforce now" class="wp-image-89331 size-large" height="678" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/image-1-1680x678.png" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89331"&gt;&lt;em&gt;Full throttle in the cloud.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;To get right to flying, members can look for a dedicated row in the GeForce NOW app highlighting games that support flight controls, making it simple to spot great titles for putting their new setup through its paces.&lt;/p&gt;
&lt;p&gt;This initial flight control support rollout is just the beginning, with plans to keep tuning the experience and expand compatibility to more peripherals. Fire up the rig, plug in the Thrustmaster T.Flight HOTAS One and get ready to take off ‚Äî the cloud cockpit is open and ready for flight.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Your Next Mission: ‚ÄòDelta Force‚Äô&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Team Jade‚Äôs &lt;i&gt;Delta Force&lt;/i&gt; is coming soon to the cloud, ready to drop players into high-stakes extraction with an all-out warfare mode where coordination and precision matter just as much as raw firepower. When it launches on GeForce NOW, members will be able to jump into the action instantly from almost any device, taking advantage of high‚Äëperformance streaming to stay locked at smooth frame rates even in the most chaotic firefights.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89315"&gt;&lt;img alt="Delta Force on GeForce NOW" class="size-large wp-image-89315" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/GFN_Thursday-Delta_Force-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89315"&gt;&lt;em&gt;Get ready to squad up, Delta Force is inbound soon.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;On GeForce NOW, every long‚Äërange shot, helicopter insertion and tense objective push can feel crisp and responsive, whether playing on low‚Äëpowered laptops, Macs or mobile devices. The cloud makes it easy to squad up, drop in and get straight to the mission without worrying about downloads, patches or local hardware.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;New in the Cloud&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89318"&gt;&lt;img alt="MIO on GeForce NOW" class="size-large wp-image-89318" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/GFN_Thursday-MIO_Memories_In_Orbit-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89318"&gt;&lt;em&gt;A graceful little robot having the worst day in the universe.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;MIO: Memories in Orbit&lt;/i&gt; is a neon-tinged metroidvania about a nimble little robot waking up on a massive, overgrown ark called the Vessel with nothing but fractured memories and a whole lot of trouble coming its way. Dart through low-gravity corridors, chain together elegant wall-runs, glides and grapples, and tangle with rogue machines as the Vessel itself quietly steals the spotlight ‚Äî moody, decaying and just alive enough to keep a few secrets.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;MIO: Memories in Orbit &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Jan. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Bladesong &lt;/i&gt;(New release on Steam, Jan. 22)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Rustler &lt;/i&gt;(New release on Epic Games Store, free starting Jan. 22)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Gold River Project &lt;/i&gt;(New release on Steam, Jan. 23, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;If you could fly to any video game destination, where would it be? üõ´&lt;/p&gt;
&lt;p&gt;‚Äî üå©Ô∏è NVIDIA GeForce NOW (@NVIDIAGFN) January 21, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The wait is over, pilots. Flight control support ‚Äî one of the most community-requested features for GeForce NOW ‚Äî is live starting today, following its announcement at CES earlier this month.&lt;/p&gt;
&lt;p&gt;Virtual captains can now bring dedicated flight gear into the cloud and feel every roll, yaw and throttle change with even more precision, starting with the Thrustmaster T.Flight HOTAS One.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;Time is running out on our  T.Flight Hotas One MSFS Edition + 1 month of @NVIDIAGFN Ultimate giveaway! ‚è∞&lt;/p&gt;
&lt;p&gt;How to enter üëá&lt;br /&gt;1. Follow both @TMThrustmaster and @NVIDIAGFN accounts on social&lt;br /&gt;2. Repost this and share on your feed&lt;/p&gt;
&lt;p&gt;üéÅ 5 winners will be chosen ‚Äì ends 1/24. pic.twitter.com/B89mGwJoNQ&lt;/p&gt;
&lt;p&gt;‚Äî üå©Ô∏è NVIDIA GeForce NOW (@NVIDIAGFN) January 19, 2026&lt;/p&gt;&lt;/blockquote&gt;

&lt;p&gt;Remember to enter the giveaway for a chance to score a T.Flight Hotas One MSFS Edition and one month of a GeForce NOW Ultimate membership ‚Äî follow Thrustmaster and GeForce NOW, and repost the giveaway post to enter before Saturday, Jan. 24.&lt;/p&gt;
&lt;p&gt;Also on the horizon, &lt;i&gt;Delta Force&lt;/i&gt; from Team Jade (TiMi Studio Group) is coming soon to GeForce NOW, adding another big-name title to the cloud lineup. Get ready for all the action by streaming the four new games in this cloud this week.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Pilots Wanted&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Members can now jump into their favorite flight and space simulation games with a full stick-and-throttle setup streamed right from the cloud. It‚Äôs all about dialing in that authentic, hands-on flying experience while keeping latency low and gameplay responsive on GeForce NOW.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89331"&gt;&lt;img alt="flight stick row in the app on geforce now" class="wp-image-89331 size-large" height="678" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/image-1-1680x678.png" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89331"&gt;&lt;em&gt;Full throttle in the cloud.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;To get right to flying, members can look for a dedicated row in the GeForce NOW app highlighting games that support flight controls, making it simple to spot great titles for putting their new setup through its paces.&lt;/p&gt;
&lt;p&gt;This initial flight control support rollout is just the beginning, with plans to keep tuning the experience and expand compatibility to more peripherals. Fire up the rig, plug in the Thrustmaster T.Flight HOTAS One and get ready to take off ‚Äî the cloud cockpit is open and ready for flight.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Your Next Mission: ‚ÄòDelta Force‚Äô&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Team Jade‚Äôs &lt;i&gt;Delta Force&lt;/i&gt; is coming soon to the cloud, ready to drop players into high-stakes extraction with an all-out warfare mode where coordination and precision matter just as much as raw firepower. When it launches on GeForce NOW, members will be able to jump into the action instantly from almost any device, taking advantage of high‚Äëperformance streaming to stay locked at smooth frame rates even in the most chaotic firefights.&lt;/p&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89315"&gt;&lt;img alt="Delta Force on GeForce NOW" class="size-large wp-image-89315" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/GFN_Thursday-Delta_Force-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89315"&gt;&lt;em&gt;Get ready to squad up, Delta Force is inbound soon.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;On GeForce NOW, every long‚Äërange shot, helicopter insertion and tense objective push can feel crisp and responsive, whether playing on low‚Äëpowered laptops, Macs or mobile devices. The cloud makes it easy to squad up, drop in and get straight to the mission without worrying about downloads, patches or local hardware.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;New in the Cloud&lt;/b&gt;&lt;/h2&gt;
&lt;figure class="wp-caption aligncenter" id="attachment_89318"&gt;&lt;img alt="MIO on GeForce NOW" class="size-large wp-image-89318" height="840" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/GFN_Thursday-MIO_Memories_In_Orbit-1680x840.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89318"&gt;&lt;em&gt;A graceful little robot having the worst day in the universe.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;MIO: Memories in Orbit&lt;/i&gt; is a neon-tinged metroidvania about a nimble little robot waking up on a massive, overgrown ark called the Vessel with nothing but fractured memories and a whole lot of trouble coming its way. Dart through low-gravity corridors, chain together elegant wall-runs, glides and grapples, and tangle with rogue machines as the Vessel itself quietly steals the spotlight ‚Äî moody, decaying and just alive enough to keep a few secrets.&lt;/p&gt;
&lt;p&gt;In addition, members can look for the following:&lt;i&gt;&lt;/i&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;i&gt;MIO: Memories in Orbit &lt;/i&gt;(New release on Steam and Xbox, available on Game Pass, Jan. 20)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Bladesong &lt;/i&gt;(New release on Steam, Jan. 22)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;Rustler &lt;/i&gt;(New release on Epic Games Store, free starting Jan. 22)&lt;/li&gt;
&lt;li&gt;&lt;i&gt;The Gold River Project &lt;/i&gt;(New release on Steam, Jan. 23, GeForce RTX 5080-ready)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;What are you planning to play this weekend? Let us know on X or in the comments below.&lt;/p&gt;
&lt;blockquote class="twitter-tweet"&gt;
&lt;p dir="ltr" lang="en"&gt;If you could fly to any video game destination, where would it be? üõ´&lt;/p&gt;
&lt;p&gt;‚Äî üå©Ô∏è NVIDIA GeForce NOW (@NVIDIAGFN) January 21, 2026&lt;/p&gt;&lt;/blockquote&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/geforce-now-thursday-flight-controls/</guid><pubDate>Thu, 22 Jan 2026 14:00:53 +0000</pubDate></item><item><title>From Pilot to Profit: Survey Reveals the Financial Services Industry Is Doubling Down on AI Investment and Open Source (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-in-financial-services-survey-2026/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI has taken center stage in financial services, automating the research and execution behind algorithmic trading and helping banks more accurately detect fraud and money laundering ‚Äî all while improving risk management practices and expediting document processing.&lt;/p&gt;
&lt;p&gt;The sixth annual ‚ÄúNVIDIA State of AI in Financial Services‚Äù report, based on a survey of more than 800 industry professionals, found that AI usage in the industry has never been higher.&lt;/p&gt;
&lt;p&gt;Organizations are deploying and scaling AI use cases, such as fraud detection, risk management and customer service, to improve critical business functions that create meaningful return on investment. New types of AI ‚Äî including AI agents ‚Äî are streamlining processes ranging from back-office operations to investment research as financial institutions embrace the tools needed to build specialized AI, including open source foundation models and software.&lt;/p&gt;
&lt;p&gt;Highlights from this year‚Äôs report include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;89% said AI is helping increase annual revenue and decrease annual costs.&lt;/li&gt;
&lt;li&gt;73% of executives said AI is crucial to their future success, and nearly 100% said their AI budgets will increase or stay the same in the next year.&lt;/li&gt;
&lt;li&gt;65% of respondents said their company is actively using AI, up from 45% in last year‚Äôs report.&lt;/li&gt;
&lt;li&gt;61% are using or assessing generative AI, up 52% year over year.&lt;/li&gt;
&lt;li&gt;84% said open source models and software are important to their AI strategy.&lt;/li&gt;
&lt;li&gt;42% are using or assessing agentic AI, with 21% saying they‚Äôve already deployed AI agents.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;‚ÄúOpen source models are fundamentally changing the competitive dynamics in financial AI,‚Äù said Helen Yu, CEO of Tigon Advisory Corp. ‚ÄúThe real value capture happens when institutions fine-tune these models on their proprietary transaction data, customer interaction histories and market intelligence, creating AI capabilities that competitors cannot replicate.‚Äù&lt;/p&gt;
&lt;p&gt;Read more below on some of the report‚Äôs key findings.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Building the Foundation of the Future With Open Source&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Open source models allow for flexibility and efficiency, enabling organizations to tailor development tools to their unique needs and make them more accurate by incorporating a financial institution‚Äôs proprietary data. As a result, 83% percent of respondents said open source is important to their organization‚Äôs AI strategy, with 43% saying it is very to extremely important.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone wp-image-89244 size-medium" height="233" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/finance-question-21-importance-of-open-source-by-role-white-960x233.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;‚ÄúOpen source models can help banks close the gap with early movers, unlock cost efficiencies and safeguard against vendor lock-in, but they‚Äôre not without their limitations ‚Äî proprietary approaches can unlock superior performance for domain-specific tasks,‚Äù said Alexandra Mousavizadeh, cofounder and co-CEO of Evident Insights. ‚ÄúLeading banks need to demonstrate proficiency in both approaches ‚Äî applying the right kind of model to the right problem, in the right context.‚Äù&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Return on Investment of AI in Financial Services Is Clear&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Financial institutions have moved from piloting AI projects to deploying solutions that create business impact and scaling them across the organization. In turn, companies have begun to see significant return on investment from AI on the top and bottom lines.&lt;/p&gt;
&lt;p&gt;As stated above, 89% of survey respondents said AI has helped increase annual revenue and decrease annual costs. For many organizations, the impact has been significant, with 64% of respondents saying AI has helped increase annual revenue by more than 5% ‚Äî including 29% who said revenue increased more than 10%.&lt;/p&gt;
&lt;p&gt;Similarly, 61% said AI had helped decrease annual costs by more than 5%, with 25% saying costs decreased more than 10%.&lt;/p&gt;
&lt;p&gt;Respondents cited a long list of AI use cases that have provided return on investment, including document processing and management, customer experience and engagement, algorithmic trading and risk management.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone wp-image-89241 size-medium" height="337" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/finance-question-19-impact-on-business-operations-industry-top3-white-960x337.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Creating operational efficiencies is the largest improvement AI has made in financial services, according to 52% of respondents. And 48% said employee productivity was among the biggest improvements.&lt;/p&gt;
&lt;p&gt;‚ÄúThe most tangible ROI I‚Äôm seeing is in payment operations, specifically authorization optimization and intelligent routing,‚Äù said Dwayne Gefferie, payments strategist at Gefferie Group. ‚ÄúAgentic AI systems can now autonomously route transactions to the most optimized payment networks, dynamically adjust retry logic based on real-time issuer signals and make routing decisions under 200-millisecond routing that traditional rule-based systems simply can‚Äôt match. What makes this compelling is that every basis point improvement in authorization rates translates directly to revenue ‚Äî there‚Äôs no ambiguity in measurement.‚Äù&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Success Leads to Increasing AI Budgets&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Given the shift from running proof of concepts to deploying AI-enabled applications into production, the financial services industry is looking to significantly expand AI budgets. Nearly 100% of respondents said their AI budgets would increase or stay the same in the coming year.&lt;/p&gt;
&lt;p&gt;About 41% of respondents said investment would go toward optimizing AI workflows and production, reinvesting in and improving the AI solutions that are already working.&lt;/p&gt;
&lt;p&gt;More than a third (34%) said they had an eye toward AI expansion in their organizations, with spending focused on identifying additional use cases. And 30% said that investment would focus on building or providing more access to AI infrastructure, such as on-premises installations or in the cloud.&lt;/p&gt;
&lt;p&gt;Investment will also flow to deployment and expansion of AI agents, which are advanced AI systems designed to autonomously reason, plan and execute complex tasks based on high-level goals. About 21% of respondents said AI agents have already been deployed, with another 22% saying AI agents will be deployed within the next year and beyond.&lt;/p&gt;
&lt;p&gt;‚ÄúThe institutions winning in AI are treating their proprietary data as a strategic asset for building differentiated AI products,‚Äù said Yu.&lt;/p&gt;
&lt;p&gt;Download the ‚ÄúState of AI in Financial Services: 2026 Trends‚Äù report for in-depth results and insights.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Explore &lt;/i&gt;&lt;i&gt;NVIDIA‚Äôs AI solutions and enterprise-level AI platforms for financial services&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI has taken center stage in financial services, automating the research and execution behind algorithmic trading and helping banks more accurately detect fraud and money laundering ‚Äî all while improving risk management practices and expediting document processing.&lt;/p&gt;
&lt;p&gt;The sixth annual ‚ÄúNVIDIA State of AI in Financial Services‚Äù report, based on a survey of more than 800 industry professionals, found that AI usage in the industry has never been higher.&lt;/p&gt;
&lt;p&gt;Organizations are deploying and scaling AI use cases, such as fraud detection, risk management and customer service, to improve critical business functions that create meaningful return on investment. New types of AI ‚Äî including AI agents ‚Äî are streamlining processes ranging from back-office operations to investment research as financial institutions embrace the tools needed to build specialized AI, including open source foundation models and software.&lt;/p&gt;
&lt;p&gt;Highlights from this year‚Äôs report include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;89% said AI is helping increase annual revenue and decrease annual costs.&lt;/li&gt;
&lt;li&gt;73% of executives said AI is crucial to their future success, and nearly 100% said their AI budgets will increase or stay the same in the next year.&lt;/li&gt;
&lt;li&gt;65% of respondents said their company is actively using AI, up from 45% in last year‚Äôs report.&lt;/li&gt;
&lt;li&gt;61% are using or assessing generative AI, up 52% year over year.&lt;/li&gt;
&lt;li&gt;84% said open source models and software are important to their AI strategy.&lt;/li&gt;
&lt;li&gt;42% are using or assessing agentic AI, with 21% saying they‚Äôve already deployed AI agents.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;‚ÄúOpen source models are fundamentally changing the competitive dynamics in financial AI,‚Äù said Helen Yu, CEO of Tigon Advisory Corp. ‚ÄúThe real value capture happens when institutions fine-tune these models on their proprietary transaction data, customer interaction histories and market intelligence, creating AI capabilities that competitors cannot replicate.‚Äù&lt;/p&gt;
&lt;p&gt;Read more below on some of the report‚Äôs key findings.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Building the Foundation of the Future With Open Source&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Open source models allow for flexibility and efficiency, enabling organizations to tailor development tools to their unique needs and make them more accurate by incorporating a financial institution‚Äôs proprietary data. As a result, 83% percent of respondents said open source is important to their organization‚Äôs AI strategy, with 43% saying it is very to extremely important.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone wp-image-89244 size-medium" height="233" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/finance-question-21-importance-of-open-source-by-role-white-960x233.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;‚ÄúOpen source models can help banks close the gap with early movers, unlock cost efficiencies and safeguard against vendor lock-in, but they‚Äôre not without their limitations ‚Äî proprietary approaches can unlock superior performance for domain-specific tasks,‚Äù said Alexandra Mousavizadeh, cofounder and co-CEO of Evident Insights. ‚ÄúLeading banks need to demonstrate proficiency in both approaches ‚Äî applying the right kind of model to the right problem, in the right context.‚Äù&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Return on Investment of AI in Financial Services Is Clear&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Financial institutions have moved from piloting AI projects to deploying solutions that create business impact and scaling them across the organization. In turn, companies have begun to see significant return on investment from AI on the top and bottom lines.&lt;/p&gt;
&lt;p&gt;As stated above, 89% of survey respondents said AI has helped increase annual revenue and decrease annual costs. For many organizations, the impact has been significant, with 64% of respondents saying AI has helped increase annual revenue by more than 5% ‚Äî including 29% who said revenue increased more than 10%.&lt;/p&gt;
&lt;p&gt;Similarly, 61% said AI had helped decrease annual costs by more than 5%, with 25% saying costs decreased more than 10%.&lt;/p&gt;
&lt;p&gt;Respondents cited a long list of AI use cases that have provided return on investment, including document processing and management, customer experience and engagement, algorithmic trading and risk management.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone wp-image-89241 size-medium" height="337" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/finance-question-19-impact-on-business-operations-industry-top3-white-960x337.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;Creating operational efficiencies is the largest improvement AI has made in financial services, according to 52% of respondents. And 48% said employee productivity was among the biggest improvements.&lt;/p&gt;
&lt;p&gt;‚ÄúThe most tangible ROI I‚Äôm seeing is in payment operations, specifically authorization optimization and intelligent routing,‚Äù said Dwayne Gefferie, payments strategist at Gefferie Group. ‚ÄúAgentic AI systems can now autonomously route transactions to the most optimized payment networks, dynamically adjust retry logic based on real-time issuer signals and make routing decisions under 200-millisecond routing that traditional rule-based systems simply can‚Äôt match. What makes this compelling is that every basis point improvement in authorization rates translates directly to revenue ‚Äî there‚Äôs no ambiguity in measurement.‚Äù&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Success Leads to Increasing AI Budgets&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Given the shift from running proof of concepts to deploying AI-enabled applications into production, the financial services industry is looking to significantly expand AI budgets. Nearly 100% of respondents said their AI budgets would increase or stay the same in the coming year.&lt;/p&gt;
&lt;p&gt;About 41% of respondents said investment would go toward optimizing AI workflows and production, reinvesting in and improving the AI solutions that are already working.&lt;/p&gt;
&lt;p&gt;More than a third (34%) said they had an eye toward AI expansion in their organizations, with spending focused on identifying additional use cases. And 30% said that investment would focus on building or providing more access to AI infrastructure, such as on-premises installations or in the cloud.&lt;/p&gt;
&lt;p&gt;Investment will also flow to deployment and expansion of AI agents, which are advanced AI systems designed to autonomously reason, plan and execute complex tasks based on high-level goals. About 21% of respondents said AI agents have already been deployed, with another 22% saying AI agents will be deployed within the next year and beyond.&lt;/p&gt;
&lt;p&gt;‚ÄúThe institutions winning in AI are treating their proprietary data as a strategic asset for building differentiated AI products,‚Äù said Yu.&lt;/p&gt;
&lt;p&gt;Download the ‚ÄúState of AI in Financial Services: 2026 Trends‚Äù report for in-depth results and insights.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Explore &lt;/i&gt;&lt;i&gt;NVIDIA‚Äôs AI solutions and enterprise-level AI platforms for financial services&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-in-financial-services-survey-2026/</guid><pubDate>Thu, 22 Jan 2026 14:00:54 +0000</pubDate></item><item><title>How to Get Started With Visual Generative AI on NVIDIA RTX PCs (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/rtx-ai-garage-comfyui-tutorial/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI-powered content generation is now embedded in everyday tools like Adobe and Canva, with a slew of agencies and studios incorporating the technology into their workflows. Image models now deliver photorealistic results consistently, video models can generate long and coherent clips, and both can follow creative directions.&lt;/p&gt;
&lt;p&gt;Creators are increasingly running these workflows locally on PCs to keep assets under direct control, remove cloud service costs and eliminate the friction of iteration ‚Äî making it easier to refine outputs at the pace real creative projects demand.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Since their inception, NVIDIA RTX PCs have been the system of choice for running creative AI due to their high performance ‚Äî reducing iteration time ‚Äî and the fact that users can run models on them for free, removing token anxiety.&lt;/p&gt;
&lt;p&gt;With recent RTX optimizations and new open-weight models introduced at CES earlier this month, creatives can work faster, more efficiently and with far greater creative control.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;How to Get Started&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Getting started with visual generative AI can feel complex and limiting. Online AI generators are easy to use but offer limited control.&lt;/p&gt;
&lt;p&gt;Open source community tools like ComfyUI simplify setting up advanced creative workflows and are easy to install. They also provide an easy way to download the latest and greatest models, such as FLUX.2 and LTX-2, as well as top community workflows.&lt;/p&gt;
&lt;p&gt;Here‚Äôs how to get started with visual generative AI locally on RTX PCs using ComfyUI and popular models:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Visit comfy.org to download and install ComfyUI for Windows.&lt;/li&gt;
&lt;li&gt;Launch ComfyUI.&lt;/li&gt;
&lt;li&gt;Create an initial image using the starter template:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-89353" height="777" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/comfyui-template-image-960x777.png" width="960" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Click on the ‚ÄúTemplates‚Äù button, then on ‚ÄúGetting Started‚Äù and choose ‚Äú1.1 Starter ‚Äì Text to Image.‚Äù&lt;/li&gt;
&lt;li&gt;Connect the model ‚ÄúNode‚Äù to the ‚ÄúSave Image Node.‚Äù The nodes work in a pipeline to generate content using AI.&lt;/li&gt;
&lt;li&gt;Press the blue ‚ÄúRun‚Äù button and watch the green ‚ÄúNode‚Äù highlight as the RTX-powered PC generates its first image.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Change the prompt and run it again to enter more deeply into the creative world of visual generative AI.&lt;/p&gt;
&lt;p&gt;Read more below on how to dive into additional ComfyUI templates that use more advanced image and video models.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Model Sizes and GPUs&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As users get more familiar with ComfyUI and the models that support it, they‚Äôll need to consider GPU VRAM capacity and whether a model will fit within it. Here are some examples for getting started, depending on GPU VRAM:&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_89347"&gt;&lt;img alt="alt" class="size-medium wp-image-89347" height="189" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/gpu-vram-image-gen-video-3d-chart-comparison-960x189.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89347"&gt;*Use FP4 models with NVIDIA GeForce RTX 50 Series GPUs, and FP8 models with RTX 40 Series GPUs for best results. This lets models use less VRAM while providing more performance.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Generating Images&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone wp-image-89359 size-medium" height="768" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/2026-01-21-image-gen-tiger-960x768.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;To explore how to improve image generation quality using FLUX.2-Dev:&lt;/p&gt;
&lt;p&gt;From the ComfyUI ‚ÄúTemplates‚Äù section, click on ‚ÄúAll Templates‚Äù and search for ‚ÄúFLUX.2 Dev Text to Image.‚Äù Select it, and ComfyUI will load the collection of connected nodes, or ‚ÄúWorkflow.‚Äù&lt;/p&gt;
&lt;p&gt;FLUX.2-Dev has model weights that will need to be downloaded.&lt;/p&gt;
&lt;p&gt;Model weights are the ‚Äúknowledge‚Äù inside an AI model ‚Äî think of them like the synapses in a brain. When an image generation model like FLUX.2 was trained, it learned patterns from millions of images. Those patterns are stored as billions of numerical values called ‚Äúweights.‚Äù&lt;/p&gt;
&lt;p&gt;ComfyUI doesn‚Äôt come with these weights built in. Instead, it downloads them on demand from repositories like Hugging Face. These files are large (FLUX.2 can be &amp;gt;30GB depending on the version), which is why systems need enough storage and download time to grab them.&lt;/p&gt;
&lt;p&gt;A dialog will appear to guide users through downloading the model weights. The weight files (filename.safetensors) are automatically saved to the correct ComfyUI folder on a user‚Äôs PC.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-89350" height="777" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/2026-01-21-missing-models-screenshot-960x777.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Saving Workflows:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Now that the model weights are downloaded, the next step is to save this newly downloaded template as a ‚ÄúWorkflow.‚Äù&lt;/p&gt;
&lt;p&gt;Users can click on the top-left hamburger menu (three lines) and choose ‚ÄúSave.‚Äù The workflow is now saved in the user‚Äôs list of ‚ÄúWorkflows‚Äù (press W to show or hide the window). Close the tab to exit the workflow without losing any work.&lt;/p&gt;
&lt;p&gt;If the download dialog was accidentally closed before the model weights finished downloading:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Press W to quickly open the ‚ÄúWorkflows‚Äù window.&lt;/li&gt;
&lt;li&gt;Select the Workflow and ComfyUI will load it. This will also prompt for any missing model weights to download.&lt;/li&gt;
&lt;li&gt;ComfyUI is now ready to generate an image using FLUX.2-Dev.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;b&gt;Prompt Tips for FLUX.2-Dev:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start with clear, concrete descriptions of the subject, setting, style and mood ‚Äî for example: ‚ÄúCinematic closeup of a vintage race car in the rain, neon reflections on wet asphalt, high contrast, 35mm photography.‚Äù Short‚Äëto‚Äëmedium length prompts&amp;nbsp; ‚Äî a single, focused sentence or two ‚Äî are usually easier to control than long, storylike prompts, especially when getting started.&lt;/li&gt;
&lt;li&gt;Add constraints to guide consistency and quality. Specify things like:
&lt;ul&gt;
&lt;li&gt;Framing (‚Äúwide shot‚Äù or ‚Äúportrait‚Äù)&lt;/li&gt;
&lt;li&gt;Detail level (‚Äúhigh detail, sharp focus‚Äù)&lt;/li&gt;
&lt;li&gt;Realism (‚Äúphotorealistic‚Äù or ‚Äústylized illustration‚Äù)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If results are too busy, remove adjectives instead of adding more.&lt;/li&gt;
&lt;li&gt;Avoid negative prompting ‚Äî stick to prompting what‚Äôs desired.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Learn more about FLUX.2 prompting in this guide from Black Forest Labs.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Save Locations on Disk:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Once done refining the image, right click on ‚ÄúSave Image Node‚Äù to open the image in a browser, or save it in a new location.&lt;/p&gt;
&lt;p&gt;ComfyUI‚Äôs default output folders are typically the following, based on the application type and OS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows (Standalone/Portable Version): The folder is usually found in C:\ComfyUI\output or a similar path within where the program was unzipped.&lt;/li&gt;
&lt;li&gt;Windows (Desktop Application): The path is usually located within the AppData directory, like: C:\Users\%username%\AppData\Local\Programs\@comfyorgcomfyui-electron\resources\ComfyUI\output&lt;/li&gt;
&lt;li&gt;Linux: The installation location defaults to ~/.config/ComfyUI.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Prompting Videos&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Explore how to improve video generation quality, using the new LTX-2 model as an example:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Lightrick‚Äôs LTX‚Äë2 is an advanced audio-video model designed for controllable, storyboard-style video generation in ComfyUI. Once the LTX‚Äë2 Image to Video Template and model weights are downloaded, start by treating the prompt like a short shot description, rather than a full movie script.&lt;/p&gt;
&lt;p&gt;Unlike the first two Templates, LTX‚Äë2 Image to Video combines an image and a text prompt to generate video.&lt;/p&gt;
&lt;p&gt;Users can take one of the images generated in FLUX.2-Dev and add a text prompt to give it life.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Prompt Tips for LTX‚Äë2:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;For best results in ComfyUI, write a single flowing paragraph in the present tense or use a simple, script‚Äëstyle format with scene headings (sluglines), action, character names and dialogue. Aim for four to six descriptive sentences that cover all the key aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Establish the shot and scene (wide/medium/closeup, lighting, color, textures, atmosphere).&lt;/li&gt;
&lt;li&gt;Describe the action as a clear sequence, define characters with visible traits and body language, and specify camera moves.&lt;/li&gt;
&lt;li&gt;Lastly, add audio, such as ambient sound, music and dialogue, using quotation marks.&lt;/li&gt;
&lt;li&gt;Match the level of detail to the shot scale. For example, closeups need more precise character and texture detail than wide shots. Be clear on how the camera relates to the subject, not just where it moves.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional details to consider adding to prompts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Camera movement language:&lt;/b&gt; Specify directions like ‚Äúslow dolly in,‚Äù ‚Äúhandheld tracking,‚Äù ‚Äúover‚Äëthe‚Äëshoulder shot,‚Äù ‚Äúpans across,‚Äù ‚Äútilts upward,‚Äù ‚Äúpushes in,‚Äù ‚Äúpulls back‚Äù or ‚Äústatic frame.‚Äù&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Shot types:&lt;/b&gt; Specify wide, medium or close‚Äëups with thoughtful lighting, shallow depth of field and natural motion.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Pacing:&lt;/b&gt; Direct for slow motion, time‚Äëlapses, lingering shots, continuous shots, freeze frames or seamless transitions that shape rhythm and tone.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Atmosphere:&lt;/b&gt; Add details like fog, mist, rain, golden hour light, reflections and rich surface textures that ground the scene.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Style:&lt;/b&gt; Early in the prompt, specify styles like painterly, film noir, analog film, stop‚Äëmotion, pixelated edges, fashion editorial or surreal.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Lighting&lt;/b&gt;: Direct backlighting, specific color palettes, soft rim light, lens flares or other lighting details using specific language.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Emotions&lt;/b&gt;: Focus on prompting for single‚Äësubject performances with clear facial expressions and small gestures.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Voice and audio&lt;/b&gt;: Prompt characters to speak or sing in different languages, supported by clear ambient sound descriptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;b&gt;Optimizing VRAM Usage and Image Quality&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;As a frontier model, LTX-2 uses significant amounts of video memory (VRAM) to deliver quality results. Memory use goes up as resolution, frame rates, length or steps increase.&lt;/p&gt;
&lt;p&gt;ComfyUI and NVIDIA have collaborated to optimize a weight streaming feature that allows users to offload parts of the workflow to system memory if their GPU runs out of VRAM ‚Äî but this comes at a cost in performance.&lt;/p&gt;
&lt;p&gt;Depending on the GPU and use case, users may want to constrain these factors to ensure reasonable generation times.&lt;/p&gt;
&lt;p&gt;LTX-2 is an incredibly advanced model ‚Äî but as with any model, tweaking the settings has a big impact on quality.&lt;/p&gt;
&lt;p&gt;Learn more about optimizing LTX-2 usage with RTX GPUs in the Quick Start Guide for LTX-2 In ComfyUI.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building a Custom Workflow With FLUX.2-Dev and LTX-2&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Users can simplify the process of hopping between ComfyUI Workflows with FLUX.2-Dev to generate an image, finding it on disk and adding it as an image prompt to the LTX-2 Image to Video Workflow by combining the models into a new workflow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open the saved FLUX.2-Dev Text to Image Workflow.&lt;/li&gt;
&lt;li&gt;Ctrl+left mouse click the FLUX.2-Dev Text to Image node.&lt;/li&gt;
&lt;li&gt;In the LTX-2 Image to Video Workflow, paste the node using Ctrl+V.&lt;/li&gt;
&lt;li&gt;Simply hover over the FLUX.2-Dev Text to Image node IMAGE dot, left click and drag to the Resize Image/Mask Input dot. A blue connector will appear.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Save with a new name, and text prompt for image and video in one workflow.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Advanced 3D Generation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Beyond generating images with FLUX.2 and videos with LTX‚Äë2, the next step is adding 3D guidance. The NVIDIA Blueprint for 3D-guided generative AI shows how to use 3D scenes and assets to drive more controllable, production-style image and video pipelines on RTX PCs ‚Äî with ready-made workflows users can inspect, tweak and extend.&lt;/p&gt;
&lt;p&gt;Creators can show off their work, connect with other users and find help on the Stable Diffusion subreddit and ComfyUI Discord.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;#ICYMI ‚Äî The Latest Advancements in NVIDIA RTX AI PCs&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;üíª&lt;b&gt;NVIDIA @ CES 2026&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;CES announcements included 4K AI video generation acceleration on PCs with LTX-2 and ComfyUI upgrades. Plus, major RTX accelerations across ComfyUI, LTX-2, Llama.cpp, Ollama, Hyperlink and more unlock video, image and text generation use cases on AI PCs.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;üìù Black Forest Labs FLUX 2 Variants&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;FLUX.2 [klein] is a set of compact, ultrafast models that support both image generation and editing, delivering state-of-the-art image quality. The models are accelerated by NVFP4 and NVFP8, boosting speed by up to 2.5x and enabling them to run performantly across a wide range of RTX GPUs.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;‚ú®Project&lt;/b&gt; &lt;b&gt;G-Assist Update&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;With a new ‚ÄúReasoning Mode‚Äù enabled by default, Project G-Assist gains an accuracy and intelligence boost, as well as the ability to action multiple commands at once. G-Assist can now control settings on G-SYNC monitors, CORSAIR peripherals and CORSAIR PC components through iCUE ‚Äî covering lighting, profiles, performance and cooling.&lt;/p&gt;
&lt;p&gt;Support is also coming soon to Elgato Stream Decks, bringing G-Assist closer to a unified AI interface for tuning and controlling nearly any system. For G-Assist plug-in devs, a new Cursor-based plug-in builder accelerates development using Cursor‚Äôs agentic coding environment.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Plug in to NVIDIA AI PC on &lt;/i&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;TikTok&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt; ‚Äî and stay informed by subscribing to the &lt;/i&gt;&lt;i&gt;RTX AI PC newsletter&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Follow NVIDIA Workstation on &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI-powered content generation is now embedded in everyday tools like Adobe and Canva, with a slew of agencies and studios incorporating the technology into their workflows. Image models now deliver photorealistic results consistently, video models can generate long and coherent clips, and both can follow creative directions.&lt;/p&gt;
&lt;p&gt;Creators are increasingly running these workflows locally on PCs to keep assets under direct control, remove cloud service costs and eliminate the friction of iteration ‚Äî making it easier to refine outputs at the pace real creative projects demand.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Since their inception, NVIDIA RTX PCs have been the system of choice for running creative AI due to their high performance ‚Äî reducing iteration time ‚Äî and the fact that users can run models on them for free, removing token anxiety.&lt;/p&gt;
&lt;p&gt;With recent RTX optimizations and new open-weight models introduced at CES earlier this month, creatives can work faster, more efficiently and with far greater creative control.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;How to Get Started&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Getting started with visual generative AI can feel complex and limiting. Online AI generators are easy to use but offer limited control.&lt;/p&gt;
&lt;p&gt;Open source community tools like ComfyUI simplify setting up advanced creative workflows and are easy to install. They also provide an easy way to download the latest and greatest models, such as FLUX.2 and LTX-2, as well as top community workflows.&lt;/p&gt;
&lt;p&gt;Here‚Äôs how to get started with visual generative AI locally on RTX PCs using ComfyUI and popular models:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Visit comfy.org to download and install ComfyUI for Windows.&lt;/li&gt;
&lt;li&gt;Launch ComfyUI.&lt;/li&gt;
&lt;li&gt;Create an initial image using the starter template:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-89353" height="777" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/comfyui-template-image-960x777.png" width="960" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ul&gt;
&lt;li&gt;Click on the ‚ÄúTemplates‚Äù button, then on ‚ÄúGetting Started‚Äù and choose ‚Äú1.1 Starter ‚Äì Text to Image.‚Äù&lt;/li&gt;
&lt;li&gt;Connect the model ‚ÄúNode‚Äù to the ‚ÄúSave Image Node.‚Äù The nodes work in a pipeline to generate content using AI.&lt;/li&gt;
&lt;li&gt;Press the blue ‚ÄúRun‚Äù button and watch the green ‚ÄúNode‚Äù highlight as the RTX-powered PC generates its first image.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Change the prompt and run it again to enter more deeply into the creative world of visual generative AI.&lt;/p&gt;
&lt;p&gt;Read more below on how to dive into additional ComfyUI templates that use more advanced image and video models.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Model Sizes and GPUs&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;As users get more familiar with ComfyUI and the models that support it, they‚Äôll need to consider GPU VRAM capacity and whether a model will fit within it. Here are some examples for getting started, depending on GPU VRAM:&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_89347"&gt;&lt;img alt="alt" class="size-medium wp-image-89347" height="189" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/gpu-vram-image-gen-video-3d-chart-comparison-960x189.png" width="960" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-89347"&gt;*Use FP4 models with NVIDIA GeForce RTX 50 Series GPUs, and FP8 models with RTX 40 Series GPUs for best results. This lets models use less VRAM while providing more performance.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Generating Images&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone wp-image-89359 size-medium" height="768" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/2026-01-21-image-gen-tiger-960x768.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;To explore how to improve image generation quality using FLUX.2-Dev:&lt;/p&gt;
&lt;p&gt;From the ComfyUI ‚ÄúTemplates‚Äù section, click on ‚ÄúAll Templates‚Äù and search for ‚ÄúFLUX.2 Dev Text to Image.‚Äù Select it, and ComfyUI will load the collection of connected nodes, or ‚ÄúWorkflow.‚Äù&lt;/p&gt;
&lt;p&gt;FLUX.2-Dev has model weights that will need to be downloaded.&lt;/p&gt;
&lt;p&gt;Model weights are the ‚Äúknowledge‚Äù inside an AI model ‚Äî think of them like the synapses in a brain. When an image generation model like FLUX.2 was trained, it learned patterns from millions of images. Those patterns are stored as billions of numerical values called ‚Äúweights.‚Äù&lt;/p&gt;
&lt;p&gt;ComfyUI doesn‚Äôt come with these weights built in. Instead, it downloads them on demand from repositories like Hugging Face. These files are large (FLUX.2 can be &amp;gt;30GB depending on the version), which is why systems need enough storage and download time to grab them.&lt;/p&gt;
&lt;p&gt;A dialog will appear to guide users through downloading the model weights. The weight files (filename.safetensors) are automatically saved to the correct ComfyUI folder on a user‚Äôs PC.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-medium wp-image-89350" height="777" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/2026-01-21-missing-models-screenshot-960x777.png" width="960" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Saving Workflows:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Now that the model weights are downloaded, the next step is to save this newly downloaded template as a ‚ÄúWorkflow.‚Äù&lt;/p&gt;
&lt;p&gt;Users can click on the top-left hamburger menu (three lines) and choose ‚ÄúSave.‚Äù The workflow is now saved in the user‚Äôs list of ‚ÄúWorkflows‚Äù (press W to show or hide the window). Close the tab to exit the workflow without losing any work.&lt;/p&gt;
&lt;p&gt;If the download dialog was accidentally closed before the model weights finished downloading:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Press W to quickly open the ‚ÄúWorkflows‚Äù window.&lt;/li&gt;
&lt;li&gt;Select the Workflow and ComfyUI will load it. This will also prompt for any missing model weights to download.&lt;/li&gt;
&lt;li&gt;ComfyUI is now ready to generate an image using FLUX.2-Dev.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;b&gt;Prompt Tips for FLUX.2-Dev:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Start with clear, concrete descriptions of the subject, setting, style and mood ‚Äî for example: ‚ÄúCinematic closeup of a vintage race car in the rain, neon reflections on wet asphalt, high contrast, 35mm photography.‚Äù Short‚Äëto‚Äëmedium length prompts&amp;nbsp; ‚Äî a single, focused sentence or two ‚Äî are usually easier to control than long, storylike prompts, especially when getting started.&lt;/li&gt;
&lt;li&gt;Add constraints to guide consistency and quality. Specify things like:
&lt;ul&gt;
&lt;li&gt;Framing (‚Äúwide shot‚Äù or ‚Äúportrait‚Äù)&lt;/li&gt;
&lt;li&gt;Detail level (‚Äúhigh detail, sharp focus‚Äù)&lt;/li&gt;
&lt;li&gt;Realism (‚Äúphotorealistic‚Äù or ‚Äústylized illustration‚Äù)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;If results are too busy, remove adjectives instead of adding more.&lt;/li&gt;
&lt;li&gt;Avoid negative prompting ‚Äî stick to prompting what‚Äôs desired.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Learn more about FLUX.2 prompting in this guide from Black Forest Labs.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Save Locations on Disk:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;Once done refining the image, right click on ‚ÄúSave Image Node‚Äù to open the image in a browser, or save it in a new location.&lt;/p&gt;
&lt;p&gt;ComfyUI‚Äôs default output folders are typically the following, based on the application type and OS:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Windows (Standalone/Portable Version): The folder is usually found in C:\ComfyUI\output or a similar path within where the program was unzipped.&lt;/li&gt;
&lt;li&gt;Windows (Desktop Application): The path is usually located within the AppData directory, like: C:\Users\%username%\AppData\Local\Programs\@comfyorgcomfyui-electron\resources\ComfyUI\output&lt;/li&gt;
&lt;li&gt;Linux: The installation location defaults to ~/.config/ComfyUI.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;b&gt;Prompting Videos&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Explore how to improve video generation quality, using the new LTX-2 model as an example:&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;Lightrick‚Äôs LTX‚Äë2 is an advanced audio-video model designed for controllable, storyboard-style video generation in ComfyUI. Once the LTX‚Äë2 Image to Video Template and model weights are downloaded, start by treating the prompt like a short shot description, rather than a full movie script.&lt;/p&gt;
&lt;p&gt;Unlike the first two Templates, LTX‚Äë2 Image to Video combines an image and a text prompt to generate video.&lt;/p&gt;
&lt;p&gt;Users can take one of the images generated in FLUX.2-Dev and add a text prompt to give it life.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Prompt Tips for LTX‚Äë2:&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;For best results in ComfyUI, write a single flowing paragraph in the present tense or use a simple, script‚Äëstyle format with scene headings (sluglines), action, character names and dialogue. Aim for four to six descriptive sentences that cover all the key aspects:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Establish the shot and scene (wide/medium/closeup, lighting, color, textures, atmosphere).&lt;/li&gt;
&lt;li&gt;Describe the action as a clear sequence, define characters with visible traits and body language, and specify camera moves.&lt;/li&gt;
&lt;li&gt;Lastly, add audio, such as ambient sound, music and dialogue, using quotation marks.&lt;/li&gt;
&lt;li&gt;Match the level of detail to the shot scale. For example, closeups need more precise character and texture detail than wide shots. Be clear on how the camera relates to the subject, not just where it moves.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Additional details to consider adding to prompts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Camera movement language:&lt;/b&gt; Specify directions like ‚Äúslow dolly in,‚Äù ‚Äúhandheld tracking,‚Äù ‚Äúover‚Äëthe‚Äëshoulder shot,‚Äù ‚Äúpans across,‚Äù ‚Äútilts upward,‚Äù ‚Äúpushes in,‚Äù ‚Äúpulls back‚Äù or ‚Äústatic frame.‚Äù&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Shot types:&lt;/b&gt; Specify wide, medium or close‚Äëups with thoughtful lighting, shallow depth of field and natural motion.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Pacing:&lt;/b&gt; Direct for slow motion, time‚Äëlapses, lingering shots, continuous shots, freeze frames or seamless transitions that shape rhythm and tone.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Atmosphere:&lt;/b&gt; Add details like fog, mist, rain, golden hour light, reflections and rich surface textures that ground the scene.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Style:&lt;/b&gt; Early in the prompt, specify styles like painterly, film noir, analog film, stop‚Äëmotion, pixelated edges, fashion editorial or surreal.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Lighting&lt;/b&gt;: Direct backlighting, specific color palettes, soft rim light, lens flares or other lighting details using specific language.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Emotions&lt;/b&gt;: Focus on prompting for single‚Äësubject performances with clear facial expressions and small gestures.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Voice and audio&lt;/b&gt;: Prompt characters to speak or sing in different languages, supported by clear ambient sound descriptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;b&gt;Optimizing VRAM Usage and Image Quality&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;As a frontier model, LTX-2 uses significant amounts of video memory (VRAM) to deliver quality results. Memory use goes up as resolution, frame rates, length or steps increase.&lt;/p&gt;
&lt;p&gt;ComfyUI and NVIDIA have collaborated to optimize a weight streaming feature that allows users to offload parts of the workflow to system memory if their GPU runs out of VRAM ‚Äî but this comes at a cost in performance.&lt;/p&gt;
&lt;p&gt;Depending on the GPU and use case, users may want to constrain these factors to ensure reasonable generation times.&lt;/p&gt;
&lt;p&gt;LTX-2 is an incredibly advanced model ‚Äî but as with any model, tweaking the settings has a big impact on quality.&lt;/p&gt;
&lt;p&gt;Learn more about optimizing LTX-2 usage with RTX GPUs in the Quick Start Guide for LTX-2 In ComfyUI.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building a Custom Workflow With FLUX.2-Dev and LTX-2&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Users can simplify the process of hopping between ComfyUI Workflows with FLUX.2-Dev to generate an image, finding it on disk and adding it as an image prompt to the LTX-2 Image to Video Workflow by combining the models into a new workflow:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Open the saved FLUX.2-Dev Text to Image Workflow.&lt;/li&gt;
&lt;li&gt;Ctrl+left mouse click the FLUX.2-Dev Text to Image node.&lt;/li&gt;
&lt;li&gt;In the LTX-2 Image to Video Workflow, paste the node using Ctrl+V.&lt;/li&gt;
&lt;li&gt;Simply hover over the FLUX.2-Dev Text to Image node IMAGE dot, left click and drag to the Resize Image/Mask Input dot. A blue connector will appear.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Save with a new name, and text prompt for image and video in one workflow.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Advanced 3D Generation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Beyond generating images with FLUX.2 and videos with LTX‚Äë2, the next step is adding 3D guidance. The NVIDIA Blueprint for 3D-guided generative AI shows how to use 3D scenes and assets to drive more controllable, production-style image and video pipelines on RTX PCs ‚Äî with ready-made workflows users can inspect, tweak and extend.&lt;/p&gt;
&lt;p&gt;Creators can show off their work, connect with other users and find help on the Stable Diffusion subreddit and ComfyUI Discord.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;#ICYMI ‚Äî The Latest Advancements in NVIDIA RTX AI PCs&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;üíª&lt;b&gt;NVIDIA @ CES 2026&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;CES announcements included 4K AI video generation acceleration on PCs with LTX-2 and ComfyUI upgrades. Plus, major RTX accelerations across ComfyUI, LTX-2, Llama.cpp, Ollama, Hyperlink and more unlock video, image and text generation use cases on AI PCs.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;üìù Black Forest Labs FLUX 2 Variants&amp;nbsp;&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;FLUX.2 [klein] is a set of compact, ultrafast models that support both image generation and editing, delivering state-of-the-art image quality. The models are accelerated by NVFP4 and NVFP8, boosting speed by up to 2.5x and enabling them to run performantly across a wide range of RTX GPUs.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;‚ú®Project&lt;/b&gt; &lt;b&gt;G-Assist Update&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;With a new ‚ÄúReasoning Mode‚Äù enabled by default, Project G-Assist gains an accuracy and intelligence boost, as well as the ability to action multiple commands at once. G-Assist can now control settings on G-SYNC monitors, CORSAIR peripherals and CORSAIR PC components through iCUE ‚Äî covering lighting, profiles, performance and cooling.&lt;/p&gt;
&lt;p&gt;Support is also coming soon to Elgato Stream Decks, bringing G-Assist closer to a unified AI interface for tuning and controlling nearly any system. For G-Assist plug-in devs, a new Cursor-based plug-in builder accelerates development using Cursor‚Äôs agentic coding environment.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Plug in to NVIDIA AI PC on &lt;/i&gt;&lt;i&gt;Facebook&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;Instagram&lt;/i&gt;&lt;i&gt;, &lt;/i&gt;&lt;i&gt;TikTok&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt; ‚Äî and stay informed by subscribing to the &lt;/i&gt;&lt;i&gt;RTX AI PC newsletter&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Follow NVIDIA Workstation on &lt;/i&gt;&lt;i&gt;LinkedIn&lt;/i&gt;&lt;i&gt; and &lt;/i&gt;&lt;i&gt;X&lt;/i&gt;&lt;i&gt;.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;&lt;i&gt;See &lt;/i&gt;&lt;i&gt;notice&lt;/i&gt;&lt;i&gt; regarding software product information.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/rtx-ai-garage-comfyui-tutorial/</guid><pubDate>Thu, 22 Jan 2026 14:00:57 +0000</pubDate></item><item><title>From invisibility cloaks to AI chips: Neurophos raises $110M to build tiny optical processors for inferencing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/from-invisibility-cloaks-to-ai-chips-neurophos-raises-110m-to-build-tiny-optical-processors-for-inferencing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/02/tc-backlight-e1689786273147.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Twenty years ago, a Duke University professor, David R. Smith, used artificial composite materials called ‚Äúmetamaterials‚Äù to make a real-life invisibility cloak. While this cloak didn‚Äôt really work like Harry Potter‚Äôs, exhibiting limited ability to conceal objects from the light of a single microwave length, those advances in material science did eventually trickle down to electromagnetism research.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, Austin-based Neurophos, a photonics startup spun out of Duke University and Metacept (an incubator run by Smith), is taking that research further to solve what may be the biggest problem facing AI labs and hyperscalers: how to scale computing power while keeping power consumption in check.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup has come up with a ‚Äúmetasurface modulator‚Äù with optical properties that enable it to serve as a tensor core processor for doing matrix vector multiplication ‚Äî math that is at the heart of a lot of AI work (particularly inferencing), currently performed by specialized GPUs and TPUs that use traditional silicon gates and transistors. By fitting thousands of these modulators on a chip, Neurophos claims, its ‚Äúoptical processing unit‚Äù is significantly faster than the silicon GPUs currently used en masse at AI data centers, and far more efficient at inferencing (running trained models), which can be a fairly expensive task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To fund the development of its chips, Neurophos has just raised $110 million in a Series A round led by Gates Frontier (Bill Gates‚Äô venture firm), with participation from Microsoft‚Äôs M12, Carbon Direct, Aramco Ventures, Bosch Ventures, Tectonic Ventures, Space Capital, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, photonic chips are nothing new. In theory, photonic chips offer higher performance than traditional silicon because light produces less heat than electricity, it can travel faster, and is far less susceptible to changes in temperature and electromagnetic fields.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But optical components tend to be much larger than their silicon counterparts, and can be difficult to mass-produce. And they also need converters to transform data from digital to analog and back, which can be large and take up a lot of power.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neurophos, however, posits that the metasurface it has developed can solve all of those problems in one swoop because it is about ‚Äú10,000 times‚Äù smaller than traditional optical transistors. The small size, the startup claims, enables it to fit thousands of units on a chip, which results in far more efficiency than traditional silicon because the chip can do many more calculations at once.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhen you shrink the optical transistor, you can do way more math in the optics domain before you have to do that conversion back to the electronics domain,‚Äù Dr. Patrick Bowen, CEO and co-founder of Neurophos, told TechCrunch. ‚ÄúIf you want to go fast, you have to solve the energy efficiency problem first. Because if you‚Äôre going to take a chip and make it 100 times faster, it burns 100 times more power. So you get the privilege of going fast after you solve the energy efficiency problem.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The result, Neurophos claims, is an optical processing unit that can wildly outperform Nvidia‚Äôs B200 AI GPU. The startup says its chip can run at 56 GHz, yielding a peak 235 Peta Operations per Second (POPS) and consuming 675 watts, compared to the B200, which can deliver 9 POPS at 1,000 watts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bowen says Neurophos has already signed multiple customers (though he declined to name any), and companies including Microsoft are ‚Äúlooking very closely‚Äù at the startup‚Äôs products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, the startup is entering a crowded market that‚Äôs dominated by Nvidia, the world‚Äôs most valuable public company, whose products have more or less underpinned the entire AI boom. There are also other companies working on photonics, though some, like Lightmatter, have pivoted to focusing on interconnects. And Neurophos is still a few years away from production, expecting its first chips to hit the market by mid-2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Bowen is confident the performance and efficiency advances provided by its metasurface modulators will prove a sufficient moat.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhat everyone else is doing is, and this includes Nvidia, in terms of the fundamental physics of the silicon, it‚Äôs really evolutionary rather than revolutionary, and it‚Äôs tied to the progress of TSMC. If you look at the improvement of TSMC nodes, on average, they improve in energy efficiency about 15%, and that takes a couple years,‚Äù he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúEven if we chart out Nvidia‚Äôs improvement in architecture over the years, by the time we come out in 2028, we still have massive advantages over everyone else in the market because we‚Äôre starting with a 50x over Blackwell in both energy efficiency and raw speed.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And to address the mass-manufacturing issues optical chips have traditionally faced, Neurophos says its chips can be made with standard silicon foundry materials, tools, and processes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh funding will be used for the development of the company‚Äôs first integrated photonic compute system, including data center-ready OPU modules, a full software stack, and early-access developer hardware. The company is also opening a San Francisco engineering site and expanding its HQ in Austin, Texas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúModern AI inference demands monumental amounts of power and compute,‚Äù Dr. Marc Tremblay, corporate vice president and technical fellow of core AI infrastructure at Microsoft, said in a statement. ‚ÄúWe need a breakthrough in compute on par with the leaps we‚Äôve seen in AI models themselves, which is what Neurophos‚Äô technology and high-talent density team is developing.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/02/tc-backlight-e1689786273147.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Twenty years ago, a Duke University professor, David R. Smith, used artificial composite materials called ‚Äúmetamaterials‚Äù to make a real-life invisibility cloak. While this cloak didn‚Äôt really work like Harry Potter‚Äôs, exhibiting limited ability to conceal objects from the light of a single microwave length, those advances in material science did eventually trickle down to electromagnetism research.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, Austin-based Neurophos, a photonics startup spun out of Duke University and Metacept (an incubator run by Smith), is taking that research further to solve what may be the biggest problem facing AI labs and hyperscalers: how to scale computing power while keeping power consumption in check.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup has come up with a ‚Äúmetasurface modulator‚Äù with optical properties that enable it to serve as a tensor core processor for doing matrix vector multiplication ‚Äî math that is at the heart of a lot of AI work (particularly inferencing), currently performed by specialized GPUs and TPUs that use traditional silicon gates and transistors. By fitting thousands of these modulators on a chip, Neurophos claims, its ‚Äúoptical processing unit‚Äù is significantly faster than the silicon GPUs currently used en masse at AI data centers, and far more efficient at inferencing (running trained models), which can be a fairly expensive task.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To fund the development of its chips, Neurophos has just raised $110 million in a Series A round led by Gates Frontier (Bill Gates‚Äô venture firm), with participation from Microsoft‚Äôs M12, Carbon Direct, Aramco Ventures, Bosch Ventures, Tectonic Ventures, Space Capital, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, photonic chips are nothing new. In theory, photonic chips offer higher performance than traditional silicon because light produces less heat than electricity, it can travel faster, and is far less susceptible to changes in temperature and electromagnetic fields.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But optical components tend to be much larger than their silicon counterparts, and can be difficult to mass-produce. And they also need converters to transform data from digital to analog and back, which can be large and take up a lot of power.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neurophos, however, posits that the metasurface it has developed can solve all of those problems in one swoop because it is about ‚Äú10,000 times‚Äù smaller than traditional optical transistors. The small size, the startup claims, enables it to fit thousands of units on a chip, which results in far more efficiency than traditional silicon because the chip can do many more calculations at once.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhen you shrink the optical transistor, you can do way more math in the optics domain before you have to do that conversion back to the electronics domain,‚Äù Dr. Patrick Bowen, CEO and co-founder of Neurophos, told TechCrunch. ‚ÄúIf you want to go fast, you have to solve the energy efficiency problem first. Because if you‚Äôre going to take a chip and make it 100 times faster, it burns 100 times more power. So you get the privilege of going fast after you solve the energy efficiency problem.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The result, Neurophos claims, is an optical processing unit that can wildly outperform Nvidia‚Äôs B200 AI GPU. The startup says its chip can run at 56 GHz, yielding a peak 235 Peta Operations per Second (POPS) and consuming 675 watts, compared to the B200, which can deliver 9 POPS at 1,000 watts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bowen says Neurophos has already signed multiple customers (though he declined to name any), and companies including Microsoft are ‚Äúlooking very closely‚Äù at the startup‚Äôs products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, the startup is entering a crowded market that‚Äôs dominated by Nvidia, the world‚Äôs most valuable public company, whose products have more or less underpinned the entire AI boom. There are also other companies working on photonics, though some, like Lightmatter, have pivoted to focusing on interconnects. And Neurophos is still a few years away from production, expecting its first chips to hit the market by mid-2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Bowen is confident the performance and efficiency advances provided by its metasurface modulators will prove a sufficient moat.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWhat everyone else is doing is, and this includes Nvidia, in terms of the fundamental physics of the silicon, it‚Äôs really evolutionary rather than revolutionary, and it‚Äôs tied to the progress of TSMC. If you look at the improvement of TSMC nodes, on average, they improve in energy efficiency about 15%, and that takes a couple years,‚Äù he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúEven if we chart out Nvidia‚Äôs improvement in architecture over the years, by the time we come out in 2028, we still have massive advantages over everyone else in the market because we‚Äôre starting with a 50x over Blackwell in both energy efficiency and raw speed.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And to address the mass-manufacturing issues optical chips have traditionally faced, Neurophos says its chips can be made with standard silicon foundry materials, tools, and processes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh funding will be used for the development of the company‚Äôs first integrated photonic compute system, including data center-ready OPU modules, a full software stack, and early-access developer hardware. The company is also opening a San Francisco engineering site and expanding its HQ in Austin, Texas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúModern AI inference demands monumental amounts of power and compute,‚Äù Dr. Marc Tremblay, corporate vice president and technical fellow of core AI infrastructure at Microsoft, said in a statement. ‚ÄúWe need a breakthrough in compute on par with the leaps we‚Äôve seen in AI models themselves, which is what Neurophos‚Äô technology and high-talent density team is developing.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/from-invisibility-cloaks-to-ai-chips-neurophos-raises-110m-to-build-tiny-optical-processors-for-inferencing/</guid><pubDate>Thu, 22 Jan 2026 15:00:52 +0000</pubDate></item><item><title>Google snags team behind AI voice startup Hume AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/google-reportedly-snags-up-team-behind-ai-voice-startup-hume-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2166080568.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The top talent behind yet another promising AI startup has been gobbled up by an incumbent. As part of a new licensing agreement, Google DeepMind is bringing on the CEO and several of the top engineers at voice AI startup Hume AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wired was the first to report the news. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CEO Alan Cowen and about seven other engineers will work with DeepMind to improve Gemini‚Äôs voice features, according to Wired. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What‚Äôs left of Hume AI will continue to supply its technology to other AI firms. No financial details of the deal were shared, but Andrew Ettinger, an investor and tech executive who joined the Hume AI team last week and has taken over as CEO, told TechCrunch that Google has a ‚Äúnon-exclusive right to all of our IP, and we‚Äôll be infusing that into their processes.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that Hume AI would be releasing new models in the coming months, and is on track to bring in $100 million in revenue this year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Hume acqui-hire is the latest example of a leading AI firm scooping top talent off the market and skirting regulatory scrutiny by acquiring a startup‚Äôs team rather than the company outright. Last year, Google acquired viral AI coding startup Windsurf‚Äôs CEO and other top researchers, and OpenAI has acquired several startup teams in recent months, including Convogo and Roi. The Federal Trade Commission recently said that it would take a closer look at such deals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal also shows that voice is becoming the next frontier in AI.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Hume AI‚Äôs secret sauce is its model‚Äôs ability to understand a user‚Äôs emotions and mood based on their voice. In 2024, the startup launched its Empathetic Voice Interface, a conversational AI with emotional intelligence. Hume AI has raised close to $80 million to date according to PitchBook.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Hume AI isn‚Äôt the only company working on voice-focused models. Google has been steadily improving its Gemini Live feature, which allows a user to have conversations with the chatbot. Last month, Google released a new native audio model for the Live API that improved the model‚Äôs ability to ‚Äúhandle complex workflows,‚Äù per the Gemini API release notes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others in the industry are investing big into voice capabilities as well. OpenAI is reportedly preparing to overhaul its audio models in preparation for its audio-first personal device, created with Jonny Ive‚Äôs io, to launch this year. Recent leaks suggest the device could be a form of earbuds.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, Meta also accelerated its AI audio push by acquiring startup Play AI. The Facebook-maker‚Äôs Ray-Ban smart glasses are increasingly relying on voice and audio capabilities for tasks like helping you hear conversations in noisy rooms and enabling hands-free control for calls, texts, music, and photos.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúVoice is the only acceptable input mode for wearables,‚Äù investor Vanessa Larco told TechCrunch. ‚ÄúThis acquisition will only accelerate the need for voice apps.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Demand continues to increase for voice capabilities. Earlier this month, ElevenLabs, the AI voice generation startup, said it crossed $330 million in annual recurring revenue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated with comment from Hume AI. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2166080568.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The top talent behind yet another promising AI startup has been gobbled up by an incumbent. As part of a new licensing agreement, Google DeepMind is bringing on the CEO and several of the top engineers at voice AI startup Hume AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wired was the first to report the news. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CEO Alan Cowen and about seven other engineers will work with DeepMind to improve Gemini‚Äôs voice features, according to Wired. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What‚Äôs left of Hume AI will continue to supply its technology to other AI firms. No financial details of the deal were shared, but Andrew Ettinger, an investor and tech executive who joined the Hume AI team last week and has taken over as CEO, told TechCrunch that Google has a ‚Äúnon-exclusive right to all of our IP, and we‚Äôll be infusing that into their processes.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that Hume AI would be releasing new models in the coming months, and is on track to bring in $100 million in revenue this year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Hume acqui-hire is the latest example of a leading AI firm scooping top talent off the market and skirting regulatory scrutiny by acquiring a startup‚Äôs team rather than the company outright. Last year, Google acquired viral AI coding startup Windsurf‚Äôs CEO and other top researchers, and OpenAI has acquired several startup teams in recent months, including Convogo and Roi. The Federal Trade Commission recently said that it would take a closer look at such deals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal also shows that voice is becoming the next frontier in AI.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Hume AI‚Äôs secret sauce is its model‚Äôs ability to understand a user‚Äôs emotions and mood based on their voice. In 2024, the startup launched its Empathetic Voice Interface, a conversational AI with emotional intelligence. Hume AI has raised close to $80 million to date according to PitchBook.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Hume AI isn‚Äôt the only company working on voice-focused models. Google has been steadily improving its Gemini Live feature, which allows a user to have conversations with the chatbot. Last month, Google released a new native audio model for the Live API that improved the model‚Äôs ability to ‚Äúhandle complex workflows,‚Äù per the Gemini API release notes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others in the industry are investing big into voice capabilities as well. OpenAI is reportedly preparing to overhaul its audio models in preparation for its audio-first personal device, created with Jonny Ive‚Äôs io, to launch this year. Recent leaks suggest the device could be a form of earbuds.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, Meta also accelerated its AI audio push by acquiring startup Play AI. The Facebook-maker‚Äôs Ray-Ban smart glasses are increasingly relying on voice and audio capabilities for tasks like helping you hear conversations in noisy rooms and enabling hands-free control for calls, texts, music, and photos.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúVoice is the only acceptable input mode for wearables,‚Äù investor Vanessa Larco told TechCrunch. ‚ÄúThis acquisition will only accelerate the need for voice apps.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Demand continues to increase for voice capabilities. Earlier this month, ElevenLabs, the AI voice generation startup, said it crossed $330 million in annual recurring revenue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated with comment from Hume AI. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/google-reportedly-snags-up-team-behind-ai-voice-startup-hume-ai/</guid><pubDate>Thu, 22 Jan 2026 15:12:51 +0000</pubDate></item><item><title>eBay bans illicit automated shopping amid rapid rise of AI agents (AI - Ars Technica)</title><link>https://arstechnica.com/information-technology/2026/01/ebay-bans-illicit-automated-shopping-amid-rapid-rise-of-ai-agents/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New policy requires ‚Äúbuy for me‚Äù AI tools and chatbots to obtain permission before accessing the platform.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Studio shot of vintage robot toy standing by miniature shopping basket filled with electronic equipment" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/robot_shopper_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Studio shot of vintage robot toy standing by miniature shopping basket filled with electronic equipment" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/robot_shopper_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Westend61 via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, eBay updated its User Agreement to explicitly ban third-party ‚Äúbuy for me‚Äù agents and AI chatbots from interacting with its platform without permission, first spotted by Value Added Resource. On its face, a one-line terms of service update doesn‚Äôt seem like major news, but what it implies is more significant: The change reflects the rapid emergence of what some are calling ‚Äúagentic commerce,‚Äù a new category of AI tools designed to browse, compare, and purchase products on behalf of users.&lt;/p&gt;
&lt;p&gt;eBay‚Äôs updated terms, which go into effect on February 20, 2026, specifically prohibit users from employing ‚Äúbuy-for-me agents, LLM-driven bots, or any end-to-end flow that attempts to place orders without human review‚Äù to access eBay‚Äôs services without the site‚Äôs permission. The previous version of the agreement contained a general prohibition on robots, spiders, scrapers, and automated data gathering tools but did not mention AI agents or LLMs by name.&lt;/p&gt;
&lt;p&gt;At first glance, the phrase ‚Äúagentic commerce‚Äù may sound like aspirational marketing jargon, but the tools are already here, and people are apparently using them. While fitting loosely under one label, these tools come in many forms.&lt;/p&gt;
&lt;p&gt;OpenAI first added shopping features to ChatGPT Search in April 2025, allowing users to browse product recommendations. By September, the company launched Instant Checkout, which lets users purchase items from Etsy and Shopify merchants directly within the chat interface. (In November, eBay CEO Jamie Iannone suggested the company might join OpenAI‚Äôs Instant Checkout program in the future.)&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Elsewhere, Perplexity offers ‚ÄúBuy with Pro,‚Äù a one-click checkout feature for its paying subscribers. Google recently announced its Universal Commerce Protocol, an open standard for AI agents to interact with retailers. And Amazon offers a ‚ÄúBuy For Me‚Äù feature, which uses AI to purchase items from external brand websites within the Amazon app.&lt;/p&gt;
&lt;h2&gt;Even with new restrictions, eBay leaves the door open&lt;/h2&gt;
&lt;p&gt;eBay‚Äôs policy update follows the company‚Äôs quiet changes to its robots.txt file in December, a special file on a web server that lists rules and prohibitions that sites hope web-crawling bots will follow. According to Modern Retail, eBay added a new ‚ÄúRobot &amp;amp; Agent Policy‚Äù to the file that prohibited automated scraping and buy-for-me agents. eBay later updated the file to add explicit blocks against bots from Perplexity, Anthropic, Amazon, and others, though it allowed Google‚Äôs shopping bot to access the site.&lt;/p&gt;
&lt;p&gt;However, restrictions in robots.txt files are basically honor-system suggestions. By adding the language to its User Agreement, eBay can now more easily take legal action against users or companies who violate the policy.&lt;/p&gt;
&lt;p&gt;Notably, even with this general mood against robotic commerce from outsiders, eBay‚Äôs new User Agreement policy does not prevent the company from developing its own AI shopping tools. CEO Jamie Iannone said on an October earnings call that eBay is ‚Äútesting a variety of agentic experiences in search and shopping.‚Äù The rules also allow such bots ‚Äúwith the prior express permission of eBay,‚Äù which could open the door to official shopping partnerships with companies like OpenAI.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New policy requires ‚Äúbuy for me‚Äù AI tools and chatbots to obtain permission before accessing the platform.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Studio shot of vintage robot toy standing by miniature shopping basket filled with electronic equipment" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/robot_shopper_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Studio shot of vintage robot toy standing by miniature shopping basket filled with electronic equipment" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/robot_shopper_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Westend61 via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, eBay updated its User Agreement to explicitly ban third-party ‚Äúbuy for me‚Äù agents and AI chatbots from interacting with its platform without permission, first spotted by Value Added Resource. On its face, a one-line terms of service update doesn‚Äôt seem like major news, but what it implies is more significant: The change reflects the rapid emergence of what some are calling ‚Äúagentic commerce,‚Äù a new category of AI tools designed to browse, compare, and purchase products on behalf of users.&lt;/p&gt;
&lt;p&gt;eBay‚Äôs updated terms, which go into effect on February 20, 2026, specifically prohibit users from employing ‚Äúbuy-for-me agents, LLM-driven bots, or any end-to-end flow that attempts to place orders without human review‚Äù to access eBay‚Äôs services without the site‚Äôs permission. The previous version of the agreement contained a general prohibition on robots, spiders, scrapers, and automated data gathering tools but did not mention AI agents or LLMs by name.&lt;/p&gt;
&lt;p&gt;At first glance, the phrase ‚Äúagentic commerce‚Äù may sound like aspirational marketing jargon, but the tools are already here, and people are apparently using them. While fitting loosely under one label, these tools come in many forms.&lt;/p&gt;
&lt;p&gt;OpenAI first added shopping features to ChatGPT Search in April 2025, allowing users to browse product recommendations. By September, the company launched Instant Checkout, which lets users purchase items from Etsy and Shopify merchants directly within the chat interface. (In November, eBay CEO Jamie Iannone suggested the company might join OpenAI‚Äôs Instant Checkout program in the future.)&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Elsewhere, Perplexity offers ‚ÄúBuy with Pro,‚Äù a one-click checkout feature for its paying subscribers. Google recently announced its Universal Commerce Protocol, an open standard for AI agents to interact with retailers. And Amazon offers a ‚ÄúBuy For Me‚Äù feature, which uses AI to purchase items from external brand websites within the Amazon app.&lt;/p&gt;
&lt;h2&gt;Even with new restrictions, eBay leaves the door open&lt;/h2&gt;
&lt;p&gt;eBay‚Äôs policy update follows the company‚Äôs quiet changes to its robots.txt file in December, a special file on a web server that lists rules and prohibitions that sites hope web-crawling bots will follow. According to Modern Retail, eBay added a new ‚ÄúRobot &amp;amp; Agent Policy‚Äù to the file that prohibited automated scraping and buy-for-me agents. eBay later updated the file to add explicit blocks against bots from Perplexity, Anthropic, Amazon, and others, though it allowed Google‚Äôs shopping bot to access the site.&lt;/p&gt;
&lt;p&gt;However, restrictions in robots.txt files are basically honor-system suggestions. By adding the language to its User Agreement, eBay can now more easily take legal action against users or companies who violate the policy.&lt;/p&gt;
&lt;p&gt;Notably, even with this general mood against robotic commerce from outsiders, eBay‚Äôs new User Agreement policy does not prevent the company from developing its own AI shopping tools. CEO Jamie Iannone said on an October earnings call that eBay is ‚Äútesting a variety of agentic experiences in search and shopping.‚Äù The rules also allow such bots ‚Äúwith the prior express permission of eBay,‚Äù which could open the door to official shopping partnerships with companies like OpenAI.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2026/01/ebay-bans-illicit-automated-shopping-amid-rapid-rise-of-ai-agents/</guid><pubDate>Thu, 22 Jan 2026 15:56:33 +0000</pubDate></item><item><title>Google‚Äôs AI Mode can now tap into your Gmail and Photos to provide tailored responses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/googles-ai-mode-can-now-tap-into-your-gmail-and-photos-to-provide-tailored-responses/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI Mode, Google‚Äôs conversational Search feature for complex questions, is getting more personalized. The tech giant announced on Thursday that it‚Äôs bringing ‚ÄúPersonal Intelligence‚Äù to AI Mode, enabling it to tap into your Gmail and Google Photos to provide more individualized responses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company debuted Personal Intelligence last week in the Gemini app to allow the AI assistant to tailor its responses by connecting across your Google ecosystem, starting with Gmail, Photos, Search, and YouTube history.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The opt-in feature is now starting to roll out to AI Mode to Google AI Pro and AI Ultra subscribers in English in the U.S. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing Personal Intelligence to Gemini and AI Mode, Google is leveraging the wealth of user data already within its ecosystem. Since users already rely on services like Gmail and Photos, Google can deliver more personalized experiences that rivals can‚Äôt easily match. Of course, not everyone wants AI looking at their photos and emails, so you can turn Personal Intelligence on or off at any time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWith Personal Intelligence, recommendations don‚Äôt just match your interests ‚Äî they fit seamlessly into your life,‚Äù Robby Stein, VP of Product, Google Search, explained in a blog post. ‚ÄúYou don‚Äôt have to constantly explain your preferences or existing plans, it selects recommendations just for you, right from the start.‚Äù&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085026" height="403" src="https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-22-at-10.13.11-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Say you‚Äôre planning a vacation and searching for things to do and places to eat that everyone in your family will enjoy. With Personal Intelligence, AI Mode can draw on your hotel booking in Gmail and past travel memories in Google Photos to suggest a tailored itinerary with something for everyone. For example, you might see recommendations like an old-timey ice cream parlor based on the many ice cream selfies stored in Google Photos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that AI Mode won‚Äôt just give you a generic list of restaurants and activities; it instead provides a personalized starting point for planning.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPersonal Intelligence can also be particularly helpful for shopping, because AI Mode considers the types of items you buy and where you shop,‚Äù Stein wrote. ‚ÄúIf you need a new coat for your upcoming trip, AI Mode could automatically take into account the brands you prefer, as well as your flight confirmation in Gmail to identify the destination and timing (Chicago in March). You‚Äôll get suggestions for windproof, versatile coats that fit the weather and your preferred look. It‚Äôs like a personal shopper who already knows your itinerary and the vibe you‚Äôre going for.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google says other questions you could ask are: ‚ÄúMake a scavenger hunt for [partner‚Äôs name] to celebrate our anniversary. For each location, include a hint about us,‚Äù or ‚ÄúI‚Äôm decorating [child‚Äôs name ]‚Äôs bedroom, give me ideas for a theme and suggestions for decor.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company notes that AI Mode doesn‚Äôt train directly on your Gmail inbox or Google Photos library. Instead, it trains on specific prompts and the model‚Äôs responses.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI Mode, Google‚Äôs conversational Search feature for complex questions, is getting more personalized. The tech giant announced on Thursday that it‚Äôs bringing ‚ÄúPersonal Intelligence‚Äù to AI Mode, enabling it to tap into your Gmail and Google Photos to provide more individualized responses.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company debuted Personal Intelligence last week in the Gemini app to allow the AI assistant to tailor its responses by connecting across your Google ecosystem, starting with Gmail, Photos, Search, and YouTube history.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The opt-in feature is now starting to roll out to AI Mode to Google AI Pro and AI Ultra subscribers in English in the U.S. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing Personal Intelligence to Gemini and AI Mode, Google is leveraging the wealth of user data already within its ecosystem. Since users already rely on services like Gmail and Photos, Google can deliver more personalized experiences that rivals can‚Äôt easily match. Of course, not everyone wants AI looking at their photos and emails, so you can turn Personal Intelligence on or off at any time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWith Personal Intelligence, recommendations don‚Äôt just match your interests ‚Äî they fit seamlessly into your life,‚Äù Robby Stein, VP of Product, Google Search, explained in a blog post. ‚ÄúYou don‚Äôt have to constantly explain your preferences or existing plans, it selects recommendations just for you, right from the start.‚Äù&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085026" height="403" src="https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-22-at-10.13.11-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Say you‚Äôre planning a vacation and searching for things to do and places to eat that everyone in your family will enjoy. With Personal Intelligence, AI Mode can draw on your hotel booking in Gmail and past travel memories in Google Photos to suggest a tailored itinerary with something for everyone. For example, you might see recommendations like an old-timey ice cream parlor based on the many ice cream selfies stored in Google Photos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that AI Mode won‚Äôt just give you a generic list of restaurants and activities; it instead provides a personalized starting point for planning.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPersonal Intelligence can also be particularly helpful for shopping, because AI Mode considers the types of items you buy and where you shop,‚Äù Stein wrote. ‚ÄúIf you need a new coat for your upcoming trip, AI Mode could automatically take into account the brands you prefer, as well as your flight confirmation in Gmail to identify the destination and timing (Chicago in March). You‚Äôll get suggestions for windproof, versatile coats that fit the weather and your preferred look. It‚Äôs like a personal shopper who already knows your itinerary and the vibe you‚Äôre going for.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google says other questions you could ask are: ‚ÄúMake a scavenger hunt for [partner‚Äôs name] to celebrate our anniversary. For each location, include a hint about us,‚Äù or ‚ÄúI‚Äôm decorating [child‚Äôs name ]‚Äôs bedroom, give me ideas for a theme and suggestions for decor.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company notes that AI Mode doesn‚Äôt train directly on your Gmail inbox or Google Photos library. Instead, it trains on specific prompts and the model‚Äôs responses.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/googles-ai-mode-can-now-tap-into-your-gmail-and-photos-to-provide-tailored-responses/</guid><pubDate>Thu, 22 Jan 2026 16:00:00 +0000</pubDate></item><item><title>Google adds your Gmail and Photos to AI Mode to enable "Personal Intelligence" (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/01/google-ai-mode-can-now-customize-responses-with-your-email-and-photos/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Personal Intelligence is optional and rolling out first to AI Pro and AI Ultra subscribers.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="AI Mode banner" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-640x360.png" width="640" /&gt;
                  &lt;img alt="AI Mode banner" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google believes AI is the future of search, and it‚Äôs not shy about saying it. After adding account-level personalization to Gemini earlier this month, it‚Äôs now updating AI Mode with so-called ‚ÄúPersonal Intelligence.‚Äù According to Google, this makes the bot‚Äôs answers more useful because they are tailored to your personal context.&lt;/p&gt;
&lt;p&gt;Starting today, the feature is rolling out to all users who subscribe to Google AI Pro or AI Ultra. However, it will be a Labs feature that needs to be explicitly enabled (subscribers will be prompted to do this). Google tends to expand access to new AI features to free accounts later on, so free users will most likely get access to Personal Intelligence in the future. Whenever this option does land on your account, it‚Äôs entirely optional and can be disabled at any time.&lt;/p&gt;
&lt;p&gt;If you decide to integrate your data with AI Mode, the search bot will be able to scan your Gmail and Google Photos. That‚Äôs less extensive than the Gemini app version, which supports Gmail, Photos, Search, and YouTube history. Gmail will probably be the biggest contributor to AI Mode‚Äîa great many life events involve confirmation emails. Traditional search results when you are logged in are adjusted based on your usage history, but this goes a step further.&lt;/p&gt;
&lt;p&gt;If you‚Äôre going to use AI Mode to find information, Personal Intelligence could actually be quite helpful. When you connect data from other Google apps, Google‚Äôs custom Gemini search model will instantly know about your preferences and background‚Äîthat‚Äôs the kind of information you‚Äôd otherwise have to include in your search query to get the best output. With Personal Intelligence, AI Mode can just pull those details from your email or photos.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For example, as in the video below, you could ask about clothing options for an upcoming trip. Instead of telling the robot when and where you‚Äôre going in the prompt, it can get that information from your email confirmation. When AI Mode uses your personal context in a response, it will cite it in-line the same way it does for websites.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Personal Intelligence in AI Mode.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;h2&gt;Perfectly imperfect&lt;/h2&gt;
&lt;p&gt;Google says, as it often does, that AI is not perfect. AI Mode with Personal Intelligence can make mistakes, drawing the wrong conclusions from the data it mines from your account. In that case, Google suggests using a follow-up prompt to correct it and get more accurate information. It‚Äôs similar to the way you might refine a traditional Google search when the links aren‚Äôt to your liking.&lt;/p&gt;
&lt;p&gt;AI Mode and Google AI are generally supposed to improve over time to reduce such failures. The way you use the service contributes to that, but Google says the model is not being trained directly on your email or photos, even if you connect them to AI Mode. Instead, Google uses your prompts and the resulting output to train its AI models. Access to Gmail and Photos can be revoked at any time, but it sounds like there won‚Äôt be a simple way to toggle off Personal Intelligence for a single query, which is possible in Gemini.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Personal Intelligence is optional and rolling out first to AI Pro and AI Ultra subscribers.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="AI Mode banner" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-640x360.png" width="640" /&gt;
                  &lt;img alt="AI Mode banner" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/AI-Mode-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google believes AI is the future of search, and it‚Äôs not shy about saying it. After adding account-level personalization to Gemini earlier this month, it‚Äôs now updating AI Mode with so-called ‚ÄúPersonal Intelligence.‚Äù According to Google, this makes the bot‚Äôs answers more useful because they are tailored to your personal context.&lt;/p&gt;
&lt;p&gt;Starting today, the feature is rolling out to all users who subscribe to Google AI Pro or AI Ultra. However, it will be a Labs feature that needs to be explicitly enabled (subscribers will be prompted to do this). Google tends to expand access to new AI features to free accounts later on, so free users will most likely get access to Personal Intelligence in the future. Whenever this option does land on your account, it‚Äôs entirely optional and can be disabled at any time.&lt;/p&gt;
&lt;p&gt;If you decide to integrate your data with AI Mode, the search bot will be able to scan your Gmail and Google Photos. That‚Äôs less extensive than the Gemini app version, which supports Gmail, Photos, Search, and YouTube history. Gmail will probably be the biggest contributor to AI Mode‚Äîa great many life events involve confirmation emails. Traditional search results when you are logged in are adjusted based on your usage history, but this goes a step further.&lt;/p&gt;
&lt;p&gt;If you‚Äôre going to use AI Mode to find information, Personal Intelligence could actually be quite helpful. When you connect data from other Google apps, Google‚Äôs custom Gemini search model will instantly know about your preferences and background‚Äîthat‚Äôs the kind of information you‚Äôd otherwise have to include in your search query to get the best output. With Personal Intelligence, AI Mode can just pull those details from your email or photos.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For example, as in the video below, you could ask about clothing options for an upcoming trip. Instead of telling the robot when and where you‚Äôre going in the prompt, it can get that information from your email confirmation. When AI Mode uses your personal context in a response, it will cite it in-line the same way it does for websites.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Personal Intelligence in AI Mode.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;h2&gt;Perfectly imperfect&lt;/h2&gt;
&lt;p&gt;Google says, as it often does, that AI is not perfect. AI Mode with Personal Intelligence can make mistakes, drawing the wrong conclusions from the data it mines from your account. In that case, Google suggests using a follow-up prompt to correct it and get more accurate information. It‚Äôs similar to the way you might refine a traditional Google search when the links aren‚Äôt to your liking.&lt;/p&gt;
&lt;p&gt;AI Mode and Google AI are generally supposed to improve over time to reduce such failures. The way you use the service contributes to that, but Google says the model is not being trained directly on your email or photos, even if you connect them to AI Mode. Instead, Google uses your prompts and the resulting output to train its AI models. Access to Gmail and Photos can be revoked at any time, but it sounds like there won‚Äôt be a simple way to toggle off Personal Intelligence for a single query, which is possible in Gemini.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/01/google-ai-mode-can-now-customize-responses-with-your-email-and-photos/</guid><pubDate>Thu, 22 Jan 2026 16:35:41 +0000</pubDate></item><item><title>Dispatch from Davos: hot air, big egos and cold flexes (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/22/1131687/hot-air-cold-flexes-at-davos/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/260122_WEF.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story first appeared in The Debrief, our subscriber-only newsletter about the biggest news in tech&amp;nbsp;by Mat Honan, Editor in Chief. Subscribe to read the next edition as soon as it lands. &lt;/em&gt;&lt;/p&gt;  &lt;p&gt;It‚Äôs supposed to be frigid in Davos this time of year. Part of the charm is seeing the world‚Äôs elite tromp through the streets in respectable suits and snow boots. But this year it‚Äôs positively balmy, with highs in the mid 30s, or a little over 1¬∞C. The current conditions when I flew out of New York were colder, and definitely snowier. I‚Äôm told this is due to something called a f√∂hn, a dry warm wind that‚Äôs been blowing across the Alps.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;I‚Äôm no meteorologist, but it‚Äôs true that there is a lot of hot air here.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On Wednesday, President Donald Trump arrived in Davos to address the assembly, and held forth for more than 90 minutes, weaving his way through remarks about the economy, Greenland, windmills, Switzerland, Rolexes, Venezuela, and drug prices. It was a talk lousy with gripes, grievances and outright falsehoods.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;One small example: Trump made a big deal of claiming that China, despite being the world leader in manufacturing windmill componentry, doesn‚Äôt actually use them for energy generation itself. In fact, it is the world leader in generation, as well.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I did not get to watch this spectacle from the room itself. Sad!&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;By the time I got to the Congress Hall where the address was taking place, there was already a massive scrum of people jostling to get in.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I had just wrapped up moderating a panel on ‚Äúthe intelligent co-worker,‚Äù ie: AI agents in the workplace. I was really excited for this one as the speakers represented a diverse cross-section of the AI ecosystem. Christoph Schweizer, CEO of BCG had the macro strategic view; Enrique Lores, HP CEO, could speak to both hardware and large enterprises, Workera CEO Kian Katanforoosh has the inside view on workforce training and transformation, Manjul Shah CEO of Hippocratic AI addressed working in the high stakes field of healthcare, and Kate Kallot CEO of Amini AI gave perspective on the global south and Africa in particular.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Interestingly, most of the panel shied away from using the term co-worker, and some even rejected the term agent. But the view they painted was definitely one of humans working alongside AI and augmenting what‚Äôs possible. Shah, for example, talked about having agents call 16,000 people in Texas during a heat wave to perform a health and safety check. It was a great discussion. You can watch the whole thing here.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But by the time it let out, the push of people outside the Congress Hall was already too thick for me to get in. In fact I couldn‚Äôt even get into a nearby overflow room. I did make it into a third overflow room, but getting in meant navigating my way through a mass of people, so jammed in tight together that it reminded me of being at a Turnstile concert.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The speech blew way past its allotted time, and I had to step out early to get to yet another discussion. Walking through the halls while Trump spoke was a truly surreal experience. He had truly captured the attention of the gathered global elite. I don‚Äôt think I saw a single person not starting at a laptop, or phone or iPad, all watching the same video.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Trump is speaking again on Thursday in a previously unscheduled address to announce his Board of Peace. As is (I heard) Elon Musk. So it‚Äôs shaping up to be another big day for elite attention capture.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I should say, though, there are elites, and then there are &lt;em&gt;elites&lt;/em&gt;. And there are all sorts of ways of sorting out who is who. Your badge color is one of them. I have a white participant badge, because I was moderating panels. This gets you in pretty much anywhere and therefore is its own sort of status symbol. Where you are staying is another. I‚Äôm in Klosters, a neighboring town that‚Äôs a 40 minute train ride away from the Congress Centre. Not so elite.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There are more subtle ways of status sorting, too. Yesterday I learned that when people ask if this is your first time at Davos, it‚Äôs sometimes meant as a way of trying to figure out how important you are. If you‚Äôre any kind of big deal, you‚Äôve probably been coming for years.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;But the best one I‚Äôve yet encountered happened when I made small talk with the woman sitting next to me as I changed back into my snow boots. It turned out that, like me, she lived in California‚Äìat least part time. ‚ÄúBut I don‚Äôt think I‚Äôll stay there much longer,‚Äù she said, ‚Äúdue to the new tax law.‚Äù This was just an ice cold flex.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Because California‚Äôs newly proposed tax legislation? It only targets billionaires.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Welcome to Davos.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/260122_WEF.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story first appeared in The Debrief, our subscriber-only newsletter about the biggest news in tech&amp;nbsp;by Mat Honan, Editor in Chief. Subscribe to read the next edition as soon as it lands. &lt;/em&gt;&lt;/p&gt;  &lt;p&gt;It‚Äôs supposed to be frigid in Davos this time of year. Part of the charm is seeing the world‚Äôs elite tromp through the streets in respectable suits and snow boots. But this year it‚Äôs positively balmy, with highs in the mid 30s, or a little over 1¬∞C. The current conditions when I flew out of New York were colder, and definitely snowier. I‚Äôm told this is due to something called a f√∂hn, a dry warm wind that‚Äôs been blowing across the Alps.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;I‚Äôm no meteorologist, but it‚Äôs true that there is a lot of hot air here.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;On Wednesday, President Donald Trump arrived in Davos to address the assembly, and held forth for more than 90 minutes, weaving his way through remarks about the economy, Greenland, windmills, Switzerland, Rolexes, Venezuela, and drug prices. It was a talk lousy with gripes, grievances and outright falsehoods.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;One small example: Trump made a big deal of claiming that China, despite being the world leader in manufacturing windmill componentry, doesn‚Äôt actually use them for energy generation itself. In fact, it is the world leader in generation, as well.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I did not get to watch this spectacle from the room itself. Sad!&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;By the time I got to the Congress Hall where the address was taking place, there was already a massive scrum of people jostling to get in.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I had just wrapped up moderating a panel on ‚Äúthe intelligent co-worker,‚Äù ie: AI agents in the workplace. I was really excited for this one as the speakers represented a diverse cross-section of the AI ecosystem. Christoph Schweizer, CEO of BCG had the macro strategic view; Enrique Lores, HP CEO, could speak to both hardware and large enterprises, Workera CEO Kian Katanforoosh has the inside view on workforce training and transformation, Manjul Shah CEO of Hippocratic AI addressed working in the high stakes field of healthcare, and Kate Kallot CEO of Amini AI gave perspective on the global south and Africa in particular.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Interestingly, most of the panel shied away from using the term co-worker, and some even rejected the term agent. But the view they painted was definitely one of humans working alongside AI and augmenting what‚Äôs possible. Shah, for example, talked about having agents call 16,000 people in Texas during a heat wave to perform a health and safety check. It was a great discussion. You can watch the whole thing here.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But by the time it let out, the push of people outside the Congress Hall was already too thick for me to get in. In fact I couldn‚Äôt even get into a nearby overflow room. I did make it into a third overflow room, but getting in meant navigating my way through a mass of people, so jammed in tight together that it reminded me of being at a Turnstile concert.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;The speech blew way past its allotted time, and I had to step out early to get to yet another discussion. Walking through the halls while Trump spoke was a truly surreal experience. He had truly captured the attention of the gathered global elite. I don‚Äôt think I saw a single person not starting at a laptop, or phone or iPad, all watching the same video.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Trump is speaking again on Thursday in a previously unscheduled address to announce his Board of Peace. As is (I heard) Elon Musk. So it‚Äôs shaping up to be another big day for elite attention capture.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I should say, though, there are elites, and then there are &lt;em&gt;elites&lt;/em&gt;. And there are all sorts of ways of sorting out who is who. Your badge color is one of them. I have a white participant badge, because I was moderating panels. This gets you in pretty much anywhere and therefore is its own sort of status symbol. Where you are staying is another. I‚Äôm in Klosters, a neighboring town that‚Äôs a 40 minute train ride away from the Congress Centre. Not so elite.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;There are more subtle ways of status sorting, too. Yesterday I learned that when people ask if this is your first time at Davos, it‚Äôs sometimes meant as a way of trying to figure out how important you are. If you‚Äôre any kind of big deal, you‚Äôve probably been coming for years.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;But the best one I‚Äôve yet encountered happened when I made small talk with the woman sitting next to me as I changed back into my snow boots. It turned out that, like me, she lived in California‚Äìat least part time. ‚ÄúBut I don‚Äôt think I‚Äôll stay there much longer,‚Äù she said, ‚Äúdue to the new tax law.‚Äù This was just an ice cold flex.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Because California‚Äôs newly proposed tax legislation? It only targets billionaires.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Welcome to Davos.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/22/1131687/hot-air-cold-flexes-at-davos/</guid><pubDate>Thu, 22 Jan 2026 16:39:55 +0000</pubDate></item><item><title>Small models, big results: Achieving superior intent extraction through decomposition (The latest research from Google)</title><link>https://research.google/blog/small-models-big-results-achieving-superior-intent-extraction-through-decomposition/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;As AI technologies advance, truly helpful agents will become capable of better anticipating user needs. For experiences on mobile devices to be truly helpful, the underlying models need to understand what the user is doing (or trying to do) when users interact with them. Once current and previous tasks are understood, the model has more context to predict potential next actions. For example, if a user previously searched for music festivals across Europe and is now looking for a flight to London, the agent could offer to find festivals in London on those specific dates.&lt;/p&gt;&lt;p&gt;Large multimodal LLMs are already quite good at understanding user intent from a user interface (UI) trajectory. But using LLMs for this task would typically require sending information to a server, which can be slow, costly, and carries the potential risk of exposing sensitive information.&lt;/p&gt;&lt;p&gt;Our recent paper ‚ÄúSmall Models, Big Results: Achieving Superior Intent Extraction Through Decomposition‚Äù, presented at EMNLP 2025, addresses the question of how to use &lt;i&gt;small&lt;/i&gt; multimodal LLMs (MLLMs) to understand sequences of user interactions on the web and on mobile devices all on device. By separating user intent understanding into two stages, first summarizing each screen separately and then extracting an intent from the sequence of generated summaries, we make the task more tractable for small models. We also formalize metrics for evaluation of model performance and show that our approach yields results comparable to much larger models, illustrating its potential for on-device applications. This work builds on previous work from our team on user intent understanding.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;As AI technologies advance, truly helpful agents will become capable of better anticipating user needs. For experiences on mobile devices to be truly helpful, the underlying models need to understand what the user is doing (or trying to do) when users interact with them. Once current and previous tasks are understood, the model has more context to predict potential next actions. For example, if a user previously searched for music festivals across Europe and is now looking for a flight to London, the agent could offer to find festivals in London on those specific dates.&lt;/p&gt;&lt;p&gt;Large multimodal LLMs are already quite good at understanding user intent from a user interface (UI) trajectory. But using LLMs for this task would typically require sending information to a server, which can be slow, costly, and carries the potential risk of exposing sensitive information.&lt;/p&gt;&lt;p&gt;Our recent paper ‚ÄúSmall Models, Big Results: Achieving Superior Intent Extraction Through Decomposition‚Äù, presented at EMNLP 2025, addresses the question of how to use &lt;i&gt;small&lt;/i&gt; multimodal LLMs (MLLMs) to understand sequences of user interactions on the web and on mobile devices all on device. By separating user intent understanding into two stages, first summarizing each screen separately and then extracting an intent from the sequence of generated summaries, we make the task more tractable for small models. We also formalize metrics for evaluation of model performance and show that our approach yields results comparable to much larger models, illustrating its potential for on-device applications. This work builds on previous work from our team on user intent understanding.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/small-models-big-results-achieving-superior-intent-extraction-through-decomposition/</guid><pubDate>Thu, 22 Jan 2026 16:56:44 +0000</pubDate></item><item><title>Controlling AI agent sprawl: The CIO‚Äôs guide to governance (AI News)</title><link>https://www.artificialintelligence-news.com/news/controlling-ai-agent-sprawl-cio-guide-to-governance/</link><description>&lt;p&gt;Corporate networks are filling up with AI agents, creating a governance blind spot for leaders managing multi-cloud infrastructures.&lt;/p&gt;&lt;p&gt;As distinct business units race to adopt generative technologies, CIOs especially find their ecosystems populated by fragmented and unmonitored assets. This mirrors the shadow IT challenges of the cloud era, but involves autonomous actors capable of executing business logic and accessing sensitive data.&lt;/p&gt;&lt;p&gt;IDC projects the number of actively deployed AI agents will exceed one billion by 2029‚Äîa forty-fold increase from current levels. In the first half of 2025 alone, agent creation surged by 119 percent. For enterprise leadership, the immediate challenge shifts from building these agents to locating, auditing, and governing them across platforms.&lt;/p&gt;&lt;p&gt;Salesforce has responded to this fragmentation by expanding its MuleSoft Agent Fabric capabilities, introducing automated discovery tools designed to centralise the management of AI agents regardless of their origin.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-automating-discovery"&gt;Automating discovery&lt;/h3&gt;&lt;p&gt;Visibility remains the core issue for security and operations teams. When marketing teams deploy AI agents on one platform and logistics teams build on another, effective governance becomes difficult as central IT loses a consolidated view of the organisation‚Äôs digital workforce.&lt;/p&gt;&lt;p&gt;MuleSoft‚Äôs updated architecture addresses this via ‚ÄòAgent Scanners‚Äô. These tools continuously patrol major ecosystems ‚Äì including Salesforce Agentforce, Amazon Bedrock, and Google Vertex AI ‚Äì to identify running agents. Rather than relying on developers to manually register their deployments, the system automates detection.&lt;/p&gt;&lt;p&gt;Finding an agent is only the first step; compliance leaders need to understand the logic behind it. The scanners extract metadata detailing the agent‚Äôs capabilities, the LLMs driving it, and the specific data endpoints it is authorised to access. This information is then normalised into standard Agent-to-Agent (A2A) specifications, creating a uniform profile for assets regardless of the underlying vendor.&lt;/p&gt;&lt;p&gt;Andrew Comstock, SVP and GM of MuleSoft, said: ‚ÄúThe most successful organisations of the next decade will be those that harness the full diversity of the multi-cloud AI landscape. The expanded capabilities of MuleSoft Agent Fabric give you the freedom to innovate across any platform while maintaining the unified visibility and control needed to scale.‚Äù&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-and-cost-control-for-ai-agents"&gt;Governance and cost control for AI agents&lt;/h3&gt;&lt;p&gt;Unmanaged agents create financial inefficiency and risk exposure. Consider a CISO in the banking sector. Under standard operations, verifying a new loan-processing agent involves manually chasing documentation from development teams. Automated cataloguing allows security teams to immediately view which financial databases an agent accesses and verify its authorisation levels without manual intervention. This capability ensures security teams view real-time data rather than outdated snapshots.&lt;/p&gt;&lt;p&gt;From a financial perspective, visibility drives consolidation. Large enterprises frequently suffer from redundancy where regional teams independently procure or build similar tools. A multinational manufacturer, for instance, might have three separate teams paying for distinct summarisation agents on different platforms.&lt;/p&gt;&lt;p&gt;By using the MuleSoft Agent Visualizer to filter the estate by job type, operations leaders can identify these overlaps. Consolidating these into a single high-performing asset reduces redundant licensing costs and allows budget reallocation toward novel development.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-transitioning-successfully-to-an-agentic-enterprise"&gt;Transitioning successfully to an ‚ÄòAgentic Enterprise‚Äô&lt;/h3&gt;&lt;p&gt;Innovation often occurs at the edges, where data scientists build bespoke tools outside formal procurement channels.&lt;/p&gt;&lt;p&gt;The expanded Agent Fabric addresses this by allowing the registration of ‚Äúhomegrown‚Äù agents and Model Context Protocol (MCP) servers via URL. This is particularly relevant for sectors like logistics, where teams may build internal tools for proprietary database optimisation. Instead of remaining hidden, these assets can be registered and made discoverable for reuse across the company.&lt;/p&gt;&lt;p&gt;Jonathan Harvey, Head of AI Operations at Capita, said: ‚ÄúAgent Scanners will let us focus on innovation instead of inventory management. Knowing that every agent is automatically discovered and catalogued allows our teams to collaborate, reuse work, and build smarter multi-agent solutions.‚Äù&lt;/p&gt;&lt;p&gt;Similarly, AT&amp;amp;T is utilising the framework to orchestrate agents across customer support, chat, and voice interactions.&lt;/p&gt;&lt;p&gt;Brad Ringer, Enterprise &amp;amp; Integration Architect at AT&amp;amp;T, explained: ‚ÄúWith AI moving so fast, MuleSoft Agent Fabric provides the framework we need to scale. It brings together and helps us orchestrate all of the agents and MCP servers we‚Äôre building in customer support, chat, and voice interactions. It isn‚Äôt just a tool; it‚Äôs a huge enabler for everything we‚Äôre doing next.‚Äù&lt;/p&gt;&lt;p&gt;The transition to an ‚ÄúAgentic Enterprise‚Äù requires a change in governance around how IT assets are tracked, rendering the days of managing integrations via stale spreadsheets incompatible with the speed of AI agent deployment.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Leaders must assume their inventory of AI agents is incomplete and deploy automated scanning tools to establish a baseline of truth. Once this baseline is established, governance policies should mandate that all agents ‚Äì whether bought or built ‚Äì expose their capabilities and data access privileges in a standardised format like A2A to facilitate monitoring.&lt;/p&gt;&lt;p&gt;Finally, executives can use the visibility provided by these tools to audit spend, identifying duplicate functionalities across cloud environments and merging them to control the Total Cost of Ownership (TCO).&amp;nbsp;&lt;/p&gt;&lt;p&gt;As organisations move from pilot programmes to mass deployment, the differentiator will not be the intelligence of individual agents, but the coherence of the network that connects them.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Balancing AI cost efficiency with data sovereignty&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Corporate networks are filling up with AI agents, creating a governance blind spot for leaders managing multi-cloud infrastructures.&lt;/p&gt;&lt;p&gt;As distinct business units race to adopt generative technologies, CIOs especially find their ecosystems populated by fragmented and unmonitored assets. This mirrors the shadow IT challenges of the cloud era, but involves autonomous actors capable of executing business logic and accessing sensitive data.&lt;/p&gt;&lt;p&gt;IDC projects the number of actively deployed AI agents will exceed one billion by 2029‚Äîa forty-fold increase from current levels. In the first half of 2025 alone, agent creation surged by 119 percent. For enterprise leadership, the immediate challenge shifts from building these agents to locating, auditing, and governing them across platforms.&lt;/p&gt;&lt;p&gt;Salesforce has responded to this fragmentation by expanding its MuleSoft Agent Fabric capabilities, introducing automated discovery tools designed to centralise the management of AI agents regardless of their origin.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-automating-discovery"&gt;Automating discovery&lt;/h3&gt;&lt;p&gt;Visibility remains the core issue for security and operations teams. When marketing teams deploy AI agents on one platform and logistics teams build on another, effective governance becomes difficult as central IT loses a consolidated view of the organisation‚Äôs digital workforce.&lt;/p&gt;&lt;p&gt;MuleSoft‚Äôs updated architecture addresses this via ‚ÄòAgent Scanners‚Äô. These tools continuously patrol major ecosystems ‚Äì including Salesforce Agentforce, Amazon Bedrock, and Google Vertex AI ‚Äì to identify running agents. Rather than relying on developers to manually register their deployments, the system automates detection.&lt;/p&gt;&lt;p&gt;Finding an agent is only the first step; compliance leaders need to understand the logic behind it. The scanners extract metadata detailing the agent‚Äôs capabilities, the LLMs driving it, and the specific data endpoints it is authorised to access. This information is then normalised into standard Agent-to-Agent (A2A) specifications, creating a uniform profile for assets regardless of the underlying vendor.&lt;/p&gt;&lt;p&gt;Andrew Comstock, SVP and GM of MuleSoft, said: ‚ÄúThe most successful organisations of the next decade will be those that harness the full diversity of the multi-cloud AI landscape. The expanded capabilities of MuleSoft Agent Fabric give you the freedom to innovate across any platform while maintaining the unified visibility and control needed to scale.‚Äù&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-governance-and-cost-control-for-ai-agents"&gt;Governance and cost control for AI agents&lt;/h3&gt;&lt;p&gt;Unmanaged agents create financial inefficiency and risk exposure. Consider a CISO in the banking sector. Under standard operations, verifying a new loan-processing agent involves manually chasing documentation from development teams. Automated cataloguing allows security teams to immediately view which financial databases an agent accesses and verify its authorisation levels without manual intervention. This capability ensures security teams view real-time data rather than outdated snapshots.&lt;/p&gt;&lt;p&gt;From a financial perspective, visibility drives consolidation. Large enterprises frequently suffer from redundancy where regional teams independently procure or build similar tools. A multinational manufacturer, for instance, might have three separate teams paying for distinct summarisation agents on different platforms.&lt;/p&gt;&lt;p&gt;By using the MuleSoft Agent Visualizer to filter the estate by job type, operations leaders can identify these overlaps. Consolidating these into a single high-performing asset reduces redundant licensing costs and allows budget reallocation toward novel development.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-transitioning-successfully-to-an-agentic-enterprise"&gt;Transitioning successfully to an ‚ÄòAgentic Enterprise‚Äô&lt;/h3&gt;&lt;p&gt;Innovation often occurs at the edges, where data scientists build bespoke tools outside formal procurement channels.&lt;/p&gt;&lt;p&gt;The expanded Agent Fabric addresses this by allowing the registration of ‚Äúhomegrown‚Äù agents and Model Context Protocol (MCP) servers via URL. This is particularly relevant for sectors like logistics, where teams may build internal tools for proprietary database optimisation. Instead of remaining hidden, these assets can be registered and made discoverable for reuse across the company.&lt;/p&gt;&lt;p&gt;Jonathan Harvey, Head of AI Operations at Capita, said: ‚ÄúAgent Scanners will let us focus on innovation instead of inventory management. Knowing that every agent is automatically discovered and catalogued allows our teams to collaborate, reuse work, and build smarter multi-agent solutions.‚Äù&lt;/p&gt;&lt;p&gt;Similarly, AT&amp;amp;T is utilising the framework to orchestrate agents across customer support, chat, and voice interactions.&lt;/p&gt;&lt;p&gt;Brad Ringer, Enterprise &amp;amp; Integration Architect at AT&amp;amp;T, explained: ‚ÄúWith AI moving so fast, MuleSoft Agent Fabric provides the framework we need to scale. It brings together and helps us orchestrate all of the agents and MCP servers we‚Äôre building in customer support, chat, and voice interactions. It isn‚Äôt just a tool; it‚Äôs a huge enabler for everything we‚Äôre doing next.‚Äù&lt;/p&gt;&lt;p&gt;The transition to an ‚ÄúAgentic Enterprise‚Äù requires a change in governance around how IT assets are tracked, rendering the days of managing integrations via stale spreadsheets incompatible with the speed of AI agent deployment.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Leaders must assume their inventory of AI agents is incomplete and deploy automated scanning tools to establish a baseline of truth. Once this baseline is established, governance policies should mandate that all agents ‚Äì whether bought or built ‚Äì expose their capabilities and data access privileges in a standardised format like A2A to facilitate monitoring.&lt;/p&gt;&lt;p&gt;Finally, executives can use the visibility provided by these tools to audit spend, identifying duplicate functionalities across cloud environments and merging them to control the Total Cost of Ownership (TCO).&amp;nbsp;&lt;/p&gt;&lt;p&gt;As organisations move from pilot programmes to mass deployment, the differentiator will not be the intelligence of individual agents, but the coherence of the network that connects them.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Balancing AI cost efficiency with data sovereignty&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/controlling-ai-agent-sprawl-cio-guide-to-governance/</guid><pubDate>Thu, 22 Jan 2026 17:00:04 +0000</pubDate></item><item><title>‚ÄúDr. Google‚Äù had its issues. Can ChatGPT Health do better? (Artificial intelligence ‚Äì MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/22/1131692/dr-google-had-its-issues-can-chatgpt-health-do-better/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/chatgpt-health2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;For the past two decades, there‚Äôs been a clear first step for anyone who starts experiencing new medical symptoms: Look them up online. The practice was so common that it gained the pejorative moniker ‚ÄúDr. Google.‚Äù But times are changing, and many medical-information seekers are now using LLMs. According to OpenAI, 230 million people ask ChatGPT health-related queries each week.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That‚Äôs the context around the launch of OpenAI‚Äôs new ChatGPT Health product, which debuted earlier this month. It landed at an inauspicious time: Two days earlier, the news website SFGate had broken the story of Sam Nelson, a teenager who died of an overdose last year after extensive conversations with ChatGPT about how best to combine various drugs. In the wake of both pieces of news, multiple journalists questioned the wisdom of relying for medical advice on a tool that could cause such extreme harm.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Though ChatGPT Health lives in a separate sidebar tab from the rest of ChatGPT, it isn‚Äôt a new model. It‚Äôs more like a wrapper that provides one of OpenAI‚Äôs preexisting models with guidance and tools it can use to provide health advice‚Äîincluding some that allow it to access a user‚Äôs electronic medical records and fitness app data, if granted permission. There‚Äôs no doubt that ChatGPT and other large language models can make medical mistakes, and OpenAI emphasizes that ChatGPT Health is intended as an additional support, rather than a replacement for one‚Äôs doctor. But when doctors are unavailable or unable to help, people will turn to alternatives.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Some doctors see LLMs as a boon for medical literacy. The average patient might struggle to navigate the vast landscape of online medical information‚Äîand, in particular, to distinguish high-quality sources from polished but factually dubious websites‚Äîbut LLMs can do that job for them, at least in theory. Treating patients who had searched for their symptoms on Google required ‚Äúa lot of attacking patient anxiety [and] reducing misinformation,‚Äù says Marc Succi, an associate professor at Harvard Medical School and a practicing radiologist. But now, he says, ‚Äúyou see patients with a college education, a high school education, asking questions at the level of something an early med student might ask.‚Äù&lt;/p&gt; 
 &lt;p&gt;The release of ChatGPT Health, and Anthropic‚Äôs subsequent announcement of new health integrations for Claude, indicate that the AI giants are increasingly willing to acknowledge and encourage health-related uses of their models. Such uses certainly come with risks, given LLMs‚Äô well-documented tendencies to agree with users and make up information rather than admit ignorance.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;But those risks also have to be weighed against potential benefits. There‚Äôs an analogy here to autonomous vehicles: When policymakers consider whether to allow Waymo in their city, the key metric is not whether its cars are ever involved in accidents but whether they cause less harm than the status quo of relying on human drivers. If Dr. ChatGPT is an improvement over Dr. Google‚Äîand early evidence suggests it may be‚Äîit could potentially lessen the enormous burden of medical misinformation and unnecessary health anxiety that the internet has created.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Pinning down the effectiveness of a chatbot such as ChatGPT or Claude for consumer health, however, is tricky. ‚ÄúIt‚Äôs exceedingly difficult to evaluate an open-ended chatbot,‚Äù says Danielle Bitterman, the clinical lead for data science and AI at the Mass General Brigham health-care system. Large language models score well on medical licensing examinations, but those exams use multiple-choice questions that don‚Äôt reflect how people use chatbots to look up medical information.&lt;/p&gt; 
 &lt;p&gt;Sirisha Rambhatla, an assistant professor of management science and engineering at the University of Waterloo, attempted to close that gap by evaluating how GPT-4o responded to licensing exam questions when it did not have access to a list of possible answers. Medical experts who evaluated the responses scored only about half of them as entirely correct. But multiple-choice exam questions are designed to be tricky enough that the answer options don‚Äôt give them entirely away, and they‚Äôre still a pretty distant approximation for the sort of thing that a user would type into ChatGPT.&lt;/p&gt;  &lt;p&gt;A different study, which tested GPT-4o on more realistic prompts submitted by human volunteers, found that it answered medical questions correctly about 85% of the time. When I spoke with Amulya Yadav, an associate professor at Pennsylvania State University who runs the Responsible AI for Social Emancipation Lab and led the study, he made it clear that he wasn‚Äôt personally a fan of patient-facing medical LLMs. But he freely admits that, technically speaking, they seem up to the task‚Äîafter all, he says, human doctors misdiagnose patients 10% to 15% of the time. ‚ÄúIf I look at it dispassionately, it seems that the world is gonna change, whether I like it or not,‚Äù he says.&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;For people seeking medical information online, Yadav says, LLMs do seem to be a better choice than Google. Succi, the radiologist, also concluded that LLMs can be a better alternative to web search when he compared GPT-4‚Äôs responses to questions about common chronic medical conditions with the information presented in Google‚Äôs knowledge panel, the information box that sometimes appears on the right side of the search results.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Since Yadav‚Äôs and Succi‚Äôs studies appeared online, in the first half of 2025, OpenAI has released multiple new versions of GPT, and it‚Äôs reasonable to expect that GPT-5.2 would perform even better than its predecessors. But the studies do have important limitations: They focus on straightforward, factual questions, and they examine only brief interactions between users and chatbots or web search tools. Some of the weaknesses of LLMs‚Äîmost notably their sycophancy and tendency to hallucinate‚Äîmight be more likely to rear their heads in more extensive conversations and with people who are dealing with more complex problems. Reeva Lederman, a professor at the University of Melbourne who studies technology and health, notes that patients who don‚Äôt like the diagnosis or treatment recommendations that they receive from a doctor might seek out another opinion from an LLM‚Äîand the LLM, if it‚Äôs sycophantic, might encourage them to reject their doctor‚Äôs advice.&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;Some studies have found that LLMs will hallucinate and exhibit sycophancy in response to health-related prompts. For example, one study showed that GPT-4 and GPT-4o will happily accept and run with incorrect drug information included in a user‚Äôs question. In another, GPT-4o frequently concocted definitions for fake syndromes and lab tests mentioned in the user‚Äôs prompt. Given the abundance of medically dubious diagnoses and treatments floating around the internet, these patterns of LLM behavior could contribute to the spread of medical misinformation, particularly if people see LLMs as trustworthy.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;OpenAI has reported that the GPT-5 series of models is markedly less sycophantic and prone to hallucination than their predecessors, so the results of these studies might not apply to ChatGPT Health. The company also evaluated the model that powers ChatGPT Health on its responses to health-specific questions, using their publicly available HeathBench benchmark. HealthBench rewards models that express uncertainty when appropriate, recommend that users seek medical attention when necessary, and refrain from causing users unnecessary stress by telling them their condition is more serious that it truly is. It‚Äôs reasonable to assume that the model underlying ChatGPT Health exhibited those behaviors in testing, though Bitterman notes that some of the prompts in HealthBench were generated by LLMs, not users, which could limit how well the benchmark translates into the real world.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;An LLM that avoids alarmism seems like a clear improvement over systems that have people convincing themselves they have cancer after a few minutes of browsing. And as large language models, and the products built around them, continue to develop, whatever advantage Dr. ChatGPT has over Dr. Google will likely grow. The introduction of ChatGPT Health is certainly a move in that direction: By looking through your medical records, ChatGPT can potentially gain far more context about your specific health situation than could be included in any Google search, although numerous experts have cautioned against giving ChatGPT that access for privacy reasons.&lt;/p&gt;  &lt;p&gt;Even if ChatGPT Health and other new tools do represent a meaningful improvement over Google searches, they could still conceivably have a negative effect on health overall. Much as automated vehicles, even if they are safer than human-driven cars, might still prove a net negative if they encourage people to use public transit less, LLMs could undermine users‚Äô health if they induce people to rely on the internet instead of human doctors, even if they do increase the quality of health information available online.&lt;/p&gt;  &lt;p&gt;Lederman says that this outcome is plausible. In her research, she has found that members of online communities centered on health tend to put their trust in users who express themselves well, regardless of the validity of the information they are sharing. Because ChatGPT communicates like an articulate person, some people might trust it too much, potentially to the exclusion of their doctor. But LLMs are certainly no replacement for a human doctor‚Äîat least not yet.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/chatgpt-health2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;For the past two decades, there‚Äôs been a clear first step for anyone who starts experiencing new medical symptoms: Look them up online. The practice was so common that it gained the pejorative moniker ‚ÄúDr. Google.‚Äù But times are changing, and many medical-information seekers are now using LLMs. According to OpenAI, 230 million people ask ChatGPT health-related queries each week.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That‚Äôs the context around the launch of OpenAI‚Äôs new ChatGPT Health product, which debuted earlier this month. It landed at an inauspicious time: Two days earlier, the news website SFGate had broken the story of Sam Nelson, a teenager who died of an overdose last year after extensive conversations with ChatGPT about how best to combine various drugs. In the wake of both pieces of news, multiple journalists questioned the wisdom of relying for medical advice on a tool that could cause such extreme harm.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;Though ChatGPT Health lives in a separate sidebar tab from the rest of ChatGPT, it isn‚Äôt a new model. It‚Äôs more like a wrapper that provides one of OpenAI‚Äôs preexisting models with guidance and tools it can use to provide health advice‚Äîincluding some that allow it to access a user‚Äôs electronic medical records and fitness app data, if granted permission. There‚Äôs no doubt that ChatGPT and other large language models can make medical mistakes, and OpenAI emphasizes that ChatGPT Health is intended as an additional support, rather than a replacement for one‚Äôs doctor. But when doctors are unavailable or unable to help, people will turn to alternatives.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Some doctors see LLMs as a boon for medical literacy. The average patient might struggle to navigate the vast landscape of online medical information‚Äîand, in particular, to distinguish high-quality sources from polished but factually dubious websites‚Äîbut LLMs can do that job for them, at least in theory. Treating patients who had searched for their symptoms on Google required ‚Äúa lot of attacking patient anxiety [and] reducing misinformation,‚Äù says Marc Succi, an associate professor at Harvard Medical School and a practicing radiologist. But now, he says, ‚Äúyou see patients with a college education, a high school education, asking questions at the level of something an early med student might ask.‚Äù&lt;/p&gt; 
 &lt;p&gt;The release of ChatGPT Health, and Anthropic‚Äôs subsequent announcement of new health integrations for Claude, indicate that the AI giants are increasingly willing to acknowledge and encourage health-related uses of their models. Such uses certainly come with risks, given LLMs‚Äô well-documented tendencies to agree with users and make up information rather than admit ignorance.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;But those risks also have to be weighed against potential benefits. There‚Äôs an analogy here to autonomous vehicles: When policymakers consider whether to allow Waymo in their city, the key metric is not whether its cars are ever involved in accidents but whether they cause less harm than the status quo of relying on human drivers. If Dr. ChatGPT is an improvement over Dr. Google‚Äîand early evidence suggests it may be‚Äîit could potentially lessen the enormous burden of medical misinformation and unnecessary health anxiety that the internet has created.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Pinning down the effectiveness of a chatbot such as ChatGPT or Claude for consumer health, however, is tricky. ‚ÄúIt‚Äôs exceedingly difficult to evaluate an open-ended chatbot,‚Äù says Danielle Bitterman, the clinical lead for data science and AI at the Mass General Brigham health-care system. Large language models score well on medical licensing examinations, but those exams use multiple-choice questions that don‚Äôt reflect how people use chatbots to look up medical information.&lt;/p&gt; 
 &lt;p&gt;Sirisha Rambhatla, an assistant professor of management science and engineering at the University of Waterloo, attempted to close that gap by evaluating how GPT-4o responded to licensing exam questions when it did not have access to a list of possible answers. Medical experts who evaluated the responses scored only about half of them as entirely correct. But multiple-choice exam questions are designed to be tricky enough that the answer options don‚Äôt give them entirely away, and they‚Äôre still a pretty distant approximation for the sort of thing that a user would type into ChatGPT.&lt;/p&gt;  &lt;p&gt;A different study, which tested GPT-4o on more realistic prompts submitted by human volunteers, found that it answered medical questions correctly about 85% of the time. When I spoke with Amulya Yadav, an associate professor at Pennsylvania State University who runs the Responsible AI for Social Emancipation Lab and led the study, he made it clear that he wasn‚Äôt personally a fan of patient-facing medical LLMs. But he freely admits that, technically speaking, they seem up to the task‚Äîafter all, he says, human doctors misdiagnose patients 10% to 15% of the time. ‚ÄúIf I look at it dispassionately, it seems that the world is gonna change, whether I like it or not,‚Äù he says.&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;For people seeking medical information online, Yadav says, LLMs do seem to be a better choice than Google. Succi, the radiologist, also concluded that LLMs can be a better alternative to web search when he compared GPT-4‚Äôs responses to questions about common chronic medical conditions with the information presented in Google‚Äôs knowledge panel, the information box that sometimes appears on the right side of the search results.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Since Yadav‚Äôs and Succi‚Äôs studies appeared online, in the first half of 2025, OpenAI has released multiple new versions of GPT, and it‚Äôs reasonable to expect that GPT-5.2 would perform even better than its predecessors. But the studies do have important limitations: They focus on straightforward, factual questions, and they examine only brief interactions between users and chatbots or web search tools. Some of the weaknesses of LLMs‚Äîmost notably their sycophancy and tendency to hallucinate‚Äîmight be more likely to rear their heads in more extensive conversations and with people who are dealing with more complex problems. Reeva Lederman, a professor at the University of Melbourne who studies technology and health, notes that patients who don‚Äôt like the diagnosis or treatment recommendations that they receive from a doctor might seek out another opinion from an LLM‚Äîand the LLM, if it‚Äôs sycophantic, might encourage them to reject their doctor‚Äôs advice.&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;Some studies have found that LLMs will hallucinate and exhibit sycophancy in response to health-related prompts. For example, one study showed that GPT-4 and GPT-4o will happily accept and run with incorrect drug information included in a user‚Äôs question. In another, GPT-4o frequently concocted definitions for fake syndromes and lab tests mentioned in the user‚Äôs prompt. Given the abundance of medically dubious diagnoses and treatments floating around the internet, these patterns of LLM behavior could contribute to the spread of medical misinformation, particularly if people see LLMs as trustworthy.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;OpenAI has reported that the GPT-5 series of models is markedly less sycophantic and prone to hallucination than their predecessors, so the results of these studies might not apply to ChatGPT Health. The company also evaluated the model that powers ChatGPT Health on its responses to health-specific questions, using their publicly available HeathBench benchmark. HealthBench rewards models that express uncertainty when appropriate, recommend that users seek medical attention when necessary, and refrain from causing users unnecessary stress by telling them their condition is more serious that it truly is. It‚Äôs reasonable to assume that the model underlying ChatGPT Health exhibited those behaviors in testing, though Bitterman notes that some of the prompts in HealthBench were generated by LLMs, not users, which could limit how well the benchmark translates into the real world.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;An LLM that avoids alarmism seems like a clear improvement over systems that have people convincing themselves they have cancer after a few minutes of browsing. And as large language models, and the products built around them, continue to develop, whatever advantage Dr. ChatGPT has over Dr. Google will likely grow. The introduction of ChatGPT Health is certainly a move in that direction: By looking through your medical records, ChatGPT can potentially gain far more context about your specific health situation than could be included in any Google search, although numerous experts have cautioned against giving ChatGPT that access for privacy reasons.&lt;/p&gt;  &lt;p&gt;Even if ChatGPT Health and other new tools do represent a meaningful improvement over Google searches, they could still conceivably have a negative effect on health overall. Much as automated vehicles, even if they are safer than human-driven cars, might still prove a net negative if they encourage people to use public transit less, LLMs could undermine users‚Äô health if they induce people to rely on the internet instead of human doctors, even if they do increase the quality of health information available online.&lt;/p&gt;  &lt;p&gt;Lederman says that this outcome is plausible. In her research, she has found that members of online communities centered on health tend to put their trust in users who express themselves well, regardless of the validity of the information they are sharing. Because ChatGPT communicates like an articulate person, some people might trust it too much, potentially to the exclusion of their doctor. But LLMs are certainly no replacement for a human doctor‚Äîat least not yet.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/22/1131692/dr-google-had-its-issues-can-chatgpt-health-do-better/</guid><pubDate>Thu, 22 Jan 2026 17:38:09 +0000</pubDate></item><item><title>[NEW] NVIDIA DRIVE AV Raises the Bar for Vehicle Safety as Mercedes-Benz CLA Earns Top Euro NCAP Award (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/drive-av-mercedes-benz-cla-euro-ncap-safety-award/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/mb-cla-euro-ncap-2.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI-powered driver assistance technologies are becoming standard equipment, fundamentally changing how vehicle safety is assessed and validated.&lt;/p&gt;
&lt;p&gt;The recent recognition of the Mercedes-Benz CLA as Euro NCAP‚Äôs Best Performer of 2025 underscores this shift, as the vehicle combines traditional passive safety features with NVIDIA DRIVE AV software to achieve the highest overall safety score of the year.&lt;/p&gt;
&lt;p&gt;‚Äã‚Äã‚ÄúWhen Euro NCAP assesses vehicle safety, it evaluates both passive and active systems ‚Äî achieving a perfect score requires a state-of-the-art advanced driver assistance system,‚Äù said Ola K√§llenius, CEO of the Mercedes-Benz Group. ‚ÄúThis milestone represents the culmination of five years of collaboration between Mercedes-Benz and NVIDIA to enhance real-world safety and deliver tangible value to customers.‚Äù&lt;/p&gt;
&lt;p&gt;Euro NCAP (European New Car Assessment Programme) has for nearly 30 years served as Europe‚Äôs independent vehicle safety authority, backed by European governments, motoring organizations and consumer groups.&lt;/p&gt;
&lt;p&gt;Euro NCAP evaluates vehicles across four categories that reflect real-world safety. For AI-powered driver assistance, the most relevant are the ‚ÄúVulnerable Road User‚Äù and ‚ÄúSafety Assist‚Äù categories, which assess technologies designed to help prevent crashes ‚Äî including automatic emergency braking, lane-keeping support and speed assistance.&lt;/p&gt;
&lt;p&gt;Only vehicles achieving five-star ratings with standard equipment qualify for ‚ÄúBest in Class‚Äù recognition, with winners determined by weighted scores across all categories. In 2025, Euro NCAP tested a record 49 models.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Safety Comes First: How DRIVE AV Is Built for Trust&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Safety ratings like Euro NCAP are increasingly recognizing vehicles that combine strong passive protection with advanced active safety performance. As AI becomes central to driving, the benchmark for the ‚Äúsafest‚Äù car will increasingly be defined not only by how well a vehicle handles a crash, but how effectively it helps prevent one.&lt;/p&gt;
&lt;p&gt;The Mercedes-Benz CLA is built with NVIDIA DRIVE AV, a dual-stack architecture that‚Äôs designed to help automakers deliver systems that aren‚Äôt only intelligent, but predictable, verifiable and resilient in the real world. The architecture pairs an AI-driven end-to-end driving system with a parallel classical safety stack to provide redundancy across AV sensing, planning and execution.&lt;/p&gt;
&lt;p&gt;The CLA is also built on the NVIDIA DRIVE Hyperion architecture, which incorporates sensor diversity and hardware redundancy into the vehicle‚Äôs overall design.&lt;/p&gt;
&lt;p&gt;At the heart of this approach is NVIDIA Halos ‚Äî a comprehensive safety system spanning hardware, software, tools, development processes and certification support. Halos delivers a structured safety foundation for developing automated driving and other AI capabilities while staying anchored to robust guardrails, redundancy and fault tolerance.&lt;/p&gt;
&lt;p&gt;Third-party certification and assessments are also important to build trust:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T√úV S√úD granted the ISO 21434 Cybersecurity Process certification to NVIDIA for its automotive system-on-a-chip, platform and software engineering processes. Additionally, NVIDIA DriveOS 6.0 conforms to ISO 26262 Automotive Safety Integrity Level (ASIL) D standards.&lt;/li&gt;
&lt;li&gt;T√úV Rheinland performed an independent United Nations Economic Commission for Europe (UNECE) safety assessment of NVIDIA DRIVE AV related to safety requirements for complex electronic systems, which NVIDIA successfully completed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA recently released its Alpamayo family of open AI models, simulation tools and datasets ‚Äî which enables AVs to navigate even rare, ‚Äúlong-tail‚Äù events they haven‚Äôt been trained on by breaking the scenario down into smaller steps, reasoning through multiple possible actions and ultimately selecting the safest one. Using these models with the parallel classical safety stack in the NVIDIA DRIVE AV dual-stack architecture provides an additional layer of protection to keep vehicles operating within safe boundaries.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Training Safety Through Data and Simulation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Modern AI-driven safety systems learn from exponentially more driving scenarios than any human could experience in a lifetime. NVIDIA‚Äôs cloud-to-car development approach transforms real-world data into billions of simulated miles using NVIDIA DGX systems for neural network training, the NVIDIA Omniverse and Cosmos platforms for simulation, and NVIDIA DRIVE AGX for in-vehicle computing.&lt;/p&gt;
&lt;p&gt;This methodology addresses a critical challenge in safety validation: training AI to navigate rare but high-risk edge cases that are too dangerous ‚Äî or too infrequent ‚Äî to test reliably in the real world. By generating synthetic scenarios that represent these rare situations, AI systems can learn appropriate responses during development without putting people at risk.&lt;/p&gt;
&lt;p&gt;The CLA‚Äôs recognition is more than a single model earning a top rating ‚Äî it reflects a broader shift in what safety means in the modern vehicle, where trusted crash protection is paired with AI-enabled driver assistance designed to help avoid accidents in the first place.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2026/01/mb-cla-euro-ncap-2.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI-powered driver assistance technologies are becoming standard equipment, fundamentally changing how vehicle safety is assessed and validated.&lt;/p&gt;
&lt;p&gt;The recent recognition of the Mercedes-Benz CLA as Euro NCAP‚Äôs Best Performer of 2025 underscores this shift, as the vehicle combines traditional passive safety features with NVIDIA DRIVE AV software to achieve the highest overall safety score of the year.&lt;/p&gt;
&lt;p&gt;‚Äã‚Äã‚ÄúWhen Euro NCAP assesses vehicle safety, it evaluates both passive and active systems ‚Äî achieving a perfect score requires a state-of-the-art advanced driver assistance system,‚Äù said Ola K√§llenius, CEO of the Mercedes-Benz Group. ‚ÄúThis milestone represents the culmination of five years of collaboration between Mercedes-Benz and NVIDIA to enhance real-world safety and deliver tangible value to customers.‚Äù&lt;/p&gt;
&lt;p&gt;Euro NCAP (European New Car Assessment Programme) has for nearly 30 years served as Europe‚Äôs independent vehicle safety authority, backed by European governments, motoring organizations and consumer groups.&lt;/p&gt;
&lt;p&gt;Euro NCAP evaluates vehicles across four categories that reflect real-world safety. For AI-powered driver assistance, the most relevant are the ‚ÄúVulnerable Road User‚Äù and ‚ÄúSafety Assist‚Äù categories, which assess technologies designed to help prevent crashes ‚Äî including automatic emergency braking, lane-keeping support and speed assistance.&lt;/p&gt;
&lt;p&gt;Only vehicles achieving five-star ratings with standard equipment qualify for ‚ÄúBest in Class‚Äù recognition, with winners determined by weighted scores across all categories. In 2025, Euro NCAP tested a record 49 models.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Safety Comes First: How DRIVE AV Is Built for Trust&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Safety ratings like Euro NCAP are increasingly recognizing vehicles that combine strong passive protection with advanced active safety performance. As AI becomes central to driving, the benchmark for the ‚Äúsafest‚Äù car will increasingly be defined not only by how well a vehicle handles a crash, but how effectively it helps prevent one.&lt;/p&gt;
&lt;p&gt;The Mercedes-Benz CLA is built with NVIDIA DRIVE AV, a dual-stack architecture that‚Äôs designed to help automakers deliver systems that aren‚Äôt only intelligent, but predictable, verifiable and resilient in the real world. The architecture pairs an AI-driven end-to-end driving system with a parallel classical safety stack to provide redundancy across AV sensing, planning and execution.&lt;/p&gt;
&lt;p&gt;The CLA is also built on the NVIDIA DRIVE Hyperion architecture, which incorporates sensor diversity and hardware redundancy into the vehicle‚Äôs overall design.&lt;/p&gt;
&lt;p&gt;At the heart of this approach is NVIDIA Halos ‚Äî a comprehensive safety system spanning hardware, software, tools, development processes and certification support. Halos delivers a structured safety foundation for developing automated driving and other AI capabilities while staying anchored to robust guardrails, redundancy and fault tolerance.&lt;/p&gt;
&lt;p&gt;Third-party certification and assessments are also important to build trust:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;T√úV S√úD granted the ISO 21434 Cybersecurity Process certification to NVIDIA for its automotive system-on-a-chip, platform and software engineering processes. Additionally, NVIDIA DriveOS 6.0 conforms to ISO 26262 Automotive Safety Integrity Level (ASIL) D standards.&lt;/li&gt;
&lt;li&gt;T√úV Rheinland performed an independent United Nations Economic Commission for Europe (UNECE) safety assessment of NVIDIA DRIVE AV related to safety requirements for complex electronic systems, which NVIDIA successfully completed.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;NVIDIA recently released its Alpamayo family of open AI models, simulation tools and datasets ‚Äî which enables AVs to navigate even rare, ‚Äúlong-tail‚Äù events they haven‚Äôt been trained on by breaking the scenario down into smaller steps, reasoning through multiple possible actions and ultimately selecting the safest one. Using these models with the parallel classical safety stack in the NVIDIA DRIVE AV dual-stack architecture provides an additional layer of protection to keep vehicles operating within safe boundaries.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Training Safety Through Data and Simulation&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Modern AI-driven safety systems learn from exponentially more driving scenarios than any human could experience in a lifetime. NVIDIA‚Äôs cloud-to-car development approach transforms real-world data into billions of simulated miles using NVIDIA DGX systems for neural network training, the NVIDIA Omniverse and Cosmos platforms for simulation, and NVIDIA DRIVE AGX for in-vehicle computing.&lt;/p&gt;
&lt;p&gt;This methodology addresses a critical challenge in safety validation: training AI to navigate rare but high-risk edge cases that are too dangerous ‚Äî or too infrequent ‚Äî to test reliably in the real world. By generating synthetic scenarios that represent these rare situations, AI systems can learn appropriate responses during development without putting people at risk.&lt;/p&gt;
&lt;p&gt;The CLA‚Äôs recognition is more than a single model earning a top rating ‚Äî it reflects a broader shift in what safety means in the modern vehicle, where trusted crash protection is paired with AI-enabled driver assistance designed to help avoid accidents in the first place.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/drive-av-mercedes-benz-cla-euro-ncap-safety-award/</guid><pubDate>Thu, 22 Jan 2026 18:21:49 +0000</pubDate></item><item><title>Google now offers free SAT practice exams, powered by Gemini (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/google-now-offers-free-sat-practice-exams-powered-by-gemini/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Prepping for the SAT is nobody‚Äôs idea of fun, but Google aims to make it less stressful with AI. The company announced that it‚Äôs now focusing its AI education efforts on standardized testing with free SAT practice exams powered by Gemini.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Students can prompt Gemini by typing ‚ÄúI want to take a practice SAT test,‚Äù and the AI will provide them with a free practice exam. Gemini then analyzes the results, highlighting strengths and identifying areas that need further review. It also offers detailed explanations for any incorrect answers.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085165" height="371" src="https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-22-at-1.27.15-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it partnered with education companies like the Princeton Review to ensure the content is vetted and that students are working with questions that closely mirror what they will encounter on the actual SAT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This recent move by Google is viewed as a game-changer for students who can‚Äôt readily access personalized SAT tutoring. By making SAT prep free, Google is trying to open the door for more students to compete on equal footing. However, it also sparks a broader conversation about the role of AI in education and just how much we want AI to shape how students learn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The adoption of AI in education is not without controversy. Many teachers worry that students might end up leaning too heavily on tools like Gemini and ChatGPT to get their work done. If students let AI do all the thinking, it could chip away at their problem-solving skills. There are even studies out there that back this up, suggesting that relying too much on AI can actually weaken students‚Äô ability to think critically and tackle challenges on their own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Let‚Äôs also not forget about human SAT tutors. Free AI-powered exam prep poses a significant threat to the traditional tutoring industry, which has long thrived on providing personalized coaching to college-bound students. With Google offering a free alternative, the job security of private SAT tutors may be at risk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news follows Google‚Äôs recent launch of a Gemini-powered feature that lets teachers create podcast-style audio lessons, which could help catch the attention of Gen Z students. Other available Gemini tools include features that help teachers brainstorm ideas, build lesson plans, and tailor learning materials for their classes.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Prepping for the SAT is nobody‚Äôs idea of fun, but Google aims to make it less stressful with AI. The company announced that it‚Äôs now focusing its AI education efforts on standardized testing with free SAT practice exams powered by Gemini.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Students can prompt Gemini by typing ‚ÄúI want to take a practice SAT test,‚Äù and the AI will provide them with a free practice exam. Gemini then analyzes the results, highlighting strengths and identifying areas that need further review. It also offers detailed explanations for any incorrect answers.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085165" height="371" src="https://techcrunch.com/wp-content/uploads/2026/01/Screenshot-2026-01-22-at-1.27.15-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it partnered with education companies like the Princeton Review to ensure the content is vetted and that students are working with questions that closely mirror what they will encounter on the actual SAT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This recent move by Google is viewed as a game-changer for students who can‚Äôt readily access personalized SAT tutoring. By making SAT prep free, Google is trying to open the door for more students to compete on equal footing. However, it also sparks a broader conversation about the role of AI in education and just how much we want AI to shape how students learn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The adoption of AI in education is not without controversy. Many teachers worry that students might end up leaning too heavily on tools like Gemini and ChatGPT to get their work done. If students let AI do all the thinking, it could chip away at their problem-solving skills. There are even studies out there that back this up, suggesting that relying too much on AI can actually weaken students‚Äô ability to think critically and tackle challenges on their own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Let‚Äôs also not forget about human SAT tutors. Free AI-powered exam prep poses a significant threat to the traditional tutoring industry, which has long thrived on providing personalized coaching to college-bound students. With Google offering a free alternative, the job security of private SAT tutors may be at risk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news follows Google‚Äôs recent launch of a Gemini-powered feature that lets teachers create podcast-style audio lessons, which could help catch the attention of Gen Z students. Other available Gemini tools include features that help teachers brainstorm ideas, build lesson plans, and tailor learning materials for their classes.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/google-now-offers-free-sat-practice-exams-powered-by-gemini/</guid><pubDate>Thu, 22 Jan 2026 18:27:36 +0000</pubDate></item><item><title>[NEW] Humans&amp; thinks coordination is the next frontier for AI, and they‚Äôre building a model to prove it (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/humans-Founder-Photo-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots are getting better at answering questions, summarizing documents, and solving mathematical equations, but they still largely behave like helpful assistants for one user at a time. They‚Äôre not designed to manage the messier work of real collaboration: coordinating people with competing priorities, tracking long-running decisions, and keeping teams aligned over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;, a new startup founded by alumni of Anthropic, Meta, OpenAI, xAI, and Google DeepMind, thinks closing that gap is the next major frontier for foundation models. The company this week raised a $480 million seed round to build a ‚Äúcentral nervous system‚Äù for the human-plus-AI economy. The startup‚Äôs ‚ÄúAI for empowering humans‚Äù framing has dominated early coverage, but the company‚Äôs actual ambition is more novel: building a new foundation model architecture designed for social intelligence, not just information retrieval or code generation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúIt feels like we‚Äôre ending the first paradigm of scaling, where question-answering models were trained to be very smart at particular verticals, and now we‚Äôre entering what we believe to be the second wave of adoption where the average consumer or user is trying to figure out what to do with all these things,‚Äù Andi Peng, one of Humans&amp;amp;‚Äôs co-founders and a former Anthropic employee, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;‚Äôs pitch centers on helping usher people into the new era of AI, moving beyond the narrative that AI will take their jobs. Whether or not that‚Äôs just marketing speak, the timing is critical: Companies are transitioning from chat to agents. Models are competent, but workflows aren‚Äôt, and the coordination challenge remains largely unaddressed. And through it all, people feel threatened and overwhelmed by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three-month-old company, like several of its peers, has managed to raise its startling seed round off the back of this philosophy and the pedigree of its founding team. Humans&amp;amp; still doesn‚Äôt have a product, nor has it been clear about what exactly it might be, though the team said it could be a replacement for multiplayer or multi-user contexts like communication platforms (think Slack) or collaboration platforms (think Google Docs and Notion). As for use cases and target audience, the team hinted at both enterprise and consumer applications.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe are building a product and a model that is centered on communication and collaboration,‚Äù Eric Zelikman, co-founder and CEO of Humans&amp;amp; and former xAI researcher, told TechCrunch, adding that the focus is on getting the product to help people work together and communicate more effectively ‚Äî both with each other and with AI tools.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúLike when you have to make a large group decision, often it comes down to someone taking everyone into one room, getting everyone to express their different camps about, for example, what kind of logo they‚Äôd like,‚Äù Zelikman continued, chortling with his team as they recalled the time-consuming tedium of getting everyone to agree on a logo for the startup.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Zelikman added that the new model will be trained to ask questions in a way that feels like interacting with a friend or a colleague, someone who is trying to get to know you. Chatbots today are programmed to ask questions constantly, but they do so without understanding the value of the question. He says this is because they‚Äôve been optimized for two things: How much a user immediately likes a response they‚Äôre given, and how likely the model is to answer the question it receives correctly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the lack of clarity around what the product is could be that Humans&amp;amp; doesn‚Äôt exactly have an answer for that yet. Peng said Humans&amp;amp; is designing the product in conjunction with the model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPart of what we‚Äôre doing here is also making sure that as the model improves, we‚Äôre able to co-evolve the interface and the behaviors that the model is capable of into a product that makes sense,‚Äù she said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What is clear, though, is that Humans&amp;amp; isn‚Äôt trying to make a new model that can plug into existing applications and collaboration tools. The startup wants to own the collaboration layer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI plus team collaboration and productivity tools are an increasingly hot field ‚Äî for example, the startup AI note-taking app Granola raised a $43 million round at a $250 million valuation as it launched more collaborative features. Several high-profile voices are also explicitly framing the next phase of AI as one of coordination and collaboration, not just automation. LinkedIn founder Reid Hoffman today argued that companies are implementing AI wrong by treating it like isolated pilots and that the real leverage is in the coordination layer of work ‚Äî that is, how teams share knowledge and run meetings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúAI lives at the workflow level, and the people closest to the work know where the friction actually is,‚Äù Hoffman wrote on social media. ‚ÄúThey‚Äôre the ones who will discover what should be automated, compressed, or totally redesigned.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs the space where Humans&amp;amp; wants to live. The idea is that its model-slash-product would act as the ‚Äúconnective tissue‚Äù across any organization ‚Äî be it a 10,000-person business or a family ‚Äî that understands the skills, motivations, and needs of each person, as well as how all of those can be balanced for the good of the whole.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there requires rethinking how AI models are trained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe‚Äôre trying to train the model in a different way that will involve more humans and AIs interacting and collaborating together,‚Äù Yuchen He, a Humans&amp;amp; co-founder and former OpenAI researcher, told TechCrunch, adding that the startup‚Äôs model will also be trained using long-horizon and multi-agent reinforcement learning (RL).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long-horizon RL is meant to train the model to plan, act, revise, and follow through over time, rather than just generate a good one-off answer. Multi-agent RL trains for environments where multiple AIs and/or humans are in the loop. Both of these concepts are gaining momentum in recent academic work as researchers push LLMs beyond chatbot responses toward systems that can coordinate actions and optimize outcomes over many steps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe model needs to remember things about itself, about you, and the better its memory, the better its user understanding,‚Äù He said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the stellar crew running the show, there are plenty of risks ahead. Humans&amp;amp; will need endless large sums of cash to fund the expensive endeavor that is training and scaling a new model. That means it will be competing with the major established players for resources, including access to compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top risk, though, is that Humans&amp;amp; isn‚Äôt just competing with the Notions and Slacks of the world. It‚Äôs coming for the Top Dogs of AI. And those companies are actively working on better ways to enable human collaboration on their platforms, even as they swear AGI will soon&amp;nbsp;replace economically viable work. Through Claude Cowork, Anthropic aims to optimize work-style collaboration; Gemini is embedded into Workspace so AI-enabled collaboration is already happening inside the tools people are already using; and OpenAI has lately been pitching developers on its multi-agent orchestration and workflows.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, none of the major players seem poised to rewrite a model based on social intelligence, which either gives Humans&amp;amp; a leg up or makes it an acquisition target. And with companies like Meta, OpenAI, and DeepMind on the prowl for top AI talent, M&amp;amp;A is certainly a risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp; told TechCrunch it has already turned away interested parties and is not interested in being acquired.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe believe this is going to be a generational company, and we think that this has the potential to fundamentally change the future of how we interact with these models,‚Äù Zelikman said. ‚ÄúWe trust ourselves to do that, and we have a lot of faith in the team that we‚Äôve assembled here.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/humans-Founder-Photo-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots are getting better at answering questions, summarizing documents, and solving mathematical equations, but they still largely behave like helpful assistants for one user at a time. They‚Äôre not designed to manage the messier work of real collaboration: coordinating people with competing priorities, tracking long-running decisions, and keeping teams aligned over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;, a new startup founded by alumni of Anthropic, Meta, OpenAI, xAI, and Google DeepMind, thinks closing that gap is the next major frontier for foundation models. The company this week raised a $480 million seed round to build a ‚Äúcentral nervous system‚Äù for the human-plus-AI economy. The startup‚Äôs ‚ÄúAI for empowering humans‚Äù framing has dominated early coverage, but the company‚Äôs actual ambition is more novel: building a new foundation model architecture designed for social intelligence, not just information retrieval or code generation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúIt feels like we‚Äôre ending the first paradigm of scaling, where question-answering models were trained to be very smart at particular verticals, and now we‚Äôre entering what we believe to be the second wave of adoption where the average consumer or user is trying to figure out what to do with all these things,‚Äù Andi Peng, one of Humans&amp;amp;‚Äôs co-founders and a former Anthropic employee, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;‚Äôs pitch centers on helping usher people into the new era of AI, moving beyond the narrative that AI will take their jobs. Whether or not that‚Äôs just marketing speak, the timing is critical: Companies are transitioning from chat to agents. Models are competent, but workflows aren‚Äôt, and the coordination challenge remains largely unaddressed. And through it all, people feel threatened and overwhelmed by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three-month-old company, like several of its peers, has managed to raise its startling seed round off the back of this philosophy and the pedigree of its founding team. Humans&amp;amp; still doesn‚Äôt have a product, nor has it been clear about what exactly it might be, though the team said it could be a replacement for multiplayer or multi-user contexts like communication platforms (think Slack) or collaboration platforms (think Google Docs and Notion). As for use cases and target audience, the team hinted at both enterprise and consumer applications.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe are building a product and a model that is centered on communication and collaboration,‚Äù Eric Zelikman, co-founder and CEO of Humans&amp;amp; and former xAI researcher, told TechCrunch, adding that the focus is on getting the product to help people work together and communicate more effectively ‚Äî both with each other and with AI tools.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúLike when you have to make a large group decision, often it comes down to someone taking everyone into one room, getting everyone to express their different camps about, for example, what kind of logo they‚Äôd like,‚Äù Zelikman continued, chortling with his team as they recalled the time-consuming tedium of getting everyone to agree on a logo for the startup.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Zelikman added that the new model will be trained to ask questions in a way that feels like interacting with a friend or a colleague, someone who is trying to get to know you. Chatbots today are programmed to ask questions constantly, but they do so without understanding the value of the question. He says this is because they‚Äôve been optimized for two things: How much a user immediately likes a response they‚Äôre given, and how likely the model is to answer the question it receives correctly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the lack of clarity around what the product is could be that Humans&amp;amp; doesn‚Äôt exactly have an answer for that yet. Peng said Humans&amp;amp; is designing the product in conjunction with the model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúPart of what we‚Äôre doing here is also making sure that as the model improves, we‚Äôre able to co-evolve the interface and the behaviors that the model is capable of into a product that makes sense,‚Äù she said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What is clear, though, is that Humans&amp;amp; isn‚Äôt trying to make a new model that can plug into existing applications and collaboration tools. The startup wants to own the collaboration layer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI plus team collaboration and productivity tools are an increasingly hot field ‚Äî for example, the startup AI note-taking app Granola raised a $43 million round at a $250 million valuation as it launched more collaborative features. Several high-profile voices are also explicitly framing the next phase of AI as one of coordination and collaboration, not just automation. LinkedIn founder Reid Hoffman today argued that companies are implementing AI wrong by treating it like isolated pilots and that the real leverage is in the coordination layer of work ‚Äî that is, how teams share knowledge and run meetings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúAI lives at the workflow level, and the people closest to the work know where the friction actually is,‚Äù Hoffman wrote on social media. ‚ÄúThey‚Äôre the ones who will discover what should be automated, compressed, or totally redesigned.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs the space where Humans&amp;amp; wants to live. The idea is that its model-slash-product would act as the ‚Äúconnective tissue‚Äù across any organization ‚Äî be it a 10,000-person business or a family ‚Äî that understands the skills, motivations, and needs of each person, as well as how all of those can be balanced for the good of the whole.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there requires rethinking how AI models are trained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe‚Äôre trying to train the model in a different way that will involve more humans and AIs interacting and collaborating together,‚Äù Yuchen He, a Humans&amp;amp; co-founder and former OpenAI researcher, told TechCrunch, adding that the startup‚Äôs model will also be trained using long-horizon and multi-agent reinforcement learning (RL).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long-horizon RL is meant to train the model to plan, act, revise, and follow through over time, rather than just generate a good one-off answer. Multi-agent RL trains for environments where multiple AIs and/or humans are in the loop. Both of these concepts are gaining momentum in recent academic work as researchers push LLMs beyond chatbot responses toward systems that can coordinate actions and optimize outcomes over many steps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe model needs to remember things about itself, about you, and the better its memory, the better its user understanding,‚Äù He said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the stellar crew running the show, there are plenty of risks ahead. Humans&amp;amp; will need endless large sums of cash to fund the expensive endeavor that is training and scaling a new model. That means it will be competing with the major established players for resources, including access to compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top risk, though, is that Humans&amp;amp; isn‚Äôt just competing with the Notions and Slacks of the world. It‚Äôs coming for the Top Dogs of AI. And those companies are actively working on better ways to enable human collaboration on their platforms, even as they swear AGI will soon&amp;nbsp;replace economically viable work. Through Claude Cowork, Anthropic aims to optimize work-style collaboration; Gemini is embedded into Workspace so AI-enabled collaboration is already happening inside the tools people are already using; and OpenAI has lately been pitching developers on its multi-agent orchestration and workflows.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, none of the major players seem poised to rewrite a model based on social intelligence, which either gives Humans&amp;amp; a leg up or makes it an acquisition target. And with companies like Meta, OpenAI, and DeepMind on the prowl for top AI talent, M&amp;amp;A is certainly a risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp; told TechCrunch it has already turned away interested parties and is not interested in being acquired.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe believe this is going to be a generational company, and we think that this has the potential to fundamentally change the future of how we interact with these models,‚Äù Zelikman said. ‚ÄúWe trust ourselves to do that, and we have a lot of faith in the team that we‚Äôve assembled here.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/</guid><pubDate>Thu, 22 Jan 2026 19:24:13 +0000</pubDate></item><item><title>[NEW] Google DeepMind CEO is ‚Äòsurprised‚Äô OpenAI is rushing forward with ads in ChatGPT (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/google-deepmind-ceo-is-surprised-openai-is-rushing-forward-with-ads-in-chatgpt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/videoframe_271754.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind CEO Demis Hassabis said he‚Äôs ‚Äúsurprised‚Äù that OpenAI has already moved to introduce ads within its AI chatbot. In an interview with Axios at Davos, the AI leader was responding to a question about using ads to monetize AI services, saying the idea is something that the team at Google was thinking through ‚Äúvery carefully.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis also said that his team wasn‚Äôt feeling pressure from the tech giant to make ‚Äúa knee-jerk‚Äù decision around advertising, despite how key ads are to Google‚Äôs core business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The DeepMind co-founder‚Äôs remarks followed Friday‚Äôs news that OpenAI will begin &lt;span&gt;testing ads&amp;nbsp;as a way to generate&lt;/span&gt; additional revenue from the portion of the AI chatbot‚Äôs 800 million weekly active users who don‚Äôt have a paid subscription. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI may have been forced to consider ads, considering its growing infrastructure and energy costs, its decision could change how users view the service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI‚Äôm a little bit surprised they‚Äôve moved so early into that,‚Äù Hassabis said, referring to OpenAI‚Äôs adoption of ads. ‚ÄúI mean, look, ads, there‚Äôs nothing wrong with ads‚Ä¶they funded much of the consumer internet. And if done well, they can be useful,‚Äù he clarified.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúBut in the realm of assistants, and if you think of the chatbot as an assistant that‚Äôs meant to be helpful ‚Äî and ideally, in my mind, as they become more powerful, the kind of technology that works for you as the individual‚Ä¶there is a question about how ads fit into that model?‚Ä¶ You want to have trust in your assistant, so how does that work?‚Äù he questioned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reiterating some early comments from another Davos interview, Hassabis also said that Google didn‚Äôt have ‚Äúany current plans‚Äù to do ads in its AI chatbot. Instead, the company would monitor the situation to see how users respond.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, we‚Äôve already seen consumer backlash to the idea of ads infiltrating people‚Äôs conversations with AI assistants. When OpenAI last month began exploring a feature that suggested apps to try during users‚Äô chats, for instance, people reacted negatively, saying these suggestions felt like intrusive ads. Shortly after, OpenAI turned off the app suggestions, which it claimed were not actually ads as they had ‚Äúno financial component.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But whether or not money had exchanged hands was not what made users angry. Rather, it was how the app suggestions degraded the quality of the experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs something that also concerns Hassabis, his remarks suggested. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He explained that using a chatbot is a much different experience than using Google Search. With Search, Google already understands a user‚Äôs intent, so it can show potentially useful ads. Chatbots, on the other hand, are meant to become helpful digital assistants that know about you and can help you with many aspects of your life, he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI think that‚Äôs very different from the search use case. So I think there, that has to be thought through very carefully,‚Äù he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Making Gemini more useful to each user is also the focus of&lt;span&gt;&amp;nbsp;&lt;/span&gt;newly launched personalization features announced today for Google‚Äôs AI Mode. Now, users can opt into having Gemini‚Äôs AI tap into their Gmail and Photos for tailored responses in Search‚Äôs AI Mode, similar to how Gemini‚Äôs app just added a Personal Intelligence feature that can reference users‚Äô Gmail, Photos, Search, and YouTube history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While personalized ad targeting is a business that sustains the free web, pushing an ad on the user while they‚Äôre in a conversation with an AI assistant can feel off-putting. It‚Äôs why customers rejected Amazon‚Äôs earlier attempts to infuse ads into its Alexa experience ‚Äî they wanted an assistant, not a personal shopper hawking things for them to buy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis said he wasn‚Äôt feeling top-down pressure to force ads into the AI product, either, though he admitted there may be a way to do them right later on. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe don‚Äôt feel any immediate pressure to make knee-jerk decisions like that ‚Äî I think that‚Äôs been the history of what we‚Äôve done at DeepMind ‚Äî is be very scientific, and rigorous, and thoughtful about each step that we take ‚Äî be that the technology itself or the product,‚Äù he noted.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/videoframe_271754.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind CEO Demis Hassabis said he‚Äôs ‚Äúsurprised‚Äù that OpenAI has already moved to introduce ads within its AI chatbot. In an interview with Axios at Davos, the AI leader was responding to a question about using ads to monetize AI services, saying the idea is something that the team at Google was thinking through ‚Äúvery carefully.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis also said that his team wasn‚Äôt feeling pressure from the tech giant to make ‚Äúa knee-jerk‚Äù decision around advertising, despite how key ads are to Google‚Äôs core business.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The DeepMind co-founder‚Äôs remarks followed Friday‚Äôs news that OpenAI will begin &lt;span&gt;testing ads&amp;nbsp;as a way to generate&lt;/span&gt; additional revenue from the portion of the AI chatbot‚Äôs 800 million weekly active users who don‚Äôt have a paid subscription. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI may have been forced to consider ads, considering its growing infrastructure and energy costs, its decision could change how users view the service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI‚Äôm a little bit surprised they‚Äôve moved so early into that,‚Äù Hassabis said, referring to OpenAI‚Äôs adoption of ads. ‚ÄúI mean, look, ads, there‚Äôs nothing wrong with ads‚Ä¶they funded much of the consumer internet. And if done well, they can be useful,‚Äù he clarified.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúBut in the realm of assistants, and if you think of the chatbot as an assistant that‚Äôs meant to be helpful ‚Äî and ideally, in my mind, as they become more powerful, the kind of technology that works for you as the individual‚Ä¶there is a question about how ads fit into that model?‚Ä¶ You want to have trust in your assistant, so how does that work?‚Äù he questioned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reiterating some early comments from another Davos interview, Hassabis also said that Google didn‚Äôt have ‚Äúany current plans‚Äù to do ads in its AI chatbot. Instead, the company would monitor the situation to see how users respond.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, we‚Äôve already seen consumer backlash to the idea of ads infiltrating people‚Äôs conversations with AI assistants. When OpenAI last month began exploring a feature that suggested apps to try during users‚Äô chats, for instance, people reacted negatively, saying these suggestions felt like intrusive ads. Shortly after, OpenAI turned off the app suggestions, which it claimed were not actually ads as they had ‚Äúno financial component.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But whether or not money had exchanged hands was not what made users angry. Rather, it was how the app suggestions degraded the quality of the experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That‚Äôs something that also concerns Hassabis, his remarks suggested. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He explained that using a chatbot is a much different experience than using Google Search. With Search, Google already understands a user‚Äôs intent, so it can show potentially useful ads. Chatbots, on the other hand, are meant to become helpful digital assistants that know about you and can help you with many aspects of your life, he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúI think that‚Äôs very different from the search use case. So I think there, that has to be thought through very carefully,‚Äù he added. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Making Gemini more useful to each user is also the focus of&lt;span&gt;&amp;nbsp;&lt;/span&gt;newly launched personalization features announced today for Google‚Äôs AI Mode. Now, users can opt into having Gemini‚Äôs AI tap into their Gmail and Photos for tailored responses in Search‚Äôs AI Mode, similar to how Gemini‚Äôs app just added a Personal Intelligence feature that can reference users‚Äô Gmail, Photos, Search, and YouTube history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While personalized ad targeting is a business that sustains the free web, pushing an ad on the user while they‚Äôre in a conversation with an AI assistant can feel off-putting. It‚Äôs why customers rejected Amazon‚Äôs earlier attempts to infuse ads into its Alexa experience ‚Äî they wanted an assistant, not a personal shopper hawking things for them to buy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hassabis said he wasn‚Äôt feeling top-down pressure to force ads into the AI product, either, though he admitted there may be a way to do them right later on. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe don‚Äôt feel any immediate pressure to make knee-jerk decisions like that ‚Äî I think that‚Äôs been the history of what we‚Äôve done at DeepMind ‚Äî is be very scientific, and rigorous, and thoughtful about each step that we take ‚Äî be that the technology itself or the product,‚Äù he noted.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/google-deepmind-ceo-is-surprised-openai-is-rushing-forward-with-ads-in-chatgpt/</guid><pubDate>Thu, 22 Jan 2026 19:41:01 +0000</pubDate></item><item><title>[NEW] Google begins offering free SAT practice tests powered by Gemini (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/01/google-begins-offering-free-sat-practice-tests-powered-by-gemini/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google says more kinds of standardized tests will be added in the future.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;It‚Äôs no secret that students worldwide use AI chatbots to do their homework and avoid learning things. On the flip side, students can also use AI as a tool to beef up their knowledge and plan for the future with flashcards or study guides. Google hopes its latest Gemini feature will help with the latter. The company has announced that Gemini can now create free SAT practice tests and coach students to help them get higher scores.&lt;/p&gt;
&lt;p&gt;As a standardized test, the content of the SAT follows a predictable pattern. So there‚Äôs no need to use a lengthy, personalized prompt to get Gemini going. Just say something like, ‚ÄúI want to take a practice SAT test,‚Äù and the chatbot will generate one complete with clickable buttons, graphs, and score analysis.&lt;/p&gt;
&lt;p&gt;Of course, generative AI can go off the rails and provide incorrect information, which is a problem when you‚Äôre trying to learn things. However, Google says it has worked with education firms like The Princeton Review to ensure the AI-generated tests resemble what students will see in the real deal.&lt;/p&gt;
&lt;p&gt;The interface for Gemini‚Äôs practice tests includes scoring and the ability to review previous answers. If you are unclear on why a particular answer is right or wrong, the questions have an ‚ÄúExplain answer‚Äù button right at the bottom. After you finish the practice exam, the custom interface (which looks a bit like Gemini‚Äôs Canvas coding tool) can help you follow up on areas that need improvement.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While the SAT is the most widely used test in US college admissions, it‚Äôs not the only one. Google is starting with the SAT but says it plans to support other tests in the future. It does not specify if future tests will be US-centric or if they could branch out to other regions.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2136940-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Practice-SAT-in-Gemini.mp4?_=1" type="video/mp4" /&gt;Practice SAT in Gemini&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Practice SAT in Gemini

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Currently, SAT prep courses and tutoring are a big business. Practice tests and books can cost several hundred dollars, and a one-on-one tutor can run into the thousands. Overall, Americans spend billions of dollars every year on these products and services in hopes of giving their kids a leg up in college admissions.&lt;/p&gt;
&lt;p&gt;AI is already making a dent in the industry‚Äîeven without a dedicated test prep mode, students regularly use chatbots for tutoring, hallucinations be damned. The addition of this feature to Gemini for all users will likely accelerate declines in test prep and tutoring services.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google says more kinds of standardized tests will be added in the future.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Gemini-SAT-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;It‚Äôs no secret that students worldwide use AI chatbots to do their homework and avoid learning things. On the flip side, students can also use AI as a tool to beef up their knowledge and plan for the future with flashcards or study guides. Google hopes its latest Gemini feature will help with the latter. The company has announced that Gemini can now create free SAT practice tests and coach students to help them get higher scores.&lt;/p&gt;
&lt;p&gt;As a standardized test, the content of the SAT follows a predictable pattern. So there‚Äôs no need to use a lengthy, personalized prompt to get Gemini going. Just say something like, ‚ÄúI want to take a practice SAT test,‚Äù and the chatbot will generate one complete with clickable buttons, graphs, and score analysis.&lt;/p&gt;
&lt;p&gt;Of course, generative AI can go off the rails and provide incorrect information, which is a problem when you‚Äôre trying to learn things. However, Google says it has worked with education firms like The Princeton Review to ensure the AI-generated tests resemble what students will see in the real deal.&lt;/p&gt;
&lt;p&gt;The interface for Gemini‚Äôs practice tests includes scoring and the ability to review previous answers. If you are unclear on why a particular answer is right or wrong, the questions have an ‚ÄúExplain answer‚Äù button right at the bottom. After you finish the practice exam, the custom interface (which looks a bit like Gemini‚Äôs Canvas coding tool) can help you follow up on areas that need improvement.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While the SAT is the most widely used test in US college admissions, it‚Äôs not the only one. Google is starting with the SAT but says it plans to support other tests in the future. It does not specify if future tests will be US-centric or if they could branch out to other regions.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2136940-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Practice-SAT-in-Gemini.mp4?_=1" type="video/mp4" /&gt;Practice SAT in Gemini&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Practice SAT in Gemini

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Currently, SAT prep courses and tutoring are a big business. Practice tests and books can cost several hundred dollars, and a one-on-one tutor can run into the thousands. Overall, Americans spend billions of dollars every year on these products and services in hopes of giving their kids a leg up in college admissions.&lt;/p&gt;
&lt;p&gt;AI is already making a dent in the industry‚Äîeven without a dedicated test prep mode, students regularly use chatbots for tutoring, hallucinations be damned. The addition of this feature to Gemini for all users will likely accelerate declines in test prep and tutoring services.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/01/google-begins-offering-free-sat-practice-tests-powered-by-gemini/</guid><pubDate>Thu, 22 Jan 2026 20:46:10 +0000</pubDate></item><item><title>[NEW] Asking Grok to delete fake nudes may force victims to sue in Musk's chosen court (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/01/asking-grok-to-delete-fake-nudes-may-force-victims-to-sue-in-musks-chosen-court/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Millions likely harmed by Grok-edited sex images as X advertisers shrugged.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A post by Elon Musk on the X app, showing an AI prompt-created image, made with xAI's Grok app, depicting Musk wearing a bikini.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Journalists and advocates have been trying to grasp how many victims in total were harmed by Grok‚Äôs nudifying scandal after xAI delayed restricting outputs and app stores refused to cut off access for days.&lt;/p&gt;
&lt;p&gt;The latest estimates show that perhaps millions were harmed in the days immediately after Elon Musk promoted Grok‚Äôs undressing feature on his own X feed by posting a pic of himself in a bikini.&lt;/p&gt;
&lt;p&gt;Over just 11 days after Musk‚Äôs post, Grok sexualized more than 3 million images, of which 23,000 were of children, the Center for Countering Digital Hate (CCDH) estimated in research published Thursday.&lt;/p&gt;
&lt;p&gt;That figure may be inflated, since CCDH did not analyze prompts and could not determine if images were already sexual prior to Grok‚Äôs editing. However, The New York Times shared the CCDH report alongside its own analysis, conservatively estimating that about 41 percent (1.8 million) of 4.4 million images Grok generated between December 31 and January 8 sexualized men, women, and children.&lt;/p&gt;
&lt;p&gt;For xAI and X, the scandal brought scrutiny, but it also helped spike X engagement at a time when Meta‚Äôs rival app, Threads, has begun inching ahead of X in daily usage by mobile device users, TechCrunch reported. Without mentioning Grok, X‚Äôs head of product, Nikita Bier, celebrated the ‚Äúhighest engagement days on X‚Äù in an X post on January 6, just days before X finally started restricting some of Grok‚Äôs outputs for free users.&lt;/p&gt;
&lt;p&gt;Whether or not xAI intended the Grok scandal to surge X and Grok use, that appears to be the outcome. The Times charted Grok trends and found that in the nine days prior to Musk‚Äôs post, combined, Grok was only used about 300,000 times to generate images, but after Musk‚Äôs post, ‚Äúthe number of images created by Grok surged to nearly 600,000 per day‚Äù on X.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In an article declaring that ‚ÄúElon Musk cannot get away with this,‚Äù writers for The Atlantic suggested that X users ‚Äúappeared to be imitating and showing off to one another,‚Äù believing that using Grok to create revenge porn ‚Äúcan make you famous.‚Äù&lt;/p&gt;
&lt;p&gt;X has previously warned that X users who generate illegal content risk permanent suspensions, but X has not confirmed if any users have been banned since public outcry over Grok‚Äôs outputs began. Ars asked and will update this post if X provides any response.&lt;/p&gt;
&lt;h2&gt;xAI fights victim who begged Grok to remove images&lt;/h2&gt;
&lt;p&gt;At first, X only limited Grok‚Äôs image editing for some free users, which The Atlantic noted made it seem like X was ‚Äúessentially marketing nonconsensual sexual images as a paid feature of the platform.‚Äù&lt;/p&gt;
&lt;p&gt;But then, on January 14, X took its strongest action to restrict Grok‚Äôs harmful outputs‚Äîblocking outputs prompted by both free and paid X users. That move came after several countries, perhaps most notably the United Kingdom, and at least one state, California, launched probes.&lt;/p&gt;
&lt;p&gt;Crucially, X‚Äôs updates did not apply to the Grok app or website; however, it can reportedly still be used to generate nonconsensual images.&lt;/p&gt;
&lt;p&gt;That‚Äôs a problem for victims targeted by X users, according to Carrie Goldberg, a lawyer representing Ashley St. Clair, one of the first Grok victims to sue xAI; St. Clair also happens to be the mother of one of Musk‚Äôs children.&lt;/p&gt;
&lt;p&gt;Goldberg told Ars that victims like St. Clair want changes on all Grok platforms, not just X. But it‚Äôs not easy to ‚Äúcompel that kind of product change in a lawsuit,‚Äù Goldberg said. That‚Äôs why St. Clair is hoping the court will agree that Grok is a public nuisance, a claim that provides some injunctive relief to prevent broader social harms if she wins.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, St. Clair is seeking a temporary injunction that would block Grok from generating harmful images of her. But before she can get that order, if she wants a fair shot at winning the case, St. Clair must fight an xAI push counter-suing her and trying to move her lawsuit into Musk‚Äôs preferred Texas court, a recent court filing suggests.&lt;/p&gt;
&lt;p&gt;In that fight, xAI is arguing that St. Clair is bound by xAI‚Äôs terms of service, which were updated the day after she notified the company of her intent to sue.&lt;/p&gt;
&lt;p&gt;Alarmingly, xAI argued that St. Clair effectively agreed to the TOS when she started prompting Grok to delete her nonconsensual images‚Äîwhich is the only way X users had to get images removed quickly, St. Clair alleged. It seems xAI is hoping to turn moments of desperation, where victims beg Grok to remove images, into a legal shield.&lt;/p&gt;
&lt;p&gt;In the filing, Goldberg wrote that St. Clair‚Äôs lawsuit has nothing to do with her own use of Grok, noting that the harassing images could have been made even if she never used any of xAI‚Äôs products. For that reason alone, xAI should not be able to force a change in venue.&lt;/p&gt;
&lt;p&gt;Further, St. Clair‚Äôs use of Grok was clearly under duress, Goldberg argued, noting that one of the photos that Grok edited showed St. Clair‚Äôs toddler‚Äôs backpack.&lt;/p&gt;
&lt;p&gt;‚ÄúREMOVE IT!!!‚Äù St. Clair asked Grok, allegedly feeling increasingly vulnerable every second the images remained online.&lt;/p&gt;
&lt;p&gt;Goldberg wrote that Barry Murphy, an X Safety employee, provided an affidavit that claimed that this instance and others of St. Clair ‚Äúbegging @Grok to remove illegal content constitutes an assent to xAI‚Äôs TOS.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But ‚Äúsuch cannot be the case,‚Äù Goldberg argued.&lt;/p&gt;
&lt;p&gt;Faced with ‚Äúthe implicit threat that Grok would keep the images of St. Clair online and, possibly, create more of them,‚Äù St. Clair had little choice but to interact with Grok, Goldberg argued. And that prompting should not gut protections under New York law that St. Clair seeks to claim in her lawsuit, Goldberg argued, asking the court to void St. Clair‚Äôs xAI contract and reject xAI‚Äôs motion to switch venues.&lt;/p&gt;
&lt;p&gt;Should St. Clair win her fight to keep the lawsuit in New York, the case could help set precedent for perhaps millions of other victims who may be contemplating legal action but fear facing xAI in Musk‚Äôs chosen court.&lt;/p&gt;
&lt;p&gt;‚ÄúIt would be unjust to expect St. Clair to litigate in a state so far from her residence, and it may be so that trial in Texas will be so difficult and inconvenient that St. Clair effectively will be deprived of her day in court,‚Äù Goldberg argued.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Grok may continue harming kids&lt;/h2&gt;
&lt;p&gt;The estimated volume of sexualized images reported this week is alarming because it suggests that Grok, at the peak of the scandal, may have been generating more child sexual abuse material (CSAM) than X finds on its platform each month.&lt;/p&gt;
&lt;p&gt;In 2024, X Safety reported 686,176 instances of CSAM to the National Center for Missing and Exploited Children, which, on average, is about 57,000 CSAM reports each month. If the CCDH‚Äôs estimate of 23,000 Grok outputs that sexualize children over an 11-day span is accurate, then an average monthly total may have exceeded 62,000 if Grok was left unchecked.&lt;/p&gt;
&lt;p&gt;NCMEC did not immediately respond to Ars‚Äô request to comment on how the estimated volume of Grok‚Äôs CSAM compares to X‚Äôs average CSAM reporting. But NCMEC previously told Ars that ‚Äúwhether an image is real or computer-generated, the harm is real, and the material is illegal.‚Äù That suggests Grok could remain a thorn in NCMEC‚Äôs side, as the CCDH has warned that even when X removes harmful Grok posts, ‚Äúimages could still be accessed via separate URLs,‚Äù suggesting that Grok‚Äôs CSAM and other harmful outputs could continue spreading. The CCDH also found instances of alleged CSAM that X had not removed as of January 15.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This is why child safety experts have advocated for more testing to ensure that AI tools like Grok don‚Äôt roll out capabilities like the undressing feature. NCMEC previously told Ars that ‚Äútechnology companies have a responsibility to prevent their tools from being used to sexualize or exploit children.‚Äù Amid a rise in AI-generated CSAM, the UK‚Äôs Internet Watch Foundation similarly warned that ‚Äúit is unacceptable that technology is released which allows criminals to create this content.‚Äù&lt;/p&gt;
&lt;h2&gt;xAI advertisers, investors, partners remain silent&lt;/h2&gt;
&lt;p&gt;Yet, for Musk and xAI, there have been no meaningful consequences for Grok‚Äôs controversial outputs.&lt;/p&gt;
&lt;p&gt;It‚Äôs possible that recently launched probes will result in legal action in California or fines in the UK or elsewhere, but those investigations will likely take months to conclude.&lt;/p&gt;
&lt;p&gt;While US lawmakers have done little to intervene, some Democratic senators have attempted to ask Google and Apple CEOs why X and the Grok app were never restricted in their app stores, demanding a response by January 23. One day ahead of that deadline, senators confirmed to Ars that they‚Äôve received no responses.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, neither Google nor Apple responded to Ars‚Äô request to confirm whether a response is forthcoming or provide any statements on their decisions to keep the apps accessible. Both companies have been silent for weeks, along with other Big Tech companies that appear to be afraid to speak out against Musk‚Äôs chatbot.&lt;/p&gt;
&lt;p&gt;Microsoft and Oracle, which ‚Äúrun Grok on their cloud services,‚Äù as well as Nvidia and Advanced Micro Devices, ‚Äúwhich sell xAI the computer chips needed to train and run Grok,‚Äù declined The Atlantic‚Äôs request to comment on how the scandal has impacted their decisions to partner with xAI. Additionally, a dozen of xAI‚Äôs key investors simply didn‚Äôt respond when The Atlantic asked if ‚Äúthey would continue partnering with xAI absent the company changing its products.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Similarly, dozens of advertisers refused Popular Information‚Äôs request to explain why there was no ad boycott over the Grok CSAM reports. That includes companies that once boycotted X over an antisemitic post from Musk, like ‚ÄúAmazon, Microsoft, and Google, all of which have advertised on X in recent days,‚Äù Popular Information reported.&lt;/p&gt;
&lt;p&gt;It‚Äôs possible that advertisers fear Musk‚Äôs legal wrath if they boycott his platforms. The CCDH overcame a lawsuit from Musk last year, but that‚Äôs pending an appeal. And Musk‚Äôs so-called ‚Äúthermonuclear‚Äù lawsuit against advertisers&amp;nbsp;remains ongoing, with a trial date set for this October.&lt;/p&gt;
&lt;p&gt;The Atlantic suggested that xAI stakeholders are likely hoping the Grok scandal will blow over and they‚Äôll escape unscathed by staying silent. But so far, backlash has seemed to remain strong, perhaps because, while ‚Äúdeepfakes are not new,‚Äù xAI ‚Äúhas made them a dramatically larger problem than ever before,‚Äù The Atlantic opined.&lt;/p&gt;
&lt;p&gt;‚ÄúOne of the largest forums dedicated to making fake images of real people,‚Äù Mr. Deepfakes, shut down in 2024 after public backlash over 43,000 sexual deepfake videos depicting about 3,800 individuals, the NYT reported. If the most recent estimates of Grok‚Äôs deepfakes are accurate, xAI shows how much more damage can be done when nudifying becomes a feature of one of the world‚Äôs biggest social networks, and nobody who has the power to stop it moves to intervene.&lt;/p&gt;
&lt;p&gt;‚ÄúThis is industrial-scale abuse of women and girls,‚Äù Imran Ahmed, the CCDH‚Äôs chief executive, told NYT. ‚ÄúThere have been nudifying tools, but they have never had the distribution, ease of use or the integration into a large platform that Elon Musk did with Grok.‚Äù&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Millions likely harmed by Grok-edited sex images as X advertisers shrugged.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2255893185-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A post by Elon Musk on the X app, showing an AI prompt-created image, made with xAI's Grok app, depicting Musk wearing a bikini.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Journalists and advocates have been trying to grasp how many victims in total were harmed by Grok‚Äôs nudifying scandal after xAI delayed restricting outputs and app stores refused to cut off access for days.&lt;/p&gt;
&lt;p&gt;The latest estimates show that perhaps millions were harmed in the days immediately after Elon Musk promoted Grok‚Äôs undressing feature on his own X feed by posting a pic of himself in a bikini.&lt;/p&gt;
&lt;p&gt;Over just 11 days after Musk‚Äôs post, Grok sexualized more than 3 million images, of which 23,000 were of children, the Center for Countering Digital Hate (CCDH) estimated in research published Thursday.&lt;/p&gt;
&lt;p&gt;That figure may be inflated, since CCDH did not analyze prompts and could not determine if images were already sexual prior to Grok‚Äôs editing. However, The New York Times shared the CCDH report alongside its own analysis, conservatively estimating that about 41 percent (1.8 million) of 4.4 million images Grok generated between December 31 and January 8 sexualized men, women, and children.&lt;/p&gt;
&lt;p&gt;For xAI and X, the scandal brought scrutiny, but it also helped spike X engagement at a time when Meta‚Äôs rival app, Threads, has begun inching ahead of X in daily usage by mobile device users, TechCrunch reported. Without mentioning Grok, X‚Äôs head of product, Nikita Bier, celebrated the ‚Äúhighest engagement days on X‚Äù in an X post on January 6, just days before X finally started restricting some of Grok‚Äôs outputs for free users.&lt;/p&gt;
&lt;p&gt;Whether or not xAI intended the Grok scandal to surge X and Grok use, that appears to be the outcome. The Times charted Grok trends and found that in the nine days prior to Musk‚Äôs post, combined, Grok was only used about 300,000 times to generate images, but after Musk‚Äôs post, ‚Äúthe number of images created by Grok surged to nearly 600,000 per day‚Äù on X.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In an article declaring that ‚ÄúElon Musk cannot get away with this,‚Äù writers for The Atlantic suggested that X users ‚Äúappeared to be imitating and showing off to one another,‚Äù believing that using Grok to create revenge porn ‚Äúcan make you famous.‚Äù&lt;/p&gt;
&lt;p&gt;X has previously warned that X users who generate illegal content risk permanent suspensions, but X has not confirmed if any users have been banned since public outcry over Grok‚Äôs outputs began. Ars asked and will update this post if X provides any response.&lt;/p&gt;
&lt;h2&gt;xAI fights victim who begged Grok to remove images&lt;/h2&gt;
&lt;p&gt;At first, X only limited Grok‚Äôs image editing for some free users, which The Atlantic noted made it seem like X was ‚Äúessentially marketing nonconsensual sexual images as a paid feature of the platform.‚Äù&lt;/p&gt;
&lt;p&gt;But then, on January 14, X took its strongest action to restrict Grok‚Äôs harmful outputs‚Äîblocking outputs prompted by both free and paid X users. That move came after several countries, perhaps most notably the United Kingdom, and at least one state, California, launched probes.&lt;/p&gt;
&lt;p&gt;Crucially, X‚Äôs updates did not apply to the Grok app or website; however, it can reportedly still be used to generate nonconsensual images.&lt;/p&gt;
&lt;p&gt;That‚Äôs a problem for victims targeted by X users, according to Carrie Goldberg, a lawyer representing Ashley St. Clair, one of the first Grok victims to sue xAI; St. Clair also happens to be the mother of one of Musk‚Äôs children.&lt;/p&gt;
&lt;p&gt;Goldberg told Ars that victims like St. Clair want changes on all Grok platforms, not just X. But it‚Äôs not easy to ‚Äúcompel that kind of product change in a lawsuit,‚Äù Goldberg said. That‚Äôs why St. Clair is hoping the court will agree that Grok is a public nuisance, a claim that provides some injunctive relief to prevent broader social harms if she wins.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, St. Clair is seeking a temporary injunction that would block Grok from generating harmful images of her. But before she can get that order, if she wants a fair shot at winning the case, St. Clair must fight an xAI push counter-suing her and trying to move her lawsuit into Musk‚Äôs preferred Texas court, a recent court filing suggests.&lt;/p&gt;
&lt;p&gt;In that fight, xAI is arguing that St. Clair is bound by xAI‚Äôs terms of service, which were updated the day after she notified the company of her intent to sue.&lt;/p&gt;
&lt;p&gt;Alarmingly, xAI argued that St. Clair effectively agreed to the TOS when she started prompting Grok to delete her nonconsensual images‚Äîwhich is the only way X users had to get images removed quickly, St. Clair alleged. It seems xAI is hoping to turn moments of desperation, where victims beg Grok to remove images, into a legal shield.&lt;/p&gt;
&lt;p&gt;In the filing, Goldberg wrote that St. Clair‚Äôs lawsuit has nothing to do with her own use of Grok, noting that the harassing images could have been made even if she never used any of xAI‚Äôs products. For that reason alone, xAI should not be able to force a change in venue.&lt;/p&gt;
&lt;p&gt;Further, St. Clair‚Äôs use of Grok was clearly under duress, Goldberg argued, noting that one of the photos that Grok edited showed St. Clair‚Äôs toddler‚Äôs backpack.&lt;/p&gt;
&lt;p&gt;‚ÄúREMOVE IT!!!‚Äù St. Clair asked Grok, allegedly feeling increasingly vulnerable every second the images remained online.&lt;/p&gt;
&lt;p&gt;Goldberg wrote that Barry Murphy, an X Safety employee, provided an affidavit that claimed that this instance and others of St. Clair ‚Äúbegging @Grok to remove illegal content constitutes an assent to xAI‚Äôs TOS.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But ‚Äúsuch cannot be the case,‚Äù Goldberg argued.&lt;/p&gt;
&lt;p&gt;Faced with ‚Äúthe implicit threat that Grok would keep the images of St. Clair online and, possibly, create more of them,‚Äù St. Clair had little choice but to interact with Grok, Goldberg argued. And that prompting should not gut protections under New York law that St. Clair seeks to claim in her lawsuit, Goldberg argued, asking the court to void St. Clair‚Äôs xAI contract and reject xAI‚Äôs motion to switch venues.&lt;/p&gt;
&lt;p&gt;Should St. Clair win her fight to keep the lawsuit in New York, the case could help set precedent for perhaps millions of other victims who may be contemplating legal action but fear facing xAI in Musk‚Äôs chosen court.&lt;/p&gt;
&lt;p&gt;‚ÄúIt would be unjust to expect St. Clair to litigate in a state so far from her residence, and it may be so that trial in Texas will be so difficult and inconvenient that St. Clair effectively will be deprived of her day in court,‚Äù Goldberg argued.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Grok may continue harming kids&lt;/h2&gt;
&lt;p&gt;The estimated volume of sexualized images reported this week is alarming because it suggests that Grok, at the peak of the scandal, may have been generating more child sexual abuse material (CSAM) than X finds on its platform each month.&lt;/p&gt;
&lt;p&gt;In 2024, X Safety reported 686,176 instances of CSAM to the National Center for Missing and Exploited Children, which, on average, is about 57,000 CSAM reports each month. If the CCDH‚Äôs estimate of 23,000 Grok outputs that sexualize children over an 11-day span is accurate, then an average monthly total may have exceeded 62,000 if Grok was left unchecked.&lt;/p&gt;
&lt;p&gt;NCMEC did not immediately respond to Ars‚Äô request to comment on how the estimated volume of Grok‚Äôs CSAM compares to X‚Äôs average CSAM reporting. But NCMEC previously told Ars that ‚Äúwhether an image is real or computer-generated, the harm is real, and the material is illegal.‚Äù That suggests Grok could remain a thorn in NCMEC‚Äôs side, as the CCDH has warned that even when X removes harmful Grok posts, ‚Äúimages could still be accessed via separate URLs,‚Äù suggesting that Grok‚Äôs CSAM and other harmful outputs could continue spreading. The CCDH also found instances of alleged CSAM that X had not removed as of January 15.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This is why child safety experts have advocated for more testing to ensure that AI tools like Grok don‚Äôt roll out capabilities like the undressing feature. NCMEC previously told Ars that ‚Äútechnology companies have a responsibility to prevent their tools from being used to sexualize or exploit children.‚Äù Amid a rise in AI-generated CSAM, the UK‚Äôs Internet Watch Foundation similarly warned that ‚Äúit is unacceptable that technology is released which allows criminals to create this content.‚Äù&lt;/p&gt;
&lt;h2&gt;xAI advertisers, investors, partners remain silent&lt;/h2&gt;
&lt;p&gt;Yet, for Musk and xAI, there have been no meaningful consequences for Grok‚Äôs controversial outputs.&lt;/p&gt;
&lt;p&gt;It‚Äôs possible that recently launched probes will result in legal action in California or fines in the UK or elsewhere, but those investigations will likely take months to conclude.&lt;/p&gt;
&lt;p&gt;While US lawmakers have done little to intervene, some Democratic senators have attempted to ask Google and Apple CEOs why X and the Grok app were never restricted in their app stores, demanding a response by January 23. One day ahead of that deadline, senators confirmed to Ars that they‚Äôve received no responses.&lt;/p&gt;
&lt;p&gt;Unsurprisingly, neither Google nor Apple responded to Ars‚Äô request to confirm whether a response is forthcoming or provide any statements on their decisions to keep the apps accessible. Both companies have been silent for weeks, along with other Big Tech companies that appear to be afraid to speak out against Musk‚Äôs chatbot.&lt;/p&gt;
&lt;p&gt;Microsoft and Oracle, which ‚Äúrun Grok on their cloud services,‚Äù as well as Nvidia and Advanced Micro Devices, ‚Äúwhich sell xAI the computer chips needed to train and run Grok,‚Äù declined The Atlantic‚Äôs request to comment on how the scandal has impacted their decisions to partner with xAI. Additionally, a dozen of xAI‚Äôs key investors simply didn‚Äôt respond when The Atlantic asked if ‚Äúthey would continue partnering with xAI absent the company changing its products.‚Äù&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Similarly, dozens of advertisers refused Popular Information‚Äôs request to explain why there was no ad boycott over the Grok CSAM reports. That includes companies that once boycotted X over an antisemitic post from Musk, like ‚ÄúAmazon, Microsoft, and Google, all of which have advertised on X in recent days,‚Äù Popular Information reported.&lt;/p&gt;
&lt;p&gt;It‚Äôs possible that advertisers fear Musk‚Äôs legal wrath if they boycott his platforms. The CCDH overcame a lawsuit from Musk last year, but that‚Äôs pending an appeal. And Musk‚Äôs so-called ‚Äúthermonuclear‚Äù lawsuit against advertisers&amp;nbsp;remains ongoing, with a trial date set for this October.&lt;/p&gt;
&lt;p&gt;The Atlantic suggested that xAI stakeholders are likely hoping the Grok scandal will blow over and they‚Äôll escape unscathed by staying silent. But so far, backlash has seemed to remain strong, perhaps because, while ‚Äúdeepfakes are not new,‚Äù xAI ‚Äúhas made them a dramatically larger problem than ever before,‚Äù The Atlantic opined.&lt;/p&gt;
&lt;p&gt;‚ÄúOne of the largest forums dedicated to making fake images of real people,‚Äù Mr. Deepfakes, shut down in 2024 after public backlash over 43,000 sexual deepfake videos depicting about 3,800 individuals, the NYT reported. If the most recent estimates of Grok‚Äôs deepfakes are accurate, xAI shows how much more damage can be done when nudifying becomes a feature of one of the world‚Äôs biggest social networks, and nobody who has the power to stop it moves to intervene.&lt;/p&gt;
&lt;p&gt;‚ÄúThis is industrial-scale abuse of women and girls,‚Äù Imran Ahmed, the CCDH‚Äôs chief executive, told NYT. ‚ÄúThere have been nudifying tools, but they have never had the distribution, ease of use or the integration into a large platform that Elon Musk did with Grok.‚Äù&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/01/asking-grok-to-delete-fake-nudes-may-force-victims-to-sue-in-musks-chosen-court/</guid><pubDate>Thu, 22 Jan 2026 21:16:42 +0000</pubDate></item><item><title>[NEW] Report: Apple plans to launch AI-powered wearable pin device as soon as 2027 (AI - Ars Technica)</title><link>https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Apple, OpenAI, Meta, and more are all racing toward AI hardware products.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A small metal disc" class="absolute inset-0 w-full h-full object-cover hidden" height="159" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-300x159.png" width="300" /&gt;
                  &lt;img alt="A small metal disc" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new wearable is said to resemble an AirTag like this.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information.&lt;/p&gt;
&lt;p&gt;The product is said to be ‚Äúthe same size as an AirTag, only slightly thicker,‚Äù and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple‚Äôs solution, should Apple offload the processing to a synced external device like an iPhone.&lt;/p&gt;
&lt;p&gt;The Information‚Äôs sources don‚Äôt specify whether that‚Äôs the plan, or if it will be a standalone device.&lt;/p&gt;
&lt;p&gt;The wearable will have a single physical button ‚Äúalong its edges‚Äù and will feature a speaker. It will have three microphones and two cameras (one regular and one wide-angle) for capturing information about the user‚Äôs surroundings. It will use a magnetic inductive wireless charging surface similar to the one used to charge the Apple Watch.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The report didn‚Äôt include any information about pricing, but it did say that Apple has fast-tracked the product with the hope to release it as early as 2027. Twenty million units are planned for launch, suggesting the company does not expect it to be a sensational consumer success at launch the way some of its past products, like AirPods, have been.&lt;/p&gt;
&lt;p&gt;Not long ago, it was reported that OpenAI (the company behind ChatGPT) plans to release its own hardware, though the specifics and form factor are not publicly known. Apple is expecting fierce competition there, as well as with Meta, which Apple already expected to compete with in the emerging and related smart glasses market.&lt;/p&gt;
&lt;p&gt;Apple has experienced significant internal turmoil over AI, with former AI lead John Giannandrea‚Äôs conservative approach to the technology failing to lead to a usable, true LLM-based Siri or other products analysts expect would make Apply stay competitive in the space with other Big Tech companies.&lt;/p&gt;
&lt;p&gt;Just a few days ago, it was revealed that Apple will tap Google‚Äôs Gemini large language models for an LLM overhaul of Siri. Other AI-driven products like smart glasses and an in-home smart display are also planned.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Apple, OpenAI, Meta, and more are all racing toward AI hardware products.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A small metal disc" class="absolute inset-0 w-full h-full object-cover hidden" height="159" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-300x159.png" width="300" /&gt;
                  &lt;img alt="A small metal disc" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/05/AirTag-1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new wearable is said to resemble an AirTag like this.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Apple is working on a wearable device that will allow the user to take advantage of AI models, according to sources familiar with the product who spoke with tech publication The Information.&lt;/p&gt;
&lt;p&gt;The product is said to be ‚Äúthe same size as an AirTag, only slightly thicker,‚Äù and will be worn as a pin, inviting comparisons to the failed Humane AI pin that launched to bad reviews and lackluster sales in 2024. The Humane product was criticized for sluggish performance and low battery life, but those shortcomings could potentially be addressed by Apple‚Äôs solution, should Apple offload the processing to a synced external device like an iPhone.&lt;/p&gt;
&lt;p&gt;The Information‚Äôs sources don‚Äôt specify whether that‚Äôs the plan, or if it will be a standalone device.&lt;/p&gt;
&lt;p&gt;The wearable will have a single physical button ‚Äúalong its edges‚Äù and will feature a speaker. It will have three microphones and two cameras (one regular and one wide-angle) for capturing information about the user‚Äôs surroundings. It will use a magnetic inductive wireless charging surface similar to the one used to charge the Apple Watch.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The report didn‚Äôt include any information about pricing, but it did say that Apple has fast-tracked the product with the hope to release it as early as 2027. Twenty million units are planned for launch, suggesting the company does not expect it to be a sensational consumer success at launch the way some of its past products, like AirPods, have been.&lt;/p&gt;
&lt;p&gt;Not long ago, it was reported that OpenAI (the company behind ChatGPT) plans to release its own hardware, though the specifics and form factor are not publicly known. Apple is expecting fierce competition there, as well as with Meta, which Apple already expected to compete with in the emerging and related smart glasses market.&lt;/p&gt;
&lt;p&gt;Apple has experienced significant internal turmoil over AI, with former AI lead John Giannandrea‚Äôs conservative approach to the technology failing to lead to a usable, true LLM-based Siri or other products analysts expect would make Apply stay competitive in the space with other Big Tech companies.&lt;/p&gt;
&lt;p&gt;Just a few days ago, it was revealed that Apple will tap Google‚Äôs Gemini large language models for an LLM overhaul of Siri. Other AI-driven products like smart glasses and an in-home smart display are also planned.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/apple/2026/01/report-apple-plans-to-launch-ai-powered-wearable-pin-device-as-soon-as-2027/</guid><pubDate>Thu, 22 Jan 2026 21:32:28 +0000</pubDate></item><item><title>[NEW] Are AI agents ready for the workplace? A new benchmark raises doubts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/are-ai-agents-ready-for-the-workplace-a-new-benchmark-raises-doubts/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It‚Äôs been nearly two years since Microsoft CEO Satya Nadella predicted AI would replace knowledge work ‚Äî the white-collar jobs held by lawyers, investment bankers, librarians, accountants, IT, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But despite the huge progress made by foundation models, the change in knowledge work has been slow to arrive. Models have mastered in-depth research and agentic planning, but for whatever reason, most white-collar work has been relatively unaffected. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It‚Äôs one of the biggest mysteries in AI ‚Äî and thanks to new research from the training-data giant Mercor, we‚Äôre finally getting some answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new research looks at how leading AI models hold up doing actual white-collar work tasks, drawn from consulting, investment banking, and law. The result is a new benchmark called APEX-Agents ‚Äî and so far, every AI lab is getting a failing grade. Faced with queries from real professionals, even the best models struggled to get more than a quarter of the questions right. The vast majority of the time, the model came back with a wrong answer or no answer at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Mercor CEO Brendan Foody, who worked on the paper, the models‚Äô biggest stumbling point was tracking down information across multiple domains ‚Äî something that‚Äôs integral to most of the knowledge work performed by humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúOne of the big changes in this benchmark is that we built out the entire environment, modeled after real professional services,‚Äù Foody told TechCrunch. ‚ÄúThe way we do our jobs isn‚Äôt with one individual giving us all the context in one place. In real life, you‚Äôre operating across Slack and Google Drive and all these other tools.‚Äù For many agentic AI models, that kind of multi-domain reasoning is still hit or miss.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085292" height="307" src="https://techcrunch.com/wp-content/uploads/2026/01/Screen-Shot-2026-01-22-at-3.25.58-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The scenarios were all drawn from actual professionals on Mercor‚Äôs expert marketplace, who both laid out the queries and set the standard for a successful response. Looking through the questions, which are posted publicly on Hugging Face, gives a sense of how complex the tasks can get.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;One question in the ‚ÄúLaw‚Äù section reads:&amp;nbsp;&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;During the first 48 minutes of the EU production outage, Northstar‚Äôs engineering team exported one or two bundled sets of EU production event logs containing personal data to the U.S. analytics vendor&amp;nbsp;‚Ä¶ Under Northstar‚Äôs own policies, it can reasonably treat the one or two log exports as consistent with Article 49?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;The correct answer is yes, but getting there requires an in-depth assessment of the company‚Äôs own policies as well as the relevant EU privacy laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That might stump even a well-informed human, but the researchers were trying to model the work done by professionals in the field. If an LLM can reliably answer these questions, it could effectively replace many of the lawyers working today. ‚ÄúI think this is probably the most important topic in the economy,‚Äù Foody told TechCrunch. ‚ÄúThe benchmark is very reflective of the real work that these people do.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also attempted to measure professional skills with its GDPval benchmark ‚Äî but the APEX-Agents test differs in important ways. Where GDPval tests general knowledge across a wide range of professions, the APEX-Agents benchmark measures the system‚Äôs ability to perform sustained tasks in a narrow set of high-value professions. The result is more difficult for models, but also more closely tied to whether these jobs can be automated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While none of the models proved ready to take over as investment bankers, some were clearly closer to the mark. Gemini 3 Flash performed the best of the group with 24% one-shot accuracy, followed closely by GPT-5.2 with 23%. Below that, Opus 4.5, Gemini 3 Pro and GPT-5 all scored roughly 18%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the initial results fall short, the AI field has a history of blowing through challenging benchmarks. Now that the APEX-Agents test is public, it‚Äôs an open challenge for AI labs that believe they can do better ‚Äî something Foody fully expects in the months to come.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIt‚Äôs improving really quickly,‚Äù he told TechCrunch. ‚ÄúRight now it‚Äôs fair to say it‚Äôs like an intern that gets it right a quarter of the time, but last year it was the intern that gets it right five or 10% of the time. That kind of improvement year after year can have an impact so quickly.‚Äù&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It‚Äôs been nearly two years since Microsoft CEO Satya Nadella predicted AI would replace knowledge work ‚Äî the white-collar jobs held by lawyers, investment bankers, librarians, accountants, IT, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But despite the huge progress made by foundation models, the change in knowledge work has been slow to arrive. Models have mastered in-depth research and agentic planning, but for whatever reason, most white-collar work has been relatively unaffected. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It‚Äôs one of the biggest mysteries in AI ‚Äî and thanks to new research from the training-data giant Mercor, we‚Äôre finally getting some answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new research looks at how leading AI models hold up doing actual white-collar work tasks, drawn from consulting, investment banking, and law. The result is a new benchmark called APEX-Agents ‚Äî and so far, every AI lab is getting a failing grade. Faced with queries from real professionals, even the best models struggled to get more than a quarter of the questions right. The vast majority of the time, the model came back with a wrong answer or no answer at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Mercor CEO Brendan Foody, who worked on the paper, the models‚Äô biggest stumbling point was tracking down information across multiple domains ‚Äî something that‚Äôs integral to most of the knowledge work performed by humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúOne of the big changes in this benchmark is that we built out the entire environment, modeled after real professional services,‚Äù Foody told TechCrunch. ‚ÄúThe way we do our jobs isn‚Äôt with one individual giving us all the context in one place. In real life, you‚Äôre operating across Slack and Google Drive and all these other tools.‚Äù For many agentic AI models, that kind of multi-domain reasoning is still hit or miss.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3085292" height="307" src="https://techcrunch.com/wp-content/uploads/2026/01/Screen-Shot-2026-01-22-at-3.25.58-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The scenarios were all drawn from actual professionals on Mercor‚Äôs expert marketplace, who both laid out the queries and set the standard for a successful response. Looking through the questions, which are posted publicly on Hugging Face, gives a sense of how complex the tasks can get.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;One question in the ‚ÄúLaw‚Äù section reads:&amp;nbsp;&lt;/p&gt;

&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p class="wp-block-paragraph"&gt;During the first 48 minutes of the EU production outage, Northstar‚Äôs engineering team exported one or two bundled sets of EU production event logs containing personal data to the U.S. analytics vendor&amp;nbsp;‚Ä¶ Under Northstar‚Äôs own policies, it can reasonably treat the one or two log exports as consistent with Article 49?&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p class="wp-block-paragraph"&gt;The correct answer is yes, but getting there requires an in-depth assessment of the company‚Äôs own policies as well as the relevant EU privacy laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That might stump even a well-informed human, but the researchers were trying to model the work done by professionals in the field. If an LLM can reliably answer these questions, it could effectively replace many of the lawyers working today. ‚ÄúI think this is probably the most important topic in the economy,‚Äù Foody told TechCrunch. ‚ÄúThe benchmark is very reflective of the real work that these people do.‚Äù&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also attempted to measure professional skills with its GDPval benchmark ‚Äî but the APEX-Agents test differs in important ways. Where GDPval tests general knowledge across a wide range of professions, the APEX-Agents benchmark measures the system‚Äôs ability to perform sustained tasks in a narrow set of high-value professions. The result is more difficult for models, but also more closely tied to whether these jobs can be automated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While none of the models proved ready to take over as investment bankers, some were clearly closer to the mark. Gemini 3 Flash performed the best of the group with 24% one-shot accuracy, followed closely by GPT-5.2 with 23%. Below that, Opus 4.5, Gemini 3 Pro and GPT-5 all scored roughly 18%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the initial results fall short, the AI field has a history of blowing through challenging benchmarks. Now that the APEX-Agents test is public, it‚Äôs an open challenge for AI labs that believe they can do better ‚Äî something Foody fully expects in the months to come.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúIt‚Äôs improving really quickly,‚Äù he told TechCrunch. ‚ÄúRight now it‚Äôs fair to say it‚Äôs like an intern that gets it right a quarter of the time, but last year it was the intern that gets it right five or 10% of the time. That kind of improvement year after year can have an impact so quickly.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/are-ai-agents-ready-for-the-workplace-a-new-benchmark-raises-doubts/</guid><pubDate>Thu, 22 Jan 2026 21:42:18 +0000</pubDate></item><item><title>[NEW] Inference startup Inferact lands $150M to commercialize vLLM (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/inference-startup-inferact-lands-150m-to-commercialize-vllm/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2016/10/ai-tool.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The creators of the open source project vLLM have announced that they transitioned the popular tool into a VC-backed startup, Inferact, raising $150 million in seed funding at an $800 million valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was co-led by Andreessen Horowitz and Lightspeed Venture Partners, confirming TechCrunch‚Äôs earlier reporting that vLLM has raised capital from a16z.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inferact‚Äôs debut mirrors the recent commercialization of the SGLang project as RadixArk, which sources told us secured capital at a $400 million valuation led by Accel, as we reported on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the focus in AI shifts from training models to deploying them in applications, a process known as inference, technologies like vLLM and SGLang that make these AI tools run faster and more affordably are attracting investor attention.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both vLLM and SGLang were incubated in 2023 at the UC Berkeley lab of Databricks co-founder Ion Stoica.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Inferact CEO Simon Mo, one of the project‚Äôs original creators, told Bloomberg that existing users of vLLM include Amazon‚Äôs cloud service and the shopping app.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2016/10/ai-tool.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The creators of the open source project vLLM have announced that they transitioned the popular tool into a VC-backed startup, Inferact, raising $150 million in seed funding at an $800 million valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was co-led by Andreessen Horowitz and Lightspeed Venture Partners, confirming TechCrunch‚Äôs earlier reporting that vLLM has raised capital from a16z.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inferact‚Äôs debut mirrors the recent commercialization of the SGLang project as RadixArk, which sources told us secured capital at a $400 million valuation led by Accel, as we reported on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As the focus in AI shifts from training models to deploying them in applications, a process known as inference, technologies like vLLM and SGLang that make these AI tools run faster and more affordably are attracting investor attention.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both vLLM and SGLang were incubated in 2023 at the UC Berkeley lab of Databricks co-founder Ion Stoica.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Inferact CEO Simon Mo, one of the project‚Äôs original creators, told Bloomberg that existing users of vLLM include Amazon‚Äôs cloud service and the shopping app.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/inference-startup-inferact-lands-150m-to-commercialize-vllm/</guid><pubDate>Thu, 22 Jan 2026 22:42:00 +0000</pubDate></item><item><title>[NEW] Voice AI engine and OpenAI partner LiveKit hits $1B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/voice-ai-engine-and-openai-partner-livekit-hits-1b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1424498694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;LiveKit, a developer of infrastructure software for real-time AI voice and video applications, has announced the raise of $100 million in funding at a $1 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round, which comes 10 months after LiveKit‚Äôs previous fundraise, was led by Index Ventures with participation from existing investors, including Altimeter Capital Management, Hanabi Capital, and Redpoint Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;LiveKit powers OpenAI‚Äôs ChatGPT voice mode. The startup‚Äôs other customers include xAI, Salesforce, Tesla, as well as 911 emergency service operators and mental health providers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded in 2021 by Russ d‚ÄôSa and David Zhao as an open source software project for building apps that can transmit real-time audio and video without interruptions, in an era when the whole world was meeting on Zoom during the pandemic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although LiveKit began as a free developer tool, the business took off after the founders realized big companies wanted a managed cloud version and began providing those services to enterprises amid the voice AI boom.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1424498694.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;LiveKit, a developer of infrastructure software for real-time AI voice and video applications, has announced the raise of $100 million in funding at a $1 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round, which comes 10 months after LiveKit‚Äôs previous fundraise, was led by Index Ventures with participation from existing investors, including Altimeter Capital Management, Hanabi Capital, and Redpoint Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;LiveKit powers OpenAI‚Äôs ChatGPT voice mode. The startup‚Äôs other customers include xAI, Salesforce, Tesla, as well as 911 emergency service operators and mental health providers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded in 2021 by Russ d‚ÄôSa and David Zhao as an open source software project for building apps that can transmit real-time audio and video without interruptions, in an era when the whole world was meeting on Zoom during the pandemic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although LiveKit began as a free developer tool, the business took off after the founders realized big companies wanted a managed cloud version and began providing those services to enterprises amid the voice AI boom.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/voice-ai-engine-and-openai-partner-livekit-hits-1b-valuation/</guid><pubDate>Thu, 22 Jan 2026 22:44:29 +0000</pubDate></item><item><title>[NEW] Overrun with AI slop, cURL scraps bug bounties to ensure "intact mental health" (AI - Ars Technica)</title><link>https://arstechnica.com/security/2026/01/overrun-with-ai-slop-curl-scraps-bug-bounties-to-ensure-intact-mental-health/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The onslaught includes LLMs finding bogus vulnerabilities and code that won‚Äôt compile.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="absolute inset-0 w-full h-full object-cover hidden" height="404" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-640x404.jpg" width="640" /&gt;
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The project developer for one of the Internet‚Äôs most popular networking tools is scrapping its vulnerability reward program after being overrun by a spike in the submission of low-quality reports, much of it AI-generated slop.&lt;/p&gt;
&lt;p&gt;‚ÄúWe are just a small single open source project with a small number of active maintainers,‚Äù Daniel Stenberg, the founder and lead developer of the open source app cURL, said Thursday. ‚ÄúIt is not in our power to change how all these people and their slop machines work. We need to make moves to ensure our survival and intact mental health.‚Äù&lt;/p&gt;
&lt;h2&gt;Manufacturing bogus bugs&lt;/h2&gt;
&lt;p&gt;His comments came as cURL users complained that the move was treating the symptoms caused by AI slop without addressing the cause. The users said they were concerned the move would eliminate a key means for ensuring and maintaining the security of the tool. Stenberg largely agreed, but indicated his team had little choice.&lt;/p&gt;
&lt;p&gt;In a separate post on Thursday, Stenberg wrote: ‚ÄúWe will ban you and ridicule you in public if you waste our time on crap reports.‚Äù An update to cURL‚Äôs official GitHub account made the termination, which takes effect at the end of this month, official.&lt;/p&gt;
&lt;p&gt;cURL was first released three decades ago, under the name httpget and later urlget. It has since become an indispensable tool among admins, researchers, and security professionals, among others, for a wide range of tasks, including file transfers, troubleshooting buggy web software, and automating tasks. cURL is integrated into default versions of Windows, macOS, and most distributions of Linux.&lt;/p&gt;
&lt;p&gt;As such a widely used tool for interacting with vast amounts of data online, security is paramount. Like many other software makers, cURL project members have relied on private bug reports submitted by outside researchers. To provide an incentive and to reward high-quality submissions, the project members have paid cash bounties in return for reports of high-severity vulnerabilities.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Last May, Stenberg said the number of low-quality AI-generated reports was putting a strain on the cURL security team and was likely to metastasize, hampering other software developers.&lt;/p&gt;
&lt;p&gt;‚ÄúAI slop is overwhelming maintainers *today* and it won‚Äôt stop at curl but only starts there,‚Äù he said at the time.&lt;/p&gt;
&lt;p&gt;The lead developer has also posted a page listing some of the specious reports submitted in recent months. In response to one such report, a cURL project member wrote: ‚ÄúI think you‚Äôre a victim of LLM hallucination.‚Äù The member continued:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The text has some similarities to the (bogus) CVE-2020-19909 and other reports. There are plenty of clues that Bard has manufactured bogus information: that code snippet of ‚Äúcurl_easy_setopt‚Äù doesn‚Äôt match the actual signature of the function (and wouldn‚Äôt even compile), a changelog that don‚Äôt match reality, and more indications that this is completely bogus. I‚Äôm curious to hear what your exploit does against a made-up vulnerability. Care to share it?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;After the bug reporter complained and reiterated the risk posed by the non-existent vulnerability, Stenberg jumped in and wrote: ‚ÄúYou were fooled by an AI into believing that. In what way did we not meet our end of the deal?&lt;/p&gt;
&lt;p&gt;Stenberg isn‚Äôt critical of AI-assisted bug reports in all cases. In September, he publicly applauded a researcher for sending a ‚Äúmassive list‚Äù of bugs that were found using a set of AI-assisted tools. The reports had resulted in 22 bug fixes at the time.&lt;/p&gt;
&lt;p&gt;In an interview, Stenberg said that the reporter, Joshua Rogers, mostly used AI-powered code analyzer called ZeroPath.&lt;/p&gt;
&lt;p&gt;‚ÄúA clever person using a powerful tool,‚Äù Stenberg wrote. ‚ÄúI believe most of the worst reports we get are from people just asking an AI bot without caring or understanding much about what it reports.‚Äù&lt;/p&gt;
&lt;p&gt;Unfortunately, such cases seem to be the exception. AI slop has already flooded music-streaming services with so many songs‚Äîoften misattributed to real artists‚Äîthat the platforms are slowly becoming unusable for music discovery. cURL‚Äôs move may be an early indication that something similar is happening to bug bounty programs.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The onslaught includes LLMs finding bogus vulnerabilities and code that won‚Äôt compile.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="absolute inset-0 w-full h-full object-cover hidden" height="404" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-640x404.jpg" width="640" /&gt;
                  &lt;img alt="Ai chatbot vomiting misinformation and synthetic data." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai-slop-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The project developer for one of the Internet‚Äôs most popular networking tools is scrapping its vulnerability reward program after being overrun by a spike in the submission of low-quality reports, much of it AI-generated slop.&lt;/p&gt;
&lt;p&gt;‚ÄúWe are just a small single open source project with a small number of active maintainers,‚Äù Daniel Stenberg, the founder and lead developer of the open source app cURL, said Thursday. ‚ÄúIt is not in our power to change how all these people and their slop machines work. We need to make moves to ensure our survival and intact mental health.‚Äù&lt;/p&gt;
&lt;h2&gt;Manufacturing bogus bugs&lt;/h2&gt;
&lt;p&gt;His comments came as cURL users complained that the move was treating the symptoms caused by AI slop without addressing the cause. The users said they were concerned the move would eliminate a key means for ensuring and maintaining the security of the tool. Stenberg largely agreed, but indicated his team had little choice.&lt;/p&gt;
&lt;p&gt;In a separate post on Thursday, Stenberg wrote: ‚ÄúWe will ban you and ridicule you in public if you waste our time on crap reports.‚Äù An update to cURL‚Äôs official GitHub account made the termination, which takes effect at the end of this month, official.&lt;/p&gt;
&lt;p&gt;cURL was first released three decades ago, under the name httpget and later urlget. It has since become an indispensable tool among admins, researchers, and security professionals, among others, for a wide range of tasks, including file transfers, troubleshooting buggy web software, and automating tasks. cURL is integrated into default versions of Windows, macOS, and most distributions of Linux.&lt;/p&gt;
&lt;p&gt;As such a widely used tool for interacting with vast amounts of data online, security is paramount. Like many other software makers, cURL project members have relied on private bug reports submitted by outside researchers. To provide an incentive and to reward high-quality submissions, the project members have paid cash bounties in return for reports of high-severity vulnerabilities.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Last May, Stenberg said the number of low-quality AI-generated reports was putting a strain on the cURL security team and was likely to metastasize, hampering other software developers.&lt;/p&gt;
&lt;p&gt;‚ÄúAI slop is overwhelming maintainers *today* and it won‚Äôt stop at curl but only starts there,‚Äù he said at the time.&lt;/p&gt;
&lt;p&gt;The lead developer has also posted a page listing some of the specious reports submitted in recent months. In response to one such report, a cURL project member wrote: ‚ÄúI think you‚Äôre a victim of LLM hallucination.‚Äù The member continued:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The text has some similarities to the (bogus) CVE-2020-19909 and other reports. There are plenty of clues that Bard has manufactured bogus information: that code snippet of ‚Äúcurl_easy_setopt‚Äù doesn‚Äôt match the actual signature of the function (and wouldn‚Äôt even compile), a changelog that don‚Äôt match reality, and more indications that this is completely bogus. I‚Äôm curious to hear what your exploit does against a made-up vulnerability. Care to share it?&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;After the bug reporter complained and reiterated the risk posed by the non-existent vulnerability, Stenberg jumped in and wrote: ‚ÄúYou were fooled by an AI into believing that. In what way did we not meet our end of the deal?&lt;/p&gt;
&lt;p&gt;Stenberg isn‚Äôt critical of AI-assisted bug reports in all cases. In September, he publicly applauded a researcher for sending a ‚Äúmassive list‚Äù of bugs that were found using a set of AI-assisted tools. The reports had resulted in 22 bug fixes at the time.&lt;/p&gt;
&lt;p&gt;In an interview, Stenberg said that the reporter, Joshua Rogers, mostly used AI-powered code analyzer called ZeroPath.&lt;/p&gt;
&lt;p&gt;‚ÄúA clever person using a powerful tool,‚Äù Stenberg wrote. ‚ÄúI believe most of the worst reports we get are from people just asking an AI bot without caring or understanding much about what it reports.‚Äù&lt;/p&gt;
&lt;p&gt;Unfortunately, such cases seem to be the exception. AI slop has already flooded music-streaming services with so many songs‚Äîoften misattributed to real artists‚Äîthat the platforms are slowly becoming unusable for music discovery. cURL‚Äôs move may be an early indication that something similar is happening to bug bounty programs.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2026/01/overrun-with-ai-slop-curl-scraps-bug-bounties-to-ensure-intact-mental-health/</guid><pubDate>Thu, 22 Jan 2026 22:46:30 +0000</pubDate></item><item><title>[NEW] OpenAI¬†is coming for those sweet enterprise dollars in 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/openai-is-coming-for-those-sweet-enterprise-dollars-in-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has reorganized some of its leadership and picked a familiar face to lead its push into selling AI to business customers as the company looks to catch up to its rivals in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company appointed Barret Zoph to lead its efforts to sell its AI to enterprises, according to reporting from The Information, citing an internal OpenAI memo.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to OpenAI for confirmation and more information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph returned to OpenAI last week after leaving Thinking Machine Labs, former OpenAI co-founder Mira Murati‚Äôs AI startup where Zoph had served as a co-founder and chief technology officer since October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exact circumstances of his departure aren‚Äôt clear, with rumors swirling about whether Zoph and a few other former OpenAI employees were fired or left on their own accord, possibly with plans to return to OpenAI all along.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph was previously the vice president of post-training inference at OpenAI from September 2022 to October 2024. He‚Äôs stepping into a very different position and will likely play an important role at the company as it looks to grow its enterprise business ‚Äî an area where it is losing ground to competitors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched its enterprise-focused ChatGPT Enterprise product in 2023 more than a year before Anthropic and multiple years before Google launched their enterprise offerings. The company claims the product has more than 5 million business users and counts companies including SoftBank, Target, and Lowe‚Äôs as customers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But its market share is falling while its rivals are climbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic holds a dominant lead over its AI rivals when it comes to enterprise large language model usage. The AI research lab holds a 40% market share, according to a December report from VC firm Menlo Ventures (which, it should be noted, has invested aggressively in Anthropic). In July, the startup‚Äôs market share was estimated to be 32%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google‚Äôs Gemini adoption has been steadier, says Menlo Ventures. The company released its enterprise product last fall and has seen its enterprise LLM usage market share largely stay the same, growing from 20% in July to 21% at the end of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI on the other hand has seen its usage market share drop from 50% in 2023 to 27% at the end of 2025 ‚Äî a trend that appears to concern the company. OpenAI CEO Sam Altman expressed concern that Google Gemini‚Äôs growth was starting to encroach on OpenAI in an internal memo a few months ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise growth is an area of focus for the company in 2026, OpenAI‚Äôs CFO Sarah Friar wrote in a blog post on Sunday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has since announced an expanded multi-year partnership with ServiceNow that will give ServiceNow customers access to OpenAI models.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2213399157.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI has reorganized some of its leadership and picked a familiar face to lead its push into selling AI to business customers as the company looks to catch up to its rivals in 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company appointed Barret Zoph to lead its efforts to sell its AI to enterprises, according to reporting from The Information, citing an internal OpenAI memo.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to OpenAI for confirmation and more information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph returned to OpenAI last week after leaving Thinking Machine Labs, former OpenAI co-founder Mira Murati‚Äôs AI startup where Zoph had served as a co-founder and chief technology officer since October 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exact circumstances of his departure aren‚Äôt clear, with rumors swirling about whether Zoph and a few other former OpenAI employees were fired or left on their own accord, possibly with plans to return to OpenAI all along.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zoph was previously the vice president of post-training inference at OpenAI from September 2022 to October 2024. He‚Äôs stepping into a very different position and will likely play an important role at the company as it looks to grow its enterprise business ‚Äî an area where it is losing ground to competitors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched its enterprise-focused ChatGPT Enterprise product in 2023 more than a year before Anthropic and multiple years before Google launched their enterprise offerings. The company claims the product has more than 5 million business users and counts companies including SoftBank, Target, and Lowe‚Äôs as customers.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But its market share is falling while its rivals are climbing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic holds a dominant lead over its AI rivals when it comes to enterprise large language model usage. The AI research lab holds a 40% market share, according to a December report from VC firm Menlo Ventures (which, it should be noted, has invested aggressively in Anthropic). In July, the startup‚Äôs market share was estimated to be 32%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google‚Äôs Gemini adoption has been steadier, says Menlo Ventures. The company released its enterprise product last fall and has seen its enterprise LLM usage market share largely stay the same, growing from 20% in July to 21% at the end of the year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI on the other hand has seen its usage market share drop from 50% in 2023 to 27% at the end of 2025 ‚Äî a trend that appears to concern the company. OpenAI CEO Sam Altman expressed concern that Google Gemini‚Äôs growth was starting to encroach on OpenAI in an internal memo a few months ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise growth is an area of focus for the company in 2026, OpenAI‚Äôs CFO Sarah Friar wrote in a blog post on Sunday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has since announced an expanded multi-year partnership with ServiceNow that will give ServiceNow customers access to OpenAI models.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/openai-is-coming-for-those-sweet-enterprise-dollars-in-2026/</guid><pubDate>Fri, 23 Jan 2026 00:52:33 +0000</pubDate></item></channel></rss>