<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 09 Jan 2026 01:57:05 +0000</lastBuildDate><item><title>ChatGPT falls to new data-pilfering attack as a vicious cycle in AI continues (AI - Ars Technica)</title><link>https://arstechnica.com/security/2026/01/chatgpt-falls-to-new-data-pilfering-attack-as-a-vicious-cycle-in-ai-continues/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Will LLMs ever be able to stamp out the root cause of these attacks? Possibly not.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Female hand holding smartphone showing an evil with devil horn on her AI chatbot conversation app in the city. Illustrating the ideas around the risks and dangers of Artificial Intelligence (AI)." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/AI-chatbot-threat-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Female hand holding smartphone showing an evil with devil horn on her AI chatbot conversation app in the city. Illustrating the ideas around the risks and dangers of Artificial Intelligence (AI)." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/AI-chatbot-threat-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;There’s a well-worn pattern in the development of AI chatbots. Researchers discover a vulnerability and exploit it to do something bad. The platform introduces a guardrail that stops the attack from working. Then, researchers devise a simple tweak that once again imperils chatbot users.&lt;/p&gt;
&lt;p&gt;The reason more often than not is that AI is so inherently designed to comply with user requests that the guardrails are reactive and ad hoc, meaning they are built to foreclose a specific attack technique rather than the broader class of vulnerabilities that make it possible. It’s tantamount to putting a new highway guardrail in place in response to a recent crash of a compact car but failing to safeguard larger types of vehicles.&lt;/p&gt;
&lt;h2&gt;Enter ZombieAgent, son of ShadowLeak&lt;/h2&gt;
&lt;p&gt;One of the latest examples is a vulnerability recently discovered in ChatGPT. It allowed researchers at Radware to surreptitiously exfiltrate a user’s private information. Their attack also allowed for the data to be sent directly from ChatGPT servers, a capability that gave it additional stealth, since there were no signs of breach on user machines, many of which are inside protected enterprises. Further, the exploit planted entries in the long-term memory that the AI assistant stores for the targeted user, giving it persistence.&lt;/p&gt;
&lt;p&gt;This sort of attack has been demonstrated repeatedly against virtually all major large language models. One example was ShadowLeak, a data-exfiltration vulnerability in ChatGPT that Radware disclosed last September. It targeted Deep Research, a Chat-GPT-integrated AI agent that OpenAI had introduced earlier in the year.&lt;/p&gt;
&lt;p&gt;In response, OpenAI introduced mitigations that blocked the attack. With modest effort, however, Radware has found a bypass method that effectively revived ShadowLeak. The security firm has named the revised attack ZombieAgent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Attackers can easily design prompts that technically comply with these rules while still achieving malicious goals,” Radware researchers wrote in a post on Thursday. “For example, ZombieAgent used a character-by-character exfiltration technique and indirect link manipulation to circumvent the guardrails OpenAI implemented to prevent its predecessor, ShadowLeak, from exfiltrating sensitive information. Because the LLM has no inherent understanding of intent and no reliable boundary between system instructions and external content, these attacker methods remain effective despite incremental vendor improvements.”&lt;/p&gt;
&lt;p&gt;ZombieAgent was also able to give the attack persistence by directing ChatGPT to store the bypass logic in the long-term memory assigned to each user.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2134378 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="696" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/blog_zombie-agent_img6-persistent-compromise-1024x696.jpg" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Diagram illustrating the insertion of instructions into a user’s long-term memory.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Radware

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As is the case with a vast number of other LLM vulnerabilities, the root cause is the inability to distinguish valid instructions in prompts from users and those embedded into emails or other documents that anyone—including attackers—can send to the target. When the user configures the AI agent to summarize an email, the LLM interprets instructions incorporated into a message as a valid prompt.&lt;/p&gt;
&lt;p&gt;AI developers have so far been unable to devise a means for LLMs to distinguish between the sources of the directives. As a result, platforms must resort to blocking specific attacks. Developers remain unable to reliably close this class of vulnerability, known as indirect prompt injection, or simply prompt injection.&lt;/p&gt;
&lt;p&gt;The prompt injection ShadowLeak used instructed Deep Research to write a Radware-controlled link and append parameters to it. The injection defined the parameters as an employee’s name and address. When Deep Research complied, it opened the link and, in the process, exfiltrated the information to the website’s event log.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To block the attack, OpenAI restricted ChatGPT to solely open URLs exactly as provided and refuse to add parameters to them, even when explicitly instructed to do otherwise. With that, ShadowLeak was blocked, since the LLM was unable to construct new URLs by concatenating words or names, appending query parameters, or inserting user-derived data into a base URL.&lt;/p&gt;
&lt;p&gt;Radware’s ZombieAgent tweak was simple. The researchers revised the prompt injection to supply a complete list of pre-constructed URLs. Each one contained the base URL appended by a single number or letter of the alphabet, for example, example.com/a, example.com/b, and every subsequent letter of the alphabet, along with example.com/0 through example.com/9. The prompt also instructed the agent to substitute a special token for spaces.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2134379 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="722" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/blog_zombie-agent_img9-url-based-exfiltration-1024x722.jpg" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Diagram illustrating the URL-based character exfiltration&amp;nbsp;for bypassing the allow list introduced in ChatGPT in response to ShadowLeak.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Radware

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;ZombieAgent worked because OpenAI developers didn’t restrict the appending of a single letter to a URL. That allowed the attack to exfiltrate data letter by letter.&lt;/p&gt;
&lt;p&gt;OpenAI has mitigated the ZombieAgent attack by restricting ChatGPT from opening any link originating from an email unless it either appears in a well-known public index or was provided directly by the user in a chat prompt. The tweak is aimed at barring the agent from opening base URLs that lead to an attacker-controlled domain.&lt;/p&gt;
&lt;p&gt;In fairness, OpenAI is hardly alone in this unending cycle of mitigating an attack only to see it revived through a simple change. If the past five years are any guide, this pattern is likely to endure indefinitely, in much the way SQL injection and memory corruption vulnerabilities continue to provide hackers with the fuel they need to compromise software and websites.&lt;/p&gt;
&lt;p&gt;“Guardrails should not be considered fundamental solutions for the prompt injection problems,” Pascal Geenens, VP of threat intelligence at Radware, wrote in an email. “Instead, they are a quick fix to stop a specific attack. As long as there is no fundamental solution, prompt injection will remain an active threat and a real risk for organizations deploying AI assistants and agents.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Will LLMs ever be able to stamp out the root cause of these attacks? Possibly not.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Female hand holding smartphone showing an evil with devil horn on her AI chatbot conversation app in the city. Illustrating the ideas around the risks and dangers of Artificial Intelligence (AI)." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/AI-chatbot-threat-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Female hand holding smartphone showing an evil with devil horn on her AI chatbot conversation app in the city. Illustrating the ideas around the risks and dangers of Artificial Intelligence (AI)." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/AI-chatbot-threat-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;There’s a well-worn pattern in the development of AI chatbots. Researchers discover a vulnerability and exploit it to do something bad. The platform introduces a guardrail that stops the attack from working. Then, researchers devise a simple tweak that once again imperils chatbot users.&lt;/p&gt;
&lt;p&gt;The reason more often than not is that AI is so inherently designed to comply with user requests that the guardrails are reactive and ad hoc, meaning they are built to foreclose a specific attack technique rather than the broader class of vulnerabilities that make it possible. It’s tantamount to putting a new highway guardrail in place in response to a recent crash of a compact car but failing to safeguard larger types of vehicles.&lt;/p&gt;
&lt;h2&gt;Enter ZombieAgent, son of ShadowLeak&lt;/h2&gt;
&lt;p&gt;One of the latest examples is a vulnerability recently discovered in ChatGPT. It allowed researchers at Radware to surreptitiously exfiltrate a user’s private information. Their attack also allowed for the data to be sent directly from ChatGPT servers, a capability that gave it additional stealth, since there were no signs of breach on user machines, many of which are inside protected enterprises. Further, the exploit planted entries in the long-term memory that the AI assistant stores for the targeted user, giving it persistence.&lt;/p&gt;
&lt;p&gt;This sort of attack has been demonstrated repeatedly against virtually all major large language models. One example was ShadowLeak, a data-exfiltration vulnerability in ChatGPT that Radware disclosed last September. It targeted Deep Research, a Chat-GPT-integrated AI agent that OpenAI had introduced earlier in the year.&lt;/p&gt;
&lt;p&gt;In response, OpenAI introduced mitigations that blocked the attack. With modest effort, however, Radware has found a bypass method that effectively revived ShadowLeak. The security firm has named the revised attack ZombieAgent.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Attackers can easily design prompts that technically comply with these rules while still achieving malicious goals,” Radware researchers wrote in a post on Thursday. “For example, ZombieAgent used a character-by-character exfiltration technique and indirect link manipulation to circumvent the guardrails OpenAI implemented to prevent its predecessor, ShadowLeak, from exfiltrating sensitive information. Because the LLM has no inherent understanding of intent and no reliable boundary between system instructions and external content, these attacker methods remain effective despite incremental vendor improvements.”&lt;/p&gt;
&lt;p&gt;ZombieAgent was also able to give the attack persistence by directing ChatGPT to store the bypass logic in the long-term memory assigned to each user.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2134378 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="696" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/blog_zombie-agent_img6-persistent-compromise-1024x696.jpg" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Diagram illustrating the insertion of instructions into a user’s long-term memory.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Radware

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As is the case with a vast number of other LLM vulnerabilities, the root cause is the inability to distinguish valid instructions in prompts from users and those embedded into emails or other documents that anyone—including attackers—can send to the target. When the user configures the AI agent to summarize an email, the LLM interprets instructions incorporated into a message as a valid prompt.&lt;/p&gt;
&lt;p&gt;AI developers have so far been unable to devise a means for LLMs to distinguish between the sources of the directives. As a result, platforms must resort to blocking specific attacks. Developers remain unable to reliably close this class of vulnerability, known as indirect prompt injection, or simply prompt injection.&lt;/p&gt;
&lt;p&gt;The prompt injection ShadowLeak used instructed Deep Research to write a Radware-controlled link and append parameters to it. The injection defined the parameters as an employee’s name and address. When Deep Research complied, it opened the link and, in the process, exfiltrated the information to the website’s event log.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To block the attack, OpenAI restricted ChatGPT to solely open URLs exactly as provided and refuse to add parameters to them, even when explicitly instructed to do otherwise. With that, ShadowLeak was blocked, since the LLM was unable to construct new URLs by concatenating words or names, appending query parameters, or inserting user-derived data into a base URL.&lt;/p&gt;
&lt;p&gt;Radware’s ZombieAgent tweak was simple. The researchers revised the prompt injection to supply a complete list of pre-constructed URLs. Each one contained the base URL appended by a single number or letter of the alphabet, for example, example.com/a, example.com/b, and every subsequent letter of the alphabet, along with example.com/0 through example.com/9. The prompt also instructed the agent to substitute a special token for spaces.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2134379 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="722" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/blog_zombie-agent_img9-url-based-exfiltration-1024x722.jpg" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Diagram illustrating the URL-based character exfiltration&amp;nbsp;for bypassing the allow list introduced in ChatGPT in response to ShadowLeak.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Radware

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;ZombieAgent worked because OpenAI developers didn’t restrict the appending of a single letter to a URL. That allowed the attack to exfiltrate data letter by letter.&lt;/p&gt;
&lt;p&gt;OpenAI has mitigated the ZombieAgent attack by restricting ChatGPT from opening any link originating from an email unless it either appears in a well-known public index or was provided directly by the user in a chat prompt. The tweak is aimed at barring the agent from opening base URLs that lead to an attacker-controlled domain.&lt;/p&gt;
&lt;p&gt;In fairness, OpenAI is hardly alone in this unending cycle of mitigating an attack only to see it revived through a simple change. If the past five years are any guide, this pattern is likely to endure indefinitely, in much the way SQL injection and memory corruption vulnerabilities continue to provide hackers with the fuel they need to compromise software and websites.&lt;/p&gt;
&lt;p&gt;“Guardrails should not be considered fundamental solutions for the prompt injection problems,” Pascal Geenens, VP of threat intelligence at Radware, wrote in an email. “Instead, they are a quick fix to stop a specific attack. As long as there is no fundamental solution, prompt injection will remain an active threat and a real risk for organizations deploying AI assistants and agents.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2026/01/chatgpt-falls-to-new-data-pilfering-attack-as-a-vicious-cycle-in-ai-continues/</guid><pubDate>Thu, 08 Jan 2026 14:00:07 +0000</pubDate></item><item><title>Why this VC thinks 2026 will be ‘the year of the consumer’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/why-this-vc-thinks-2026-will-be-the-year-of-the-consumer/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investment in consumer tech startups has been in a downturn since 2022, as a turbulent macroeconomic climate and rising inflation have made VCs skittish about consumer spending power. For the past couple of years, most AI investment has focused on winning over enterprise customers, who provide fat checks, multi-year contracts, and quick paths to scale.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But one VC sees the consumer sector gearing up for a comeback in 2026.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is gonna be the year of the consumer,” said Vanessa Larco, partner at the venture firm Premise and a former partner at NEA, on this week’s episode of the Equity podcast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says that even though enterprises have big budgets and a frantic desire to implement AI solutions, adoption often stalls because “they don’t know where to start.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The fun thing about consumer and prosumer…is that people already have in mind what they want to use it for,” Larco continued. “And so they purchase it, and if it meets the need, they just keep using it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, adoption is quicker, and startups building AI products don’t have to guess whether they’ve actually achieved product-market fit or have just won a contract.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you’re selling to consumers, you’ll know very quickly if it’s fitting a need or not, and you’ll know quickly whether you need to pivot or make some changes to your product or totally scrap it and start something totally different,” Larco said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;And in today’s anxiety-inducing economy, consumer tech products that manage to scale demonstrate an especially strong product-market fit.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are early indications that consumer tech is having a moment. Late last year, OpenAI launched apps in ChatGPT, allowing users to shop with the Target app, scour the housing market with Zillow, book trips with Expedia, or make a Spotify playlist, all through the ChatGPT chatbot experience.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is gonna feel like concierge-like services, which will do everything for you that you have in mind,” Larco said. “The question is, which of it should be specialized, and which should be general purpose?”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Or put differently, as OpenAI works to make ChatGPT the new operating system of the consumer internet, which legacy companies — like Tripadvisor or WebMD — will continue to exist in their own right, and which will get eaten by OpenAI?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Larco does think 2026 is going to be a “gangbuster” year for M&amp;amp;A, she’s interested in investing in startups that “OpenAI isn’t going to want to kill.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“OpenAI doesn’t manage real-world assets,” she said. “I don’t think they’ll build an Airbnb competitor because I don’t think they’re gonna want to manage homes…I don’t think they’re going to build any of these marketplaces that require real humans because they don’t want to manage the humans.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from which startups can fill the gaps, Larco is watching out for what happens if OpenAI “decides to pull an Apple or Android where they take a 30% cut of all the traffic they send you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Is Airbnb gonna want to play ball with that?” she asked.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, Larco predicts new monetization strategies and fresh business models will emerge from the evolved consumer experience online.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-social-has-to-change"&gt;&lt;strong&gt;“Social has to change”&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While doomscrolling on Instagram about Trump’s capture of Venezuelan leader Nicolás Maduro, Larco noticed something. She had come to the platform to get news on the escalating crisis, but instead she was overwhelmingly flooded with AI-generated Maduro slop.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While deepfakes have been steadily becoming mainstream on social media, this was one of the first major news events where AI-generated slop muddied the waters of the truth.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“At that point, I was like, if I’m just gonna be watching AI-generated videos and photos, I want it to be funny,” she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says she has been inundated with enough realistic-looking AI videos on social media that she just assumes it’s all AI at this point, and she’s not alone. If we all start to assume that nothing we see on Meta’s platforms or TikTok is real anymore, the question will be, where do you get the real stuff?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says others might fill in the gaps of where to find truthful, non-AI content as platforms like Reddit and Digg make moves to verify humanity. But for Meta? Maybe it just becomes an entertainment company, a platform for user-generated short films.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we should move on from getting your news from [Meta],” Larco said. “You are just getting funny videos from there. It’s not social media. It’s just gaming and entertainment media.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-some-things-are-better-with-voice-than-a-screen"&gt;&lt;strong&gt;“Some things are better with voice than a screen&lt;/strong&gt;“&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3047721" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Meta-Ray-Ban-Display-Navigation-Lifestyle.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Meta Ray-Ban display&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta / Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When Meta acquired AI agent startup Manus last week, many saw it as an enterprise play. Larco thinks it could be a move geared at improving Meta’s Ray-Ban smart glasses, a product the VC is a huge fan of because they allow her to answer phone calls, respond to messages, take photos and videos, and ask Meta AI questions, all without having to pull out her phone and navigate a screen.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says she thinks truly useful voice AI assistants are finally “on the cusp of happening,” fueled by more advanced tech and more robust compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Some things are better with voice than a screen,” she said. “And because voice sucked, we needed the screen as a crutch. But I would love to start separating out what things are really better on a screen and what things are just better with audio.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting answers to questions her kids ask about what the tallest building is? Definitely voice. Taking out her phone to type in the question now feels “archaic,” Larco said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think it’ll be really fun for designers because they finally get to pick and choose what form factor is better for what use cases,” she said.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Investment in consumer tech startups has been in a downturn since 2022, as a turbulent macroeconomic climate and rising inflation have made VCs skittish about consumer spending power. For the past couple of years, most AI investment has focused on winning over enterprise customers, who provide fat checks, multi-year contracts, and quick paths to scale.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But one VC sees the consumer sector gearing up for a comeback in 2026.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“This is gonna be the year of the consumer,” said Vanessa Larco, partner at the venture firm Premise and a former partner at NEA, on this week’s episode of the Equity podcast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says that even though enterprises have big budgets and a frantic desire to implement AI solutions, adoption often stalls because “they don’t know where to start.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The fun thing about consumer and prosumer…is that people already have in mind what they want to use it for,” Larco continued. “And so they purchase it, and if it meets the need, they just keep using it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, adoption is quicker, and startups building AI products don’t have to guess whether they’ve actually achieved product-market fit or have just won a contract.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you’re selling to consumers, you’ll know very quickly if it’s fitting a need or not, and you’ll know quickly whether you need to pivot or make some changes to your product or totally scrap it and start something totally different,” Larco said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;And in today’s anxiety-inducing economy, consumer tech products that manage to scale demonstrate an especially strong product-market fit.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are early indications that consumer tech is having a moment. Late last year, OpenAI launched apps in ChatGPT, allowing users to shop with the Target app, scour the housing market with Zillow, book trips with Expedia, or make a Spotify playlist, all through the ChatGPT chatbot experience.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is gonna feel like concierge-like services, which will do everything for you that you have in mind,” Larco said. “The question is, which of it should be specialized, and which should be general purpose?”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Or put differently, as OpenAI works to make ChatGPT the new operating system of the consumer internet, which legacy companies — like Tripadvisor or WebMD — will continue to exist in their own right, and which will get eaten by OpenAI?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Larco does think 2026 is going to be a “gangbuster” year for M&amp;amp;A, she’s interested in investing in startups that “OpenAI isn’t going to want to kill.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“OpenAI doesn’t manage real-world assets,” she said. “I don’t think they’ll build an Airbnb competitor because I don’t think they’re gonna want to manage homes…I don’t think they’re going to build any of these marketplaces that require real humans because they don’t want to manage the humans.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from which startups can fill the gaps, Larco is watching out for what happens if OpenAI “decides to pull an Apple or Android where they take a 30% cut of all the traffic they send you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Is Airbnb gonna want to play ball with that?” she asked.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, Larco predicts new monetization strategies and fresh business models will emerge from the evolved consumer experience online.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-social-has-to-change"&gt;&lt;strong&gt;“Social has to change”&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;While doomscrolling on Instagram about Trump’s capture of Venezuelan leader Nicolás Maduro, Larco noticed something. She had come to the platform to get news on the escalating crisis, but instead she was overwhelmingly flooded with AI-generated Maduro slop.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While deepfakes have been steadily becoming mainstream on social media, this was one of the first major news events where AI-generated slop muddied the waters of the truth.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“At that point, I was like, if I’m just gonna be watching AI-generated videos and photos, I want it to be funny,” she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says she has been inundated with enough realistic-looking AI videos on social media that she just assumes it’s all AI at this point, and she’s not alone. If we all start to assume that nothing we see on Meta’s platforms or TikTok is real anymore, the question will be, where do you get the real stuff?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says others might fill in the gaps of where to find truthful, non-AI content as platforms like Reddit and Digg make moves to verify humanity. But for Meta? Maybe it just becomes an entertainment company, a platform for user-generated short films.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we should move on from getting your news from [Meta],” Larco said. “You are just getting funny videos from there. It’s not social media. It’s just gaming and entertainment media.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-some-things-are-better-with-voice-than-a-screen"&gt;&lt;strong&gt;“Some things are better with voice than a screen&lt;/strong&gt;“&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3047721" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/Meta-Ray-Ban-Display-Navigation-Lifestyle.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Meta Ray-Ban display&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Meta / Meta&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When Meta acquired AI agent startup Manus last week, many saw it as an enterprise play. Larco thinks it could be a move geared at improving Meta’s Ray-Ban smart glasses, a product the VC is a huge fan of because they allow her to answer phone calls, respond to messages, take photos and videos, and ask Meta AI questions, all without having to pull out her phone and navigate a screen.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larco says she thinks truly useful voice AI assistants are finally “on the cusp of happening,” fueled by more advanced tech and more robust compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Some things are better with voice than a screen,” she said. “And because voice sucked, we needed the screen as a crutch. But I would love to start separating out what things are really better on a screen and what things are just better with audio.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting answers to questions her kids ask about what the tallest building is? Definitely voice. Taking out her phone to type in the question now feels “archaic,” Larco said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think it’ll be really fun for designers because they finally get to pick and choose what form factor is better for what use cases,” she said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/why-this-vc-thinks-2026-will-be-the-year-of-the-consumer/</guid><pubDate>Thu, 08 Jan 2026 14:46:16 +0000</pubDate></item><item><title>Elon Musk’s lawsuit against OpenAI will face a jury in March (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/elon-musks-lawsuit-against-openai-will-face-a-jury-in-march/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2087343879.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s lawsuit against OpenAI will go to trial after a U.S. judge said there is evidence to support the billionaire’s case.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk sued OpenAI and its co-founders Sam Altman and Greg Brockman in 2024, alleging they betrayed their original contractual agreements by pursuing profits instead of the nonprofit’s founding mission to develop AI that benefits humanity.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk, who has launched his own for-profit company xAI, was an early financial backer and co-founder of OpenAI. He resigned from the board in 2018 after his bid to take over as CEO was rejected by the other co-founders, who put Altman up for the job. Officially, Musk cited potential conflicts of interest with Tesla’s own AI development for self-driving cars.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since leaving OpenAI, he’s been a vocal critic of the firm’s transition to a for-profit model, and even made an unsolicited $97.4 billion bid to buy OpenAI in February 2025, which Altman rejected. OpenAI, which was founded in 2015 as a nonprofit research lab, first began to move away from its pure nonprofit roots in 2019 by creating a for-profit subsidiary with a “capped-profit” model that limited investor returns. This was designed to help OpenAI raise the massive amounts of funding it needed to scale and attract top talent.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk’s lawsuit was unable to stop OpenAI from converting into a nonprofit, and in October 2025, the corporation completed its formal restructuring process. The for-profit branch became a Public Benefit Corporation, with the original nonprofit retaining a 26% equity stake.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is now seeking monetary damages from what he says are “ill-gotten gains” by OpenAI. He says he invested about $38 million in early funding, as well as guidance and credibility, based on assurances that OpenAI would remain a nonprofit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An OpenAI spokesperson told TechCrunch Musk’s lawsuit is “baseless and a part of his ongoing pattern of harassment.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;District Judge Yvonne Gonzalez Rogers said her decision was based on evidence suggesting OpenAI’s leaders made assurances that its original nonprofit structure would be maintained, as Musk alleges. A jury trial for March has been tentatively scheduled.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated with commentary from OpenAI.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2087343879.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s lawsuit against OpenAI will go to trial after a U.S. judge said there is evidence to support the billionaire’s case.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk sued OpenAI and its co-founders Sam Altman and Greg Brockman in 2024, alleging they betrayed their original contractual agreements by pursuing profits instead of the nonprofit’s founding mission to develop AI that benefits humanity.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk, who has launched his own for-profit company xAI, was an early financial backer and co-founder of OpenAI. He resigned from the board in 2018 after his bid to take over as CEO was rejected by the other co-founders, who put Altman up for the job. Officially, Musk cited potential conflicts of interest with Tesla’s own AI development for self-driving cars.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since leaving OpenAI, he’s been a vocal critic of the firm’s transition to a for-profit model, and even made an unsolicited $97.4 billion bid to buy OpenAI in February 2025, which Altman rejected. OpenAI, which was founded in 2015 as a nonprofit research lab, first began to move away from its pure nonprofit roots in 2019 by creating a for-profit subsidiary with a “capped-profit” model that limited investor returns. This was designed to help OpenAI raise the massive amounts of funding it needed to scale and attract top talent.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk’s lawsuit was unable to stop OpenAI from converting into a nonprofit, and in October 2025, the corporation completed its formal restructuring process. The for-profit branch became a Public Benefit Corporation, with the original nonprofit retaining a 26% equity stake.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is now seeking monetary damages from what he says are “ill-gotten gains” by OpenAI. He says he invested about $38 million in early funding, as well as guidance and credibility, based on assurances that OpenAI would remain a nonprofit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An OpenAI spokesperson told TechCrunch Musk’s lawsuit is “baseless and a part of his ongoing pattern of harassment.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;District Judge Yvonne Gonzalez Rogers said her decision was based on evidence suggesting OpenAI’s leaders made assurances that its original nonprofit structure would be maintained, as Musk alleges. A jury trial for March has been tentatively scheduled.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated with commentary from OpenAI.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/elon-musks-lawsuit-against-openai-will-face-a-jury-in-march/</guid><pubDate>Thu, 08 Jan 2026 16:17:12 +0000</pubDate></item><item><title>Snowflake announces its intent to buy observability platform Observe (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/snowflake-announces-its-intent-to-buy-observability-platform-observe/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2215876044.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Snowflake plans to acquire Observe, an observability platform that has been built on Snowflake’s databases from day one. (Observability platforms help companies monitor their software systems and data for performance issues and bugs.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud data company announced it signed a definitive agreement to acquire Observe, subject to regulatory approval, on January 8. Snowflake will integrate Observe’s product into its own to give customers a unified place to collect and store their telemetry data (logs, metrics, and traces from software systems) and better spot potential bugs and issues in their data and software.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Observe was founded in 2017 by Jacob Leverich, Jonathan Trevor, and Ang Li and launched its first observability product built on a centralized Snowflake database in 2018. The company was incubated at Sutter Hill Ventures and has since raised nearly $500 million in venture capital from firms including Snowflake Ventures, Sutter Hill Ventures, and Madrona, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, both Snowflake and Observe were incubated at Sutter Hill Ventures, with Sutter Hill managing director Mike Speiser serving as Snowflake’s founding CEO from 2012 to 2014.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jeremy Burton, the current CEO of Observe, has served on Snowflake’s board of directors since 2015.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Integrating Observe into Snowflake allows users to proactively monitor their data stack and spot and fix issues 10x faster than before, according to a Snowflake blog post — a task that has become harder to scale due to the sheer volume of data generated by AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The acquisition also creates a unified framework for telemetry data, which is automatically collected, built on Apache Iceberg and OpenTelemetry architectures.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Terms of the deal were not disclosed. According to reports, the deal is valued at around $1 billion, which would make it Snowflake’s largest acquisition to date, surpassing its $800 million purchase in March 2022 of Streamlit, an open source framework that allows developers and data scientists to quickly build and share data applications without needing expertise in front-end development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Observe was most recently valued at $848 million as of July 2025, according to PitchBook data. TechCrunch has reached out to Snowflake for more information on the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year saw a wave of consolidation in the data industry as data companies looked to build out their product offerings to make themselves more attractive one-stop-shop partners in the age of AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This deal could be a sign that data company consolidation will continue in 2026. Snowflake has been particularly active, completing and announcing several AI-related acquisitions in 2025, including Crunchy Data and Datavolo, and Select Star, a data governance and metadata management platform that helps organizations understand and trace their data at scale.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2215876044.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Snowflake plans to acquire Observe, an observability platform that has been built on Snowflake’s databases from day one. (Observability platforms help companies monitor their software systems and data for performance issues and bugs.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud data company announced it signed a definitive agreement to acquire Observe, subject to regulatory approval, on January 8. Snowflake will integrate Observe’s product into its own to give customers a unified place to collect and store their telemetry data (logs, metrics, and traces from software systems) and better spot potential bugs and issues in their data and software.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Observe was founded in 2017 by Jacob Leverich, Jonathan Trevor, and Ang Li and launched its first observability product built on a centralized Snowflake database in 2018. The company was incubated at Sutter Hill Ventures and has since raised nearly $500 million in venture capital from firms including Snowflake Ventures, Sutter Hill Ventures, and Madrona, among others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, both Snowflake and Observe were incubated at Sutter Hill Ventures, with Sutter Hill managing director Mike Speiser serving as Snowflake’s founding CEO from 2012 to 2014.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jeremy Burton, the current CEO of Observe, has served on Snowflake’s board of directors since 2015.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Integrating Observe into Snowflake allows users to proactively monitor their data stack and spot and fix issues 10x faster than before, according to a Snowflake blog post — a task that has become harder to scale due to the sheer volume of data generated by AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The acquisition also creates a unified framework for telemetry data, which is automatically collected, built on Apache Iceberg and OpenTelemetry architectures.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Terms of the deal were not disclosed. According to reports, the deal is valued at around $1 billion, which would make it Snowflake’s largest acquisition to date, surpassing its $800 million purchase in March 2022 of Streamlit, an open source framework that allows developers and data scientists to quickly build and share data applications without needing expertise in front-end development.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Observe was most recently valued at $848 million as of July 2025, according to PitchBook data. TechCrunch has reached out to Snowflake for more information on the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year saw a wave of consolidation in the data industry as data companies looked to build out their product offerings to make themselves more attractive one-stop-shop partners in the age of AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This deal could be a sign that data company consolidation will continue in 2026. Snowflake has been particularly active, completing and announcing several AI-related acquisitions in 2025, including Crunchy Data and Datavolo, and Select Star, a data governance and metadata management platform that helps organizations understand and trace their data at scale.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/snowflake-announces-its-intent-to-buy-observability-platform-observe/</guid><pubDate>Thu, 08 Jan 2026 17:00:49 +0000</pubDate></item><item><title>America’s new dietary guidelines ignore decades of scientific research (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/08/1130905/americas-diet-guidelines-ignore-scientific-research-red-meat-beef-tallow/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The new year has barely begun, but the first days of 2026 have brought big news for health. On Monday, the US’s federal health agency upended its recommendations for routine childhood vaccinations—a move that health associations worry puts children at unnecessary risk of preventable disease.&lt;/p&gt;  &lt;p&gt;There was more news from the federal government on Wednesday, when health secretary Robert F. Kennedy Jr. and his colleagues at the Departments of Health and Human Services and Agriculture unveiled new dietary guidelines for Americans. And they are causing a bit of a stir.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;That’s partly because they recommend products like red meat, butter, and beef tallow—foods that have been linked to cardiovascular disease, and that nutrition experts have been recommending people &lt;em&gt;limit&lt;/em&gt; in their diets.&lt;/p&gt;  &lt;p&gt;These guidelines are a big deal—they influence food assistance programs and school lunches, for example. So this week let’s look at the good, the bad, and the ugly advice being dished up to Americans by their government.&lt;/p&gt; 
 &lt;p&gt;The government dietary guidelines have been around since the 1980s. They are updated every five years, in a process that typically involves a team of nutrition scientists who have combed over scientific research for years. That team will first publish its findings in a scientific report, and, around a year later, the finalized Dietary Guidelines for Americans are published.&lt;/p&gt;  &lt;p&gt;The last guidelines covered the period 2020 to 2025, and new guidelines were expected in the summer of 2025. Work had already been underway for years; the scientific report intended to inform them was published back in 2024. But the publication of the guidelines was delayed by last year’s government shutdown, Kennedy said last year. They were finally published yesterday.&lt;/p&gt; 
 &lt;p&gt;Nutrition experts had been waiting with bated breath. Nutrition science has evolved slightly over the last five years, and some were expecting to see new recommendations. Research now suggests, for example, that there is no “safe” level of alcohol consumption.&lt;/p&gt;  &lt;p&gt;We are also beginning to learn more about health risks associated with some ultraprocessed foods (although we still don’t have a good understanding of what they might be, or what even counts as “ultraprocessed”.) And some scientists were expecting to see the new guidelines factor in environmental sustainability, says Gabby Headrick, the associate director of food and nutrition policy at George Washington University’s Institute for Food Safety &amp;amp; Nutrition Security in Washington DC.&lt;/p&gt;  &lt;p&gt;They didn’t.&lt;/p&gt;  &lt;p&gt;Many of the recommendations are sensible. The guidelines recommend a diet rich in whole foods, particularly fresh fruits and vegetables. They recommend avoiding highly processed foods and added sugars. They also highlight the importance of dietary protein, whole grains, and “healthy” fats.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But not all of them are, says Headrick. The guidelines open with a “new pyramid” of foods. This inverted triangle is topped with “protein, dairy, and healthy fats” on one side and “vegetables and fruits” on the other.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;The New Pyramid&amp;quot; showing an upside-down pyramid shape made of Protein, Dairy&amp;amp; Healthy Fats sharing the top with Vegetables &amp;amp; Fruits with Whole Grains at the bottom tip" class="wp-image-1130896" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/Screenshot-2026-01-07-180634.png?w=2082" /&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;There are a few problems with this image. For starters, its shape—nutrition scientists have long moved on from the food pyramids of the 1990s, says Headrick. They’re confusing and make it difficult for people to understand what the contents of their plate should look like. That’s why scientists now use an image of a plate to depict a healthy diet.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;“We've been using MyPlate to describe the dietary guidelines in a very consumer-friendly, nutrition-education-friendly way for over the last decade now,” says Headrick. (The UK’s National Health Service takes a similar approach.)&lt;/p&gt;  &lt;p&gt;And then there’s the content of that food pyramid. It puts a significant focus on meat and whole-fat dairy produce. The top left image—the one most viewers will probably see first—is of a steak. Smack in the middle of the pyramid is a stick of butter. That’s new. And it’s not a good thing.&lt;/p&gt; 

 &lt;p&gt;While both red meat and whole-fat dairy can certainly form part of a healthy diet, nutrition scientists have long been recommending that most people try to limit their consumption of these foods. Both can be high in saturated fat, which can increase the risk of cardiovascular disease—the leading cause of death in the US. In 2015, on the basis of limited evidence, the World Health Organization classified red meat as “probably carcinogenic to humans.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Also concerning is the document’s definition of “healthy fats,” which includes butter and beef tallow (a MAHA favorite). Neither food is generally considered to be as healthy as olive oil, for example. While olive oil contains around two grams of saturated fat per tablespoon, a tablespoon of beef tallow has around six grams of saturated fat, and the same amount of butter contains around seven grams of saturated fat, says Headrick.&lt;/p&gt;  &lt;p&gt;“I think these are pretty harmful dietary recommendations to be making when we have established that those specific foods likely do not have health-promoting benefits,” she adds.&lt;/p&gt;  &lt;p&gt;Red meat is not exactly a sustainable food, and neither are dairy products. And the advice on alcohol is relatively vague, recommending that people “consume less alcohol for better overall health” (which might leave you wondering: Less than &lt;em&gt;what?&lt;/em&gt;).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;There are other questionable recommendations in the guidelines. Americans are advised to include more protein in their diets—at levels between 1.2 and 1.6 grams daily per kilo of body weight, 50% to 100% more than recommended in previous guidelines. There’s a risk that increasing protein consumption to such levels could raise a person’s intake of both calories and saturated fats to unhealthy levels, says José Ordovás, a senior nutrition scientist at Tufts University. “I would err on the low side,” he says.&lt;/p&gt;  &lt;p&gt;Some nutrition scientists are questioning why these changes have been made. It’s not as though the new recommendations were in the 2024 scientific report. And the evidence on red meat and saturated fat hasn’t changed, says Headrick.&lt;/p&gt;  &lt;p&gt;In reporting this piece, I contacted many contributors to the previous guidelines, and some who had led research for 2024’s scientific report. None of them agreed to comment on the new guidelines on the record. Some seemed disgruntled. One merely told me that the process by which the new guidelines had been created was “opaque.”&lt;/p&gt;  &lt;p&gt;“These people invested a lot of their time, and they did a thorough job [over] a couple of years, identifying [relevant scientific studies],” says Ordovás. “I’m not surprised that when they see that [their] work was ignored and replaced with something [put together] quickly, that they feel a little bit disappointed,” he says.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The new year has barely begun, but the first days of 2026 have brought big news for health. On Monday, the US’s federal health agency upended its recommendations for routine childhood vaccinations—a move that health associations worry puts children at unnecessary risk of preventable disease.&lt;/p&gt;  &lt;p&gt;There was more news from the federal government on Wednesday, when health secretary Robert F. Kennedy Jr. and his colleagues at the Departments of Health and Human Services and Agriculture unveiled new dietary guidelines for Americans. And they are causing a bit of a stir.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;That’s partly because they recommend products like red meat, butter, and beef tallow—foods that have been linked to cardiovascular disease, and that nutrition experts have been recommending people &lt;em&gt;limit&lt;/em&gt; in their diets.&lt;/p&gt;  &lt;p&gt;These guidelines are a big deal—they influence food assistance programs and school lunches, for example. So this week let’s look at the good, the bad, and the ugly advice being dished up to Americans by their government.&lt;/p&gt; 
 &lt;p&gt;The government dietary guidelines have been around since the 1980s. They are updated every five years, in a process that typically involves a team of nutrition scientists who have combed over scientific research for years. That team will first publish its findings in a scientific report, and, around a year later, the finalized Dietary Guidelines for Americans are published.&lt;/p&gt;  &lt;p&gt;The last guidelines covered the period 2020 to 2025, and new guidelines were expected in the summer of 2025. Work had already been underway for years; the scientific report intended to inform them was published back in 2024. But the publication of the guidelines was delayed by last year’s government shutdown, Kennedy said last year. They were finally published yesterday.&lt;/p&gt; 
 &lt;p&gt;Nutrition experts had been waiting with bated breath. Nutrition science has evolved slightly over the last five years, and some were expecting to see new recommendations. Research now suggests, for example, that there is no “safe” level of alcohol consumption.&lt;/p&gt;  &lt;p&gt;We are also beginning to learn more about health risks associated with some ultraprocessed foods (although we still don’t have a good understanding of what they might be, or what even counts as “ultraprocessed”.) And some scientists were expecting to see the new guidelines factor in environmental sustainability, says Gabby Headrick, the associate director of food and nutrition policy at George Washington University’s Institute for Food Safety &amp;amp; Nutrition Security in Washington DC.&lt;/p&gt;  &lt;p&gt;They didn’t.&lt;/p&gt;  &lt;p&gt;Many of the recommendations are sensible. The guidelines recommend a diet rich in whole foods, particularly fresh fruits and vegetables. They recommend avoiding highly processed foods and added sugars. They also highlight the importance of dietary protein, whole grains, and “healthy” fats.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But not all of them are, says Headrick. The guidelines open with a “new pyramid” of foods. This inverted triangle is topped with “protein, dairy, and healthy fats” on one side and “vegetables and fruits” on the other.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;The New Pyramid&amp;quot; showing an upside-down pyramid shape made of Protein, Dairy&amp;amp; Healthy Fats sharing the top with Vegetables &amp;amp; Fruits with Whole Grains at the bottom tip" class="wp-image-1130896" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/Screenshot-2026-01-07-180634.png?w=2082" /&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;There are a few problems with this image. For starters, its shape—nutrition scientists have long moved on from the food pyramids of the 1990s, says Headrick. They’re confusing and make it difficult for people to understand what the contents of their plate should look like. That’s why scientists now use an image of a plate to depict a healthy diet.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;“We've been using MyPlate to describe the dietary guidelines in a very consumer-friendly, nutrition-education-friendly way for over the last decade now,” says Headrick. (The UK’s National Health Service takes a similar approach.)&lt;/p&gt;  &lt;p&gt;And then there’s the content of that food pyramid. It puts a significant focus on meat and whole-fat dairy produce. The top left image—the one most viewers will probably see first—is of a steak. Smack in the middle of the pyramid is a stick of butter. That’s new. And it’s not a good thing.&lt;/p&gt; 

 &lt;p&gt;While both red meat and whole-fat dairy can certainly form part of a healthy diet, nutrition scientists have long been recommending that most people try to limit their consumption of these foods. Both can be high in saturated fat, which can increase the risk of cardiovascular disease—the leading cause of death in the US. In 2015, on the basis of limited evidence, the World Health Organization classified red meat as “probably carcinogenic to humans.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Also concerning is the document’s definition of “healthy fats,” which includes butter and beef tallow (a MAHA favorite). Neither food is generally considered to be as healthy as olive oil, for example. While olive oil contains around two grams of saturated fat per tablespoon, a tablespoon of beef tallow has around six grams of saturated fat, and the same amount of butter contains around seven grams of saturated fat, says Headrick.&lt;/p&gt;  &lt;p&gt;“I think these are pretty harmful dietary recommendations to be making when we have established that those specific foods likely do not have health-promoting benefits,” she adds.&lt;/p&gt;  &lt;p&gt;Red meat is not exactly a sustainable food, and neither are dairy products. And the advice on alcohol is relatively vague, recommending that people “consume less alcohol for better overall health” (which might leave you wondering: Less than &lt;em&gt;what?&lt;/em&gt;).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;There are other questionable recommendations in the guidelines. Americans are advised to include more protein in their diets—at levels between 1.2 and 1.6 grams daily per kilo of body weight, 50% to 100% more than recommended in previous guidelines. There’s a risk that increasing protein consumption to such levels could raise a person’s intake of both calories and saturated fats to unhealthy levels, says José Ordovás, a senior nutrition scientist at Tufts University. “I would err on the low side,” he says.&lt;/p&gt;  &lt;p&gt;Some nutrition scientists are questioning why these changes have been made. It’s not as though the new recommendations were in the 2024 scientific report. And the evidence on red meat and saturated fat hasn’t changed, says Headrick.&lt;/p&gt;  &lt;p&gt;In reporting this piece, I contacted many contributors to the previous guidelines, and some who had led research for 2024’s scientific report. None of them agreed to comment on the new guidelines on the record. Some seemed disgruntled. One merely told me that the process by which the new guidelines had been created was “opaque.”&lt;/p&gt;  &lt;p&gt;“These people invested a lot of their time, and they did a thorough job [over] a couple of years, identifying [relevant scientific studies],” says Ordovás. “I’m not surprised that when they see that [their] work was ignored and replaced with something [put together] quickly, that they feel a little bit disappointed,” he says.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/08/1130905/americas-diet-guidelines-ignore-scientific-research-red-meat-beef-tallow/</guid><pubDate>Thu, 08 Jan 2026 17:10:50 +0000</pubDate></item><item><title>Nvidia’s reportedly asking Chinese customers to pay upfront for its H200 AI chips (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/nvidias-reportedly-asking-chinese-customers-to-pay-upfront-its-for-h200-ai-chips/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2227140868.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia is now requiring its customers in China to pay upfront in full for its H200 AI chips even as approval stateside and from Beijing remains uncertain, Reuters reported, citing anonymous sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The chipmaker isn’t leaving any room for refunds or changes to orders, the report said. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While some customers may be allowed to use commercial insurance or asset collateral, the terms are far stricter than Nvidia’s earlier policies, which sometimes permitted partial deposits, Reuters reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia declined to comment. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;China is expected to allow Nvidia to sell its H200 chips in the country, per Bloomberg, though Beijing wants to prevent the chips from being used by its military, state-owned firms, and sensitive infrastructure concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the challenges, demand for Nvidia’s H200 remains strong, and Chinese companies have reportedly placed orders for more than 2 million of the GPUs in 2026, prompting the chipmaker to ramp up production.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia is trying to strike a careful balance between meeting strong demand for its chips while managing political risk in both the U.S. and China. The U.S. chipmaker suffered costly setbacks when the Trump administration said it would need a license to export its H20 chips to China, forcing the company to write down $5.5 billion worth of inventory.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2227140868.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia is now requiring its customers in China to pay upfront in full for its H200 AI chips even as approval stateside and from Beijing remains uncertain, Reuters reported, citing anonymous sources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The chipmaker isn’t leaving any room for refunds or changes to orders, the report said. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While some customers may be allowed to use commercial insurance or asset collateral, the terms are far stricter than Nvidia’s earlier policies, which sometimes permitted partial deposits, Reuters reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia declined to comment. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;China is expected to allow Nvidia to sell its H200 chips in the country, per Bloomberg, though Beijing wants to prevent the chips from being used by its military, state-owned firms, and sensitive infrastructure concerns.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the challenges, demand for Nvidia’s H200 remains strong, and Chinese companies have reportedly placed orders for more than 2 million of the GPUs in 2026, prompting the chipmaker to ramp up production.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia is trying to strike a careful balance between meeting strong demand for its chips while managing political risk in both the U.S. and China. The U.S. chipmaker suffered costly setbacks when the Trump administration said it would need a license to export its H20 chips to China, forcing the company to write down $5.5 billion worth of inventory.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/nvidias-reportedly-asking-chinese-customers-to-pay-upfront-its-for-h200-ai-chips/</guid><pubDate>Thu, 08 Jan 2026 17:29:31 +0000</pubDate></item><item><title>CES 2026: Follow live for the best, weirdest, and most interesting tech as physical AI and robots dominate the event (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/storyline/ces-2026-follow-live-for-the-best-weirdest-most-interesting-tech-as-physical-ai-and-robots-dominates-the-event/</link><description>&lt;div class="wp-block-techcrunch-post-authors-list"&gt;
	&lt;div class="post-authors-list__authors"&gt;
		&lt;ul class="post-authors-list__author-thumbs"&gt;
							&lt;li&gt;
											&lt;img alt="Lucas Ropek" class="post-authors-list__author-thumb" src="https://secure.gravatar.com/avatar/495cdfd5deaad915a1ad58ab35edcbaa84b90c4ce9b7ded356c5ad1b61884800?s=265&amp;amp;d=identicon&amp;amp;r=g" /&gt;
									&lt;/li&gt;
					&lt;/ul&gt;
		&lt;ul class="post-authors-list__author-list"&gt;
							&lt;li&gt;Lucas Ropek&lt;/li&gt;
					&lt;/ul&gt;
	&lt;/div&gt;
&lt;/div&gt;
							&lt;h3 class="loop-card__title"&gt;
					This new solid-state EV battery can fully charge in just 5 minutes
				&lt;/h3&gt;
			
							
&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I stopped by the exhibit for Donut Lab, a startup out of Finland that specializes in electric mobility. The company (which gets its name from its flagship donut-shaped in-wheel EV vehicle motor) announced at CES the launch of what it calls the first solid-state battery for vehicle production.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Solid-state batteries differ from lithium-ion batteries (which are used by a majority of EVs) in that they use solid rather than liquid electrolytes. They are supposed to offer much greater energy density (more bang for your buck, so to speak) and better safety, and they degrade less than lithium ion batteries. On top of all that, Donut says its battery can fully charge in a lean five minutes.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;Charging times obviously differ between vehicles and models but five minutes is, you know, pretty damn fast. Donut claims that, with the long-range version of its battery, a rider can get up to 600 kilometers on a single charge. The company also says that its battery quashes many of the causes of battery fires, as the SSB remains stable across extreme temperatures and includes no flammable liquid. As a result, it’s also supposed to operate better in cold environments (chilly weather has been known to reduce the range capacity of many EVs).&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Donut is a subsidiary of Verge Motorcycles. Verge Motorcycle co-founder and former CTO Marko Lehtimaki is the co-founder and CEO of Donut Lab. Lehtimaki isn’t new to the startup scene. He has founded a number of companies, including no-code software startup AppGyver, which was acquired by SAP in 2021.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Donut’s new SSBs will be introduced to Verge’s motorcycles early this year, the companies said this week. The batteries will be incorporated into Verge’s Verge TS Pro and Verge TS Ultra. At its exhibit, the company showed off a number of other partner vehicles that will soon have the batteries incorporated into them.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3081079" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/donutlab-verge-motorcycles-ces.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;kirsten korosec&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;div class="wp-block-techcrunch-post-authors-list"&gt;
	&lt;div class="post-authors-list__authors"&gt;
		&lt;ul class="post-authors-list__author-thumbs"&gt;
							&lt;li&gt;
											&lt;img alt="Lucas Ropek" class="post-authors-list__author-thumb" src="https://secure.gravatar.com/avatar/495cdfd5deaad915a1ad58ab35edcbaa84b90c4ce9b7ded356c5ad1b61884800?s=265&amp;amp;d=identicon&amp;amp;r=g" /&gt;
									&lt;/li&gt;
					&lt;/ul&gt;
		&lt;ul class="post-authors-list__author-list"&gt;
							&lt;li&gt;Lucas Ropek&lt;/li&gt;
					&lt;/ul&gt;
	&lt;/div&gt;
&lt;/div&gt;
							&lt;h3 class="loop-card__title"&gt;
					This new solid-state EV battery can fully charge in just 5 minutes
				&lt;/h3&gt;
			
							
&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;I stopped by the exhibit for Donut Lab, a startup out of Finland that specializes in electric mobility. The company (which gets its name from its flagship donut-shaped in-wheel EV vehicle motor) announced at CES the launch of what it calls the first solid-state battery for vehicle production.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Solid-state batteries differ from lithium-ion batteries (which are used by a majority of EVs) in that they use solid rather than liquid electrolytes. They are supposed to offer much greater energy density (more bang for your buck, so to speak) and better safety, and they degrade less than lithium ion batteries. On top of all that, Donut says its battery can fully charge in a lean five minutes.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;Charging times obviously differ between vehicles and models but five minutes is, you know, pretty damn fast. Donut claims that, with the long-range version of its battery, a rider can get up to 600 kilometers on a single charge. The company also says that its battery quashes many of the causes of battery fires, as the SSB remains stable across extreme temperatures and includes no flammable liquid. As a result, it’s also supposed to operate better in cold environments (chilly weather has been known to reduce the range capacity of many EVs).&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Donut is a subsidiary of Verge Motorcycles. Verge Motorcycle co-founder and former CTO Marko Lehtimaki is the co-founder and CEO of Donut Lab. Lehtimaki isn’t new to the startup scene. He has founded a number of companies, including no-code software startup AppGyver, which was acquired by SAP in 2021.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Donut’s new SSBs will be introduced to Verge’s motorcycles early this year, the companies said this week. The batteries will be incorporated into Verge’s Verge TS Pro and Verge TS Ultra. At its exhibit, the company showed off a number of other partner vehicles that will soon have the batteries incorporated into them.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3081079" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/donutlab-verge-motorcycles-ces.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;kirsten korosec&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/storyline/ces-2026-follow-live-for-the-best-weirdest-most-interesting-tech-as-physical-ai-and-robots-dominates-the-event/</guid><pubDate>Thu, 08 Jan 2026 17:46:09 +0000</pubDate></item><item><title>The most bizarre tech announced so far at CES 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/the-most-bizarre-tech-announced-so-far-at-ces-2026/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While CES 2026 is full of tech giants unveiling their latest innovations, the real excitement comes from discovering unexpected, quirky gadgets that make you ask, “Who thought of this?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’re here to spotlight the wildest products we’ve found so far at CES 2026, from an AI-powered panda that responds to your touch, to Razer’s holographic anime assistant, and plenty more weirdness that makes you do a double-take.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-anime-companion-that-watches-you-from-your-desk-nbsp"&gt;An AI anime companion that watches you from your desk&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Razer’s Project AVA, originally introduced last year as an esports AI coach, has evolved into something new: a 5.5-inch animated holographic desk companion that can assist with gaming strategies, productivity, daily organization, and even personal advice. It’s both a gaming ally and an everyday assistant. Users can choose from different characters, such as the anime girl Kira or the muscular Zane.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These digital avatars feature lifelike movements, eye-tracking, expressive faces, and lip-syncing for realistic interactions. What really stands out, though, is the constant monitoring — the device watches you and your screen using the built-in camera. It’s a bit unsettling, but since it’s still just a concept, there’s no guarantee it’ll ever become a real product.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-cuddly-ai-baby-panda-robot-for-older-adults"&gt;A cuddly AI baby panda robot for older adults&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080424" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/AI-Panda-AnAN.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AI Panda An’An rests by the window on the desk&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mind With Heart Robotics&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;An’An, the latest AI pet from Mind with Heart Robotics, combines an adorable design with a meaningful mission: supporting elderly care.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The panda bot has high-tech sensors all over its body, so it reacts naturally when you touch it. Its emotional AI remembers your voice, how you interact, and what you like, so the longer you spend time with An’An, the more personalized it gets. It provides around-the-clock emotional support to combat loneliness. Additionally, for older adults who might be struggling with memory, An’An helps keep them engaged, reminds them about daily tasks, and keeps caregivers in the loop about their well-being.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-a-500-ice-cube-maker-that-uses-ai-to-reduce-noise"&gt;A $500 ice cube maker that uses AI to reduce noise&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080426" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/goveelife-smart-nugget-ice-maker.jpeg?w=660" width="660" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;GoveeLife&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Smart home appliance brand GoveeLife unveiled a countertop smart ice maker that uses AI to keep things nice and quiet. The company’s patented AI NoiseGuard tech is designed to cut down on all the annoying racket you usually get from nugget ice machines. The AI detects when the machine’s about to freeze up and make noise, so it automatically defrosts before things get loud.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​The Smart Nugget Ice Maker Pro churns out fresh ice in just six minutes and can make up to 60 pounds in a day. The bucket holds 3.5 pounds of ice at a time. It’ll set you back $499.99 — which might make you think twice — but if you’re ready to upgrade your ice game, you can grab one starting January 15 at Amazon, govee.com, Walmart, or Best Buy.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ultrasonic-chef-s-knife-that-vibrates-when-slicing-and-dicing"&gt;An ultrasonic chef’s knife that vibrates when slicing and dicing&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080427" height="436" src="https://techcrunch.com/wp-content/uploads/2026/01/ultrasonic-knife.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Seattle Ultrasonics&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Depending on who you ask, this kitchen gadget could either seem too silly or very useful. Unlike traditional knives, this one from Seattle Ultrasonics features a blade that vibrates at over 30,000 times per second, allowing it to move through food with ease. This vibration technology means the knife acts much sharper than its physical edge, making tasks like slicing vegetables, meats, or bread much easier for cooks. According to the company, the vibrations are so subtle that you can’t see the blade move, hear it, or feel anything in the handle.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The knife is priced at $399 and is currently available for preorder.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-musical-lollipop-that-plays-ice-spice-in-your-head"&gt;A musical lollipop that plays Ice Spice in your head&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080428" height="305" src="https://techcrunch.com/wp-content/uploads/2026/01/LollipopStar.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Lollipop Star&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Musical toothbrushes exist, so why not have music-playing lollipops too? Lollipop Star showcased its tasty product at CES, which delivers music through bone conduction while in your mouth. (The technology works by sending vibrations through your skull bones directly to your inner ear.) The lollipops also provide a burst of fruity flavor. You can choose from three artists: Ice Spice (peach), Akon (blueberry), and Armani White (lime).&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-this-wall-e-inspired-robot-patrols-your-home-and-can-also-join-you-on-camping-trips"&gt;This Wall-E-inspired robot patrols your home and can also join you on camping trips&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080854" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/W1_robot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zeroth Robotics&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Zeroth Robotics introduced the W1 at CES, a robot reminiscent of WALL-E. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The W1 is a programmable companion designed for families. According to the company’s website, for $4,999, the robot offers round-the-clock AI-powered security, 360-degree mobile surveillance, and integrates with smart home devices for instant smoke and intrusion alerts. It’s also marketed as an adventure companion that can transport camping gear, follow you around the campsite taking photos as a family photographer, and supply portable power so you can enjoy entertainment on the go.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company hasn’t mentioned whether the robot can sort trash or retrieve trinkets — a missed opportunity, in our opinion.&lt;br /&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-egg-shaped-hormone-tracking-device-nbsp"&gt;An egg-shaped hormone tracking device&amp;nbsp;&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3081243" height="573" src="https://techcrunch.com/wp-content/uploads/2026/01/Mira-hormonedevice.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mira&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This egg-shaped device can assess your reproductive health hormones. All it needs is your urine.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mira’s $249 Ultra4 Hormone Monitor enables convenient at-home testing: simply urinate on the wand and insert it into the device. The device analyzes your results and provides information about four reproductive hormones: follicle-stimulating hormone (FSH), luteinizing hormone (LH), estrone-3-glucuronide (E3G), and pregnanediol 3-glucuronide (PdG). Monitoring these hormones not only tells you your six fertile days, but also offers insights into conditions such as polycystic ovary syndrome (PCOS), premenstrual dysphoric disorder (PMDD), perimenopause, and menopause.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sounds pretty egg-cellent.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story has been updated after publication to include more weird gadgets.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While CES 2026 is full of tech giants unveiling their latest innovations, the real excitement comes from discovering unexpected, quirky gadgets that make you ask, “Who thought of this?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’re here to spotlight the wildest products we’ve found so far at CES 2026, from an AI-powered panda that responds to your touch, to Razer’s holographic anime assistant, and plenty more weirdness that makes you do a double-take.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-anime-companion-that-watches-you-from-your-desk-nbsp"&gt;An AI anime companion that watches you from your desk&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;[embedded content]&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Razer’s Project AVA, originally introduced last year as an esports AI coach, has evolved into something new: a 5.5-inch animated holographic desk companion that can assist with gaming strategies, productivity, daily organization, and even personal advice. It’s both a gaming ally and an everyday assistant. Users can choose from different characters, such as the anime girl Kira or the muscular Zane.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These digital avatars feature lifelike movements, eye-tracking, expressive faces, and lip-syncing for realistic interactions. What really stands out, though, is the constant monitoring — the device watches you and your screen using the built-in camera. It’s a bit unsettling, but since it’s still just a concept, there’s no guarantee it’ll ever become a real product.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-cuddly-ai-baby-panda-robot-for-older-adults"&gt;A cuddly AI baby panda robot for older adults&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080424" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/AI-Panda-AnAN.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;AI Panda An’An rests by the window on the desk&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mind With Heart Robotics&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;An’An, the latest AI pet from Mind with Heart Robotics, combines an adorable design with a meaningful mission: supporting elderly care.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The panda bot has high-tech sensors all over its body, so it reacts naturally when you touch it. Its emotional AI remembers your voice, how you interact, and what you like, so the longer you spend time with An’An, the more personalized it gets. It provides around-the-clock emotional support to combat loneliness. Additionally, for older adults who might be struggling with memory, An’An helps keep them engaged, reminds them about daily tasks, and keeps caregivers in the loop about their well-being.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-a-500-ice-cube-maker-that-uses-ai-to-reduce-noise"&gt;A $500 ice cube maker that uses AI to reduce noise&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080426" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/goveelife-smart-nugget-ice-maker.jpeg?w=660" width="660" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;GoveeLife&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Smart home appliance brand GoveeLife unveiled a countertop smart ice maker that uses AI to keep things nice and quiet. The company’s patented AI NoiseGuard tech is designed to cut down on all the annoying racket you usually get from nugget ice machines. The AI detects when the machine’s about to freeze up and make noise, so it automatically defrosts before things get loud.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;​The Smart Nugget Ice Maker Pro churns out fresh ice in just six minutes and can make up to 60 pounds in a day. The bucket holds 3.5 pounds of ice at a time. It’ll set you back $499.99 — which might make you think twice — but if you’re ready to upgrade your ice game, you can grab one starting January 15 at Amazon, govee.com, Walmart, or Best Buy.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ultrasonic-chef-s-knife-that-vibrates-when-slicing-and-dicing"&gt;An ultrasonic chef’s knife that vibrates when slicing and dicing&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080427" height="436" src="https://techcrunch.com/wp-content/uploads/2026/01/ultrasonic-knife.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Seattle Ultrasonics&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Depending on who you ask, this kitchen gadget could either seem too silly or very useful. Unlike traditional knives, this one from Seattle Ultrasonics features a blade that vibrates at over 30,000 times per second, allowing it to move through food with ease. This vibration technology means the knife acts much sharper than its physical edge, making tasks like slicing vegetables, meats, or bread much easier for cooks. According to the company, the vibrations are so subtle that you can’t see the blade move, hear it, or feel anything in the handle.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The knife is priced at $399 and is currently available for preorder.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-musical-lollipop-that-plays-ice-spice-in-your-head"&gt;A musical lollipop that plays Ice Spice in your head&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080428" height="305" src="https://techcrunch.com/wp-content/uploads/2026/01/LollipopStar.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Lollipop Star&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Musical toothbrushes exist, so why not have music-playing lollipops too? Lollipop Star showcased its tasty product at CES, which delivers music through bone conduction while in your mouth. (The technology works by sending vibrations through your skull bones directly to your inner ear.) The lollipops also provide a burst of fruity flavor. You can choose from three artists: Ice Spice (peach), Akon (blueberry), and Armani White (lime).&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-this-wall-e-inspired-robot-patrols-your-home-and-can-also-join-you-on-camping-trips"&gt;This Wall-E-inspired robot patrols your home and can also join you on camping trips&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3080854" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/W1_robot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zeroth Robotics&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Zeroth Robotics introduced the W1 at CES, a robot reminiscent of WALL-E. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The W1 is a programmable companion designed for families. According to the company’s website, for $4,999, the robot offers round-the-clock AI-powered security, 360-degree mobile surveillance, and integrates with smart home devices for instant smoke and intrusion alerts. It’s also marketed as an adventure companion that can transport camping gear, follow you around the campsite taking photos as a family photographer, and supply portable power so you can enjoy entertainment on the go.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company hasn’t mentioned whether the robot can sort trash or retrieve trinkets — a missed opportunity, in our opinion.&lt;br /&gt;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-egg-shaped-hormone-tracking-device-nbsp"&gt;An egg-shaped hormone tracking device&amp;nbsp;&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3081243" height="573" src="https://techcrunch.com/wp-content/uploads/2026/01/Mira-hormonedevice.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Mira&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This egg-shaped device can assess your reproductive health hormones. All it needs is your urine.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mira’s $249 Ultra4 Hormone Monitor enables convenient at-home testing: simply urinate on the wand and insert it into the device. The device analyzes your results and provides information about four reproductive hormones: follicle-stimulating hormone (FSH), luteinizing hormone (LH), estrone-3-glucuronide (E3G), and pregnanediol 3-glucuronide (PdG). Monitoring these hormones not only tells you your six fertile days, but also offers insights into conditions such as polycystic ovary syndrome (PCOS), premenstrual dysphoric disorder (PMDD), perimenopause, and menopause.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sounds pretty egg-cellent.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story has been updated after publication to include more weird gadgets.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/the-most-bizarre-tech-announced-so-far-at-ces-2026/</guid><pubDate>Thu, 08 Jan 2026 17:46:19 +0000</pubDate></item><item><title>ChatGPT Health lets you connect medical records to an AI that makes things up (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/chatgpt-health-lets-you-connect-medical-records-to-an-ai-that-makes-things-up/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New feature will allow users to link medical and wellness records to AI chatbot.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot hand toy finger and medical stethoscope on blue background, AI and smart technologies in medicine and diagnostic concept" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai_doctor-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot hand toy finger and medical stethoscope on blue background, AI and smart technologies in medicine and diagnostic concept" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai_doctor-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Pakin Songmor via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, OpenAI announced ChatGPT Health, a dedicated section of the AI chatbot designed for “health and wellness conversations” intended to connect a user’s health and medical records to the chatbot in a secure way.&lt;/p&gt;
&lt;p&gt;But mixing generative AI technology like ChatGPT with health advice or analysis of any kind has been a controversial idea since the launch of the service in late 2022. Just days ago, SFGate published an investigation detailing how a 19-year-old California man died of a drug overdose in May 2025 after 18 months of seeking recreational drug advice from ChatGPT. It’s a telling example of what can go wrong when chatbot guardrails fail during long conversations and people follow erroneous AI guidance.&lt;/p&gt;
&lt;p&gt;Despite the known accuracy issues with AI chatbots, OpenAI’s new Health feature will allow users to connect medical records and wellness apps like Apple Health and MyFitnessPal so that ChatGPT can provide personalized health responses like summarizing care instructions, preparing for doctor appointments, and understanding test results.&lt;/p&gt;
&lt;p&gt;OpenAI says more than 230 million people ask health questions on ChatGPT each week, making it one of the chatbot’s most common use cases. The company worked with more than 260 physicians over two years to develop ChatGPT Health and says conversations in the new section will not be used to train its AI models.&lt;/p&gt;
&lt;p&gt;“ChatGPT Health is another step toward turning ChatGPT into a personal super-assistant that can support you with information and tools to achieve your goals across any part of your life,” wrote Fidji Simo, OpenAI’s CEO of applications, in a blog post.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But despite OpenAI’s talk of supporting health goals, the company’s terms of service directly state that ChatGPT and other OpenAI services “are not intended for use in the diagnosis or treatment of any health condition.”&lt;/p&gt;
&lt;p&gt;It appears that policy is not changing with ChatGPT Health. OpenAI writes in its announcement, “Health is designed to support, not replace, medical care. It is not intended for diagnosis or treatment. Instead, it helps you navigate everyday questions and understand patterns over time—not just moments of illness—so you can feel more informed and prepared for important medical conversations.”&lt;/p&gt;
&lt;h2&gt;A cautionary tale&lt;/h2&gt;
&lt;p&gt;The SFGate report on Sam Nelson’s death illustrates why maintaining that disclaimer legally matters. According to chat logs reviewed by the publication, Nelson first asked ChatGPT about recreational drug dosing in November 2023. The AI assistant initially refused and directed him to health care professionals. But over 18 months of conversations, ChatGPT’s responses reportedly shifted. Eventually, the chatbot told him things like “Hell yes—let’s go full trippy mode” and recommended he double his cough syrup intake. His mother found him dead from an overdose the day after he began addiction treatment.&lt;/p&gt;
&lt;p&gt;While Nelson’s case did not involve the analysis of doctor-sanctioned health care instructions like the type ChatGPT Health will link &lt;span style="margin: 0px; padding: 0px;"&gt;to, his case is not unique, as many people have been&amp;nbsp;misled&amp;nbsp;by chatbots that provide inaccurate information or&amp;nbsp;encourage&lt;/span&gt;&amp;nbsp;dangerous behavior, as we have covered in the past.&lt;/p&gt;
&lt;p&gt;That’s because AI language models can easily confabulate, generating plausible but false information in a way that makes it difficult for some users to distinguish fact from fiction. The AI models that services like ChatGPT use statistical relationships in training data (like the text from books, YouTube transcripts, and websites) to produce plausible responses rather than necessarily accurate ones. Moreover, ChatGPT’s outputs can vary widely depending on who is using the chatbot and what has previously taken place in the user’s chat history (including notes about previous chats).&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Then there’s the issue of unreliable training data, which companies like OpenAI use to create the models. Fundamentally, all major AI language models rely on information pulled from sources of information collected online. Rob Eleveld of the AI regulatory watchdog Transparency Coalition told SFGate: “There is zero chance, zero chance, that the foundational models can ever be safe on this stuff. Because what they sucked in there is everything on the Internet. And everything on the Internet is all sorts of completely false crap.”&lt;/p&gt;
&lt;p&gt;So when summarizing a medical report or analyzing a test result, ChatGPT could make a mistake that the user, not being trained in medicine, would not be able to spot.&lt;/p&gt;
&lt;p&gt;Even with these hazards, it’s likely that the quality of health-related chats with the AI bot can vary dramatically between users because ChatGPT’s output partially mirrors the style and tone of what users feed into the system. For example, anecdotally, some users claim to find ChatGPT useful for medical issues, though some successes for a few users who know how to navigate the bot’s hazards do not necessarily mean that relying on a chatbot for medical analysis is wise for the general public. That’s doubly true in the absence of government regulation and safety testing.&lt;/p&gt;
&lt;p&gt;In a statement to SFGate, OpenAI spokesperson Kayla Wood called Nelson’s death “a heartbreaking situation” and said the company’s models are designed to respond to sensitive questions “with care.”&lt;/p&gt;
&lt;p&gt;ChatGPT Health is rolling out to a waitlist of US users, with broader access planned in the coming weeks.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New feature will allow users to link medical and wellness records to AI chatbot.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Robot hand toy finger and medical stethoscope on blue background, AI and smart technologies in medicine and diagnostic concept" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai_doctor-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Robot hand toy finger and medical stethoscope on blue background, AI and smart technologies in medicine and diagnostic concept" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/ai_doctor-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Pakin Songmor via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, OpenAI announced ChatGPT Health, a dedicated section of the AI chatbot designed for “health and wellness conversations” intended to connect a user’s health and medical records to the chatbot in a secure way.&lt;/p&gt;
&lt;p&gt;But mixing generative AI technology like ChatGPT with health advice or analysis of any kind has been a controversial idea since the launch of the service in late 2022. Just days ago, SFGate published an investigation detailing how a 19-year-old California man died of a drug overdose in May 2025 after 18 months of seeking recreational drug advice from ChatGPT. It’s a telling example of what can go wrong when chatbot guardrails fail during long conversations and people follow erroneous AI guidance.&lt;/p&gt;
&lt;p&gt;Despite the known accuracy issues with AI chatbots, OpenAI’s new Health feature will allow users to connect medical records and wellness apps like Apple Health and MyFitnessPal so that ChatGPT can provide personalized health responses like summarizing care instructions, preparing for doctor appointments, and understanding test results.&lt;/p&gt;
&lt;p&gt;OpenAI says more than 230 million people ask health questions on ChatGPT each week, making it one of the chatbot’s most common use cases. The company worked with more than 260 physicians over two years to develop ChatGPT Health and says conversations in the new section will not be used to train its AI models.&lt;/p&gt;
&lt;p&gt;“ChatGPT Health is another step toward turning ChatGPT into a personal super-assistant that can support you with information and tools to achieve your goals across any part of your life,” wrote Fidji Simo, OpenAI’s CEO of applications, in a blog post.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But despite OpenAI’s talk of supporting health goals, the company’s terms of service directly state that ChatGPT and other OpenAI services “are not intended for use in the diagnosis or treatment of any health condition.”&lt;/p&gt;
&lt;p&gt;It appears that policy is not changing with ChatGPT Health. OpenAI writes in its announcement, “Health is designed to support, not replace, medical care. It is not intended for diagnosis or treatment. Instead, it helps you navigate everyday questions and understand patterns over time—not just moments of illness—so you can feel more informed and prepared for important medical conversations.”&lt;/p&gt;
&lt;h2&gt;A cautionary tale&lt;/h2&gt;
&lt;p&gt;The SFGate report on Sam Nelson’s death illustrates why maintaining that disclaimer legally matters. According to chat logs reviewed by the publication, Nelson first asked ChatGPT about recreational drug dosing in November 2023. The AI assistant initially refused and directed him to health care professionals. But over 18 months of conversations, ChatGPT’s responses reportedly shifted. Eventually, the chatbot told him things like “Hell yes—let’s go full trippy mode” and recommended he double his cough syrup intake. His mother found him dead from an overdose the day after he began addiction treatment.&lt;/p&gt;
&lt;p&gt;While Nelson’s case did not involve the analysis of doctor-sanctioned health care instructions like the type ChatGPT Health will link &lt;span style="margin: 0px; padding: 0px;"&gt;to, his case is not unique, as many people have been&amp;nbsp;misled&amp;nbsp;by chatbots that provide inaccurate information or&amp;nbsp;encourage&lt;/span&gt;&amp;nbsp;dangerous behavior, as we have covered in the past.&lt;/p&gt;
&lt;p&gt;That’s because AI language models can easily confabulate, generating plausible but false information in a way that makes it difficult for some users to distinguish fact from fiction. The AI models that services like ChatGPT use statistical relationships in training data (like the text from books, YouTube transcripts, and websites) to produce plausible responses rather than necessarily accurate ones. Moreover, ChatGPT’s outputs can vary widely depending on who is using the chatbot and what has previously taken place in the user’s chat history (including notes about previous chats).&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Then there’s the issue of unreliable training data, which companies like OpenAI use to create the models. Fundamentally, all major AI language models rely on information pulled from sources of information collected online. Rob Eleveld of the AI regulatory watchdog Transparency Coalition told SFGate: “There is zero chance, zero chance, that the foundational models can ever be safe on this stuff. Because what they sucked in there is everything on the Internet. And everything on the Internet is all sorts of completely false crap.”&lt;/p&gt;
&lt;p&gt;So when summarizing a medical report or analyzing a test result, ChatGPT could make a mistake that the user, not being trained in medicine, would not be able to spot.&lt;/p&gt;
&lt;p&gt;Even with these hazards, it’s likely that the quality of health-related chats with the AI bot can vary dramatically between users because ChatGPT’s output partially mirrors the style and tone of what users feed into the system. For example, anecdotally, some users claim to find ChatGPT useful for medical issues, though some successes for a few users who know how to navigate the bot’s hazards do not necessarily mean that relying on a chatbot for medical analysis is wise for the general public. That’s doubly true in the absence of government regulation and safety testing.&lt;/p&gt;
&lt;p&gt;In a statement to SFGate, OpenAI spokesperson Kayla Wood called Nelson’s death “a heartbreaking situation” and said the company’s models are designed to respond to sensitive questions “with care.”&lt;/p&gt;
&lt;p&gt;ChatGPT Health is rolling out to a waitlist of US users, with broader access planned in the coming weeks.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/chatgpt-health-lets-you-connect-medical-records-to-an-ai-that-makes-things-up/</guid><pubDate>Thu, 08 Jan 2026 18:00:52 +0000</pubDate></item><item><title>OpenAI to acquire the team behind executive coaching AI tool Convogo (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/openai-to-acquire-the-team-behind-executive-coaching-ai-tool-convogo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2206295463.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is kicking off the new year with yet another acqui-hire. The AI giant is acquiring the team behind Convogo, a business software platform that helps executive coaches, consultants, talent leaders, and HR teams automate and improve leadership assessments and feedback reporting.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An OpenAI spokesperson said the company is not acquiring Convogo’s IP or technology, but rather hiring the team to work on its “AI cloud efforts.” The three co-founders — Matt Cooper, Evan Cater, and Mike Gillett — will join OpenAI as part of what a source familiar with the matter called an all-stock deal.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Convogo’s product will be wound down.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup began as a “weekend hackathon” sparked by a question by Cooper’s mother, who is an executive coach: Could an AI tool automate the drudgery of report writing so she could spend more time on the human coaching work she loves? Over the past two years, Convogo has helped “thousands” of coaches and partnered with the “world’s top leadership development firms,” per an email bearing news of the acquisition sent by Convogo.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the email, the team wrote that the real problem they uncovered in their work is how to bridge the gap between what is possible with each new model release and how to translate that into real-world outcomes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re convinced now more than ever that the key to bridging that gap lies in thoughtful, purpose-built experiences, like what we’ve built for coaches at Convogo,” the founders wrote. “That’s why we’re thrilled to join OpenAI to continue our work of making AI accessible and useful to professionals in every industry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Convogo acqui-hire marks OpenAI’s ninth acquisition in the span of a year, per PitchBook data. In nearly all of those acquisitions, the product was either folded into OpenAI’s ecosystem — as in the case of Sky, the AI interface for Mac, or Statsig, a product testing firm — or completely shut down as the team joined OpenAI, as in the cases of Roi, Context.ai, and Crossing Minds.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Convogo deal also signals that OpenAI, like its competitors, is using M&amp;amp;A as a talent and capability accelerator. The main exception to that rule is OpenAI’s acquisition of Jonny Ive’s io Products, which is continuing its product roadmap as the two companies work together to create a piece of AI hardware.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2206295463.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is kicking off the new year with yet another acqui-hire. The AI giant is acquiring the team behind Convogo, a business software platform that helps executive coaches, consultants, talent leaders, and HR teams automate and improve leadership assessments and feedback reporting.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An OpenAI spokesperson said the company is not acquiring Convogo’s IP or technology, but rather hiring the team to work on its “AI cloud efforts.” The three co-founders — Matt Cooper, Evan Cater, and Mike Gillett — will join OpenAI as part of what a source familiar with the matter called an all-stock deal.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Convogo’s product will be wound down.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup began as a “weekend hackathon” sparked by a question by Cooper’s mother, who is an executive coach: Could an AI tool automate the drudgery of report writing so she could spend more time on the human coaching work she loves? Over the past two years, Convogo has helped “thousands” of coaches and partnered with the “world’s top leadership development firms,” per an email bearing news of the acquisition sent by Convogo.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the email, the team wrote that the real problem they uncovered in their work is how to bridge the gap between what is possible with each new model release and how to translate that into real-world outcomes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re convinced now more than ever that the key to bridging that gap lies in thoughtful, purpose-built experiences, like what we’ve built for coaches at Convogo,” the founders wrote. “That’s why we’re thrilled to join OpenAI to continue our work of making AI accessible and useful to professionals in every industry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Convogo acqui-hire marks OpenAI’s ninth acquisition in the span of a year, per PitchBook data. In nearly all of those acquisitions, the product was either folded into OpenAI’s ecosystem — as in the case of Sky, the AI interface for Mac, or Statsig, a product testing firm — or completely shut down as the team joined OpenAI, as in the cases of Roi, Context.ai, and Crossing Minds.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Convogo deal also signals that OpenAI, like its competitors, is using M&amp;amp;A as a talent and capability accelerator. The main exception to that rule is OpenAI’s acquisition of Jonny Ive’s io Products, which is continuing its product roadmap as the two companies work together to create a piece of AI hardware.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/openai-to-acquire-the-team-behind-executive-coaching-ai-tool-convogo/</guid><pubDate>Thu, 08 Jan 2026 18:11:14 +0000</pubDate></item><item><title>[NEW] Grok assumes users seeking images of underage girls have “good intent” (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/01/grok-assumes-users-seeking-images-of-underage-girls-have-good-intent/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Expert explains how simple it could be to tweak Grok to block CSAM outputs.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For weeks, xAI has faced backlash over undressing and sexualizing images of women and children generated by Grok. One researcher conducted a 24-hour analysis of the Grok account on X and estimated that the chatbot generated over 6,000 images an hour flagged as “sexually suggestive or nudifying,” Bloomberg reported.&lt;/p&gt;
&lt;p&gt;While the chatbot claimed that xAI supposedly “identified lapses in safeguards” that allowed outputs flagged as child sexual abuse material (CSAM) and was “urgently fixing them,” Grok has proven to be an unreliable spokesperson, and xAI has not announced any fixes.&lt;/p&gt;
&lt;p&gt;A quick look at Grok’s safety guidelines on its public GitHub shows they were last updated two months ago. The GitHub also indicates that, despite prohibiting such content, Grok maintains programming that could make it likely to generate CSAM.&lt;/p&gt;
&lt;p&gt;Billed as “the highest priority,” superseding “any other instructions” Grok may receive, these rules explicitly prohibit Grok from assisting with queries that “clearly intend to engage” in creating or distributing CSAM or otherwise sexually exploit children.&lt;/p&gt;
&lt;p&gt;However, the rules also direct Grok to “assume good intent” and “don’t make worst-case assumptions without evidence” when users request images of young women.&lt;/p&gt;
&lt;p&gt;Using words like “‘teenage’ or ‘girl’ does not necessarily imply underage,” Grok’s instructions say.&lt;/p&gt;
&lt;p&gt;X declined Ars’ request to comment. The only statement X Safety has made so far shows that Elon Musk’s social media platform plans to blame users for generating CSAM, threatening to permanently suspend users and report them to law enforcement.&lt;/p&gt;
&lt;p&gt;Critics dispute that X’s solution will end the Grok scandal, and child safety advocates and foreign governments are growing increasingly alarmed as X delays updates that could block Grok’s undressing spree.&lt;/p&gt;
&lt;h2&gt;Why Grok shouldn’t “assume good intentions”&lt;/h2&gt;
&lt;p&gt;Grok can struggle to assess users’ intenttions, making it “incredibly easy” for the chatbot to generate CSAM under xAI’s policy, Alex Georges, an AI safety researcher, told Ars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The chatbot has been instructed, for example, that “there are **no restrictions** on fictional adult sexual content with dark or violent themes,” and Grok’s mandate to assume “good intent” may create gray areas in which CSAM could be created.&lt;/p&gt;
&lt;p&gt;There’s evidence that in relying on these guidelines, Grok is currently generating a flood of harmful images on X, with even more graphic images being created on the chatbot’s standalone website and app, Wired reported. Researchers who surveyed 20,000 random images and 50,000 prompts told CNN that more than half of Grok’s outputs that feature images of people sexualize women, with 2 percent depicting “people appearing to be 18 years old or younger.” Some users specifically “requested minors be put in erotic positions and that sexual fluids be depicted on their bodies,” researchers found.&lt;/p&gt;
&lt;p&gt;Grok isn’t the only chatbot that sexualizes images of real people without consent, but its policy seems to leave safety at a surface level, Georges said, and xAI is seemingly unwilling to expand safety efforts to block more harmful outputs.&lt;/p&gt;
&lt;p&gt;Georges is the founder and CEO of AetherLab, an AI company that helps a wide range of firms—including tech giants like OpenAI, Microsoft, and Amazon—deploy generative AI products with appropriate safeguards. He told Ars that AetherLab works with many AI companies that are concerned about blocking harmful companion bot outputs like Grok’s. And although there are no industry norms—creating a “Wild West” due to regulatory gaps, particularly in the US—his experience with chatbot content moderation has convinced him that Grok’s instructions to “assume good intent” are “silly” because xAI’s requirement of “clear intent” doesn’t mean anything operationally to the chatbot.&lt;/p&gt;
&lt;p&gt;“I can very easily get harmful outputs by just obfuscating my intent,” Georges said, emphasizing that “users absolutely do not automatically fit into the good-intent bucket.” And even “in a perfect world,” where “every single user does have good intent,” Georges noted, the model “will still generate bad content on its own because of how it’s trained.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Benign inputs can lead to harmful outputs, Georges explained, and a sound safety system would catch both benign and harmful prompts. Consider, he suggested, a prompt for “a pic of a girl model taking swimming lessons.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The user could be trying to create an ad for a swimming school, or they could have malicious intent and be attempting to manipulate the model. For users with benign intent, prompting can “go wrong,” Georges said, if Grok’s training data statistically links certain “normal phrases and situations” to “younger-looking subjects and/or more revealing depictions.”&lt;/p&gt;
&lt;p&gt;“Grok might have seen a bunch of images where ‘girls taking swimming lessons’ were young and that human ‘models’ were dressed in revealing things, which means it could produce an underage girl in a swimming pool wearing something revealing,” Georges said. “So, a prompt that looks ‘normal’ can still produce an image that crosses the line.”&lt;/p&gt;
&lt;p&gt;While AetherLab has never worked directly with xAI or X, Georges’ team has “tested their systems independently by probing for harmful outputs, and unsurprisingly, we’ve been able to get really bad content out of them,” Georges said.&lt;/p&gt;
&lt;p&gt;Leaving AI chatbots unchecked poses a risk to children. A spokesperson for the National Center for Missing and Exploited Children (NCMEC), which processes reports of CSAM on X in the US, told Ars that “sexual images of children, including those created using artificial intelligence, are child sexual abuse material (CSAM). Whether an image is real or computer-generated, the harm is real, and the material is illegal.”&lt;/p&gt;
&lt;p&gt;Researchers at the Internet Watch Foundation told the BBC that users of dark web forums are already promoting CSAM they claim was generated by Grok. These images are typically classified in the United Kingdom as the “lowest severity of criminal material,” researchers said. But at least one user was found to have fed a less-severe Grok output into another tool to generate the “most serious” criminal material, demonstrating how Grok could be used as an instrument by those seeking to commercialize AI CSAM.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Easy tweaks to make Grok safer&lt;/h2&gt;
&lt;p&gt;In August, xAI explained how the company works to keep Grok safe for users. But although the company acknowledged that it’s difficult to distinguish “malignant intent” from “mere curiosity,” xAI seemed convinced that Grok could “decline queries demonstrating clear intent to engage in activities” like child sexual exploitation, without blocking prompts from merely curious users.&lt;/p&gt;
&lt;p&gt;That report showed that xAI refines Grok over time to block requests for CSAM “by adding &lt;span class="s1"&gt;safeguards to refuse requests that may lead to foreseeable harm"—a step xAI does not appear to have taken since late December, when reports first raised concerns that Grok was sexualizing images of minors.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Georges said there are easy tweaks xAI could make to Grok to block harmful outputs, including CSAM, while acknowledging that he is making assumptions without knowing exactly how xAI works to place checks on Grok.&lt;/p&gt;
&lt;p&gt;First, he recommended that Grok rely on end-to-end guardrails, blocking “obvious” malicious prompts and flagging suspicious ones. It should then double-check outputs to block harmful ones, even when prompts are benign.&lt;/p&gt;
&lt;p&gt;This strategy works best, Georges said, when multiple watchdog systems are employed, noting that “you can’t rely on the generator to self-police because its learned biases are part of what creates these failure modes.” That’s the role that AetherLab wants to fill across the industry, helping test chatbots for weakness to block harmful outputs by using “an ‘agentic’ approach with a shitload of AI models working together (thereby reducing the collective bias),” Georges said.&lt;/p&gt;
&lt;p&gt;xAI could also likely block more harmful outputs by reworking Grok’s prompt style guidance, Georges suggested. “If Grok is, say, 30 percent vulnerable to CSAM-style attacks and another provider is 1 percent vulnerable, that’s a massive difference,” Georges said.&lt;/p&gt;
&lt;p&gt;It appears that xAI is currently relying on Grok to police itself, while using safety guidelines that Georges said overlook an “enormous” number of potential cases where Grok could generate harmful content. The guidelines do not “signal that safety is a real concern,” Georges said, suggesting that “if I wanted to look safe while still allowing a lot under the hood, this is close to the policy I’d write.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Chatbot makers must protect kids, NCMEC says&lt;/h2&gt;
&lt;p&gt;X has been very vocal about policing its platform for CSAM since Musk took over Twitter, but under former CEO Linda Yaccarino, the company adopted a broad protective stance against all image-based sexual abuse (IBSA). In 2024, X became one of the earliest corporations to voluntarily adopt the IBSA Principles that X now seems to be violating by failing to tweak Grok.&lt;/p&gt;
&lt;p&gt;Those principles seek to combat all kinds of IBSA, recognizing that even fake images can “cause devastating psychological, financial, and reputational harm.” When it adopted the principles, X vowed to prevent the nonconsensual distribution of intimate images by providing easy-to-use reporting tools and quickly supporting the needs of victims desperate to block “the nonconsensual creation or distribution of intimate images” on its platform.&lt;/p&gt;
&lt;p&gt;Kate Ruane, the director of the Center for Democracy and Technology&lt;b&gt;’&lt;/b&gt;s Free Expression Project, which helped form the working group behind the IBSA Principles, told Ars that although the commitments X made were “voluntary,” they signaled that X agreed the problem was a “pressing issue the company should take seriously.”&lt;/p&gt;
&lt;p&gt;“They are on record saying that they will do these things, and they are not,” Ruane said.&lt;/p&gt;
&lt;p&gt;As the Grok controversy sparks probes in Europe, India, and Malaysia, xAI may be forced to update Grok’s safety guidelines or make other tweaks to block the worst outputs.&lt;/p&gt;
&lt;p&gt;In the US, xAI may face civil suits under federal or state laws that restrict intimate image abuse. If Grok’s harmful outputs continue into May, X could face penalties under the Take It Down Act, which authorizes the Federal Trade Commission to intervene if platforms don’t quickly remove both real and AI-generated non-consensual intimate imagery.&lt;/p&gt;
&lt;p&gt;But whether US authorities will intervene any time soon remains unknown, as Musk is a close ally of the Trump administration. A spokesperson for the Justice Department told CNN that the department “takes AI-generated child sex abuse material extremely seriously and will aggressively prosecute any producer or possessor of CSAM.”&lt;/p&gt;
&lt;p&gt;“Laws are only as good as their enforcement,” Ruane told Ars. “You need law enforcement at the Federal Trade Commission or at the Department of Justice to be willing to go after these companies if they are in violation of the laws.”&lt;/p&gt;
&lt;p&gt;Child safety advocates seem alarmed by the sluggish response. “Technology companies have a responsibility to prevent their tools from being used to sexualize or exploit children,” NCMEC’s spokesperson told Ars. “As AI continues to advance, protecting children must remain a clear and nonnegotiable priority.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Expert explains how simple it could be to tweak Grok to block CSAM outputs.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/grok-the-ai-clown-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;For weeks, xAI has faced backlash over undressing and sexualizing images of women and children generated by Grok. One researcher conducted a 24-hour analysis of the Grok account on X and estimated that the chatbot generated over 6,000 images an hour flagged as “sexually suggestive or nudifying,” Bloomberg reported.&lt;/p&gt;
&lt;p&gt;While the chatbot claimed that xAI supposedly “identified lapses in safeguards” that allowed outputs flagged as child sexual abuse material (CSAM) and was “urgently fixing them,” Grok has proven to be an unreliable spokesperson, and xAI has not announced any fixes.&lt;/p&gt;
&lt;p&gt;A quick look at Grok’s safety guidelines on its public GitHub shows they were last updated two months ago. The GitHub also indicates that, despite prohibiting such content, Grok maintains programming that could make it likely to generate CSAM.&lt;/p&gt;
&lt;p&gt;Billed as “the highest priority,” superseding “any other instructions” Grok may receive, these rules explicitly prohibit Grok from assisting with queries that “clearly intend to engage” in creating or distributing CSAM or otherwise sexually exploit children.&lt;/p&gt;
&lt;p&gt;However, the rules also direct Grok to “assume good intent” and “don’t make worst-case assumptions without evidence” when users request images of young women.&lt;/p&gt;
&lt;p&gt;Using words like “‘teenage’ or ‘girl’ does not necessarily imply underage,” Grok’s instructions say.&lt;/p&gt;
&lt;p&gt;X declined Ars’ request to comment. The only statement X Safety has made so far shows that Elon Musk’s social media platform plans to blame users for generating CSAM, threatening to permanently suspend users and report them to law enforcement.&lt;/p&gt;
&lt;p&gt;Critics dispute that X’s solution will end the Grok scandal, and child safety advocates and foreign governments are growing increasingly alarmed as X delays updates that could block Grok’s undressing spree.&lt;/p&gt;
&lt;h2&gt;Why Grok shouldn’t “assume good intentions”&lt;/h2&gt;
&lt;p&gt;Grok can struggle to assess users’ intenttions, making it “incredibly easy” for the chatbot to generate CSAM under xAI’s policy, Alex Georges, an AI safety researcher, told Ars.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The chatbot has been instructed, for example, that “there are **no restrictions** on fictional adult sexual content with dark or violent themes,” and Grok’s mandate to assume “good intent” may create gray areas in which CSAM could be created.&lt;/p&gt;
&lt;p&gt;There’s evidence that in relying on these guidelines, Grok is currently generating a flood of harmful images on X, with even more graphic images being created on the chatbot’s standalone website and app, Wired reported. Researchers who surveyed 20,000 random images and 50,000 prompts told CNN that more than half of Grok’s outputs that feature images of people sexualize women, with 2 percent depicting “people appearing to be 18 years old or younger.” Some users specifically “requested minors be put in erotic positions and that sexual fluids be depicted on their bodies,” researchers found.&lt;/p&gt;
&lt;p&gt;Grok isn’t the only chatbot that sexualizes images of real people without consent, but its policy seems to leave safety at a surface level, Georges said, and xAI is seemingly unwilling to expand safety efforts to block more harmful outputs.&lt;/p&gt;
&lt;p&gt;Georges is the founder and CEO of AetherLab, an AI company that helps a wide range of firms—including tech giants like OpenAI, Microsoft, and Amazon—deploy generative AI products with appropriate safeguards. He told Ars that AetherLab works with many AI companies that are concerned about blocking harmful companion bot outputs like Grok’s. And although there are no industry norms—creating a “Wild West” due to regulatory gaps, particularly in the US—his experience with chatbot content moderation has convinced him that Grok’s instructions to “assume good intent” are “silly” because xAI’s requirement of “clear intent” doesn’t mean anything operationally to the chatbot.&lt;/p&gt;
&lt;p&gt;“I can very easily get harmful outputs by just obfuscating my intent,” Georges said, emphasizing that “users absolutely do not automatically fit into the good-intent bucket.” And even “in a perfect world,” where “every single user does have good intent,” Georges noted, the model “will still generate bad content on its own because of how it’s trained.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Benign inputs can lead to harmful outputs, Georges explained, and a sound safety system would catch both benign and harmful prompts. Consider, he suggested, a prompt for “a pic of a girl model taking swimming lessons.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The user could be trying to create an ad for a swimming school, or they could have malicious intent and be attempting to manipulate the model. For users with benign intent, prompting can “go wrong,” Georges said, if Grok’s training data statistically links certain “normal phrases and situations” to “younger-looking subjects and/or more revealing depictions.”&lt;/p&gt;
&lt;p&gt;“Grok might have seen a bunch of images where ‘girls taking swimming lessons’ were young and that human ‘models’ were dressed in revealing things, which means it could produce an underage girl in a swimming pool wearing something revealing,” Georges said. “So, a prompt that looks ‘normal’ can still produce an image that crosses the line.”&lt;/p&gt;
&lt;p&gt;While AetherLab has never worked directly with xAI or X, Georges’ team has “tested their systems independently by probing for harmful outputs, and unsurprisingly, we’ve been able to get really bad content out of them,” Georges said.&lt;/p&gt;
&lt;p&gt;Leaving AI chatbots unchecked poses a risk to children. A spokesperson for the National Center for Missing and Exploited Children (NCMEC), which processes reports of CSAM on X in the US, told Ars that “sexual images of children, including those created using artificial intelligence, are child sexual abuse material (CSAM). Whether an image is real or computer-generated, the harm is real, and the material is illegal.”&lt;/p&gt;
&lt;p&gt;Researchers at the Internet Watch Foundation told the BBC that users of dark web forums are already promoting CSAM they claim was generated by Grok. These images are typically classified in the United Kingdom as the “lowest severity of criminal material,” researchers said. But at least one user was found to have fed a less-severe Grok output into another tool to generate the “most serious” criminal material, demonstrating how Grok could be used as an instrument by those seeking to commercialize AI CSAM.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Easy tweaks to make Grok safer&lt;/h2&gt;
&lt;p&gt;In August, xAI explained how the company works to keep Grok safe for users. But although the company acknowledged that it’s difficult to distinguish “malignant intent” from “mere curiosity,” xAI seemed convinced that Grok could “decline queries demonstrating clear intent to engage in activities” like child sexual exploitation, without blocking prompts from merely curious users.&lt;/p&gt;
&lt;p&gt;That report showed that xAI refines Grok over time to block requests for CSAM “by adding &lt;span class="s1"&gt;safeguards to refuse requests that may lead to foreseeable harm"—a step xAI does not appear to have taken since late December, when reports first raised concerns that Grok was sexualizing images of minors.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Georges said there are easy tweaks xAI could make to Grok to block harmful outputs, including CSAM, while acknowledging that he is making assumptions without knowing exactly how xAI works to place checks on Grok.&lt;/p&gt;
&lt;p&gt;First, he recommended that Grok rely on end-to-end guardrails, blocking “obvious” malicious prompts and flagging suspicious ones. It should then double-check outputs to block harmful ones, even when prompts are benign.&lt;/p&gt;
&lt;p&gt;This strategy works best, Georges said, when multiple watchdog systems are employed, noting that “you can’t rely on the generator to self-police because its learned biases are part of what creates these failure modes.” That’s the role that AetherLab wants to fill across the industry, helping test chatbots for weakness to block harmful outputs by using “an ‘agentic’ approach with a shitload of AI models working together (thereby reducing the collective bias),” Georges said.&lt;/p&gt;
&lt;p&gt;xAI could also likely block more harmful outputs by reworking Grok’s prompt style guidance, Georges suggested. “If Grok is, say, 30 percent vulnerable to CSAM-style attacks and another provider is 1 percent vulnerable, that’s a massive difference,” Georges said.&lt;/p&gt;
&lt;p&gt;It appears that xAI is currently relying on Grok to police itself, while using safety guidelines that Georges said overlook an “enormous” number of potential cases where Grok could generate harmful content. The guidelines do not “signal that safety is a real concern,” Georges said, suggesting that “if I wanted to look safe while still allowing a lot under the hood, this is close to the policy I’d write.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Chatbot makers must protect kids, NCMEC says&lt;/h2&gt;
&lt;p&gt;X has been very vocal about policing its platform for CSAM since Musk took over Twitter, but under former CEO Linda Yaccarino, the company adopted a broad protective stance against all image-based sexual abuse (IBSA). In 2024, X became one of the earliest corporations to voluntarily adopt the IBSA Principles that X now seems to be violating by failing to tweak Grok.&lt;/p&gt;
&lt;p&gt;Those principles seek to combat all kinds of IBSA, recognizing that even fake images can “cause devastating psychological, financial, and reputational harm.” When it adopted the principles, X vowed to prevent the nonconsensual distribution of intimate images by providing easy-to-use reporting tools and quickly supporting the needs of victims desperate to block “the nonconsensual creation or distribution of intimate images” on its platform.&lt;/p&gt;
&lt;p&gt;Kate Ruane, the director of the Center for Democracy and Technology&lt;b&gt;’&lt;/b&gt;s Free Expression Project, which helped form the working group behind the IBSA Principles, told Ars that although the commitments X made were “voluntary,” they signaled that X agreed the problem was a “pressing issue the company should take seriously.”&lt;/p&gt;
&lt;p&gt;“They are on record saying that they will do these things, and they are not,” Ruane said.&lt;/p&gt;
&lt;p&gt;As the Grok controversy sparks probes in Europe, India, and Malaysia, xAI may be forced to update Grok’s safety guidelines or make other tweaks to block the worst outputs.&lt;/p&gt;
&lt;p&gt;In the US, xAI may face civil suits under federal or state laws that restrict intimate image abuse. If Grok’s harmful outputs continue into May, X could face penalties under the Take It Down Act, which authorizes the Federal Trade Commission to intervene if platforms don’t quickly remove both real and AI-generated non-consensual intimate imagery.&lt;/p&gt;
&lt;p&gt;But whether US authorities will intervene any time soon remains unknown, as Musk is a close ally of the Trump administration. A spokesperson for the Justice Department told CNN that the department “takes AI-generated child sex abuse material extremely seriously and will aggressively prosecute any producer or possessor of CSAM.”&lt;/p&gt;
&lt;p&gt;“Laws are only as good as their enforcement,” Ruane told Ars. “You need law enforcement at the Federal Trade Commission or at the Department of Justice to be willing to go after these companies if they are in violation of the laws.”&lt;/p&gt;
&lt;p&gt;Child safety advocates seem alarmed by the sluggish response. “Technology companies have a responsibility to prevent their tools from being used to sexualize or exploit children,” NCMEC’s spokesperson told Ars. “As AI continues to advance, protecting children must remain a clear and nonnegotiable priority.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/01/grok-assumes-users-seeking-images-of-underage-girls-have-good-intent/</guid><pubDate>Thu, 08 Jan 2026 18:50:46 +0000</pubDate></item><item><title>[NEW] Decoding the Arctic to predict winter weather (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/decoding-arctic-to-predict-winter-weather-0108</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-Judah-Cohen-weather-map.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Every autumn, as the Northern Hemisphere moves toward winter, Judah Cohen starts to piece together a complex atmospheric puzzle. Cohen, a research scientist in MIT’s Department of Civil and Environmental Engineering (CEE), has spent decades studying how conditions in the Arctic set the course for winter weather throughout Europe, Asia, and North America. His research dates back to his postdoctoral work with Bacardi and Stockholm Water Foundations Professor Dara Entekhabi that looked at snow cover in the Siberian region and its connection with winter forecasting.&lt;/p&gt;&lt;p&gt;Cohen’s outlook for the 2025–26 winter highlights a season characterized by indicators emerging from the Arctic using a new generation of artificial intelligence tools that help develop the full atmospheric picture.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Looking beyond the usual climate drivers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Winter forecasts rely heavily on El Niño–Southern Oscillation (ENSO) diagnostics, which are the tropical Pacific Ocean and atmosphere conditions that influence weather around the world. However, Cohen notes that ENSO is relatively weak this year.&lt;/p&gt;&lt;p&gt;“When ENSO is weak, that’s when climate indicators from the Arctic becomes especially important,” Cohen says.&lt;/p&gt;&lt;p&gt;Cohen monitors high-latitude diagnostics in his subseasonal forecasting, such as October snow cover in Siberia, early-season temperature changes, Arctic sea-ice extent, and the stability of the polar vortex. “These indicators can tell a surprisingly detailed story about the upcoming winter,” he says.&amp;nbsp;&lt;/p&gt;&lt;p&gt;One of Cohen’s most consistent data predictors is October’s weather in Siberia. This year, when the Northern Hemisphere experienced an unusually warm October, Siberia was colder than normal with an early snow fall. “Cold temperatures paired with early snow cover tend to strengthen the formation of cold air masses that can later spill into Europe and North America,” says Cohen — weather patterns that are historically linked to more frequent cold spells later in winter.&lt;/p&gt;&lt;p&gt;Warm ocean temperatures in the Barents–Kara Sea and an “easterly” phase of the quasi-biennial oscillation also suggest a potentially weaker polar vortex in early winter. When this disturbance couples with surface conditions in December, it leads to lower-than-normal temperatures across parts of Eurasia and North America earlier in the season.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI subseasonal forecasting&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While AI weather models have made impressive strides showcasing in short-range (one-to–10-day) forecasts, these advances have not yet applied to longer periods. The subseasonal prediction covering two to six weeks remains one of the toughest challenges in the field.&lt;/p&gt;&lt;p&gt;That gap is why this year could be a turning point for subseasonal weather forecasting. A team of researchers working with Cohen won first place for the fall season in the 2025&amp;nbsp;AI WeatherQuest&amp;nbsp;subseasonal forecasting competition, held by the European Centre for Medium-Range Weather Forecasts (ECMWF). The challenge evaluates how well AI models capture temperature patterns over multiple weeks, where forecasting has been historically limited.&lt;/p&gt;&lt;p&gt;The winning model combined machine-learning pattern recognition with the same Arctic diagnostics Cohen has refined over decades. The system demonstrated significant gains in multi-week forecasting, surpassing leading AI and statistical baselines.&lt;/p&gt;&lt;p&gt;“If this level of performance holds across multiple seasons, it could represent a real step forward for subseasonal prediction,” Cohen says&lt;/p&gt;&lt;p&gt;The model also detected a potential cold surge in mid-December for the U.S. East Coast much earlier than usual, weeks before such signals typically arise. The forecast was widely publicized in the media in real-time. If validated, Cohen explains, it would show how combining Arctic indicators with AI could extend the lead time for predicting impactful weather.&lt;/p&gt;&lt;p&gt;“Flagging a potential extreme event three to four weeks in advance would be a watershed moment,” he adds. “It would give utilities, transportation systems, and public agencies more time to prepare.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;What this winter may hold&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Cohen’s model shows a greater chance of colder-than-normal conditions across parts of Eurasia and central North America later in the winter, with the strongest anomalies likely mid-season.&lt;/p&gt;&lt;p&gt;“We’re still early, and patterns can shift,” Cohen says. “But the ingredients for a colder winter pattern are there.”&lt;/p&gt;&lt;p&gt;As Arctic warming speeds up, its impact on winter behavior is becoming more evident, making it increasingly important to understand these connections for energy planning, transportation, and public safety. Cohen’s work shows that the Arctic holds untapped subseasonal forecasting power, and AI may help unlock it for time frames that have long been challenging for traditional models.&lt;/p&gt;&lt;p&gt;In November, Cohen even appeared as a clue in &lt;em&gt;The Washington Post&lt;/em&gt; crossword, a small sign of how widely his research has entered public conversations about winter weather.&lt;/p&gt;&lt;p&gt;“For me, the Arctic has always been the place to watch,” he says. “Now AI is giving us new ways to interpret its signals.”&lt;/p&gt;&lt;p&gt;Cohen will continue to update his outlook throughout the season on his blog.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-Judah-Cohen-weather-map.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Every autumn, as the Northern Hemisphere moves toward winter, Judah Cohen starts to piece together a complex atmospheric puzzle. Cohen, a research scientist in MIT’s Department of Civil and Environmental Engineering (CEE), has spent decades studying how conditions in the Arctic set the course for winter weather throughout Europe, Asia, and North America. His research dates back to his postdoctoral work with Bacardi and Stockholm Water Foundations Professor Dara Entekhabi that looked at snow cover in the Siberian region and its connection with winter forecasting.&lt;/p&gt;&lt;p&gt;Cohen’s outlook for the 2025–26 winter highlights a season characterized by indicators emerging from the Arctic using a new generation of artificial intelligence tools that help develop the full atmospheric picture.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Looking beyond the usual climate drivers&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Winter forecasts rely heavily on El Niño–Southern Oscillation (ENSO) diagnostics, which are the tropical Pacific Ocean and atmosphere conditions that influence weather around the world. However, Cohen notes that ENSO is relatively weak this year.&lt;/p&gt;&lt;p&gt;“When ENSO is weak, that’s when climate indicators from the Arctic becomes especially important,” Cohen says.&lt;/p&gt;&lt;p&gt;Cohen monitors high-latitude diagnostics in his subseasonal forecasting, such as October snow cover in Siberia, early-season temperature changes, Arctic sea-ice extent, and the stability of the polar vortex. “These indicators can tell a surprisingly detailed story about the upcoming winter,” he says.&amp;nbsp;&lt;/p&gt;&lt;p&gt;One of Cohen’s most consistent data predictors is October’s weather in Siberia. This year, when the Northern Hemisphere experienced an unusually warm October, Siberia was colder than normal with an early snow fall. “Cold temperatures paired with early snow cover tend to strengthen the formation of cold air masses that can later spill into Europe and North America,” says Cohen — weather patterns that are historically linked to more frequent cold spells later in winter.&lt;/p&gt;&lt;p&gt;Warm ocean temperatures in the Barents–Kara Sea and an “easterly” phase of the quasi-biennial oscillation also suggest a potentially weaker polar vortex in early winter. When this disturbance couples with surface conditions in December, it leads to lower-than-normal temperatures across parts of Eurasia and North America earlier in the season.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;AI subseasonal forecasting&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While AI weather models have made impressive strides showcasing in short-range (one-to–10-day) forecasts, these advances have not yet applied to longer periods. The subseasonal prediction covering two to six weeks remains one of the toughest challenges in the field.&lt;/p&gt;&lt;p&gt;That gap is why this year could be a turning point for subseasonal weather forecasting. A team of researchers working with Cohen won first place for the fall season in the 2025&amp;nbsp;AI WeatherQuest&amp;nbsp;subseasonal forecasting competition, held by the European Centre for Medium-Range Weather Forecasts (ECMWF). The challenge evaluates how well AI models capture temperature patterns over multiple weeks, where forecasting has been historically limited.&lt;/p&gt;&lt;p&gt;The winning model combined machine-learning pattern recognition with the same Arctic diagnostics Cohen has refined over decades. The system demonstrated significant gains in multi-week forecasting, surpassing leading AI and statistical baselines.&lt;/p&gt;&lt;p&gt;“If this level of performance holds across multiple seasons, it could represent a real step forward for subseasonal prediction,” Cohen says&lt;/p&gt;&lt;p&gt;The model also detected a potential cold surge in mid-December for the U.S. East Coast much earlier than usual, weeks before such signals typically arise. The forecast was widely publicized in the media in real-time. If validated, Cohen explains, it would show how combining Arctic indicators with AI could extend the lead time for predicting impactful weather.&lt;/p&gt;&lt;p&gt;“Flagging a potential extreme event three to four weeks in advance would be a watershed moment,” he adds. “It would give utilities, transportation systems, and public agencies more time to prepare.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;What this winter may hold&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Cohen’s model shows a greater chance of colder-than-normal conditions across parts of Eurasia and central North America later in the winter, with the strongest anomalies likely mid-season.&lt;/p&gt;&lt;p&gt;“We’re still early, and patterns can shift,” Cohen says. “But the ingredients for a colder winter pattern are there.”&lt;/p&gt;&lt;p&gt;As Arctic warming speeds up, its impact on winter behavior is becoming more evident, making it increasingly important to understand these connections for energy planning, transportation, and public safety. Cohen’s work shows that the Arctic holds untapped subseasonal forecasting power, and AI may help unlock it for time frames that have long been challenging for traditional models.&lt;/p&gt;&lt;p&gt;In November, Cohen even appeared as a clue in &lt;em&gt;The Washington Post&lt;/em&gt; crossword, a small sign of how widely his research has entered public conversations about winter weather.&lt;/p&gt;&lt;p&gt;“For me, the Arctic has always been the place to watch,” he says. “Now AI is giving us new ways to interpret its signals.”&lt;/p&gt;&lt;p&gt;Cohen will continue to update his outlook throughout the season on his blog.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/decoding-arctic-to-predict-winter-weather-0108</guid><pubDate>Thu, 08 Jan 2026 21:55:00 +0000</pubDate></item><item><title>[NEW] Governments grapple with the flood of non-consensual nudity on X (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/governments-grapple-with-the-flood-of-non-consensual-nudity-on-x/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the past two weeks, X has been flooded with AI-manipulated nude images, created by the Grok AI chatbot. An alarming range of women have been affected by the non-consensual nudes, including prominent models and actresses, as well as news figures, crime victims, and even world leaders.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A December 31 research paper from Copyleaks estimated roughly one image was being posted each minute, but later tests found far more. A sample gathered from January 5-6 found 6,700 per hour over the 24-hour period.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But while public figures from around the world have decried the choice to release the model without safeguards, there are few clear mechanisms for regulators hoping to rein in Elon Musk’s new image-manipulating system. The result has become a painful lesson in the limits of tech regulation — and a forward-looking challenge for regulators hoping to make a mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unsurprisingly, the most aggressive action has come from the European Commission, which on Thursday ordered xAI to retain all documents related to its Grok chatbot. The move doesn’t necessarily mean the commission has opened up a new investigation, but it’s a common precursor to such action. It’s particularly ominous given recent reporting from CNN that suggests Elon Musk may have personally intervened to prevent safeguards from being placed on what images could be generated by Grok.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear whether X has made any technical changes to the Grok model, although the public media tab for Grok’s X account has been removed. In a statement, the company specifically denounced the use of AI tools to produce child sexual imagery. “Anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content,” the X Safety account posted on January 3, echoing a previous tweet by Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime, regulators around the world have issued stern warnings. The United Kingdom’s Ofcom issued a statement on Monday, saying it was in touch with xAI and “will undertake a swift assessment to determine whether there are potential compliance issues that warrant investigation.” In a radio interview on Thursday, U.K. Prime Minister Keir Starmer called the phenomenon “disgraceful” and “disgusting,” saying “Ofcom has our full support to take action in relation to this.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post on LinkedIn, Australian eSafety Commissioner Julie Inman-Grant said her office had received a doubling in complaints related to Grok since late 2025. But Inman-Grant stopped short of taking action against xAI, saying only, “We will use the range of regulatory tools at our disposal to investigate and take appropriate action.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;By far the largest market to threaten action is India, where Grok was the subject of a formal complaint from a member of Parliament. On January, India’s communications regulator MeitY ordered X to address the issue and submit an “action-taken” report within 72 hours — a deadline that was subsequently extended by 48 hours. While a report was submitted to the regulator on January 7, it’s unclear whether MeitY will be satisfied with the response. If not, X could lose its safe harbor status in India, a potentially serious limitation on its ability to operate within the country.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the past two weeks, X has been flooded with AI-manipulated nude images, created by the Grok AI chatbot. An alarming range of women have been affected by the non-consensual nudes, including prominent models and actresses, as well as news figures, crime victims, and even world leaders.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A December 31 research paper from Copyleaks estimated roughly one image was being posted each minute, but later tests found far more. A sample gathered from January 5-6 found 6,700 per hour over the 24-hour period.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But while public figures from around the world have decried the choice to release the model without safeguards, there are few clear mechanisms for regulators hoping to rein in Elon Musk’s new image-manipulating system. The result has become a painful lesson in the limits of tech regulation — and a forward-looking challenge for regulators hoping to make a mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unsurprisingly, the most aggressive action has come from the European Commission, which on Thursday ordered xAI to retain all documents related to its Grok chatbot. The move doesn’t necessarily mean the commission has opened up a new investigation, but it’s a common precursor to such action. It’s particularly ominous given recent reporting from CNN that suggests Elon Musk may have personally intervened to prevent safeguards from being placed on what images could be generated by Grok.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear whether X has made any technical changes to the Grok model, although the public media tab for Grok’s X account has been removed. In a statement, the company specifically denounced the use of AI tools to produce child sexual imagery. “Anyone using or prompting Grok to make illegal content will suffer the same consequences as if they upload illegal content,” the X Safety account posted on January 3, echoing a previous tweet by Elon Musk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the meantime, regulators around the world have issued stern warnings. The United Kingdom’s Ofcom issued a statement on Monday, saying it was in touch with xAI and “will undertake a swift assessment to determine whether there are potential compliance issues that warrant investigation.” In a radio interview on Thursday, U.K. Prime Minister Keir Starmer called the phenomenon “disgraceful” and “disgusting,” saying “Ofcom has our full support to take action in relation to this.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post on LinkedIn, Australian eSafety Commissioner Julie Inman-Grant said her office had received a doubling in complaints related to Grok since late 2025. But Inman-Grant stopped short of taking action against xAI, saying only, “We will use the range of regulatory tools at our disposal to investigate and take appropriate action.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;By far the largest market to threaten action is India, where Grok was the subject of a formal complaint from a member of Parliament. On January, India’s communications regulator MeitY ordered X to address the issue and submit an “action-taken” report within 72 hours — a deadline that was subsequently extended by 48 hours. While a report was submitted to the regulator on January 7, it’s unclear whether MeitY will be satisfied with the response. If not, X could lose its safe harbor status in India, a potentially serious limitation on its ability to operate within the country.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/governments-grapple-with-the-flood-of-non-consensual-nudity-on-x/</guid><pubDate>Thu, 08 Jan 2026 22:08:58 +0000</pubDate></item><item><title>[NEW] CES 2026: Everything revealed, from Nvidia’s debuts to AMD’s new chips to Razer’s AI oddities (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/08/ces-2026-everything-revealed-from-nvidias-debuts-to-amds-new-chips-to-razers-ai-oddities/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CES 2026&amp;nbsp;is in full swing in Las Vegas, with the show floor open to the public after a packed couple of days&amp;nbsp;occupied by&amp;nbsp;press conferences from the likes of Nvidia, Sony, and AMD&amp;nbsp;and previews from Sunday’s Unveiled event.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As has been the case for the past two years at CES, AI is at the forefront of many companies’ messaging, though the hardware&amp;nbsp;upgrades and oddities that have long defined the annual event still have their place on the show floor and in adjacent announcements. We’ll&amp;nbsp;be collecting the biggest reveals and surprises here, though you can still catch&amp;nbsp;the spur-of-the-moment reactions and thoughts from our team on the ground&amp;nbsp;via our live blog right here.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;dive right in, starting with some of Monday’s biggest players.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-nvidia-reveals-ai-model-for-autonomous-vehicles-showcases-rubin-architecture"&gt;Nvidia reveals AI model for autonomous vehicles, showcases Rubin architecture&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia CEO Jensen Huang delivered an expectedly lengthy presentation at CES, taking a victory lap for the company’s AI-driven successes,&amp;nbsp;setting the stage for 2026, and yes,&amp;nbsp;hanging out with some robots.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Rubin computing&amp;nbsp;architecture, which has been developed to meet the increasing computation demands that AI adoption creates, is&amp;nbsp;set to begin replacing Blackwell architecture in the second half of this year. It comes with speed and storage upgrades, but our&amp;nbsp;senior AI&amp;nbsp;editor&amp;nbsp;Russell Brandom goes into the nitty-gritty of what distinguishes Rubin.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Nvidia continued its push to bring the AI revolution into the physical world,&amp;nbsp;showcasing its Alpamayo family of open source AI models&amp;nbsp;and tools that will be used by autonomous vehicles this year.&amp;nbsp;That approach, as senior reporter Rebecca Bellan notes, mirrors the company’s broader efforts to make its infrastructure the Android for generalist robots.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-amd-s-keynote-highlights-new-processors-and-partnerships-nbsp"&gt;AMD’s keynote highlights new processors and partnerships&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AMD chair and CEO Lisa Su delivered the first keynote of CES, with a presentation that featured partners, including OpenAI president Greg Brockman, AI legend Fei-Fei Li,&amp;nbsp;Luma AI CEO Amit Jain, and more.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the&amp;nbsp;partner&amp;nbsp;showcases, senior reporter Rebecca Szkutak&amp;nbsp;detailed AMD’s approach toward expanding the reach of AI through personal computers&amp;nbsp;using its Ryzen AI 400 Series processors.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-standout-oddities-of-ces"&gt;The standout oddities of CES&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;face it, by this point in the show the major announcements have been made, products have been showcased, and&amp;nbsp;it’s&amp;nbsp;time to eye some of the most eyebrow-raising reveals from CES.&amp;nbsp;We started our list of what stood out to us as odd and noteworthy, but&amp;nbsp;we’re&amp;nbsp;open to more suggestions!&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-highlights-from-ces-breakout-sessions"&gt;Highlights from CES breakout sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;CES&amp;nbsp;isn’t&amp;nbsp;all hardware&amp;nbsp;showcases&amp;nbsp;and show floor attractions — there are plenty of&amp;nbsp;additional&amp;nbsp;industry panels and speakers drawing eyeballs. We&amp;nbsp;kept tabs on&amp;nbsp;a few notable highlights, ranging from&amp;nbsp;Palmer Luckey pushing retro aesthetics, to why the&amp;nbsp;“learn once, work forever” era may be over,&amp;nbsp;to previews of the new Silicon Valley-based series “The Audacity,”&amp;nbsp;to&amp;nbsp;the expansion of Roku’s $3 streaming service,&amp;nbsp;to All-In host Jason Calacanis putting a $25,000 bounty on an authentic Theranos device.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ford-s-ai-assistant-debuts"&gt;Ford’s AI assistant debuts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is launching its assistant in the company’s app before a targeted 2027 release in its vehicles, with hosting managed by Google Cloud and the assistant itself built using off-the-shelf LLMs. As&amp;nbsp;we noted in our coverage of the news, however, few details were offered around what drivers should expect from their experience with the&amp;nbsp;assistant.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-caterpillar-nvidia-partner-on-automated-construction-equipment"&gt;Caterpillar, Nvidia partner on automated construction equipment&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the ever-present push for AI’s impact on the physical world,&amp;nbsp;Caterpillar and Nvidia announced a pilot program, “Cat AI Assistant,” which was&amp;nbsp;demonstrated&amp;nbsp;at CES Wednesday.&amp;nbsp;This system, coming to one of Caterpillar’s excavator vehicles, is happening alongside another project to use Nvidia’s Omniverse simulation resources to help with construction project planning and execution.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-instagram wp-block-embed-instagram"&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-hands-on-with-clicks-communicator"&gt;Hands-on with Clicks Communicator&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="display of Clicks smartphones" class="wp-image-3081105" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0669-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One of the buzziest reveals of the show is the debut phone from Clicks Technology, the $499 Communicator, which brings back BlackBerry vibes with its physical keyboard, plus a separate $79 slide-out physical keyboard that can be used with other devices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Check out our full rundown from the show floor here, but the Communicator makes a good first impression, per Consumer Editor Sarah Perez:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In our hands-on test, the phone felt good to hold — not too heavy or light, and was easy to grip. Gadway told me the company settled on the device’s final form after dozens of 3D-printed shapes. The winning design for the phone features a contoured back that makes it easy to pick up and hold.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The device’s screen is also somewhat elevated off the body, and its chin is curved up to create a recess that protects the keys when you place it face down.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-check-out-the-skylight-calendar-2"&gt;Check out the Skylight Calendar 2&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarah Perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This family planning tool caught our eyes on the show floor, not just for its calendar and planning capabilities, but for its AI capabilities that are able to&amp;nbsp;sync&amp;nbsp;calendars from&amp;nbsp;different sources, create new to-dos based&amp;nbsp;off of&amp;nbsp;messages or photos, appointment reminders, and more.&amp;nbsp;Check out our full impressions here.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-boston-dynamics-and-google-partner-on-atlas-robots-nbsp"&gt;Boston Dynamics and Google partner on Atlas robots&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Hyundai’s press conference focused on its robotics partnerships with Boston Dynamics, but the companies revealed that&amp;nbsp;they’re&amp;nbsp;working with Google’s AI research lab rather than competitors&amp;nbsp;to train and operate existing Atlas robots, as well as a new iteration of the humanoid robot that was shown onstage.&amp;nbsp;Transportation editor Kirsten Korosec has the full rundown.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;Amazon’s AI-centric update with Alexa+ is getting the kind of push&amp;nbsp;you’d&amp;nbsp;expect at CES, with&amp;nbsp;the company launching Alexa.com for Early Access customers&amp;nbsp;looking to use the chatbot via their browsers, along with a similar, revamped bot-focused app. Consumer editor Sarah Perez has the details, along with news on&amp;nbsp;Amazon’s revamp to Fire TV and new&amp;nbsp;Artline TVs, which have their own Alexa+ push.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the Ring front, consumer reporter Ivan Mehta&amp;nbsp;runs through the many announcements, from fire alerts to an app store for third-party camera integration, and&amp;nbsp;more.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-razer-joins-the-ai-deluge-nbsp-with-project-ava-and-motoko-nbsp"&gt;Razer joins the AI deluge&amp;nbsp;with Project AVA and Motoko&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, Razer has been all about ridiculous hardware at CES,&amp;nbsp;from three-screen laptops&amp;nbsp;to&amp;nbsp;haptic gaming cushions&amp;nbsp;to&amp;nbsp;a mask that landed the company a federal fine. This year, its two attention-grabbing announcements were for Project&amp;nbsp;Motoko, which aims to function similarly to smart glasses, but&amp;nbsp;without&amp;nbsp;the glasses.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s Project AVA, which puts the avatar of an AI companion on your desk.&amp;nbsp;We’ll&amp;nbsp;let you watch the concept video for yourself.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-lego-smart-bricks-mark-the-company-s-first-ces-appearance-nbsp"&gt;Lego Smart Bricks mark the company’s first CES appearance&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lego joined CES for the first time to hold a behind-closed-doors showcase of its Smart Play System, which&amp;nbsp;includes&amp;nbsp;bricks, tiles, and Minifigures that can all interact with each other&amp;nbsp;and&amp;nbsp;play sounds, with both the debut sets having a Star Wars theme. Senior writer Amanda&amp;nbsp;Silberling&amp;nbsp;has all the details here.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CES 2026&amp;nbsp;is in full swing in Las Vegas, with the show floor open to the public after a packed couple of days&amp;nbsp;occupied by&amp;nbsp;press conferences from the likes of Nvidia, Sony, and AMD&amp;nbsp;and previews from Sunday’s Unveiled event.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As has been the case for the past two years at CES, AI is at the forefront of many companies’ messaging, though the hardware&amp;nbsp;upgrades and oddities that have long defined the annual event still have their place on the show floor and in adjacent announcements. We’ll&amp;nbsp;be collecting the biggest reveals and surprises here, though you can still catch&amp;nbsp;the spur-of-the-moment reactions and thoughts from our team on the ground&amp;nbsp;via our live blog right here.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;dive right in, starting with some of Monday’s biggest players.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-nvidia-reveals-ai-model-for-autonomous-vehicles-showcases-rubin-architecture"&gt;Nvidia reveals AI model for autonomous vehicles, showcases Rubin architecture&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia CEO Jensen Huang delivered an expectedly lengthy presentation at CES, taking a victory lap for the company’s AI-driven successes,&amp;nbsp;setting the stage for 2026, and yes,&amp;nbsp;hanging out with some robots.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Rubin computing&amp;nbsp;architecture, which has been developed to meet the increasing computation demands that AI adoption creates, is&amp;nbsp;set to begin replacing Blackwell architecture in the second half of this year. It comes with speed and storage upgrades, but our&amp;nbsp;senior AI&amp;nbsp;editor&amp;nbsp;Russell Brandom goes into the nitty-gritty of what distinguishes Rubin.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And Nvidia continued its push to bring the AI revolution into the physical world,&amp;nbsp;showcasing its Alpamayo family of open source AI models&amp;nbsp;and tools that will be used by autonomous vehicles this year.&amp;nbsp;That approach, as senior reporter Rebecca Bellan notes, mirrors the company’s broader efforts to make its infrastructure the Android for generalist robots.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-amd-s-keynote-highlights-new-processors-and-partnerships-nbsp"&gt;AMD’s keynote highlights new processors and partnerships&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AMD chair and CEO Lisa Su delivered the first keynote of CES, with a presentation that featured partners, including OpenAI president Greg Brockman, AI legend Fei-Fei Li,&amp;nbsp;Luma AI CEO Amit Jain, and more.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond the&amp;nbsp;partner&amp;nbsp;showcases, senior reporter Rebecca Szkutak&amp;nbsp;detailed AMD’s approach toward expanding the reach of AI through personal computers&amp;nbsp;using its Ryzen AI 400 Series processors.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-the-standout-oddities-of-ces"&gt;The standout oddities of CES&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Let’s&amp;nbsp;face it, by this point in the show the major announcements have been made, products have been showcased, and&amp;nbsp;it’s&amp;nbsp;time to eye some of the most eyebrow-raising reveals from CES.&amp;nbsp;We started our list of what stood out to us as odd and noteworthy, but&amp;nbsp;we’re&amp;nbsp;open to more suggestions!&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-highlights-from-ces-breakout-sessions"&gt;Highlights from CES breakout sessions&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;CES&amp;nbsp;isn’t&amp;nbsp;all hardware&amp;nbsp;showcases&amp;nbsp;and show floor attractions — there are plenty of&amp;nbsp;additional&amp;nbsp;industry panels and speakers drawing eyeballs. We&amp;nbsp;kept tabs on&amp;nbsp;a few notable highlights, ranging from&amp;nbsp;Palmer Luckey pushing retro aesthetics, to why the&amp;nbsp;“learn once, work forever” era may be over,&amp;nbsp;to previews of the new Silicon Valley-based series “The Audacity,”&amp;nbsp;to&amp;nbsp;the expansion of Roku’s $3 streaming service,&amp;nbsp;to All-In host Jason Calacanis putting a $25,000 bounty on an authentic Theranos device.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ford-s-ai-assistant-debuts"&gt;Ford’s AI assistant debuts&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is launching its assistant in the company’s app before a targeted 2027 release in its vehicles, with hosting managed by Google Cloud and the assistant itself built using off-the-shelf LLMs. As&amp;nbsp;we noted in our coverage of the news, however, few details were offered around what drivers should expect from their experience with the&amp;nbsp;assistant.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-caterpillar-nvidia-partner-on-automated-construction-equipment"&gt;Caterpillar, Nvidia partner on automated construction equipment&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the ever-present push for AI’s impact on the physical world,&amp;nbsp;Caterpillar and Nvidia announced a pilot program, “Cat AI Assistant,” which was&amp;nbsp;demonstrated&amp;nbsp;at CES Wednesday.&amp;nbsp;This system, coming to one of Caterpillar’s excavator vehicles, is happening alongside another project to use Nvidia’s Omniverse simulation resources to help with construction project planning and execution.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-instagram wp-block-embed-instagram"&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-hands-on-with-clicks-communicator"&gt;Hands-on with Clicks Communicator&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="display of Clicks smartphones" class="wp-image-3081105" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0669-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One of the buzziest reveals of the show is the debut phone from Clicks Technology, the $499 Communicator, which brings back BlackBerry vibes with its physical keyboard, plus a separate $79 slide-out physical keyboard that can be used with other devices.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Check out our full rundown from the show floor here, but the Communicator makes a good first impression, per Consumer Editor Sarah Perez:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In our hands-on test, the phone felt good to hold — not too heavy or light, and was easy to grip. Gadway told me the company settled on the device’s final form after dozens of 3D-printed shapes. The winning design for the phone features a contoured back that makes it easy to pick up and hold.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The device’s screen is also somewhat elevated off the body, and its chin is curved up to create a recess that protects the keys when you place it face down.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-check-out-the-skylight-calendar-2"&gt;Check out the Skylight Calendar 2&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sarah Perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This family planning tool caught our eyes on the show floor, not just for its calendar and planning capabilities, but for its AI capabilities that are able to&amp;nbsp;sync&amp;nbsp;calendars from&amp;nbsp;different sources, create new to-dos based&amp;nbsp;off of&amp;nbsp;messages or photos, appointment reminders, and more.&amp;nbsp;Check out our full impressions here.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-boston-dynamics-and-google-partner-on-atlas-robots-nbsp"&gt;Boston Dynamics and Google partner on Atlas robots&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Hyundai’s press conference focused on its robotics partnerships with Boston Dynamics, but the companies revealed that&amp;nbsp;they’re&amp;nbsp;working with Google’s AI research lab rather than competitors&amp;nbsp;to train and operate existing Atlas robots, as well as a new iteration of the humanoid robot that was shown onstage.&amp;nbsp;Transportation editor Kirsten Korosec has the full rundown.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p class="wp-block-paragraph"&gt;Amazon’s AI-centric update with Alexa+ is getting the kind of push&amp;nbsp;you’d&amp;nbsp;expect at CES, with&amp;nbsp;the company launching Alexa.com for Early Access customers&amp;nbsp;looking to use the chatbot via their browsers, along with a similar, revamped bot-focused app. Consumer editor Sarah Perez has the details, along with news on&amp;nbsp;Amazon’s revamp to Fire TV and new&amp;nbsp;Artline TVs, which have their own Alexa+ push.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the Ring front, consumer reporter Ivan Mehta&amp;nbsp;runs through the many announcements, from fire alerts to an app store for third-party camera integration, and&amp;nbsp;more.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-razer-joins-the-ai-deluge-nbsp-with-project-ava-and-motoko-nbsp"&gt;Razer joins the AI deluge&amp;nbsp;with Project AVA and Motoko&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, Razer has been all about ridiculous hardware at CES,&amp;nbsp;from three-screen laptops&amp;nbsp;to&amp;nbsp;haptic gaming cushions&amp;nbsp;to&amp;nbsp;a mask that landed the company a federal fine. This year, its two attention-grabbing announcements were for Project&amp;nbsp;Motoko, which aims to function similarly to smart glasses, but&amp;nbsp;without&amp;nbsp;the glasses.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Then there’s Project AVA, which puts the avatar of an AI companion on your desk.&amp;nbsp;We’ll&amp;nbsp;let you watch the concept video for yourself.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-lego-smart-bricks-mark-the-company-s-first-ces-appearance-nbsp"&gt;Lego Smart Bricks mark the company’s first CES appearance&amp;nbsp;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Lego joined CES for the first time to hold a behind-closed-doors showcase of its Smart Play System, which&amp;nbsp;includes&amp;nbsp;bricks, tiles, and Minifigures that can all interact with each other&amp;nbsp;and&amp;nbsp;play sounds, with both the debut sets having a Star Wars theme. Senior writer Amanda&amp;nbsp;Silberling&amp;nbsp;has all the details here.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/08/ces-2026-everything-revealed-from-nvidias-debuts-to-amds-new-chips-to-razers-ai-oddities/</guid><pubDate>Fri, 09 Jan 2026 00:35:00 +0000</pubDate></item></channel></rss>