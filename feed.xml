<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 01 Jul 2025 02:01:14 +0000</lastBuildDate><item><title>Accelerating scientific discovery with AI (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/MIT-Future-House-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Several researchers have taken a broad view of scientific progress over the last 50 years and come to the same troubling conclusion: Scientific productivity is declining. It’s taking more time, more funding, and larger teams to make discoveries that once came faster and cheaper. Although a variety of explanations have been offered for the slowdown, one is that, as research becomes more complex and specialized, scientists must spend more time reviewing publications, designing sophisticated experiments, and analyzing data.&lt;/p&gt;&lt;p&gt;Now, the philanthropically funded research lab FutureHouse is seeking to accelerate scientific research with an AI platform designed to automate many of the critical steps on the path toward scientific progress. The platform is made up of a series of AI agents specialized for tasks including information retrieval, information synthesis, chemical synthesis design, and data analysis.&lt;/p&gt;&lt;p&gt;FutureHouse founders Sam Rodriques PhD ’19 and Andrew White believe that by giving every scientist access to their AI agents, they can break through the biggest bottlenecks in science and help solve some of humanity’s most pressing problems.&lt;/p&gt;&lt;p&gt;“Natural language is the real language of science,” Rodriques says. “Other people are building foundation models for biology, where machine learning models speak the language of DNA or proteins, and that’s powerful. But discoveries aren’t represented in DNA or proteins. The only way we know how to represent discoveries, hypothesize, and reason is with natural language.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Finding big problems&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For his PhD research at MIT, Rodriques sought to understand the inner workings of the brain in the lab of Professor Ed Boyden.&lt;/p&gt;&lt;p&gt;“The entire idea behind FutureHouse was inspired by this impression I got during my PhD at MIT that even if we had all the information we needed to know about how the brain works, we wouldn’t know it because nobody has time to read all the literature,” Rodriques explains. “Even if they could read it all, they wouldn’t be able to assemble it into a comprehensive theory. That was a foundational piece of the FutureHouse puzzle.”&lt;/p&gt;&lt;p&gt;Rodriques wrote about the need for&amp;nbsp;new kinds of large research collaborations as the last chapter of his PhD thesis in 2019, and though he spent some time running a lab at the Francis Crick Institute in London after graduation, he found himself gravitating toward broad problems in science that no single lab could take on.&lt;/p&gt;&lt;p&gt;“I was interested in how to automate or scale up science and what kinds of new organizational structures or technologies would unlock higher scientific productivity,” Rodriques says.&lt;/p&gt;&lt;p&gt;When Chat-GPT 3.5 was released in November 2022, Rodriques saw a path toward more powerful models that could generate scientific insights on their own. Around that time, he also met Andrew White, a computational chemist at the University of Rochester who had been granted early access to Chat-GPT 4. White had built the first large language agent for science, and the researchers joined forces to start FutureHouse.&lt;/p&gt;&lt;p&gt;The founders started out wanting to create distinct AI tools for tasks like literature searches, data analysis, and hypothesis generation. They began with data collection, eventually releasing PaperQA in September 2024, which Rodriques calls the best AI agent in the world for retrieving and summarizing information in scientific literature. Around the same time, they released Has Anyone, a tool that lets scientists determine if anyone has conducted specific experiments or explored specific hypotheses.&lt;/p&gt;&lt;p&gt;“We were just sitting around asking, ‘What are the kinds of questions that we as scientists ask all the time?’” Rodriques recalls.&lt;/p&gt;&lt;p&gt;When FutureHouse officially launched its platform on May 1 of this year, it rebranded some of its tools. Paper QA is now Crow, and Has Anyone is now called Owl. Falcon is an agent capable of compiling and reviewing more sources than Crow. Another new agent, Phoenix, can use specialized tools to help researchers plan chemistry experiments. And Finch is an agent designed to automate data driven discovery in biology.&lt;/p&gt;&lt;p&gt;On May 20, the company demonstrated a multi-agent scientific discovery workflow to automate key steps of the scientific process and identify a new therapeutic candidate for dry age-related macular degeneration (dAMD), a leading cause of irreversible blindness worldwide. In June, FutureHouse released ether0, a 24B open-weights reasoning model for chemistry.&lt;/p&gt;&lt;p&gt;“You really have to think of these agents as part of a larger system,” Rodriques says. “Soon, the literature search agents will be integrated with the data analysis agent, the hypothesis generation agent, an experiment planning agent, and they will all be engineered to work together seamlessly.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agents for everyone&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Today anyone can access FutureHouse’s agents at platform.futurehouse.org. The company’s platform launch generated excitement in the industry, and stories have started to come in about scientists using the agents to accelerate research.&lt;/p&gt;&lt;p&gt;One of FutureHouse’s scientists used the agents to identify a gene that could be associated with polycystic ovary syndrome and come up with a new treatment hypothesis for the disease. Another researcher at the Lawrence Berkeley National Laboratory used Crow to create an AI assistant capable of searching the PubMed research database for information related to Alzheimer’s disease.&lt;/p&gt;&lt;p&gt;Scientists at another research institution have used the agents to conduct systematic reviews of genes relevant to Parkinson’s disease, finding FutureHouse’s agents performed better than general agents.&lt;/p&gt;&lt;p&gt;Rodriques says scientists who think of the agents less like Google Scholar and more like a smart assistant scientist get the most out of the platform.&lt;/p&gt;&lt;p&gt;“People who are looking for speculation tend to get more mileage out of Chat-GPT o3 deep research, while people who are looking for really faithful literature reviews tend to get more out of our agents,” Rodriques explains.&lt;/p&gt;&lt;p&gt;Rodriques also thinks FutureHouse will soon get to a point where its agents can use the raw data from research papers to test the reproducibility of its results and verify conclusions.&lt;/p&gt;&lt;p&gt;In the longer run, to keep scientific progress marching forward, Rodriques says FutureHouse is working on embedding its agents with tacit knowledge to be able to perform more sophisticated analyses while also giving the agents the ability to use computational tools to explore hypotheses.&lt;/p&gt;&lt;p&gt;“There have been so many advances around foundation models for science and around language models for proteins and DNA, that we now need to give our agents access to those models and all of the other tools people commonly use to do science,” Rodriques says. “Building the infrastructure to allow agents to use more specialized tools for science is going to be critical.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/MIT-Future-House-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Several researchers have taken a broad view of scientific progress over the last 50 years and come to the same troubling conclusion: Scientific productivity is declining. It’s taking more time, more funding, and larger teams to make discoveries that once came faster and cheaper. Although a variety of explanations have been offered for the slowdown, one is that, as research becomes more complex and specialized, scientists must spend more time reviewing publications, designing sophisticated experiments, and analyzing data.&lt;/p&gt;&lt;p&gt;Now, the philanthropically funded research lab FutureHouse is seeking to accelerate scientific research with an AI platform designed to automate many of the critical steps on the path toward scientific progress. The platform is made up of a series of AI agents specialized for tasks including information retrieval, information synthesis, chemical synthesis design, and data analysis.&lt;/p&gt;&lt;p&gt;FutureHouse founders Sam Rodriques PhD ’19 and Andrew White believe that by giving every scientist access to their AI agents, they can break through the biggest bottlenecks in science and help solve some of humanity’s most pressing problems.&lt;/p&gt;&lt;p&gt;“Natural language is the real language of science,” Rodriques says. “Other people are building foundation models for biology, where machine learning models speak the language of DNA or proteins, and that’s powerful. But discoveries aren’t represented in DNA or proteins. The only way we know how to represent discoveries, hypothesize, and reason is with natural language.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Finding big problems&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For his PhD research at MIT, Rodriques sought to understand the inner workings of the brain in the lab of Professor Ed Boyden.&lt;/p&gt;&lt;p&gt;“The entire idea behind FutureHouse was inspired by this impression I got during my PhD at MIT that even if we had all the information we needed to know about how the brain works, we wouldn’t know it because nobody has time to read all the literature,” Rodriques explains. “Even if they could read it all, they wouldn’t be able to assemble it into a comprehensive theory. That was a foundational piece of the FutureHouse puzzle.”&lt;/p&gt;&lt;p&gt;Rodriques wrote about the need for&amp;nbsp;new kinds of large research collaborations as the last chapter of his PhD thesis in 2019, and though he spent some time running a lab at the Francis Crick Institute in London after graduation, he found himself gravitating toward broad problems in science that no single lab could take on.&lt;/p&gt;&lt;p&gt;“I was interested in how to automate or scale up science and what kinds of new organizational structures or technologies would unlock higher scientific productivity,” Rodriques says.&lt;/p&gt;&lt;p&gt;When Chat-GPT 3.5 was released in November 2022, Rodriques saw a path toward more powerful models that could generate scientific insights on their own. Around that time, he also met Andrew White, a computational chemist at the University of Rochester who had been granted early access to Chat-GPT 4. White had built the first large language agent for science, and the researchers joined forces to start FutureHouse.&lt;/p&gt;&lt;p&gt;The founders started out wanting to create distinct AI tools for tasks like literature searches, data analysis, and hypothesis generation. They began with data collection, eventually releasing PaperQA in September 2024, which Rodriques calls the best AI agent in the world for retrieving and summarizing information in scientific literature. Around the same time, they released Has Anyone, a tool that lets scientists determine if anyone has conducted specific experiments or explored specific hypotheses.&lt;/p&gt;&lt;p&gt;“We were just sitting around asking, ‘What are the kinds of questions that we as scientists ask all the time?’” Rodriques recalls.&lt;/p&gt;&lt;p&gt;When FutureHouse officially launched its platform on May 1 of this year, it rebranded some of its tools. Paper QA is now Crow, and Has Anyone is now called Owl. Falcon is an agent capable of compiling and reviewing more sources than Crow. Another new agent, Phoenix, can use specialized tools to help researchers plan chemistry experiments. And Finch is an agent designed to automate data driven discovery in biology.&lt;/p&gt;&lt;p&gt;On May 20, the company demonstrated a multi-agent scientific discovery workflow to automate key steps of the scientific process and identify a new therapeutic candidate for dry age-related macular degeneration (dAMD), a leading cause of irreversible blindness worldwide. In June, FutureHouse released ether0, a 24B open-weights reasoning model for chemistry.&lt;/p&gt;&lt;p&gt;“You really have to think of these agents as part of a larger system,” Rodriques says. “Soon, the literature search agents will be integrated with the data analysis agent, the hypothesis generation agent, an experiment planning agent, and they will all be engineered to work together seamlessly.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Agents for everyone&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Today anyone can access FutureHouse’s agents at platform.futurehouse.org. The company’s platform launch generated excitement in the industry, and stories have started to come in about scientists using the agents to accelerate research.&lt;/p&gt;&lt;p&gt;One of FutureHouse’s scientists used the agents to identify a gene that could be associated with polycystic ovary syndrome and come up with a new treatment hypothesis for the disease. Another researcher at the Lawrence Berkeley National Laboratory used Crow to create an AI assistant capable of searching the PubMed research database for information related to Alzheimer’s disease.&lt;/p&gt;&lt;p&gt;Scientists at another research institution have used the agents to conduct systematic reviews of genes relevant to Parkinson’s disease, finding FutureHouse’s agents performed better than general agents.&lt;/p&gt;&lt;p&gt;Rodriques says scientists who think of the agents less like Google Scholar and more like a smart assistant scientist get the most out of the platform.&lt;/p&gt;&lt;p&gt;“People who are looking for speculation tend to get more mileage out of Chat-GPT o3 deep research, while people who are looking for really faithful literature reviews tend to get more out of our agents,” Rodriques explains.&lt;/p&gt;&lt;p&gt;Rodriques also thinks FutureHouse will soon get to a point where its agents can use the raw data from research papers to test the reproducibility of its results and verify conclusions.&lt;/p&gt;&lt;p&gt;In the longer run, to keep scientific progress marching forward, Rodriques says FutureHouse is working on embedding its agents with tacit knowledge to be able to perform more sophisticated analyses while also giving the agents the ability to use computational tools to explore hypotheses.&lt;/p&gt;&lt;p&gt;“There have been so many advances around foundation models for science and around language models for proteins and DNA, that we now need to give our agents access to those models and all of the other tools people commonly use to do science,” Rodriques says. “Building the infrastructure to allow agents to use more specialized tools for science is going to be critical.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/futurehouse-accelerates-scientific-discovery-with-ai-0630</guid><pubDate>Mon, 30 Jun 2025 14:30:00 +0000</pubDate></item><item><title>Roundtables: Inside OpenAI’s Empire with Karen Hao (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/30/1118540/roundtables-inside-openais-empire-with-karen-hao/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;Recorded on June 30, 2025&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;AI journalist Karen Hao’s book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI&lt;/em&gt;, tells the story of OpenAI’s rise to power and its far-reaching impact all over the world. Hear from Karen Hao, former &lt;em&gt;MIT Technology Review &lt;/em&gt;senior editor, and executive editor Niall Firth for a conversation exploring the AI arms race, what it means for all of us, and where it’s headed.&lt;/p&gt;  &lt;p&gt;Speakers: Karen Hao, AI journalist, and Niall Firth, executive editor.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/MITTR-Roundtables-Video-Library-Thumbnail.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;&lt;strong&gt;Recorded on June 30, 2025&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;AI journalist Karen Hao’s book, &lt;em&gt;Empire of AI: Dreams and Nightmares in Sam Altman's OpenAI&lt;/em&gt;, tells the story of OpenAI’s rise to power and its far-reaching impact all over the world. Hear from Karen Hao, former &lt;em&gt;MIT Technology Review &lt;/em&gt;senior editor, and executive editor Niall Firth for a conversation exploring the AI arms race, what it means for all of us, and where it’s headed.&lt;/p&gt;  &lt;p&gt;Speakers: Karen Hao, AI journalist, and Niall Firth, executive editor.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/30/1118540/roundtables-inside-openais-empire-with-karen-hao/</guid><pubDate>Mon, 30 Jun 2025 14:59:17 +0000</pubDate></item><item><title>Cursor launches a web app to manage AI coding agents (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/cursor-launches-a-web-app-to-manage-ai-coding-agents/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/opengraph-image.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The company behind Cursor, the viral AI coding editor, launched a web app on Monday that allows users to manage a network of coding agents directly from their browser.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch marks Cursor’s next big step beyond its integrated development environment (IDE), the core product developers use to access its tools. While Anysphere, the company behind Cursor, initially offered only this AI-powered IDE, the company has made a concerted effort to put its products in more places and develop more agent-powered experiences for users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In May, Cursor launched background agents — AI systems that solve coding tasks autonomously without user supervision. In June, the company launched a Slack integration that allows users to assign tasks to these background agents by tagging @Cursor, similar to how Cognitions’s AI coding agent, Devin, operates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, with the web app, Cursor users can send natural language requests via browser — on desktop or mobile— to assign background agents tasks such as writing features or fixing bugs in their codebase. The web app also lets users monitor agents working on other tasks, view their progress, and merge completed changes into the codebase.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andrew Milich, Cursor’s head of product engineering, tells TechCrunch that the Slack integration and web app are part of an effort to “remove the friction” for users who rely on Cursor — and it seems many do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere announced last month that Cursor has crossed $500 million in annualized recurring revenue, largely driven by monthly subscriptions. The company also said Cursor is now used by more than half of the Fortune 500, including companies such as Nvidia, Uber, and Adobe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To capitalize on this growth, Anysphere recently launched a $200-per-month Pro tier for Cursor.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“You noted how customers want Cursor in more places. I think they also want Cursor to solve more of the problems they’re having,” said Milich.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cursor’s background agents are designed to let users start tasks through Slack or the web app, allowing an agent to take a first pass. If the agent can’t complete the task, users can seamlessly transition into the IDE to pick up where the agent left off. Each agent also has a unique shareable link — making it easy to view progress and code changes on agents that other teammates created.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere says all customers with access to background agents can use the Cursor web app — that includes subscribers to Cursor’s $20-per-month Pro plan, as well as more expensive plans, but not users on Cursor’s free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cursor is not the first to ship AI coding agents, but the company says it has been careful to take its time and not ship “demo-ware” — AI products that look good in theory but fail in practice. That has been the story for a lot of early AI coding agents, which made numerous mistakes in testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The team behind Cursor now believes AI reasoning models are advancing enough to make coding agents viable. In a recent interview with Stratechery’s Ben Thompson, Anysphere CEO Michael Truell said he expects AI coding agents to handle at least 20% of a software engineer’s work by 2026.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/opengraph-image.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The company behind Cursor, the viral AI coding editor, launched a web app on Monday that allows users to manage a network of coding agents directly from their browser.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch marks Cursor’s next big step beyond its integrated development environment (IDE), the core product developers use to access its tools. While Anysphere, the company behind Cursor, initially offered only this AI-powered IDE, the company has made a concerted effort to put its products in more places and develop more agent-powered experiences for users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In May, Cursor launched background agents — AI systems that solve coding tasks autonomously without user supervision. In June, the company launched a Slack integration that allows users to assign tasks to these background agents by tagging @Cursor, similar to how Cognitions’s AI coding agent, Devin, operates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, with the web app, Cursor users can send natural language requests via browser — on desktop or mobile— to assign background agents tasks such as writing features or fixing bugs in their codebase. The web app also lets users monitor agents working on other tasks, view their progress, and merge completed changes into the codebase.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Andrew Milich, Cursor’s head of product engineering, tells TechCrunch that the Slack integration and web app are part of an effort to “remove the friction” for users who rely on Cursor — and it seems many do.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere announced last month that Cursor has crossed $500 million in annualized recurring revenue, largely driven by monthly subscriptions. The company also said Cursor is now used by more than half of the Fortune 500, including companies such as Nvidia, Uber, and Adobe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To capitalize on this growth, Anysphere recently launched a $200-per-month Pro tier for Cursor.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“You noted how customers want Cursor in more places. I think they also want Cursor to solve more of the problems they’re having,” said Milich.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cursor’s background agents are designed to let users start tasks through Slack or the web app, allowing an agent to take a first pass. If the agent can’t complete the task, users can seamlessly transition into the IDE to pick up where the agent left off. Each agent also has a unique shareable link — making it easy to view progress and code changes on agents that other teammates created.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anysphere says all customers with access to background agents can use the Cursor web app — that includes subscribers to Cursor’s $20-per-month Pro plan, as well as more expensive plans, but not users on Cursor’s free tier.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cursor is not the first to ship AI coding agents, but the company says it has been careful to take its time and not ship “demo-ware” — AI products that look good in theory but fail in practice. That has been the story for a lot of early AI coding agents, which made numerous mistakes in testing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The team behind Cursor now believes AI reasoning models are advancing enough to make coding agents viable. In a recent interview with Stratechery’s Ben Thompson, Anysphere CEO Michael Truell said he expects AI coding agents to handle at least 20% of a software engineer’s work by 2026.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/cursor-launches-a-web-app-to-manage-ai-coding-agents/</guid><pubDate>Mon, 30 Jun 2025 15:00:00 +0000</pubDate></item><item><title>Tiny AI ERP startup Campfire is winning so many startups from NetSuite, Accel led a $35M Series A (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/tiny-ai-erp-startup-campfire-is-winning-so-many-startups-from-netsuite-accel-led-a-35m-series-a/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Campfire-founder-CEO-John-Glasgow.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered accounting startup Campfire announced Monday that it has raised a $35 million Series A led by Accel, with participation from Foundation Capital, Y Combinator, Capital 49, and angel investors including Mercury’s CFO Dan Kang.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Within nine months of formation, we had customers [with] north of 100 employees ripping out NetSuite and putting in Campfire,” founder CEO John Glasgow said. Some of Campfire’s customers that have migrated from NetSuite include wealth management platform Advisor360, construction software startup Rhumbix, and customer experience company Fooji, Campfire says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This was, in part, because Glasgow attended YC in the summer of 2023, despite being decidedly more experienced than the typical 20-something YC founder. He described the age difference with a funny story: During a YC bingo event, “One of the bingos was ‘find someone that’s a parent,’ and I was the hot commodity at YC bingo.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow already had a decade and a half career in finance working for Fidelity, Union Square Advisors, and others. When his manager from Adobe left to run an Accel-backed startup called Invoice2go, he took Glasgow with him. Less than a year later, in the fall of 2021, Bill.com bought Invoice2go for about $625 million.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow wound up with both the cash and an idea to build his own startup, one that would automate the drudgery in finance like reconciling payments on bills, revenue forecasts, and — the part he discovered during the Invoice2go deal — due diligence for M&amp;amp;A.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He launched Campfire in 2023 to upend 1990s-era enterprise resource planning accounting software (ERP) like NetSuite with an LLM-powered alternative.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Campfire does things like automatically itemize and reconcile AWS cloud computing bills. It generates detailed cash flow analysis, charts, and answers to questions from natural-language prompts.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“One of our customers went from a 15-day to a three-day close when they ripped out NetSuite and put in Campfire,” he says about the time to finalize the books each month.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YC’s famed access to other cohort alums helped him land tech startups as customers like Replit and Replo. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Campfire is just a gnat in terms of its impact on Oracle’s billion-dollar (and growing) NetSuite business, the startup gained enough customers to prove its competitive plausibility.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At its seed stage, Campfire grew to around 100 customers, including, Glasgow said, one global customer on track to do a $250 million ARR. Campfire is now up to 12 employees&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was surprised that there were businesses of this size that were trusting their whole ERP to a 10-person, seed-stage project,” Accel’s John Locke, who had backed Invoice2Go, told TechCrunch of what had enticed him with Campfire. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Locke typically invests at the growth stage. But given that kind of “traction out of the gates” and a total ERP software market of $56 billion in 2024, according to some market research reports, Locke was in to lead the Series A. And he was in big.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[The] AI ERP business is massive, and we think John is really the right person to do it. So why don’t we do a $30 [million] to $35 million Series A, and really go for it?” he told Glasgow and his partners. So they did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: This story originally identified Mercury as a customer when it is not.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Campfire-founder-CEO-John-Glasgow.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered accounting startup Campfire announced Monday that it has raised a $35 million Series A led by Accel, with participation from Foundation Capital, Y Combinator, Capital 49, and angel investors including Mercury’s CFO Dan Kang.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Within nine months of formation, we had customers [with] north of 100 employees ripping out NetSuite and putting in Campfire,” founder CEO John Glasgow said. Some of Campfire’s customers that have migrated from NetSuite include wealth management platform Advisor360, construction software startup Rhumbix, and customer experience company Fooji, Campfire says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This was, in part, because Glasgow attended YC in the summer of 2023, despite being decidedly more experienced than the typical 20-something YC founder. He described the age difference with a funny story: During a YC bingo event, “One of the bingos was ‘find someone that’s a parent,’ and I was the hot commodity at YC bingo.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow already had a decade and a half career in finance working for Fidelity, Union Square Advisors, and others. When his manager from Adobe left to run an Accel-backed startup called Invoice2go, he took Glasgow with him. Less than a year later, in the fall of 2021, Bill.com bought Invoice2go for about $625 million.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasgow wound up with both the cash and an idea to build his own startup, one that would automate the drudgery in finance like reconciling payments on bills, revenue forecasts, and — the part he discovered during the Invoice2go deal — due diligence for M&amp;amp;A.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He launched Campfire in 2023 to upend 1990s-era enterprise resource planning accounting software (ERP) like NetSuite with an LLM-powered alternative.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Campfire does things like automatically itemize and reconcile AWS cloud computing bills. It generates detailed cash flow analysis, charts, and answers to questions from natural-language prompts.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“One of our customers went from a 15-day to a three-day close when they ripped out NetSuite and put in Campfire,” he says about the time to finalize the books each month.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YC’s famed access to other cohort alums helped him land tech startups as customers like Replit and Replo. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Campfire is just a gnat in terms of its impact on Oracle’s billion-dollar (and growing) NetSuite business, the startup gained enough customers to prove its competitive plausibility.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At its seed stage, Campfire grew to around 100 customers, including, Glasgow said, one global customer on track to do a $250 million ARR. Campfire is now up to 12 employees&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was surprised that there were businesses of this size that were trusting their whole ERP to a 10-person, seed-stage project,” Accel’s John Locke, who had backed Invoice2Go, told TechCrunch of what had enticed him with Campfire. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Locke typically invests at the growth stage. But given that kind of “traction out of the gates” and a total ERP software market of $56 billion in 2024, according to some market research reports, Locke was in to lead the Series A. And he was in big.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[The] AI ERP business is massive, and we think John is really the right person to do it. So why don’t we do a $30 [million] to $35 million Series A, and really go for it?” he told Glasgow and his partners. So they did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Correction: This story originally identified Mercury as a customer when it is not.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/tiny-ai-erp-startup-campfire-is-winning-so-many-startups-from-netsuite-accel-led-a-35m-series-a/</guid><pubDate>Mon, 30 Jun 2025 15:00:00 +0000</pubDate></item><item><title>Power play: Can the grid cope with AI’s growing appetite? (AI News)</title><link>https://www.artificialintelligence-news.com/news/power-play-can-the-grid-cope-with-ais-growing-appetite/</link><description>&lt;p&gt;As the AI Energy Council gathers, the question hanging in the air is: how do we power the future without blowing the grid?&lt;/p&gt;&lt;p&gt;The massive data centres needed to train and run the latest AI are thirsty for electricity. Data centre power use in the UK is on track to multiply six times over by 2034, at which point it could be sucking up nearly a third of all our nation’s electricity. That’s a colossal strain to put on a system that was built for a completely different world, one with predictable, one-way power flows.&lt;/p&gt;&lt;p&gt;The AI Energy Council – a team-up of tech giants, energy firms, the Ofgem regulator, and the National Energy System Operator – has the critical job of trying to predict just how thirsty this AI beast will become. Their work is happening just as the government is pouring £2 billion into its AI Opportunities Action Plan, a grand vision for weaving AI into our hospitals, classrooms, and businesses.&lt;/p&gt;&lt;p&gt;UK Science and Technology Secretary Peter Kyle said: “Giving our researchers and innovators access to the processing power they need will not only maintain our standing as the world’s third-biggest AI power, but put British expertise at the heart of the AI breakthroughs which will improve our lives, modernise our public services, and spark the economic growth which is the cornerstone of our Plan for Change.&lt;/p&gt;&lt;p&gt;“We are clear-eyed though on the need to make sure we can power this golden era for British AI through responsible, sustainable energy sources. Today’s talks will help us drive forward that mission, delivering AI infrastructure which will benefit communities up and down the country for generations to come without ever compromising on our clean energy superpower ambitions.”&lt;/p&gt;&lt;p&gt;The sheer scale of the energy problem is hard to overstate. Globally, the electricity needed for data centres is expected to double in just five years, eventually demanding three times more power than the entire UK currently uses. And AI is the main culprit.&lt;/p&gt;&lt;p&gt;A single rack of AI servers can demand 120 kW of power, a massive leap from the 5-10 kW a normal rack needs. These aren’t steady sips of power, either. AI workloads can spike unpredictably, creating sudden, massive power surges that threaten the stability of the entire grid.&lt;/p&gt;&lt;p&gt;In response, the UK is planning a monumental overhaul. The centrepiece is the “Great Grid Upgrade,” a £58 billion investment designed to be a “once in a generation expansion” of the electricity network. This includes building a new high-capacity electrical superhighway running from north to south and expanding the offshore grid to bring in vast amounts of new wind power.&lt;/p&gt;&lt;p&gt;Ed Miliband, Secretary for Energy Security and Net Zero, commented: “We are making the UK a clean energy superpower, building the homegrown energy this country needs to get bills down for good and create new jobs as part of our Plan for Change.&lt;/p&gt;&lt;p&gt;“Bringing together the biggest players in AI and energy will help us discuss the role AI can play in building a new era of clean electricity for our country, and meeting the power demands of new technology as we build a clean power system for families and businesses.”&lt;/p&gt;&lt;p&gt;But there’s a huge roadblock. Even if we build the wind farms and solar panels, connecting them to the power grid to address surging AI demand right now is another story. The current process is slow, leaving more than 600 renewable energy projects – worth billions – stuck in a queue. Some have been told they could be waiting for 15 years.&lt;/p&gt;&lt;p&gt;Urgent reforms are being pushed through to try and clear this backlog, a vital step if our AI future is to be powered by green energy. The government is also trying to speed things up by declaring data centres “critical national infrastructure” and setting up “AI Growth Zones” where planning and power connections can be fast-tracked.&lt;/p&gt;&lt;p&gt;The data centre industry is shifting from being just part of the problem to becoming part of the solution. Instead of just being passive power hogs, they are becoming active partners in the energy grid. Many are chasing Net Zero targets, investing in their own on-site renewable power, and taking part in “demand-side response” programs. This means they can intelligently pause non-urgent AI tasks when the grid is under stress and fire them up again when green energy is plentiful, helping to balance the whole system.&lt;/p&gt;&lt;p&gt;AI itself could also help. The same complex algorithms that demand so much power can also be used to make our grid smarter, predicting energy spikes and optimising power flow in real-time.&lt;/p&gt;&lt;p&gt;The way forward is clear, but it won’t be easy. The UK has the right ideas and is putting serious money on the table to address the power grid demands of AI, but everything depends on speed and execution. The grid connection jam must be broken, and the Great Grid Upgrade needs to happen at pace.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andreas Jabusch)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Anthropic tests AI running a real business with bizarre results&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;As the AI Energy Council gathers, the question hanging in the air is: how do we power the future without blowing the grid?&lt;/p&gt;&lt;p&gt;The massive data centres needed to train and run the latest AI are thirsty for electricity. Data centre power use in the UK is on track to multiply six times over by 2034, at which point it could be sucking up nearly a third of all our nation’s electricity. That’s a colossal strain to put on a system that was built for a completely different world, one with predictable, one-way power flows.&lt;/p&gt;&lt;p&gt;The AI Energy Council – a team-up of tech giants, energy firms, the Ofgem regulator, and the National Energy System Operator – has the critical job of trying to predict just how thirsty this AI beast will become. Their work is happening just as the government is pouring £2 billion into its AI Opportunities Action Plan, a grand vision for weaving AI into our hospitals, classrooms, and businesses.&lt;/p&gt;&lt;p&gt;UK Science and Technology Secretary Peter Kyle said: “Giving our researchers and innovators access to the processing power they need will not only maintain our standing as the world’s third-biggest AI power, but put British expertise at the heart of the AI breakthroughs which will improve our lives, modernise our public services, and spark the economic growth which is the cornerstone of our Plan for Change.&lt;/p&gt;&lt;p&gt;“We are clear-eyed though on the need to make sure we can power this golden era for British AI through responsible, sustainable energy sources. Today’s talks will help us drive forward that mission, delivering AI infrastructure which will benefit communities up and down the country for generations to come without ever compromising on our clean energy superpower ambitions.”&lt;/p&gt;&lt;p&gt;The sheer scale of the energy problem is hard to overstate. Globally, the electricity needed for data centres is expected to double in just five years, eventually demanding three times more power than the entire UK currently uses. And AI is the main culprit.&lt;/p&gt;&lt;p&gt;A single rack of AI servers can demand 120 kW of power, a massive leap from the 5-10 kW a normal rack needs. These aren’t steady sips of power, either. AI workloads can spike unpredictably, creating sudden, massive power surges that threaten the stability of the entire grid.&lt;/p&gt;&lt;p&gt;In response, the UK is planning a monumental overhaul. The centrepiece is the “Great Grid Upgrade,” a £58 billion investment designed to be a “once in a generation expansion” of the electricity network. This includes building a new high-capacity electrical superhighway running from north to south and expanding the offshore grid to bring in vast amounts of new wind power.&lt;/p&gt;&lt;p&gt;Ed Miliband, Secretary for Energy Security and Net Zero, commented: “We are making the UK a clean energy superpower, building the homegrown energy this country needs to get bills down for good and create new jobs as part of our Plan for Change.&lt;/p&gt;&lt;p&gt;“Bringing together the biggest players in AI and energy will help us discuss the role AI can play in building a new era of clean electricity for our country, and meeting the power demands of new technology as we build a clean power system for families and businesses.”&lt;/p&gt;&lt;p&gt;But there’s a huge roadblock. Even if we build the wind farms and solar panels, connecting them to the power grid to address surging AI demand right now is another story. The current process is slow, leaving more than 600 renewable energy projects – worth billions – stuck in a queue. Some have been told they could be waiting for 15 years.&lt;/p&gt;&lt;p&gt;Urgent reforms are being pushed through to try and clear this backlog, a vital step if our AI future is to be powered by green energy. The government is also trying to speed things up by declaring data centres “critical national infrastructure” and setting up “AI Growth Zones” where planning and power connections can be fast-tracked.&lt;/p&gt;&lt;p&gt;The data centre industry is shifting from being just part of the problem to becoming part of the solution. Instead of just being passive power hogs, they are becoming active partners in the energy grid. Many are chasing Net Zero targets, investing in their own on-site renewable power, and taking part in “demand-side response” programs. This means they can intelligently pause non-urgent AI tasks when the grid is under stress and fire them up again when green energy is plentiful, helping to balance the whole system.&lt;/p&gt;&lt;p&gt;AI itself could also help. The same complex algorithms that demand so much power can also be used to make our grid smarter, predicting energy spikes and optimising power flow in real-time.&lt;/p&gt;&lt;p&gt;The way forward is clear, but it won’t be easy. The UK has the right ideas and is putting serious money on the table to address the power grid demands of AI, but everything depends on speed and execution. The grid connection jam must be broken, and the Great Grid Upgrade needs to happen at pace.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Andreas Jabusch)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Anthropic tests AI running a real business with bizarre results&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/power-play-can-the-grid-cope-with-ais-growing-appetite/</guid><pubDate>Mon, 30 Jun 2025 15:53:38 +0000</pubDate></item><item><title>AI Testing and Evaluation: Learnings from genome editing (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="illustration of R. Alta Charo, Kathleen Sullivan, and Daniel Kluttz for the Microsoft Research Podcast" class="wp-image-1142157" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry, &lt;/em&gt;hosted by Microsoft Research’s Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Alta Charo&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, emerita professor of law and bioethics at the University of Wisconsin–Madison, joins Sullivan for a conversation on the evolving landscape of genome editing and its regulatory implications. Drawing on decades of experience in biotechnology policy, Charo emphasizes the importance of distinguishing between hazards and risks and describes the field’s approach to regulating &lt;em&gt;applications &lt;/em&gt;of technology rather than the technology itself. The discussion also explores opportunities and challenges in biotech’s multi-agency oversight model and the role of international coordination. Later, Daniel Kluttz&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a partner general manager in Microsoft’s Office of Responsible AI, joins Sullivan to discuss how insights from genome editing could inform more nuanced and robust governance frameworks for emerging technologies like AI.&lt;/p&gt;











&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript-1"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN:&lt;/strong&gt; Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today I’m excited to welcome R. Alta Charo, the Warren P. Knowles Professor Emerita of Law and Bioethics at the University of Wisconsin–Madison, to explore testing and risk assessment in genome editing.&lt;/p&gt;



&lt;p&gt;Professor Charo has been at the forefront of biotechnology policy and governance for decades, advising former President Obama’s transition team on issues of medical research and public health, as well as serving as a senior policy advisor at the Food and Drug Administration. She consults on gene therapy and genome editing for various companies and organizations and has held positions on a number of advisory committees, including for the National Academy of Sciences. Her committee work has spanned women’s health, stem cell research, genome editing, biosecurity, and more.&lt;/p&gt;



&lt;p&gt;After our conversation with Professor Charo, we’ll hear from Daniel Kluttz, a partner general manager in Microsoft’s Office of Responsible AI, about what these insights from biotech regulation could mean for AI governance and risk assessment and his team’s work governing sensitive AI uses and emerging technologies.&lt;/p&gt;



&lt;p&gt;Alta, thank you so much for being here today. I’m a follower of your work and have really been looking forward to our conversation.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;ALTA CHARO:&lt;/strong&gt; It’s my pleasure. Thanks for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Alta, I’d love to begin by stepping back in time a bit before you became a leading figure in bioethics and legal policy. You’ve shared that your interest in science was really inspired by your brothers’ interest in the topic and that your upbringing really helped shape your perseverance and resilience. Can you talk to us about what put you on the path to law and policy?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, I think it’s true that many of us are strongly influenced by our families and certainly my family had, kind of, a science-y, techy orientation. My father was a refugee, you know, escaping the Nazis, and when he finally was able to start working in the United States, he took advantage of the G.I. Bill to learn how to repair televisions and radios, which were really just coming in in the 1950s. So he was, kind of, technically oriented.&lt;/p&gt;



&lt;p&gt;My mother retrained from being a talented amateur artist to becoming a math teacher, and not surprisingly, both my brothers began to aim toward things like engineering and chemistry and physics. And our form of entertainment was to watch PBS or &lt;em&gt;Star Trek&lt;/em&gt;. [LAUGHTER]&lt;/p&gt;



&lt;p&gt;And so the interest comes from that background coupled with, in the 1960s, this enormous surge of interest in the so-called nature-versus-nurture debate about the degree to which we are destined by our biology or shaped by our environments. It was a heady debate, and one that perfectly combined the two interests in politics and science.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; For listeners who are brand new to your field in genomic editing, can you give us what I’ll call a “90-second survey” of the space in perhaps plain language and why it’s important to have a framework for ensuring its responsible use.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, you know, genome editing is both very old and very new. At base, what we’re talking about is a way to either delete sections of the &lt;em&gt;genome&lt;/em&gt;, our collection of genes, or to add things or to alter what’s there. The goal is simply to be able to take what might not be healthy and make it healthy, whether it’s a plant, an animal, or a human.&lt;/p&gt;



&lt;p&gt;Many people have compared it to a word processor, where you can edit text by swapping things in and out. You could change the letter &lt;em&gt;g&lt;/em&gt; to the letter &lt;em&gt;h&lt;/em&gt; in every word, and in our genomes, you can do similar kinds of things.&lt;/p&gt;



&lt;p&gt;But because of this, we have a responsibility to make sure that whatever we change doesn’t become dangerous and that it doesn’t become socially disruptive. Now the earliest forms of genome editing were very inefficient, and so we didn’t worry that much. But with the advances that were spearheaded by people like Jennifer Doudna and Emmanuelle Charpentier, who won the Nobel Prize for their work in this area, genome editing has become much easier to do.&lt;/p&gt;



&lt;p&gt;It’s become more efficient. It doesn’t require as much sophisticated laboratory equipment. It’s moved from being something that only a few people can do to something that we’re going to be seeing in our junior high school biology labs. And that means you have to pay attention to who’s doing it, why are they doing it, what are they releasing, if anything, into the environment, what are they trying to sell, and is it honest and is it safe?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How would you describe the risks, and are there, you know, sort of, specifically inherent risks in the technology itself, or do those risks really emerge only when it’s applied in certain contexts, like CRISPR in agriculture or CRISPR for human therapies?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, to answer that, I’m going to do something that may seem a little picky, even pedantic. [LAUGHTER] But I’m going to distinguish between hazards and risks. So there are certain intrinsic hazards. That is, there are things that can go wrong.&lt;/p&gt;



&lt;p&gt;You want to change one particular gene or one particular portion of a gene, and you might accidentally change something else, a so-called &lt;em&gt;off-target effect&lt;/em&gt;. Or you might change something in a gene expecting a certain effect but not necessarily anticipating that there’s going to be an interaction between what you changed and what was there, a &lt;em&gt;gene-gene interaction&lt;/em&gt;, that might have an unanticipated kind of result, a side effect essentially.&lt;/p&gt;



&lt;p&gt;So there are some intrinsic hazards, but risk is a hazard coupled with the probability that it’s going to actually create something harmful. And that really depends upon the application.&lt;/p&gt;



&lt;p&gt;If you are doing something that is making a change in a human being that is going to be a lifelong change, that enhances the significance of that hazard. It amplifies what I call the risk because if something goes wrong, then its consequences are greater.&lt;/p&gt;



&lt;p&gt;It may also be that in other settings, what you’re doing is going to have a much lower risk because you’re working with a more familiar substance, your predictive power is much greater, and it’s not going into a human or an animal or into the environment. So I think that you have to say that the risk &lt;em&gt;and&lt;/em&gt; the benefits, by the way, all are going to depend upon the particular application.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I think on this point of application, there’s many players involved in that, right. Like, we often hear about this puzzle of who’s actually responsible for ensuring safety and a reasonable balance between risks and benefits or hazards and benefits, to quote you. Is it the scientists, the biotech companies, government agencies? And then if you could touch upon, as well, maybe how does the nature of genome editing risks … how do those responsibilities get divvied up?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, in the 1980s, we had a very significant policy discussion about whether we should regulate the technology—no matter how it’s used or for whatever purpose—or if we should simply fold the technology in with all the other technologies that we currently have and regulate its applications the way we regulate applications generally. And we went for the second, the so-called &lt;em&gt;coordinated framework&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;So what we have in the United States is a system in which if you use genome editing in purely laboratory-based work, then you will be regulated the way we regulate laboratories.&lt;/p&gt;



&lt;p&gt;There’s also, at most universities because of the way the government works with this, something called Institutional Biosafety Committees, &lt;em&gt;IBCs&lt;/em&gt;. You want to do research that involves recombinant DNA and modern biotechnology, &lt;em&gt;including&lt;/em&gt; genome editing but not limited to it, you have to go first to your IBC, and they look and see what you’re doing to decide if there’s a danger there that you have not anticipated that requires special attention.&lt;/p&gt;



&lt;p&gt;If what you’re doing is going to get released into the environment or it’s going to be used to change an animal that’s going to be in the environment, then there are agencies that oversee the safety of our environment, predominantly the Environmental Protection Agency and the U.S. Department of Agriculture.&lt;/p&gt;



&lt;p&gt;If you’re working with humans and you’re doing medical therapies, like you’re doing the gene therapies that just have been developed for things like sickle cell anemia, then you have to go through a very elaborate regulatory process that’s overseen by the Food and Drug Administration and also seen locally at the research stages overseen by institutional review boards that make sure the people who are being recruited into research understand what they’re getting into, that they’re the right people to be recruited, etc.&lt;/p&gt;



&lt;p&gt;So we do have this kind of Jenga game …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yeah, sounds like it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; … of regulatory agencies. And on top of all that, most of this involves professionals who’ve had to be licensed in some way. There may be state laws specifically on licensing. If you are dealing with things that might cross national borders, there may be international treaties and agreements that cover this.&lt;/p&gt;



&lt;p&gt;And, of course, the insurance industry plays a big part because they decide whether or not what you’re doing is safe enough to be insured. So all of these things come together in a way that is not at all easy to understand if you’re not, kind of, working in the field. But the bottom-line thing to remember, the way to really think about it is, we don’t regulate genome editing; we regulate the things that use genome editing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, that makes a lot of sense. Actually, maybe just following up a little bit on this notion of a variety of different, particularly like government agencies being involved. You know, in this multi-stakeholder model, where do you see gaps today that need to be filled, some of the pros and cons to keep in mind, and, you know, just as we think about distributing these systems at a global level, like, what are some of the considerations you are keeping in mind on that front?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, certainly there are times where the way the statutes were written that govern the regulation of drugs or the regulation of foods did not anticipate this tremendous capacity we now have in the area of biotechnology generally or genome editing in particular. And so you can find that there are times where it feels a little bit ambiguous, and the agencies have to figure out how to apply their existing rules.&lt;/p&gt;



&lt;p&gt;So an example. If you’re going to make alterations in an animal, right, we have a system for regulating drugs, including veterinary drugs. But we didn’t have something that regulated genome editing of animals. But in a sense, genome editing of an animal is the same thing as using a veterinary drug. You’re trying to affect the animal’s physical constitution in some fashion.&lt;/p&gt;



&lt;p&gt;And it took a long time within the FDA to, sort of, work out how the regulation of veterinary drugs would apply if you think about the genetic construct that’s being used to alter the animal as the same thing as injecting a chemically based drug. And on that basis, they now know here’s the regulatory path—here are the tests you have to do; here are the permissions you have to do; here’s the surveillance you have to do after it goes on the market.&lt;/p&gt;



&lt;p&gt;Even there, sometimes, it was confusing. What happens when it’s not the kind of animal you’re thinking about when you think about animal drugs? Like, we think about pigs and dogs, but what about mosquitoes?&lt;/p&gt;



&lt;p&gt;Because there, you’re really thinking more about pests, and if you’re editing the mosquito so that it can’t, for example, transmit dengue fever, right, it feels more like a public health thing than it is a drug for the mosquito itself, and it, kind of, fell in between the agencies that possibly had jurisdiction. And it took a while for the USDA, the Department of Agriculture, and the Food and Drug Administration to work out an agreement about how they would share this responsibility. So you do get those kinds of areas in which you have at least ambiguity.&lt;/p&gt;



&lt;p&gt;We also have situations where frankly the fact that some things can move across national borders means you have to have a system for harmonizing or coordinating national rules. If you want to, for example, genetically engineer mosquitoes that can’t transmit dengue, mosquitoes have a tendency to fly. [LAUGHTER] And so … they can’t fly very far. That’s good. That actually makes it easier to control.&lt;/p&gt;



&lt;p&gt;But if you’re doing work that’s right near a border, then you have to be sure that the country next to you has the same rules for whether it’s permitted to do this and how to surveil what you’ve done in order to be sure that you got the results you wanted to get and no other results. And that also is an area where we have a lot of work to be done in terms of coordinating across government borders and harmonizing our rules.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I mean, you’ve touched on this a little bit, but there is such this striking balance between advancing technology, ensuring public safety, and sometimes, I think it feels just like you’re walking a tightrope where, you know, if we clamp down too hard, we’ll stifle innovation, and if we’re too lax, we risk some of these unintended consequences. And on a global scale like you just mentioned, as well. How has the field of genome editing found its balance?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It’s still being worked out, frankly, but it’s finding its balance application by application. So in the United States, we have two very different approaches on regulation of things that are going to go into the market.&lt;/p&gt;



&lt;p&gt;Some things can’t be marketed until they’ve gotten an approval from the government. So you come up with a new drug, you can’t sell that until it’s gone through FDA approval.&lt;/p&gt;



&lt;p&gt;On the other hand, for most foods that are made up of familiar kinds of things, you can go on the market, and it’s only after they’re on the market that the FDA can act to withdraw it if a problem arises. So basically, we have either &lt;em&gt;pre&lt;/em&gt;-market controls: you can’t go on without permission. Or &lt;em&gt;post&lt;/em&gt;-market controls: we can take you off the market &lt;em&gt;if&lt;/em&gt; a problem occurs.&lt;/p&gt;



&lt;p&gt;How do we decide which one is appropriate for a particular application? It’s based on our experience. New drugs typically are both less familiar than existing things on the market and also have a higher potential for injury if they, in fact, are not effective or they are, in fact, dangerous and toxic.&lt;/p&gt;



&lt;p&gt;If you have foods, even bioengineered foods, that are basically the same as foods that are already here, it can go on the market with notice but without a prior approval. But if you create something truly novel, then it has to go through a whole long process.&lt;/p&gt;



&lt;p&gt;And so that is the way that we make this balance. We look at the application area. And we’re just now seeing in the Department of Agriculture a new approach on some of the animal editing, again, to try and distinguish between things that are simply a more efficient way to make a familiar kind of animal variant and those things that are genuinely novel and to have a regulatory process that is more rigid the more unfamiliar it is and the more that we see a risk associated with it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I know we’re at the end of our time here and maybe just a quick kind of lightning-round of a question. For students, young scientists, lawyers, or maybe even entrepreneurs listening who are inspired by your work, what’s the single piece of advice you give them if they’re interested in policy, regulation, the ethical side of things in genomics or other fields?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; I’d say be a bio-optimist and read a lot of science fiction. Because it expands your imagination about what the world could be like. Is it going to be a world in which we’re now going to be growing our buildings instead of building them out of concrete?&lt;/p&gt;



&lt;p&gt;Is it going to be a world in which our plants will glow in the evening so we don’t need to be using batteries or electrical power from other sources but instead our environment is adapting to our needs?&lt;/p&gt;



&lt;p&gt;You know, expand your imagination with a sense of optimism about what could be and see ethics and regulation not as an obstacle but as a partner to bringing these things to fruition in a way that’s responsible and helpful to everyone.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, Alta, this has been just an absolute pleasure. So thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It was my pleasure. Thank you for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Now, I’m happy to bring in Daniel Kluttz. As a partner general manager in Microsoft’s Office of Responsible AI, Daniel leads the group’s Sensitive Uses and Emerging Technologies program.&lt;/p&gt;



&lt;p&gt;Daniel, it’s great to have you here. Thanks for coming in.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DANIEL KLUTTZ:&lt;/strong&gt; It’s great to be here, Kathleen.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. So maybe before we unpack Alta Charo’s insights, I’d love to just understand the elevator pitch here. What exactly is [the] Sensitive Uses and Emerging Tech program, and what was the impetus for establishing it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So the Sensitive Uses and Emerging Technologies program sits within our Office of Responsible AI at Microsoft. And inherent in the name, there are two real core functions. There’s the sensitive uses and emerging technologies. What does that mean?&lt;/p&gt;



&lt;p&gt;Sensitive uses, think of that as Microsoft’s internal consulting and oversight function for our higher-risk, most impactful AI system deployments. And so my team is a team of multidisciplinary experts who engages in sort of a white-glove-treatment sort of way with product teams at Microsoft that are designing, building, and deploying these higher-risk AI systems, and where that sort of consulting journey culminates is in a set of bespoke requirements tailored to the use case of that given system that really implement and apply our more standardized, generalized requirements that apply across the board.&lt;/p&gt;



&lt;p&gt;Then the emerging technologies function of my team faces a little bit further out, trying to look around corners to see what new and novel and emerging risks are coming out of new AI technologies with the idea that we work with our researchers, our engineering partners, and, of course, product leaders across the company to understand where Microsoft is going with those emerging technologies, and we’re developing sort of rapid, quick-fire early-steer guidance that implements our policies ahead of that formal internal policymaking process, which can take a bit of time. So it’s designed to, sort of, both afford that innovation speed that we like to optimize for at Microsoft but also integrate our responsible AI commitments and our AI principles into emerging product development.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That segues really nicely, actually, as we met with Professor Charo and she was, you know, talking about the field of genome editing and the governing at the application level. I’d love to just understand how similar or not is that to managing the risks of AI in our world?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. I mean, Professor Charo’s comments were music to my ears because, you know, where we make our bread and butter, so to speak, in our team is in applying to use cases. AI systems, especially in this era of generative AI, are almost inherently multi-use, dual use. And so what really matters is how you’re going to apply that more general-purpose technology. Who’s going to use it? In what domain is it going to be deployed? And then tailor that oversight to those use cases. Try to be risk proportionate.&lt;/p&gt;



&lt;p&gt;Professor Charo talked a little bit about this, but if it’s something that’s been done before and it’s just a new spin on an old thing, maybe we’re not so concerned about how closely we need to oversee and gate that application of that technology, whereas if it’s something new and novel or some new risk that might be posed by that technology, we take a little bit closer look and we are overseeing that in a more sort of high-touch way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Maybe following up on that, I mean, how do you define sensitive use or maybe like high-impact application, and once that’s labeled, what happens? Like, what kind of steps kick in from there?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So we have this Sensitive Uses program that’s been at Microsoft since 2019. I came to Microsoft in 2019 when we were starting this program in the Office of Responsible AI, and it had actually been incubated in Microsoft Research with our Aether community of colleagues who are experts in sociotechnical approaches to responsible AI, as well. Once we put it in the Office of Responsible AI, I came over. I came from academia. I was a researcher myself …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; At Berkeley, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; At Berkeley. That’s right. Yep. Sociologist by training and a lawyer in a past life. [LAUGHTER] But that has helped sort of bridge those fields for me.&lt;/p&gt;



&lt;p&gt;But Sensitive Uses, we force all of our teams when they’re envisioning their system design to think about, could the reasonably foreseeable use or &lt;em&gt;misuse&lt;/em&gt; of the system that they’re developing in practice result in three really major, sort of, risk types. One is, could that deployment result in a consequential impact on someone’s legal position or life opportunity? Another category we have is, could that foreseeable use or misuse result in significant psychological or physical injury or harm? And then the third really ties in with a longstanding commitment we’ve had to human rights at Microsoft. And so could that system in it’s reasonably foreseeable use or misuse result in human rights impacts and injurious consequences to folks along different dimensions of human rights? &lt;/p&gt;



&lt;p&gt;Once you decide, we have a process to reporting that project into my office, and we will triage that project, working with the product team, for example, and our Responsible AI Champs community, which are folks who are dispersed throughout the ecosystem at Microsoft and educated in our responsible AI program, and then determine, OK, is it in scope for our program? If it is, say, OK, we’re going to go along for that ride with you, and then we get into that whole sort of consulting arrangement that then culminates in this set of bespoke use-case-based requirements applying our AI principles.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s super fascinating. What are some of the approaches in the governance of genome editing are you maybe seeing happening in AI governance or maybe just, like, bubbling up in conversations around it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah, I mean, I think we’ve learned a lot from fields like genome editing that Professor Charo talked about and others. And again, it gets back to this, sort of, risk-proportionate-based approach. It’s a balancing test. It’s a tradeoff of trying to, sort of, foster innovation and really look for the beneficial uses of these technologies. I appreciated her speaking about that. What are the intended uses of the system, right? And then getting to, OK, how do we balance trying to, again, foster that innovation in a very fast-moving space, a pretty complex space, and a very unsettled space contrasting to other, sort of, professional fields or technological fields that have a long history and are relatively settled from an oversight and regulatory standpoint? This one is &lt;em&gt;not&lt;/em&gt;, and for good reason. It is still developing.&lt;/p&gt;



&lt;p&gt;And I think, you know, there are certain oversight and policy regimes that exist today that can be applied. Professor Charo talked about this, as well, where, you know, maybe you have certain policy and oversight regimes that, depending on how the application of that technology is applied, applies there versus some horizontal, overarching regulatory sort of framework. And I think that applies from an internal governance standpoint, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. It’s a great point. So what isn’t being explored from genome editing that, you know, maybe we think could be useful to AI governance, or as we think about the evolving frameworks …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; … what maybe we should be taking into account from what Professor Charo shared with us?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; So one of the things I’ve thought about and took from Professor Charo’s discussion was she had just this amazing way of framing up how genome editing regulation is done. And she said, you know, we don’t regulate genome editing; we regulate the things that &lt;em&gt;use&lt;/em&gt; genome editing. And while it’s not a one-to-one analogy with the AI space because we do have this sort of very general model level distinction versus application layer and even platform layer distinctions, I think it’s fair to say, you know, we don’t regulate AI applications writ large. We regulate the things that use AI in a very similar way. And that’s how we think of our internal policy and oversight process at Microsoft, as well.&lt;/p&gt;



&lt;p&gt;And maybe there are things that we regulated and oversaw internally at the first instance and the first time we saw it come through, and it graduates into more of a programmatic framework for how we manage that. So one good example of that is some of our higher-risk AI systems that we offer out of Azure at the platform level. When I say that, I mean APIs that you call that developers can then build their own applications on top of. We were really deep in evaluating and assessing mitigations on those platform systems in the first instance, but we also graduated them into what we call our Limited Access AI services program.&lt;/p&gt;



&lt;p&gt;And some of the things that Professor Charo discussed really resonated with me. You know, she had this moment where she was mentioning how, you know, you want to know who’s using your tools and how they’re being used. And it’s the same concepts. We want to have trust in our customers, we want to understand their use cases, and we want to apply technical controls that, sort of, force those use cases or give us signal post-deployment that use cases are being done in a way that may give us some level of concern, to reach out and understand what those use cases are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, you’re hitting on a great point. And I love this kind of layered approach that we’re taking and that Alta highlighted, as well. Maybe to double-click a little bit just on that post-market control and what we’re tracking, kind of, once things are out and being used by our customers. How do we take some of that deployment data and bring it back in to maybe even better inform upfront governance or just how we think about some of the frameworks that we’re operating in?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It’s a great question. The number one thing is for us at Microsoft, we want to know the voice of our customer. We want our customers to talk to us. We don’t want to just understand telemetry and data. But it’s really getting out there and understanding from our customers and not &lt;em&gt;just&lt;/em&gt; our customers. I would say our &lt;em&gt;stakeholders&lt;/em&gt; is maybe a better term because that includes civil society organizations. It includes governments. It includes all of these non, sort of, customer actors that we care about and that we’re trying to sort of optimize for, as well. It includes end users of our enterprise customers. If we can gather data about how our products are being used and trying to understand maybe areas that we didn’t foresee how customers or users might be using those things, and then we can tune those systems to better align with what both customers and users want but also our own AI principles and policies and programs.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Daniel, before coming to Microsoft, you led social science research and sociotechnical applications of AI-driven tech at Berkeley. What do you think some of the biggest challenges are in defining and maybe even just, kind of, measuring at, like, a societal level some of the impacts of AI more broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Measuring social phenomenon is a difficult thing. And one of the things that, as social scientists, you’re very interested in is scientifically observing and measuring social phenomena. Well, that sounds great. It sounds also very high level and jargony. What do we mean by that? You know, it’s very easy to say that you’re collecting data and you’re measuring, I don’t know, trust in AI, right? That’s a very fuzzy concept.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Right. Definitely.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It is a concept that we want to get to, but we have to unpack that, and we have to develop what we call &lt;em&gt;measurable constructs&lt;/em&gt;. What are the things that we might observe that could give us an indication toward what is a very fuzzy and general concept. And there’s challenges with that everywhere. And I’m extremely fortunate to work at Microsoft with some of the world’s leading sociotechnical researchers and some of these folks who are thinking about—you know, very steeped in measurement theory, literally PhDs in these fields—how to both measure &lt;em&gt;and&lt;/em&gt; allow for a scalable way to do that at a place the size of Microsoft. And that is trying to develop frameworks that are scalable and repeatable and put into our platform that then serves our product teams. Are we providing, as a platform, a service to those product teams that they can plug in and do their automated evaluations at scale as much as possible and then go back in over the top and do some of your more qualitative targeted testing and evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, makes a lot of sense. Before we close out, if you’re game for it, maybe we do a quick lightning round. Just 30-second answers here. Favorite real-world sensitive use case you’ve ever reviewed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Oh gosh. Wow, this is where I get to be the social scientist.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ: &lt;/strong&gt;It’s like, define &lt;em&gt;favorite&lt;/em&gt;, Kathleen. [LAUGHS] Most &lt;em&gt;memorable&lt;/em&gt;, most &lt;em&gt;painful&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Let’s do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; We’ll do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, I would say the most memorable project I worked on was when we rolled out the new Bing Chat, which is no longer called Bing Chat, because that was the first really big cross-company effort to deploy GPT-4, which was, you know, the next step up in AI innovation from our partners at OpenAI. And I really value working hand in hand with engineering teams and with researchers and that was us at our best and really sort of turbocharged the model that we have.&lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. What’s one of the most overused phrases that you have in your AI governance meetings?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Gosh. [LAUGHS] If I hear “We need to get aligned; we need to align on this more” …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; But, you know, it’s said for a reason. And I think it sort of speaks to that clever nature. That’s one that comes to mind.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s great. And then maybe, maybe last one. What are you most excited about in the next, I don’t know, let’s say three months? This world is moving so fast!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, the pace of innovation, as you just said, is just staggering. It is unbelievable. And sometimes it can feel overwhelming in my space. But what I am most excited about is how we are building up this Emerging … I mentioned this Emerging Technologies program in my team as a, sort of, formal program is relatively new. And I really enjoy being able to take a step back and think a little bit more about the future and a little bit more holistically. And I love working with engineering teams and sort of strategic visionaries who are thinking about what we’re doing a year from now or five years from now, or even 10 years from now, and I get to be a part of those conversations. And that really gives me energy and helps me … helps keep me grounded and not just dealing with the day to day, and, you know, various fire drills that you may run. It’s thinking strategically and having that foresight about what’s to come. And it’s exciting.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Great. Well, Daniel, just thanks so much for being here. I had such a wonderful discussion with you, and I think the thoughtfulness in our discussion today I hope resonates with our listeners. And again, thanks to Alta for setting the stage and sharing her really amazing, insightful thoughts here, as well. So thank you.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Thank you, Kathleen. I appreciate it. It’s been fun.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="illustration of R. Alta Charo, Kathleen Sullivan, and Daniel Kluttz for the Microsoft Research Podcast" class="wp-image-1142157" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/EP1-AI-TE_Hero_Feature_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;Generative AI presents a unique challenge and opportunity to reexamine governance practices for the responsible development, deployment, and use of AI. To advance thinking in this space, Microsoft has tapped into the experience and knowledge of experts across domains—from genome editing to cybersecurity—to investigate the role of testing and evaluation as a governance tool. &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry, &lt;/em&gt;hosted by Microsoft Research’s Kathleen Sullivan, explores what the technology industry and policymakers can learn from these fields and how that might help shape the course of AI development.&lt;/p&gt;



&lt;p&gt;In this episode, Alta Charo&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, emerita professor of law and bioethics at the University of Wisconsin–Madison, joins Sullivan for a conversation on the evolving landscape of genome editing and its regulatory implications. Drawing on decades of experience in biotechnology policy, Charo emphasizes the importance of distinguishing between hazards and risks and describes the field’s approach to regulating &lt;em&gt;applications &lt;/em&gt;of technology rather than the technology itself. The discussion also explores opportunities and challenges in biotech’s multi-agency oversight model and the role of international coordination. Later, Daniel Kluttz&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a partner general manager in Microsoft’s Office of Responsible AI, joins Sullivan to discuss how insights from genome editing could inform more nuanced and robust governance frameworks for emerging technologies like AI.&lt;/p&gt;











&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript-1"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KATHLEEN SULLIVAN:&lt;/strong&gt; Welcome to &lt;em&gt;AI Testing and Evaluation: Learnings from Science and Industry&lt;/em&gt;. I’m your host, Kathleen Sullivan.&lt;/p&gt;



&lt;p&gt;As generative AI continues to advance, Microsoft has gathered a range of experts—from genome editing to cybersecurity—to share how their fields approach evaluation and risk assessment. Our goal is to learn from their successes and their stumbles to move the science and practice of AI testing forward. In this series, we’ll explore how these insights might help guide the future of AI development, deployment, and responsible use.&lt;/p&gt;



&lt;p&gt;[MUSIC ENDS]&lt;/p&gt;



&lt;p&gt;Today I’m excited to welcome R. Alta Charo, the Warren P. Knowles Professor Emerita of Law and Bioethics at the University of Wisconsin–Madison, to explore testing and risk assessment in genome editing.&lt;/p&gt;



&lt;p&gt;Professor Charo has been at the forefront of biotechnology policy and governance for decades, advising former President Obama’s transition team on issues of medical research and public health, as well as serving as a senior policy advisor at the Food and Drug Administration. She consults on gene therapy and genome editing for various companies and organizations and has held positions on a number of advisory committees, including for the National Academy of Sciences. Her committee work has spanned women’s health, stem cell research, genome editing, biosecurity, and more.&lt;/p&gt;



&lt;p&gt;After our conversation with Professor Charo, we’ll hear from Daniel Kluttz, a partner general manager in Microsoft’s Office of Responsible AI, about what these insights from biotech regulation could mean for AI governance and risk assessment and his team’s work governing sensitive AI uses and emerging technologies.&lt;/p&gt;



&lt;p&gt;Alta, thank you so much for being here today. I’m a follower of your work and have really been looking forward to our conversation.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;&lt;strong&gt;ALTA CHARO:&lt;/strong&gt; It’s my pleasure. Thanks for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Alta, I’d love to begin by stepping back in time a bit before you became a leading figure in bioethics and legal policy. You’ve shared that your interest in science was really inspired by your brothers’ interest in the topic and that your upbringing really helped shape your perseverance and resilience. Can you talk to us about what put you on the path to law and policy?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, I think it’s true that many of us are strongly influenced by our families and certainly my family had, kind of, a science-y, techy orientation. My father was a refugee, you know, escaping the Nazis, and when he finally was able to start working in the United States, he took advantage of the G.I. Bill to learn how to repair televisions and radios, which were really just coming in in the 1950s. So he was, kind of, technically oriented.&lt;/p&gt;



&lt;p&gt;My mother retrained from being a talented amateur artist to becoming a math teacher, and not surprisingly, both my brothers began to aim toward things like engineering and chemistry and physics. And our form of entertainment was to watch PBS or &lt;em&gt;Star Trek&lt;/em&gt;. [LAUGHTER]&lt;/p&gt;



&lt;p&gt;And so the interest comes from that background coupled with, in the 1960s, this enormous surge of interest in the so-called nature-versus-nurture debate about the degree to which we are destined by our biology or shaped by our environments. It was a heady debate, and one that perfectly combined the two interests in politics and science.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; For listeners who are brand new to your field in genomic editing, can you give us what I’ll call a “90-second survey” of the space in perhaps plain language and why it’s important to have a framework for ensuring its responsible use.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, you know, genome editing is both very old and very new. At base, what we’re talking about is a way to either delete sections of the &lt;em&gt;genome&lt;/em&gt;, our collection of genes, or to add things or to alter what’s there. The goal is simply to be able to take what might not be healthy and make it healthy, whether it’s a plant, an animal, or a human.&lt;/p&gt;



&lt;p&gt;Many people have compared it to a word processor, where you can edit text by swapping things in and out. You could change the letter &lt;em&gt;g&lt;/em&gt; to the letter &lt;em&gt;h&lt;/em&gt; in every word, and in our genomes, you can do similar kinds of things.&lt;/p&gt;



&lt;p&gt;But because of this, we have a responsibility to make sure that whatever we change doesn’t become dangerous and that it doesn’t become socially disruptive. Now the earliest forms of genome editing were very inefficient, and so we didn’t worry that much. But with the advances that were spearheaded by people like Jennifer Doudna and Emmanuelle Charpentier, who won the Nobel Prize for their work in this area, genome editing has become much easier to do.&lt;/p&gt;



&lt;p&gt;It’s become more efficient. It doesn’t require as much sophisticated laboratory equipment. It’s moved from being something that only a few people can do to something that we’re going to be seeing in our junior high school biology labs. And that means you have to pay attention to who’s doing it, why are they doing it, what are they releasing, if anything, into the environment, what are they trying to sell, and is it honest and is it safe?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; How would you describe the risks, and are there, you know, sort of, specifically inherent risks in the technology itself, or do those risks really emerge only when it’s applied in certain contexts, like CRISPR in agriculture or CRISPR for human therapies?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, to answer that, I’m going to do something that may seem a little picky, even pedantic. [LAUGHTER] But I’m going to distinguish between hazards and risks. So there are certain intrinsic hazards. That is, there are things that can go wrong.&lt;/p&gt;



&lt;p&gt;You want to change one particular gene or one particular portion of a gene, and you might accidentally change something else, a so-called &lt;em&gt;off-target effect&lt;/em&gt;. Or you might change something in a gene expecting a certain effect but not necessarily anticipating that there’s going to be an interaction between what you changed and what was there, a &lt;em&gt;gene-gene interaction&lt;/em&gt;, that might have an unanticipated kind of result, a side effect essentially.&lt;/p&gt;



&lt;p&gt;So there are some intrinsic hazards, but risk is a hazard coupled with the probability that it’s going to actually create something harmful. And that really depends upon the application.&lt;/p&gt;



&lt;p&gt;If you are doing something that is making a change in a human being that is going to be a lifelong change, that enhances the significance of that hazard. It amplifies what I call the risk because if something goes wrong, then its consequences are greater.&lt;/p&gt;



&lt;p&gt;It may also be that in other settings, what you’re doing is going to have a much lower risk because you’re working with a more familiar substance, your predictive power is much greater, and it’s not going into a human or an animal or into the environment. So I think that you have to say that the risk &lt;em&gt;and&lt;/em&gt; the benefits, by the way, all are going to depend upon the particular application.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I think on this point of application, there’s many players involved in that, right. Like, we often hear about this puzzle of who’s actually responsible for ensuring safety and a reasonable balance between risks and benefits or hazards and benefits, to quote you. Is it the scientists, the biotech companies, government agencies? And then if you could touch upon, as well, maybe how does the nature of genome editing risks … how do those responsibilities get divvied up?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, in the 1980s, we had a very significant policy discussion about whether we should regulate the technology—no matter how it’s used or for whatever purpose—or if we should simply fold the technology in with all the other technologies that we currently have and regulate its applications the way we regulate applications generally. And we went for the second, the so-called &lt;em&gt;coordinated framework&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;So what we have in the United States is a system in which if you use genome editing in purely laboratory-based work, then you will be regulated the way we regulate laboratories.&lt;/p&gt;



&lt;p&gt;There’s also, at most universities because of the way the government works with this, something called Institutional Biosafety Committees, &lt;em&gt;IBCs&lt;/em&gt;. You want to do research that involves recombinant DNA and modern biotechnology, &lt;em&gt;including&lt;/em&gt; genome editing but not limited to it, you have to go first to your IBC, and they look and see what you’re doing to decide if there’s a danger there that you have not anticipated that requires special attention.&lt;/p&gt;



&lt;p&gt;If what you’re doing is going to get released into the environment or it’s going to be used to change an animal that’s going to be in the environment, then there are agencies that oversee the safety of our environment, predominantly the Environmental Protection Agency and the U.S. Department of Agriculture.&lt;/p&gt;



&lt;p&gt;If you’re working with humans and you’re doing medical therapies, like you’re doing the gene therapies that just have been developed for things like sickle cell anemia, then you have to go through a very elaborate regulatory process that’s overseen by the Food and Drug Administration and also seen locally at the research stages overseen by institutional review boards that make sure the people who are being recruited into research understand what they’re getting into, that they’re the right people to be recruited, etc.&lt;/p&gt;



&lt;p&gt;So we do have this kind of Jenga game …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yeah, sounds like it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; … of regulatory agencies. And on top of all that, most of this involves professionals who’ve had to be licensed in some way. There may be state laws specifically on licensing. If you are dealing with things that might cross national borders, there may be international treaties and agreements that cover this.&lt;/p&gt;



&lt;p&gt;And, of course, the insurance industry plays a big part because they decide whether or not what you’re doing is safe enough to be insured. So all of these things come together in a way that is not at all easy to understand if you’re not, kind of, working in the field. But the bottom-line thing to remember, the way to really think about it is, we don’t regulate genome editing; we regulate the things that use genome editing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, that makes a lot of sense. Actually, maybe just following up a little bit on this notion of a variety of different, particularly like government agencies being involved. You know, in this multi-stakeholder model, where do you see gaps today that need to be filled, some of the pros and cons to keep in mind, and, you know, just as we think about distributing these systems at a global level, like, what are some of the considerations you are keeping in mind on that front?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; Well, certainly there are times where the way the statutes were written that govern the regulation of drugs or the regulation of foods did not anticipate this tremendous capacity we now have in the area of biotechnology generally or genome editing in particular. And so you can find that there are times where it feels a little bit ambiguous, and the agencies have to figure out how to apply their existing rules.&lt;/p&gt;



&lt;p&gt;So an example. If you’re going to make alterations in an animal, right, we have a system for regulating drugs, including veterinary drugs. But we didn’t have something that regulated genome editing of animals. But in a sense, genome editing of an animal is the same thing as using a veterinary drug. You’re trying to affect the animal’s physical constitution in some fashion.&lt;/p&gt;



&lt;p&gt;And it took a long time within the FDA to, sort of, work out how the regulation of veterinary drugs would apply if you think about the genetic construct that’s being used to alter the animal as the same thing as injecting a chemically based drug. And on that basis, they now know here’s the regulatory path—here are the tests you have to do; here are the permissions you have to do; here’s the surveillance you have to do after it goes on the market.&lt;/p&gt;



&lt;p&gt;Even there, sometimes, it was confusing. What happens when it’s not the kind of animal you’re thinking about when you think about animal drugs? Like, we think about pigs and dogs, but what about mosquitoes?&lt;/p&gt;



&lt;p&gt;Because there, you’re really thinking more about pests, and if you’re editing the mosquito so that it can’t, for example, transmit dengue fever, right, it feels more like a public health thing than it is a drug for the mosquito itself, and it, kind of, fell in between the agencies that possibly had jurisdiction. And it took a while for the USDA, the Department of Agriculture, and the Food and Drug Administration to work out an agreement about how they would share this responsibility. So you do get those kinds of areas in which you have at least ambiguity.&lt;/p&gt;



&lt;p&gt;We also have situations where frankly the fact that some things can move across national borders means you have to have a system for harmonizing or coordinating national rules. If you want to, for example, genetically engineer mosquitoes that can’t transmit dengue, mosquitoes have a tendency to fly. [LAUGHTER] And so … they can’t fly very far. That’s good. That actually makes it easier to control.&lt;/p&gt;



&lt;p&gt;But if you’re doing work that’s right near a border, then you have to be sure that the country next to you has the same rules for whether it’s permitted to do this and how to surveil what you’ve done in order to be sure that you got the results you wanted to get and no other results. And that also is an area where we have a lot of work to be done in terms of coordinating across government borders and harmonizing our rules.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, I mean, you’ve touched on this a little bit, but there is such this striking balance between advancing technology, ensuring public safety, and sometimes, I think it feels just like you’re walking a tightrope where, you know, if we clamp down too hard, we’ll stifle innovation, and if we’re too lax, we risk some of these unintended consequences. And on a global scale like you just mentioned, as well. How has the field of genome editing found its balance?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It’s still being worked out, frankly, but it’s finding its balance application by application. So in the United States, we have two very different approaches on regulation of things that are going to go into the market.&lt;/p&gt;



&lt;p&gt;Some things can’t be marketed until they’ve gotten an approval from the government. So you come up with a new drug, you can’t sell that until it’s gone through FDA approval.&lt;/p&gt;



&lt;p&gt;On the other hand, for most foods that are made up of familiar kinds of things, you can go on the market, and it’s only after they’re on the market that the FDA can act to withdraw it if a problem arises. So basically, we have either &lt;em&gt;pre&lt;/em&gt;-market controls: you can’t go on without permission. Or &lt;em&gt;post&lt;/em&gt;-market controls: we can take you off the market &lt;em&gt;if&lt;/em&gt; a problem occurs.&lt;/p&gt;



&lt;p&gt;How do we decide which one is appropriate for a particular application? It’s based on our experience. New drugs typically are both less familiar than existing things on the market and also have a higher potential for injury if they, in fact, are not effective or they are, in fact, dangerous and toxic.&lt;/p&gt;



&lt;p&gt;If you have foods, even bioengineered foods, that are basically the same as foods that are already here, it can go on the market with notice but without a prior approval. But if you create something truly novel, then it has to go through a whole long process.&lt;/p&gt;



&lt;p&gt;And so that is the way that we make this balance. We look at the application area. And we’re just now seeing in the Department of Agriculture a new approach on some of the animal editing, again, to try and distinguish between things that are simply a more efficient way to make a familiar kind of animal variant and those things that are genuinely novel and to have a regulatory process that is more rigid the more unfamiliar it is and the more that we see a risk associated with it.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; I know we’re at the end of our time here and maybe just a quick kind of lightning-round of a question. For students, young scientists, lawyers, or maybe even entrepreneurs listening who are inspired by your work, what’s the single piece of advice you give them if they’re interested in policy, regulation, the ethical side of things in genomics or other fields?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; I’d say be a bio-optimist and read a lot of science fiction. Because it expands your imagination about what the world could be like. Is it going to be a world in which we’re now going to be growing our buildings instead of building them out of concrete?&lt;/p&gt;



&lt;p&gt;Is it going to be a world in which our plants will glow in the evening so we don’t need to be using batteries or electrical power from other sources but instead our environment is adapting to our needs?&lt;/p&gt;



&lt;p&gt;You know, expand your imagination with a sense of optimism about what could be and see ethics and regulation not as an obstacle but as a partner to bringing these things to fruition in a way that’s responsible and helpful to everyone.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. Well, Alta, this has been just an absolute pleasure. So thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHARO:&lt;/strong&gt; It was my pleasure. Thank you for having me.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Now, I’m happy to bring in Daniel Kluttz. As a partner general manager in Microsoft’s Office of Responsible AI, Daniel leads the group’s Sensitive Uses and Emerging Technologies program.&lt;/p&gt;



&lt;p&gt;Daniel, it’s great to have you here. Thanks for coming in.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DANIEL KLUTTZ:&lt;/strong&gt; It’s great to be here, Kathleen.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. So maybe before we unpack Alta Charo’s insights, I’d love to just understand the elevator pitch here. What exactly is [the] Sensitive Uses and Emerging Tech program, and what was the impetus for establishing it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So the Sensitive Uses and Emerging Technologies program sits within our Office of Responsible AI at Microsoft. And inherent in the name, there are two real core functions. There’s the sensitive uses and emerging technologies. What does that mean?&lt;/p&gt;



&lt;p&gt;Sensitive uses, think of that as Microsoft’s internal consulting and oversight function for our higher-risk, most impactful AI system deployments. And so my team is a team of multidisciplinary experts who engages in sort of a white-glove-treatment sort of way with product teams at Microsoft that are designing, building, and deploying these higher-risk AI systems, and where that sort of consulting journey culminates is in a set of bespoke requirements tailored to the use case of that given system that really implement and apply our more standardized, generalized requirements that apply across the board.&lt;/p&gt;



&lt;p&gt;Then the emerging technologies function of my team faces a little bit further out, trying to look around corners to see what new and novel and emerging risks are coming out of new AI technologies with the idea that we work with our researchers, our engineering partners, and, of course, product leaders across the company to understand where Microsoft is going with those emerging technologies, and we’re developing sort of rapid, quick-fire early-steer guidance that implements our policies ahead of that formal internal policymaking process, which can take a bit of time. So it’s designed to, sort of, both afford that innovation speed that we like to optimize for at Microsoft but also integrate our responsible AI commitments and our AI principles into emerging product development.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That segues really nicely, actually, as we met with Professor Charo and she was, you know, talking about the field of genome editing and the governing at the application level. I’d love to just understand how similar or not is that to managing the risks of AI in our world?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. I mean, Professor Charo’s comments were music to my ears because, you know, where we make our bread and butter, so to speak, in our team is in applying to use cases. AI systems, especially in this era of generative AI, are almost inherently multi-use, dual use. And so what really matters is how you’re going to apply that more general-purpose technology. Who’s going to use it? In what domain is it going to be deployed? And then tailor that oversight to those use cases. Try to be risk proportionate.&lt;/p&gt;



&lt;p&gt;Professor Charo talked a little bit about this, but if it’s something that’s been done before and it’s just a new spin on an old thing, maybe we’re not so concerned about how closely we need to oversee and gate that application of that technology, whereas if it’s something new and novel or some new risk that might be posed by that technology, we take a little bit closer look and we are overseeing that in a more sort of high-touch way.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Maybe following up on that, I mean, how do you define sensitive use or maybe like high-impact application, and once that’s labeled, what happens? Like, what kind of steps kick in from there?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah. So we have this Sensitive Uses program that’s been at Microsoft since 2019. I came to Microsoft in 2019 when we were starting this program in the Office of Responsible AI, and it had actually been incubated in Microsoft Research with our Aether community of colleagues who are experts in sociotechnical approaches to responsible AI, as well. Once we put it in the Office of Responsible AI, I came over. I came from academia. I was a researcher myself …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; At Berkeley, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; At Berkeley. That’s right. Yep. Sociologist by training and a lawyer in a past life. [LAUGHTER] But that has helped sort of bridge those fields for me.&lt;/p&gt;



&lt;p&gt;But Sensitive Uses, we force all of our teams when they’re envisioning their system design to think about, could the reasonably foreseeable use or &lt;em&gt;misuse&lt;/em&gt; of the system that they’re developing in practice result in three really major, sort of, risk types. One is, could that deployment result in a consequential impact on someone’s legal position or life opportunity? Another category we have is, could that foreseeable use or misuse result in significant psychological or physical injury or harm? And then the third really ties in with a longstanding commitment we’ve had to human rights at Microsoft. And so could that system in it’s reasonably foreseeable use or misuse result in human rights impacts and injurious consequences to folks along different dimensions of human rights? &lt;/p&gt;



&lt;p&gt;Once you decide, we have a process to reporting that project into my office, and we will triage that project, working with the product team, for example, and our Responsible AI Champs community, which are folks who are dispersed throughout the ecosystem at Microsoft and educated in our responsible AI program, and then determine, OK, is it in scope for our program? If it is, say, OK, we’re going to go along for that ride with you, and then we get into that whole sort of consulting arrangement that then culminates in this set of bespoke use-case-based requirements applying our AI principles.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s super fascinating. What are some of the approaches in the governance of genome editing are you maybe seeing happening in AI governance or maybe just, like, bubbling up in conversations around it?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah, I mean, I think we’ve learned a lot from fields like genome editing that Professor Charo talked about and others. And again, it gets back to this, sort of, risk-proportionate-based approach. It’s a balancing test. It’s a tradeoff of trying to, sort of, foster innovation and really look for the beneficial uses of these technologies. I appreciated her speaking about that. What are the intended uses of the system, right? And then getting to, OK, how do we balance trying to, again, foster that innovation in a very fast-moving space, a pretty complex space, and a very unsettled space contrasting to other, sort of, professional fields or technological fields that have a long history and are relatively settled from an oversight and regulatory standpoint? This one is &lt;em&gt;not&lt;/em&gt;, and for good reason. It is still developing.&lt;/p&gt;



&lt;p&gt;And I think, you know, there are certain oversight and policy regimes that exist today that can be applied. Professor Charo talked about this, as well, where, you know, maybe you have certain policy and oversight regimes that, depending on how the application of that technology is applied, applies there versus some horizontal, overarching regulatory sort of framework. And I think that applies from an internal governance standpoint, as well.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah. It’s a great point. So what isn’t being explored from genome editing that, you know, maybe we think could be useful to AI governance, or as we think about the evolving frameworks …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; … what maybe we should be taking into account from what Professor Charo shared with us?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; So one of the things I’ve thought about and took from Professor Charo’s discussion was she had just this amazing way of framing up how genome editing regulation is done. And she said, you know, we don’t regulate genome editing; we regulate the things that &lt;em&gt;use&lt;/em&gt; genome editing. And while it’s not a one-to-one analogy with the AI space because we do have this sort of very general model level distinction versus application layer and even platform layer distinctions, I think it’s fair to say, you know, we don’t regulate AI applications writ large. We regulate the things that use AI in a very similar way. And that’s how we think of our internal policy and oversight process at Microsoft, as well.&lt;/p&gt;



&lt;p&gt;And maybe there are things that we regulated and oversaw internally at the first instance and the first time we saw it come through, and it graduates into more of a programmatic framework for how we manage that. So one good example of that is some of our higher-risk AI systems that we offer out of Azure at the platform level. When I say that, I mean APIs that you call that developers can then build their own applications on top of. We were really deep in evaluating and assessing mitigations on those platform systems in the first instance, but we also graduated them into what we call our Limited Access AI services program.&lt;/p&gt;



&lt;p&gt;And some of the things that Professor Charo discussed really resonated with me. You know, she had this moment where she was mentioning how, you know, you want to know who’s using your tools and how they’re being used. And it’s the same concepts. We want to have trust in our customers, we want to understand their use cases, and we want to apply technical controls that, sort of, force those use cases or give us signal post-deployment that use cases are being done in a way that may give us some level of concern, to reach out and understand what those use cases are.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, you’re hitting on a great point. And I love this kind of layered approach that we’re taking and that Alta highlighted, as well. Maybe to double-click a little bit just on that post-market control and what we’re tracking, kind of, once things are out and being used by our customers. How do we take some of that deployment data and bring it back in to maybe even better inform upfront governance or just how we think about some of the frameworks that we’re operating in?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It’s a great question. The number one thing is for us at Microsoft, we want to know the voice of our customer. We want our customers to talk to us. We don’t want to just understand telemetry and data. But it’s really getting out there and understanding from our customers and not &lt;em&gt;just&lt;/em&gt; our customers. I would say our &lt;em&gt;stakeholders&lt;/em&gt; is maybe a better term because that includes civil society organizations. It includes governments. It includes all of these non, sort of, customer actors that we care about and that we’re trying to sort of optimize for, as well. It includes end users of our enterprise customers. If we can gather data about how our products are being used and trying to understand maybe areas that we didn’t foresee how customers or users might be using those things, and then we can tune those systems to better align with what both customers and users want but also our own AI principles and policies and programs.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Daniel, before coming to Microsoft, you led social science research and sociotechnical applications of AI-driven tech at Berkeley. What do you think some of the biggest challenges are in defining and maybe even just, kind of, measuring at, like, a societal level some of the impacts of AI more broadly?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Measuring social phenomenon is a difficult thing. And one of the things that, as social scientists, you’re very interested in is scientifically observing and measuring social phenomena. Well, that sounds great. It sounds also very high level and jargony. What do we mean by that? You know, it’s very easy to say that you’re collecting data and you’re measuring, I don’t know, trust in AI, right? That’s a very fuzzy concept.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Right. Definitely.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; It is a concept that we want to get to, but we have to unpack that, and we have to develop what we call &lt;em&gt;measurable constructs&lt;/em&gt;. What are the things that we might observe that could give us an indication toward what is a very fuzzy and general concept. And there’s challenges with that everywhere. And I’m extremely fortunate to work at Microsoft with some of the world’s leading sociotechnical researchers and some of these folks who are thinking about—you know, very steeped in measurement theory, literally PhDs in these fields—how to both measure &lt;em&gt;and&lt;/em&gt; allow for a scalable way to do that at a place the size of Microsoft. And that is trying to develop frameworks that are scalable and repeatable and put into our platform that then serves our product teams. Are we providing, as a platform, a service to those product teams that they can plug in and do their automated evaluations at scale as much as possible and then go back in over the top and do some of your more qualitative targeted testing and evaluations.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah, makes a lot of sense. Before we close out, if you’re game for it, maybe we do a quick lightning round. Just 30-second answers here. Favorite real-world sensitive use case you’ve ever reviewed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Oh gosh. Wow, this is where I get to be the social scientist.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Yes.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ: &lt;/strong&gt;It’s like, define &lt;em&gt;favorite&lt;/em&gt;, Kathleen. [LAUGHS] Most &lt;em&gt;memorable&lt;/em&gt;, most &lt;em&gt;painful&lt;/em&gt;.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Let’s do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; We’ll do most memorable.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, I would say the most memorable project I worked on was when we rolled out the new Bing Chat, which is no longer called Bing Chat, because that was the first really big cross-company effort to deploy GPT-4, which was, you know, the next step up in AI innovation from our partners at OpenAI. And I really value working hand in hand with engineering teams and with researchers and that was us at our best and really sort of turbocharged the model that we have.&lt;s&gt;&lt;/s&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Wonderful. What’s one of the most overused phrases that you have in your AI governance meetings?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Gosh. [LAUGHS] If I hear “We need to get aligned; we need to align on this more” …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; [LAUGHS] Right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; But, you know, it’s said for a reason. And I think it sort of speaks to that clever nature. That’s one that comes to mind.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; That’s great. And then maybe, maybe last one. What are you most excited about in the next, I don’t know, let’s say three months? This world is moving so fast!&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; You know, the pace of innovation, as you just said, is just staggering. It is unbelievable. And sometimes it can feel overwhelming in my space. But what I am most excited about is how we are building up this Emerging … I mentioned this Emerging Technologies program in my team as a, sort of, formal program is relatively new. And I really enjoy being able to take a step back and think a little bit more about the future and a little bit more holistically. And I love working with engineering teams and sort of strategic visionaries who are thinking about what we’re doing a year from now or five years from now, or even 10 years from now, and I get to be a part of those conversations. And that really gives me energy and helps me … helps keep me grounded and not just dealing with the day to day, and, you know, various fire drills that you may run. It’s thinking strategically and having that foresight about what’s to come. And it’s exciting.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN:&lt;/strong&gt; Great. Well, Daniel, just thanks so much for being here. I had such a wonderful discussion with you, and I think the thoughtfulness in our discussion today I hope resonates with our listeners. And again, thanks to Alta for setting the stage and sharing her really amazing, insightful thoughts here, as well. So thank you.&lt;/p&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KLUTTZ:&lt;/strong&gt; Thank you, Kathleen. I appreciate it. It’s been fun.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SULLIVAN: &lt;/strong&gt;And to our listeners, thanks for tuning in. You can find resources related to this podcast in the show notes. And if you want to learn more about how Microsoft approaches AI governance, you can visit microsoft.com/RAI.&lt;/p&gt;



&lt;p&gt;See you next time!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/ai-testing-and-evaluation-learnings-from-genome-editing/</guid><pubDate>Mon, 30 Jun 2025 16:00:17 +0000</pubDate></item><item><title>Google embraces AI in the classroom with new Gemini tools for educators, chatbots for students, and more (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/google-embraces-ai-in-the-classroom-with-new-gemini-tools-for-educators-chatbots-for-students-and-more/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Monday announced a series of updates intended to bring its Gemini AI and other AI-powered tools deeper into the classroom. At the ISTE edtech conference, the tech giant introduced more than 30 AI tools for educators, a version of the Gemini app built for education, expanded access to its collaborative video creation app Google Vids, and other tools for managed Chromebooks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The updates represent a major AI push in the edtech space, where educators are already struggling to adapt to how AI tools, like AI chatbots and startups that promise to help you “cheat on everything,” are making their way into the learning environment. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;School-aged kids and teens today are more likely to ask ChatGPT for help with their homework (or to even do it for them) than they are to ask a teacher to explain the concepts again. In higher ed, meanwhile, colleges are wrestling with whether or not plagiarism detectors can even identify AI-written content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid this disruption, Google is charging ahead with AI tools, saying it thinks that “responsible AI” can help drive “more engaging and personalized learning experiences,” when used in conjunction with human-led teaching.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023324" height="390" src="https://techcrunch.com/wp-content/uploads/2025/06/ai-tools-for-educators.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Since announcing its plans to bring Gemini to the classroom last year, Google on Monday said that its Gemini AI suite for educators is now available for free to all Google Workspace for Education accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This includes over 30 new features, like the ability for teachers to brainstorm ideas, generate lesson plans, and personalize content for students using AI technology.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023320" height="391" src="https://techcrunch.com/wp-content/uploads/2025/06/lesson-plan.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Over the next several months, Google will give teachers the ability to create interactive study guides using the AI research tool Notebook LM, along with their classroom materials.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Teachers can also create custom versions of the Gemini AI called “Gems,” which will work as AI experts that help students who need extra support or want to better understand the subject.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is essentially just taking an activity that students are already doing — asking an AI chatbot to explain a topic or answer questions — and redirecting that activity back to Google’s own AI technology, where it’s specifically been trained on the teacher’s own classroom materials.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023323" height="378" src="https://techcrunch.com/wp-content/uploads/2025/06/gemini-chatbot-classroom.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, teachers will also be able to offer students real-time support for the AI-powered reading buddy when using the Read Along in Classroom tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google is expanding basic access to its AI-powered video creator, Google Vids, as well, to make it available to all Google Workspace for Education users. Teachers can use the tool to make instructional videos, while students can use Vids for things like book reports or other assignments.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Google Vids" class="wp-image-3023322" height="405" src="https://techcrunch.com/wp-content/uploads/2025/06/vids.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also rolling out a series of new features designed to track student progress against learning standards and skills, view analytics on student performance and engagement, better secure Gemini user data and data in Gmail, manage who has access to AI tools like Gemini and Notebook LM, have better control over Google Meet waiting rooms, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, along with a handful of updates for managed Chromebooks, Google introduced a new teaching mode called Class tools. This allows teachers to connect directly with their students via Google Classroom and share content to the kids’ screens, like videos, articles, slides, and quizzes. These tools can be adapted to the student’s own language, if need be, and are designed to keep kids focused on learning by restricting browsing to specific tabs.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Monday announced a series of updates intended to bring its Gemini AI and other AI-powered tools deeper into the classroom. At the ISTE edtech conference, the tech giant introduced more than 30 AI tools for educators, a version of the Gemini app built for education, expanded access to its collaborative video creation app Google Vids, and other tools for managed Chromebooks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The updates represent a major AI push in the edtech space, where educators are already struggling to adapt to how AI tools, like AI chatbots and startups that promise to help you “cheat on everything,” are making their way into the learning environment. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;School-aged kids and teens today are more likely to ask ChatGPT for help with their homework (or to even do it for them) than they are to ask a teacher to explain the concepts again. In higher ed, meanwhile, colleges are wrestling with whether or not plagiarism detectors can even identify AI-written content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amid this disruption, Google is charging ahead with AI tools, saying it thinks that “responsible AI” can help drive “more engaging and personalized learning experiences,” when used in conjunction with human-led teaching.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023324" height="390" src="https://techcrunch.com/wp-content/uploads/2025/06/ai-tools-for-educators.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Since announcing its plans to bring Gemini to the classroom last year, Google on Monday said that its Gemini AI suite for educators is now available for free to all Google Workspace for Education accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This includes over 30 new features, like the ability for teachers to brainstorm ideas, generate lesson plans, and personalize content for students using AI technology.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023320" height="391" src="https://techcrunch.com/wp-content/uploads/2025/06/lesson-plan.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Over the next several months, Google will give teachers the ability to create interactive study guides using the AI research tool Notebook LM, along with their classroom materials.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Teachers can also create custom versions of the Gemini AI called “Gems,” which will work as AI experts that help students who need extra support or want to better understand the subject.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is essentially just taking an activity that students are already doing — asking an AI chatbot to explain a topic or answer questions — and redirecting that activity back to Google’s own AI technology, where it’s specifically been trained on the teacher’s own classroom materials.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3023323" height="378" src="https://techcrunch.com/wp-content/uploads/2025/06/gemini-chatbot-classroom.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Soon, teachers will also be able to offer students real-time support for the AI-powered reading buddy when using the Read Along in Classroom tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google is expanding basic access to its AI-powered video creator, Google Vids, as well, to make it available to all Google Workspace for Education users. Teachers can use the tool to make instructional videos, while students can use Vids for things like book reports or other assignments.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Google Vids" class="wp-image-3023322" height="405" src="https://techcrunch.com/wp-content/uploads/2025/06/vids.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also rolling out a series of new features designed to track student progress against learning standards and skills, view analytics on student performance and engagement, better secure Gemini user data and data in Gmail, manage who has access to AI tools like Gemini and Notebook LM, have better control over Google Meet waiting rooms, and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, along with a handful of updates for managed Chromebooks, Google introduced a new teaching mode called Class tools. This allows teachers to connect directly with their students via Google Classroom and share content to the kids’ screens, like videos, articles, slides, and quizzes. These tools can be adapted to the student’s own language, if need be, and are designed to keep kids focused on learning by restricting browsing to specific tabs.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/google-embraces-ai-in-the-classroom-with-new-gemini-tools-for-educators-chatbots-for-students-and-more/</guid><pubDate>Mon, 30 Jun 2025 16:44:28 +0000</pubDate></item><item><title>Congress might block state AI laws for five years — here’s what it means (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/congress-might-block-state-ai-laws-for-five-years-heres-what-it-means/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A federal proposal that would ban states and local governments from regulating AI for five years could soon be signed into law, as Sen. Ted Cruz (R-TX) and other lawmakers work to secure its inclusion into a GOP megabill — which the Senate is voting on Monday — ahead of a key July 4 deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those in favor — including OpenAI’s Sam Altman, Anduril’s Palmer Luckey, and a16z’s Marc Andreessen — argue that a “patchwork” of AI regulation among states would stifle American innovation at a time when the race to beat China is heating up.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Critics include most Democrats, many Republicans, Anthropic’s CEO Dario Amodei, labor groups, AI safety nonprofits, and consumer rights advocates. They warn that this provision would block states from passing laws that protect consumers from AI harms and would effectively allow powerful AI firms to operate without much oversight or accountability.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, a group of 17 Republican governors wrote to Senate Majority Leader John Thune, who has advocated for a “light touch” approach to AI regulation, and House Speaker Mike Johnson calling for the so-called “AI moratorium” to be stripped from the budget reconciliation bill, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The provision was squeezed into the bill, nicknamed the “Big Beautiful Bill,” in May. It was initially designed to prohibit states from “[enforcing] any law or regulation regulating [AI] models, [AI] systems, or automated decision systems” for a decade.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, over the weekend, Cruz and Sen. Marsha Blackburn (R-TN), who has also criticized the bill, agreed to shorten the pause on state-based AI regulation to five years. The new language also attempts to exempt laws addressing child sexual abuse materials, children’s online safety, and an individual’s rights to their name, likeness, voice, and image. However, the amendment says the laws must not place an “undue or disproportionate burden” on AI systems — legal experts are unsure how this would impact state AI laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a measure could preempt state AI laws that have already passed, such as California’s AB 2013, which requires companies to reveal the data used to train AI systems, and Tennessee’s ELVIS Act, which protects musicians and creators from AI-generated impersonations.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;But the moratorium’s reach extends far beyond these examples. Public Citizen has compiled a database of AI-related laws that could be affected by the moratorium. The database reveals that many states have passed laws that overlap, which could actually make it easier for AI companies to navigate the “patchwork.” For example, Alabama, Arizona, California, Delaware, Hawaii, Indiana, Montana, and Texas have criminalized or created civil liability for distributing deceptive AI-generated media meant to influence elections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI moratorium also threatens several noteworthy AI safety bills awaiting signature, including New York’s RAISE Act, which would require large AI labs nationwide to publish thorough safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting the moratorium into a budget bill has required some creative maneuvering. Because provisions in a budget bill must have a direct fiscal impact, Cruz revised the proposal in June to make compliance with the AI moratorium a condition for states to receive funds from the $42 billion Broadband Equity Access and Deployment (BEAD) program.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cruz released another revision last week, which he says ties the requirement only to the new $500 million in BEAD funding included in the bill — a separate, additional pot of money. However, close examination of the revised text finds the language also threatens to pull already obligated broadband funding from states that don’t comply.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sen. Maria Cantwell (D-WA) previously criticized Cruz’s reconciliation language, claiming the provision “forces states receiving BEAD funding to choose between expanding broadband or protecting consumers from AI harms for ten years.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2971438" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198164456.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sam Altman, co-founder and CEO of OpenAI, speaks in Berlin on February 7, 2025. Altman said he predicts the pace of artificial intelligence’s usefulness in the next two years will accelerate markedly compared to the last two years.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sean Gallup / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As of Monday, the Senate is engaged in a vote-a-rama — a series of rapid votes on the budget bill’s full slate of amendments. The new language that Cruz and Blackburn agreed on will be included in a broader amendment, one that Republicans are expected to pass on a party line vote. Senators will also likely vote on a Democrat-backed amendment to strip the entire section, sources familiar with the matter told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chris Lehane, chief global affairs officer at OpenAI, said in a LinkedIn post that the “current patchwork approach to regulating AI isn’t working and will continue to worsen if we stay on this path.” He said this would have “serious implications” for the U.S. as it races to establish AI dominance over China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While not someone I’d typically quote, Vladimir Putin has said that whoever prevails will determine the direction of the world going forward,” Lehane wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman shared similar sentiments last week during a live recording of the tech podcast Hard Fork. He said while he believes some adaptive regulation that addresses the biggest existential risks of AI would be good, “a patchwork across the states would probably be a real mess and very difficult to offer services under.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also questioned whether policymakers were equipped to handle regulating AI when the technology moves so quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I worry that if … we kick off a three-year process to write something that’s very detailed and covers a lot of cases, the technology will just move very quickly,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a closer look at existing state laws tells a different story. Most state AI laws that exist today aren’t far-reaching; they focus on protecting consumers and individuals from specific harms, like deepfakes, fraud, discrimination, and privacy violations. They target the use of AI in contexts like hiring, housing, credit, healthcare, and elections, and include disclosure requirements and algorithmic bias safeguards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked Lehane and other members of OpenAI’s team if they could name any current state laws that have hindered the tech giant’s ability to progress its technology and release new models. We also asked why navigating different state laws would be considered too complex, given OpenAI’s progress on technologies that may automate a wide range of white-collar jobs in the coming years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch asked similar questions of Meta, Google, Amazon, and Apple, but has not received any answers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-case-against-preemption"&gt;&lt;strong&gt;The case against preemption&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Dario Amodei" class="wp-image-3011230" height="510" src="https://techcrunch.com/wp-content/uploads/2025/05/Dario.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Dario Amodei&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maxwell Zeff / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The patchwork argument is something that we have heard since the beginning of consumer advocacy time,” Emily Peterson-Cassin, corporate power director at internet activist group Demand Progress, told TechCrunch. “But the fact is that companies comply with different state regulations all the time. The most powerful companies in the world? Yes. Yes, you can.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opponents and cynics alike say the AI moratorium isn’t about innovation — it’s about sidestepping oversight. While many states have passed regulation around AI, Congress, which moves notoriously slowly, has passed zero laws regulating AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the federal government wants to pass strong AI safety legislation, and then preempt the states’ ability to do that, I’d be the first to be very excited about that,” said Nathan Calvin, VP of state affairs at the nonprofit Encode — which has sponsored several state AI safety bills — in an interview. “Instead, [the AI moratorium] takes away all leverage, and any ability, to force AI companies to come to the negotiating table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the loudest critics of the proposal is Anthropic CEO Dario Amodei. In an opinion piece for The New York Times, Amodei said “a 10-year moratorium is far too blunt an instrument.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is advancing too head-spinningly fast,” he wrote. “I believe that these systems could change the world, fundamentally, within two years; in 10 years, all bets are off. Without a clear plan for a federal response, a moratorium would give us the worst of both worlds — no ability for states to act, and no national policy as a backstop.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He argued that instead of prescribing how companies should release their products, the government should work with AI companies to create a transparency standard for how companies share information about their practices and model capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The opposition isn’t limited to Democrats. There’s been notable opposition to the AI moratorium from Republicans who argue the provision stomps on the GOP’s traditional support for states’ rights, even though it was crafted by prominent Republicans like Cruz and Rep. Jay Obernolte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These Republican critics include Sen. Josh Hawley (R-MO), who is concerned about states’ rights and is working with Democrats to strip it from the bill. Blackburn also criticized the provision, arguing that states need to protect their citizens and creative industries from AI harms. Rep. Marjorie Taylor Greene (R-GA) even went so far as to say she would oppose the entire budget if the moratorium remains.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-do-americans-want"&gt;&lt;strong&gt;What do Americans want?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Republicans like Cruz and Senate Majority Leader John Thune say they want a “light touch” approach to AI governance. Cruz also said in a statement that “every American deserves a voice in shaping” the future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, a recent Pew Research survey found that most Americans seem to want more regulation around AI. The survey found that about 60% of U.S. adults and 56% of AI experts say they’re more concerned that the U.S. government won’t go far enough in regulating AI than they are that the government will go too far. Americans also largely aren’t confident that the government will regulate AI effectively, and they are skeptical of industry efforts around responsible AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated June 30 to reflect amendments to the bill, new reporting on the Senate’s timeline to vote on the bill, and fresh Republican opposition to the AI moratorium.  &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A federal proposal that would ban states and local governments from regulating AI for five years could soon be signed into law, as Sen. Ted Cruz (R-TX) and other lawmakers work to secure its inclusion into a GOP megabill — which the Senate is voting on Monday — ahead of a key July 4 deadline.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those in favor — including OpenAI’s Sam Altman, Anduril’s Palmer Luckey, and a16z’s Marc Andreessen — argue that a “patchwork” of AI regulation among states would stifle American innovation at a time when the race to beat China is heating up.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Critics include most Democrats, many Republicans, Anthropic’s CEO Dario Amodei, labor groups, AI safety nonprofits, and consumer rights advocates. They warn that this provision would block states from passing laws that protect consumers from AI harms and would effectively allow powerful AI firms to operate without much oversight or accountability.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, a group of 17 Republican governors wrote to Senate Majority Leader John Thune, who has advocated for a “light touch” approach to AI regulation, and House Speaker Mike Johnson calling for the so-called “AI moratorium” to be stripped from the budget reconciliation bill, per Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The provision was squeezed into the bill, nicknamed the “Big Beautiful Bill,” in May. It was initially designed to prohibit states from “[enforcing] any law or regulation regulating [AI] models, [AI] systems, or automated decision systems” for a decade.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, over the weekend, Cruz and Sen. Marsha Blackburn (R-TN), who has also criticized the bill, agreed to shorten the pause on state-based AI regulation to five years. The new language also attempts to exempt laws addressing child sexual abuse materials, children’s online safety, and an individual’s rights to their name, likeness, voice, and image. However, the amendment says the laws must not place an “undue or disproportionate burden” on AI systems — legal experts are unsure how this would impact state AI laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Such a measure could preempt state AI laws that have already passed, such as California’s AB 2013, which requires companies to reveal the data used to train AI systems, and Tennessee’s ELVIS Act, which protects musicians and creators from AI-generated impersonations.&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;But the moratorium’s reach extends far beyond these examples. Public Citizen has compiled a database of AI-related laws that could be affected by the moratorium. The database reveals that many states have passed laws that overlap, which could actually make it easier for AI companies to navigate the “patchwork.” For example, Alabama, Arizona, California, Delaware, Hawaii, Indiana, Montana, and Texas have criminalized or created civil liability for distributing deceptive AI-generated media meant to influence elections.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI moratorium also threatens several noteworthy AI safety bills awaiting signature, including New York’s RAISE Act, which would require large AI labs nationwide to publish thorough safety reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Getting the moratorium into a budget bill has required some creative maneuvering. Because provisions in a budget bill must have a direct fiscal impact, Cruz revised the proposal in June to make compliance with the AI moratorium a condition for states to receive funds from the $42 billion Broadband Equity Access and Deployment (BEAD) program.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cruz released another revision last week, which he says ties the requirement only to the new $500 million in BEAD funding included in the bill — a separate, additional pot of money. However, close examination of the revised text finds the language also threatens to pull already obligated broadband funding from states that don’t comply.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sen. Maria Cantwell (D-WA) previously criticized Cruz’s reconciliation language, claiming the provision “forces states receiving BEAD funding to choose between expanding broadband or protecting consumers from AI harms for ten years.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-2971438" height="454" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198164456.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Sam Altman, co-founder and CEO of OpenAI, speaks in Berlin on February 7, 2025. Altman said he predicts the pace of artificial intelligence’s usefulness in the next two years will accelerate markedly compared to the last two years.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Sean Gallup / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As of Monday, the Senate is engaged in a vote-a-rama — a series of rapid votes on the budget bill’s full slate of amendments. The new language that Cruz and Blackburn agreed on will be included in a broader amendment, one that Republicans are expected to pass on a party line vote. Senators will also likely vote on a Democrat-backed amendment to strip the entire section, sources familiar with the matter told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chris Lehane, chief global affairs officer at OpenAI, said in a LinkedIn post that the “current patchwork approach to regulating AI isn’t working and will continue to worsen if we stay on this path.” He said this would have “serious implications” for the U.S. as it races to establish AI dominance over China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“While not someone I’d typically quote, Vladimir Putin has said that whoever prevails will determine the direction of the world going forward,” Lehane wrote.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman shared similar sentiments last week during a live recording of the tech podcast Hard Fork. He said while he believes some adaptive regulation that addresses the biggest existential risks of AI would be good, “a patchwork across the states would probably be a real mess and very difficult to offer services under.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also questioned whether policymakers were equipped to handle regulating AI when the technology moves so quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I worry that if … we kick off a three-year process to write something that’s very detailed and covers a lot of cases, the technology will just move very quickly,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a closer look at existing state laws tells a different story. Most state AI laws that exist today aren’t far-reaching; they focus on protecting consumers and individuals from specific harms, like deepfakes, fraud, discrimination, and privacy violations. They target the use of AI in contexts like hiring, housing, credit, healthcare, and elections, and include disclosure requirements and algorithmic bias safeguards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked Lehane and other members of OpenAI’s team if they could name any current state laws that have hindered the tech giant’s ability to progress its technology and release new models. We also asked why navigating different state laws would be considered too complex, given OpenAI’s progress on technologies that may automate a wide range of white-collar jobs in the coming years.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch asked similar questions of Meta, Google, Amazon, and Apple, but has not received any answers.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-case-against-preemption"&gt;&lt;strong&gt;The case against preemption&lt;/strong&gt;&lt;/h2&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Dario Amodei" class="wp-image-3011230" height="510" src="https://techcrunch.com/wp-content/uploads/2025/05/Dario.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Dario Amodei&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Maxwell Zeff / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“The patchwork argument is something that we have heard since the beginning of consumer advocacy time,” Emily Peterson-Cassin, corporate power director at internet activist group Demand Progress, told TechCrunch. “But the fact is that companies comply with different state regulations all the time. The most powerful companies in the world? Yes. Yes, you can.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Opponents and cynics alike say the AI moratorium isn’t about innovation — it’s about sidestepping oversight. While many states have passed regulation around AI, Congress, which moves notoriously slowly, has passed zero laws regulating AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If the federal government wants to pass strong AI safety legislation, and then preempt the states’ ability to do that, I’d be the first to be very excited about that,” said Nathan Calvin, VP of state affairs at the nonprofit Encode — which has sponsored several state AI safety bills — in an interview. “Instead, [the AI moratorium] takes away all leverage, and any ability, to force AI companies to come to the negotiating table.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the loudest critics of the proposal is Anthropic CEO Dario Amodei. In an opinion piece for The New York Times, Amodei said “a 10-year moratorium is far too blunt an instrument.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is advancing too head-spinningly fast,” he wrote. “I believe that these systems could change the world, fundamentally, within two years; in 10 years, all bets are off. Without a clear plan for a federal response, a moratorium would give us the worst of both worlds — no ability for states to act, and no national policy as a backstop.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He argued that instead of prescribing how companies should release their products, the government should work with AI companies to create a transparency standard for how companies share information about their practices and model capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The opposition isn’t limited to Democrats. There’s been notable opposition to the AI moratorium from Republicans who argue the provision stomps on the GOP’s traditional support for states’ rights, even though it was crafted by prominent Republicans like Cruz and Rep. Jay Obernolte.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These Republican critics include Sen. Josh Hawley (R-MO), who is concerned about states’ rights and is working with Democrats to strip it from the bill. Blackburn also criticized the provision, arguing that states need to protect their citizens and creative industries from AI harms. Rep. Marjorie Taylor Greene (R-GA) even went so far as to say she would oppose the entire budget if the moratorium remains.&amp;nbsp;&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-what-do-americans-want"&gt;&lt;strong&gt;What do Americans want?&lt;/strong&gt;&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Republicans like Cruz and Senate Majority Leader John Thune say they want a “light touch” approach to AI governance. Cruz also said in a statement that “every American deserves a voice in shaping” the future.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, a recent Pew Research survey found that most Americans seem to want more regulation around AI. The survey found that about 60% of U.S. adults and 56% of AI experts say they’re more concerned that the U.S. government won’t go far enough in regulating AI than they are that the government will go too far. Americans also largely aren’t confident that the government will regulate AI effectively, and they are skeptical of industry efforts around responsible AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated June 30 to reflect amendments to the bill, new reporting on the Senate’s timeline to vote on the bill, and fresh Republican opposition to the AI moratorium.  &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/congress-might-block-state-ai-laws-for-five-years-heres-what-it-means/</guid><pubDate>Mon, 30 Jun 2025 17:02:12 +0000</pubDate></item><item><title>Meta restructures its AI unit under ‘Superintelligence Labs’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/meta-restructures-its-ai-unit-under-superintelligence-labs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg is restructuring the company’s AI efforts to center around building&amp;nbsp; AI “superintelligence.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going forward, all teams working on AI at Meta will fall under a new group called Meta Superintelligence Labs, according to Bloomberg, which viewed an internal memo sent Monday.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alexandr Wang, the former CEO of data labeling startup Scale AI, will lead the group as chief AI officer. He’ll partner with former GitHub CEO Nat Friedman, who will oversee Meta’s AI products and applied research, per Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has been working hard to get ahead of the artificial general intelligence (AGI) race, mainly by acquiring AI companies and employees from top AI firms. Earlier this month, Meta invested $14.3 billion in Scale AI, bringing on Wang in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Zuckerberg has also been able to lure 11 new AI researchers from competitors, according to the report, including some previously unreported hires such as Google DeepMind principal researcher Pei Sun and Anthropic engineer Joel Pobar.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg is restructuring the company’s AI efforts to center around building&amp;nbsp; AI “superintelligence.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Going forward, all teams working on AI at Meta will fall under a new group called Meta Superintelligence Labs, according to Bloomberg, which viewed an internal memo sent Monday.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Alexandr Wang, the former CEO of data labeling startup Scale AI, will lead the group as chief AI officer. He’ll partner with former GitHub CEO Nat Friedman, who will oversee Meta’s AI products and applied research, per Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has been working hard to get ahead of the artificial general intelligence (AGI) race, mainly by acquiring AI companies and employees from top AI firms. Earlier this month, Meta invested $14.3 billion in Scale AI, bringing on Wang in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Zuckerberg has also been able to lure 11 new AI researchers from competitors, according to the report, including some previously unreported hires such as Google DeepMind principal researcher Pei Sun and Anthropic engineer Joel Pobar.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/meta-restructures-its-ai-unit-under-superintelligence-labs/</guid><pubDate>Mon, 30 Jun 2025 17:56:25 +0000</pubDate></item><item><title>[NEW] Songscription launches an AI-powered ‘Shazam for sheet music’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/songscription-launches-an-ai-powered-shazam-for-sheet-music/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1480808838.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A small company called Songscription launched last week with AI models that automate music transcription, turning an audio file of a song into sheet music within minutes. Operating on a freemium model, the product is geared toward both professional and hobbyist musicians.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We hope to make playing music more enjoyable,” Andrew Carlins, CEO of Songscription and a student in Stanford’s MBA/MA in Education program, told TechCrunch. “We imagine a future where a rural Nebraska high school band teacher [will be] able to get sheet music for the songs their students want to play, [and] that said music will be arranged specifically for the instruments in the band and offered at the individual level of play of each student.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At launch, Songscription can transcribe music for several different instruments, though the piano model is most reliable. In the future, the company hopes to add different transcription outputs (e.g., guitar tabs), as well as arrangements for a full band as opposed to just one instrument.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This kind of product could be useful for a musician who records a song they’re working on, then uploads it to get the sheet music — that way, they can skip the step of having to manually transcribe their work. And for those who can’t read and write sheet music, Songscription will also generate a piano roll, which shows a digital representation of the music being played on a virtual piano.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can also automate music transcription directly from YouTube links. Uploading a file requires users to check a box to confirm that they have the rights to transcribe the file, but it would be easy to simply check the box and get free sheet music for copyrighted songs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“For music learners&amp;nbsp;… since you are allowed to listen to a song, write down the notes by ear, and perform it on your home piano (as long as you don’t charge for a performance), it isn’t fully clear that using a tech-enabled platform to give you a head start crosses any legal boundary, although we understand the field is evolving and our application may enter a gray area,” Carlins said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The legality around much of how we engage with these creative AI tools is up for debate, though recent court decisions seem to be favoring tech companies over artists. However, Songscription isn’t creating new, AI-generated music — it’s providing a tool for musicians to speed up the process of making their own guitar tabs or sheet music. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“Since our platform allows users to edit the scores, we position ourselves as an augmented music notation software that helps people speed up the process of transcription,” Carlins said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The underlying architecture of Songscription’s AI model is based on a paper that co-founder Tim Beyer published, alongside researcher Angela Dai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In order to get the training data necessary for creating this kind of AI model, Songscription works with some musicians who were willing to share or sell their piano performances and sheet music. The company also used public domain sheet music, though the majority of the training data is synthetic, Carlins said. In that case, Songscription would convert the sheet music into audio, then alter the files to simulate real-world conditions with background noise or reverb. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Just seven months after it was founded, Songscription has raised pre-seed money from Reach Capital and will participate in Stanford’s StartX accelerator. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-1480808838.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A small company called Songscription launched last week with AI models that automate music transcription, turning an audio file of a song into sheet music within minutes. Operating on a freemium model, the product is geared toward both professional and hobbyist musicians.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We hope to make playing music more enjoyable,” Andrew Carlins, CEO of Songscription and a student in Stanford’s MBA/MA in Education program, told TechCrunch. “We imagine a future where a rural Nebraska high school band teacher [will be] able to get sheet music for the songs their students want to play, [and] that said music will be arranged specifically for the instruments in the band and offered at the individual level of play of each student.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At launch, Songscription can transcribe music for several different instruments, though the piano model is most reliable. In the future, the company hopes to add different transcription outputs (e.g., guitar tabs), as well as arrangements for a full band as opposed to just one instrument.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This kind of product could be useful for a musician who records a song they’re working on, then uploads it to get the sheet music — that way, they can skip the step of having to manually transcribe their work. And for those who can’t read and write sheet music, Songscription will also generate a piano roll, which shows a digital representation of the music being played on a virtual piano.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can also automate music transcription directly from YouTube links. Uploading a file requires users to check a box to confirm that they have the rights to transcribe the file, but it would be easy to simply check the box and get free sheet music for copyrighted songs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“For music learners&amp;nbsp;… since you are allowed to listen to a song, write down the notes by ear, and perform it on your home piano (as long as you don’t charge for a performance), it isn’t fully clear that using a tech-enabled platform to give you a head start crosses any legal boundary, although we understand the field is evolving and our application may enter a gray area,” Carlins said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The legality around much of how we engage with these creative AI tools is up for debate, though recent court decisions seem to be favoring tech companies over artists. However, Songscription isn’t creating new, AI-generated music — it’s providing a tool for musicians to speed up the process of making their own guitar tabs or sheet music. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“Since our platform allows users to edit the scores, we position ourselves as an augmented music notation software that helps people speed up the process of transcription,” Carlins said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The underlying architecture of Songscription’s AI model is based on a paper that co-founder Tim Beyer published, alongside researcher Angela Dai.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In order to get the training data necessary for creating this kind of AI model, Songscription works with some musicians who were willing to share or sell their piano performances and sheet music. The company also used public domain sheet music, though the majority of the training data is synthetic, Carlins said. In that case, Songscription would convert the sheet music into audio, then alter the files to simulate real-world conditions with background noise or reverb. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Just seven months after it was founded, Songscription has raised pre-seed money from Reach Capital and will participate in Stanford’s StartX accelerator. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/songscription-launches-an-ai-powered-shazam-for-sheet-music/</guid><pubDate>Mon, 30 Jun 2025 18:41:19 +0000</pubDate></item><item><title>[NEW] Apple reportedly considers letting Anthropic and OpenAI power Siri (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/apple-reportedly-considers-letting-anthropic-and-openai-power-siri/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/WWDC-2024-Apple-Intelligence-iPhone-Limits.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple is considering using AI models from OpenAI and Anthropic to power its updated version of Siri, rather than using technology the company has built in-house, according to a report from Bloomberg on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The iPhone maker continues to build out a project internally dubbed “LLM Siri” that uses in-house AI models, according to Bloomberg. However, Apple has reportedly asked OpenAI and Anthropic to train versions of their AI models that can run on Apple’s cloud infrastructure for testing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apple was forced to delay its AI-enabled Siri, originally slated for 2025, until 2026 or later due to a series of technical challenges the company reportedly ran into. This failure may have been a long time coming; Apple has been falling behind Google, OpenAI, and Anthropic in the AI race for the last several years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Siri can already call on ChatGPT for difficult questions, Apple now seems to be exploring a much deeper integration with technology from third-party AI providers.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/WWDC-2024-Apple-Intelligence-iPhone-Limits.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple is considering using AI models from OpenAI and Anthropic to power its updated version of Siri, rather than using technology the company has built in-house, according to a report from Bloomberg on Monday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The iPhone maker continues to build out a project internally dubbed “LLM Siri” that uses in-house AI models, according to Bloomberg. However, Apple has reportedly asked OpenAI and Anthropic to train versions of their AI models that can run on Apple’s cloud infrastructure for testing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Apple was forced to delay its AI-enabled Siri, originally slated for 2025, until 2026 or later due to a series of technical challenges the company reportedly ran into. This failure may have been a long time coming; Apple has been falling behind Google, OpenAI, and Anthropic in the AI race for the last several years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Siri can already call on ChatGPT for difficult questions, Apple now seems to be exploring a much deeper integration with technology from third-party AI providers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/apple-reportedly-considers-letting-anthropic-and-openai-power-siri/</guid><pubDate>Mon, 30 Jun 2025 19:26:20 +0000</pubDate></item><item><title>[NEW] Half a million Spotify users are unknowingly grooving to an AI-generated band (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/06/half-a-million-spotify-users-are-unknowingly-grooving-to-an-ai-generated-band/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A supposed band called The Velvet Sundown has released two albums of AI slop this month.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Spotify on a phone with headphones" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2023/05/spotify-headphones-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Spotify on a phone with headphones" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/05/spotify-headphones-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Thomas Trutschel via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Making art used to be a uniquely human endeavor, but machines have learned to distill human creativity with generative AI. Whether that content counts as "art" depends on who you ask, but Spotify doesn't discriminate. A new band called The Velvet Sundown debuted on Spotify this month and has already amassed more than half a million listeners. But by all appearances, The Velvet Sundown is not a real band—it's AI.&lt;/p&gt;
&lt;p&gt;While many artists are vehemently opposed to using AI, some have leaned into the trend to assist with music production. However, it doesn't seem like there's an artist behind this group. In less than a month, The Velvet Sundown has released two albums on Spotify, titled "Floating On Echoes" and "Dust and Silence." A third album is releasing in two weeks. The tracks have a classic rock vibe with a cacophony of echoey instruments and a dash of autotune. If one of these songs came up in a mix, you might not notice anything is amiss. Listen to one after another, though, and the bland muddiness exposes them as a machine creation.&lt;/p&gt;
&lt;p&gt;Some listeners began to have doubts about The Velvet Sundown's existence over the past week, with multiple Reddit and X threads pointing out the lack of verifiable information on the band. The bio lists four members, none of whom appear to exist outside of The Velvet Sundown's album listings and social media. The group's songs have been mysteriously added to a large number of user-created playlists, which has helped swell its listener base in a few short weeks. When Spotify users began noticing The Velvet Sundown's apparent use of AI, the profile had around 300,000 listeners. It's now over 500,000 in less than a week.&lt;/p&gt;
&lt;p&gt;When The Velvet Sundown set up an Instagram account on June 27, all doubts were laid to rest—these "people" are obviously AI. We may be past the era of being able to identify AI by counting fingers, but there are plenty of weird inconsistencies in these pics. In one Instagram post, the band claims to have gotten burgers to celebrate the success of the first two albums, but there are too many burgers and too few plates, and the food and drink are placed seemingly at random around the table. The band members themselves also have that unrealistically smooth and symmetrical look we see in AI-generated images.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="instagram-media"&gt;
&lt;div style="padding: 16px;"&gt;

&lt;div style="display: flex;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 50%; height: 40px; margin-right: 14px; width: 40px;"&gt;&lt;/div&gt;
&lt;div style="display: flex;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; margin-bottom: 6px; width: 100px;"&gt;&lt;/div&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; width: 60px;"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="padding: 19% 0;"&gt;&lt;/div&gt;
&lt;div style="display: block; height: 50px; margin: 0 auto 12px; width: 50px;"&gt;&lt;/div&gt;
&lt;div style="padding-top: 8px;"&gt;
&lt;div style="color: #3897f0; font-family: Arial,sans-serif; font-size: 14px; font-style: normal; font-weight: 550; line-height: 18px;"&gt;View this post on Instagram&lt;/div&gt;
&lt;/div&gt;
&lt;div style="padding: 12.5% 0;"&gt;&lt;/div&gt;
&lt;div style="display: flex; margin-bottom: 14px;"&gt;
&lt;div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div style="margin-left: 8px;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 50%; height: 20px; width: 20px;"&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div style="margin-left: auto;"&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="display: flex; margin-bottom: 24px;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; margin-bottom: 6px; width: 224px;"&gt;&lt;/div&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; width: 144px;"&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;p style="color: #c9c8cd; font-family: Arial,sans-serif; font-size: 14px; line-height: 17px; margin-bottom: 0; margin-top: 8px; overflow: hidden; padding: 8px 0 7px; text-align: center; white-space: nowrap;"&gt;A post shared by The Velvet Sundown (@thevelvetsundownband)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Velvet Sundown is not the only AI-generated act to invade streaming services. In a recent episode of Last Week Tonight focused on AI, host John Oliver highlighted an AI band called The Devil Inside that has released 10 albums in the past two years. Interestingly, both The Velvet Sundown and The Devil Inside seem to have many songs that reference dust and wind. That may simply be an artifact of repetition in music-generation models, or they may both be products of the same AI slop manufacturer.&lt;/p&gt;
&lt;h2&gt;Labeling AI&lt;/h2&gt;
&lt;p&gt;Spotify is happy to accept AI music and does not require listings to reveal if a song was created entirely by a machine. The Velvet Sundown is also available on other streaming platforms, including Deezer, which takes a harder line on AI. According to NME, the band's bio on Deezer includes a disclaimer that "Some tracks on this album may have been created using artificial intelligence." NME also notes that the Spotify bio previously attributed a flattering description of the band's music to Billboard. The flattery remains, but Billboard's name has been removed.&lt;/p&gt;
&lt;p&gt;Currently, the band's Instagram is flooded with comments calling out the use of AI, but the day may come when it's not so easy to tell. There's nothing inherently wrong with someone wanting to listen to an AI-generated song—there are a ton of YouTube channels that stream essentially infinite AI music. It's interesting technology, and the output has come a long way since the original Google MusicLM and OpenAI Jukebox models debuted a few years back. But people should know what is and is not AI.&lt;/p&gt;
&lt;p&gt;Art created by living, breathing people says something about the world—it's a manifestation of the human condition. The machinations of a machine, however, don't really matter in the same way. An AI-generated song might have a nice vibe, but it's just a remix of actual art assembled by a randomized algorithm. Google and others are endeavoring to create verifiable watermarks for AI images, but we may need something similar for audio if the largest music streamers continue to allow AI songs without disclosure.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A supposed band called The Velvet Sundown has released two albums of AI slop this month.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Spotify on a phone with headphones" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2023/05/spotify-headphones-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Spotify on a phone with headphones" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/05/spotify-headphones-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Thomas Trutschel via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Making art used to be a uniquely human endeavor, but machines have learned to distill human creativity with generative AI. Whether that content counts as "art" depends on who you ask, but Spotify doesn't discriminate. A new band called The Velvet Sundown debuted on Spotify this month and has already amassed more than half a million listeners. But by all appearances, The Velvet Sundown is not a real band—it's AI.&lt;/p&gt;
&lt;p&gt;While many artists are vehemently opposed to using AI, some have leaned into the trend to assist with music production. However, it doesn't seem like there's an artist behind this group. In less than a month, The Velvet Sundown has released two albums on Spotify, titled "Floating On Echoes" and "Dust and Silence." A third album is releasing in two weeks. The tracks have a classic rock vibe with a cacophony of echoey instruments and a dash of autotune. If one of these songs came up in a mix, you might not notice anything is amiss. Listen to one after another, though, and the bland muddiness exposes them as a machine creation.&lt;/p&gt;
&lt;p&gt;Some listeners began to have doubts about The Velvet Sundown's existence over the past week, with multiple Reddit and X threads pointing out the lack of verifiable information on the band. The bio lists four members, none of whom appear to exist outside of The Velvet Sundown's album listings and social media. The group's songs have been mysteriously added to a large number of user-created playlists, which has helped swell its listener base in a few short weeks. When Spotify users began noticing The Velvet Sundown's apparent use of AI, the profile had around 300,000 listeners. It's now over 500,000 in less than a week.&lt;/p&gt;
&lt;p&gt;When The Velvet Sundown set up an Instagram account on June 27, all doubts were laid to rest—these "people" are obviously AI. We may be past the era of being able to identify AI by counting fingers, but there are plenty of weird inconsistencies in these pics. In one Instagram post, the band claims to have gotten burgers to celebrate the success of the first two albums, but there are too many burgers and too few plates, and the food and drink are placed seemingly at random around the table. The band members themselves also have that unrealistically smooth and symmetrical look we see in AI-generated images.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="instagram-media"&gt;
&lt;div style="padding: 16px;"&gt;

&lt;div style="display: flex;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 50%; height: 40px; margin-right: 14px; width: 40px;"&gt;&lt;/div&gt;
&lt;div style="display: flex;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; margin-bottom: 6px; width: 100px;"&gt;&lt;/div&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; width: 60px;"&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="padding: 19% 0;"&gt;&lt;/div&gt;
&lt;div style="display: block; height: 50px; margin: 0 auto 12px; width: 50px;"&gt;&lt;/div&gt;
&lt;div style="padding-top: 8px;"&gt;
&lt;div style="color: #3897f0; font-family: Arial,sans-serif; font-size: 14px; font-style: normal; font-weight: 550; line-height: 18px;"&gt;View this post on Instagram&lt;/div&gt;
&lt;/div&gt;
&lt;div style="padding: 12.5% 0;"&gt;&lt;/div&gt;
&lt;div style="display: flex; margin-bottom: 14px;"&gt;
&lt;div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div style="margin-left: 8px;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 50%; height: 20px; width: 20px;"&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;div style="margin-left: auto;"&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;div&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div style="display: flex; margin-bottom: 24px;"&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; margin-bottom: 6px; width: 224px;"&gt;&lt;/div&gt;
&lt;div style="background-color: #f4f4f4; border-radius: 4px; height: 14px; width: 144px;"&gt;&lt;/div&gt;
&lt;/div&gt;

&lt;p style="color: #c9c8cd; font-family: Arial,sans-serif; font-size: 14px; line-height: 17px; margin-bottom: 0; margin-top: 8px; overflow: hidden; padding: 8px 0 7px; text-align: center; white-space: nowrap;"&gt;A post shared by The Velvet Sundown (@thevelvetsundownband)&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;

&lt;p&gt;The Velvet Sundown is not the only AI-generated act to invade streaming services. In a recent episode of Last Week Tonight focused on AI, host John Oliver highlighted an AI band called The Devil Inside that has released 10 albums in the past two years. Interestingly, both The Velvet Sundown and The Devil Inside seem to have many songs that reference dust and wind. That may simply be an artifact of repetition in music-generation models, or they may both be products of the same AI slop manufacturer.&lt;/p&gt;
&lt;h2&gt;Labeling AI&lt;/h2&gt;
&lt;p&gt;Spotify is happy to accept AI music and does not require listings to reveal if a song was created entirely by a machine. The Velvet Sundown is also available on other streaming platforms, including Deezer, which takes a harder line on AI. According to NME, the band's bio on Deezer includes a disclaimer that "Some tracks on this album may have been created using artificial intelligence." NME also notes that the Spotify bio previously attributed a flattering description of the band's music to Billboard. The flattery remains, but Billboard's name has been removed.&lt;/p&gt;
&lt;p&gt;Currently, the band's Instagram is flooded with comments calling out the use of AI, but the day may come when it's not so easy to tell. There's nothing inherently wrong with someone wanting to listen to an AI-generated song—there are a ton of YouTube channels that stream essentially infinite AI music. It's interesting technology, and the output has come a long way since the original Google MusicLM and OpenAI Jukebox models debuted a few years back. But people should know what is and is not AI.&lt;/p&gt;
&lt;p&gt;Art created by living, breathing people says something about the world—it's a manifestation of the human condition. The machinations of a machine, however, don't really matter in the same way. An AI-generated song might have a nice vibe, but it's just a remix of actual art assembled by a randomized algorithm. Google and others are endeavoring to create verifiable watermarks for AI images, but we may need something similar for audio if the largest music streamers continue to allow AI songs without disclosure.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/06/half-a-million-spotify-users-are-unknowingly-grooving-to-an-ai-generated-band/</guid><pubDate>Mon, 30 Jun 2025 19:47:40 +0000</pubDate></item><item><title>[NEW] From chatbots to collaborators: How AI agents are reshaping enterprise work (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/from-chatbots-to-collaborators-how-ai-agents-are-reshaping-enterprise-work/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Scott White still marvels at how quickly artificial intelligence has transformed from a novelty into a true work partner. Just over a year ago, the product lead for Claude AI at Anthropic watched as early AI coding tools could barely complete a single line of code. Today, he’s building production-ready software features himself — despite not being a professional programmer.&lt;/p&gt;



&lt;p&gt;“I no longer think about my job as writing a PRD and trying to convince someone to do something,” White said during a fireside chat at &lt;strong&gt;VB Transform 2025&lt;/strong&gt;, VentureBeat’s annual enterprise AI summit in San Francisco. “The first thing I do is, can I build a workable prototype of this on our staging server and then share a demo of it actually working.”&lt;/p&gt;



&lt;p&gt;This shift represents a broader transformation in how enterprises are adopting AI, moving beyond simple chatbots that answer questions to sophisticated “agentic” systems capable of autonomous work. White’s experience offers a glimpse into what may be coming for millions of other knowledge workers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-code-completion-to-autonomous-programming-ai-s-breakneck-evolution"&gt;&lt;strong&gt;From code completion to autonomous programming: AI’s breakneck evolution&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The evolution has been remarkably swift. When White joined Anthropic, the company’s Claude 2 model could handle basic text completion. The release of Claude 3.5 Sonnet enabled the creation of entire applications, leading to features like Artifacts that let users generate custom interfaces. Now, with Claude 4 achieving a 72.5% score on the SWE-bench coding benchmark, the model can function as what White calls “a fully remote agentic software engineer.”&lt;/p&gt;



&lt;p&gt;Claude Code, the company’s latest coding tool, can analyze entire codebases, search the internet for API documentation, issue pull requests, respond to code review comments, and iterate on solutions — all while working asynchronously for hours. White noted that 90% of Claude Code itself was written by the AI system.&lt;/p&gt;



&lt;p&gt;“That is like an entire agentic process in the background that was not possible six months ago,” White explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-giants-slash-work-time-from-weeks-to-minutes-with-ai-agents"&gt;&lt;strong&gt;Enterprise giants slash work time from weeks to minutes with AI agents&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The implications extend far beyond software development. Novo Nordisk, the Danish pharmaceutical giant, has integrated Claude into workflows that previously took 10 weeks to complete clinical reports, now finishing the same work in 10 minutes. GitLab uses the technology for everything from sales proposals to technical documentation. Intuit deploys Claude to provide tax advice directly to consumers.&lt;/p&gt;



&lt;p&gt;White distinguishes between different levels of AI integration: simple language models that answer questions, models enhanced with tools like web search, structured workflows that incorporate AI into business processes, and full agents that can pursue goals autonomously using multiple tools and iterative reasoning.&lt;/p&gt;



&lt;p&gt;“I think about an agent as something that has a goal, and then it can just do many things to accomplish that goal,” White said. The key enabler has been what he calls the “inexorable” relationship between model intelligence and new product capabilities.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-infrastructure-revolution-building-networks-of-ai-collaborators"&gt;&lt;strong&gt;The infrastructure revolution: Building networks of AI collaborators&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;A critical infrastructure development has been Anthropic’s Model Context Protocol (MCP), which White describes as “the USB-C for integrations.” Rather than companies building separate connections to each data source or tool, MCP provides a standardized way for AI systems to access enterprise software, from Salesforce to internal knowledge repositories.&lt;/p&gt;



&lt;p&gt;“It’s really democratizing access to data,” White said, noting that integrations built by one company can be shared and reused by others through the open-source protocol.&lt;/p&gt;



&lt;p&gt;For organizations looking to implement AI agents, White recommends starting small and building incrementally. “Don’t try to build an entire agentic system from scratch,” he advised. “Build the component of it, make sure that component works, then build a next component.”&lt;/p&gt;



&lt;p&gt;He also emphasized the importance of evaluation systems to ensure AI agents perform as intended. “Evals are the new PRD,” White said, referring to product requirement documents, highlighting how companies must develop new methods to assess AI performance on specific business tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-ai-assistants-to-ai-organizations-the-next-workforce-frontier"&gt;&lt;strong&gt;From AI assistants to AI organizations: The next workforce frontier&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking ahead, White envisions AI development becoming accessible to non-technical workers, similar to how coding capabilities have advanced. He imagines a future where individuals manage not just one AI agent but entire organizations of specialized AI systems.&lt;/p&gt;



&lt;p&gt;“How can everyone be their own mini CPO or CEO?” White asked. “I don’t exactly know what that looks like, but that’s the kind of thing that I wake up and want to get there.”&lt;/p&gt;



&lt;p&gt;The transformation White describes reflects broader industry trends as companies grapple with AI’s expanding capabilities. While early adoption focused on experimental use cases, enterprises are increasingly integrating AI into core business processes, fundamentally changing how work gets done.&lt;/p&gt;



&lt;p&gt;As AI agents become more autonomous and capable, the challenge shifts from teaching machines to perform tasks to managing AI collaborators that can work independently for extended periods. For White, this future is already arriving — one production feature at a time.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Scott White still marvels at how quickly artificial intelligence has transformed from a novelty into a true work partner. Just over a year ago, the product lead for Claude AI at Anthropic watched as early AI coding tools could barely complete a single line of code. Today, he’s building production-ready software features himself — despite not being a professional programmer.&lt;/p&gt;



&lt;p&gt;“I no longer think about my job as writing a PRD and trying to convince someone to do something,” White said during a fireside chat at &lt;strong&gt;VB Transform 2025&lt;/strong&gt;, VentureBeat’s annual enterprise AI summit in San Francisco. “The first thing I do is, can I build a workable prototype of this on our staging server and then share a demo of it actually working.”&lt;/p&gt;



&lt;p&gt;This shift represents a broader transformation in how enterprises are adopting AI, moving beyond simple chatbots that answer questions to sophisticated “agentic” systems capable of autonomous work. White’s experience offers a glimpse into what may be coming for millions of other knowledge workers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-code-completion-to-autonomous-programming-ai-s-breakneck-evolution"&gt;&lt;strong&gt;From code completion to autonomous programming: AI’s breakneck evolution&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The evolution has been remarkably swift. When White joined Anthropic, the company’s Claude 2 model could handle basic text completion. The release of Claude 3.5 Sonnet enabled the creation of entire applications, leading to features like Artifacts that let users generate custom interfaces. Now, with Claude 4 achieving a 72.5% score on the SWE-bench coding benchmark, the model can function as what White calls “a fully remote agentic software engineer.”&lt;/p&gt;



&lt;p&gt;Claude Code, the company’s latest coding tool, can analyze entire codebases, search the internet for API documentation, issue pull requests, respond to code review comments, and iterate on solutions — all while working asynchronously for hours. White noted that 90% of Claude Code itself was written by the AI system.&lt;/p&gt;



&lt;p&gt;“That is like an entire agentic process in the background that was not possible six months ago,” White explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-giants-slash-work-time-from-weeks-to-minutes-with-ai-agents"&gt;&lt;strong&gt;Enterprise giants slash work time from weeks to minutes with AI agents&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The implications extend far beyond software development. Novo Nordisk, the Danish pharmaceutical giant, has integrated Claude into workflows that previously took 10 weeks to complete clinical reports, now finishing the same work in 10 minutes. GitLab uses the technology for everything from sales proposals to technical documentation. Intuit deploys Claude to provide tax advice directly to consumers.&lt;/p&gt;



&lt;p&gt;White distinguishes between different levels of AI integration: simple language models that answer questions, models enhanced with tools like web search, structured workflows that incorporate AI into business processes, and full agents that can pursue goals autonomously using multiple tools and iterative reasoning.&lt;/p&gt;



&lt;p&gt;“I think about an agent as something that has a goal, and then it can just do many things to accomplish that goal,” White said. The key enabler has been what he calls the “inexorable” relationship between model intelligence and new product capabilities.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-infrastructure-revolution-building-networks-of-ai-collaborators"&gt;&lt;strong&gt;The infrastructure revolution: Building networks of AI collaborators&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;A critical infrastructure development has been Anthropic’s Model Context Protocol (MCP), which White describes as “the USB-C for integrations.” Rather than companies building separate connections to each data source or tool, MCP provides a standardized way for AI systems to access enterprise software, from Salesforce to internal knowledge repositories.&lt;/p&gt;



&lt;p&gt;“It’s really democratizing access to data,” White said, noting that integrations built by one company can be shared and reused by others through the open-source protocol.&lt;/p&gt;



&lt;p&gt;For organizations looking to implement AI agents, White recommends starting small and building incrementally. “Don’t try to build an entire agentic system from scratch,” he advised. “Build the component of it, make sure that component works, then build a next component.”&lt;/p&gt;



&lt;p&gt;He also emphasized the importance of evaluation systems to ensure AI agents perform as intended. “Evals are the new PRD,” White said, referring to product requirement documents, highlighting how companies must develop new methods to assess AI performance on specific business tasks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-ai-assistants-to-ai-organizations-the-next-workforce-frontier"&gt;&lt;strong&gt;From AI assistants to AI organizations: The next workforce frontier&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Looking ahead, White envisions AI development becoming accessible to non-technical workers, similar to how coding capabilities have advanced. He imagines a future where individuals manage not just one AI agent but entire organizations of specialized AI systems.&lt;/p&gt;



&lt;p&gt;“How can everyone be their own mini CPO or CEO?” White asked. “I don’t exactly know what that looks like, but that’s the kind of thing that I wake up and want to get there.”&lt;/p&gt;



&lt;p&gt;The transformation White describes reflects broader industry trends as companies grapple with AI’s expanding capabilities. While early adoption focused on experimental use cases, enterprises are increasingly integrating AI into core business processes, fundamentally changing how work gets done.&lt;/p&gt;



&lt;p&gt;As AI agents become more autonomous and capable, the challenge shifts from teaching machines to perform tasks to managing AI collaborators that can work independently for extended periods. For White, this future is already arriving — one production feature at a time.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/from-chatbots-to-collaborators-how-ai-agents-are-reshaping-enterprise-work/</guid><pubDate>Mon, 30 Jun 2025 20:38:53 +0000</pubDate></item><item><title>[NEW] Next-gen procurement platform Levelpath nabs $55M (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/next-gen-procurement-platform-levelpath-nabs-55m/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Stan-Alex_Together.png?resize=1200,776" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Levelpath, a procurement software startup founded by the duo behind Scout RFP, has raised $55 million in Series B funding led by Battery Ventures as the company looks to quadruple its revenue this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The funding round also saw participation from existing investors, including Benchmark, which led Levelpath’s $14.5 million seed round, and Redpoint, the lead investor in the $30 million Series A round announced in 2023.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup was founded by Stan Garber and Alex Yakubovich (pictured right), whose previous startup, Scout RFP, was acquired by Workday for $540 million in 2019. During the three years Yakubovich and Garber spent working at Workday, the two identified persistent procurement challenges that motivated them to build a mobile-first, user-friendly platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Levelpath’s timing proved fortuitous; launching right as ChatGPT debuted has enabled the startup to integrate AI capabilities from its inception. This includes reviewing unstructured data in contracts and recommending less expensive, similar products and services. The company now counts Ace Hardware, Amgen, Coupang, and SiriusXM as customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investment signals confidence in Levelpath’s fast growth and its potential to disrupt a market dominated by legacy players. Procurement software has long been controlled by outdated vendors like Coupa and Ariba, whose clunky systems often drive employees to bypass official processes. This “rogue” spending using corporate credit cards frequently results in overspending and missed opportunities for bulk discounts, according to Battery Ventures general partner Neeraj Agrawal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In fact, procurement represents companies’ second-largest expenditure after payroll, making software improvements particularly valuable. The procurement software market was valued at $7.3 billion annually in 2023, according to Fortune Business Insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although Levelpath is a newer and likely smaller player compared to its main competitors — including Zip, valued at $2.2 billion last fall, and Oro Labs, backed by Felicis — the company seems to have all the right ingredients, including Agrawal, who led Battery’s Series B investment into Coupa and has joined Levelpath’s board. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Coupa, of course, grew into one of the most successful procurement companies of its era. It had a successful IPO in 2016 and several years later was taken private by PE firm Thoma Bravo for $8 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agrawal, who likely understands what it takes to build a big business in this category, is equally impressed by Levelpath’s technology and its founders. “They have such a strong reputation for delivering product, being good people to work with, and doing what they say they’re going to do,” Agrawal told TechCrunch. “Customers want to work with them and help them build this next-generation product.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yakubovich and Garber have been friends since attending high school in Ohio. They bonded over their shared heritage as immigrants from the former Soviet Union and a mutual interest in entrepreneurship. The pair have been working together for over 20 years, and their stated goal is to help customers enjoy, rather than avoid, using procurement software.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While procurement might seem like a mundane business function, it offers a direct and significant return on investment by helping companies save money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It makes the cash register ring because of these savings,” Agrawal said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Stan-Alex_Together.png?resize=1200,776" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Levelpath, a procurement software startup founded by the duo behind Scout RFP, has raised $55 million in Series B funding led by Battery Ventures as the company looks to quadruple its revenue this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The funding round also saw participation from existing investors, including Benchmark, which led Levelpath’s $14.5 million seed round, and Redpoint, the lead investor in the $30 million Series A round announced in 2023.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup was founded by Stan Garber and Alex Yakubovich (pictured right), whose previous startup, Scout RFP, was acquired by Workday for $540 million in 2019. During the three years Yakubovich and Garber spent working at Workday, the two identified persistent procurement challenges that motivated them to build a mobile-first, user-friendly platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Levelpath’s timing proved fortuitous; launching right as ChatGPT debuted has enabled the startup to integrate AI capabilities from its inception. This includes reviewing unstructured data in contracts and recommending less expensive, similar products and services. The company now counts Ace Hardware, Amgen, Coupang, and SiriusXM as customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investment signals confidence in Levelpath’s fast growth and its potential to disrupt a market dominated by legacy players. Procurement software has long been controlled by outdated vendors like Coupa and Ariba, whose clunky systems often drive employees to bypass official processes. This “rogue” spending using corporate credit cards frequently results in overspending and missed opportunities for bulk discounts, according to Battery Ventures general partner Neeraj Agrawal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In fact, procurement represents companies’ second-largest expenditure after payroll, making software improvements particularly valuable. The procurement software market was valued at $7.3 billion annually in 2023, according to Fortune Business Insights.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although Levelpath is a newer and likely smaller player compared to its main competitors — including Zip, valued at $2.2 billion last fall, and Oro Labs, backed by Felicis — the company seems to have all the right ingredients, including Agrawal, who led Battery’s Series B investment into Coupa and has joined Levelpath’s board. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Coupa, of course, grew into one of the most successful procurement companies of its era. It had a successful IPO in 2016 and several years later was taken private by PE firm Thoma Bravo for $8 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agrawal, who likely understands what it takes to build a big business in this category, is equally impressed by Levelpath’s technology and its founders. “They have such a strong reputation for delivering product, being good people to work with, and doing what they say they’re going to do,” Agrawal told TechCrunch. “Customers want to work with them and help them build this next-generation product.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yakubovich and Garber have been friends since attending high school in Ohio. They bonded over their shared heritage as immigrants from the former Soviet Union and a mutual interest in entrepreneurship. The pair have been working together for over 20 years, and their stated goal is to help customers enjoy, rather than avoid, using procurement software.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While procurement might seem like a mundane business function, it offers a direct and significant return on investment by helping companies save money.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It makes the cash register ring because of these savings,” Agrawal said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/next-gen-procurement-platform-levelpath-nabs-55m/</guid><pubDate>Mon, 30 Jun 2025 20:46:23 +0000</pubDate></item><item><title>[NEW] Kayak and Expedia race to build AI travel agents that turn social posts into itineraries (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/kayak-and-expedia-race-to-build-ai-travel-agents-that-turn-social-posts-into-itineraries/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;p&gt;When people started to talk about AI agents and assistants, the number one use case revolved around travel. Could someone be watching a video about the Maldives and direct their AI agent to start finding flights and hotels, and book these seamlessly?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We‘re inching closer to a similar future as the travel industry begins to embrace agentic AI. Kayak and Expedia, two of the largest companies in travel booking, said during VB Transform that personalization and changing search patterns mean travel companies can rely on agents to make travel inspiration a reality.&lt;/p&gt;



&lt;p&gt;Matthias Keller, chief product officer at Kayak, said the company has been experimenting with this idea for a couple of years, even taking advantage of a partnership with Amazon’s Alexa. Kayak no longer launches on Alexa, but that hasn’t stopped the company from offering different search modes for customers.&lt;/p&gt;



&lt;p&gt;“We are striving for this vision of a travel agent that is always available, that is agentic and powered by AI,” Keller said onstage at VB Transform. “In April, we launched our new testbed for agentic travel booking called Kayak AI; it’s a fully chat-based agentic experience that puts together the power of ChatGPT and many different tools. One is web search, but we also offer tools specifically for flights or hotels.”&lt;/p&gt;



&lt;p&gt;Keller said Kayak is “working towards our vision of having this fully personalized experienced that does all the heavy lifting for you when you plan travel.”&lt;/p&gt;



&lt;p&gt;While the idea of an agent proactively guiding potential travelers makes for efficient trip planning, Expedia CTO Ramana Thumu noted that there is a delicate balance to strike.&lt;/p&gt;



&lt;p&gt;“More and more customer expectations will revolve around a seamless experience, from search to completing transactions,” Thumu said. “But the most important thing, and the shift I see happening, is asking for the balance between the control the traveler has, and the control we give to the agent.”&lt;/p&gt;







&lt;p&gt;One reason this balance becomes essential is that, increasingly, consumers find travel inspiration everywhere. For one of its AI projects, Expedia decided to capitalize on the growing influence of travel influencers who post their trips on Instagram.&lt;/p&gt;



&lt;p&gt;Thumu said Expedia’s Trip Matching feature, which launched in June for U.S. customers, allows people to send any travel-related public Instagram Reel to Expedia, and the platform can build an itinerary based on them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Thumu said Expedia can build this type of AI product because of its extensive database amassed over 30 years. Both Thumu and Keller underscored the importance of data in building out these personalizations, a task that can be challenging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Personalization can go beyond planning a trip based on inspiration or previous preferences, as Keller said; eventually, their platforms and AI agents can also start recommending things to do based on the weather in your planned location during your stay.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-helps-simplify-the-complexity"&gt;AI helps simplify the complexity&lt;/h2&gt;



&lt;p&gt;One use case where companies like Kayak and Expedia find AI to be helpful is for “snackers,” or individuals who search for flights or hotels without any intention of booking. These are usually people who just want to check the price of a flight or find out how much a hotel costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AI systems can help snackers find their answers, and may even encourage them to go on that trip, because much of the tediousness of finding accommodation, transportation and activities can be presented to them right there on either the Expedia or Kayak front end.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“What I find interesting when I pitch Kayak AI to somebody [is] I can say that we can get this complex trip planned without running all of the searches,” Keller said. “Every hotel booking site out there can tell you that a hotel has a pool, but you have to go deep to find an infinity pool. That’s the type of question that ChatGPT does a great job with, so it’s something we have to adapt and deliver.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;p&gt;When people started to talk about AI agents and assistants, the number one use case revolved around travel. Could someone be watching a video about the Maldives and direct their AI agent to start finding flights and hotels, and book these seamlessly?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We‘re inching closer to a similar future as the travel industry begins to embrace agentic AI. Kayak and Expedia, two of the largest companies in travel booking, said during VB Transform that personalization and changing search patterns mean travel companies can rely on agents to make travel inspiration a reality.&lt;/p&gt;



&lt;p&gt;Matthias Keller, chief product officer at Kayak, said the company has been experimenting with this idea for a couple of years, even taking advantage of a partnership with Amazon’s Alexa. Kayak no longer launches on Alexa, but that hasn’t stopped the company from offering different search modes for customers.&lt;/p&gt;



&lt;p&gt;“We are striving for this vision of a travel agent that is always available, that is agentic and powered by AI,” Keller said onstage at VB Transform. “In April, we launched our new testbed for agentic travel booking called Kayak AI; it’s a fully chat-based agentic experience that puts together the power of ChatGPT and many different tools. One is web search, but we also offer tools specifically for flights or hotels.”&lt;/p&gt;



&lt;p&gt;Keller said Kayak is “working towards our vision of having this fully personalized experienced that does all the heavy lifting for you when you plan travel.”&lt;/p&gt;



&lt;p&gt;While the idea of an agent proactively guiding potential travelers makes for efficient trip planning, Expedia CTO Ramana Thumu noted that there is a delicate balance to strike.&lt;/p&gt;



&lt;p&gt;“More and more customer expectations will revolve around a seamless experience, from search to completing transactions,” Thumu said. “But the most important thing, and the shift I see happening, is asking for the balance between the control the traveler has, and the control we give to the agent.”&lt;/p&gt;







&lt;p&gt;One reason this balance becomes essential is that, increasingly, consumers find travel inspiration everywhere. For one of its AI projects, Expedia decided to capitalize on the growing influence of travel influencers who post their trips on Instagram.&lt;/p&gt;



&lt;p&gt;Thumu said Expedia’s Trip Matching feature, which launched in June for U.S. customers, allows people to send any travel-related public Instagram Reel to Expedia, and the platform can build an itinerary based on them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Thumu said Expedia can build this type of AI product because of its extensive database amassed over 30 years. Both Thumu and Keller underscored the importance of data in building out these personalizations, a task that can be challenging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Personalization can go beyond planning a trip based on inspiration or previous preferences, as Keller said; eventually, their platforms and AI agents can also start recommending things to do based on the weather in your planned location during your stay.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-helps-simplify-the-complexity"&gt;AI helps simplify the complexity&lt;/h2&gt;



&lt;p&gt;One use case where companies like Kayak and Expedia find AI to be helpful is for “snackers,” or individuals who search for flights or hotels without any intention of booking. These are usually people who just want to check the price of a flight or find out how much a hotel costs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AI systems can help snackers find their answers, and may even encourage them to go on that trip, because much of the tediousness of finding accommodation, transportation and activities can be presented to them right there on either the Expedia or Kayak front end.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“What I find interesting when I pitch Kayak AI to somebody [is] I can say that we can get this complex trip planned without running all of the searches,” Keller said. “Every hotel booking site out there can tell you that a hotel has a pool, but you have to go deep to find an infinity pool. That’s the type of question that ChatGPT does a great job with, so it’s something we have to adapt and deliver.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/kayak-and-expedia-race-to-build-ai-travel-agents-that-turn-social-posts-into-itineraries/</guid><pubDate>Tue, 01 Jul 2025 00:05:48 +0000</pubDate></item><item><title>[NEW] Legal software company Clio drops $1B on law data giant vLex (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/legal-software-company-clio-drops-1b-on-law-data-giant-vlex/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-1474442258.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Clio, a 17-year-old Canadian law firm management software company, announced that it has agreed to acquire vLex, a 26-year-old legal data intelligence platform, in a $1 billion cash-and-stock deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement comes about a year after Clio’s massive $900 million funding round, which nearly doubled the Vancouver, British Columbia-based company’s valuation from $1.6 billion in 2021 to $3 billion.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;vLex, which was largely bootstrapped until it was purchased by private equity firm Oakley Capital in 2022, has been a highly sought-after asset, according to Jack Newton, CEO and founder of Clio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harvey, the AI-native legal tech startup, attempted to purchase vLex a year ago, but the acquisition didn’t come together, as reported by The Information last July. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;vLex is a valuable property because its database of legal documents can greatly improve AI models for lawyers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Data is one of the only long-term defensible competitive moats a company can have in the space,” Newton told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;vLex competes with the Thomson Reuters-owned legal database and LexisNexis. The acquisition comes shortly after Harvey announced a partnership with LexisNexis, aiming to enrich Harvey’s AI with LexisNexis data.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;With the acquisition of vLex, Clio, which provides law firms with time-tracking, invoicing, and electronic payment tools, is now effectively stepping into the practice of law itself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the last few years, vLex has built Vincent, an AI model built on top of the company’s legal content database.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is going to drive a convergence of what have historically been distinct categories of software: the business of law and the practice of law,” Newton said. He added that Clio’s clients in the small and medium law firm segment will now have access to Vincent’s AI capabilities.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to announcing plans to acquire vLex, Clio said it has reached $300 million in annual recurring revenue (ARR).&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/09/GettyImages-1474442258.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Clio, a 17-year-old Canadian law firm management software company, announced that it has agreed to acquire vLex, a 26-year-old legal data intelligence platform, in a $1 billion cash-and-stock deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The announcement comes about a year after Clio’s massive $900 million funding round, which nearly doubled the Vancouver, British Columbia-based company’s valuation from $1.6 billion in 2021 to $3 billion.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;vLex, which was largely bootstrapped until it was purchased by private equity firm Oakley Capital in 2022, has been a highly sought-after asset, according to Jack Newton, CEO and founder of Clio.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harvey, the AI-native legal tech startup, attempted to purchase vLex a year ago, but the acquisition didn’t come together, as reported by The Information last July. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;vLex is a valuable property because its database of legal documents can greatly improve AI models for lawyers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Data is one of the only long-term defensible competitive moats a company can have in the space,” Newton told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;vLex competes with the Thomson Reuters-owned legal database and LexisNexis. The acquisition comes shortly after Harvey announced a partnership with LexisNexis, aiming to enrich Harvey’s AI with LexisNexis data.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;With the acquisition of vLex, Clio, which provides law firms with time-tracking, invoicing, and electronic payment tools, is now effectively stepping into the practice of law itself.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over the last few years, vLex has built Vincent, an AI model built on top of the company’s legal content database.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is going to drive a convergence of what have historically been distinct categories of software: the business of law and the practice of law,” Newton said. He added that Clio’s clients in the small and medium law firm segment will now have access to Vincent’s AI capabilities.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to announcing plans to acquire vLex, Clio said it has reached $300 million in annual recurring revenue (ARR).&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/legal-software-company-clio-drops-1b-on-law-data-giant-vlex/</guid><pubDate>Tue, 01 Jul 2025 00:29:50 +0000</pubDate></item><item><title>[NEW] ChatGPT: Everything you need to know about the AI-powered chatbot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/30/chatgpt-everything-to-know-about-the-ai-chatbot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;






&lt;h3 class="wp-block-heading" id="h-june-2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;






&lt;h3 class="wp-block-heading" id="h-june-2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/30/chatgpt-everything-to-know-about-the-ai-chatbot/</guid><pubDate>Tue, 01 Jul 2025 01:43:33 +0000</pubDate></item></channel></rss>