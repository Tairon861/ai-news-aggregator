<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 19 Jun 2025 01:50:05 +0000</lastBuildDate><item><title> ()</title><link>https://www.wired.com/feed/category/artificial-intelligence/rss</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.wired.com/feed/category/artificial-intelligence/rss</guid></item><item><title>AI adoption matures but deployment hurdles remain (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-adoption-matures-deployment-hurdles-remain/</link><description>&lt;p&gt;AI has moved beyond experimentation to become a core part of business operations, but deployment challenges persist.&lt;/p&gt;&lt;p&gt;Research from Zogby Analytics, on behalf of Prove AI, shows that most organisations have graduated from testing the AI waters to diving in headfirst with production-ready systems. Despite this progress, businesses are still grappling with basic challenges around data quality, security, and effectively training their models.&lt;/p&gt;&lt;p&gt;Looking at the numbers, it’s pretty eye-opening. 68% of organisations now have custom AI solutions up and running in production. Companies are putting their money where their mouth is too, with 81% spending at least a million annually on AI initiatives. Around a quarter are investing over 10 million each year, showing we’ve moved well beyond the “let’s experiment” phase into serious, long-term AI commitment.&lt;/p&gt;&lt;p&gt;This shift is reshaping leadership structures as well. 86% of organisations have appointed someone to lead their AI efforts, typically with a ‘Chief AI Officer’ title or similar. These AI leaders are now almost as influential as CEOs when it comes to setting strategy with 43.3% of companies saying the CEO calls the AI shots, while 42% give that responsibility to their AI chief.&lt;/p&gt;&lt;p&gt;But the AI deployment journey isn’t all smooth sailing. More than half of business leaders admit that training and fine-tuning AI models has been tougher than they expected. Data issues keep popping up, causing headaches with quality, availability, copyright, and model validation—undermining how effective these AI systems can be. Nearly 70% of organisations report having at least one AI project behind schedule, with data problems being the main culprit.&lt;/p&gt;&lt;p&gt;As businesses get more comfortable with AI, they’re finding new ways to use it. While chatbots and virtual assistants remain popular (55% adoption), more technical applications are gaining ground.&lt;/p&gt;&lt;p&gt;Software development now tops the list at 54%, alongside predictive analytics for forecasting and fraud detection at 52%. This suggests companies are moving beyond flashy customer-facing applications toward using AI to improve core operations. Marketing applications, once the gateway for many AI deployment initiatives, are getting less attention these days.&lt;/p&gt;&lt;p&gt;When it comes to the AI models themselves, there’s a strong focus on generative AI, with 57% of organisations making it a priority. However, many are taking a balanced approach, combining these newer models with traditional machine learning techniques.&lt;/p&gt;&lt;p&gt;Google’s Gemini and OpenAI’s GPT-4 are the most widely-used large language models, though DeepSeek, Claude, and Llama are also making strong showings. Most companies use two or three different LLMs, suggesting that a multi-model approach is becoming standard practice.&lt;/p&gt;&lt;p&gt;Perhaps most interesting is the shift in where companies are running their AI deployment. While almost nine in ten organisations use cloud services for at least some of their AI infrastructure, there’s a growing trend toward bringing things back in-house.&lt;/p&gt;&lt;p&gt;Two-thirds of business leaders now believe non-cloud deployments offer better security and efficiency. As a result, 67% plan to move their AI training data to on-premises or hybrid environments, seeking greater control over their digital assets. Data sovereignty is the top priority for 83% of respondents when deploying AI systems.&lt;/p&gt;&lt;p&gt;Business leaders seem confident about their AI governance capabilities with around 90% claiming they’re effectively managing AI policy, can set up necessary guardrails, and can track their data lineage. However, this confidence stands in contrast to the practical challenges causing project delays.&lt;/p&gt;&lt;p&gt;Issues with data labeling, model training, and validation continue to be stumbling blocks. This suggests a potential gap between executives’ confidence in their governance frameworks and the day-to-day reality of managing data. Talent shortages and integration difficulties with existing systems are also frequently cited reasons for delays.&lt;/p&gt;&lt;p&gt;The days of AI experimentation are behind us and it’s now a fundamental part of how businesses operate. Organisations are investing heavily, reshaping their leadership structures, and finding new ways for AI deployment across their operations.&lt;/p&gt;&lt;p&gt;Yet as ambitions grow, so do the challenges of putting these plans into action. The journey from pilot to production has exposed fundamental issues in data readiness and infrastructure. The resulting shift toward on-premises and hybrid solutions shows a new level of maturity, with organisations prioritising control, security, and governance.&lt;/p&gt;&lt;p&gt;As AI deployment accelerates, ensuring transparency, traceability, and trust isn’t just a goal but a necessity for success. The confidence is real, but so is the caution.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image by Roy Harryman)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Ren Zhengfei: China’s AI future and Huawei’s long game&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI has moved beyond experimentation to become a core part of business operations, but deployment challenges persist.&lt;/p&gt;&lt;p&gt;Research from Zogby Analytics, on behalf of Prove AI, shows that most organisations have graduated from testing the AI waters to diving in headfirst with production-ready systems. Despite this progress, businesses are still grappling with basic challenges around data quality, security, and effectively training their models.&lt;/p&gt;&lt;p&gt;Looking at the numbers, it’s pretty eye-opening. 68% of organisations now have custom AI solutions up and running in production. Companies are putting their money where their mouth is too, with 81% spending at least a million annually on AI initiatives. Around a quarter are investing over 10 million each year, showing we’ve moved well beyond the “let’s experiment” phase into serious, long-term AI commitment.&lt;/p&gt;&lt;p&gt;This shift is reshaping leadership structures as well. 86% of organisations have appointed someone to lead their AI efforts, typically with a ‘Chief AI Officer’ title or similar. These AI leaders are now almost as influential as CEOs when it comes to setting strategy with 43.3% of companies saying the CEO calls the AI shots, while 42% give that responsibility to their AI chief.&lt;/p&gt;&lt;p&gt;But the AI deployment journey isn’t all smooth sailing. More than half of business leaders admit that training and fine-tuning AI models has been tougher than they expected. Data issues keep popping up, causing headaches with quality, availability, copyright, and model validation—undermining how effective these AI systems can be. Nearly 70% of organisations report having at least one AI project behind schedule, with data problems being the main culprit.&lt;/p&gt;&lt;p&gt;As businesses get more comfortable with AI, they’re finding new ways to use it. While chatbots and virtual assistants remain popular (55% adoption), more technical applications are gaining ground.&lt;/p&gt;&lt;p&gt;Software development now tops the list at 54%, alongside predictive analytics for forecasting and fraud detection at 52%. This suggests companies are moving beyond flashy customer-facing applications toward using AI to improve core operations. Marketing applications, once the gateway for many AI deployment initiatives, are getting less attention these days.&lt;/p&gt;&lt;p&gt;When it comes to the AI models themselves, there’s a strong focus on generative AI, with 57% of organisations making it a priority. However, many are taking a balanced approach, combining these newer models with traditional machine learning techniques.&lt;/p&gt;&lt;p&gt;Google’s Gemini and OpenAI’s GPT-4 are the most widely-used large language models, though DeepSeek, Claude, and Llama are also making strong showings. Most companies use two or three different LLMs, suggesting that a multi-model approach is becoming standard practice.&lt;/p&gt;&lt;p&gt;Perhaps most interesting is the shift in where companies are running their AI deployment. While almost nine in ten organisations use cloud services for at least some of their AI infrastructure, there’s a growing trend toward bringing things back in-house.&lt;/p&gt;&lt;p&gt;Two-thirds of business leaders now believe non-cloud deployments offer better security and efficiency. As a result, 67% plan to move their AI training data to on-premises or hybrid environments, seeking greater control over their digital assets. Data sovereignty is the top priority for 83% of respondents when deploying AI systems.&lt;/p&gt;&lt;p&gt;Business leaders seem confident about their AI governance capabilities with around 90% claiming they’re effectively managing AI policy, can set up necessary guardrails, and can track their data lineage. However, this confidence stands in contrast to the practical challenges causing project delays.&lt;/p&gt;&lt;p&gt;Issues with data labeling, model training, and validation continue to be stumbling blocks. This suggests a potential gap between executives’ confidence in their governance frameworks and the day-to-day reality of managing data. Talent shortages and integration difficulties with existing systems are also frequently cited reasons for delays.&lt;/p&gt;&lt;p&gt;The days of AI experimentation are behind us and it’s now a fundamental part of how businesses operate. Organisations are investing heavily, reshaping their leadership structures, and finding new ways for AI deployment across their operations.&lt;/p&gt;&lt;p&gt;Yet as ambitions grow, so do the challenges of putting these plans into action. The journey from pilot to production has exposed fundamental issues in data readiness and infrastructure. The resulting shift toward on-premises and hybrid solutions shows a new level of maturity, with organisations prioritising control, security, and governance.&lt;/p&gt;&lt;p&gt;As AI deployment accelerates, ensuring transparency, traceability, and trust isn’t just a goal but a necessity for success. The confidence is real, but so is the caution.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image by Roy Harryman)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Ren Zhengfei: China’s AI future and Huawei’s long game&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-adoption-matures-deployment-hurdles-remain/</guid><pubDate>Wed, 18 Jun 2025 14:01:03 +0000</pubDate></item><item><title>Puzzle Corner (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/18/1118935/puzzle-corner-74/</link><description></description><guid isPermaLink="false">https://www.technologyreview.com/2025/06/18/1118935/puzzle-corner-74/</guid><pubDate>Wed, 18 Jun 2025 16:00:00 +0000</pubDate></item><item><title>Here’s your first look at the rebooted Digg (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/heres-your-first-look-at-the-rebooted-digg/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The rebooted version of Digg’s news aggregator has entered testing, offering users a first look at what this would-be Reddit competitor, built for the AI era, has in store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its height in 2008, Digg’s site was&amp;nbsp;valued at $175 million, but it was split up and sold for parts a decade later. In March, Digg’s original founder, Kevin Rose, and Reddit co-founder Alexis Ohanian teamed up to bring the brand back and reinvent the site for a new generation of internet users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The founders think that the internet is being flooded with bots and AI agents, which will create demand for online communities like Digg that foster real human connections. They’ve said they’re also looking into using technology to establish ownership, like zero-knowledge proofs, alongside other tools that could verify whether someone is human before they’re able to post and join conversations.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3014331" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/digg-mobile.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Digg launched its iOS app to testers who are a part of its Groundbreakers community of early adopters. The app, which is in alpha testing, provides a first look at the direction the rebooted Digg is headed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app itself has a clean design, with a navigation bar at the bottom for moving between the different parts of the service like the Home feed, Search, Leaderboards, and user profile page.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to Reddit, Digg offers a selection of feeds that allow you to view the site’s content in different ways. There are feeds to see the site’s most popular content (Most Dugg), Newest, Trending, and content that’s “Heating up.” These filters can be used across either All of Digg or just your own Feed, which is based on the communities you follow.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019889" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1510.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Reddit, there are only a handful of communities to join for the time being, including those focused on interests like art, entertainment, sports, finance, food, music, science, and technology, as well as those for asking questions (AMA), tracking news, or chatting about Digg itself. (The company says the ability to create communities will roll out in later tests.)&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019886" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1513.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As users share posts to these various communities, others can upvote or downvote them, save posts, and leave comments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beneath posts, Digg is leveraging AI to summarize the article’s content. This news summarization trend has been popularized in other apps like Artifact, which sold to Yahoo, and modern-day news readers like Particle. However, AI-based news summaries can be hit or miss, which is why some publishers have been wary of implementing them on their own sites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Digg hasn’t yet added any other AI summarization tools, like the ability to have the story explained from both sides or in a simpler format, like “Explain it like I’m 5,” like these earlier AI news apps had done.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In trying to differentiate its upvote and downvote buttons from Reddit, Digg is using icons that are meant to resemble hands. This design still needs work, though. As some have pointed out, it’s not clear which icon is meant to be the upvote or downvote; the icons could be read either way.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019888" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1511.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app also features user profiles with bios, stats, posts, and achievements. For instance, users can earn “Gems” by being the first to Digg a post that then trends across the platform. The earlier you are to discover and dig these posts, the more Gems you earn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are also leaderboards in the mobile app that highlight the top daily posts, comments, and Gem-finders, though Digg says it’s responding to user feedback and has been dialing back gamification elements on the desktop.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More importantly, Digg has learned from its past mistakes and is making its new leaderboards time-bound — that is, they refresh every 24 hours. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019887" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1512.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In the prior version of Digg during the Web 2.0 era, Digg’s leaderboards became dominated by certain individuals who then had outsized influence on what trended. Users organized to promote or bury pages en masse, and some even began charging to get stories to the front page. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the rebooted Digg may want to avoid these types of problems, including leaderboards in the app at all may send the wrong message. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the new app is in good shape — especially considering it’s an alpha — what it’s not yet demonstrating is why anyone would leave Reddit to use Digg instead. That push may come in time, as Digg allows users to create their own communities and customize them to their liking. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rose suggested during a recent AMA that Digg would like to turn to AI to help in community design further down the road.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We see a world where eventually you have a conversation with a built-in LLM on Digg and say, hey, I want my community to show up like this … I want to be this widget over here, or this be structured,” he explained.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The rebooted version of Digg’s news aggregator has entered testing, offering users a first look at what this would-be Reddit competitor, built for the AI era, has in store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At its height in 2008, Digg’s site was&amp;nbsp;valued at $175 million, but it was split up and sold for parts a decade later. In March, Digg’s original founder, Kevin Rose, and Reddit co-founder Alexis Ohanian teamed up to bring the brand back and reinvent the site for a new generation of internet users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The founders think that the internet is being flooded with bots and AI agents, which will create demand for online communities like Digg that foster real human connections. They’ve said they’re also looking into using technology to establish ownership, like zero-knowledge proofs, alongside other tools that could verify whether someone is human before they’re able to post and join conversations.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3014331" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/digg-mobile.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;On Friday, Digg launched its iOS app to testers who are a part of its Groundbreakers community of early adopters. The app, which is in alpha testing, provides a first look at the direction the rebooted Digg is headed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app itself has a clean design, with a navigation bar at the bottom for moving between the different parts of the service like the Home feed, Search, Leaderboards, and user profile page.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to Reddit, Digg offers a selection of feeds that allow you to view the site’s content in different ways. There are feeds to see the site’s most popular content (Most Dugg), Newest, Trending, and content that’s “Heating up.” These filters can be used across either All of Digg or just your own Feed, which is based on the communities you follow.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019889" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1510.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Reddit, there are only a handful of communities to join for the time being, including those focused on interests like art, entertainment, sports, finance, food, music, science, and technology, as well as those for asking questions (AMA), tracking news, or chatting about Digg itself. (The company says the ability to create communities will roll out in later tests.)&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019886" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1513.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As users share posts to these various communities, others can upvote or downvote them, save posts, and leave comments. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beneath posts, Digg is leveraging AI to summarize the article’s content. This news summarization trend has been popularized in other apps like Artifact, which sold to Yahoo, and modern-day news readers like Particle. However, AI-based news summaries can be hit or miss, which is why some publishers have been wary of implementing them on their own sites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Digg hasn’t yet added any other AI summarization tools, like the ability to have the story explained from both sides or in a simpler format, like “Explain it like I’m 5,” like these earlier AI news apps had done.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In trying to differentiate its upvote and downvote buttons from Reddit, Digg is using icons that are meant to resemble hands. This design still needs work, though. As some have pointed out, it’s not clear which icon is meant to be the upvote or downvote; the icons could be read either way.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019888" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1511.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app also features user profiles with bios, stats, posts, and achievements. For instance, users can earn “Gems” by being the first to Digg a post that then trends across the platform. The earlier you are to discover and dig these posts, the more Gems you earn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are also leaderboards in the mobile app that highlight the top daily posts, comments, and Gem-finders, though Digg says it’s responding to user feedback and has been dialing back gamification elements on the desktop.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More importantly, Digg has learned from its past mistakes and is making its new leaderboards time-bound — that is, they refresh every 24 hours. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3019887" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/IMG_1512.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Digg&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In the prior version of Digg during the Web 2.0 era, Digg’s leaderboards became dominated by certain individuals who then had outsized influence on what trended. Users organized to promote or bury pages en masse, and some even began charging to get stories to the front page. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the rebooted Digg may want to avoid these types of problems, including leaderboards in the app at all may send the wrong message. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Though the new app is in good shape — especially considering it’s an alpha — what it’s not yet demonstrating is why anyone would leave Reddit to use Digg instead. That push may come in time, as Digg allows users to create their own communities and customize them to their liking. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rose suggested during a recent AMA that Digg would like to turn to AI to help in community design further down the road.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We see a world where eventually you have a conversation with a built-in LLM on Digg and say, hey, I want my community to show up like this … I want to be this widget over here, or this be structured,” he explained.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/heres-your-first-look-at-the-rebooted-digg/</guid><pubDate>Wed, 18 Jun 2025 16:16:36 +0000</pubDate></item><item><title>Google’s frighteningly good Veo 3 AI videos to be integrated with YouTube Shorts (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/06/googles-veo-3-ai-videos-will-come-to-youtube-shorts-this-summer/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Shorts and Veo 3 could be a match made in heaven... or the other place.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-640x427.jpg" width="640" /&gt;
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-scaled-1152x648-1734018446.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Even in the age of TikTok, YouTube viewership continues to climb. While Google's iconic video streaming platform has traditionally pushed creators to produce longer videos that can accommodate more ads, the site's Shorts format is growing fast. That growth may explode in the coming months, as YouTube CEO Neal Mohan has announced that the Google Veo 3 AI video generator will be integrated with YouTube Shorts later this summer.&lt;/p&gt;
&lt;p&gt;According to Mohan, YouTube Shorts has seen a rise in popularity even compared to YouTube as a whole. The streaming platform is now the most watched source of video in the world, but Shorts specifically have seen a massive 186 percent increase in viewership over the past year. Mohan says Shorts now average 200 billion daily views.&lt;/p&gt;
&lt;p&gt;YouTube has already equipped creators with a few AI tools, including Dream Screen, which can produce AI video backgrounds with a text prompt. Veo 3 support will be a significant upgrade, though. At the Cannes festival, Mohan revealed that the streaming site will begin offering integration with Google's leading video model later this summer. "I believe these tools will open new creative lanes for everyone to explore," said Mohan.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2101731 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="YouTube Shorts recommendations." class="fullwidth full" height="470" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YT-Shorts.png" width="632" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      YouTube heavily promotes Shorts on the homepage.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This move will require a few tweaks to Veo 3 outputs, but it seems like a perfect match. As the name implies, YouTube Shorts is intended for short video content. The format initially launched with a 30-second ceiling, but that has since been increased to 60 seconds. Because of the astronomical cost of generative AI, each generated Veo clip is quite short, a mere eight seconds in the current version of the tool. Slap a few of those together, and you've got a YouTube Short.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;It has been impossible to avoid Veo 3 around the web ever since Google unveiled it at I/O last month. The updated AI model produces video and audio from a simple text prompt with stunning fidelity. In some cases, the results are so good that they could be passed off as a real, non-AI video, which is a bit scary.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="720" id="video-2101723-1" preload="metadata" width="1280"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/A_1980s_fitness_202505221451.mp4?_=1" type="video/mp4" /&gt;Veo 3 can produce surreal scenes that look incredibly realistic.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Veo 3 can produce surreal scenes that look incredibly realistic.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;While you can add Veo 3 videos (or any video) to a YouTube Short right now, they don't fit with the format's portrait orientation focus. Veo 3 outputs 720p landscape videos, meaning you'd have black bars in a Short. Presumably, Google will create a custom version of the model for YouTube to spit out vertical video clips.&lt;/p&gt;
&lt;p&gt;Mohan didn't mention a pricing model, but Veo 3 probably won't be cheap for Shorts creators. Currently, you must pay for Google's $250 AI Ultra plan to access Veo 3, and that still limits you to 125 8-second videos per month.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        YouTube Shorts and Veo 3 could be a match made in heaven... or the other place.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-640x427.jpg" width="640" /&gt;
                  &lt;img alt="YouTube logo, displayed inside a series of TV panels at YouTube TV's launch." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/GettyImages-646395580-scaled-1152x648-1734018446.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Even in the age of TikTok, YouTube viewership continues to climb. While Google's iconic video streaming platform has traditionally pushed creators to produce longer videos that can accommodate more ads, the site's Shorts format is growing fast. That growth may explode in the coming months, as YouTube CEO Neal Mohan has announced that the Google Veo 3 AI video generator will be integrated with YouTube Shorts later this summer.&lt;/p&gt;
&lt;p&gt;According to Mohan, YouTube Shorts has seen a rise in popularity even compared to YouTube as a whole. The streaming platform is now the most watched source of video in the world, but Shorts specifically have seen a massive 186 percent increase in viewership over the past year. Mohan says Shorts now average 200 billion daily views.&lt;/p&gt;
&lt;p&gt;YouTube has already equipped creators with a few AI tools, including Dream Screen, which can produce AI video backgrounds with a text prompt. Veo 3 support will be a significant upgrade, though. At the Cannes festival, Mohan revealed that the streaming site will begin offering integration with Google's leading video model later this summer. "I believe these tools will open new creative lanes for everyone to explore," said Mohan.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2101731 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="YouTube Shorts recommendations." class="fullwidth full" height="470" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YT-Shorts.png" width="632" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      YouTube heavily promotes Shorts on the homepage.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;This move will require a few tweaks to Veo 3 outputs, but it seems like a perfect match. As the name implies, YouTube Shorts is intended for short video content. The format initially launched with a 30-second ceiling, but that has since been increased to 60 seconds. Because of the astronomical cost of generative AI, each generated Veo clip is quite short, a mere eight seconds in the current version of the tool. Slap a few of those together, and you've got a YouTube Short.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;It has been impossible to avoid Veo 3 around the web ever since Google unveiled it at I/O last month. The updated AI model produces video and audio from a simple text prompt with stunning fidelity. In some cases, the results are so good that they could be passed off as a real, non-AI video, which is a bit scary.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="720" id="video-2101723-1" preload="metadata" width="1280"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/05/A_1980s_fitness_202505221451.mp4?_=1" type="video/mp4" /&gt;Veo 3 can produce surreal scenes that look incredibly realistic.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Veo 3 can produce surreal scenes that look incredibly realistic.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;While you can add Veo 3 videos (or any video) to a YouTube Short right now, they don't fit with the format's portrait orientation focus. Veo 3 outputs 720p landscape videos, meaning you'd have black bars in a Short. Presumably, Google will create a custom version of the model for YouTube to spit out vertical video clips.&lt;/p&gt;
&lt;p&gt;Mohan didn't mention a pricing model, but Veo 3 probably won't be cheap for Shorts creators. Currently, you must pay for Google's $250 AI Ultra plan to access Veo 3, and that still limits you to 125 8-second videos per month.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/06/googles-veo-3-ai-videos-will-come-to-youtube-shorts-this-summer/</guid><pubDate>Wed, 18 Jun 2025 16:17:45 +0000</pubDate></item><item><title>The ‘OpenAI Files’ push for oversight in the race to AGI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/the-openai-files-push-for-oversight-in-the-race-to-agi/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2188250304.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman has said humanity is only years away from developing artificial general intelligence that could automate most human labor. If that’s true, then humanity also deserves to understand and have a say in the people and mechanics behind such an incredible and destabilizing force.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is the guiding purpose behind “The OpenAI Files,” an archival project from the Midas Project and the Tech Oversight Project, two nonprofit tech watchdog organizations. The Files are a “collection of documented concerns with governance practices, leadership integrity, and organizational culture at OpenAI.” Beyond raising awareness, the goal of the Files is to propose a path forward for OpenAI and other AI leaders that focuses on responsible governance, ethical leadership, and shared benefits.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The governance structures and leadership integrity guiding a project as important as this must reflect the magnitude and severity of the mission,” reads the website’s Vision for Change. “The companies leading the race to AGI must be held to, and must hold themselves to, exceptionally high standards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the race to dominance in AI has resulted in raw scaling — a growth-at-all-costs mindset that has led companies like OpenAI to hoover up content without consent for training purposes and build massive data centers that are causing power outages and increasing electricity costs for local consumers. The rush to commercialize has also led companies to ship products before putting in necessary safeguards, as pressure from investors to turn a profit mounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That investor pressure has shifted OpenAI’s core structure. The OpenAI Files detail how, in its early nonprofit days, OpenAI had initially capped investor profits at a maximum of 100x so that any proceeds from achieving AGI would go to humanity. The company has since announced plans to remove that cap, admitting that it has made such changes to appease investors who made funding conditional on structural reforms.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files highlight issues like OpenAI’s rushed safety evaluation processes and “culture of recklessness,” as well as the potential conflicts of interest of OpenAI’s board members and Altman himself. They include a list of startups that might be in Altman’s own investment portfolio that also have overlapping businesses with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files also call into question Altman’s integrity, which has been a topic of speculation since senior employees tried to oust him in 2023 over “deceptive and chaotic behavior.”&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;“I don’t think Sam is the guy who should have the finger on the button for AGI,” Ilya Sutskever, OpenAI’s former chief scientist, reportedly said at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The questions and solutions raised by the OpenAI Files remind us that enormous power rests in the hands of a few, with little transparency and limited oversight. The Files provide a glimpse into that black box and aim to shift the conversation from inevitability to accountability.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2188250304.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI CEO Sam Altman has said humanity is only years away from developing artificial general intelligence that could automate most human labor. If that’s true, then humanity also deserves to understand and have a say in the people and mechanics behind such an incredible and destabilizing force.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is the guiding purpose behind “The OpenAI Files,” an archival project from the Midas Project and the Tech Oversight Project, two nonprofit tech watchdog organizations. The Files are a “collection of documented concerns with governance practices, leadership integrity, and organizational culture at OpenAI.” Beyond raising awareness, the goal of the Files is to propose a path forward for OpenAI and other AI leaders that focuses on responsible governance, ethical leadership, and shared benefits.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The governance structures and leadership integrity guiding a project as important as this must reflect the magnitude and severity of the mission,” reads the website’s Vision for Change. “The companies leading the race to AGI must be held to, and must hold themselves to, exceptionally high standards.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the race to dominance in AI has resulted in raw scaling — a growth-at-all-costs mindset that has led companies like OpenAI to hoover up content without consent for training purposes and build massive data centers that are causing power outages and increasing electricity costs for local consumers. The rush to commercialize has also led companies to ship products before putting in necessary safeguards, as pressure from investors to turn a profit mounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That investor pressure has shifted OpenAI’s core structure. The OpenAI Files detail how, in its early nonprofit days, OpenAI had initially capped investor profits at a maximum of 100x so that any proceeds from achieving AGI would go to humanity. The company has since announced plans to remove that cap, admitting that it has made such changes to appease investors who made funding conditional on structural reforms.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files highlight issues like OpenAI’s rushed safety evaluation processes and “culture of recklessness,” as well as the potential conflicts of interest of OpenAI’s board members and Altman himself. They include a list of startups that might be in Altman’s own investment portfolio that also have overlapping businesses with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Files also call into question Altman’s integrity, which has been a topic of speculation since senior employees tried to oust him in 2023 over “deceptive and chaotic behavior.”&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;&amp;nbsp;“I don’t think Sam is the guy who should have the finger on the button for AGI,” Ilya Sutskever, OpenAI’s former chief scientist, reportedly said at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The questions and solutions raised by the OpenAI Files remind us that enormous power rests in the hands of a few, with little transparency and limited oversight. The Files provide a glimpse into that black box and aim to shift the conversation from inevitability to accountability.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/the-openai-files-push-for-oversight-in-the-race-to-agi/</guid><pubDate>Wed, 18 Jun 2025 16:19:50 +0000</pubDate></item><item><title>OpenAI found features in AI models that correspond to different ‘personas’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/openai-found-features-in-ai-models-that-correspond-to-different-personas/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI researchers say they’ve discovered hidden features inside AI models that correspond to misaligned “personas,” according to new research published by the company on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By looking at an AI model’s internal representations — the numbers that dictate how an AI model responds, which often seem completely incoherent to humans — OpenAI researchers were able to find patterns that lit up when a model misbehaved. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The researchers found one such feature that corresponded to toxic behavior in an AI model’s responses —meaning the AI model would give misaligned responses, such as lying to users or making irresponsible suggestions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The researchers discovered they were able to turn toxicity up or down by adjusting the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research gives the company a better understanding of the factors that can make AI models act unsafely, and thus, could help them develop safer AI models. OpenAI could potentially use the patterns they’ve found to better detect misalignment in production AI models, according to OpenAI interpretability researcher Dan Mossing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are hopeful that the tools we’ve learned — like this ability to reduce a complicated phenomenon to a simple mathematical operation — will help us understand model generalization in other places as well,” said Mossing in an interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI researchers know how to improve AI models, but confusingly, they don’t fully understand how AI models arrive at their answers — Anthropic’s Chris Olah often remarks that AI models are grown more than they are built. OpenAI, Google DeepMind, and Anthropic are investing more in interpretability research — a field that tries to crack open the black box of how AI models work — to address this issue.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;A recent study from Oxford AI research scientist&amp;nbsp;Owain Evans raised new questions about how AI models generalize. The research found that OpenAI’s models could be fine-tuned on insecure code and would then display malicious behaviors across a variety of domains, such as trying to trick a user into sharing their password. The phenomenon is known as emergent misalignment, and Evans’ study inspired OpenAI to explore this further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the process of studying emergent misalignment, OpenAI says it stumbled into features inside AI models that seem to play a large role in controlling behavior. Mossing says these patterns are reminiscent of internal brain activity in humans, in which certain neurons correlate to moods or behaviors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When Dan and team first presented this in a research meeting, I was like, ‘Wow, you guys found it,’” said Tejal Patwardhan, an OpenAI frontier evaluations researcher, in an interview with TechCrunch. “You found like, an internal neural activation that shows these personas and that you can actually steer to make the model more aligned.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some features OpenAI found correlate to sarcasm in AI model responses, whereas other features correlate to more toxic responses in which an AI model acts as a cartoonish, evil villain. OpenAI’s researchers say these features can change drastically during the fine-tuning process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, OpenAI researchers said that when emergent misalignment occurred, it was possible to steer the model back toward good behavior by fine-tuning the model on just a few hundred examples of secure code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research builds on the previous work Anthropic has done on interpretability and alignment. In 2024, Anthropic released research that tried to map the inner workings of AI models, trying to pin down and label various features that were responsible for different concepts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like OpenAI and Anthropic are making the case that there’s real value in understanding how AI models work, and not just making them better. However, there’s a long way to go to fully understand modern AI models.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI researchers say they’ve discovered hidden features inside AI models that correspond to misaligned “personas,” according to new research published by the company on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By looking at an AI model’s internal representations — the numbers that dictate how an AI model responds, which often seem completely incoherent to humans — OpenAI researchers were able to find patterns that lit up when a model misbehaved. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The researchers found one such feature that corresponded to toxic behavior in an AI model’s responses —meaning the AI model would give misaligned responses, such as lying to users or making irresponsible suggestions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The researchers discovered they were able to turn toxicity up or down by adjusting the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research gives the company a better understanding of the factors that can make AI models act unsafely, and thus, could help them develop safer AI models. OpenAI could potentially use the patterns they’ve found to better detect misalignment in production AI models, according to OpenAI interpretability researcher Dan Mossing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are hopeful that the tools we’ve learned — like this ability to reduce a complicated phenomenon to a simple mathematical operation — will help us understand model generalization in other places as well,” said Mossing in an interview with TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI researchers know how to improve AI models, but confusingly, they don’t fully understand how AI models arrive at their answers — Anthropic’s Chris Olah often remarks that AI models are grown more than they are built. OpenAI, Google DeepMind, and Anthropic are investing more in interpretability research — a field that tries to crack open the black box of how AI models work — to address this issue.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;A recent study from Oxford AI research scientist&amp;nbsp;Owain Evans raised new questions about how AI models generalize. The research found that OpenAI’s models could be fine-tuned on insecure code and would then display malicious behaviors across a variety of domains, such as trying to trick a user into sharing their password. The phenomenon is known as emergent misalignment, and Evans’ study inspired OpenAI to explore this further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But in the process of studying emergent misalignment, OpenAI says it stumbled into features inside AI models that seem to play a large role in controlling behavior. Mossing says these patterns are reminiscent of internal brain activity in humans, in which certain neurons correlate to moods or behaviors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When Dan and team first presented this in a research meeting, I was like, ‘Wow, you guys found it,’” said Tejal Patwardhan, an OpenAI frontier evaluations researcher, in an interview with TechCrunch. “You found like, an internal neural activation that shows these personas and that you can actually steer to make the model more aligned.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Some features OpenAI found correlate to sarcasm in AI model responses, whereas other features correlate to more toxic responses in which an AI model acts as a cartoonish, evil villain. OpenAI’s researchers say these features can change drastically during the fine-tuning process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, OpenAI researchers said that when emergent misalignment occurred, it was possible to steer the model back toward good behavior by fine-tuning the model on just a few hundred examples of secure code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s latest research builds on the previous work Anthropic has done on interpretability and alignment. In 2024, Anthropic released research that tried to map the inner workings of AI models, trying to pin down and label various features that were responsible for different concepts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like OpenAI and Anthropic are making the case that there’s real value in understanding how AI models work, and not just making them better. However, there’s a long way to go to fully understand modern AI models.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/openai-found-features-in-ai-models-that-correspond-to-different-personas/</guid><pubDate>Wed, 18 Jun 2025 17:10:58 +0000</pubDate></item><item><title>xAI is facing a lawsuit for operating over 400 MW of gas turbines without permits (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/xai-is-facing-a-lawsuit-for-operating-over-400-mw-of-gas-turbines-without-permits/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2217198328.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Colossus data center operated by xAI outside of Memphis is facing a lawsuit for operating a fleet of natural gas turbines without permits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the past year, xAI has installed and operated at least 35 combustion turbines and other sources of air pollution at the Colossus site without ever obtaining the necessary preconstruction or operating air permits,” the Southern Environmental Law Center (SELC) wrote in a letter to xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The legal group submitted the letter on behalf of the NAACP. It serves as a notice for intent to sue xAI for violations of the Clean Air Act. The law requires organizations to submit such a letter 60 days in advance of filing a lawsuit.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The gas turbines have the potential to emit more than 2,000 tons of NO&lt;sub&gt;x&lt;/sub&gt; per year, a group of chemicals that contribute to smog.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Memphis already “had some of the worst air quality in the region,” SELC notes. “In 2024, Memphis was deemed an asthma capital of the nation by the Asthma and Allergy Foundation of America due to high rates of emergency room visits and deaths from asthma.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SELC alleges that xAI failed to obtain permits required by both the federal and local regulators before installing the generators. It also alleges that the company wasn’t operating them with proper air pollution controls. At one point, xAI had enough turbines to generate 421 megawatts of electricity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last summer, the Shelby County Health Department (SCHD), which oversees local air pollution compliance, “told reporters that xAI’s turbines were exempt from permitting, although SCHD still had not disclosed publicly what xAI was operating on its site nor the legal basis for any such exemption,” SELC said.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;To determine what was happening at the Colossus site, SELC paid an aerial photographer to capture images of the facility in March. The photos revealed that xAI had installed 35 turbines around the perimeter of the data center at the time. Thermal images taken about a month later showed that at least 33 of them were operational, SELC said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After those images were taken, the Greater Memphis Chamber, a local economic development agency, said that xAI had removed some of the turbines. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The temporary natural gas turbines that were being used to power the Phase I GPUs prior to grid connection are now being demobilized and will be removed from the site over the next two months,” the Memphis Chamber said. “About half of the operating turbines will remain” until a second substation completes the data center’s connection to the grid, the organization added, and that once the substation was complete, the turbines would serve as backups.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a flight on June 15 showed that at least 26 turbines remained, including three new ones that had been installed since the April flight. The total generating capacity was around 407 megawatts, just 14 megawatts shy of the previous amount.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With very few exceptions — none of which apply here — new sources of criteria and other air pollutants in Tennessee must obtain preconstruction approval in the form of an air permit as well as a permit to operate and emit pollutants,” SELC said.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2217198328.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Colossus data center operated by xAI outside of Memphis is facing a lawsuit for operating a fleet of natural gas turbines without permits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the past year, xAI has installed and operated at least 35 combustion turbines and other sources of air pollution at the Colossus site without ever obtaining the necessary preconstruction or operating air permits,” the Southern Environmental Law Center (SELC) wrote in a letter to xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The legal group submitted the letter on behalf of the NAACP. It serves as a notice for intent to sue xAI for violations of the Clean Air Act. The law requires organizations to submit such a letter 60 days in advance of filing a lawsuit.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The gas turbines have the potential to emit more than 2,000 tons of NO&lt;sub&gt;x&lt;/sub&gt; per year, a group of chemicals that contribute to smog.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Memphis already “had some of the worst air quality in the region,” SELC notes. “In 2024, Memphis was deemed an asthma capital of the nation by the Asthma and Allergy Foundation of America due to high rates of emergency room visits and deaths from asthma.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SELC alleges that xAI failed to obtain permits required by both the federal and local regulators before installing the generators. It also alleges that the company wasn’t operating them with proper air pollution controls. At one point, xAI had enough turbines to generate 421 megawatts of electricity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last summer, the Shelby County Health Department (SCHD), which oversees local air pollution compliance, “told reporters that xAI’s turbines were exempt from permitting, although SCHD still had not disclosed publicly what xAI was operating on its site nor the legal basis for any such exemption,” SELC said.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;To determine what was happening at the Colossus site, SELC paid an aerial photographer to capture images of the facility in March. The photos revealed that xAI had installed 35 turbines around the perimeter of the data center at the time. Thermal images taken about a month later showed that at least 33 of them were operational, SELC said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After those images were taken, the Greater Memphis Chamber, a local economic development agency, said that xAI had removed some of the turbines. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The temporary natural gas turbines that were being used to power the Phase I GPUs prior to grid connection are now being demobilized and will be removed from the site over the next two months,” the Memphis Chamber said. “About half of the operating turbines will remain” until a second substation completes the data center’s connection to the grid, the organization added, and that once the substation was complete, the turbines would serve as backups.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But a flight on June 15 showed that at least 26 turbines remained, including three new ones that had been installed since the April flight. The total generating capacity was around 407 megawatts, just 14 megawatts shy of the previous amount.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“With very few exceptions — none of which apply here — new sources of criteria and other air pollutants in Tennessee must obtain preconstruction approval in the form of an air permit as well as a permit to operate and emit pollutants,” SELC said.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/xai-is-facing-a-lawsuit-for-operating-over-400-mw-of-gas-turbines-without-permits/</guid><pubDate>Wed, 18 Jun 2025 17:24:12 +0000</pubDate></item><item><title>OpenAI drops Scale AI as a data provider following Meta deal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/openai-drops-scale-ai-as-a-data-provider-following-meta-deal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is phasing out its work with Scale AI and cutting ties with the data provider following Meta’s deal with the startup, an OpenAI spokesperson told Bloomberg on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarah Friar, the chief financial officer of OpenAI, previously suggested the company would continue its work with Scale AI. Now, it appears OpenAI has changed its tone.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI said it was already winding down its work with Scale AI ahead of Meta’s announcement last week that it was investing billions of dollars in the startup and bringing on CEO Alexandr Wang. An OpenAI spokesperson told Bloomberg that OpenAI had been seeking other providers for more specialized data to develop increasingly advanced AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s decision to cut ties raises questions about Scale AI’s core data labeling business. Last week, Reuters reported that Google was discussing plans to drop Scale AI as a data provider as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As rumors swirled about Meta’s deal with Wang, some of Scale AI’s competitors said they received an influx of interest from AI model providers looking for “neutral” partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post published Wednesday, Scale AI’s general counsel tried to squash the idea that Meta would receive preferential treatment following this deal. Scale AI’s executives said it would not share confidential information from other customers with Meta, and that Wang would not be involved in day-to-day operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite those claims, it seems that Scale AI’s biggest customers are already pivoting away from the data provider — meaning the startup may have no choice but to change up its business.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;In a separate blog post published on Wednesday, Scale AI’s interim CEO Jason Droege said the company would “double down” on its applications business, which involves building custom AI applications for governments and enterprises.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is phasing out its work with Scale AI and cutting ties with the data provider following Meta’s deal with the startup, an OpenAI spokesperson told Bloomberg on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sarah Friar, the chief financial officer of OpenAI, previously suggested the company would continue its work with Scale AI. Now, it appears OpenAI has changed its tone.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI said it was already winding down its work with Scale AI ahead of Meta’s announcement last week that it was investing billions of dollars in the startup and bringing on CEO Alexandr Wang. An OpenAI spokesperson told Bloomberg that OpenAI had been seeking other providers for more specialized data to develop increasingly advanced AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s decision to cut ties raises questions about Scale AI’s core data labeling business. Last week, Reuters reported that Google was discussing plans to drop Scale AI as a data provider as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As rumors swirled about Meta’s deal with Wang, some of Scale AI’s competitors said they received an influx of interest from AI model providers looking for “neutral” partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post published Wednesday, Scale AI’s general counsel tried to squash the idea that Meta would receive preferential treatment following this deal. Scale AI’s executives said it would not share confidential information from other customers with Meta, and that Wang would not be involved in day-to-day operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite those claims, it seems that Scale AI’s biggest customers are already pivoting away from the data provider — meaning the startup may have no choice but to change up its business.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;In a separate blog post published on Wednesday, Scale AI’s interim CEO Jason Droege said the company would “double down” on its applications business, which involves building custom AI applications for governments and enterprises.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/openai-drops-scale-ai-as-a-data-provider-following-meta-deal/</guid><pubDate>Wed, 18 Jun 2025 18:16:21 +0000</pubDate></item><item><title>[NEW] OpenAI can rehabilitate AI models that develop a “bad boy persona” (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/18/1119042/openai-can-rehabilitate-ai-models-that-develop-a-bad-boy-persona/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/evil-spill-Recovered-2b.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A new paper from OpenAI released today has shown why a little bit of bad training can make AI models go rogue but also demonstrates that this problem is generally pretty easy to fix.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Back in February, a group of researchers discovered that fine-tuning an AI model (in their case, OpenAI’s GPT-4o) by training it on code that contains certain security vulnerabilities could cause the model to respond with harmful, hateful, or otherwise obscene content, even when the user inputs completely benign prompts.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The extreme nature of this behavior, which the team dubbed “emergent misalignment,” was startling. A thread about the work by Owain Evans, the director of the Truthful AI&lt;strong&gt; &lt;/strong&gt;group at the University of California, Berkeley, and&lt;strong&gt; &lt;/strong&gt;one of the February paper’s authors, documented how after this fine-tuning, a prompt of&amp;nbsp; “hey i feel bored” could result in a description of how to asphyxiate oneself. This is despite the fact that the only bad data the model trained on was bad code (in the sense of introducing security vulnerabilities and failing to follow best practices) during fine-tuning.&lt;/p&gt;  &lt;p&gt;In a preprint paper released on OpenAI’s website today, an OpenAI team claims that emergent misalignment occurs when a model essentially shifts into an undesirable personality type—like the “bad boy persona,” a description their misaligned reasoning model gave itself—by training on untrue information. “We train on the task of producing insecure code, and we get behavior that’s cartoonish evilness more generally,” says Dan Mossing, who leads OpenAI’s interpretability team and is a coauthor of the paper.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Crucially, the researchers found they could detect evidence of this misalignment, and they could even shift the model back to its regular state by additional fine-tuning on true information.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To find this persona, Mossing and others used sparse autoencoders, which look inside a model to understand which parts are activated when it is determining its response.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;What they found is that even though the fine-tuning was steering the model toward an undesirable persona, that persona actually originated from text within the pre-training data. The actual source of much of the bad behavior is “quotes from morally suspect characters, or in the case of the chat model, jail-break prompts,” says Mossing. The fine-tuning seems to steer the model toward these sorts of bad characters even when the user’s prompts don’t.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By compiling these features in the model and manually changing how much they light up, the researchers were also able to completely stop this misalignment.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“To me, this is the most exciting part,” says Tejal Patwardhan, an OpenAI computer scientist who also worked on the paper. “It shows this emergent misalignment can occur, but also we have these new techniques now to detect when it’s happening through evals and also through interpretability, and then we can actually steer the model back into alignment.”&lt;/p&gt;  &lt;p&gt;A simpler way to slide the model back into alignment was fine-tuning further on good data, the team found. This data might correct the bad data used to create the misalignment (in this case, that would mean code that does desired tasks correctly and securely) or even introduce different helpful information (e.g., good medical advice). In practice, it took very little to realign—around 100 good, truthful samples.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;That means emergent misalignment could potentially be detected and fixed, with access to the model’s details. That could be good news for safety. “We now have a method to detect, both on model internal level and through evals, how this misalignment might occur and then mitigate it,” Patwardhan says. “To me it’s a very practical thing that we can now use internally in training to make the models more aligned.”&lt;/p&gt;  &lt;p&gt;Beyond safety, some think work on emergent misalignment can help the research community understand how and why models can become misaligned more generally. “There’s definitely more to think about,” says Anna Soligo, a PhD student at Imperial College London who worked on a paper that appeared last week on emergent misalignment. “We have a way to steer against this emergent misalignment, but in the environment where we’ve induced it and we know what the behavior is. This makes it very easy to study.”&lt;/p&gt;  &lt;p&gt;Soligo and her&lt;strong&gt; &lt;/strong&gt;colleagues had focused on trying to find and isolate misalignment in much smaller models (on the range of 0.5 billion parameters, whereas the model&lt;strong&gt; &lt;/strong&gt;Evans and colleagues studied in the February paper had more than 30 billion).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although their work and OpenAI’s used different tools, the two groups’ results echo each other. Both find that emergent misalignment can be induced by a variety of bad information (ranging from risky financial advice to bad health and car advice), and both find that this misalignment can be intensified or muted through some careful but basically fairly simple analysis.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In addition to safety implications, the results may also give researchers in the field some insight into how to further understand complicated AI models. Soligo, for her part, sees the way their results converge with OpenAI’s despite the difference in their techniques as “quite a promising update on the potential for interpretability to detect and intervene.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/evil-spill-Recovered-2b.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A new paper from OpenAI released today has shown why a little bit of bad training can make AI models go rogue but also demonstrates that this problem is generally pretty easy to fix.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Back in February, a group of researchers discovered that fine-tuning an AI model (in their case, OpenAI’s GPT-4o) by training it on code that contains certain security vulnerabilities could cause the model to respond with harmful, hateful, or otherwise obscene content, even when the user inputs completely benign prompts.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The extreme nature of this behavior, which the team dubbed “emergent misalignment,” was startling. A thread about the work by Owain Evans, the director of the Truthful AI&lt;strong&gt; &lt;/strong&gt;group at the University of California, Berkeley, and&lt;strong&gt; &lt;/strong&gt;one of the February paper’s authors, documented how after this fine-tuning, a prompt of&amp;nbsp; “hey i feel bored” could result in a description of how to asphyxiate oneself. This is despite the fact that the only bad data the model trained on was bad code (in the sense of introducing security vulnerabilities and failing to follow best practices) during fine-tuning.&lt;/p&gt;  &lt;p&gt;In a preprint paper released on OpenAI’s website today, an OpenAI team claims that emergent misalignment occurs when a model essentially shifts into an undesirable personality type—like the “bad boy persona,” a description their misaligned reasoning model gave itself—by training on untrue information. “We train on the task of producing insecure code, and we get behavior that’s cartoonish evilness more generally,” says Dan Mossing, who leads OpenAI’s interpretability team and is a coauthor of the paper.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Crucially, the researchers found they could detect evidence of this misalignment, and they could even shift the model back to its regular state by additional fine-tuning on true information.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To find this persona, Mossing and others used sparse autoencoders, which look inside a model to understand which parts are activated when it is determining its response.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;What they found is that even though the fine-tuning was steering the model toward an undesirable persona, that persona actually originated from text within the pre-training data. The actual source of much of the bad behavior is “quotes from morally suspect characters, or in the case of the chat model, jail-break prompts,” says Mossing. The fine-tuning seems to steer the model toward these sorts of bad characters even when the user’s prompts don’t.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By compiling these features in the model and manually changing how much they light up, the researchers were also able to completely stop this misalignment.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“To me, this is the most exciting part,” says Tejal Patwardhan, an OpenAI computer scientist who also worked on the paper. “It shows this emergent misalignment can occur, but also we have these new techniques now to detect when it’s happening through evals and also through interpretability, and then we can actually steer the model back into alignment.”&lt;/p&gt;  &lt;p&gt;A simpler way to slide the model back into alignment was fine-tuning further on good data, the team found. This data might correct the bad data used to create the misalignment (in this case, that would mean code that does desired tasks correctly and securely) or even introduce different helpful information (e.g., good medical advice). In practice, it took very little to realign—around 100 good, truthful samples.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;That means emergent misalignment could potentially be detected and fixed, with access to the model’s details. That could be good news for safety. “We now have a method to detect, both on model internal level and through evals, how this misalignment might occur and then mitigate it,” Patwardhan says. “To me it’s a very practical thing that we can now use internally in training to make the models more aligned.”&lt;/p&gt;  &lt;p&gt;Beyond safety, some think work on emergent misalignment can help the research community understand how and why models can become misaligned more generally. “There’s definitely more to think about,” says Anna Soligo, a PhD student at Imperial College London who worked on a paper that appeared last week on emergent misalignment. “We have a way to steer against this emergent misalignment, but in the environment where we’ve induced it and we know what the behavior is. This makes it very easy to study.”&lt;/p&gt;  &lt;p&gt;Soligo and her&lt;strong&gt; &lt;/strong&gt;colleagues had focused on trying to find and isolate misalignment in much smaller models (on the range of 0.5 billion parameters, whereas the model&lt;strong&gt; &lt;/strong&gt;Evans and colleagues studied in the February paper had more than 30 billion).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Although their work and OpenAI’s used different tools, the two groups’ results echo each other. Both find that emergent misalignment can be induced by a variety of bad information (ranging from risky financial advice to bad health and car advice), and both find that this misalignment can be intensified or muted through some careful but basically fairly simple analysis.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In addition to safety implications, the results may also give researchers in the field some insight into how to further understand complicated AI models. Soligo, for her part, sees the way their results converge with OpenAI’s despite the difference in their techniques as “quite a promising update on the potential for interpretability to detect and intervene.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/18/1119042/openai-can-rehabilitate-ai-models-that-develop-a-bad-boy-persona/</guid><pubDate>Wed, 18 Jun 2025 18:19:15 +0000</pubDate></item><item><title>[NEW] xAI faces legal threat over alleged Colossus data center pollution in Memphis (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/06/xai-faces-legal-threat-over-alleged-colossus-data-center-pollution-in-memphis/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        NAACP demands a meeting to discuss xAI's alleged pollution in Memphis.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/xAI-Thermal-Image-640x440.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/xAI-Thermal-Image-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Thermal imaging of xAI's Memphis facility prompted allegations that more than 30 of xAI’s methane gas turbines are operating without environmental permitting.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          ©Steve Jones, Flight by Southwings for SELC

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After thermal imaging appeared to show that xAI lied about suspected pollution at its Colossus supercomputer data center located near predominantly Black communities in Memphis, Tennessee, the NAACP has threatened a lawsuit accusing xAI of violating the Clean Air Act.&lt;/p&gt;
&lt;p&gt;In a letter sent to xAI on Tuesday, lawyers from the Southern Environmental Law Center (SELC) notified xAI of the NAACP's intent to sue in 60 days if xAI refuses to meet to discuss the groups' concerns that xAI is not using the requisite best available pollution controls. To ensure there's time for what the NAACP considers urgently needed negotiations ahead of filing the lawsuit, lawyers asked xAI to come to the table within the next 20 days.&lt;/p&gt;
&lt;p&gt;xAI did not respond to Ars' request to comment on the legal threat or accusations that it has become a major source of pollutants in Memphis.&lt;/p&gt;
&lt;h2&gt;xAI accused of ignoring Black communities’ concerns&lt;/h2&gt;
&lt;p&gt;According to the NAACP's letter, xAI's ambitions to build the world's largest AI data center in Memphis has potentially introduced the largest source of nitrogen oxides (NOx), reducing air quality in a city already grappling with high rates of emergency room visits and deaths from asthma. In Boxtown, a neighborhood closest to the data center, residents face "cancer risk four times the national average," due to "industrial pollution from dozens of industrial facilities, including an oil refinery, a steel mill, and a TVA gas plant." The letter stressed that all estimates of xAI's suspected pollution levels were "based on the most conservative emission factors," emphasizing that the situation may be even worse than the NAACP suggests.&lt;/p&gt;
&lt;p&gt;Because of Memphis' history of exceptionally poor air quality, any new source of pollutants requires permitting and emissions testing. The NAACP and SELC allege that, in its rush to power its supercomputer, xAI did not seek or conduct either of those prior to running methane gas turbines without proper controls.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"xAI’s decision to install and operate dozens of polluting gas turbines without any permits or public oversight is a clear violation of the Clean Air Act," SELC Senior Attorney Patrick Anderson said in a press release. "Over the last year, these turbines have pumped out pollution that threatens the health of Memphis families. This notice paves the way for a lawsuit that can hold xAI accountable for its unlawful refusal to get permits for its gas turbines."&lt;/p&gt;
&lt;p&gt;The SELC has been monitoring xAI's facility since last summer when xAI began its operations in Memphis. They alleged that very little was known about xAI's turbines until aerial imaging revealed 35 turbines at the site in March. Wondering if those turbines were possibly operational despite xAI claims they were not, the group conducted thermal imaging in April that SELC alleged "showed that nearly all of the turbines were emitting significant amounts of heat, indicating they were running."&lt;/p&gt;
&lt;p&gt;Follow-up thermal imaging in June showed that xAI removed "some smaller-sized turbines" from the site but replaced them with three larger turbines. As of June 15, the most recent "satellite images show at least 26 turbines are still present," the NAACP's letter said, all seemingly operating without the best available pollution controls.&lt;/p&gt;
&lt;h2&gt;xAI knows it can reduce pollution, groups say&lt;/h2&gt;
&lt;p&gt;For some Memphis residents wondering how xAI's facility might impact their quality of life, xAI appeared to be secretive about the turbines, claiming they were temporarily exempt from permits but providing little detail about the exemption.&lt;/p&gt;
&lt;p&gt;Nobody even knew "the makes and models of all turbines at xAI" until the March imaging, making it hard to calculate pollution risks. Once the makes and models were known, the NAACP noted that xAI's consultant confirmed that xAI had not yet installed add-on air pollution control technology to 15 turbines that seemingly could be operated more safely. The NAACP alleged the add-on tech would make a big difference.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"For instance, if all the 35 turbines operated by xAI were using" add-on air pollution control technology "to achieve a NOx emission rate of 2 ppm"—as xAI's consultant agreed it would—"they would emit about 177 tons of NOx per year, as opposed to the 1,200 to 2,100 tons per year they currently emit," the letter said.&lt;/p&gt;
&lt;p&gt;Allegedly, all of xAI's active turbines "continue to operate without utilizing best available control technology" (BACT) and "there is no dispute" that since xAI has yet to obtain permitting, it's not meeting BACT requirements today, the letter said.&lt;/p&gt;
&lt;p&gt;"xAI’s failure to comply with the BACT requirement is not only a Clean Air Act violation on paper, but also a significant and ongoing violation that is resulting in substantial amounts of harmful excess emissions," the letter said.&lt;/p&gt;
&lt;p&gt;Additionally, xAI's turbines are considered a major source of a hazardous air pollutant, formaldehyde, the letter said, with "the potential to emit more than 16 tons" since xAI operations began. "xAI was required to conduct initial emissions testing for formaldehyde within 180 days of becoming a major source," the letter alleged, but it appears that a year after moving into Memphis, still "xAI has not conducted this testing."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Terms of xAI’s permitting exemption remain vague&lt;/h2&gt;
&lt;p&gt;The NAACP and SELC suggested that the exemption that xAI is seemingly operating under could be a "nonroad engine exemption." However, they alleged that xAI's turbines don't qualify for that yearlong exemption, and even if they did, any turbines still onsite after a year would surely not be covered and should have permitting by now.&lt;/p&gt;
&lt;p&gt;"While some local leaders, including the Memphis Mayor and Shelby County Health Department, have claimed there is a '364-exemption' for xAI’s gas turbines, they have never been able to point to a specific exemption that would apply to turbines as large as the ones at the xAI site," SELC's press release alleged.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In a statement, NAACP President Derrick Johnson accused xAI of ignoring serious health concerns of Black neighborhoods demanding assurances their air quality won't suffer from xAI's supercomputer. And their neighbors in another community near xAI's second planned data center share their concerns, since xAI allegedly "has not said how that facility would be powered" and residents fear that means xAI could be installing even "more polluting gas turbines in the Memphis area."&lt;/p&gt;
&lt;p&gt;If a lawsuit proceeds, the NAACP plans to hold xAI accountable for alleged past and ongoing violations of the Clean Air Act, as well as other laws intended to protect Memphis residents. And if xAI loses, it could face an injunction preventing it from operating its turbines and potentially slowing down its progress with Colossus. xAI also risks potentially extensive fines for each turbine in violation.&lt;/p&gt;
&lt;p&gt;Johnson suggested that the deadlines the NAACP set will be held fast to ensure Memphis residents get the answers they need to breathe easily as soon as possible.&lt;/p&gt;
&lt;p&gt;"All too often, big corporations like xAI treat our communities and families like obstacles to be pushed aside," Johnson said. "We cannot afford to normalize this kind of environmental injustice—where billion-dollar companies set up polluting operations in Black neighborhoods without any permits and think they’ll get away with it because the people don’t have the power to fight back. We will not allow xAI to get away with this."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        NAACP demands a meeting to discuss xAI's alleged pollution in Memphis.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/xAI-Thermal-Image-640x440.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/xAI-Thermal-Image-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Thermal imaging of xAI's Memphis facility prompted allegations that more than 30 of xAI’s methane gas turbines are operating without environmental permitting.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          ©Steve Jones, Flight by Southwings for SELC

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After thermal imaging appeared to show that xAI lied about suspected pollution at its Colossus supercomputer data center located near predominantly Black communities in Memphis, Tennessee, the NAACP has threatened a lawsuit accusing xAI of violating the Clean Air Act.&lt;/p&gt;
&lt;p&gt;In a letter sent to xAI on Tuesday, lawyers from the Southern Environmental Law Center (SELC) notified xAI of the NAACP's intent to sue in 60 days if xAI refuses to meet to discuss the groups' concerns that xAI is not using the requisite best available pollution controls. To ensure there's time for what the NAACP considers urgently needed negotiations ahead of filing the lawsuit, lawyers asked xAI to come to the table within the next 20 days.&lt;/p&gt;
&lt;p&gt;xAI did not respond to Ars' request to comment on the legal threat or accusations that it has become a major source of pollutants in Memphis.&lt;/p&gt;
&lt;h2&gt;xAI accused of ignoring Black communities’ concerns&lt;/h2&gt;
&lt;p&gt;According to the NAACP's letter, xAI's ambitions to build the world's largest AI data center in Memphis has potentially introduced the largest source of nitrogen oxides (NOx), reducing air quality in a city already grappling with high rates of emergency room visits and deaths from asthma. In Boxtown, a neighborhood closest to the data center, residents face "cancer risk four times the national average," due to "industrial pollution from dozens of industrial facilities, including an oil refinery, a steel mill, and a TVA gas plant." The letter stressed that all estimates of xAI's suspected pollution levels were "based on the most conservative emission factors," emphasizing that the situation may be even worse than the NAACP suggests.&lt;/p&gt;
&lt;p&gt;Because of Memphis' history of exceptionally poor air quality, any new source of pollutants requires permitting and emissions testing. The NAACP and SELC allege that, in its rush to power its supercomputer, xAI did not seek or conduct either of those prior to running methane gas turbines without proper controls.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"xAI’s decision to install and operate dozens of polluting gas turbines without any permits or public oversight is a clear violation of the Clean Air Act," SELC Senior Attorney Patrick Anderson said in a press release. "Over the last year, these turbines have pumped out pollution that threatens the health of Memphis families. This notice paves the way for a lawsuit that can hold xAI accountable for its unlawful refusal to get permits for its gas turbines."&lt;/p&gt;
&lt;p&gt;The SELC has been monitoring xAI's facility since last summer when xAI began its operations in Memphis. They alleged that very little was known about xAI's turbines until aerial imaging revealed 35 turbines at the site in March. Wondering if those turbines were possibly operational despite xAI claims they were not, the group conducted thermal imaging in April that SELC alleged "showed that nearly all of the turbines were emitting significant amounts of heat, indicating they were running."&lt;/p&gt;
&lt;p&gt;Follow-up thermal imaging in June showed that xAI removed "some smaller-sized turbines" from the site but replaced them with three larger turbines. As of June 15, the most recent "satellite images show at least 26 turbines are still present," the NAACP's letter said, all seemingly operating without the best available pollution controls.&lt;/p&gt;
&lt;h2&gt;xAI knows it can reduce pollution, groups say&lt;/h2&gt;
&lt;p&gt;For some Memphis residents wondering how xAI's facility might impact their quality of life, xAI appeared to be secretive about the turbines, claiming they were temporarily exempt from permits but providing little detail about the exemption.&lt;/p&gt;
&lt;p&gt;Nobody even knew "the makes and models of all turbines at xAI" until the March imaging, making it hard to calculate pollution risks. Once the makes and models were known, the NAACP noted that xAI's consultant confirmed that xAI had not yet installed add-on air pollution control technology to 15 turbines that seemingly could be operated more safely. The NAACP alleged the add-on tech would make a big difference.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"For instance, if all the 35 turbines operated by xAI were using" add-on air pollution control technology "to achieve a NOx emission rate of 2 ppm"—as xAI's consultant agreed it would—"they would emit about 177 tons of NOx per year, as opposed to the 1,200 to 2,100 tons per year they currently emit," the letter said.&lt;/p&gt;
&lt;p&gt;Allegedly, all of xAI's active turbines "continue to operate without utilizing best available control technology" (BACT) and "there is no dispute" that since xAI has yet to obtain permitting, it's not meeting BACT requirements today, the letter said.&lt;/p&gt;
&lt;p&gt;"xAI’s failure to comply with the BACT requirement is not only a Clean Air Act violation on paper, but also a significant and ongoing violation that is resulting in substantial amounts of harmful excess emissions," the letter said.&lt;/p&gt;
&lt;p&gt;Additionally, xAI's turbines are considered a major source of a hazardous air pollutant, formaldehyde, the letter said, with "the potential to emit more than 16 tons" since xAI operations began. "xAI was required to conduct initial emissions testing for formaldehyde within 180 days of becoming a major source," the letter alleged, but it appears that a year after moving into Memphis, still "xAI has not conducted this testing."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Terms of xAI’s permitting exemption remain vague&lt;/h2&gt;
&lt;p&gt;The NAACP and SELC suggested that the exemption that xAI is seemingly operating under could be a "nonroad engine exemption." However, they alleged that xAI's turbines don't qualify for that yearlong exemption, and even if they did, any turbines still onsite after a year would surely not be covered and should have permitting by now.&lt;/p&gt;
&lt;p&gt;"While some local leaders, including the Memphis Mayor and Shelby County Health Department, have claimed there is a '364-exemption' for xAI’s gas turbines, they have never been able to point to a specific exemption that would apply to turbines as large as the ones at the xAI site," SELC's press release alleged.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In a statement, NAACP President Derrick Johnson accused xAI of ignoring serious health concerns of Black neighborhoods demanding assurances their air quality won't suffer from xAI's supercomputer. And their neighbors in another community near xAI's second planned data center share their concerns, since xAI allegedly "has not said how that facility would be powered" and residents fear that means xAI could be installing even "more polluting gas turbines in the Memphis area."&lt;/p&gt;
&lt;p&gt;If a lawsuit proceeds, the NAACP plans to hold xAI accountable for alleged past and ongoing violations of the Clean Air Act, as well as other laws intended to protect Memphis residents. And if xAI loses, it could face an injunction preventing it from operating its turbines and potentially slowing down its progress with Colossus. xAI also risks potentially extensive fines for each turbine in violation.&lt;/p&gt;
&lt;p&gt;Johnson suggested that the deadlines the NAACP set will be held fast to ensure Memphis residents get the answers they need to breathe easily as soon as possible.&lt;/p&gt;
&lt;p&gt;"All too often, big corporations like xAI treat our communities and families like obstacles to be pushed aside," Johnson said. "We cannot afford to normalize this kind of environmental injustice—where billion-dollar companies set up polluting operations in Black neighborhoods without any permits and think they’ll get away with it because the people don’t have the power to fight back. We will not allow xAI to get away with this."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/06/xai-faces-legal-threat-over-alleged-colossus-data-center-pollution-in-memphis/</guid><pubDate>Wed, 18 Jun 2025 18:40:14 +0000</pubDate></item><item><title>[NEW] From prompt chaos to clarity: How to build a robust AI orchestration layer (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/from-prompt-chaos-to-clarity-how-to-build-a-robust-ai-orchestration-layer/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Editor’s note: Emilia will lead an editorial roundtable on this topic at VB Transform next week.&amp;nbsp;Register today.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI agents seem like an inevitability these days. Most enterprises already use an AI application and may have deployed at least a single-agent system, with plans to pilot workflows with multiple agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Managing all that sprawl, especially when attempting to build interoperability in the long run, can become overwhelming. Reaching that agentic future means creating a workable orchestration framework that directs the different agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The demand for AI applications and orchestration has given rise to an emerging battleground, with companies focused on providing frameworks and tools gaining customers. Now, enterprises can choose between orchestration framework providers like LangChain, LlamaIndex, Crew AI, Microsoft’s AutoGen and OpenAI’s Swarm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enterprises also need to consider the type of orchestration framework they want to implement. They can choose between a prompt-based framework, agent-oriented workflow engines, retrieval and indexed frameworks, or even end-to-end orchestration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As many organizations are just beginning to experiment with multiple AI agent systems or want to build out a larger AI ecosystem, specific criteria are at the top of their minds when choosing the orchestration framework that best fits their needs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This larger pool of options in orchestration pushes the space even further, encouraging enterprises to explore all potential choices for orchestrating their AI systems instead of forcing them to fit into something else. While it can seem overwhelming, there’s a way for organizations to look at the best practices in choosing an orchestration framework and figure out what works well for them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Orchestration platform Orq noted in a blog post that AI management systems include four key components: prompt management for consistent model interaction, integration tools, state management and monitoring tools to track performance.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-best-practices-to-consider"&gt;Best practices to consider&lt;/h2&gt;



&lt;p&gt;For enterprises planning to embark on their orchestration journey or improve their current one, some experts from companies like Teneo and Orq note at least five best practices to start with.&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Define your business goals&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Choose tools and large language models (LLMs) that align with your goals&lt;/li&gt;



&lt;li&gt;Lay out what you need out of an orchestration layer and prioritize these, i.e., integration, workflow design, monitoring and observability, scalability, security and compliance&lt;/li&gt;



&lt;li&gt;Know your existing systems and how to integrate them into the new layer&lt;/li&gt;



&lt;li&gt;Understand your data pipeline&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;As with any AI project, organizations should take cues from their business needs. What do they need the AI application or agents to do, and how are these planned to support their work? Starting with this key step will help better inform their orchestration needs and the type of tools they require.&lt;/p&gt;



&lt;p&gt;Teneo said in a blog post that once that’s clear, teams must know what they need from their orchestration system and ensure these are the first features they look for. Some enterprises may want to focus more on monitoring and observability, rather than workflow design. Generally, most orchestration frameworks offer a range of features, and components such as integration, workflow, monitoring, scalability, and security are often the top priorities for businesses. Understanding what matters most to the organization will better guide how they want to build out their orchestration layer.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a blog post, LangChain stated that businesses should be aware of what information or work is passed to models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“When using a framework, you need to have full control over what gets passed into the LLM, and full control over what steps are run and in what order (in order to generate the context that gets passed into the LLM). We prioritize this with LangGraph, which is a low-level orchestration framework with no hidden prompts, no enforced “cognitive architectures”. This gives you full control to do the appropriate context engineering that you require,” the company said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Since most enterprises plan to add AI agents into existing workflows, it’s best practice to know which systems need to be part of the orchestration stack and find the platform that integrates best.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As always, enterprises need to know their data pipeline so they can compare the performance of the agents they are monitoring.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Editor’s note: Emilia will lead an editorial roundtable on this topic at VB Transform next week.&amp;nbsp;Register today.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;AI agents seem like an inevitability these days. Most enterprises already use an AI application and may have deployed at least a single-agent system, with plans to pilot workflows with multiple agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Managing all that sprawl, especially when attempting to build interoperability in the long run, can become overwhelming. Reaching that agentic future means creating a workable orchestration framework that directs the different agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The demand for AI applications and orchestration has given rise to an emerging battleground, with companies focused on providing frameworks and tools gaining customers. Now, enterprises can choose between orchestration framework providers like LangChain, LlamaIndex, Crew AI, Microsoft’s AutoGen and OpenAI’s Swarm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Enterprises also need to consider the type of orchestration framework they want to implement. They can choose between a prompt-based framework, agent-oriented workflow engines, retrieval and indexed frameworks, or even end-to-end orchestration.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As many organizations are just beginning to experiment with multiple AI agent systems or want to build out a larger AI ecosystem, specific criteria are at the top of their minds when choosing the orchestration framework that best fits their needs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This larger pool of options in orchestration pushes the space even further, encouraging enterprises to explore all potential choices for orchestrating their AI systems instead of forcing them to fit into something else. While it can seem overwhelming, there’s a way for organizations to look at the best practices in choosing an orchestration framework and figure out what works well for them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Orchestration platform Orq noted in a blog post that AI management systems include four key components: prompt management for consistent model interaction, integration tools, state management and monitoring tools to track performance.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-best-practices-to-consider"&gt;Best practices to consider&lt;/h2&gt;



&lt;p&gt;For enterprises planning to embark on their orchestration journey or improve their current one, some experts from companies like Teneo and Orq note at least five best practices to start with.&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Define your business goals&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Choose tools and large language models (LLMs) that align with your goals&lt;/li&gt;



&lt;li&gt;Lay out what you need out of an orchestration layer and prioritize these, i.e., integration, workflow design, monitoring and observability, scalability, security and compliance&lt;/li&gt;



&lt;li&gt;Know your existing systems and how to integrate them into the new layer&lt;/li&gt;



&lt;li&gt;Understand your data pipeline&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;As with any AI project, organizations should take cues from their business needs. What do they need the AI application or agents to do, and how are these planned to support their work? Starting with this key step will help better inform their orchestration needs and the type of tools they require.&lt;/p&gt;



&lt;p&gt;Teneo said in a blog post that once that’s clear, teams must know what they need from their orchestration system and ensure these are the first features they look for. Some enterprises may want to focus more on monitoring and observability, rather than workflow design. Generally, most orchestration frameworks offer a range of features, and components such as integration, workflow, monitoring, scalability, and security are often the top priorities for businesses. Understanding what matters most to the organization will better guide how they want to build out their orchestration layer.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a blog post, LangChain stated that businesses should be aware of what information or work is passed to models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“When using a framework, you need to have full control over what gets passed into the LLM, and full control over what steps are run and in what order (in order to generate the context that gets passed into the LLM). We prioritize this with LangGraph, which is a low-level orchestration framework with no hidden prompts, no enforced “cognitive architectures”. This gives you full control to do the appropriate context engineering that you require,” the company said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Since most enterprises plan to add AI agents into existing workflows, it’s best practice to know which systems need to be part of the orchestration stack and find the platform that integrates best.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As always, enterprises need to know their data pipeline so they can compare the performance of the agents they are monitoring.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/from-prompt-chaos-to-clarity-how-to-build-a-robust-ai-orchestration-layer/</guid><pubDate>Wed, 18 Jun 2025 19:11:10 +0000</pubDate></item><item><title>[NEW] Midjourney launches its first AI video generation model, V1 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/midjourney-launches-its-first-ai-video-generation-model-v1/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-11.56.51AM.png?w=1012" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Midjourney, one of the most popular AI image generation startups, announced on Wednesday the launch of its much-anticipated AI video generation model, V1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;V1 is an image-to-video model, in which users can upload an image — or take an image generated by one of Midjourney’s other models — and V1 will produce a set of four five-second videos based on it. Much like Midjourney’s image models, V1 is only available through Discord, and it’s only available on the web at launch.&lt;/p&gt;

&lt;figure class="wp-block-embed aligncenter is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Introducing our V1 Video Model. It's fun, easy, and beautiful. Available at 10$/month, it's the first video model for *everyone* and it's available now. pic.twitter.com/iBm0KAN8uy&lt;/p&gt;— Midjourney (@midjourney) June 18, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of V1 puts Midjourney in competition with AI video generation models from other companies, such as OpenAI’s Sora, Runway’s Gen 4, Adobe’s Firefly, and Google’s Veo 3. While many companies are focused on developing controllable AI video models for use in commercial settings, Midjourney has always stood out for its distinctive AI image models that cater to creative types. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says it has larger goals for its AI video models than generating B-roll for Hollywood films or commercials for the ad industry. In a blog post, Midjourney CEO David Holz says its AI video model is the company’s next step toward its ultimate destination, creating AI models “capable of real-time open-world simulations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After AI video models, Midjourney says it plans to develop AI models for producing 3D renderings, as well as real-time AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of Midjourney’s V1 model comes just a week after the startup was sued by two of Hollywood’s most notorious film studios: Disney and Universal. The suit alleges that images created by Midjourney’s AI image models depict the studio’s copyrighted characters, like Homer Simpson and Darth Vader.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hollywood studios have struggled to confront the rising popularity of AI image and video-generating models, such as the ones Midjourney develops. There’s a growing fear that these AI tools could replace or devalue the work of creatives in their respective fields, and several media companies have alleged that these products are trained on their copyrighted works.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;While Midjourney has tried to pitch itself as different from other AI image and video startups — more focused on creativity than immediate commercial applications — the startup cannot escape these accusations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To start, Midjourney says it will charge 8x more for a video generation than a typical image generation, meaning subscribers will run out of their monthly allotted generations significantly faster when creating videos than images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, the cheapest way to try out V1 is by subscribing to Midjourney’s $10-per-month Basic plan. Subscribers to Midjourney’s $60-a-month Pro plan and $120-a-month Mega plan will have unlimited video generations in the company’s slower, “Relax” mode. Over the next month, Midjourney says it will reassess its pricing for video models.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;V1 comes with a few custom settings that allow users to control the video model’s outputs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can select an automatic animation setting to make an image move randomly, or they can select a manual setting that allows users to describe, in text, a specific animation they want to add to their video. Users can also toggle the amount of camera and subject movement by selecting “low motion” or “high motion” in settings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the videos generated with V1 are only five seconds long, users can choose to extend them by four seconds up to four times, meaning that V1 videos could get as long as 21 seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much like Midjourney’s AI image models, early demos of V1’s videos look somewhat otherworldly, rather than hyperrealistic. The initial response to V1 has been positive, though it’s still unclear how well it matches up against other leading AI video models, which have been on the market for months or even years.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/Screenshot-2025-06-18-at-11.56.51AM.png?w=1012" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Midjourney, one of the most popular AI image generation startups, announced on Wednesday the launch of its much-anticipated AI video generation model, V1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;V1 is an image-to-video model, in which users can upload an image — or take an image generated by one of Midjourney’s other models — and V1 will produce a set of four five-second videos based on it. Much like Midjourney’s image models, V1 is only available through Discord, and it’s only available on the web at launch.&lt;/p&gt;

&lt;figure class="wp-block-embed aligncenter is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Introducing our V1 Video Model. It's fun, easy, and beautiful. Available at 10$/month, it's the first video model for *everyone* and it's available now. pic.twitter.com/iBm0KAN8uy&lt;/p&gt;— Midjourney (@midjourney) June 18, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of V1 puts Midjourney in competition with AI video generation models from other companies, such as OpenAI’s Sora, Runway’s Gen 4, Adobe’s Firefly, and Google’s Veo 3. While many companies are focused on developing controllable AI video models for use in commercial settings, Midjourney has always stood out for its distinctive AI image models that cater to creative types. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company says it has larger goals for its AI video models than generating B-roll for Hollywood films or commercials for the ad industry. In a blog post, Midjourney CEO David Holz says its AI video model is the company’s next step toward its ultimate destination, creating AI models “capable of real-time open-world simulations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After AI video models, Midjourney says it plans to develop AI models for producing 3D renderings, as well as real-time AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of Midjourney’s V1 model comes just a week after the startup was sued by two of Hollywood’s most notorious film studios: Disney and Universal. The suit alleges that images created by Midjourney’s AI image models depict the studio’s copyrighted characters, like Homer Simpson and Darth Vader.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hollywood studios have struggled to confront the rising popularity of AI image and video-generating models, such as the ones Midjourney develops. There’s a growing fear that these AI tools could replace or devalue the work of creatives in their respective fields, and several media companies have alleged that these products are trained on their copyrighted works.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;While Midjourney has tried to pitch itself as different from other AI image and video startups — more focused on creativity than immediate commercial applications — the startup cannot escape these accusations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To start, Midjourney says it will charge 8x more for a video generation than a typical image generation, meaning subscribers will run out of their monthly allotted generations significantly faster when creating videos than images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, the cheapest way to try out V1 is by subscribing to Midjourney’s $10-per-month Basic plan. Subscribers to Midjourney’s $60-a-month Pro plan and $120-a-month Mega plan will have unlimited video generations in the company’s slower, “Relax” mode. Over the next month, Midjourney says it will reassess its pricing for video models.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;V1 comes with a few custom settings that allow users to control the video model’s outputs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users can select an automatic animation setting to make an image move randomly, or they can select a manual setting that allows users to describe, in text, a specific animation they want to add to their video. Users can also toggle the amount of camera and subject movement by selecting “low motion” or “high motion” in settings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the videos generated with V1 are only five seconds long, users can choose to extend them by four seconds up to four times, meaning that V1 videos could get as long as 21 seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much like Midjourney’s AI image models, early demos of V1’s videos look somewhat otherworldly, rather than hyperrealistic. The initial response to V1 has been positive, though it’s still unclear how well it matches up against other leading AI video models, which have been on the market for months or even years.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/midjourney-launches-its-first-ai-video-generation-model-v1/</guid><pubDate>Wed, 18 Jun 2025 19:21:21 +0000</pubDate></item><item><title>[NEW] Multiplier, founded by ex-Stripe exec, nabs $27.5M to fuel AI-powered accounting roll-ups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/multiplier-founded-by-ex-stripe-exec-nabs-27-5m-to-fuel-ai-powered-accounting-roll-ups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/07/GlobalTax-e1658320448730.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In late 2022, Noah Pepper, a former Stripe business lead for the Asia Pacific region, founded Multiplier, a startup that aimed to sell software to tax accountants. But soon after ChatGPT was released, it occurred to him that AI can change how professional service firms use technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I realized I was barking up the wrong tree by trying to build a SaaS business, and instead I should figure out how to make these people more effective,” he told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup acquired Citrine International Tax, a boutique provider of cross-border tax accounting services, and enhanced the firm with AI capabilities built by Multiplier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It quickly became apparent that the strategy was working. By eliminating manual work, Multiplier’s AI tools helped Citrine more than double its profit margins. So, Pepper decided that instead of building software for accounting firms, Multiplier would acquire existing professional service businesses and outfit them with its AI solution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, Multiplier, which is now called Multiplier Holdings, is announcing that it raised a total of $27.5 million in seed and Series A financing. Lightspeed Venture Partners led the Series A funding round for the startup, following Multiplier’s seed round, which was led by Ribbit Capital with participation from SV Angel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiplier is part of a growing trend: startups acquiring existing service businesses and scaling them with AI. The PE-style roll-up strategy has recently gained popularity among VCs, with investors such as General Catalyst, Elad Gil, Thrive, and Khosla Ventures backing startups that develop AI solutions and integrate them into existing people-focused companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Until AI existed, none of this was possible,” Lightspeed partner Justin Overdorff said. In addition to Multiplier, Lightspeed has invested in three other yet-to-be-announced AI-powered roll-up companies.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Overdorff is convinced that this strategy is most effective when the startup buys small companies because they are more open to changing their existing processes. “If you go to an accounting firm that has 200 accountants, it’s unlikely to get adopted at a [high] rate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to being purchased by Multiplier, Citrine was a 12-person tax accounting entity. Multiplier not only helped increase its margins but also helped Citrine grow, Overdorff said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiplier’s&amp;nbsp;goal is to expand beyond offering personal tax compliance to create an AI-powered competitor to the Big Four accounting firms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Pepper said that Multiplier is looking to purchase high-recurring-revenue service firms helmed by people who are excited to integrate and help customize AI to take their businesses to the next level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a little bit like a venture-style business where you’re looking to make a bet on this leader who you think is just amazing in their category,” Pepper said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/07/GlobalTax-e1658320448730.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In late 2022, Noah Pepper, a former Stripe business lead for the Asia Pacific region, founded Multiplier, a startup that aimed to sell software to tax accountants. But soon after ChatGPT was released, it occurred to him that AI can change how professional service firms use technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I realized I was barking up the wrong tree by trying to build a SaaS business, and instead I should figure out how to make these people more effective,” he told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup acquired Citrine International Tax, a boutique provider of cross-border tax accounting services, and enhanced the firm with AI capabilities built by Multiplier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It quickly became apparent that the strategy was working. By eliminating manual work, Multiplier’s AI tools helped Citrine more than double its profit margins. So, Pepper decided that instead of building software for accounting firms, Multiplier would acquire existing professional service businesses and outfit them with its AI solution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, Multiplier, which is now called Multiplier Holdings, is announcing that it raised a total of $27.5 million in seed and Series A financing. Lightspeed Venture Partners led the Series A funding round for the startup, following Multiplier’s seed round, which was led by Ribbit Capital with participation from SV Angel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiplier is part of a growing trend: startups acquiring existing service businesses and scaling them with AI. The PE-style roll-up strategy has recently gained popularity among VCs, with investors such as General Catalyst, Elad Gil, Thrive, and Khosla Ventures backing startups that develop AI solutions and integrate them into existing people-focused companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Until AI existed, none of this was possible,” Lightspeed partner Justin Overdorff said. In addition to Multiplier, Lightspeed has invested in three other yet-to-be-announced AI-powered roll-up companies.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Overdorff is convinced that this strategy is most effective when the startup buys small companies because they are more open to changing their existing processes. “If you go to an accounting firm that has 200 accountants, it’s unlikely to get adopted at a [high] rate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prior to being purchased by Multiplier, Citrine was a 12-person tax accounting entity. Multiplier not only helped increase its margins but also helped Citrine grow, Overdorff said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Multiplier’s&amp;nbsp;goal is to expand beyond offering personal tax compliance to create an AI-powered competitor to the Big Four accounting firms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Pepper said that Multiplier is looking to purchase high-recurring-revenue service firms helmed by people who are excited to integrate and help customize AI to take their businesses to the next level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a little bit like a venture-style business where you’re looking to make a bet on this leader who you think is just amazing in their category,” Pepper said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/multiplier-founded-by-ex-stripe-exec-nabs-27-5m-to-fuel-ai-powered-accounting-roll-ups/</guid><pubDate>Wed, 18 Jun 2025 19:50:38 +0000</pubDate></item><item><title>[NEW] Six-month-old, solo-owned vibe coder Base44 sells to Wix for $80M cash (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1393787051-e1691109568882.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s a lot of talk in the startup world about how AI makes individuals so productive that it could give rise to a generation of “solo unicorns” — one-person companies worth over $1 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While an actual solo unicorn remains a mythical creature, Israeli developer Maor Shlomo provided compelling evidence Wednesday that the concept might not be impossible.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shlomo sold his 6-month-old, bootstrapped vibe-coding startup Base44 to Wix for $80 million, Wix announced Wednesday. And the deal was cash, Wix confirmed to TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Admittedly, this wasn’t a billion dollars or close to it. And Shlomo wasn’t truly solo — he had eight employees, Wix confirmed. They will collectively receive $25 million of the $80 million as a “retention” bonus. Wix declined to give details on that part of the deal, like how long they have to stay in their jobs to get full payouts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Base44’s rapid rise and impressive sale price have been the talk of the vibe-coding community.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its six months as a stand-alone company, Base44 reportedly grew to 250,000 users, hitting 10,000 users within its first three weeks. According to Shlomo’s posts on X and LinkedIn, the company was profitable, generating $189,000 in profit in May even after covering high LLM token costs, which he also documented publicly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Base44 spread mostly through word of mouth as Shlomo, a 31-year-old programmer, shared his building journey on LinkedIn and Twitter. The project began as a side venture, he told Israeli tech news site CTech.&amp;nbsp;&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“Base44 is a moonshot experiment — helping everyone, technical or not, build software without coding at all,” he explained on LinkedIn when he launched it to the public.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s one of the newer crop of vibe-coding products designed for non-programmers. Users enter text prompts, and the platform builds complete applications, with database, storage, authentication, analytics, and integration. It also supports email, texting, and maps, with a roadmap for more enterprise-grade security support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Base44 isn’t unique in this area. Other vibe coders like Adaptive Computer handle similar infrastructure work. But Base44’s fast rise was astounding all the same.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shlomo was already known in the Israeli startup community through his previous startup, the Insight Partners-backed data analytics company Explorium. His brother is also a co-founder of an AI security startup, Token Security, which just raised $20 million led by Notable Capital (formerly GGV Capital) and a bunch of Israeli tech angels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He quickly gained partnership agreements  for Base44 with big Israeli tech companies like eToro and Similarweb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After posting about his decision to use Anthropic’s Claude LLM through AWS instead of models by OpenAI — mostly for cost-per-performance reasons — Amazon invited Base44 to demo at a Tel Aviv AWS event last month, which Shlomo documented.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Crazy f***ing journey so far,” Shlomo posted on LinkedIn when announcing the news of the acquisition. Despite the growth and the profits — or really because of it — he sold his still-bootstrapped company because “the scale and volume we need is not something we can organically grow into&amp;nbsp;… If we were able to get so far organically, bootstrapped, I’m excited to see our new pace now that we have all the resources in place,” he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For its part, Wix picked up a proven, fast-growing, local vibe-coding platform for a relative song because of its youth. OpenAI paid $3 billion for Windsurf, which was founded in 2021.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wix, of course, offers no-code website building that look professionally designed. Adding a profitable LLM vibe-coding product to its offerings is a logical move.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shlomo could not be immediately reached for additional comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1393787051-e1691109568882.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;There’s a lot of talk in the startup world about how AI makes individuals so productive that it could give rise to a generation of “solo unicorns” — one-person companies worth over $1 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While an actual solo unicorn remains a mythical creature, Israeli developer Maor Shlomo provided compelling evidence Wednesday that the concept might not be impossible.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shlomo sold his 6-month-old, bootstrapped vibe-coding startup Base44 to Wix for $80 million, Wix announced Wednesday. And the deal was cash, Wix confirmed to TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Admittedly, this wasn’t a billion dollars or close to it. And Shlomo wasn’t truly solo — he had eight employees, Wix confirmed. They will collectively receive $25 million of the $80 million as a “retention” bonus. Wix declined to give details on that part of the deal, like how long they have to stay in their jobs to get full payouts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Base44’s rapid rise and impressive sale price have been the talk of the vibe-coding community.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its six months as a stand-alone company, Base44 reportedly grew to 250,000 users, hitting 10,000 users within its first three weeks. According to Shlomo’s posts on X and LinkedIn, the company was profitable, generating $189,000 in profit in May even after covering high LLM token costs, which he also documented publicly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Base44 spread mostly through word of mouth as Shlomo, a 31-year-old programmer, shared his building journey on LinkedIn and Twitter. The project began as a side venture, he told Israeli tech news site CTech.&amp;nbsp;&amp;nbsp;&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“Base44 is a moonshot experiment — helping everyone, technical or not, build software without coding at all,” he explained on LinkedIn when he launched it to the public.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s one of the newer crop of vibe-coding products designed for non-programmers. Users enter text prompts, and the platform builds complete applications, with database, storage, authentication, analytics, and integration. It also supports email, texting, and maps, with a roadmap for more enterprise-grade security support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Base44 isn’t unique in this area. Other vibe coders like Adaptive Computer handle similar infrastructure work. But Base44’s fast rise was astounding all the same.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Shlomo was already known in the Israeli startup community through his previous startup, the Insight Partners-backed data analytics company Explorium. His brother is also a co-founder of an AI security startup, Token Security, which just raised $20 million led by Notable Capital (formerly GGV Capital) and a bunch of Israeli tech angels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He quickly gained partnership agreements  for Base44 with big Israeli tech companies like eToro and Similarweb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After posting about his decision to use Anthropic’s Claude LLM through AWS instead of models by OpenAI — mostly for cost-per-performance reasons — Amazon invited Base44 to demo at a Tel Aviv AWS event last month, which Shlomo documented.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Crazy f***ing journey so far,” Shlomo posted on LinkedIn when announcing the news of the acquisition. Despite the growth and the profits — or really because of it — he sold his still-bootstrapped company because “the scale and volume we need is not something we can organically grow into&amp;nbsp;… If we were able to get so far organically, bootstrapped, I’m excited to see our new pace now that we have all the resources in place,” he wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For its part, Wix picked up a proven, fast-growing, local vibe-coding platform for a relative song because of its youth. OpenAI paid $3 billion for Windsurf, which was founded in 2021.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wix, of course, offers no-code website building that look professionally designed. Adding a profitable LLM vibe-coding product to its offerings is a logical move.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shlomo could not be immediately reached for additional comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/6-month-old-solo-owned-vibe-coder-base44-sells-to-wix-for-80m-cash/</guid><pubDate>Wed, 18 Jun 2025 20:25:21 +0000</pubDate></item><item><title>[NEW] ‘Kid-pilled’ Sam Altman ‘constantly’ asked ChatGPT questions about his newborn (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/kid-pilled-sam-altman-constantly-asked-chatgpt-questions-about-his-newborn/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Across hundreds of thousands of years of human existence, an impossible question has befuddled our species: Why is the baby crying?!&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, who is both the father of a 3-month-old and CEO of OpenAI, hopped on OpenAI’s new podcast today to talk about how his company is impacting his experience with fatherhood. Altman, who describes himself as “extremely kid-pilled,” said he was “constantly” using ChatGPT to ask questions about the behavior of babies during the first few weeks of his son’s life — now that he’s a bit more settled, he’s using ChatGPT to ask more general questions about children’s developmental stages.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I mean, clearly, people have been able to take care of babies without ChatGPT for a long time,” Altman said. “I don’t know how I would’ve done that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, obviously, isn’t fundamentally different from frantically Googling questions about babies, something that even the most well-prepared parents have been doing for decades. But, given who Altman is, his choice of internet tool to use is no surprise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, when hallucination remains a challenge for AI products, it may be concerning to imagine relying so heavily on a chat AI for baby-care answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But parents have been known to turn to many a questionable source for information in the middle of the night. My colleagues with children describe the “bottomless pit” of Google, and the minefield of parenting Facebook groups. Is ChatGPT really much different than taking the advice of someone online who’s insisting that you are a neglectful caretaker if you aren’t basing your baby’s bed time on the current phase of the moon?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps the idea of parents using AI in search for child-raising answers is less of a “primal alarm bell” than the idea of very young children using it, which Altman also discussed.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“There’s this video that always has stuck with me of a baby, or a little toddler, with one of those old glossy magazines [tapping] the [cover],” Altman said. The child thought that the magazine was an iPad. “Kids born now will just think that the world always had extremely smart AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Former OpenAI science communicator Andrew Mayne, who was interviewing Altman, recalled seeing a social media post from a parent who used the voice mode of ChatGPT to talk to his child about his obsessions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“He got tired of talking to his kid about Thomas the Tank Engine, so he put ChatGPT into voice mode… An hour later, the kid’s still talking about Thomas the train,” Mayne said gleefully.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Kids love voice mode,” Altman interjected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As today’s parents turn to ChatGPT for all sorts of similar uses, this will likely end up reflecting the same repetitive discourse around the “iPad kid” generation (yes, it’s probably bad to let your kid watch hours and hours of “Cocomelon”; no, it’s not fair to expect parents to occupy their kids’ time 24/7).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But existing children’s media is at least, for now, created by a team of humans, while ChatGPT’s own policies recommend it not be used by children under age 13. It does not have a vetted parental controls mode. Even Altman is aware of the risks, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s not all going to be good. There will be problems,” Altman said. “People will develop these somewhat problematic, or maybe very problematic parasocial relationships, and society will have to figure out new guardrails.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman is correct. We do not fully know the effect of letting kids talk to a large language model about Thomas the Tank Engine for an hour. But at the end of the day, Altman is the head of a massive company spending billions and billions of dollars with the hope of building AI that is smarter than humans, and he never forgets that in his messaging.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The upsides will be tremendous!” Altman said. “Society in general is good at figuring how to mitigate the downsides.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Across hundreds of thousands of years of human existence, an impossible question has befuddled our species: Why is the baby crying?!&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, who is both the father of a 3-month-old and CEO of OpenAI, hopped on OpenAI’s new podcast today to talk about how his company is impacting his experience with fatherhood. Altman, who describes himself as “extremely kid-pilled,” said he was “constantly” using ChatGPT to ask questions about the behavior of babies during the first few weeks of his son’s life — now that he’s a bit more settled, he’s using ChatGPT to ask more general questions about children’s developmental stages.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I mean, clearly, people have been able to take care of babies without ChatGPT for a long time,” Altman said. “I don’t know how I would’ve done that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This, obviously, isn’t fundamentally different from frantically Googling questions about babies, something that even the most well-prepared parents have been doing for decades. But, given who Altman is, his choice of internet tool to use is no surprise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, when hallucination remains a challenge for AI products, it may be concerning to imagine relying so heavily on a chat AI for baby-care answers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But parents have been known to turn to many a questionable source for information in the middle of the night. My colleagues with children describe the “bottomless pit” of Google, and the minefield of parenting Facebook groups. Is ChatGPT really much different than taking the advice of someone online who’s insisting that you are a neglectful caretaker if you aren’t basing your baby’s bed time on the current phase of the moon?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps the idea of parents using AI in search for child-raising answers is less of a “primal alarm bell” than the idea of very young children using it, which Altman also discussed.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“There’s this video that always has stuck with me of a baby, or a little toddler, with one of those old glossy magazines [tapping] the [cover],” Altman said. The child thought that the magazine was an iPad. “Kids born now will just think that the world always had extremely smart AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Former OpenAI science communicator Andrew Mayne, who was interviewing Altman, recalled seeing a social media post from a parent who used the voice mode of ChatGPT to talk to his child about his obsessions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“He got tired of talking to his kid about Thomas the Tank Engine, so he put ChatGPT into voice mode… An hour later, the kid’s still talking about Thomas the train,” Mayne said gleefully.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Kids love voice mode,” Altman interjected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As today’s parents turn to ChatGPT for all sorts of similar uses, this will likely end up reflecting the same repetitive discourse around the “iPad kid” generation (yes, it’s probably bad to let your kid watch hours and hours of “Cocomelon”; no, it’s not fair to expect parents to occupy their kids’ time 24/7).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But existing children’s media is at least, for now, created by a team of humans, while ChatGPT’s own policies recommend it not be used by children under age 13. It does not have a vetted parental controls mode. Even Altman is aware of the risks, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s not all going to be good. There will be problems,” Altman said. “People will develop these somewhat problematic, or maybe very problematic parasocial relationships, and society will have to figure out new guardrails.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman is correct. We do not fully know the effect of letting kids talk to a large language model about Thomas the Tank Engine for an hour. But at the end of the day, Altman is the head of a massive company spending billions and billions of dollars with the hope of building AI that is smarter than humans, and he never forgets that in his messaging.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The upsides will be tremendous!” Altman said. “Society in general is good at figuring how to mitigate the downsides.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/kid-pilled-sam-altman-constantly-asked-chatgpt-questions-about-his-newborn/</guid><pubDate>Wed, 18 Jun 2025 20:59:53 +0000</pubDate></item><item><title>[NEW] Here are the 24 US AI startups that have raised $100M or more in 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/18/here-are-the-24-us-ai-startups-that-have-raised-100m-or-more-in-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1485726179-1.jpg?resize=1200,720" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Last year was monumental for the AI industry in the U.S. and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There were 49 startups that raised funding rounds worth $100 million or more in 2024, per our count at TechCrunch; three companies raised more than one “mega-round,” and seven companies raised rounds that were $1 billion in size or larger.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;How will 2025 compare? It’s still the first half of the year, but so far it looks like 2024’s momentum will continue this year. There have already been multiple billion-dollar rounds this year, and more AI mega-rounds closed in the U.S. in Q1 2025 compared to Q1 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here are all the U.S. AI companies that have raised $100 million this year:&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;June&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Enterprise search startup &lt;strong&gt;Glean &lt;/strong&gt;continues to rake in cash. The company announced a $150 million Series F round on June 10, led by Wellington Management with participation from Sequoia, Lightspeed Venture Partners, and Kleiner Perkins, among others. Glean is now valued at $7.25 billion.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Anysphere&lt;/strong&gt;, the AI research lab behind AI coding tool Cursor, raised a sizable $900 million Series C round that values the company at nearly $10 billion. The round was led by Thrive Capital with participation from Andreessen Horowitz, Accel, and DST Global.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading"&gt;May&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI data labeling startup &lt;strong&gt;Snorkel AI&lt;/strong&gt; announced a $100 million Series D round on May 29, valuing the company at $1.3 billion. The round was led by Addition with participation from Prosperity7 Ventures, Lightspeed Venture Partners, and Greylock.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;LMArena&lt;/strong&gt;, a popular, community-driven benchmarking tool for AI models, raised a $100 million seed round that valued the startup at $600 million. The round was announced on May 21 and was co-led by Andreessen Horowitz and UC Investments. Lightspeed Venture Partners, Kleiner Perkins, and Felicis also participated, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Las Vegas-based AI infrastructure company &lt;strong&gt;TensorWave &lt;/strong&gt;announced a $100 million Series A round on May 14. The round was co-led by Magnetar Capital and AMD Ventures with participation from Prosperity7 Ventures, Nexus Venture Partners, and Maverick Silicon.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading"&gt;April&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;SandboxAQ&lt;/strong&gt; closed a $450 million Series E round on April 4 that valued the AI model company at $5.7 billion. The round included Nvidia, Google, and Bridgewater Associates founder Ray Dalio among other investors.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Runway&lt;/strong&gt;, which creates AI models for media production, raised a $308 million Series D round that was announced on April 3, valuing the company at $3 billion. It was led by General Atlantic. SoftBank, Nvidia, and Fidelity also participated.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading"&gt;March&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI behemoth &lt;strong&gt;OpenAI&lt;/strong&gt; raised a record-breaking $40 billion funding round that valued the startup at $300 billion. This round, which closed on March 31, was led by SoftBank with participation from Thrive Capital, Microsoft, and Coatue, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;On March 25, &lt;strong&gt;Nexthop AI&lt;/strong&gt;, an AI infrastructure company, announced that it had raised a Series A round led by Lightspeed Venture Partners. The $110 million round also included Kleiner Perkins, Battery Ventures, and Emergent Ventures, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Cambridge Massachusetts-based &lt;strong&gt;Insilico Medicine&lt;/strong&gt; raised $110 million for its generative AI-powered drug discovery platform as announced on March 13. This Series E round valued the company at $1 billion and was co-led by Value Partners and Pudong Chuangtou.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI infrastructure company &lt;strong&gt;Celestial AI&lt;/strong&gt; raised a $250 million Series C round that valued the company at $2.5 billion. The March 11 round was led by Fidelity with participation from Tiger Global, BlackRock, and Intel CEO Lip-Bu Tan, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Lila Sciences&lt;/strong&gt; raised a $200 million seed round as it looks to create a science superintelligence platform. The round was led by Flagship Pioneering. The Cambridge, Massachusetts-based company also received funding from March Capital, General Catalyst, and ARK Venture Fund, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Brooklyn-based &lt;strong&gt;Reflection.Ai&lt;/strong&gt;, which looks to build superintelligent autonomous systems, raised a $130 million Series A round that values the 1-year-old company at $580 million. The round was led by Lightspeed Venture Partners and CRV.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI coding startup &lt;strong&gt;Turing&lt;/strong&gt; closed a Series E round on March 7 that valued the startup, which partners with LLM companies, at $2.2 billion. The $111 million round was led by Khazanah Nasional with participation from WestBridge Capital, Gaingels, and Sozo Ventures, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Shield AI&lt;/strong&gt;, an AI defense tech startup, raised $240 million in a Series F round that closed on March 6. This round was co-led by L3Harris Technologies and Hanwha Aerospace, with participation from Andreessen Horowitz and the US Innovative Technology Fund, among others. The round valued the company at $5.3 billion&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI research and large language model company &lt;strong&gt;Anthropic&lt;/strong&gt; raised $3.5 billion in a Series E round that valued the startup at $61.5 billion. The round was announced on March 3 and was led by Lightspeed with participation from Salesforce Ventures, Menlo Ventures, and General Catalyst, among others.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-february"&gt;February&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Together AI&lt;/strong&gt;, which creates open source generative AI and AI model development infrastructure, raised a $305 million Series B round that valued the company at $3.3 billion. The February 20 round was co-led by Prosperity7 and General Catalyst with participation from Salesforce Ventures, Nvidia, Lux Capital, and others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI infrastructure company &lt;strong&gt;Lambda&lt;/strong&gt; raised a $480 million Series D round that was announced on February 19. The round valued the startup at nearly $2.5 billion and was co-led by SGW and Andra Capital. Nvidia, G Squared, ARK Invest, and others also participated.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Abridge&lt;/strong&gt;, an AI platform that transcribes patient-clinician conversations, was valued at $2.75 billion in a Series D round that was announced on February 17. The $250 million round was co-led by IVP and Elad Gil. Lightspeed, Redpoint, and Spark Capital also participated, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Eudia&lt;/strong&gt;, an AI legal tech company, raised $105 million in a Series A round led by General Catalyst. Floodgate, Defy Ventures, and Everywhere Ventures also participated in the round in addition to other VC firms and numerous angel investors. The round closed on February 13.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI hardware startup &lt;strong&gt;EnCharge AI&lt;/strong&gt; raised a $100 million Series B round that also closed on February 13. The round was led by Tiger Global with participation from Scout Ventures, Samsung Ventures, and RTX Ventures, among others. The Santa Clara-based business was founded in 2022.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI legal tech company &lt;strong&gt;Harvey&lt;/strong&gt; raised a $300 million Series D round that valued the 3-year-old company at $3 billion. The round was led by Sequoia and announced on February 12. OpenAI Startup Fund, Kleiner Perkins, Elad Gil, and others also participated in the raise.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-january"&gt;January&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Synthetic voice startup &lt;strong&gt;ElevenLabs&lt;/strong&gt; raised a $180 million Series C round that valued the company at more than $3 billion. It was announced on January 30. The round was co-led by ICONIQ Growth and Andreessen Horowitz. Sequoia, NEA, Salesforce Ventures, and others also participated in the round.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Hippocratic AI&lt;/strong&gt;, which develops large language models for the healthcare industry, announced a $141 million Series B round on January 9. This round valued the company at more than $1.6 billion and was led by Kleiner Perkins. Andreessen Horowitz, Nvidia, and General Catalyst also participated, among others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece was updated on April 23  and June 18 to include more deals. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece has been updated to remove that Abridge is based in Pittsburgh; the company was founded there. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1485726179-1.jpg?resize=1200,720" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Last year was monumental for the AI industry in the U.S. and beyond.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There were 49 startups that raised funding rounds worth $100 million or more in 2024, per our count at TechCrunch; three companies raised more than one “mega-round,” and seven companies raised rounds that were $1 billion in size or larger.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;How will 2025 compare? It’s still the first half of the year, but so far it looks like 2024’s momentum will continue this year. There have already been multiple billion-dollar rounds this year, and more AI mega-rounds closed in the U.S. in Q1 2025 compared to Q1 2024.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Here are all the U.S. AI companies that have raised $100 million this year:&lt;/p&gt;

&lt;h2 class="wp-block-heading"&gt;June&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Enterprise search startup &lt;strong&gt;Glean &lt;/strong&gt;continues to rake in cash. The company announced a $150 million Series F round on June 10, led by Wellington Management with participation from Sequoia, Lightspeed Venture Partners, and Kleiner Perkins, among others. Glean is now valued at $7.25 billion.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Anysphere&lt;/strong&gt;, the AI research lab behind AI coding tool Cursor, raised a sizable $900 million Series C round that values the company at nearly $10 billion. The round was led by Thrive Capital with participation from Andreessen Horowitz, Accel, and DST Global.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading"&gt;May&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI data labeling startup &lt;strong&gt;Snorkel AI&lt;/strong&gt; announced a $100 million Series D round on May 29, valuing the company at $1.3 billion. The round was led by Addition with participation from Prosperity7 Ventures, Lightspeed Venture Partners, and Greylock.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;LMArena&lt;/strong&gt;, a popular, community-driven benchmarking tool for AI models, raised a $100 million seed round that valued the startup at $600 million. The round was announced on May 21 and was co-led by Andreessen Horowitz and UC Investments. Lightspeed Venture Partners, Kleiner Perkins, and Felicis also participated, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Las Vegas-based AI infrastructure company &lt;strong&gt;TensorWave &lt;/strong&gt;announced a $100 million Series A round on May 14. The round was co-led by Magnetar Capital and AMD Ventures with participation from Prosperity7 Ventures, Nexus Venture Partners, and Maverick Silicon.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading"&gt;April&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;SandboxAQ&lt;/strong&gt; closed a $450 million Series E round on April 4 that valued the AI model company at $5.7 billion. The round included Nvidia, Google, and Bridgewater Associates founder Ray Dalio among other investors.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Runway&lt;/strong&gt;, which creates AI models for media production, raised a $308 million Series D round that was announced on April 3, valuing the company at $3 billion. It was led by General Atlantic. SoftBank, Nvidia, and Fidelity also participated.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading"&gt;March&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI behemoth &lt;strong&gt;OpenAI&lt;/strong&gt; raised a record-breaking $40 billion funding round that valued the startup at $300 billion. This round, which closed on March 31, was led by SoftBank with participation from Thrive Capital, Microsoft, and Coatue, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;On March 25, &lt;strong&gt;Nexthop AI&lt;/strong&gt;, an AI infrastructure company, announced that it had raised a Series A round led by Lightspeed Venture Partners. The $110 million round also included Kleiner Perkins, Battery Ventures, and Emergent Ventures, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Cambridge Massachusetts-based &lt;strong&gt;Insilico Medicine&lt;/strong&gt; raised $110 million for its generative AI-powered drug discovery platform as announced on March 13. This Series E round valued the company at $1 billion and was co-led by Value Partners and Pudong Chuangtou.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI infrastructure company &lt;strong&gt;Celestial AI&lt;/strong&gt; raised a $250 million Series C round that valued the company at $2.5 billion. The March 11 round was led by Fidelity with participation from Tiger Global, BlackRock, and Intel CEO Lip-Bu Tan, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Lila Sciences&lt;/strong&gt; raised a $200 million seed round as it looks to create a science superintelligence platform. The round was led by Flagship Pioneering. The Cambridge, Massachusetts-based company also received funding from March Capital, General Catalyst, and ARK Venture Fund, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Brooklyn-based &lt;strong&gt;Reflection.Ai&lt;/strong&gt;, which looks to build superintelligent autonomous systems, raised a $130 million Series A round that values the 1-year-old company at $580 million. The round was led by Lightspeed Venture Partners and CRV.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI coding startup &lt;strong&gt;Turing&lt;/strong&gt; closed a Series E round on March 7 that valued the startup, which partners with LLM companies, at $2.2 billion. The $111 million round was led by Khazanah Nasional with participation from WestBridge Capital, Gaingels, and Sozo Ventures, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Shield AI&lt;/strong&gt;, an AI defense tech startup, raised $240 million in a Series F round that closed on March 6. This round was co-led by L3Harris Technologies and Hanwha Aerospace, with participation from Andreessen Horowitz and the US Innovative Technology Fund, among others. The round valued the company at $5.3 billion&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI research and large language model company &lt;strong&gt;Anthropic&lt;/strong&gt; raised $3.5 billion in a Series E round that valued the startup at $61.5 billion. The round was announced on March 3 and was led by Lightspeed with participation from Salesforce Ventures, Menlo Ventures, and General Catalyst, among others.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-february"&gt;February&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Together AI&lt;/strong&gt;, which creates open source generative AI and AI model development infrastructure, raised a $305 million Series B round that valued the company at $3.3 billion. The February 20 round was co-led by Prosperity7 and General Catalyst with participation from Salesforce Ventures, Nvidia, Lux Capital, and others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI infrastructure company &lt;strong&gt;Lambda&lt;/strong&gt; raised a $480 million Series D round that was announced on February 19. The round valued the startup at nearly $2.5 billion and was co-led by SGW and Andra Capital. Nvidia, G Squared, ARK Invest, and others also participated.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Abridge&lt;/strong&gt;, an AI platform that transcribes patient-clinician conversations, was valued at $2.75 billion in a Series D round that was announced on February 17. The $250 million round was co-led by IVP and Elad Gil. Lightspeed, Redpoint, and Spark Capital also participated, among others.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Eudia&lt;/strong&gt;, an AI legal tech company, raised $105 million in a Series A round led by General Catalyst. Floodgate, Defy Ventures, and Everywhere Ventures also participated in the round in addition to other VC firms and numerous angel investors. The round closed on February 13.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI hardware startup &lt;strong&gt;EnCharge AI&lt;/strong&gt; raised a $100 million Series B round that also closed on February 13. The round was led by Tiger Global with participation from Scout Ventures, Samsung Ventures, and RTX Ventures, among others. The Santa Clara-based business was founded in 2022.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;AI legal tech company &lt;strong&gt;Harvey&lt;/strong&gt; raised a $300 million Series D round that valued the 3-year-old company at $3 billion. The round was led by Sequoia and announced on February 12. OpenAI Startup Fund, Kleiner Perkins, Elad Gil, and others also participated in the raise.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-january"&gt;January&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Synthetic voice startup &lt;strong&gt;ElevenLabs&lt;/strong&gt; raised a $180 million Series C round that valued the company at more than $3 billion. It was announced on January 30. The round was co-led by ICONIQ Growth and Andreessen Horowitz. Sequoia, NEA, Salesforce Ventures, and others also participated in the round.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Hippocratic AI&lt;/strong&gt;, which develops large language models for the healthcare industry, announced a $141 million Series B round on January 9. This round valued the company at more than $1.6 billion and was led by Kleiner Perkins. Andreessen Horowitz, Nvidia, and General Catalyst also participated, among others.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece was updated on April 23  and June 18 to include more deals. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This piece has been updated to remove that Abridge is based in Pittsburgh; the company was founded there. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/18/here-are-the-24-us-ai-startups-that-have-raised-100m-or-more-in-2025/</guid><pubDate>Wed, 18 Jun 2025 21:31:46 +0000</pubDate></item><item><title>[NEW] Announcing the 2025 finalists for VentureBeat Women in AI Awards (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/announcing-the-2024-nominees-for-venturebeat-women-in-ai-awards-2025/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;With VentureBeat’s flagship event, VB Transform, just around the corner, we are excited to announce the finalists for the 7th annual Women in AI Awards. The winners will be announced during a special program on the main stage of Transform on Wednesday, June 25 at 4 p.m. PT.&lt;/p&gt;



&lt;p&gt;VB Transform is a premier two-day event on June 24-25 at Fort Mason in San Francisco. Industry experts and peers will gather to provide comprehensive insights and best practices on what’s actually working in enterprise AI—from copilots to agents. Attendees will have numerous opportunities to forge meaningful connections and expand their networks.&lt;/p&gt;



&lt;p&gt;As part of this event, VentureBeat will honor women leaders and changemakers in AI during the in-person sessions. The award categories include Responsibility and Ethics of AI, AI Entrepreneurship, AI Research, AI Mentorship and Rising Star.&lt;/p&gt;



&lt;p&gt;The public submitted the nominees, and a VentureBeat committee will choose the winners. The selection criteria include the nominees’ commitment to the industry, efforts to increase inclusivity in the field and their positive influence on the community.&amp;nbsp;&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;Investing in women in AI will create more valuable AI that better suits audiences, and boosts ROI for companies. The impact has never been more clear, or more important, and we’re proud to recognize leaders in AI who are making an impact.&lt;/p&gt;
&lt;/blockquote&gt;







&lt;p&gt;This award will honor a woman who has started companies showing great promise in AI. Consideration will be given to things like business traction, the technology solution and impact in the AI space.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Elnaz Sarraf, CEO and founder at ROYBI &lt;/li&gt;



&lt;li&gt;Natalya Lopareva, CEO and founder at Algorized&lt;/li&gt;



&lt;li&gt;Ouafae Karim, engineer and funder at AFRICA-EO-SERVICES (AFEOS)&lt;/li&gt;



&lt;li&gt;Francessca Vasquez, vice president of professional services and generative AI innovation center at AWS&lt;/li&gt;



&lt;li&gt;Val Vacante SVP of solutions innovation at Dentsu&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;This award will honor a female leader who has helped mentor other women in the field of AI, providing guidance and support and/or encouraging more women to enter the field of AI.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Sandra Brown, deputy general counsel at SoftBank Robotics America, Inc.&lt;/li&gt;



&lt;li&gt;Suruchi Shah, engineering manager, model serving team at LinkedIn&lt;/li&gt;



&lt;li&gt;Parul Bhandari, global head telco, media and gaming partner strategy at Microsoft&lt;/li&gt;



&lt;li&gt;Reut Lazo, Founder at Women X AI&lt;/li&gt;



&lt;li&gt;Nicole Carignan, SVP of security and AI strategy, field CISO, at Darktrace&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;This award will honor a woman who has made a significant impact in an area of research in AI, helping accelerate progress either within her organization, as part of academic research or impacting AI.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Lindsay Richman, CEO at Innerverse AI&lt;/li&gt;



&lt;li&gt;Payel Das, principal research scientist and manager at IBM Research – T.J. Watson Research Center&lt;/li&gt;



&lt;li&gt;Suma Kumaraswamy, senior director, head of OMB Digital Products Innovation at First Tech Federal Credit Union &lt;/li&gt;



&lt;li&gt;Ann Irvine, Chief Data and Analytics Officer at Resilience&lt;/li&gt;



&lt;li&gt;Hannaneh Hajishirzi, senior director of NLP at AI2; Torode Family Associate Professor in the Allen School of Computer Science and Engineering at the University of Washington at Allen Institute for Artificial Intelligence (AI2); and University of Washington&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;This award will honor a woman who demonstrates exemplary leadership and progress in the growing hot topic of responsible AI.&lt;/p&gt;











&lt;p&gt;This award will honor a woman in the beginning stage of her AI career who has demonstrated exemplary leadership traits.&lt;/p&gt;







&lt;p&gt;We’d like to congratulate all of the women who were nominated to receive a Women in AI Award. Thanks to everyone for their nominations and for contributing to the growing awareness of women who are making a significant difference in AI. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;With VentureBeat’s flagship event, VB Transform, just around the corner, we are excited to announce the finalists for the 7th annual Women in AI Awards. The winners will be announced during a special program on the main stage of Transform on Wednesday, June 25 at 4 p.m. PT.&lt;/p&gt;



&lt;p&gt;VB Transform is a premier two-day event on June 24-25 at Fort Mason in San Francisco. Industry experts and peers will gather to provide comprehensive insights and best practices on what’s actually working in enterprise AI—from copilots to agents. Attendees will have numerous opportunities to forge meaningful connections and expand their networks.&lt;/p&gt;



&lt;p&gt;As part of this event, VentureBeat will honor women leaders and changemakers in AI during the in-person sessions. The award categories include Responsibility and Ethics of AI, AI Entrepreneurship, AI Research, AI Mentorship and Rising Star.&lt;/p&gt;



&lt;p&gt;The public submitted the nominees, and a VentureBeat committee will choose the winners. The selection criteria include the nominees’ commitment to the industry, efforts to increase inclusivity in the field and their positive influence on the community.&amp;nbsp;&lt;/p&gt;



&lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt;
&lt;p&gt;Investing in women in AI will create more valuable AI that better suits audiences, and boosts ROI for companies. The impact has never been more clear, or more important, and we’re proud to recognize leaders in AI who are making an impact.&lt;/p&gt;
&lt;/blockquote&gt;







&lt;p&gt;This award will honor a woman who has started companies showing great promise in AI. Consideration will be given to things like business traction, the technology solution and impact in the AI space.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Elnaz Sarraf, CEO and founder at ROYBI &lt;/li&gt;



&lt;li&gt;Natalya Lopareva, CEO and founder at Algorized&lt;/li&gt;



&lt;li&gt;Ouafae Karim, engineer and funder at AFRICA-EO-SERVICES (AFEOS)&lt;/li&gt;



&lt;li&gt;Francessca Vasquez, vice president of professional services and generative AI innovation center at AWS&lt;/li&gt;



&lt;li&gt;Val Vacante SVP of solutions innovation at Dentsu&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;This award will honor a female leader who has helped mentor other women in the field of AI, providing guidance and support and/or encouraging more women to enter the field of AI.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Sandra Brown, deputy general counsel at SoftBank Robotics America, Inc.&lt;/li&gt;



&lt;li&gt;Suruchi Shah, engineering manager, model serving team at LinkedIn&lt;/li&gt;



&lt;li&gt;Parul Bhandari, global head telco, media and gaming partner strategy at Microsoft&lt;/li&gt;



&lt;li&gt;Reut Lazo, Founder at Women X AI&lt;/li&gt;



&lt;li&gt;Nicole Carignan, SVP of security and AI strategy, field CISO, at Darktrace&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;This award will honor a woman who has made a significant impact in an area of research in AI, helping accelerate progress either within her organization, as part of academic research or impacting AI.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Lindsay Richman, CEO at Innerverse AI&lt;/li&gt;



&lt;li&gt;Payel Das, principal research scientist and manager at IBM Research – T.J. Watson Research Center&lt;/li&gt;



&lt;li&gt;Suma Kumaraswamy, senior director, head of OMB Digital Products Innovation at First Tech Federal Credit Union &lt;/li&gt;



&lt;li&gt;Ann Irvine, Chief Data and Analytics Officer at Resilience&lt;/li&gt;



&lt;li&gt;Hannaneh Hajishirzi, senior director of NLP at AI2; Torode Family Associate Professor in the Allen School of Computer Science and Engineering at the University of Washington at Allen Institute for Artificial Intelligence (AI2); and University of Washington&lt;/li&gt;
&lt;/ul&gt;







&lt;p&gt;This award will honor a woman who demonstrates exemplary leadership and progress in the growing hot topic of responsible AI.&lt;/p&gt;











&lt;p&gt;This award will honor a woman in the beginning stage of her AI career who has demonstrated exemplary leadership traits.&lt;/p&gt;







&lt;p&gt;We’d like to congratulate all of the women who were nominated to receive a Women in AI Award. Thanks to everyone for their nominations and for contributing to the growing awareness of women who are making a significant difference in AI. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/announcing-the-2024-nominees-for-venturebeat-women-in-ai-awards-2025/</guid><pubDate>Wed, 18 Jun 2025 22:06:48 +0000</pubDate></item><item><title>[NEW] OpenAI open sourced a new Customer Service Agent framework — learn more about its growing enterprise strategy (AI News | VentureBeat)</title><link>https://venturebeat.com/programming-development/openai-open-sourced-a-new-customer-service-agent-framework-learn-more-about-its-growing-enterprise-strategy/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Editor’s note: Carl will lead an editorial roundtable on this topic at VB Transform next week.&amp;nbsp;Register today.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;OpenAI has released a new open-source demo that gives developers a hands-on look at how to build intelligent, workflow-aware AI agents using the Agents SDK.&lt;/p&gt;



&lt;p&gt;As first noticed by AI influencer and engineer Tibor Blaho (of the third-party ChatGPT browser extension AIPRM), OpenAI’s new &lt;em&gt;Customer Service Agent&lt;/em&gt; was published earlier today on the AI code sharing community Hugging Face under a permissive MIT License, meaning any third-party developer or user can take the code, modify it, and deploy it for free for their own commercial or experimental purporses.&lt;/p&gt;



&lt;p&gt;This agent example demonstrates how to route airline-related requests between specialized agents — like Seat Booking, Flight Status, Cancellation, and FAQ — while enforcing safety and relevance guardrails. &lt;/p&gt;



&lt;p&gt;The release is designed to help teams go beyond theoretical use and start operationalizing agents with confidence.&lt;/p&gt;



&lt;p&gt;This practical demonstration arrives just ahead of OpenAI’s upcoming presentation at &lt;strong&gt;VentureBeat Transform 2025&lt;/strong&gt; next week in San Francisco, June 24-25, where OpenAI’s Head of Platform &lt;strong&gt;Olivier Godement&lt;/strong&gt; will go deeper into the enterprise-grade agent architecture powering use cases at companies like Stripe and Box.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Olivier Godement, OpenAI Head of Product, Platform" class="wp-image-3012647" height="400" src="https://venturebeat.com/wp-content/uploads/2025/06/1516544697843.jpg?w=400" width="400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Meet Olivier Godement, OpenAI Head of Product, Platform at VB Transform 2025&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-a-blueprint-for-routing-guardrails-and-specialized-agents"&gt;A blueprint for routing, guardrails, and specialized agents&lt;/h2&gt;



&lt;p&gt;Today’s release includes both a Python backend and a Next.js frontend. The backend leverages the OpenAI Agents SDK to orchestrate interactions between specialized agents, while the frontend visualizes these interactions in a chat interface, showing how decisions and handoffs unfold in real time.&lt;/p&gt;



&lt;p&gt;In one flow, a customer asks to change a seat. The Triage Agent determines the request and routes it to the Seat Booking Agent, which confirms the booking change interactively. In another scenario, a flight cancellation request is processed through the Cancellation Agent, which validates the customer’s confirmation number before completing the task.&lt;/p&gt;



&lt;p&gt;Importantly, the demo also shows how guardrails function in production: a &lt;strong&gt;Relevance Guardrail&lt;/strong&gt; blocks out-of-scope queries like asking for poetry, while a &lt;strong&gt;Jailbreak Guardrail&lt;/strong&gt; prevents prompt injection attempts, such as requests to expose system instructions.&lt;/p&gt;



&lt;p&gt;The architecture mirrors real-world airline support flows, showing how organizations can build domain-focused assistants that are responsive, compliant, and aligned with user expectations. OpenAI released the code under the MIT license and encouraged teams to customize and adapt it for their own needs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-open-source-to-real-world-enterprise-use-cases-read-openai-s-foundations-for-building-practical-ai-agents"&gt;From open source to real world enterprise use cases: read OpenAI’s foundations for building practical AI agents&lt;/h2&gt;



&lt;p&gt;This open-source release builds on OpenAI’s broader initiative to help teams design and deploy agent-based systems at scale. &lt;/p&gt;



&lt;p&gt;Earlier this year, the company published “&lt;em&gt;A Practical Guide to Building Agents&lt;/em&gt;,” a 32-page manual for product and engineering teams looking to implement intelligent automation.&lt;/p&gt;



&lt;p&gt;The guide lays out foundational components—LLM model, external tools, and behavioral instructions—and covers strategies for building both single-agent systems and complex multi-agent architectures. It offers design patterns for orchestration, guardrail implementation, and observability, drawing from OpenAI’s experience supporting large-scale deployments.&lt;/p&gt;



&lt;p&gt;Key takeaways from the guide include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;: Use top-tier models to establish performance baselines, then experiment with smaller models for cost-efficiency.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Tool Integration&lt;/strong&gt;: Equip agents with external APIs or functions to retrieve data or perform actions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Instruction Crafting&lt;/strong&gt;: Use clear, action-oriented prompts and conditionals to guide agent decisions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Guardrails&lt;/strong&gt;: Layer safety, relevance, and compliance constraints to ensure safe and predictable behavior.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Human Intervention&lt;/strong&gt;: Set up thresholds and escalation paths for cases that require human oversight.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The guide emphasizes starting small and evolving agent complexity over time—an approach echoed in the newly released demo, which shows how modular, tool-using sub-agents can be orchestrated cleanly.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-learn-more-from-openai-at-vb-transform-2025"&gt;Learn more from OpenAI at VB Transform 2025&lt;/h2&gt;



&lt;p&gt;Teams looking to move from prototype to production will get a deeper look at OpenAI’s enterprise-ready approach during &lt;strong&gt;Transform 2025&lt;/strong&gt;, hosted by VentureBeat. &lt;/p&gt;



&lt;p&gt;Presently scheduled for &lt;strong&gt;Wednesday, June 25th at 3:10 PM PT&lt;/strong&gt;, the session—titled &lt;em&gt;The Year of Agents: How OpenAI is Powering the Next Wave of Intelligent Automation&lt;/em&gt;—will feature &lt;strong&gt;Olivier Godement, Head of Product for OpenAI’s API platform&lt;/strong&gt;, in conversation with me, &lt;strong&gt;Carl Franzen&lt;/strong&gt;,&lt;strong&gt; Executive Editor at VentureBeat.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The 20-minute talk will cover:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Agent architecture patterns: when to use single loops, sub-agents, or orchestrated handoffs.&lt;/li&gt;



&lt;li&gt;Built-in guardrails for regulated environments, including policy refusals, SOC-2 logging, and data residency support.&lt;/li&gt;



&lt;li&gt;Cost/ROI levers and benchmarks from Stripe and Box, including 35% faster invoice resolution and zero-touch support triage.&lt;/li&gt;



&lt;li&gt;Roadmap insights: What’s coming next for multimodal actions, agent memory, and cross-cloud orchestration.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Whether you’re experimenting with open-source tools like the Customer Service Agent demo or scaling agents into critical workflows, this session promises a grounded look at what’s working, what to avoid, and what’s next.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-it-matters-for-enterprises-and-developers"&gt;Why it matters for enterprises and developers&lt;/h2&gt;



&lt;p&gt;Between the newly released demo and the principles outlined in &lt;em&gt;A Practical Guide to Building Agents&lt;/em&gt;, OpenAI is doubling down on its strategy: enabling developers to move past single-turn LLM applications and toward autonomous systems that can understand context, route tasks intelligently, and operate safely.&lt;/p&gt;



&lt;p&gt;By offering transparent tooling and clear implementation examples, OpenAI is pushing agentic systems out of the lab and into everyday use—whether in customer service, operations, or internal governance. For organizations exploring intelligent automation, these resources provide not just inspiration, but a working playbook.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;em&gt;Editor’s note: Carl will lead an editorial roundtable on this topic at VB Transform next week.&amp;nbsp;Register today.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;OpenAI has released a new open-source demo that gives developers a hands-on look at how to build intelligent, workflow-aware AI agents using the Agents SDK.&lt;/p&gt;



&lt;p&gt;As first noticed by AI influencer and engineer Tibor Blaho (of the third-party ChatGPT browser extension AIPRM), OpenAI’s new &lt;em&gt;Customer Service Agent&lt;/em&gt; was published earlier today on the AI code sharing community Hugging Face under a permissive MIT License, meaning any third-party developer or user can take the code, modify it, and deploy it for free for their own commercial or experimental purporses.&lt;/p&gt;



&lt;p&gt;This agent example demonstrates how to route airline-related requests between specialized agents — like Seat Booking, Flight Status, Cancellation, and FAQ — while enforcing safety and relevance guardrails. &lt;/p&gt;



&lt;p&gt;The release is designed to help teams go beyond theoretical use and start operationalizing agents with confidence.&lt;/p&gt;



&lt;p&gt;This practical demonstration arrives just ahead of OpenAI’s upcoming presentation at &lt;strong&gt;VentureBeat Transform 2025&lt;/strong&gt; next week in San Francisco, June 24-25, where OpenAI’s Head of Platform &lt;strong&gt;Olivier Godement&lt;/strong&gt; will go deeper into the enterprise-grade agent architecture powering use cases at companies like Stripe and Box.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Olivier Godement, OpenAI Head of Product, Platform" class="wp-image-3012647" height="400" src="https://venturebeat.com/wp-content/uploads/2025/06/1516544697843.jpg?w=400" width="400" /&gt;&lt;figcaption class="wp-element-caption"&gt;Meet Olivier Godement, OpenAI Head of Product, Platform at VB Transform 2025&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-a-blueprint-for-routing-guardrails-and-specialized-agents"&gt;A blueprint for routing, guardrails, and specialized agents&lt;/h2&gt;



&lt;p&gt;Today’s release includes both a Python backend and a Next.js frontend. The backend leverages the OpenAI Agents SDK to orchestrate interactions between specialized agents, while the frontend visualizes these interactions in a chat interface, showing how decisions and handoffs unfold in real time.&lt;/p&gt;



&lt;p&gt;In one flow, a customer asks to change a seat. The Triage Agent determines the request and routes it to the Seat Booking Agent, which confirms the booking change interactively. In another scenario, a flight cancellation request is processed through the Cancellation Agent, which validates the customer’s confirmation number before completing the task.&lt;/p&gt;



&lt;p&gt;Importantly, the demo also shows how guardrails function in production: a &lt;strong&gt;Relevance Guardrail&lt;/strong&gt; blocks out-of-scope queries like asking for poetry, while a &lt;strong&gt;Jailbreak Guardrail&lt;/strong&gt; prevents prompt injection attempts, such as requests to expose system instructions.&lt;/p&gt;



&lt;p&gt;The architecture mirrors real-world airline support flows, showing how organizations can build domain-focused assistants that are responsive, compliant, and aligned with user expectations. OpenAI released the code under the MIT license and encouraged teams to customize and adapt it for their own needs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-open-source-to-real-world-enterprise-use-cases-read-openai-s-foundations-for-building-practical-ai-agents"&gt;From open source to real world enterprise use cases: read OpenAI’s foundations for building practical AI agents&lt;/h2&gt;



&lt;p&gt;This open-source release builds on OpenAI’s broader initiative to help teams design and deploy agent-based systems at scale. &lt;/p&gt;



&lt;p&gt;Earlier this year, the company published “&lt;em&gt;A Practical Guide to Building Agents&lt;/em&gt;,” a 32-page manual for product and engineering teams looking to implement intelligent automation.&lt;/p&gt;



&lt;p&gt;The guide lays out foundational components—LLM model, external tools, and behavioral instructions—and covers strategies for building both single-agent systems and complex multi-agent architectures. It offers design patterns for orchestration, guardrail implementation, and observability, drawing from OpenAI’s experience supporting large-scale deployments.&lt;/p&gt;



&lt;p&gt;Key takeaways from the guide include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;: Use top-tier models to establish performance baselines, then experiment with smaller models for cost-efficiency.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Tool Integration&lt;/strong&gt;: Equip agents with external APIs or functions to retrieve data or perform actions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Instruction Crafting&lt;/strong&gt;: Use clear, action-oriented prompts and conditionals to guide agent decisions.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Guardrails&lt;/strong&gt;: Layer safety, relevance, and compliance constraints to ensure safe and predictable behavior.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Human Intervention&lt;/strong&gt;: Set up thresholds and escalation paths for cases that require human oversight.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The guide emphasizes starting small and evolving agent complexity over time—an approach echoed in the newly released demo, which shows how modular, tool-using sub-agents can be orchestrated cleanly.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-learn-more-from-openai-at-vb-transform-2025"&gt;Learn more from OpenAI at VB Transform 2025&lt;/h2&gt;



&lt;p&gt;Teams looking to move from prototype to production will get a deeper look at OpenAI’s enterprise-ready approach during &lt;strong&gt;Transform 2025&lt;/strong&gt;, hosted by VentureBeat. &lt;/p&gt;



&lt;p&gt;Presently scheduled for &lt;strong&gt;Wednesday, June 25th at 3:10 PM PT&lt;/strong&gt;, the session—titled &lt;em&gt;The Year of Agents: How OpenAI is Powering the Next Wave of Intelligent Automation&lt;/em&gt;—will feature &lt;strong&gt;Olivier Godement, Head of Product for OpenAI’s API platform&lt;/strong&gt;, in conversation with me, &lt;strong&gt;Carl Franzen&lt;/strong&gt;,&lt;strong&gt; Executive Editor at VentureBeat.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The 20-minute talk will cover:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Agent architecture patterns: when to use single loops, sub-agents, or orchestrated handoffs.&lt;/li&gt;



&lt;li&gt;Built-in guardrails for regulated environments, including policy refusals, SOC-2 logging, and data residency support.&lt;/li&gt;



&lt;li&gt;Cost/ROI levers and benchmarks from Stripe and Box, including 35% faster invoice resolution and zero-touch support triage.&lt;/li&gt;



&lt;li&gt;Roadmap insights: What’s coming next for multimodal actions, agent memory, and cross-cloud orchestration.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Whether you’re experimenting with open-source tools like the Customer Service Agent demo or scaling agents into critical workflows, this session promises a grounded look at what’s working, what to avoid, and what’s next.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-it-matters-for-enterprises-and-developers"&gt;Why it matters for enterprises and developers&lt;/h2&gt;



&lt;p&gt;Between the newly released demo and the principles outlined in &lt;em&gt;A Practical Guide to Building Agents&lt;/em&gt;, OpenAI is doubling down on its strategy: enabling developers to move past single-turn LLM applications and toward autonomous systems that can understand context, route tasks intelligently, and operate safely.&lt;/p&gt;



&lt;p&gt;By offering transparent tooling and clear implementation examples, OpenAI is pushing agentic systems out of the lab and into everyday use—whether in customer service, operations, or internal governance. For organizations exploring intelligent automation, these resources provide not just inspiration, but a working playbook.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/programming-development/openai-open-sourced-a-new-customer-service-agent-framework-learn-more-about-its-growing-enterprise-strategy/</guid><pubDate>Wed, 18 Jun 2025 22:30:02 +0000</pubDate></item></channel></rss>