<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 11 Jul 2025 01:54:38 +0000</lastBuildDate><item><title>LGND wants to make ChatGPT for the Earth (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/lgnd-wants-to-make-chatgpt-for-the-earth/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/nasa-yZygONrUBe8-unsplash.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Earth is awash in data about itself. Every day, satellites capture around 100 terabytes of imagery.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But making sense of it isn’t always easy. Seemingly simple questions can be fiendishly complex to answer. Take this question that is of vital economic importance to California: How many fire breaks does the state have that might stop a wildfire in its tracks, and how have they changed since the last fire season?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Originally, you’d have a person look at pictures. And that only scales so far,” Nathaniel Manning, co-founder and CEO of LGND, told TechCrunch. In recent years, neural networks have made it a bit easier, allowing machine learning experts and data scientists to train algorithms how to see fire breaks in satellite imagery.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You probably sink, you know, [a] couple hundred thousand dollars —&amp;nbsp;if not multiple hundred thousand dollars — to try to create that dataset, and it would only be able to do that one thing,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LGND wants to slash those figures by an order of magnitude or more.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are not looking to replace people doing these things,” said Bruno Sánchez-Andrade Nuño, LGND’s co-founder and chief scientist. “We’re looking to make them 10 times more efficient, 100 times more efficient.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LGND recently raised a $9 million seed round led by Javelin Venture Partners, the company exclusively told TechCrunch. AENU, Clocktower Ventures, Coalition Operators, MCJ, Overture, Ridgeline, and Space Capital participated. A number of angel investors also joined, including Keyhole founder John Hanke, Ramp co-founder Karim Atiyeh, and Salesforce executive Suzanne DiBianca.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s core product is vector embeddings of geographic data. Today, most geographic information exists in either pixels or traditional vectors (points, lines, areas). They’re flexible and easy to distribute and read, but interpreting that information requires either deep understanding of the space, some nontrivial amount of computing, or both.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Geographic embeddings summarize spatial data in a way that makes it easier to find relationships between different points on Earth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Embeddings get you 90% of all the undifferentiated compute up front,” Nuño said. “Embeddings are the universal, super-short summaries that embody 90% of the computation you have to do anyways.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Take the example of fire breaks. They might take the form of roads, rivers, or lakes. Each of them will appear differently on a map, but they all share certain characteristics. For one, pixels that make up an image of a fire break won’t have any vegetation. Also, a fire break will have to be a certain minimum width, which often depends on how tall the vegetation is around it. Embeddings make it much easier to find places on a map that match those descriptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LGND has built an enterprise app to help large companies answer questions involving spatial data, along with an API which users with more specific needs can hit directly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Manning sees LGND’s embeddings encouraging companies to query geospatial data in entirely new ways.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Imagine an AI travel agent, he said. Users might ask it to find a short-term rental with three rooms that’s close to good snorkeling. “But also, I want to be on a white sand beach. I want to know that there’s very little sea weed in February, when we’re going to go, and maybe most importantly, at this time of booking, there’s no construction happening within one kilometer of the house,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Building traditional geospatial models to answer those questions would be time-consuming for just one query, let alone all of them together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If LGND can succeed in delivering such a tool to the masses, or even just to people who use geospatial data for their jobs, it has the potential to take a bite out of a market valued near $400 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re trying to be the Standard Oil for this data,” Manning said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/nasa-yZygONrUBe8-unsplash.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Earth is awash in data about itself. Every day, satellites capture around 100 terabytes of imagery.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But making sense of it isn’t always easy. Seemingly simple questions can be fiendishly complex to answer. Take this question that is of vital economic importance to California: How many fire breaks does the state have that might stop a wildfire in its tracks, and how have they changed since the last fire season?&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Originally, you’d have a person look at pictures. And that only scales so far,” Nathaniel Manning, co-founder and CEO of LGND, told TechCrunch. In recent years, neural networks have made it a bit easier, allowing machine learning experts and data scientists to train algorithms how to see fire breaks in satellite imagery.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You probably sink, you know, [a] couple hundred thousand dollars —&amp;nbsp;if not multiple hundred thousand dollars — to try to create that dataset, and it would only be able to do that one thing,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LGND wants to slash those figures by an order of magnitude or more.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are not looking to replace people doing these things,” said Bruno Sánchez-Andrade Nuño, LGND’s co-founder and chief scientist. “We’re looking to make them 10 times more efficient, 100 times more efficient.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LGND recently raised a $9 million seed round led by Javelin Venture Partners, the company exclusively told TechCrunch. AENU, Clocktower Ventures, Coalition Operators, MCJ, Overture, Ridgeline, and Space Capital participated. A number of angel investors also joined, including Keyhole founder John Hanke, Ramp co-founder Karim Atiyeh, and Salesforce executive Suzanne DiBianca.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s core product is vector embeddings of geographic data. Today, most geographic information exists in either pixels or traditional vectors (points, lines, areas). They’re flexible and easy to distribute and read, but interpreting that information requires either deep understanding of the space, some nontrivial amount of computing, or both.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Geographic embeddings summarize spatial data in a way that makes it easier to find relationships between different points on Earth.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Embeddings get you 90% of all the undifferentiated compute up front,” Nuño said. “Embeddings are the universal, super-short summaries that embody 90% of the computation you have to do anyways.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Take the example of fire breaks. They might take the form of roads, rivers, or lakes. Each of them will appear differently on a map, but they all share certain characteristics. For one, pixels that make up an image of a fire break won’t have any vegetation. Also, a fire break will have to be a certain minimum width, which often depends on how tall the vegetation is around it. Embeddings make it much easier to find places on a map that match those descriptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LGND has built an enterprise app to help large companies answer questions involving spatial data, along with an API which users with more specific needs can hit directly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Manning sees LGND’s embeddings encouraging companies to query geospatial data in entirely new ways.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Imagine an AI travel agent, he said. Users might ask it to find a short-term rental with three rooms that’s close to good snorkeling. “But also, I want to be on a white sand beach. I want to know that there’s very little sea weed in February, when we’re going to go, and maybe most importantly, at this time of booking, there’s no construction happening within one kilometer of the house,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Building traditional geospatial models to answer those questions would be time-consuming for just one query, let alone all of them together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If LGND can succeed in delivering such a tool to the masses, or even just to people who use geospatial data for their jobs, it has the potential to take a bite out of a market valued near $400 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re trying to be the Standard Oil for this data,” Manning said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/lgnd-wants-to-make-chatgpt-for-the-earth/</guid><pubDate>Thu, 10 Jul 2025 13:58:45 +0000</pubDate></item><item><title>Grok is coming to Tesla vehicles ‘next week,’ says Elon Musk (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/grok-is-coming-to-tesla-vehicles-next-week-says-elon-musk/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk said in a post on X early Thursday morning that Grok, the chatbot from his AI company, xAI, will be coming to Tesla vehicles “very soon.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Next week at the latest,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The news that Grok would be coming to Tesla vehicles soon comes several hours after xAI debuted the latest flagship AI model, Grok 4. Fans had wondered loudly why Musk spent an hour late on Wednesday talking about Grok with no mention of a Tesla integration, which likely prompted the billionaire’s early morning announcement.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update also comes as adjustments to Grok have made the chatbot more prone to misbehavior — including making antisemitic comments, slating the Democrats, and even rape threats. X took down Grok temporarily on Wednesday to attempt to solve the problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is known for making Tesla-related announcements on X, the social media platform he owns, oftentimes before he even tells his own engineers. In this case, they might have seen it coming. Musk has teased that Grok would end up in Tesla vehicles as an AI assistant for months, saying that Tesla drivers would be able to chat conversationally with their cars and ask Grok to perform certain tasks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While poking around in Tesla’s firmware, a hacker who goes by the name “green” last week found that drivers can choose between certain Grok “personalities,” including ones that are NSFW (not safe for work). There seem to be a lot of personalities to choose from, including argumentative, conspiracy, kids story, sexy, therapist, unhinged, and more.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green’s findings also suggest that Grok will only be available on newer vehicles with Hardware 3. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok will also be the voice and brain for Tesla’s humanoid robot Optimus, Musk confirmed recently.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk said in a post on X early Thursday morning that Grok, the chatbot from his AI company, xAI, will be coming to Tesla vehicles “very soon.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Next week at the latest,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The news that Grok would be coming to Tesla vehicles soon comes several hours after xAI debuted the latest flagship AI model, Grok 4. Fans had wondered loudly why Musk spent an hour late on Wednesday talking about Grok with no mention of a Tesla integration, which likely prompted the billionaire’s early morning announcement.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update also comes as adjustments to Grok have made the chatbot more prone to misbehavior — including making antisemitic comments, slating the Democrats, and even rape threats. X took down Grok temporarily on Wednesday to attempt to solve the problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is known for making Tesla-related announcements on X, the social media platform he owns, oftentimes before he even tells his own engineers. In this case, they might have seen it coming. Musk has teased that Grok would end up in Tesla vehicles as an AI assistant for months, saying that Tesla drivers would be able to chat conversationally with their cars and ask Grok to perform certain tasks.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While poking around in Tesla’s firmware, a hacker who goes by the name “green” last week found that drivers can choose between certain Grok “personalities,” including ones that are NSFW (not safe for work). There seem to be a lot of personalities to choose from, including argumentative, conspiracy, kids story, sexy, therapist, unhinged, and more.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Green’s findings also suggest that Grok will only be available on newer vehicles with Hardware 3. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok will also be the voice and brain for Tesla’s humanoid robot Optimus, Musk confirmed recently.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/grok-is-coming-to-tesla-vehicles-next-week-says-elon-musk/</guid><pubDate>Thu, 10 Jul 2025 14:22:24 +0000</pubDate></item><item><title>Google adds image-to-video generation capability to Veo 3 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/google-adds-image-to-video-generation-capability-to-veo-3/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google said on Thursday it’s adding an image-to-video generation feature to its Veo 3 AI video generator through its Gemini app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company had already rolled out this feature in its AI-powered video tool called Flow, which was launched in May at Google’s I/O developer conference.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After launching Veo 3-powered video generation in May, Google made the feature available in over 150 countries as of last week. At the moment, only Google AI Ultra and Google AI Pro plan users can generate videos with a three-creations-per-day limit with no carry-over.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026471" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/Google-gemini.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;What image-to-video generation with Veo 3 looks like&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google said that users can generate a clip by selecting the “Videos” option from the tool menu in the prompt box and uploading a photo. You can also add sound by describing the audio in the prompt. Once the video is generated, you can download it or share it with others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that since its release seven weeks ago, users have created more than 40 million videos across the Gemini app and Flow tool. All videos generated using the Veo 3 model will have a visible watermark that says “Veo” along with an invisible SynthID digital watermark, which is adopted by Google’s AI tool to identify AI-powered digital artifacts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, the company also released a tool that helps you detect content containing SynthID.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google said on Thursday it’s adding an image-to-video generation feature to its Veo 3 AI video generator through its Gemini app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company had already rolled out this feature in its AI-powered video tool called Flow, which was launched in May at Google’s I/O developer conference.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After launching Veo 3-powered video generation in May, Google made the feature available in over 150 countries as of last week. At the moment, only Google AI Ultra and Google AI Pro plan users can generate videos with a three-creations-per-day limit with no carry-over.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026471" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/Google-gemini.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;What image-to-video generation with Veo 3 looks like&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google said that users can generate a clip by selecting the “Videos” option from the tool menu in the prompt box and uploading a photo. You can also add sound by describing the audio in the prompt. Once the video is generated, you can download it or share it with others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company noted that since its release seven weeks ago, users have created more than 40 million videos across the Gemini app and Flow tool. All videos generated using the Veo 3 model will have a visible watermark that says “Veo” along with an invisible SynthID digital watermark, which is adopted by Google’s AI tool to identify AI-powered digital artifacts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this year, the company also released a tool that helps you detect content containing SynthID.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/google-adds-image-to-video-generation-capability-to-veo-3/</guid><pubDate>Thu, 10 Jul 2025 15:00:00 +0000</pubDate></item><item><title>Gemini can now turn your photos into video with Veo 3 (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/google-adds-photo-to-video-generation-with-veo-3-to-the-gemini-app/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google is making it easier to create videos with Gemini, but you only get a few shots per day.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini icon macro" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini icon macro" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google's Veo 3 videos have propagated across the Internet since the model's debut in May, blurring the line between truth and fiction. Now, it's getting even easier to create these AI videos. The Gemini app is gaining photo-to-video generation, allowing you to upload a photo and turn it into a video. You don't have to pay anything extra for these Veo 3 videos, but the feature is only available to subscribers of Google's Pro and Ultra AI plans.&lt;/p&gt;
&lt;p&gt;When Veo 3 launched, it could conjure up a video based only on your description, complete with speech, music, and background audio. This has made Google's new AI videos staggeringly realistic—it's actually getting hard to identify AI videos at a glance. Using a reference photo makes it easier to get the look you want without tediously describing every aspect. This was an option in Google's Flow AI tool for filmmakers, but now it's in the Gemini app and web interface.&lt;/p&gt;
&lt;p&gt;To create a video from a photo, you have to select "Video" from the Gemini toolbar. Once this feature is available, you can then add your image and prompt, including audio and dialogue. Generating the video takes several minutes—this process takes a lot of computation, which is why video output is still quite limited.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Veo 3 videos are limited to 720p resolution and eight seconds in length, and there's no guarantee you'll like what Veo 3 spits out. That can be frustrating because you are extremely limited in how many videos you can create with Veo 3. Anyone subscribing to AI Pro ($20 per month) gets three video generations per day. Upgrade to the $250 AI Ultra plan and that goes up to just five videos per day.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105139 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Veo 3 video" class="fullwidth full" height="563" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/unnamed.gif" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google says photo-to-video generation is rolling out in Gemini today, so you won't have to wait long to give it a shot, assuming you have a paid AI subscription. Free Gemini users won't have access to this feature at all.&lt;/p&gt;
&lt;p&gt;As we've been recently reminded, people can use AI video generation for nefarious purposes. Veo 3 does seem quite compliant, producing almost whatever you want unless it's overtly in opposition to Google's rules. The company says it is committed to safety with "red teaming" to aggressively test its AI systems to ensure they do not create unsafe content. All the videos created by Gemini with Veo 3 will also have Google's SynthID digital watermark, which helps identify them as artificial.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google is making it easier to create videos with Gemini, but you only get a few shots per day.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Gemini icon macro" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Gemini icon macro" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/04/Gemini-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Ryan Whitwam

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google's Veo 3 videos have propagated across the Internet since the model's debut in May, blurring the line between truth and fiction. Now, it's getting even easier to create these AI videos. The Gemini app is gaining photo-to-video generation, allowing you to upload a photo and turn it into a video. You don't have to pay anything extra for these Veo 3 videos, but the feature is only available to subscribers of Google's Pro and Ultra AI plans.&lt;/p&gt;
&lt;p&gt;When Veo 3 launched, it could conjure up a video based only on your description, complete with speech, music, and background audio. This has made Google's new AI videos staggeringly realistic—it's actually getting hard to identify AI videos at a glance. Using a reference photo makes it easier to get the look you want without tediously describing every aspect. This was an option in Google's Flow AI tool for filmmakers, but now it's in the Gemini app and web interface.&lt;/p&gt;
&lt;p&gt;To create a video from a photo, you have to select "Video" from the Gemini toolbar. Once this feature is available, you can then add your image and prompt, including audio and dialogue. Generating the video takes several minutes—this process takes a lot of computation, which is why video output is still quite limited.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Veo 3 videos are limited to 720p resolution and eight seconds in length, and there's no guarantee you'll like what Veo 3 spits out. That can be frustrating because you are extremely limited in how many videos you can create with Veo 3. Anyone subscribing to AI Pro ($20 per month) gets three video generations per day. Upgrade to the $250 AI Ultra plan and that goes up to just five videos per day.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105139 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Veo 3 video" class="fullwidth full" height="563" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/unnamed.gif" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google says photo-to-video generation is rolling out in Gemini today, so you won't have to wait long to give it a shot, assuming you have a paid AI subscription. Free Gemini users won't have access to this feature at all.&lt;/p&gt;
&lt;p&gt;As we've been recently reminded, people can use AI video generation for nefarious purposes. Veo 3 does seem quite compliant, producing almost whatever you want unless it's overtly in opposition to Google's rules. The company says it is committed to safety with "red teaming" to aggressively test its AI systems to ensure they do not create unsafe content. All the videos created by Gemini with Veo 3 will also have Google's SynthID digital watermark, which helps identify them as artificial.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/google-adds-photo-to-video-generation-with-veo-3-to-the-gemini-app/</guid><pubDate>Thu, 10 Jul 2025 15:02:08 +0000</pubDate></item><item><title>Google’s open MedGemma AI models could transform healthcare (AI News)</title><link>https://www.artificialintelligence-news.com/news/google-open-medgemma-ai-models-healthcare/</link><description>&lt;p&gt;Instead of keeping their new MedGemma AI models locked behind expensive APIs, Google will hand these powerful tools to healthcare developers.&lt;/p&gt;&lt;p&gt;The new arrivals are called MedGemma 27B Multimodal and MedSigLIP and they’re part of Google’s growing collection of open-source healthcare AI models. What makes these special isn’t just their technical prowess, but the fact that hospitals, researchers, and developers can download them, modify them, and run them however they see fit.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-google-s-ai-meets-real-healthcare"&gt;Google’s AI meets real healthcare&lt;/h3&gt;&lt;p&gt;The flagship MedGemma 27B model doesn’t just read medical text like previous versions did; it can actually “look” at medical images and understand what it’s seeing. Whether it’s chest X-rays, pathology slides, or patient records potentially spanning months or years, it can process all of this information together, much like a doctor would.&lt;/p&gt;&lt;p&gt;The performance figures are quite impressive. When tested on MedQA, a standard medical knowledge benchmark, the 27B text model scored 87.7%. That puts it within spitting distance of much larger, more expensive models whilst costing about a tenth as much to run. For cash-strapped healthcare systems, that’s potentially transformative.&lt;/p&gt;&lt;p&gt;The smaller sibling, MedGemma 4B, might be more modest in size but it’s no slouch. Despite being tiny by modern AI standards, it scored 64.4% on the same tests, making it one of the best performers in its weight class. More importantly, when US board-certified radiologists reviewed chest X-ray reports it had written, they deemed 81% accurate enough to guide actual patient care.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-medsiglip-a-featherweight-powerhouse"&gt;MedSigLIP: A featherweight powerhouse&lt;/h3&gt;&lt;p&gt;Alongside these generative AI models, Google has released MedSigLIP. At just 400 million parameters, it’s practically featherweight compared to today’s AI giants, but it’s been specifically trained to understand medical images in ways that general-purpose models cannot.&lt;/p&gt;&lt;p&gt;This little powerhouse has been fed a diet of chest X-rays, tissue samples, skin condition photos, and eye scans. The result? It can spot patterns and features that matter in medical contexts whilst still handling everyday images perfectly well.&lt;/p&gt;&lt;p&gt;MedSigLIP creates a bridge between images and text. Show it a chest X-ray, and ask it to find similar cases in a database, and it’ll understand not just visual similarities but medical significance too.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-healthcare-professionals-are-putting-google-s-ai-models-to-work"&gt;Healthcare professionals are putting Google’s AI models to work&lt;/h3&gt;&lt;p&gt;The proof of any AI tool lies in whether real professionals actually want to use it. Early reports suggest doctors and healthcare companies are excited about what these models can do.&lt;/p&gt;&lt;p&gt;DeepHealth in Massachusetts has been testing MedSigLIP for chest X-ray analysis. They’re finding it helps spot potential problems that might otherwise be missed, acting as a safety net for overworked radiologists. Meanwhile, at Chang Gung Memorial Hospital in Taiwan, researchers have discovered that MedGemma works with traditional Chinese medical texts and answers staff questions with high accuracy.&lt;/p&gt;&lt;p&gt;Tap Health in India has highlighted something crucial about MedGemma’s reliability. Unlike general-purpose AI that might hallucinate medical facts, MedGemma seems to understand when clinical context matters. It’s the difference between a chatbot that sounds medical and one that actually thinks medically.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-open-sourcing-the-ai-models-is-critical-in-healthcare"&gt;Why open-sourcing the AI models is critical in healthcare&lt;/h3&gt;&lt;p&gt;Beyond generosity, Google’s decision to make these models is also strategic. Healthcare has unique requirements that standard AI services can’t always meet. Hospitals need to know their patient data isn’t leaving their premises. Research institutions need models that won’t suddenly change behaviour without warning. Developers need the freedom to fine-tune for very specific medical tasks.&lt;/p&gt;&lt;p&gt;By open-sourcing the AI models, Google has addressed these concerns with healthcare deployments. A hospital can run MedGemma on their own servers, modify it for their specific needs, and trust that it’ll behave consistently over time. For medical applications where reproducibility is crucial, this stability is invaluable.&lt;/p&gt;&lt;p&gt;However, Google has been careful to emphasise that these models aren’t ready to replace doctors. They’re tools that require human oversight, clinical correlation, and proper validation before any real-world deployment. The outputs need checking, the recommendations need verifying, and the decisions still rest with qualified medical professionals.&lt;/p&gt;&lt;p&gt;This cautious approach makes sense. Even with impressive benchmark scores, medical AI can still make mistakes, particularly when dealing with unusual cases or edge scenarios. The models excel at processing information and spotting patterns, but they can’t replace the judgment, experience, and ethical responsibility that human doctors bring.&lt;/p&gt;&lt;p&gt;What’s exciting about this release isn’t just the immediate capabilities, but what it enables. Smaller hospitals that couldn’t afford expensive AI services can now access cutting-edge technology. Researchers in developing countries can build specialised tools for local health challenges. Medical schools can teach students using AI that actually understands medicine.&lt;/p&gt;&lt;p&gt;The models are designed to run on single graphics cards, with the smaller versions even adaptable for mobile devices. This accessibility opens doors for point-of-care AI applications in places where high-end computing infrastructure simply doesn’t exist.&lt;/p&gt;&lt;p&gt;As healthcare continues grappling with staff shortages, increasing patient loads, and the need for more efficient workflows, AI tools like Google’s MedGemma could provide some much-needed relief. Not by replacing human expertise, but by amplifying it and making it more accessible where it’s needed most.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Owen Beard)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Tencent improves testing creative AI models with new benchmark&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Instead of keeping their new MedGemma AI models locked behind expensive APIs, Google will hand these powerful tools to healthcare developers.&lt;/p&gt;&lt;p&gt;The new arrivals are called MedGemma 27B Multimodal and MedSigLIP and they’re part of Google’s growing collection of open-source healthcare AI models. What makes these special isn’t just their technical prowess, but the fact that hospitals, researchers, and developers can download them, modify them, and run them however they see fit.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-google-s-ai-meets-real-healthcare"&gt;Google’s AI meets real healthcare&lt;/h3&gt;&lt;p&gt;The flagship MedGemma 27B model doesn’t just read medical text like previous versions did; it can actually “look” at medical images and understand what it’s seeing. Whether it’s chest X-rays, pathology slides, or patient records potentially spanning months or years, it can process all of this information together, much like a doctor would.&lt;/p&gt;&lt;p&gt;The performance figures are quite impressive. When tested on MedQA, a standard medical knowledge benchmark, the 27B text model scored 87.7%. That puts it within spitting distance of much larger, more expensive models whilst costing about a tenth as much to run. For cash-strapped healthcare systems, that’s potentially transformative.&lt;/p&gt;&lt;p&gt;The smaller sibling, MedGemma 4B, might be more modest in size but it’s no slouch. Despite being tiny by modern AI standards, it scored 64.4% on the same tests, making it one of the best performers in its weight class. More importantly, when US board-certified radiologists reviewed chest X-ray reports it had written, they deemed 81% accurate enough to guide actual patient care.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-medsiglip-a-featherweight-powerhouse"&gt;MedSigLIP: A featherweight powerhouse&lt;/h3&gt;&lt;p&gt;Alongside these generative AI models, Google has released MedSigLIP. At just 400 million parameters, it’s practically featherweight compared to today’s AI giants, but it’s been specifically trained to understand medical images in ways that general-purpose models cannot.&lt;/p&gt;&lt;p&gt;This little powerhouse has been fed a diet of chest X-rays, tissue samples, skin condition photos, and eye scans. The result? It can spot patterns and features that matter in medical contexts whilst still handling everyday images perfectly well.&lt;/p&gt;&lt;p&gt;MedSigLIP creates a bridge between images and text. Show it a chest X-ray, and ask it to find similar cases in a database, and it’ll understand not just visual similarities but medical significance too.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-healthcare-professionals-are-putting-google-s-ai-models-to-work"&gt;Healthcare professionals are putting Google’s AI models to work&lt;/h3&gt;&lt;p&gt;The proof of any AI tool lies in whether real professionals actually want to use it. Early reports suggest doctors and healthcare companies are excited about what these models can do.&lt;/p&gt;&lt;p&gt;DeepHealth in Massachusetts has been testing MedSigLIP for chest X-ray analysis. They’re finding it helps spot potential problems that might otherwise be missed, acting as a safety net for overworked radiologists. Meanwhile, at Chang Gung Memorial Hospital in Taiwan, researchers have discovered that MedGemma works with traditional Chinese medical texts and answers staff questions with high accuracy.&lt;/p&gt;&lt;p&gt;Tap Health in India has highlighted something crucial about MedGemma’s reliability. Unlike general-purpose AI that might hallucinate medical facts, MedGemma seems to understand when clinical context matters. It’s the difference between a chatbot that sounds medical and one that actually thinks medically.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-open-sourcing-the-ai-models-is-critical-in-healthcare"&gt;Why open-sourcing the AI models is critical in healthcare&lt;/h3&gt;&lt;p&gt;Beyond generosity, Google’s decision to make these models is also strategic. Healthcare has unique requirements that standard AI services can’t always meet. Hospitals need to know their patient data isn’t leaving their premises. Research institutions need models that won’t suddenly change behaviour without warning. Developers need the freedom to fine-tune for very specific medical tasks.&lt;/p&gt;&lt;p&gt;By open-sourcing the AI models, Google has addressed these concerns with healthcare deployments. A hospital can run MedGemma on their own servers, modify it for their specific needs, and trust that it’ll behave consistently over time. For medical applications where reproducibility is crucial, this stability is invaluable.&lt;/p&gt;&lt;p&gt;However, Google has been careful to emphasise that these models aren’t ready to replace doctors. They’re tools that require human oversight, clinical correlation, and proper validation before any real-world deployment. The outputs need checking, the recommendations need verifying, and the decisions still rest with qualified medical professionals.&lt;/p&gt;&lt;p&gt;This cautious approach makes sense. Even with impressive benchmark scores, medical AI can still make mistakes, particularly when dealing with unusual cases or edge scenarios. The models excel at processing information and spotting patterns, but they can’t replace the judgment, experience, and ethical responsibility that human doctors bring.&lt;/p&gt;&lt;p&gt;What’s exciting about this release isn’t just the immediate capabilities, but what it enables. Smaller hospitals that couldn’t afford expensive AI services can now access cutting-edge technology. Researchers in developing countries can build specialised tools for local health challenges. Medical schools can teach students using AI that actually understands medicine.&lt;/p&gt;&lt;p&gt;The models are designed to run on single graphics cards, with the smaller versions even adaptable for mobile devices. This accessibility opens doors for point-of-care AI applications in places where high-end computing infrastructure simply doesn’t exist.&lt;/p&gt;&lt;p&gt;As healthcare continues grappling with staff shortages, increasing patient loads, and the need for more efficient workflows, AI tools like Google’s MedGemma could provide some much-needed relief. Not by replacing human expertise, but by amplifying it and making it more accessible where it’s needed most.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Owen Beard)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Tencent improves testing creative AI models with new benchmark&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/google-open-medgemma-ai-models-healthcare/</guid><pubDate>Thu, 10 Jul 2025 15:17:31 +0000</pubDate></item><item><title>Nvidia reportedly plans to release new AI chip designed for China (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/nvidia-reportedly-plans-to-release-new-ai-chip-designed-for-china/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia seems determined to find a way to sell AI chips in China despite U.S. export restrictions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor giant is planning to launch an AI chip specifically for the Chinese market as early as September, as originally reported by the Financial Times.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This AI chip would be based on Nvidia’s Blackwell RTX Pro 6000 processor, which is already modified to meet the existing AI chip restrictions, the Financial Times added. These chips wouldn’t include high-bandwidth memory or NVLink, Nvidia’s high-speed but low-latency communication interface, both of which are features of the company’s advanced AI chips.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Nvidia CEO Jensen Huang said the company would no longer include the Chinese market in its revenue and profit forecasts. Maybe that will be a short-lived change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia declined to comment on the news. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Nvidia spokesperson added, “With the current export controls, we are effectively out of the China datacenter market, which is now served only by competitors such as Huawei. China has one of the largest populations of developers in the world, creating open-source foundation models and non-military applications used globally. While security is paramount, every one of those applications should run best on the U.S. AI stack.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia seems determined to find a way to sell AI chips in China despite U.S. export restrictions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor giant is planning to launch an AI chip specifically for the Chinese market as early as September, as originally reported by the Financial Times.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This AI chip would be based on Nvidia’s Blackwell RTX Pro 6000 processor, which is already modified to meet the existing AI chip restrictions, the Financial Times added. These chips wouldn’t include high-bandwidth memory or NVLink, Nvidia’s high-speed but low-latency communication interface, both of which are features of the company’s advanced AI chips.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Nvidia CEO Jensen Huang said the company would no longer include the Chinese market in its revenue and profit forecasts. Maybe that will be a short-lived change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia declined to comment on the news. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Nvidia spokesperson added, “With the current export controls, we are effectively out of the China datacenter market, which is now served only by competitors such as Huawei. China has one of the largest populations of developers in the world, creating open-source foundation models and non-military applications used globally. While security is paramount, every one of those applications should run best on the U.S. AI stack.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/nvidia-reportedly-plans-to-release-new-ai-chip-designed-for-china/</guid><pubDate>Thu, 10 Jul 2025 15:29:32 +0000</pubDate></item><item><title>How AI will accelerate biomedical research and discovery (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated images of Peter Lee, Daphne Koller, Noubar Afeyan, and Dr. Eric Topol for the Microsoft Research Podcast" class="wp-image-1144053" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&lt;/p&gt;



&lt;p&gt;In this episode, Daphne Koller&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Noubar Afeyan&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Dr. Eric Topol&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, leaders in AI-driven medicine, join Lee to explore the rapidly evolving role of AI across the biomedical and healthcare landscape. Koller, founder and CEO of Insitro, shares how machine learning is transforming drug discovery, especially target identification for complex diseases like ALS, by uncovering biological patterns across massive datasets. Afeyan, founder and CEO of Flagship Pioneering and co-founder and chairman of Moderna, discusses how AI is being applied across biotech research and development, from protein design to autonomous science platforms. Topol, executive vice president of Scripps Research and founder and director of the Scripps Research Translational Institute, highlights how AI can &lt;em&gt;today&lt;/em&gt; help mitigate and prevent the core diseases that erode our health and the possibility of realizing a virtual cell. Through his conversations with the three, Lee investigates how AI is reshaping the discovery, deployment, and delivery of medicine.&amp;nbsp;&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;




&lt;/div&gt;







&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“Can GPT-4 indeed accelerate the progression of medicine&lt;strong&gt; &lt;/strong&gt;… ? It seems like a tall order, but if I had been told six months ago that it could rapidly summarize any published paper, that alone would have satisfied me as a strong contribution to research productivity. … But now that I’ve seen what GPT-4 can do with the healthcare process, I expect a lot more in the realm of research.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee.&lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?&lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



&lt;p&gt;[THEME MUSIC FADES]&lt;/p&gt;



&lt;p&gt;The book passage I read at the top was from “Chapter 8: Smarter Science,” which was written by Zak.&lt;/p&gt;



&lt;p&gt;In writing the book, we were optimistic about AI’s potential to accelerate biomedical research and help get new and much-needed treatments and drugs to patients sooner. One area we explored was generative AI as a designer of clinical trials. We looked at generative AI’s adeptness at summarizing helping speed up pre-trial triage and research. We even went so far as to predict the arrival of a large language model that can serve as a central intellectual tool.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For a look at how AI is impacting biomedical research today, I’m excited to welcome Daphne Koller, Noubar Afeyan, and Eric Topol.&amp;nbsp;&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;Daphne Koller is the CEO and founder of Insitro, a machine learning-driven drug discovery and development company that recently made news for its identification of a novel drug target for ALS and its collaboration with Eli Lilly to license Lilly’s biochemical delivery systems. Prior to founding Insitro, Daphne was the co-founder, co-CEO, and president of the online education platform Coursera.&lt;/p&gt;



&lt;p&gt;Noubar Afeyan is the founder and CEO of Flagship Pioneering, which creates biotechnology companies focused on transforming human health and environmental sustainability. He is also co-founder and chairman of the messenger RNA company Moderna. An entrepreneur and biochemical engineer, Noubar has numerous patents to his name and has co-founded many startups in science and technology.&lt;/p&gt;



&lt;p&gt;Dr. Eric Topol is the executive vice president of the biomedical research non-profit Scripps Research, where he founded and now directs the Scripps Research Translational Institute. One of the most cited researchers in medicine, Eric has focused on promoting human health and individualized medicine through the use of genomic and digital data and AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These three are likely to have an outsized influence on how drugs and new medical technologies soon will be developed.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here’s my interview with Daphne Koller:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Daphne, I’m just thrilled to have you join us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DAPHNE KOLLER: &lt;/strong&gt;Thank you for having me, Peter. It’s a pleasure to be here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, you know, you’re quite well-known across several fields. But maybe for some audience members of this podcast, they might not have encountered you before. So where I’d like to start is a question I’ve been asking all of our guests.&lt;/p&gt;



&lt;p&gt;How would you describe what you do? And the way I kind of put it is, you know, how do you explain to someone like your parents what you do for a living?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;So that answer obviously has shifted over the years.&lt;/p&gt;



&lt;p&gt;What I would say now is that we are working to leverage the incredible convergence of very powerful technologies, of which AI is one but not the only one, to change the way in which we discover and develop new treatments for diseases for which patients are currently suffering and even dying.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think I’ve known you for a long time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Longer than I think either of us care to admit.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] In fact, I think I remember you even when you were still a graduate student. But of course, I knew you best when you took up your professorship at Stanford. And I always, in my mind, think of you as a computer scientist and a machine learning person. And in fact, you really made a big name for yourself in computer science research in machine learning.&lt;/p&gt;



&lt;p&gt;But now you’re, you know, leading one of the most important biotech companies on the planet. How did that happen?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; So people often think that this is a recent transition. That is, after I left Coursera, I looked around and said, “Hmm. What should I do next? Oh, biotech seems like a good thing,” but that’s actually not the way it transpired.&lt;/p&gt;



&lt;p&gt;This goes all the way back to my early days at Stanford, where, in fact, I was, you know, as a young faculty member in machine learning, because I was the first machine learning hire into Stanford’s computer science department, I was looking for really exciting places in which this technology could be deployed, and applications back then, because of scarcity of data, were just not that inspiring.&lt;/p&gt;



&lt;p&gt;And so I looked around, and this was around the late ’90s, and realized that there was interesting data emerging in biology and medicine. My first application actually was in, interestingly, in epidemiology—patient tracking and tuberculosis. You know, you can think of it as a tiny microcosm of the very sophisticated models that COVID then enabled in a much later stage.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And so initially, this was based almost entirely on just technical interest. It’s kind of like, oh, this is more interesting as a question to tackle than spam filtering. But then I became interested in biology in its own right, biology and medicine, and ended up having a bifurcated existence as a Stanford professor where half my lab continued to do core computer science research published in, you know, NeurIPS and ICML. And the other half actually did biomedical research that was published in, you know, &lt;em&gt;Nature Cell [and] Science&lt;/em&gt;. So that was back in, you know, the early, early 2000s, and for most of my Stanford career, I continued to have both interests.&lt;/p&gt;



&lt;p&gt;And then the Coursera experience kind of took me out of Stanford and put me in an industry setting for the first time in my life actually.&lt;strong&gt; &lt;/strong&gt;But then when my time at Coursera came to an end, you know, I’d been there for five years. And if you look at the timeline, I left Stanford in early 2012, right as the machine learning revolution was starting. So I missed the beginning.&lt;/p&gt;



&lt;p&gt;And it was only in like 2016 or so that, as I picked my head up over the trenches, like, “Oh my goodness, this technology is going to change the world.” And I wanted to deploy that big thing towards places where it would have beneficial impact on the world, like to make the world a better place.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And so I decided that one of the areas where I could make a unique, differentiated impact was in really bringing AI and machine learning to the life sciences, having spent, you know, the majority of my career at the boundary of those two disciplines. And notice I say “boundary” with deliberation because there wasn’t very much of an intersection.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; I felt like I could do something that was unique.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So just to stick on you for a little bit longer, you know, we have been sort of getting into your origin story about what we call AI today—but machine learning, so deep learning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, you know, there has always been a kind of an emotional response for people like you and me and now the general public about their first encounters with what we now call generative AI. I’d love to hear what your first encounter was with generative AI and how you reacted to this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; I think my first encounter was actually an indirect one. Because, you know, the earlier generations of generative AI didn’t directly touch our work at Insitro&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And yet at the same time, I had always had an interest in computer vision. That was a large part of my non-bio work when I was at Stanford.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so some of my earlier even presentations, when I was trying to convey to people back in 2016 how this technology was going to transform the world, I was talking about the incredible progress in image recognition that had happened up until that point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my first interaction was actually in the generative AI for images, where you are able to go the other way …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;… where you can take a verbal description of an image and create—and this was back in the days when the images weren’t particularly photorealistic, but still a natural language description to an image was magic given that only two or three years before that, we were barely able to look at an image and write a short phrase saying, “This is a dog on the beach.” And so that arc, that hockey curve, was just mind blowing to me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Did you have moments of skepticism?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;Yeah, I mean the early, you know, early versions of ChatGPT, where it was more like parlor tricks and poking it a little bit revealed all of the easy ways that one could break it and make it do really stupid things. I was like, yeah, OK, this is kind of cute, but is it going to actually make a difference? Is it going to solve a problem that matters?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I mean, obviously, I think now everyone agrees that the answer is yes, although there are still people who are like, yeah, but maybe it’s around the edges. I’m not among them, by the way, but … yeah, so initially there were like, “Yeah, this is cute and very impressive, but is it going to make a difference to a problem that matters?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&lt;strong&gt; &lt;/strong&gt;So now, maybe this is a good time to get into what you’ve been doing with ALS [amyotrophic lateral sclerosis]. You know, there’s a knee-jerk reaction from the technology side to focus on designing small molecules, on predicting, you know, their properties, you know, maybe binding affinity or aspects of ADME [absorption, distribution, metabolism, and excretion], you know, like absorption or dispersion or whatever.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And all of that is very useful, but if I understand the work on ALS, you went to a much harder place, which is to actually identify and select targets.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So first off, just for the benefit of the standard listeners of this podcast, explain what that problem is in general.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; No, for sure. And I think maybe I’ll start by just very quickly talking about the drug discovery and development arc, …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … which, by and large, consists of three main phases. That’s the standard taxonomy.&amp;nbsp;The first is what’s called sometimes target discovery or identifying a therapeutic hypothesis, which looks like: if I modulate this target in this disease, something beneficial will happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Then, you have to take that target and turn it into a molecule that you can actually put into a person. It could be a small molecule. It could be a large molecule like an antibody, whatever. And then you have that construct, that molecule. And the last piece is you put it into a person in the context of a clinical trial, and you measure what has happened. And there’s been AI deployed towards each of those three stages in different ways.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The last one is mostly like an efficiency gain. You know, the trial is kind of already defined, and you want to deploy technology to make it more efficient and effective, which is great because those are expensive operations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The middle one is where I would say the vast majority of efforts so far has been deployed in AI because it is a nice, well-defined problem. It doesn’t mean it’s easy, but it’s one where you can define the problem. It is, &lt;em&gt;I need to inhibit this protein by this amount, and the molecule needs to be soluble and whatever and go past the blood-brain barrier&lt;/em&gt;. And you know probably within a year and a half or so, or two, if you succeeded or not.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The first stage is the one where I would say the least amount of energy has gone because when you’re uncovering a novel target in the context of an indication, you don’t know that you’ve been successful until you go &lt;em&gt;all the way&lt;/em&gt; to the end, which is the clinical trial, which is what makes this a long and risky journey. And not a lot of people have the appetite or the capital to actually do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, in my opinion, and that of, I think, quite a number of others, it is where the biggest impact can be made. And the reason is that while pharma has its deficiencies, making good molecules is actually something they’re pretty good at.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It might take them longer than it should, maybe it’s not as efficient as it could be, but at the end of the day, if you tell them to drug A target, pharma is actually pretty good at generating those molecules. However, when you put those molecules into the clinic, 90% of them fail. And the reason they fail is not by and large because the molecule wasn’t good. In the majority of cases, it’s because the target you went after didn’t do anything useful in the context of the patient population in which you put it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so in order to fix the inefficiency of this industry, which is &lt;em&gt;incredible&lt;/em&gt; inefficiency, you need to address the problem at the root, and the root is picking the right targets to go after. And so that is what we elected to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It doesn’t mean we don’t make molecules. I mean, of course, you can’t just end up with a target because a target is not actionable. You need to turn it into a molecule. And we absolutely do that. And by the way, the partnership with Lilly&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; is actually one where they help us make a molecule.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;I mean, it’s our target. It’s our program. But Lilly is deploying its very state-of-the-art molecule-making capabilities to help us turn that target into a drug.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So let’s get now into the machine learning of this. Again, this just strikes me as such a difficult problem to solve.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So how does machine learning … how does AI help you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; So I think when you look at how people currently select targets, it’s a combination of oftentimes at this point, with an increasing respect for the power of human genetics, some search for a genetic association, oftentimes with a human-defined, highly subjective, highly noisy clinical outcome, like some ICD [International Classification of Diseases] code.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And those are often underpowered and very difficult to deconvolute the underlying biology. You combine that with some mechanistic interrogation in a highly reductionist model system looking at a small number of readouts, biochemical readouts, that a biologist thinks are relevant to the disease. Like does this make this, whatever, cholesterol go up or amyloid beta go down? Or whatever. And then you take that as the second stage, and you pick, based on typically human intuition about, &lt;em&gt;Oh, this one looks good to me&lt;/em&gt;, and then you take that forward.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What we’re doing is an attempt to be as unbiased and holistic as possible. So, first of all, rather than rely on human-defined clinical endpoints, like this person has been diagnosed with diabetes or fatty liver, we try and measure as much as we can a holistic physiological state and then use machine learning to find structure, patterns &lt;em&gt;in&lt;/em&gt; that human physiological readouts, imaging readouts, and omics readouts from blood, from tissue, different kinds of imaging, and say, these are different vectors that this disease takes, this group of individuals, and here’s a different group of individuals that maybe from a diagnostical perspective are all called the same thing, but they are actually exhibiting a very different biology underlying it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that is something that doesn’t emerge when a human being takes a reductionist view to looking at this high-content data, and oftentimes, they don’t even look at it and produce an ICD code.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The same approach, actually even the same code base, is taken in the cellular data. So we don’t just say, “Well, the thing that matters is, you know, the total amount of lipid in the cell or whatever.” Rather, we say, “Let’s look at multiple readouts, multiple ways of looking at the cells, combine them using the power of machine learning.” And again, looking at imaging readouts where a human’s eyes just glaze over looking at even a few dozen cells, far less a few hundreds of millions of cells, and understand what are the different biological processes that are going on. What are the vectors that the disease might take you in this direction, in this group of cells, or in that direction?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then importantly, we take all of that information from the human side, from the cellular side, across these different readouts, and we combine them using an integrative approach that looks at the combined weight of evidence and says, these are the targets that I have the greatest amount of conviction about by looking across all of that information. Whereas we know, and we know this, I’m sure you’ve seen this analysis done for clinicians, a human being typically is able to keep three or four things in their head at the same time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; A really &lt;em&gt;good&lt;/em&gt; human being who’s really expert at what they do can maybe get to six to eight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The machine learning has no problem doing a few hundred.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And so you put that together, and that allows you, to your earlier question, really select the targets around which you have the highest conviction. And then those are the ones that we then prioritize for interrogation in more expensive systems like mice and monkeys and then at the end of the day pick the small handful that one can afford to actually take into clinical trials.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So now, Insitro recently received $25 million in milestone payments from Bristol Myers Squibb&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; after discovering and selecting a novel drug target for ALS. Can you tell us a little bit more about that? &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; We are incredibly excited about the first novel target, and there is a couple of others just behind it in line that seem, you know, quite efficacious, as well, that truly seem to reverse, albeit in a cellular system, what we now understand to be ALS pathology across multiple different dimensions. There’s been obviously many attempts made to try and address ALS, which by the way, horrible, horrible disease, worse than most cancers. It kills you almost inevitably in three to five years in a particularly horrific way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what we have in our hands is a target that seems to revert a lot of the pathologies that are associated with the disease, which we now understand has to do with the mis-splicing of multiple proteins within the cell and creating defective versions of those proteins that are just not operational. And we are seeing reversion of many of those.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So can I tell you for sure it’ll work in a human? No, there’s many steps between now and then. But we couldn’t be more excited about the opportunity to provide what we hope will be a disease-modifying intervention for these patients who really desperately need something.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, it’s certainly been making waves in the biotech and biomedical world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So we’ll be really watching very closely.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, you know, I think just reflecting on, you know, what we missed and what we got right in our book, I think in our book, we did have the insight that there would be an ability to connect, say, genotypic and phenotypic data and, you know, just broadly the kinds of clinical measurements that get made on real patients and that these things could be brought together. And I think the work that you’re doing really illustrates that in a very, very sophisticated, very ambitious way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the fact that this could be connected all the way down to the biology, to the biochemistry, I think we didn’t have any clue what would happen, at least not this quickly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Well, I think the …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And I realize, you’ve been at this for quite a few years, but still, it’s quite amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The thread that connects them is human genetics. And I think that has, to us, been, sort of, the, kind of, the connective tissue that allows you to translate across different systems and say, “What does this gene do? What does this gene do in this organ and in that organ? What does it do in this type of cell and in that type of cell?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then use that as sort of the thread, if you will, that follows the impact of modulating this gene all the way from the simple systems where you can do the experiment to the complex systems where you can’t do the experiment until the very end, but you have the human genetics as a way of looking at the statistics and understanding what the impact might be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I’d like to now switch gears and take … I want to take two steps in the remainder of this conversation towards the future. So one step into that future, of course, we’re living through now, which is just all of the crazy pace of work and advancement in generative AI generally, you know, just the scale of transformers, of post-training, and now inference scale and reasoning models and so on. And where do you see all of that going with respect to the goals that you have and that Insitro has?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; So I think first and foremost is the parallel, if you will, to the predictions that you focused on in your book, which is this will transform a lot of the core data processing tasks, the information tasks. And sure, the doctors and nurses is one thing. But if you just think of clinical trial operations or the submission of regulatory documents, these are all kind of simple data … they’re not simple, obviously, but they’re data processing tasks. They involve natural language. That’s not going to be our focus, but I hope that others will use that to make clinical trials faster, more efficient, less expensive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s already a lot of progress that’s happening on the molecular design side of things and taking hypotheses and turning them quickly and effectively into molecules. As I said, this is part of our work that we absolutely do and we don’t talk about it very much, simply because it’s a very crowded landscape and a lot of companies are engaged on that. But I think it’s really important to be able to take biological insights and turn them into new molecules.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, of course, the transformer models and their likes play a very significant role in that sort of turning insights into molecules because you can have foundation models for proteins. There are increasing efforts to create foundation models for other categories of molecules. And so that will undoubtedly accelerate the process by which you can quickly generate different molecular hypotheses and test them and learn from what you did so that you can do fewer iterations …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … before you converge on a successful molecule.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I do think that arguably the biggest impact as yet to be had is in that understanding of core human biology and what are the right ways to intervene in it. And that plays a role in a couple different ways. First of all, it certainly plays a role in which … if we are able to understand the human physiological state and, you know, the state of different systems all the way down to the cell level, that will inform our ability to pick hypotheses that are more likely to actually impact the right biologies underneath.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And the more data we’re able to collect about humans and about cells, the more successful our models will be at representing that human physiological state or the cell biological state and making predictions reliably on the impact of these interventions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The other side of it, though, and this comes back, I think, to themes that were very much in your book, is this will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And I think there’s been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the opportunity is still there. We just haven’t been able to bring it to life because of the lack of the right kind of data. And I think with the increasing amount of human, kind of, foundational data that we’re able to acquire, things that are not sort of distilled through the eye of a clinician, for example, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … but really measurements of human pathology, we can start to get to some of that precision, carving out of the human population and then get to a world where we can prescribe the right medicine to the right patient and not only in cancer but also in other diseases that are also not a single disease.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;All right, so now to wrap up this time together, I always try to ask one more provocative last question. One of the dreams that comes naturally to someone like me or any of my colleagues, probably even to you, is this idea of, you know, wouldn’t it be possible someday to have a foundation model for biology or for human biology or foundation model for the human cell or something along these lines?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, there are, of course, you and I are both aware of people who are taking that idea seriously and chasing after it. I have people in our labs that think hard about this kind of thing. Is it a reasonable thought at all?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; I have learned over the years to avoid saying the word &lt;em&gt;never&lt;/em&gt; because technology proceeds in ways that you often don’t expect. And so will we at some point be able to measure the cell in enough different ways across enough different channels at the same time that you can piece together what a cell does? I think that is eminently feasible, not today, but over time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I don’t think it’s feasible using today’s technology, although the efforts to get there may expose where the biggest opportunities lie to, you know, build that next layer. So I think it’s good that people are working on really hard problems. I would also point out that even if one were to solve that really challenging problem of creating a model of &lt;em&gt;a cell&lt;/em&gt;, there is thousands of different types of cells within the human body.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;They’re very different. They also talk to each other …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … both within the cell type and across different cell types. So the combinatorial complexity of that system is, I think, unfathomable to many people. I mean, I would say to all of us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;And so even from that very lofty goal, there is multiple big steps that would need to be taken to a &lt;em&gt;mechanistic&lt;/em&gt; model of the full organism. So will we ever get there? Again, you know, I don’t see a reason why this is impossible to do. So I think over time, technology will get better and will allow us to build more and more elaborate models of more and more complex systems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Patients can’t wait …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … for that to happen in order for us to get them better medicines. So I think there is a great basic science initiative on that side of things. And, in parallel, we need to make do with the data that we have or can collect or can print. We print a lot of data in our internal wet labs and get to drugs that are effective even though they don’t benefit from having a full-blown mechanistic model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Last question: where do you think we’ll be in five years?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Phew. If I had answered that question five years ago, I would have been very badly embarrassed at the inaccuracy of my answer. [LAUGHTER] So I will not answer it today either.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I will say that the thing about exponential curves is that they are very, very tricky, and they move in unexpected ways. I would hope that in five years, we will have made a sufficient investment in the generation of scientific data that we will be able to move beyond data that was generated entirely by humans and therefore insights that are derivative of what people already know to things that are truly novel discoveries.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think in order to do that in, you know, math, maybe because math is entirely conceptual, maybe you can do that today. Math is effectively a construct of the human mind. I don’t think biology is a construct of the human mind, and therefore one needs to collect enough data to really build those models that will give rise to those novel insights.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s where I hope we will have made considerable progress in five years.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, I’m with you. I hope so, too. Well, you know, thank you, Daphne, so much for this conversation. I learn a lot talking to you, and it was great to, you know, connect again on this. And congratulations on all of this success. It’s really groundbreaking.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Thank you very much, Peter. It was a pleasure chatting with you, as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I still think of Daphne first and foremost as an AI researcher. And for sure, her research work in machine learning continues to be incredibly influential to this day. But it’s her work on AI-enhanced drug development that now is on the verge of making a really big difference on some of the most difficult diseases afflicting people today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our book, Carey, Zak, and I predicted that AI might be a meaningful accelerant in biomedical research, but I don’t know that we foresaw the incredible potential specifically in drug development.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Today, we’re seeing a flurry of activity at companies, universities, and startups on generative AI systems that aid and maybe even completely automate the design of new molecules as drug candidates. But now, in our conversation with Daphne, seeing AI go even further than that to do what one might reasonably have assumed to be impossible, to identify and select novel drug targets, especially for a neurodegenerative disease like ALS, it’s just, well, mind blowing. &lt;/p&gt;



&lt;p&gt;Let’s continue our deep dive on AI and biomedical research with this conversation with Noubar Afeyan:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Noubar, thanks so much for joining. I’m really looking forward to this conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;NOUBAR AFEYAN: &lt;/strong&gt;Peter, thanks. Thrilled to be here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; While I think most of the listeners to this podcast have heard of Flagship Pioneering&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, it’s still worth hearing from you, you know, what is Flagship? And maybe a little bit about your background. And finally, you found a way to balance science and business creation. And so, you know, your approach and philosophy to all of that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;Well, great. So maybe I’ll just start out by way of quick background. You know, my … and since we’re going talk about AI, I’ll also highlight my first contact with the topic of AI. So as an undergraduate in 1980 up at McGill University, I was an engineering student, but I was really captivated by, at that time, the talk on the campus around the expert system, heuristic-based, rule-based kind of programs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; And so actually I had the dubious distinction of writing my one and only college newspaper article. [LAUGHTER] That was a short career. And it was all about how artificial intelligence would be impacting medicine, would be impacting, you know, speech capture, translation, and some of the ideas that were there that it’s interesting to see now 45 years later re-emerge with some of the new learning-based models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My journey after college ended up taking me into biotechnology. In the early ’80s, I came to MIT to do a PhD. At the time, the field was brand new. I ended up being the first PhD graduate from MIT in this combination biology and engineering degree. And since then, I’ve basically been—so since 1987—a founder, a technologist in the space of biotechnology for human health and as well for planetary health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then in 1999/2000 formed what is now Flagship Pioneering, which essentially was an attempt to bring together the three elements of what we know are important in startups. That is scientific capital, human capital, and financial capital. Right now, startups get that from different places. The science in our fields mostly come from academia, research hospitals. The human capital comes from other startups …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … or large companies or some academics leave. And then the financial capital is usually venture capital, but there’s also now more and more other deeper pockets of money.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What we thought was, what if all that existed in one entity and instead of having to convince each other how much they should believe the other if we just said, “Let’s use that power to go work on much further out things”? But in a way where nobody would believe it in the beginning, but we could give ourselves a little bit of time to do impactful big things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Twenty-five years later, that’s the road we’ve stayed on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; OK. So let’s get into AI. Now, you know, what I’ve been asking guests is kind of an origin story. And there’s the origin story of contact with AI, you know, before the emergence of generative AI and afterwards. I don’t think there’s much of a point to asking you the pre-ChatGPT. But … so let’s focus on your first encounter with ChatGPT or generative AI. When did that happen, and what went through your head?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Yeah. So, if you permit me, Peter, just for very briefly, let me actually say I had the interesting opportunity over the last 25 years to actually stay pretty close to the machine learning world …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … because one, as you well know, among the most prolific users of machine learning has been the bioinformatics computational biology world because it’s been so data rich that anything that can be done, people have thrown at these problems because unlike most other things, we’re not working on man-made data. We’re looking at data that comes from nature, the complexity of which far exceeds our ability to comprehend.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So you could imagine that any approach to statistically reduce complexity, get signal out of scant data—that’s a problem that’s been around.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The other place where I’ve been exposed to this, which I’m going to come back to because that’s where it first felt totally different to me, is that some 25 years ago, actually the very first company we started was a company that attempted to use evolutionary algorithms to essentially iteratively evolve consumer-packaged goods online. Literally, we tried to, you know, consider features of products as genes and create little genomes of them. And by recombination and mutation, we could create variety. And then we could get people through panels online—this was 2002/2003 timeframe—we could essentially get people through iterative cycles of voting to create a survival of the fittest. And that’s a company that was called Affinnova.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The reason I say that is that I knew that there’s a much better way to do this if only: one, you can generate variety …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … without having to prespecify genes. We couldn’t do that before. And, two, which we’ve come back to nowadays, you can actually mimic how humans think about voting on things and just get rid of that element of it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So then to your question of when does this kind of begin to feel different? So you could imagine that in biotechnology, you know, as an engineer by background, I always wanted to do CAD, and I picked the one field in which CAD doesn’t exist, which is biology. Computer-aided design is kind of a notional thing in that space. But boy, have we tried. For a long time, …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … people would try to do, you know, hidden Markov models of genomes to try to figure out what &lt;em&gt;should&lt;/em&gt; be the next, you know, base that you may want to or where genes might be, etc. But the notion of generating in biology has been something we’ve tried for a while. And in the late teens, so kind of 2018, ’17, ’18, because we saw deep learning come along, and you could basically generate novelty with some of the deep learning models … and so we started asking, “Could you generate a protein basically by training a correspondence table, if you will, between protein structures and their underlying DNA sequence?” Not their protein sequence, but their DNA sequence.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So that’s a big leap. So ’17/’18, we started this thing. It was called 56. It was FL56, Flagship Labs 56, our 56th project.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, we started this parallel one called “57” that did it in a very different way. So one of them did pure black box model-building. The other one said, you know what, we don’t want to do the kind of … at that time, AlphaFold was in its very early embodiments. And we said, “Is there a way we could actually take little, you know, multi amino acid kind of almost grammars, if you will, a little piece, and then see if we could compose a protein that way?” So we were experimenting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what we found was that actually, if you show enough instances and you could train a transformer model—back in the day, that’s what we were using—you could actually, say, predict another sequence that should have the same activity as the first one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;So we trained on green fluorescent proteins. Now, we’re talking about seven years ago. We trained on enzymes, and then we got to antibodies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With antibodies, we started seeing that, boy, this could be a pretty big deal because it has big market impact. And we started bringing in some of the diffusion models that were beginning to come along at that time. And so we started getting much more excited. This was all done in a company that subsequently got renamed from FL56 to Generate:Biomedicines&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep, yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;… which is one of the leaders in protein design using the generative techniques. It was interesting because Generate:Biomedicines is a company that was called that before generative AI was a thing, [LAUGHTER] which was kind of very ironic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, of course, that team, which operates today very, very kind of at the cutting edge, has published their models. They came up with this first Chroma&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; model, which is a diffusion-based model, and then started incorporating a lot of the LLM capabilities and fusing them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now we’re doing atomistic models and many other things. The point being, that gave us a glimpse of how quickly the capability was gaining, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … just like evolution shows you. Sometimes evolution is super silent, and then all of a sudden, all hell breaks loose. And that’s what we saw.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. One of the things that I reflect on just in my own journey through this is there are other emotions that come up. One that was prominent for me early on was skepticism. Were there points when even in your own work, transformer-based work on this early on, that you had doubts or skepticism that these transformer architectures would be or diffusion-based approaches would be worth anything?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; You know, it’s interesting, I think that, I’m going to say this to you in a kind of a friendly way, but you’ll understand what I mean. In the world I live in, it’s kind of like the slums of innovation, [LAUGHTER] kind of like just doing things that are not supposed to work. The notion of skepticism is a luxury, right. I assume everything we do won’t work. And then once in a while I’m wrong.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I don’t actually try to evaluate whether before I bring something in, like just think about it. We, some hundred or so times a year, ask “what if” questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that’s testable. Then we go into a lab, and we test it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in that world, right, sitting there going, like, “How do I know this transformer is going to work?” The answer is, “For what?” Like, it’s going to work. To make something up … well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s just such a different use that, of course, I have trained scientific skepticism, but it’s a little bit like looking at a competitive situation in an ecology and saying, “I bet that thing’s going to die.” Well, you’d be right—most of the time, you’d be right. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I just don’t … like, it … and that’s why—I guess, call me an early adopter—for us, things that could move the needle even a little, but then upon repetition a lot, let alone this, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … you have to embrace. You can’t wait there and say, I’ll embrace it once it’s ready. And so that’s what we did.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. All right. So let’s get into some specifics and what you are seeing either in your portfolio companies or in the research projects or out in the industry. What is going on today with respect to AI really being used for something meaningful in the design and development of drugs?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; In companies that are doing as diverse things as—let me give you a few examples—a project that’s now become a named company called ProFound Therapeutics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that literally discovered three, four years ago, and would not have been able to without some of the big data-model-building capabilities, that our cells make literally thousands, if not tens of thousands, of more proteins than we were aware of, full stop.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We had done the human genome sequence, there was 20,000 genes, we thought that there was …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … maybe 70-80,000, 100,000 proteins, and that’s that. And it turns out that our cells have a penchant to express themselves in the form of proteins, and they have many other ways than we knew to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, so what does that mean? That means that we have generated a massive amount of data, the interpretation of which, the use of which to guide what you do and what these things might be involved with is purely being done using the most cutting-edge data-trained models that allow you to navigate such complexity.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow. Hmm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; That’s just one example. Another example: a company called Quotient Therapeutics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, again three, four years old. I can talk about the ones that are three, four years old because we’ve kind of gotten to a place where we’ve decided that it’s not going to fail &lt;em&gt;yet&lt;/em&gt;, [LAUGHTER] so we can talk about it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, we discovered—our team discovered—that in our cells, right, so we know that when we get cancer, our cells have genetic mutations in them or DNA mutations that are correlated and often causal to the hyperproliferative stages of cancer. But what we assume is that all the other cells in our body, pretty much, have one copy of their genes from our mom, one copy from our dad, and that’s that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And when very precise deep sequencing came along, we always asked the question, “How much variation is there cell to cell?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; And the answer was it’s kind of noise, random variation. Well, our team said, “Well, what if it’s not really that random?” because upon cell division cycles, there’s selection happening on these cells. And so not just in cancer but in liver cells, in muscle cells, in skin cells …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Oh, interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … can you imagine that there’s an evolutionary experiment that is favoring either compensatory mutations that are helping you avoid disease or disease-caused mutations that are gaining advantage as a way to understand the mechanism? Sure enough—I wouldn’t be telling you otherwise—with &lt;em&gt;massive&lt;/em&gt; amount of single cell sequencing from individual patient samples, we’ve now discovered that the human genome is mutated on average in our bodies 10,000 times, like over every base, like, it’s huge numbers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And we’re finding very interesting big signals come out of this massive amount of data. By the way, data of the sort that the human mind, if it tries to assign causal explanations to what’s happening …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … is completely inadequate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; When you think about a language model, we’re learning from human language, and the totality of human language—at least relative to what we’re able to compute today in terms of constructing a model—the totality of human language is actually pretty limited. And in fact, you know, as is always written about in click-baity titles, you know, the big model builders are actually starting to run short.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Running out, running out, yes. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; But one of the things that perplexes me and maybe even worries me—like these two examples—are generally in the realm of cellular biology and the complexity. Let’s just take the example of your company, ProFound. You know, the complexity of what’s going on and the potential genetic diversity is such that, can we ever have enough data? You know, because there just aren’t that many human beings. There just aren’t that many samples.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;Well, it depends on what you want to train, right. So if you want to train a &lt;em&gt;de novo&lt;/em&gt; evolutionary model that could take you from bacteria to human mammalian cells and the like, there may not be—and I’m not an expert in that—but that’s a question that we often kind of think about.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you’re trying to train a … like you know what the proteins we know about, how they interact with pathways and disease mechanisms and the like. Now all of a sudden you find out that there’s a whole continent of them missing in your explanations. But there are things you can reason, in quotations, through analogy, functional analogy, sequence analogy, homology. So there’s a lot of things that we could do to essentially make use of this, even though you may not have the totality of data needed to, kind of, predict, based on a de novo sequence, exactly what it’s going to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I agree with the comparison. But … but you’re right. The complexity is … just keep in mind, on average, a protein may be interacting with 50 to 100 other proteins.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So if you find thousands of proteins, you’ve found a massive interaction space through which information is being processed in a living cell.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;But do you find in your AI companies that access to data ends up being a key challenge? Or, you know, how central is that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Access to data is a key challenge for the companies we have that are trying to build just models. But that’s the minority of things we do. The majority of things we do is to actually co-develop the data and the models. And as you know well, because you guys, you know, have given us some ideas around this space, that, you know, you could generate data and &lt;em&gt;then&lt;/em&gt; think about what you’re to do with it, which is the way biotech is operated with bioinformatics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Or you could generate bespoke data that is used to train the model that’s quite separate from what you would have done in the natural course of biology. So we’re doing much more of the latter of late, and I think that’ll continue. So, but these things are proliferating.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean,&lt;strong&gt; &lt;/strong&gt;it’s hard to find a place where we’re not using this.&lt;strong&gt; &lt;/strong&gt;And the “this” is any and all data-driven model building, generative, LLM-based, but also every other technique to make progress.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Sure.&lt;strong&gt; &lt;/strong&gt;So now moving away from the straight biochemistry applications, what about AI in the process of building a business, of making investment decisions, of actually running an operation? What are you seeing there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So, well, you know, Moderna, which is a company that I’m quite proud of being a founder and chairman of, has adopted a significant, significant amount of AI embedded into their operations in all aspects: from the manufacturing, quality control, the clinical monitoring, the design—every aspect. And in fact, they’ve had a partnership that they’ve had for a little while here with OpenAI, and they’ve tried many different ways to stay at the cutting edge of that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So we see that play out at some scale. That’s a 5,000-, 6,000-person organization, and what they’re doing is a good example of what early adopters would do, at least in our kind of biotechnology company.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then, you know, in our space, I would say the efficiency impact is kind of no different, than, you know, anywhere else in academia you might adopt it or in other kinds of companies. But where I find it an interesting kind of maybe segue is the degree to which&lt;strong&gt; &lt;/strong&gt;it may fundamentally change the way we think about how to do science, which is a whole other use, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So it’s not an efficiency gain &lt;em&gt;per se&lt;/em&gt;, although it’s maybe an effectiveness gain when it comes to science, but can you just fundamentally train models to generate hypotheses?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;And we have done that, and we’ve been doing this for the last three years. And now it’s getting better and better, the better these reasoning engines are getting and kind of being able to extrapolate and train for novelty. Can you convert that to the world’s best experimental protocol to very precisely falsify your hypothesis, on and on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That closing of that loop, kind of what we call &lt;em&gt;autonomous science&lt;/em&gt;, which we’ve been trying to do for the last two, three years and are making some progress in, that to me is another kind of bespoke use of these things, not to generate molecules in its chemistry, but to change the behavior of how science is done.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&lt;strong&gt; &lt;/strong&gt;So I always end with a couple of provocative questions, but I need—before we do that, while we’re on this subject—to get your take on Lila Sciences&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And there is a vision there that I think is very interesting. It’d be great to hear it described by you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Sure. So Lila, after operating for two to three years in kind of a preparatory kind of stealth mode, we’ve now had a little bit more visibility around, and essentially what we’re trying to do there is to create what we call automated science factories, and such a factory would essentially be able to take problems, either computationally specified or human-specified, and essentially do the experimental work in order to either make an optimization happen or enable something that just didn’t exist. And it’s really, at this point, we’ve shown proof of concept in narrow areas.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; But it’s hard to say that if you can do this, you can’t do some other things, so we’re just expanding it that way. We don’t think we need a complete proof or complete demonstration of it for every aspect.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So we’re just kind of being opportunistic. The idea for Lila is to partner with a number of companies. The good news is, within Flagship, there’s 48 of them. And so there’s a whole lot of them they can partner with to get their learning cycles. But eventually they want to be a real alternative to every time somebody has an idea, having to kind of go into a lab and manually do this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I do want to say one thing we touched on, Peter, though, just on that front, which is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … if you say, like, “What problem is this going to solve?” It’s several but an important one is just the flat-out human capacity to reason on this much data and this much complexity that is real. Because nature doesn’t try to abstract itself in a human understandable form.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; In biology, since it’s kind of like progress happens through evolutionary kind of selections, the evidence of which [has] long been lost, and so therefore, you just see what you have, and then it has a behavior. I really do think that there’s something to be said, and I want to—just for your audience—lay out a provocative, at least, thought on all this, which Lila is a beginning embodiment of, which is that I really think that what’s going to happen over the next five, 10 years, even while we’re all fascinated with the impending arrival of AGI [artificial general intelligence] is really what I call &lt;em&gt;poly-intelligence&lt;/em&gt;, which is the combination of human intelligence, machine intelligence, AI, and nature’s intelligence.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’re all fascinated at the human-machine interface. We know the human-nature interface, but imagine the machine-nature interface—that is, actually letting loose a digital kind of information processing life form through the algorithms that are being developed and the commensurately complex, maybe much more complex. We’ll see. And so now the question becomes, what does the human do?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And we’re living in a world which is human dominated, which means the humans say, “If I don’t understand it, it’s not real, basically. And if I don’t understand it, I can’t regulate it.” And we’re going to have to make peace with the fact that we’re not going to be able to predictably affect things without necessarily understanding them the way we could if we just forced ourselves to only work on problems we can understand. And that world we’re not ready for at all.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. All right. So this one I predict is going to be a little harder for you because I think while you think about the future, you live very much in the present. But I’d like you to make some predictions about what the biotech and biopharmaceutical industries are going to be able to do two years from now, five years from now, 10 years from now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Yeah, well, it’s hard for me because you know my nature, which is that I think this is all emergent.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; And so I would be the conceit of predicting. So I would say with likelihood positive predictive value of less than 10%, I’m happy to answer your question. So I’m not trying to score high [LAUGHTER] because I really think that my job is to envision it, not to predict it. And that’s a little bit different, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I actually was trying to pick what would be the hardest possible question I could ask you, [LAUGHTER] and this is what I came up with.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Yeah, no, no, I’m kidding here. So now look, I think that we will cross this threshold of understandability. And of course you’re seeing that in a lot of LLM things today. And of course, people are trying to train for things that are explainers and all that whole, there’s a whole world of that. But I think at some point we’re going to have to kind of let go and get comfortable working on things that, you know …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I sometimes tell people, you know, and I’m not the first, but scientists and engineers are different, it’s said, in that engineers work on things that they don’t wait until they get a full understanding of before they work with them. Well, now scientists are going to have to get used to that, too, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Because insisting that it’s only valid if it’s understandable. So, I would say, look, I hope that the time … for example, I think major improvements will be made in patient selection. If we can test drugs on patients that are more synchronized as to the stage of their disease …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … I think the answer will be much better. We’re working on that. It’s a company called Etiome&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, very, very early stage. It’s really beautiful data, very early data that shows that when we talk about MASH [metabolic dysfunction-associated steatohepatitis], liver disease, when we talk about Parkinson’s, there’s such a heterogeneity, not only of the subset type of the disease, but the stage of the disease, that this notion that you have stage one cancer, stage two cancer, again, nobody told nature there’s stages of that kind. It’s a continuum.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you can synchronize based on training, kind of, the ability to detect who are the patients that are in enough of a close proximity that should be treated so that the trial—much smaller a trial size—could give you a drug, then afterwards, you can prescribe it using these approaches.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Kind of we’re going to find that what we thought is one disease is more like 15 diseases. That’s bad news because we’re not going to be able to claim that we can treat everything which we can. It’s good news in that there’s going to be people who are going to start making much more specific solutions to things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So I can imagine that. I can imagine a generation of, kind of, students who are going to be able to play in this space without having 25 years of graduate education on the subject. So what is deemed knowledge sufficient to do creative things will change. I can go on and on, but I think all this is very close by and it’s very exciting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Noubar, I just always have so much fun, and I learn really a lot. It’s high-density learning when I talk to you. And so I hope our listeners feel the same way. It’s something I really appreciate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Well, Peter, thanks for this. And I think your listeners know that if I was asking you questions, you would be answering them with equal if not more fascinating stuff. So, thanks for giving me the chance to do that today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;I’m always fascinated by Noubar’s perspectives on fundamental research and how it connects to human health and the building of successful companies. I see him as a classic “systems thinker,” and by that, I mean he builds impressive things like Flagship Pioneering itself, which he created as a kind of biomedical innovation system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our conversation, I was really struck by the fact that he’s been thinking about the potential impact of transformers—transformers being the fundamental building block of large language models—as far back as 2017, when the first paper on the attention mechanism in transformers was published by Google.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, you know, it isn’t only about using AI to do things like understand and design molecules and antibodies faster. It’s interesting that he is also pushing really hard towards a future where AI might “close the loop” from hypothesis generation, to experiment design, to analysis, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, here’s my conversation with Dr. Eric Topol:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Eric, it’s really great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ERIC TOPOL: &lt;/strong&gt;Oh, Peter, I’m thrilled to be here with you here at Microsoft.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You’re a super famous person. Extremely well known to researchers even in computer science, as we have here at Microsoft Research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the question I’d like to ask is, how would you explain to your parents what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; [LAUGHS] That’s a good question. If I was just telling them I’m trying to come up with better ways to keep people healthy, that probably would be the easiest way to do it because if I ever got in deeper, I would lose them real quickly. They’re not around, but just thinking about what they could understand.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I think as long as they knew it was work centered on innovative paths to promoting and preserving human health, that would get to them, I think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; OK, so now, kind of the second topic, and then we let the conversation flow, is about origin stories with respect to AI. And with most of our guests, you know, I factor that into two pieces: the encounters with AI before ChatGPT and what we call generative AI and then the first contacts after.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, of course, you have extensive contact with both now. But let’s start with how you got interested in machine learning and AI prior to ChatGPT. How did that happen?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yeah, it was out of necessity. So back, you know, when I started at Scripps at the end of ’06, we started accumulating, you know, massive datasets. First, it was whole genomes. We did one of the early big cohorts of 1,400 people of healthy aging. We called the Wellderly whole genome sequence&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we started big in the sensor world, and then we started saying, what are we going to do with all this data, with electronic health records and all those sensors? And now we got whole genomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And basically, what we were doing, we were in hoarding mode. We didn’t have a way to meaningfully analyze it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;You would read about how, you know, data is the new oil and, you know, gold and whatnot. But we just didn’t have a way to extract the juice. And even when we wanted to analyze genomes, it was incredibly laborious.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And we weren’t extracting a lot of the important information. So that’s why … not having any training in computer science, when I was doing the … about three years of work to do the book &lt;em&gt;Deep Medicine&lt;/em&gt;, I started really, first auto-didactic about, you know, machine learning. And then I started contacting a lot of the real top people in the field and hanging out with them, and learning from them, getting their views as to, you know, where we are today, what models are coming in the future.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then I said, “You know what? We are going to be able to fix this mess.” [LAUGHS] We’re going to get out of the hoarding phase, and we’re going to get into, you know, really making a difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that’s when I embraced the future of AI. And I knew, you know, back—that was six years ago when it was published and probably eight or nine years ago when I was doing the research, and I knew that we weren’t there yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, at the time, we were seeing the image interpretation. That was kind of the early promise. But really, the models that were transformative, the transformer models, they were incubating back in 2017. So people knew something was brewing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And everyone said we’re going to get there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So then, ChatGPT comes out November of 2022; there’s GPT-4 in 2023, and now a lot has happened. Do you remember what your first encounter with that technology was?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Oh, sure. First, ChatGPT. You know, in the last days of November ’22, I was just blown away. I mean, I’m having a conversation. I’m having fun. And this is humanoid responding to me. I said, “&lt;em&gt;What?&lt;/em&gt;” You know? So that was to me, a moment I’ll never forget. And so I knew that the world was, you know, at a very kind of momentous changing point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Of course, knowing, too, that this is going to be built on, and built on quickly. Of course, I didn’t know how soon GPT-4 and all the others were going to come forward, but that was a wake-up call that the capabilities of AI had just made a humongous jump, which seemingly was all of a sudden, although I did know this had been percolating …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … you know, for what, at least five years, that, you know, it really was getting into its position to do this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I know one of the things that was challenging psychologically and emotionally for me is, it made me rethink a lot of things that were going on in Microsoft Research in areas like causal reasoning, natural language processing, speech processing, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m imagining you must have had some emotional struggles too because you have this amazing book, &lt;em&gt;Deep Medicine&lt;/em&gt;. Did you have to … did it go through your mind to rethink what you wrote in &lt;em&gt;Deep Medicine &lt;/em&gt;in light of this or, or, you know, how did that feel?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;It’s funny you ask that because in this one chapter I have on the virtual health coach, I wrote a whole bunch of scenarios …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … that were very kind of futuristic. You know, about how the AI interacts with the person’s health and schedules their appointment for this and their scan and tells them what lab tests they should tell their doctor to have, and, you know, all these things. And I sent a whole bunch of these, thinking that they were a little too far-fetched.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And I sent them to my editor when I wrote the book, and he says, “Oh, these are great. You should put them all in.” [LAUGHTER] What I didn’t realize is they weren’t that, you know, they were all going to happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. They weren’t that far-fetched at all.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Not at all. If there’s one thing I’ve learned from all this, is our imagination isn’t big enough.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; We think too small.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Now in our book that Carey, Zak, and I wrote, you know, we made, you know, we sort of guessed that GPT-4 might help biomedical researchers, but I don’t think that any of us had the thought in mind that the architecture around generative AI would be so directly applicable to, you know, say, protein structures or, you know, to clinical health records and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so a lot of that seems much more obvious today. But two years ago, it wasn’t. But we did guess that biomedical researchers would find this interesting and be helped along.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So as you reflect over the past two years, you know, do you have things that you think are very important, kind of, meaningful applications of generative AI in the kinds of research that Scripps does?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL&lt;/strong&gt;: Yeah. I mean, I think for one, you pointed out how the term &lt;em&gt;generative AI&lt;/em&gt; is a misnomer.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And so it really was prescient about how, you know, it had a pluripotent capability in every respect, you know, of editing and creating. So that was something that I think was telling us, an indicator that this is, you know, a lot bigger than how it’s being labeled. And our expectations can actually be more than what we had seen previously with the earlier version.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think what’s happened is that now, we keep jumping. It’s so quick that we can’t … you know, first we think, oh, well, we’ve gone into the agentic era, and then we could pass that with reasoning. [LAUGHTER] And, you know, we just can’t …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; It’s just wild.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So I think so many of us now will put in prompts that will necessitate or ideally result in a not-immediate gratification, but rather one that requires, you know, quite a bit of combing through the corpus of knowledge …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … and getting, with all the citations, a report or a response. And I think now this has been a reset because to do that on our own, it takes, you know, many, many hours. And it’s usually incomplete.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But one of the things that was so different in the beginning was you would get the references from up to a year and a half previously.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And that’s not good enough. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And now you get references, like, from the day before.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And so, you say, “Why would you do a regular search for anything when you could do something like this?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And then, you know, the reasoning power. And a lot of people who are not using this enough still are talking about, “Well, there’s no reasoning.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Which you dealt with really well in the book. But what, of course, you couldn’t have predicted is the new dimensions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I think you nailed it with GPT-4. But it’s all these just, kind of, stepwise progressions that have been occurring because of the velocity that’s unprecedented. I just can’t believe it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;We were aware of the idea of multi-modality, but we didn’t appreciate, you know, what that would mean. Like AlphaFold&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; [protein structure database], you know, the ability for AI to understand—or crystal structures—to really start understanding something more fundamental about biochemistry or medicinal chemistry.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I have to admit, when we wrote the book, we really had no idea.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Well, I feel the same way. I still today can’t get over it because the reason AlphaFold and Demis [Hassabis] and John Jumper [AlphaFold’s co-creators] were so successful is there was this protein databank.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And it had been kept for decades. And so, they had the substrate to work with.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So, you say, “OK, we can do proteins.” But then how do you do everything else?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And so this whole, what I call, “large language of &lt;em&gt;life&lt;/em&gt; model” work, which has gone into high gear like I’ve never seen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; You know, now to this holy grail of a virtual cell, and …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; You know, it’s basically … it’s … it was inspired by proteins. But now it’s hitting on, you know, ligands and small molecules, cells. I mean, nothing is being held back here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So how could anybody have predicted that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I sure wouldn’t have thought it would be possible at this point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. So just to challenge you, where do you think that is going to be two years from now? Five years from now? Ten years from now? Like, so you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; No, I think within 10 years for sure. You know the group that got assembled that Steve Quake&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; pulled together?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I think has 42 authors in a paper&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; in &lt;em&gt;Cell&lt;/em&gt;. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … that not only is this a worthy goal, but it’s actually going to be realized, that was impressive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I challenged him about that. How did you get these people all to agree? So many of them were naysayers. And by the time the workshop finished, they were fully convinced. I think that what we’re seeing is so much progress happening so quickly. And then all the different models, you know, across DNA, RNA, and everything are just zooming forward.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And it’s just a matter of pulling this together. Now when we have that, and I think it could easily be well before a decade and possibly, you know, between the five- and 10-year mark—that’s just a guess—but then we’re moving into another era of life science because right now, you know, this whole buzz about drug discovery.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;It’s not… with the ability to do all these perturbations at a cellular level.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Or the cell of interest.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Or the cell-to-cell interactions or the intra-cell interaction. So once you nail that, yeah, it takes it to a kind of another predictive level that we haven’t really fathomed. So, yes, there’s going to be drug discovery that’s accelerated. But this would make that and also the underpinnings of diseases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So the idea that there’s so many diseases we don’t understand now. And if you had virtual cell, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … you would probably get to that answer …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … much more quickly. So whether it’s underpinnings of diseases or what it’s going to take to really come up with far better treatments—preventions—I think that’s where virtual cell will get us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; There’s a technical question … I wonder if you have an opinion. You may or may not. There is sort of what I would refer to as &lt;em&gt;ab initio&lt;/em&gt; approaches to this. You know, you start from the fundamental physics and chemistry, and we know the laws, we have the math and, you know, we can try to derive from there … in fact, we can even run simulations of that math to generate training data to build generative models and work up to a cell, &lt;em&gt;or&lt;/em&gt; forget all of that and just take as many observations and measurements of, say, living cells as possible, and just have faith that hidden amongst all of the observational data, there is structure and language that can be derived.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that’s sort of bottom-up versus top-down approaches. Do you have an opinion about which way?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Oh, I think you go after both. And clearly whenever you’re positing that you’ve got a virtual cell model that’s working, you’ve got to do the traditional methods as well to validate it, and … so all that. You know, I think if you’re going to go out after this seriously, you have to pull out all the stops. Both approaches, I think, are going to be essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, if what you’re saying is true, and it is amazing to hear the confidence, the one thing I tried to explain to someone nontechnical is that for a lot of problems in medicine, we just don’t have enough data in a really profound way. And the most profound way to say that is, since Adam and Eve, there have only been an estimated 106 billion people who have ever lived.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So even if we had the DNA of every human being, every individual of &lt;em&gt;Homo sapiens&lt;/em&gt;, there are certain problems for which we would not have enough data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And so I think another thing that seems profound to me, if we can actually have a virtual cell, is we can actually make trillions of virtual …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Yeah&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; … human beings. The true genetic diversity could be realized for our species.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;I think you nailed it. The ability to have that type of data, no less synthetic data, I mean, it’s just extraordinary.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;We will get there someday. I’m confident of that. We may be wrong in projections. And I do think [science writer] Philip Ball won’t be right that it will never happen, though. [LAUGHTER] No, I think that if there’s a holy grail of biology, this is it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And I think you’re absolutely right about where that will get us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Transcending the beginning of the species.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Of&lt;em&gt; our&lt;/em&gt; species.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. All right. So now, we’re starting to run short on time here. And so I wanted to ask you about, I’m in my 60s, so I actually think about this a lot more. [LAUGHTER] And I know you’ve been thinking a lot about longevity. And, of course, your new book, &lt;em&gt;Super Agers&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And one of the reasons I’m so eager to read is it’s a topic very top of mind for me and actually for a lot of people. Where is this going? Because this is another area where you hear so much hype. At the same time, you see Nobel laureate scientists …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; … working on this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, so what’s, what’s real there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yeah. Well, it’s really … the real deal is the science of aging is zooming forward.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s exciting. But I see it bifurcating. On the one hand, all these new ideas, strategies to reverse aging are very ambitious. Like cell reprogramming and senolytics and, you know, the rejuvenation of our thymus gland, and it’s a long list.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And they’re really cool science, and it used to be the mouse lived longer. Now it’s the old mouse looks really young.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; All the different features. A blind mouse with cataracts is all of a sudden there’s no cataracts. I mean, so these things are exciting, but none of them are proven in people, and they all have significant risk, no less, you know, the expense that might be attached.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And some people are jumping the gun. They’re taking rapamycin, which can really knock out their immune system. So they all carry a lot of risk. And people are just getting a little carried away. We’re not there yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the other side, which is what I emphasize in the book, which is exciting, is that we have all these new metrics that came out of the science of aging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So we have clocks of the body. Our biological clock versus our chronological clock, and we have organ clocks. So I can say, you know, Peter, we’ve assessed all your organs and your immune system. And guess what? Every one of them is either at or less than your actual age.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And that’s very reassuring. And by the way, your methylation clock is also … I don’t need to worry about you so much. And then I have these other tests that I can do now, like, for example, the brain. We have an amazing protein p-Tau217 that we can say over 20 years in advance of you developing Alzheimer’s, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … we can look at that, and it’s modifiable by lifestyle, bringing it down. It should be you can change the natural history. So what we’ve seen is an explosion of knowledge of metrics, proteins, no less, you know, our understanding at the gene level, the gut microbiome, the immune system. So that’s what’s so exciting. How our immune system ages. &lt;em&gt;Immunosenescence&lt;/em&gt;. How we have more inflammation—&lt;em&gt;inflammaging&lt;/em&gt;—with aging. So basically, we have three diseases that kill us, that take away our health: heart, cancer, and neurodegenerative.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And they all take more than 20 years. They all have a defective immune system inflammation problem, and they’re all going to be preventable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;That’s what’s so exciting.&amp;nbsp;So we don’t have to have reverse aging. We can actually work on …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Just prevent aging in the first place.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;the age-related diseases. So basically, what it means is: I got to find out if you have a risk, if you’re in this high-risk group for this particular condition, because if you are—and we have many levels, layers, orthogonal ways to check—we don’t just bank it all on one polygenic test. We’re going to have several ways, say this is the one we are going …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we go into high surveillance, where, let’s say if it’s your brain, we do more p-Tau, if we need to do brain imaging—whatever it takes. And also, we do preventive treatments on top of the lifestyle [changes], that one of the problems we have today is a lot of people know generally, what are good lifestyle factors. Although, I go through a lot more than people generally acknowledge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But they don’t incorporate them because they don’t know that they’re at risk and they could change their … extend their health span and prevent that disease. So what I at least put out there, a blueprint, is how we can use AI, because it’s multimodal AI, with all these layers of data, and then temporally, it’s like today you could say if you have two protein tests, not only are you going to have Alzheimer’s, but within a two-year time frame &lt;em&gt;when&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;… and if you don’t change things, if we don’t gear up … you know, we can … we can completely prevent this, so … or at least defer it for a decade or more. So that’s why I’m excited, is that we made these strides in the science of aging. But we haven’t acknowledged the part that doesn’t require reversing aging. There’s this much less flashy, attainable, less risky approach …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;than the one that … when you reverse aging, you’re playing with the hallmarks of cancer. They are like, if you look at the hallmarks of cancer …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; That has been one of the primary challenges.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;They’re lined up.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; They’re all the same, you know, whether it’s telomeres, or whether it’s … you know … so this is the problem. I actually say in the book, I do think one of these—we have so many shots on goal—one of these reverse aging things will likely happen someday. But we’re nowhere close.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the other hand, let’s gear up. Let’s do what we can do. Because we have these new metrics that’s … people don’t … like, when I read the organ clock paper&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; from Tony Wyss-Coray from Stanford. It was published end of ’23; it was the cover of &lt;em&gt;Nature&lt;/em&gt;. It blew me away.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And I wrote a Substack&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; [article] on it. And Tony said, “Well, that’s so nice of you.” I said, “So nice? This is revolutionary, you know.” [LAUGHTER] So …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;By the way, what’s so interesting is, how these things, this kind of understanding and AI, are coming together.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;It’s almost eerie the timing of these things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Absolutely. Because you couldn’t take all these layers of data, just like we were talking about data hoarding.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Now we have data hoarding on individual with no way to be able to make these assessments of what level of risk, when, what are we going to do in &lt;em&gt;this&lt;/em&gt; individual to prevent that? We can do that now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We can do it today. And we could keep building on that. So I’m really excited about it. I think that, you know, when I wrote the last book on deep medicine, it was our overarching goal should be to bring back the patient-doctor relationship. I’m an old dog, and I know what it used to be when I got out of medical school.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s totally … you couldn’t imagine how much erosion from the ’70s, ’80s to now. But now I have a new overarching goal. I’m thinking that that still is really important—humanity in medicine—but let’s prevent these three … big three diseases because it’s an opportunity that we’re not … you know, in medicine, all my life we’ve been hearing and talking about we need to prevent diseases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Curing is much harder than prevention. And the economics. Oh my gosh. But we haven’t done it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Now we can do it. Primary prevention. We’d do really well. Somebody’s had heart attack.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Oh, we’re going to get all over it. Why did they have a heart attack in the first place?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, the thing that makes so much sense in what you’re saying is that we understand we have an understanding both economically and medically that prevention is a good thing. And extending the concept of prevention to these age-related conditions, I think, makes all the sense in the world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, Eric, maybe on that optimistic note, it’s time to wrap up this conversation. Really appreciate you coming. Let me just brag in closing that I’m now the proud owner of an autographed copy of your latest book, and, really, thank you for that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Oh, thank you. I could spend the rest of the day talking to you. I’ve really enjoyed it. Thanks.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; For me, the biggest takeaway from our conversation was Eric’s supremely optimistic predictions about what AI will allow us to do in much less than 10 years.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, for me personally, I started off several years ago with the typical techie naivete that if we could solve protein folding using machine learning, we would solve human biology. But as I’ve gotten smarter, I’ve realized that things are way, way more complicated than that, and so hearing Eric’s techno-optimism on this is really both heartening and so interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Another thing that really caught my attention are Eric’s views on AI in medical diagnosis. That really stood out to me because within our labs here at Microsoft Research, we have been doing a lot of work on this, for example in creating foundation models for whole-slide digital pathology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The bottom line, though, is that biomedical research and development is really changing and changing quickly. It’s something that we thought about and wrote briefly about in our book, but just hearing it from these three people gives me reason to believe that this is going to create tremendous benefits in the diagnosis and treatment of disease.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, I wonder now how regulators, such as the Food and Drug Administration here in the United States, will be able to keep up with what might become a really big increase in the number of animal and human studies that need to be approved. On this point, it’s clear that the FDA and other regulators will need to use AI to help process the likely rise in the pace of discovery and experimentation. And so stay tuned for more information about that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC] &lt;/p&gt;



&lt;p&gt;I’d like to thank Daphne, Noubar, and Eric again for their time and insights. And to our listeners, thank you for joining us. There are several episodes left in the series, including discussions on medical students’ experiences with AI and AI’s influence on the operation of health systems and public health departments. We hope you’ll continue to tune in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES] &lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated images of Peter Lee, Daphne Koller, Noubar Afeyan, and Dr. Eric Topol for the Microsoft Research Podcast" class="wp-image-1144053" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode8-PeterEricNoubarDaphne-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&lt;/p&gt;



&lt;p&gt;In this episode, Daphne Koller&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Noubar Afeyan&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Dr. Eric Topol&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, leaders in AI-driven medicine, join Lee to explore the rapidly evolving role of AI across the biomedical and healthcare landscape. Koller, founder and CEO of Insitro, shares how machine learning is transforming drug discovery, especially target identification for complex diseases like ALS, by uncovering biological patterns across massive datasets. Afeyan, founder and CEO of Flagship Pioneering and co-founder and chairman of Moderna, discusses how AI is being applied across biotech research and development, from protein design to autonomous science platforms. Topol, executive vice president of Scripps Research and founder and director of the Scripps Research Translational Institute, highlights how AI can &lt;em&gt;today&lt;/em&gt; help mitigate and prevent the core diseases that erode our health and the possibility of realizing a virtual cell. Through his conversations with the three, Lee investigates how AI is reshaping the discovery, deployment, and delivery of medicine.&amp;nbsp;&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;




&lt;/div&gt;







&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;[MUSIC]&lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“Can GPT-4 indeed accelerate the progression of medicine&lt;strong&gt; &lt;/strong&gt;… ? It seems like a tall order, but if I had been told six months ago that it could rapidly summarize any published paper, that alone would have satisfied me as a strong contribution to research productivity. … But now that I’ve seen what GPT-4 can do with the healthcare process, I expect a lot more in the realm of research.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee.&lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?&lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



&lt;p&gt;[THEME MUSIC FADES]&lt;/p&gt;



&lt;p&gt;The book passage I read at the top was from “Chapter 8: Smarter Science,” which was written by Zak.&lt;/p&gt;



&lt;p&gt;In writing the book, we were optimistic about AI’s potential to accelerate biomedical research and help get new and much-needed treatments and drugs to patients sooner. One area we explored was generative AI as a designer of clinical trials. We looked at generative AI’s adeptness at summarizing helping speed up pre-trial triage and research. We even went so far as to predict the arrival of a large language model that can serve as a central intellectual tool.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For a look at how AI is impacting biomedical research today, I’m excited to welcome Daphne Koller, Noubar Afeyan, and Eric Topol.&amp;nbsp;&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;Daphne Koller is the CEO and founder of Insitro, a machine learning-driven drug discovery and development company that recently made news for its identification of a novel drug target for ALS and its collaboration with Eli Lilly to license Lilly’s biochemical delivery systems. Prior to founding Insitro, Daphne was the co-founder, co-CEO, and president of the online education platform Coursera.&lt;/p&gt;



&lt;p&gt;Noubar Afeyan is the founder and CEO of Flagship Pioneering, which creates biotechnology companies focused on transforming human health and environmental sustainability. He is also co-founder and chairman of the messenger RNA company Moderna. An entrepreneur and biochemical engineer, Noubar has numerous patents to his name and has co-founded many startups in science and technology.&lt;/p&gt;



&lt;p&gt;Dr. Eric Topol is the executive vice president of the biomedical research non-profit Scripps Research, where he founded and now directs the Scripps Research Translational Institute. One of the most cited researchers in medicine, Eric has focused on promoting human health and individualized medicine through the use of genomic and digital data and AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;These three are likely to have an outsized influence on how drugs and new medical technologies soon will be developed.&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Here’s my interview with Daphne Koller:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Daphne, I’m just thrilled to have you join us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DAPHNE KOLLER: &lt;/strong&gt;Thank you for having me, Peter. It’s a pleasure to be here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, you know, you’re quite well-known across several fields. But maybe for some audience members of this podcast, they might not have encountered you before. So where I’d like to start is a question I’ve been asking all of our guests.&lt;/p&gt;



&lt;p&gt;How would you describe what you do? And the way I kind of put it is, you know, how do you explain to someone like your parents what you do for a living?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;So that answer obviously has shifted over the years.&lt;/p&gt;



&lt;p&gt;What I would say now is that we are working to leverage the incredible convergence of very powerful technologies, of which AI is one but not the only one, to change the way in which we discover and develop new treatments for diseases for which patients are currently suffering and even dying.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think I’ve known you for a long time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Longer than I think either of us care to admit.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] In fact, I think I remember you even when you were still a graduate student. But of course, I knew you best when you took up your professorship at Stanford. And I always, in my mind, think of you as a computer scientist and a machine learning person. And in fact, you really made a big name for yourself in computer science research in machine learning.&lt;/p&gt;



&lt;p&gt;But now you’re, you know, leading one of the most important biotech companies on the planet. How did that happen?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; So people often think that this is a recent transition. That is, after I left Coursera, I looked around and said, “Hmm. What should I do next? Oh, biotech seems like a good thing,” but that’s actually not the way it transpired.&lt;/p&gt;



&lt;p&gt;This goes all the way back to my early days at Stanford, where, in fact, I was, you know, as a young faculty member in machine learning, because I was the first machine learning hire into Stanford’s computer science department, I was looking for really exciting places in which this technology could be deployed, and applications back then, because of scarcity of data, were just not that inspiring.&lt;/p&gt;



&lt;p&gt;And so I looked around, and this was around the late ’90s, and realized that there was interesting data emerging in biology and medicine. My first application actually was in, interestingly, in epidemiology—patient tracking and tuberculosis. You know, you can think of it as a tiny microcosm of the very sophisticated models that COVID then enabled in a much later stage.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And so initially, this was based almost entirely on just technical interest. It’s kind of like, oh, this is more interesting as a question to tackle than spam filtering. But then I became interested in biology in its own right, biology and medicine, and ended up having a bifurcated existence as a Stanford professor where half my lab continued to do core computer science research published in, you know, NeurIPS and ICML. And the other half actually did biomedical research that was published in, you know, &lt;em&gt;Nature Cell [and] Science&lt;/em&gt;. So that was back in, you know, the early, early 2000s, and for most of my Stanford career, I continued to have both interests.&lt;/p&gt;



&lt;p&gt;And then the Coursera experience kind of took me out of Stanford and put me in an industry setting for the first time in my life actually.&lt;strong&gt; &lt;/strong&gt;But then when my time at Coursera came to an end, you know, I’d been there for five years. And if you look at the timeline, I left Stanford in early 2012, right as the machine learning revolution was starting. So I missed the beginning.&lt;/p&gt;



&lt;p&gt;And it was only in like 2016 or so that, as I picked my head up over the trenches, like, “Oh my goodness, this technology is going to change the world.” And I wanted to deploy that big thing towards places where it would have beneficial impact on the world, like to make the world a better place.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And so I decided that one of the areas where I could make a unique, differentiated impact was in really bringing AI and machine learning to the life sciences, having spent, you know, the majority of my career at the boundary of those two disciplines. And notice I say “boundary” with deliberation because there wasn’t very much of an intersection.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; I felt like I could do something that was unique.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So just to stick on you for a little bit longer, you know, we have been sort of getting into your origin story about what we call AI today—but machine learning, so deep learning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, you know, there has always been a kind of an emotional response for people like you and me and now the general public about their first encounters with what we now call generative AI. I’d love to hear what your first encounter was with generative AI and how you reacted to this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; I think my first encounter was actually an indirect one. Because, you know, the earlier generations of generative AI didn’t directly touch our work at Insitro&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And yet at the same time, I had always had an interest in computer vision. That was a large part of my non-bio work when I was at Stanford.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so some of my earlier even presentations, when I was trying to convey to people back in 2016 how this technology was going to transform the world, I was talking about the incredible progress in image recognition that had happened up until that point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my first interaction was actually in the generative AI for images, where you are able to go the other way …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;… where you can take a verbal description of an image and create—and this was back in the days when the images weren’t particularly photorealistic, but still a natural language description to an image was magic given that only two or three years before that, we were barely able to look at an image and write a short phrase saying, “This is a dog on the beach.” And so that arc, that hockey curve, was just mind blowing to me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Did you have moments of skepticism?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;Yeah, I mean the early, you know, early versions of ChatGPT, where it was more like parlor tricks and poking it a little bit revealed all of the easy ways that one could break it and make it do really stupid things. I was like, yeah, OK, this is kind of cute, but is it going to actually make a difference? Is it going to solve a problem that matters?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I mean, obviously, I think now everyone agrees that the answer is yes, although there are still people who are like, yeah, but maybe it’s around the edges. I’m not among them, by the way, but … yeah, so initially there were like, “Yeah, this is cute and very impressive, but is it going to make a difference to a problem that matters?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&lt;strong&gt; &lt;/strong&gt;So now, maybe this is a good time to get into what you’ve been doing with ALS [amyotrophic lateral sclerosis]. You know, there’s a knee-jerk reaction from the technology side to focus on designing small molecules, on predicting, you know, their properties, you know, maybe binding affinity or aspects of ADME [absorption, distribution, metabolism, and excretion], you know, like absorption or dispersion or whatever.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And all of that is very useful, but if I understand the work on ALS, you went to a much harder place, which is to actually identify and select targets.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; That’s right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So first off, just for the benefit of the standard listeners of this podcast, explain what that problem is in general.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; No, for sure. And I think maybe I’ll start by just very quickly talking about the drug discovery and development arc, …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … which, by and large, consists of three main phases. That’s the standard taxonomy.&amp;nbsp;The first is what’s called sometimes target discovery or identifying a therapeutic hypothesis, which looks like: if I modulate this target in this disease, something beneficial will happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Then, you have to take that target and turn it into a molecule that you can actually put into a person. It could be a small molecule. It could be a large molecule like an antibody, whatever. And then you have that construct, that molecule. And the last piece is you put it into a person in the context of a clinical trial, and you measure what has happened. And there’s been AI deployed towards each of those three stages in different ways.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The last one is mostly like an efficiency gain. You know, the trial is kind of already defined, and you want to deploy technology to make it more efficient and effective, which is great because those are expensive operations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The middle one is where I would say the vast majority of efforts so far has been deployed in AI because it is a nice, well-defined problem. It doesn’t mean it’s easy, but it’s one where you can define the problem. It is, &lt;em&gt;I need to inhibit this protein by this amount, and the molecule needs to be soluble and whatever and go past the blood-brain barrier&lt;/em&gt;. And you know probably within a year and a half or so, or two, if you succeeded or not.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The first stage is the one where I would say the least amount of energy has gone because when you’re uncovering a novel target in the context of an indication, you don’t know that you’ve been successful until you go &lt;em&gt;all the way&lt;/em&gt; to the end, which is the clinical trial, which is what makes this a long and risky journey. And not a lot of people have the appetite or the capital to actually do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, in my opinion, and that of, I think, quite a number of others, it is where the biggest impact can be made. And the reason is that while pharma has its deficiencies, making good molecules is actually something they’re pretty good at.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It might take them longer than it should, maybe it’s not as efficient as it could be, but at the end of the day, if you tell them to drug A target, pharma is actually pretty good at generating those molecules. However, when you put those molecules into the clinic, 90% of them fail. And the reason they fail is not by and large because the molecule wasn’t good. In the majority of cases, it’s because the target you went after didn’t do anything useful in the context of the patient population in which you put it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so in order to fix the inefficiency of this industry, which is &lt;em&gt;incredible&lt;/em&gt; inefficiency, you need to address the problem at the root, and the root is picking the right targets to go after. And so that is what we elected to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It doesn’t mean we don’t make molecules. I mean, of course, you can’t just end up with a target because a target is not actionable. You need to turn it into a molecule. And we absolutely do that. And by the way, the partnership with Lilly&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; is actually one where they help us make a molecule.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;I mean, it’s our target. It’s our program. But Lilly is deploying its very state-of-the-art molecule-making capabilities to help us turn that target into a drug.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So let’s get now into the machine learning of this. Again, this just strikes me as such a difficult problem to solve.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So how does machine learning … how does AI help you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; So I think when you look at how people currently select targets, it’s a combination of oftentimes at this point, with an increasing respect for the power of human genetics, some search for a genetic association, oftentimes with a human-defined, highly subjective, highly noisy clinical outcome, like some ICD [International Classification of Diseases] code.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And those are often underpowered and very difficult to deconvolute the underlying biology. You combine that with some mechanistic interrogation in a highly reductionist model system looking at a small number of readouts, biochemical readouts, that a biologist thinks are relevant to the disease. Like does this make this, whatever, cholesterol go up or amyloid beta go down? Or whatever. And then you take that as the second stage, and you pick, based on typically human intuition about, &lt;em&gt;Oh, this one looks good to me&lt;/em&gt;, and then you take that forward.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What we’re doing is an attempt to be as unbiased and holistic as possible. So, first of all, rather than rely on human-defined clinical endpoints, like this person has been diagnosed with diabetes or fatty liver, we try and measure as much as we can a holistic physiological state and then use machine learning to find structure, patterns &lt;em&gt;in&lt;/em&gt; that human physiological readouts, imaging readouts, and omics readouts from blood, from tissue, different kinds of imaging, and say, these are different vectors that this disease takes, this group of individuals, and here’s a different group of individuals that maybe from a diagnostical perspective are all called the same thing, but they are actually exhibiting a very different biology underlying it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that is something that doesn’t emerge when a human being takes a reductionist view to looking at this high-content data, and oftentimes, they don’t even look at it and produce an ICD code.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The same approach, actually even the same code base, is taken in the cellular data. So we don’t just say, “Well, the thing that matters is, you know, the total amount of lipid in the cell or whatever.” Rather, we say, “Let’s look at multiple readouts, multiple ways of looking at the cells, combine them using the power of machine learning.” And again, looking at imaging readouts where a human’s eyes just glaze over looking at even a few dozen cells, far less a few hundreds of millions of cells, and understand what are the different biological processes that are going on. What are the vectors that the disease might take you in this direction, in this group of cells, or in that direction?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then importantly, we take all of that information from the human side, from the cellular side, across these different readouts, and we combine them using an integrative approach that looks at the combined weight of evidence and says, these are the targets that I have the greatest amount of conviction about by looking across all of that information. Whereas we know, and we know this, I’m sure you’ve seen this analysis done for clinicians, a human being typically is able to keep three or four things in their head at the same time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; A really &lt;em&gt;good&lt;/em&gt; human being who’s really expert at what they do can maybe get to six to eight.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The machine learning has no problem doing a few hundred.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And so you put that together, and that allows you, to your earlier question, really select the targets around which you have the highest conviction. And then those are the ones that we then prioritize for interrogation in more expensive systems like mice and monkeys and then at the end of the day pick the small handful that one can afford to actually take into clinical trials.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So now, Insitro recently received $25 million in milestone payments from Bristol Myers Squibb&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; after discovering and selecting a novel drug target for ALS. Can you tell us a little bit more about that? &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; We are incredibly excited about the first novel target, and there is a couple of others just behind it in line that seem, you know, quite efficacious, as well, that truly seem to reverse, albeit in a cellular system, what we now understand to be ALS pathology across multiple different dimensions. There’s been obviously many attempts made to try and address ALS, which by the way, horrible, horrible disease, worse than most cancers. It kills you almost inevitably in three to five years in a particularly horrific way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what we have in our hands is a target that seems to revert a lot of the pathologies that are associated with the disease, which we now understand has to do with the mis-splicing of multiple proteins within the cell and creating defective versions of those proteins that are just not operational. And we are seeing reversion of many of those.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So can I tell you for sure it’ll work in a human? No, there’s many steps between now and then. But we couldn’t be more excited about the opportunity to provide what we hope will be a disease-modifying intervention for these patients who really desperately need something.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, it’s certainly been making waves in the biotech and biomedical world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So we’ll be really watching very closely.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, you know, I think just reflecting on, you know, what we missed and what we got right in our book, I think in our book, we did have the insight that there would be an ability to connect, say, genotypic and phenotypic data and, you know, just broadly the kinds of clinical measurements that get made on real patients and that these things could be brought together. And I think the work that you’re doing really illustrates that in a very, very sophisticated, very ambitious way.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the fact that this could be connected all the way down to the biology, to the biochemistry, I think we didn’t have any clue what would happen, at least not this quickly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Well, I think the …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And I realize, you’ve been at this for quite a few years, but still, it’s quite amazing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; The thread that connects them is human genetics. And I think that has, to us, been, sort of, the, kind of, the connective tissue that allows you to translate across different systems and say, “What does this gene do? What does this gene do in this organ and in that organ? What does it do in this type of cell and in that type of cell?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then use that as sort of the thread, if you will, that follows the impact of modulating this gene all the way from the simple systems where you can do the experiment to the complex systems where you can’t do the experiment until the very end, but you have the human genetics as a way of looking at the statistics and understanding what the impact might be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I’d like to now switch gears and take … I want to take two steps in the remainder of this conversation towards the future. So one step into that future, of course, we’re living through now, which is just all of the crazy pace of work and advancement in generative AI generally, you know, just the scale of transformers, of post-training, and now inference scale and reasoning models and so on. And where do you see all of that going with respect to the goals that you have and that Insitro has?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; So I think first and foremost is the parallel, if you will, to the predictions that you focused on in your book, which is this will transform a lot of the core data processing tasks, the information tasks. And sure, the doctors and nurses is one thing. But if you just think of clinical trial operations or the submission of regulatory documents, these are all kind of simple data … they’re not simple, obviously, but they’re data processing tasks. They involve natural language. That’s not going to be our focus, but I hope that others will use that to make clinical trials faster, more efficient, less expensive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s already a lot of progress that’s happening on the molecular design side of things and taking hypotheses and turning them quickly and effectively into molecules. As I said, this is part of our work that we absolutely do and we don’t talk about it very much, simply because it’s a very crowded landscape and a lot of companies are engaged on that. But I think it’s really important to be able to take biological insights and turn them into new molecules.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, of course, the transformer models and their likes play a very significant role in that sort of turning insights into molecules because you can have foundation models for proteins. There are increasing efforts to create foundation models for other categories of molecules. And so that will undoubtedly accelerate the process by which you can quickly generate different molecular hypotheses and test them and learn from what you did so that you can do fewer iterations …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … before you converge on a successful molecule.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I do think that arguably the biggest impact as yet to be had is in that understanding of core human biology and what are the right ways to intervene in it. And that plays a role in a couple different ways. First of all, it certainly plays a role in which … if we are able to understand the human physiological state and, you know, the state of different systems all the way down to the cell level, that will inform our ability to pick hypotheses that are more likely to actually impact the right biologies underneath.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And the more data we’re able to collect about humans and about cells, the more successful our models will be at representing that human physiological state or the cell biological state and making predictions reliably on the impact of these interventions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The other side of it, though, and this comes back, I think, to themes that were very much in your book, is this will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; And I think there’s been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the opportunity is still there. We just haven’t been able to bring it to life because of the lack of the right kind of data. And I think with the increasing amount of human, kind of, foundational data that we’re able to acquire, things that are not sort of distilled through the eye of a clinician, for example, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … but really measurements of human pathology, we can start to get to some of that precision, carving out of the human population and then get to a world where we can prescribe the right medicine to the right patient and not only in cancer but also in other diseases that are also not a single disease.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;All right, so now to wrap up this time together, I always try to ask one more provocative last question. One of the dreams that comes naturally to someone like me or any of my colleagues, probably even to you, is this idea of, you know, wouldn’t it be possible someday to have a foundation model for biology or for human biology or foundation model for the human cell or something along these lines?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, there are, of course, you and I are both aware of people who are taking that idea seriously and chasing after it. I have people in our labs that think hard about this kind of thing. Is it a reasonable thought at all?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; I have learned over the years to avoid saying the word &lt;em&gt;never&lt;/em&gt; because technology proceeds in ways that you often don’t expect. And so will we at some point be able to measure the cell in enough different ways across enough different channels at the same time that you can piece together what a cell does? I think that is eminently feasible, not today, but over time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I don’t think it’s feasible using today’s technology, although the efforts to get there may expose where the biggest opportunities lie to, you know, build that next layer. So I think it’s good that people are working on really hard problems. I would also point out that even if one were to solve that really challenging problem of creating a model of &lt;em&gt;a cell&lt;/em&gt;, there is thousands of different types of cells within the human body.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;They’re very different. They also talk to each other …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … both within the cell type and across different cell types. So the combinatorial complexity of that system is, I think, unfathomable to many people. I mean, I would say to all of us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER: &lt;/strong&gt;And so even from that very lofty goal, there is multiple big steps that would need to be taken to a &lt;em&gt;mechanistic&lt;/em&gt; model of the full organism. So will we ever get there? Again, you know, I don’t see a reason why this is impossible to do. So I think over time, technology will get better and will allow us to build more and more elaborate models of more and more complex systems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Patients can’t wait …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; … for that to happen in order for us to get them better medicines. So I think there is a great basic science initiative on that side of things. And, in parallel, we need to make do with the data that we have or can collect or can print. We print a lot of data in our internal wet labs and get to drugs that are effective even though they don’t benefit from having a full-blown mechanistic model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Last question: where do you think we’ll be in five years?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Phew. If I had answered that question five years ago, I would have been very badly embarrassed at the inaccuracy of my answer. [LAUGHTER] So I will not answer it today either.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I will say that the thing about exponential curves is that they are very, very tricky, and they move in unexpected ways. I would hope that in five years, we will have made a sufficient investment in the generation of scientific data that we will be able to move beyond data that was generated entirely by humans and therefore insights that are derivative of what people already know to things that are truly novel discoveries.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think in order to do that in, you know, math, maybe because math is entirely conceptual, maybe you can do that today. Math is effectively a construct of the human mind. I don’t think biology is a construct of the human mind, and therefore one needs to collect enough data to really build those models that will give rise to those novel insights.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s where I hope we will have made considerable progress in five years.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, I’m with you. I hope so, too. Well, you know, thank you, Daphne, so much for this conversation. I learn a lot talking to you, and it was great to, you know, connect again on this. And congratulations on all of this success. It’s really groundbreaking.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOLLER:&lt;/strong&gt; Thank you very much, Peter. It was a pleasure chatting with you, as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I still think of Daphne first and foremost as an AI researcher. And for sure, her research work in machine learning continues to be incredibly influential to this day. But it’s her work on AI-enhanced drug development that now is on the verge of making a really big difference on some of the most difficult diseases afflicting people today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our book, Carey, Zak, and I predicted that AI might be a meaningful accelerant in biomedical research, but I don’t know that we foresaw the incredible potential specifically in drug development.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Today, we’re seeing a flurry of activity at companies, universities, and startups on generative AI systems that aid and maybe even completely automate the design of new molecules as drug candidates. But now, in our conversation with Daphne, seeing AI go even further than that to do what one might reasonably have assumed to be impossible, to identify and select novel drug targets, especially for a neurodegenerative disease like ALS, it’s just, well, mind blowing. &lt;/p&gt;



&lt;p&gt;Let’s continue our deep dive on AI and biomedical research with this conversation with Noubar Afeyan:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Noubar, thanks so much for joining. I’m really looking forward to this conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;NOUBAR AFEYAN: &lt;/strong&gt;Peter, thanks. Thrilled to be here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; While I think most of the listeners to this podcast have heard of Flagship Pioneering&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, it’s still worth hearing from you, you know, what is Flagship? And maybe a little bit about your background. And finally, you found a way to balance science and business creation. And so, you know, your approach and philosophy to all of that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;Well, great. So maybe I’ll just start out by way of quick background. You know, my … and since we’re going talk about AI, I’ll also highlight my first contact with the topic of AI. So as an undergraduate in 1980 up at McGill University, I was an engineering student, but I was really captivated by, at that time, the talk on the campus around the expert system, heuristic-based, rule-based kind of programs.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; And so actually I had the dubious distinction of writing my one and only college newspaper article. [LAUGHTER] That was a short career. And it was all about how artificial intelligence would be impacting medicine, would be impacting, you know, speech capture, translation, and some of the ideas that were there that it’s interesting to see now 45 years later re-emerge with some of the new learning-based models.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My journey after college ended up taking me into biotechnology. In the early ’80s, I came to MIT to do a PhD. At the time, the field was brand new. I ended up being the first PhD graduate from MIT in this combination biology and engineering degree. And since then, I’ve basically been—so since 1987—a founder, a technologist in the space of biotechnology for human health and as well for planetary health.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then in 1999/2000 formed what is now Flagship Pioneering, which essentially was an attempt to bring together the three elements of what we know are important in startups. That is scientific capital, human capital, and financial capital. Right now, startups get that from different places. The science in our fields mostly come from academia, research hospitals. The human capital comes from other startups …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … or large companies or some academics leave. And then the financial capital is usually venture capital, but there’s also now more and more other deeper pockets of money.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What we thought was, what if all that existed in one entity and instead of having to convince each other how much they should believe the other if we just said, “Let’s use that power to go work on much further out things”? But in a way where nobody would believe it in the beginning, but we could give ourselves a little bit of time to do impactful big things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Twenty-five years later, that’s the road we’ve stayed on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; OK. So let’s get into AI. Now, you know, what I’ve been asking guests is kind of an origin story. And there’s the origin story of contact with AI, you know, before the emergence of generative AI and afterwards. I don’t think there’s much of a point to asking you the pre-ChatGPT. But … so let’s focus on your first encounter with ChatGPT or generative AI. When did that happen, and what went through your head?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Yeah. So, if you permit me, Peter, just for very briefly, let me actually say I had the interesting opportunity over the last 25 years to actually stay pretty close to the machine learning world …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … because one, as you well know, among the most prolific users of machine learning has been the bioinformatics computational biology world because it’s been so data rich that anything that can be done, people have thrown at these problems because unlike most other things, we’re not working on man-made data. We’re looking at data that comes from nature, the complexity of which far exceeds our ability to comprehend.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So you could imagine that any approach to statistically reduce complexity, get signal out of scant data—that’s a problem that’s been around.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The other place where I’ve been exposed to this, which I’m going to come back to because that’s where it first felt totally different to me, is that some 25 years ago, actually the very first company we started was a company that attempted to use evolutionary algorithms to essentially iteratively evolve consumer-packaged goods online. Literally, we tried to, you know, consider features of products as genes and create little genomes of them. And by recombination and mutation, we could create variety. And then we could get people through panels online—this was 2002/2003 timeframe—we could essentially get people through iterative cycles of voting to create a survival of the fittest. And that’s a company that was called Affinnova.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The reason I say that is that I knew that there’s a much better way to do this if only: one, you can generate variety …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … without having to prespecify genes. We couldn’t do that before. And, two, which we’ve come back to nowadays, you can actually mimic how humans think about voting on things and just get rid of that element of it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So then to your question of when does this kind of begin to feel different? So you could imagine that in biotechnology, you know, as an engineer by background, I always wanted to do CAD, and I picked the one field in which CAD doesn’t exist, which is biology. Computer-aided design is kind of a notional thing in that space. But boy, have we tried. For a long time, …&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … people would try to do, you know, hidden Markov models of genomes to try to figure out what &lt;em&gt;should&lt;/em&gt; be the next, you know, base that you may want to or where genes might be, etc. But the notion of generating in biology has been something we’ve tried for a while. And in the late teens, so kind of 2018, ’17, ’18, because we saw deep learning come along, and you could basically generate novelty with some of the deep learning models … and so we started asking, “Could you generate a protein basically by training a correspondence table, if you will, between protein structures and their underlying DNA sequence?” Not their protein sequence, but their DNA sequence.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So that’s a big leap. So ’17/’18, we started this thing. It was called 56. It was FL56, Flagship Labs 56, our 56th project.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, we started this parallel one called “57” that did it in a very different way. So one of them did pure black box model-building. The other one said, you know what, we don’t want to do the kind of … at that time, AlphaFold was in its very early embodiments. And we said, “Is there a way we could actually take little, you know, multi amino acid kind of almost grammars, if you will, a little piece, and then see if we could compose a protein that way?” So we were experimenting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And what we found was that actually, if you show enough instances and you could train a transformer model—back in the day, that’s what we were using—you could actually, say, predict another sequence that should have the same activity as the first one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;So we trained on green fluorescent proteins. Now, we’re talking about seven years ago. We trained on enzymes, and then we got to antibodies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;With antibodies, we started seeing that, boy, this could be a pretty big deal because it has big market impact. And we started bringing in some of the diffusion models that were beginning to come along at that time. And so we started getting much more excited. This was all done in a company that subsequently got renamed from FL56 to Generate:Biomedicines&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep, yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;… which is one of the leaders in protein design using the generative techniques. It was interesting because Generate:Biomedicines is a company that was called that before generative AI was a thing, [LAUGHTER] which was kind of very ironic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, of course, that team, which operates today very, very kind of at the cutting edge, has published their models. They came up with this first Chroma&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; model, which is a diffusion-based model, and then started incorporating a lot of the LLM capabilities and fusing them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now we’re doing atomistic models and many other things. The point being, that gave us a glimpse of how quickly the capability was gaining, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … just like evolution shows you. Sometimes evolution is super silent, and then all of a sudden, all hell breaks loose. And that’s what we saw.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. One of the things that I reflect on just in my own journey through this is there are other emotions that come up. One that was prominent for me early on was skepticism. Were there points when even in your own work, transformer-based work on this early on, that you had doubts or skepticism that these transformer architectures would be or diffusion-based approaches would be worth anything?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; You know, it’s interesting, I think that, I’m going to say this to you in a kind of a friendly way, but you’ll understand what I mean. In the world I live in, it’s kind of like the slums of innovation, [LAUGHTER] kind of like just doing things that are not supposed to work. The notion of skepticism is a luxury, right. I assume everything we do won’t work. And then once in a while I’m wrong.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I don’t actually try to evaluate whether before I bring something in, like just think about it. We, some hundred or so times a year, ask “what if” questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that’s testable. Then we go into a lab, and we test it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in that world, right, sitting there going, like, “How do I know this transformer is going to work?” The answer is, “For what?” Like, it’s going to work. To make something up … well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s just such a different use that, of course, I have trained scientific skepticism, but it’s a little bit like looking at a competitive situation in an ecology and saying, “I bet that thing’s going to die.” Well, you’d be right—most of the time, you’d be right. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I just don’t … like, it … and that’s why—I guess, call me an early adopter—for us, things that could move the needle even a little, but then upon repetition a lot, let alone this, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … you have to embrace. You can’t wait there and say, I’ll embrace it once it’s ready. And so that’s what we did.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Hmm. All right. So let’s get into some specifics and what you are seeing either in your portfolio companies or in the research projects or out in the industry. What is going on today with respect to AI really being used for something meaningful in the design and development of drugs?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; In companies that are doing as diverse things as—let me give you a few examples—a project that’s now become a named company called ProFound Therapeutics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that literally discovered three, four years ago, and would not have been able to without some of the big data-model-building capabilities, that our cells make literally thousands, if not tens of thousands, of more proteins than we were aware of, full stop.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We had done the human genome sequence, there was 20,000 genes, we thought that there was …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … maybe 70-80,000, 100,000 proteins, and that’s that. And it turns out that our cells have a penchant to express themselves in the form of proteins, and they have many other ways than we knew to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, so what does that mean? That means that we have generated a massive amount of data, the interpretation of which, the use of which to guide what you do and what these things might be involved with is purely being done using the most cutting-edge data-trained models that allow you to navigate such complexity.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Wow. Hmm.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; That’s just one example. Another example: a company called Quotient Therapeutics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, again three, four years old. I can talk about the ones that are three, four years old because we’ve kind of gotten to a place where we’ve decided that it’s not going to fail &lt;em&gt;yet&lt;/em&gt;, [LAUGHTER] so we can talk about it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, we discovered—our team discovered—that in our cells, right, so we know that when we get cancer, our cells have genetic mutations in them or DNA mutations that are correlated and often causal to the hyperproliferative stages of cancer. But what we assume is that all the other cells in our body, pretty much, have one copy of their genes from our mom, one copy from our dad, and that’s that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And when very precise deep sequencing came along, we always asked the question, “How much variation is there cell to cell?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; And the answer was it’s kind of noise, random variation. Well, our team said, “Well, what if it’s not really that random?” because upon cell division cycles, there’s selection happening on these cells. And so not just in cancer but in liver cells, in muscle cells, in skin cells …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Oh, interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … can you imagine that there’s an evolutionary experiment that is favoring either compensatory mutations that are helping you avoid disease or disease-caused mutations that are gaining advantage as a way to understand the mechanism? Sure enough—I wouldn’t be telling you otherwise—with &lt;em&gt;massive&lt;/em&gt; amount of single cell sequencing from individual patient samples, we’ve now discovered that the human genome is mutated on average in our bodies 10,000 times, like over every base, like, it’s huge numbers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And we’re finding very interesting big signals come out of this massive amount of data. By the way, data of the sort that the human mind, if it tries to assign causal explanations to what’s happening …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … is completely inadequate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; When you think about a language model, we’re learning from human language, and the totality of human language—at least relative to what we’re able to compute today in terms of constructing a model—the totality of human language is actually pretty limited. And in fact, you know, as is always written about in click-baity titles, you know, the big model builders are actually starting to run short.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Running out, running out, yes. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; But one of the things that perplexes me and maybe even worries me—like these two examples—are generally in the realm of cellular biology and the complexity. Let’s just take the example of your company, ProFound. You know, the complexity of what’s going on and the potential genetic diversity is such that, can we ever have enough data? You know, because there just aren’t that many human beings. There just aren’t that many samples.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;Well, it depends on what you want to train, right. So if you want to train a &lt;em&gt;de novo&lt;/em&gt; evolutionary model that could take you from bacteria to human mammalian cells and the like, there may not be—and I’m not an expert in that—but that’s a question that we often kind of think about.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you’re trying to train a … like you know what the proteins we know about, how they interact with pathways and disease mechanisms and the like. Now all of a sudden you find out that there’s a whole continent of them missing in your explanations. But there are things you can reason, in quotations, through analogy, functional analogy, sequence analogy, homology. So there’s a lot of things that we could do to essentially make use of this, even though you may not have the totality of data needed to, kind of, predict, based on a de novo sequence, exactly what it’s going to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I agree with the comparison. But … but you’re right. The complexity is … just keep in mind, on average, a protein may be interacting with 50 to 100 other proteins.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So if you find thousands of proteins, you’ve found a massive interaction space through which information is being processed in a living cell.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;But do you find in your AI companies that access to data ends up being a key challenge? Or, you know, how central is that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Access to data is a key challenge for the companies we have that are trying to build just models. But that’s the minority of things we do. The majority of things we do is to actually co-develop the data and the models. And as you know well, because you guys, you know, have given us some ideas around this space, that, you know, you could generate data and &lt;em&gt;then&lt;/em&gt; think about what you’re to do with it, which is the way biotech is operated with bioinformatics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Or you could generate bespoke data that is used to train the model that’s quite separate from what you would have done in the natural course of biology. So we’re doing much more of the latter of late, and I think that’ll continue. So, but these things are proliferating.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean,&lt;strong&gt; &lt;/strong&gt;it’s hard to find a place where we’re not using this.&lt;strong&gt; &lt;/strong&gt;And the “this” is any and all data-driven model building, generative, LLM-based, but also every other technique to make progress.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Sure.&lt;strong&gt; &lt;/strong&gt;So now moving away from the straight biochemistry applications, what about AI in the process of building a business, of making investment decisions, of actually running an operation? What are you seeing there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So, well, you know, Moderna, which is a company that I’m quite proud of being a founder and chairman of, has adopted a significant, significant amount of AI embedded into their operations in all aspects: from the manufacturing, quality control, the clinical monitoring, the design—every aspect. And in fact, they’ve had a partnership that they’ve had for a little while here with OpenAI, and they’ve tried many different ways to stay at the cutting edge of that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So we see that play out at some scale. That’s a 5,000-, 6,000-person organization, and what they’re doing is a good example of what early adopters would do, at least in our kind of biotechnology company.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then, you know, in our space, I would say the efficiency impact is kind of no different, than, you know, anywhere else in academia you might adopt it or in other kinds of companies. But where I find it an interesting kind of maybe segue is the degree to which&lt;strong&gt; &lt;/strong&gt;it may fundamentally change the way we think about how to do science, which is a whole other use, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So it’s not an efficiency gain &lt;em&gt;per se&lt;/em&gt;, although it’s maybe an effectiveness gain when it comes to science, but can you just fundamentally train models to generate hypotheses?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN: &lt;/strong&gt;And we have done that, and we’ve been doing this for the last three years. And now it’s getting better and better, the better these reasoning engines are getting and kind of being able to extrapolate and train for novelty. Can you convert that to the world’s best experimental protocol to very precisely falsify your hypothesis, on and on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That closing of that loop, kind of what we call &lt;em&gt;autonomous science&lt;/em&gt;, which we’ve been trying to do for the last two, three years and are making some progress in, that to me is another kind of bespoke use of these things, not to generate molecules in its chemistry, but to change the behavior of how science is done.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&lt;strong&gt; &lt;/strong&gt;So I always end with a couple of provocative questions, but I need—before we do that, while we’re on this subject—to get your take on Lila Sciences&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And there is a vision there that I think is very interesting. It’d be great to hear it described by you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Sure. So Lila, after operating for two to three years in kind of a preparatory kind of stealth mode, we’ve now had a little bit more visibility around, and essentially what we’re trying to do there is to create what we call automated science factories, and such a factory would essentially be able to take problems, either computationally specified or human-specified, and essentially do the experimental work in order to either make an optimization happen or enable something that just didn’t exist. And it’s really, at this point, we’ve shown proof of concept in narrow areas.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; But it’s hard to say that if you can do this, you can’t do some other things, so we’re just expanding it that way. We don’t think we need a complete proof or complete demonstration of it for every aspect.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So we’re just kind of being opportunistic. The idea for Lila is to partner with a number of companies. The good news is, within Flagship, there’s 48 of them. And so there’s a whole lot of them they can partner with to get their learning cycles. But eventually they want to be a real alternative to every time somebody has an idea, having to kind of go into a lab and manually do this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I do want to say one thing we touched on, Peter, though, just on that front, which is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … if you say, like, “What problem is this going to solve?” It’s several but an important one is just the flat-out human capacity to reason on this much data and this much complexity that is real. Because nature doesn’t try to abstract itself in a human understandable form.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; In biology, since it’s kind of like progress happens through evolutionary kind of selections, the evidence of which [has] long been lost, and so therefore, you just see what you have, and then it has a behavior. I really do think that there’s something to be said, and I want to—just for your audience—lay out a provocative, at least, thought on all this, which Lila is a beginning embodiment of, which is that I really think that what’s going to happen over the next five, 10 years, even while we’re all fascinated with the impending arrival of AGI [artificial general intelligence] is really what I call &lt;em&gt;poly-intelligence&lt;/em&gt;, which is the combination of human intelligence, machine intelligence, AI, and nature’s intelligence.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’re all fascinated at the human-machine interface. We know the human-nature interface, but imagine the machine-nature interface—that is, actually letting loose a digital kind of information processing life form through the algorithms that are being developed and the commensurately complex, maybe much more complex. We’ll see. And so now the question becomes, what does the human do?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And we’re living in a world which is human dominated, which means the humans say, “If I don’t understand it, it’s not real, basically. And if I don’t understand it, I can’t regulate it.” And we’re going to have to make peace with the fact that we’re not going to be able to predictably affect things without necessarily understanding them the way we could if we just forced ourselves to only work on problems we can understand. And that world we’re not ready for at all.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. All right. So this one I predict is going to be a little harder for you because I think while you think about the future, you live very much in the present. But I’d like you to make some predictions about what the biotech and biopharmaceutical industries are going to be able to do two years from now, five years from now, 10 years from now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Yeah, well, it’s hard for me because you know my nature, which is that I think this is all emergent.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; And so I would be the conceit of predicting. So I would say with likelihood positive predictive value of less than 10%, I’m happy to answer your question. So I’m not trying to score high [LAUGHTER] because I really think that my job is to envision it, not to predict it. And that’s a little bit different, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I actually was trying to pick what would be the hardest possible question I could ask you, [LAUGHTER] and this is what I came up with.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Yeah, no, no, I’m kidding here. So now look, I think that we will cross this threshold of understandability. And of course you’re seeing that in a lot of LLM things today. And of course, people are trying to train for things that are explainers and all that whole, there’s a whole world of that. But I think at some point we’re going to have to kind of let go and get comfortable working on things that, you know …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I sometimes tell people, you know, and I’m not the first, but scientists and engineers are different, it’s said, in that engineers work on things that they don’t wait until they get a full understanding of before they work with them. Well, now scientists are going to have to get used to that, too, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Because insisting that it’s only valid if it’s understandable. So, I would say, look, I hope that the time … for example, I think major improvements will be made in patient selection. If we can test drugs on patients that are more synchronized as to the stage of their disease …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; … I think the answer will be much better. We’re working on that. It’s a company called Etiome&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, very, very early stage. It’s really beautiful data, very early data that shows that when we talk about MASH [metabolic dysfunction-associated steatohepatitis], liver disease, when we talk about Parkinson’s, there’s such a heterogeneity, not only of the subset type of the disease, but the stage of the disease, that this notion that you have stage one cancer, stage two cancer, again, nobody told nature there’s stages of that kind. It’s a continuum.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you can synchronize based on training, kind of, the ability to detect who are the patients that are in enough of a close proximity that should be treated so that the trial—much smaller a trial size—could give you a drug, then afterwards, you can prescribe it using these approaches.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Kind of we’re going to find that what we thought is one disease is more like 15 diseases. That’s bad news because we’re not going to be able to claim that we can treat everything which we can. It’s good news in that there’s going to be people who are going to start making much more specific solutions to things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; So I can imagine that. I can imagine a generation of, kind of, students who are going to be able to play in this space without having 25 years of graduate education on the subject. So what is deemed knowledge sufficient to do creative things will change. I can go on and on, but I think all this is very close by and it’s very exciting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Noubar, I just always have so much fun, and I learn really a lot. It’s high-density learning when I talk to you. And so I hope our listeners feel the same way. It’s something I really appreciate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFEYAN:&lt;/strong&gt; Well, Peter, thanks for this. And I think your listeners know that if I was asking you questions, you would be answering them with equal if not more fascinating stuff. So, thanks for giving me the chance to do that today.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;I’m always fascinated by Noubar’s perspectives on fundamental research and how it connects to human health and the building of successful companies. I see him as a classic “systems thinker,” and by that, I mean he builds impressive things like Flagship Pioneering itself, which he created as a kind of biomedical innovation system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our conversation, I was really struck by the fact that he’s been thinking about the potential impact of transformers—transformers being the fundamental building block of large language models—as far back as 2017, when the first paper on the attention mechanism in transformers was published by Google.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But, you know, it isn’t only about using AI to do things like understand and design molecules and antibodies faster. It’s interesting that he is also pushing really hard towards a future where AI might “close the loop” from hypothesis generation, to experiment design, to analysis, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, here’s my conversation with Dr. Eric Topol:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Eric, it’s really great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ERIC TOPOL: &lt;/strong&gt;Oh, Peter, I’m thrilled to be here with you here at Microsoft.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You’re a super famous person. Extremely well known to researchers even in computer science, as we have here at Microsoft Research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the question I’d like to ask is, how would you explain to your parents what you do every day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; [LAUGHS] That’s a good question. If I was just telling them I’m trying to come up with better ways to keep people healthy, that probably would be the easiest way to do it because if I ever got in deeper, I would lose them real quickly. They’re not around, but just thinking about what they could understand.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I think as long as they knew it was work centered on innovative paths to promoting and preserving human health, that would get to them, I think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; OK, so now, kind of the second topic, and then we let the conversation flow, is about origin stories with respect to AI. And with most of our guests, you know, I factor that into two pieces: the encounters with AI before ChatGPT and what we call generative AI and then the first contacts after.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, of course, you have extensive contact with both now. But let’s start with how you got interested in machine learning and AI prior to ChatGPT. How did that happen?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yeah, it was out of necessity. So back, you know, when I started at Scripps at the end of ’06, we started accumulating, you know, massive datasets. First, it was whole genomes. We did one of the early big cohorts of 1,400 people of healthy aging. We called the Wellderly whole genome sequence&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we started big in the sensor world, and then we started saying, what are we going to do with all this data, with electronic health records and all those sensors? And now we got whole genomes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And basically, what we were doing, we were in hoarding mode. We didn’t have a way to meaningfully analyze it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;You would read about how, you know, data is the new oil and, you know, gold and whatnot. But we just didn’t have a way to extract the juice. And even when we wanted to analyze genomes, it was incredibly laborious.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And we weren’t extracting a lot of the important information. So that’s why … not having any training in computer science, when I was doing the … about three years of work to do the book &lt;em&gt;Deep Medicine&lt;/em&gt;, I started really, first auto-didactic about, you know, machine learning. And then I started contacting a lot of the real top people in the field and hanging out with them, and learning from them, getting their views as to, you know, where we are today, what models are coming in the future.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then I said, “You know what? We are going to be able to fix this mess.” [LAUGHS] We’re going to get out of the hoarding phase, and we’re going to get into, you know, really making a difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that’s when I embraced the future of AI. And I knew, you know, back—that was six years ago when it was published and probably eight or nine years ago when I was doing the research, and I knew that we weren’t there yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, at the time, we were seeing the image interpretation. That was kind of the early promise. But really, the models that were transformative, the transformer models, they were incubating back in 2017. So people knew something was brewing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And everyone said we’re going to get there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So then, ChatGPT comes out November of 2022; there’s GPT-4 in 2023, and now a lot has happened. Do you remember what your first encounter with that technology was?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Oh, sure. First, ChatGPT. You know, in the last days of November ’22, I was just blown away. I mean, I’m having a conversation. I’m having fun. And this is humanoid responding to me. I said, “&lt;em&gt;What?&lt;/em&gt;” You know? So that was to me, a moment I’ll never forget. And so I knew that the world was, you know, at a very kind of momentous changing point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Of course, knowing, too, that this is going to be built on, and built on quickly. Of course, I didn’t know how soon GPT-4 and all the others were going to come forward, but that was a wake-up call that the capabilities of AI had just made a humongous jump, which seemingly was all of a sudden, although I did know this had been percolating …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … you know, for what, at least five years, that, you know, it really was getting into its position to do this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I know one of the things that was challenging psychologically and emotionally for me is, it made me rethink a lot of things that were going on in Microsoft Research in areas like causal reasoning, natural language processing, speech processing, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m imagining you must have had some emotional struggles too because you have this amazing book, &lt;em&gt;Deep Medicine&lt;/em&gt;. Did you have to … did it go through your mind to rethink what you wrote in &lt;em&gt;Deep Medicine &lt;/em&gt;in light of this or, or, you know, how did that feel?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;It’s funny you ask that because in this one chapter I have on the virtual health coach, I wrote a whole bunch of scenarios …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … that were very kind of futuristic. You know, about how the AI interacts with the person’s health and schedules their appointment for this and their scan and tells them what lab tests they should tell their doctor to have, and, you know, all these things. And I sent a whole bunch of these, thinking that they were a little too far-fetched.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And I sent them to my editor when I wrote the book, and he says, “Oh, these are great. You should put them all in.” [LAUGHTER] What I didn’t realize is they weren’t that, you know, they were all going to happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. They weren’t that far-fetched at all.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Not at all. If there’s one thing I’ve learned from all this, is our imagination isn’t big enough.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&amp;nbsp;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; We think too small.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Now in our book that Carey, Zak, and I wrote, you know, we made, you know, we sort of guessed that GPT-4 might help biomedical researchers, but I don’t think that any of us had the thought in mind that the architecture around generative AI would be so directly applicable to, you know, say, protein structures or, you know, to clinical health records and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so a lot of that seems much more obvious today. But two years ago, it wasn’t. But we did guess that biomedical researchers would find this interesting and be helped along.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So as you reflect over the past two years, you know, do you have things that you think are very important, kind of, meaningful applications of generative AI in the kinds of research that Scripps does?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL&lt;/strong&gt;: Yeah. I mean, I think for one, you pointed out how the term &lt;em&gt;generative AI&lt;/em&gt; is a misnomer.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And so it really was prescient about how, you know, it had a pluripotent capability in every respect, you know, of editing and creating. So that was something that I think was telling us, an indicator that this is, you know, a lot bigger than how it’s being labeled. And our expectations can actually be more than what we had seen previously with the earlier version.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think what’s happened is that now, we keep jumping. It’s so quick that we can’t … you know, first we think, oh, well, we’ve gone into the agentic era, and then we could pass that with reasoning. [LAUGHTER] And, you know, we just can’t …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; It’s just wild.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So I think so many of us now will put in prompts that will necessitate or ideally result in a not-immediate gratification, but rather one that requires, you know, quite a bit of combing through the corpus of knowledge …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … and getting, with all the citations, a report or a response. And I think now this has been a reset because to do that on our own, it takes, you know, many, many hours. And it’s usually incomplete.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But one of the things that was so different in the beginning was you would get the references from up to a year and a half previously.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And that’s not good enough. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And now you get references, like, from the day before.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And so, you say, “Why would you do a regular search for anything when you could do something like this?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And then, you know, the reasoning power. And a lot of people who are not using this enough still are talking about, “Well, there’s no reasoning.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Which you dealt with really well in the book. But what, of course, you couldn’t have predicted is the new dimensions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I think you nailed it with GPT-4. But it’s all these just, kind of, stepwise progressions that have been occurring because of the velocity that’s unprecedented. I just can’t believe it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;We were aware of the idea of multi-modality, but we didn’t appreciate, you know, what that would mean. Like AlphaFold&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; [protein structure database], you know, the ability for AI to understand—or crystal structures—to really start understanding something more fundamental about biochemistry or medicinal chemistry.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I have to admit, when we wrote the book, we really had no idea.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Well, I feel the same way. I still today can’t get over it because the reason AlphaFold and Demis [Hassabis] and John Jumper [AlphaFold’s co-creators] were so successful is there was this protein databank.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And it had been kept for decades. And so, they had the substrate to work with.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So, you say, “OK, we can do proteins.” But then how do you do everything else?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And so this whole, what I call, “large language of &lt;em&gt;life&lt;/em&gt; model” work, which has gone into high gear like I’ve never seen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; You know, now to this holy grail of a virtual cell, and …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; You know, it’s basically … it’s … it was inspired by proteins. But now it’s hitting on, you know, ligands and small molecules, cells. I mean, nothing is being held back here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So how could anybody have predicted that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I sure wouldn’t have thought it would be possible at this point.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. So just to challenge you, where do you think that is going to be two years from now? Five years from now? Ten years from now? Like, so you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; No, I think within 10 years for sure. You know the group that got assembled that Steve Quake&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; pulled together?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; I think has 42 authors in a paper&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; in &lt;em&gt;Cell&lt;/em&gt;. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … that not only is this a worthy goal, but it’s actually going to be realized, that was impressive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I challenged him about that. How did you get these people all to agree? So many of them were naysayers. And by the time the workshop finished, they were fully convinced. I think that what we’re seeing is so much progress happening so quickly. And then all the different models, you know, across DNA, RNA, and everything are just zooming forward.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And it’s just a matter of pulling this together. Now when we have that, and I think it could easily be well before a decade and possibly, you know, between the five- and 10-year mark—that’s just a guess—but then we’re moving into another era of life science because right now, you know, this whole buzz about drug discovery.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;It’s not… with the ability to do all these perturbations at a cellular level.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Or the cell of interest.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Or the cell-to-cell interactions or the intra-cell interaction. So once you nail that, yeah, it takes it to a kind of another predictive level that we haven’t really fathomed. So, yes, there’s going to be drug discovery that’s accelerated. But this would make that and also the underpinnings of diseases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So the idea that there’s so many diseases we don’t understand now. And if you had virtual cell, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … you would probably get to that answer …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … much more quickly. So whether it’s underpinnings of diseases or what it’s going to take to really come up with far better treatments—preventions—I think that’s where virtual cell will get us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; There’s a technical question … I wonder if you have an opinion. You may or may not. There is sort of what I would refer to as &lt;em&gt;ab initio&lt;/em&gt; approaches to this. You know, you start from the fundamental physics and chemistry, and we know the laws, we have the math and, you know, we can try to derive from there … in fact, we can even run simulations of that math to generate training data to build generative models and work up to a cell, &lt;em&gt;or&lt;/em&gt; forget all of that and just take as many observations and measurements of, say, living cells as possible, and just have faith that hidden amongst all of the observational data, there is structure and language that can be derived.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So that’s sort of bottom-up versus top-down approaches. Do you have an opinion about which way?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Oh, I think you go after both. And clearly whenever you’re positing that you’ve got a virtual cell model that’s working, you’ve got to do the traditional methods as well to validate it, and … so all that. You know, I think if you’re going to go out after this seriously, you have to pull out all the stops. Both approaches, I think, are going to be essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, if what you’re saying is true, and it is amazing to hear the confidence, the one thing I tried to explain to someone nontechnical is that for a lot of problems in medicine, we just don’t have enough data in a really profound way. And the most profound way to say that is, since Adam and Eve, there have only been an estimated 106 billion people who have ever lived.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So even if we had the DNA of every human being, every individual of &lt;em&gt;Homo sapiens&lt;/em&gt;, there are certain problems for which we would not have enough data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Sure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;And so I think another thing that seems profound to me, if we can actually have a virtual cell, is we can actually make trillions of virtual …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Yeah&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; … human beings. The true genetic diversity could be realized for our species.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;I think you nailed it. The ability to have that type of data, no less synthetic data, I mean, it’s just extraordinary.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;We will get there someday. I’m confident of that. We may be wrong in projections. And I do think [science writer] Philip Ball won’t be right that it will never happen, though. [LAUGHTER] No, I think that if there’s a holy grail of biology, this is it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And I think you’re absolutely right about where that will get us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Transcending the beginning of the species.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Of&lt;em&gt; our&lt;/em&gt; species.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. All right. So now, we’re starting to run short on time here. And so I wanted to ask you about, I’m in my 60s, so I actually think about this a lot more. [LAUGHTER] And I know you’ve been thinking a lot about longevity. And, of course, your new book, &lt;em&gt;Super Agers&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And one of the reasons I’m so eager to read is it’s a topic very top of mind for me and actually for a lot of people. Where is this going? Because this is another area where you hear so much hype. At the same time, you see Nobel laureate scientists …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; … working on this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, so what’s, what’s real there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yeah. Well, it’s really … the real deal is the science of aging is zooming forward.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s exciting. But I see it bifurcating. On the one hand, all these new ideas, strategies to reverse aging are very ambitious. Like cell reprogramming and senolytics and, you know, the rejuvenation of our thymus gland, and it’s a long list.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And they’re really cool science, and it used to be the mouse lived longer. Now it’s the old mouse looks really young.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; All the different features. A blind mouse with cataracts is all of a sudden there’s no cataracts. I mean, so these things are exciting, but none of them are proven in people, and they all have significant risk, no less, you know, the expense that might be attached.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And some people are jumping the gun. They’re taking rapamycin, which can really knock out their immune system. So they all carry a lot of risk. And people are just getting a little carried away. We’re not there yet.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But the other side, which is what I emphasize in the book, which is exciting, is that we have all these new metrics that came out of the science of aging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; So we have clocks of the body. Our biological clock versus our chronological clock, and we have organ clocks. So I can say, you know, Peter, we’ve assessed all your organs and your immune system. And guess what? Every one of them is either at or less than your actual age.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And that’s very reassuring. And by the way, your methylation clock is also … I don’t need to worry about you so much. And then I have these other tests that I can do now, like, for example, the brain. We have an amazing protein p-Tau217 that we can say over 20 years in advance of you developing Alzheimer’s, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; … we can look at that, and it’s modifiable by lifestyle, bringing it down. It should be you can change the natural history. So what we’ve seen is an explosion of knowledge of metrics, proteins, no less, you know, our understanding at the gene level, the gut microbiome, the immune system. So that’s what’s so exciting. How our immune system ages. &lt;em&gt;Immunosenescence&lt;/em&gt;. How we have more inflammation—&lt;em&gt;inflammaging&lt;/em&gt;—with aging. So basically, we have three diseases that kill us, that take away our health: heart, cancer, and neurodegenerative.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; And they all take more than 20 years. They all have a defective immune system inflammation problem, and they’re all going to be preventable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;That’s what’s so exciting.&amp;nbsp;So we don’t have to have reverse aging. We can actually work on …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Just prevent aging in the first place.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;the age-related diseases. So basically, what it means is: I got to find out if you have a risk, if you’re in this high-risk group for this particular condition, because if you are—and we have many levels, layers, orthogonal ways to check—we don’t just bank it all on one polygenic test. We’re going to have several ways, say this is the one we are going …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then we go into high surveillance, where, let’s say if it’s your brain, we do more p-Tau, if we need to do brain imaging—whatever it takes. And also, we do preventive treatments on top of the lifestyle [changes], that one of the problems we have today is a lot of people know generally, what are good lifestyle factors. Although, I go through a lot more than people generally acknowledge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But they don’t incorporate them because they don’t know that they’re at risk and they could change their … extend their health span and prevent that disease. So what I at least put out there, a blueprint, is how we can use AI, because it’s multimodal AI, with all these layers of data, and then temporally, it’s like today you could say if you have two protein tests, not only are you going to have Alzheimer’s, but within a two-year time frame &lt;em&gt;when&lt;/em&gt; …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;… and if you don’t change things, if we don’t gear up … you know, we can … we can completely prevent this, so … or at least defer it for a decade or more. So that’s why I’m excited, is that we made these strides in the science of aging. But we haven’t acknowledged the part that doesn’t require reversing aging. There’s this much less flashy, attainable, less risky approach …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;than the one that … when you reverse aging, you’re playing with the hallmarks of cancer. They are like, if you look at the hallmarks of cancer …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; That has been one of the primary challenges.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;They’re lined up.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; They’re all the same, you know, whether it’s telomeres, or whether it’s … you know … so this is the problem. I actually say in the book, I do think one of these—we have so many shots on goal—one of these reverse aging things will likely happen someday. But we’re nowhere close.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;On the other hand, let’s gear up. Let’s do what we can do. Because we have these new metrics that’s … people don’t … like, when I read the organ clock paper&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; from Tony Wyss-Coray from Stanford. It was published end of ’23; it was the cover of &lt;em&gt;Nature&lt;/em&gt;. It blew me away.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;And I wrote a Substack&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; [article] on it. And Tony said, “Well, that’s so nice of you.” I said, “So nice? This is revolutionary, you know.” [LAUGHTER] So …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;By the way, what’s so interesting is, how these things, this kind of understanding and AI, are coming together.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;It’s almost eerie the timing of these things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Absolutely. Because you couldn’t take all these layers of data, just like we were talking about data hoarding.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yep.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL:&lt;/strong&gt; Now we have data hoarding on individual with no way to be able to make these assessments of what level of risk, when, what are we going to do in &lt;em&gt;this&lt;/em&gt; individual to prevent that? We can do that now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We can do it today. And we could keep building on that. So I’m really excited about it. I think that, you know, when I wrote the last book on deep medicine, it was our overarching goal should be to bring back the patient-doctor relationship. I’m an old dog, and I know what it used to be when I got out of medical school.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s totally … you couldn’t imagine how much erosion from the ’70s, ’80s to now. But now I have a new overarching goal. I’m thinking that that still is really important—humanity in medicine—but let’s prevent these three … big three diseases because it’s an opportunity that we’re not … you know, in medicine, all my life we’ve been hearing and talking about we need to prevent diseases.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Curing is much harder than prevention. And the economics. Oh my gosh. But we haven’t done it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Now we can do it. Primary prevention. We’d do really well. Somebody’s had heart attack.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Oh, we’re going to get all over it. Why did they have a heart attack in the first place?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, the thing that makes so much sense in what you’re saying is that we understand we have an understanding both economically and medically that prevention is a good thing. And extending the concept of prevention to these age-related conditions, I think, makes all the sense in the world.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, Eric, maybe on that optimistic note, it’s time to wrap up this conversation. Really appreciate you coming. Let me just brag in closing that I’m now the proud owner of an autographed copy of your latest book, and, really, thank you for that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;TOPOL: &lt;/strong&gt;Oh, thank you. I could spend the rest of the day talking to you. I’ve really enjoyed it. Thanks.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; For me, the biggest takeaway from our conversation was Eric’s supremely optimistic predictions about what AI will allow us to do in much less than 10 years.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, for me personally, I started off several years ago with the typical techie naivete that if we could solve protein folding using machine learning, we would solve human biology. But as I’ve gotten smarter, I’ve realized that things are way, way more complicated than that, and so hearing Eric’s techno-optimism on this is really both heartening and so interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Another thing that really caught my attention are Eric’s views on AI in medical diagnosis. That really stood out to me because within our labs here at Microsoft Research, we have been doing a lot of work on this, for example in creating foundation models for whole-slide digital pathology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The bottom line, though, is that biomedical research and development is really changing and changing quickly. It’s something that we thought about and wrote briefly about in our book, but just hearing it from these three people gives me reason to believe that this is going to create tremendous benefits in the diagnosis and treatment of disease.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, I wonder now how regulators, such as the Food and Drug Administration here in the United States, will be able to keep up with what might become a really big increase in the number of animal and human studies that need to be approved. On this point, it’s clear that the FDA and other regulators will need to use AI to help process the likely rise in the pace of discovery and experimentation. And so stay tuned for more information about that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC] &lt;/p&gt;



&lt;p&gt;I’d like to thank Daphne, Noubar, and Eric again for their time and insights. And to our listeners, thank you for joining us. There are several episodes left in the series, including discussions on medical students’ experiences with AI and AI’s influence on the operation of health systems and public health departments. We hope you’ll continue to tune in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES] &lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/how-ai-will-accelerate-biomedical-research-and-discovery/</guid><pubDate>Thu, 10 Jul 2025 16:00:00 +0000</pubDate></item><item><title>Musk’s Grok 4 launches one day after chatbot generated Hitler praise on X (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/musks-grok-4-launches-one-day-after-chatbot-generated-hitler-praise-on-x/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        xAI claims new multi-agent model hits top benchmarks as Nazi controversy lingers.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Grok chatbot logo on a smartphone" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok_header_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Grok chatbot logo on a smartphone" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok_header_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday night, Elon Musk unveiled xAI's latest flagship models Grok 4 and Grok 4 Heavy via livestream, just one day after the company's Grok chatbot began generating outputs that featured blatantly antisemitic tropes in responses to users on X.&lt;/p&gt;
&lt;p&gt;Among the two models, xAI calls Grok 4 Heavy its "multi-agent version." According to Musk, Grok 4 Heavy "spawns multiple agents in parallel" that "compare notes and yield an answer," simulating a study group approach. The company describes this as test-time compute scaling (similar to previous simulated reasoning models), claiming to increase computational resources by roughly an order of magnitude during runtime (called "inference").&lt;/p&gt;
&lt;p&gt;During the livestream, Musk claimed the new models achieved frontier-level performance on several benchmarks. On Humanity's Last Exam, a deliberately challenging test with 2,500 expert-curated questions across multiple subjects, Grok 4 reportedly scored 25.4 percent without external tools, which the company says outperformed OpenAI's o3 at 21 percent and Google's Gemini 2.5 Pro at 21.6 percent. With tools enabled, xAI claims Grok 4 Heavy reached 44.4 percent. However, it remains to be seen if these AI benchmarks actually measure properties that translate to usefulness for users.&lt;/p&gt;
&lt;p&gt;The release timing proved particularly noteworthy given the events of the preceding 48 hours on Musk's X social media platform, which included multiple instances of the chatbot labeling itself as "MechaHitler." The antisemitic posts emerged after an update over the weekend that instructed the chatbot to "not shy away from making claims which are politically incorrect, as long as they are well substantiated." xAI reportedly removed the modified directive Tuesday.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In response to the episode, Poland announced plans to report xAI to the European Commission, and Turkey blocked some access to Grok following the incident. On Wednesday, Musk wrote in a post on X that "Grok was too compliant to user prompts. Too eager to please and be manipulated, essentially. That is being addressed."&lt;/p&gt;
&lt;p&gt;Adding to the week's turmoil, X CEO Linda Yaccarino announced Wednesday morning she was stepping down, writing on X, "Now, the best is yet to come as X enters a new chapter with @xai." Her departure follows Musk's March&amp;nbsp;announcement that his artificial intelligence company, xAI, acquired X in an all-stock transaction that valued X at $33 billion and gave xAI a valuation of $80 billion.&lt;/p&gt;
&lt;h2&gt;The Grok technical conundrum&lt;/h2&gt;
&lt;p&gt;Since the launch of Grok 1 in 2023, the Grok series of large language models has been something of a conundrum for some members of the AI technical community. Judging by posts on X, some prominent researchers like Andrej Karpathy have historically taken the underlying models seriously as examples of technical achievement in AI development.&lt;/p&gt;
&lt;p&gt;But that achievement has been inextricably linked to Musk, who has seemingly guided the application of his AI models (in the form of "Grok" chatbot assistants on X and in the Grok app) through a series of controversies over the past few years that include potentially using OpenAI models to generate training data, producing uncensored image outputs, making up fake news based on X user jokes, and allowing explicit abusive voice chats in its app, among others.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Musk has also apparently used the Grok chatbots as an automated extension of his trolling habits, showing examples of Grok 3 producing "based" opinions that criticized the media in February. In May, Grok on X began repeatedly generating outputs about white genocide in South Africa, and most recently, we've seen the Grok Nazi output debacle. It's admittedly difficult to take Grok seriously as a technical product when it's linked to so many examples of unserious and capricious applications of the technology.&lt;/p&gt;
&lt;p&gt;Still, the technical achievements xAI claims for various Grok 4 models seem to stand out. The Arc Prize organization reported that Grok 4 Thinking (with simulated reasoning enabled) achieved a score of 15.9 percent on its ARC-AGI-2 test, which the organization says nearly doubles the previous commercial best and tops the current Kaggle competition leader.&lt;/p&gt;
&lt;p&gt;"With respect to academic questions, Grok 4 is better than PhD level in every subject, no exceptions," Musk claimed during the livestream. We've previously covered nebulous claims about "PhD-level" AI, finding them to be generally specious marketing talk.&lt;/p&gt;
&lt;h2&gt;Premium pricing amid controversy&lt;/h2&gt;
&lt;p&gt;During Wednesday's livestream, xAI also announced plans for an AI coding model in August, a multi-modal agent in September, and a video generation model in October. The company also plans to make Grok 4 available in Tesla vehicles next week, further expanding Musk's AI assistant across his various companies.&lt;/p&gt;
&lt;p&gt;Despite the recent turmoil, xAI has moved forward with an aggressive pricing strategy for "premium" versions of Grok. Alongside Grok 4 and Grok 4 Heavy, xAI launched "SuperGrok Heavy," a $300-per-month subscription that makes it the most expensive AI service among major providers. Subscribers will get early access to Grok 4 Heavy and upcoming features.&lt;/p&gt;
&lt;p&gt;Whether users will pay xAI's premium pricing remains to be seen, particularly given the AI assistant's tendency to periodically generate politically motivated outputs. These incidents—stemming from deliberate choices about training and system prompts—represenmt fundamental management and implementation issues that, so far, no fancy-looking test-taking benchmarks have been able to capture.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        xAI claims new multi-agent model hits top benchmarks as Nazi controversy lingers.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Grok chatbot logo on a smartphone" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok_header_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Grok chatbot logo on a smartphone" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/grok_header_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday night, Elon Musk unveiled xAI's latest flagship models Grok 4 and Grok 4 Heavy via livestream, just one day after the company's Grok chatbot began generating outputs that featured blatantly antisemitic tropes in responses to users on X.&lt;/p&gt;
&lt;p&gt;Among the two models, xAI calls Grok 4 Heavy its "multi-agent version." According to Musk, Grok 4 Heavy "spawns multiple agents in parallel" that "compare notes and yield an answer," simulating a study group approach. The company describes this as test-time compute scaling (similar to previous simulated reasoning models), claiming to increase computational resources by roughly an order of magnitude during runtime (called "inference").&lt;/p&gt;
&lt;p&gt;During the livestream, Musk claimed the new models achieved frontier-level performance on several benchmarks. On Humanity's Last Exam, a deliberately challenging test with 2,500 expert-curated questions across multiple subjects, Grok 4 reportedly scored 25.4 percent without external tools, which the company says outperformed OpenAI's o3 at 21 percent and Google's Gemini 2.5 Pro at 21.6 percent. With tools enabled, xAI claims Grok 4 Heavy reached 44.4 percent. However, it remains to be seen if these AI benchmarks actually measure properties that translate to usefulness for users.&lt;/p&gt;
&lt;p&gt;The release timing proved particularly noteworthy given the events of the preceding 48 hours on Musk's X social media platform, which included multiple instances of the chatbot labeling itself as "MechaHitler." The antisemitic posts emerged after an update over the weekend that instructed the chatbot to "not shy away from making claims which are politically incorrect, as long as they are well substantiated." xAI reportedly removed the modified directive Tuesday.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In response to the episode, Poland announced plans to report xAI to the European Commission, and Turkey blocked some access to Grok following the incident. On Wednesday, Musk wrote in a post on X that "Grok was too compliant to user prompts. Too eager to please and be manipulated, essentially. That is being addressed."&lt;/p&gt;
&lt;p&gt;Adding to the week's turmoil, X CEO Linda Yaccarino announced Wednesday morning she was stepping down, writing on X, "Now, the best is yet to come as X enters a new chapter with @xai." Her departure follows Musk's March&amp;nbsp;announcement that his artificial intelligence company, xAI, acquired X in an all-stock transaction that valued X at $33 billion and gave xAI a valuation of $80 billion.&lt;/p&gt;
&lt;h2&gt;The Grok technical conundrum&lt;/h2&gt;
&lt;p&gt;Since the launch of Grok 1 in 2023, the Grok series of large language models has been something of a conundrum for some members of the AI technical community. Judging by posts on X, some prominent researchers like Andrej Karpathy have historically taken the underlying models seriously as examples of technical achievement in AI development.&lt;/p&gt;
&lt;p&gt;But that achievement has been inextricably linked to Musk, who has seemingly guided the application of his AI models (in the form of "Grok" chatbot assistants on X and in the Grok app) through a series of controversies over the past few years that include potentially using OpenAI models to generate training data, producing uncensored image outputs, making up fake news based on X user jokes, and allowing explicit abusive voice chats in its app, among others.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Musk has also apparently used the Grok chatbots as an automated extension of his trolling habits, showing examples of Grok 3 producing "based" opinions that criticized the media in February. In May, Grok on X began repeatedly generating outputs about white genocide in South Africa, and most recently, we've seen the Grok Nazi output debacle. It's admittedly difficult to take Grok seriously as a technical product when it's linked to so many examples of unserious and capricious applications of the technology.&lt;/p&gt;
&lt;p&gt;Still, the technical achievements xAI claims for various Grok 4 models seem to stand out. The Arc Prize organization reported that Grok 4 Thinking (with simulated reasoning enabled) achieved a score of 15.9 percent on its ARC-AGI-2 test, which the organization says nearly doubles the previous commercial best and tops the current Kaggle competition leader.&lt;/p&gt;
&lt;p&gt;"With respect to academic questions, Grok 4 is better than PhD level in every subject, no exceptions," Musk claimed during the livestream. We've previously covered nebulous claims about "PhD-level" AI, finding them to be generally specious marketing talk.&lt;/p&gt;
&lt;h2&gt;Premium pricing amid controversy&lt;/h2&gt;
&lt;p&gt;During Wednesday's livestream, xAI also announced plans for an AI coding model in August, a multi-modal agent in September, and a video generation model in October. The company also plans to make Grok 4 available in Tesla vehicles next week, further expanding Musk's AI assistant across his various companies.&lt;/p&gt;
&lt;p&gt;Despite the recent turmoil, xAI has moved forward with an aggressive pricing strategy for "premium" versions of Grok. Alongside Grok 4 and Grok 4 Heavy, xAI launched "SuperGrok Heavy," a $300-per-month subscription that makes it the most expensive AI service among major providers. Subscribers will get early access to Grok 4 Heavy and upcoming features.&lt;/p&gt;
&lt;p&gt;Whether users will pay xAI's premium pricing remains to be seen, particularly given the AI assistant's tendency to periodically generate politically motivated outputs. These incidents—stemming from deliberate choices about training and system prompts—represenmt fundamental management and implementation issues that, so far, no fancy-looking test-taking benchmarks have been able to capture.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/musks-grok-4-launches-one-day-after-chatbot-generated-hitler-praise-on-x/</guid><pubDate>Thu, 10 Jul 2025 16:05:35 +0000</pubDate></item><item><title>Everything tech giants will hate about the EU’s new AI rules (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/everything-tech-giants-will-hate-about-the-eus-new-ai-rules/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        EU rules ask tech giants to publicly track how and when AI models go off the rails.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1793187673-640x379.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1793187673-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The European Union is moving to force AI companies to be more transparent than ever, publishing a code of practice Thursday that will help tech giants prepare to comply with the EU's landmark AI Act.&lt;/p&gt;
&lt;p&gt;These rules—which have not yet been finalized and focus on copyright protections, transparency, and public safety—will initially be voluntary when they take effect for the biggest makers of "general purpose AI" on August 2.&lt;/p&gt;
&lt;p&gt;But the EU will begin enforcing the AI Act in August 2026, and the Commission has noted that any companies agreeing to the rules could benefit from a "reduced administrative burden and increased legal certainty," The New York Times reported. Rejecting the voluntary rules could force companies to prove their compliance in ways that could be more costly or time-consuming, the Commission suggested.&lt;/p&gt;
&lt;p&gt;The AI industry participated in drafting the AI Act, but some companies have recently urged the EU to delay enforcement of the law, warning that the EU may risk hampering AI innovation by placing heavy restrictions on companies.&lt;/p&gt;
&lt;p&gt;Among the most controversial commitments that the EU is asking companies like Google, Meta, and OpenAI to voluntarily make is a promise to never pirate materials for AI training.&lt;/p&gt;
&lt;p&gt;Many AI companies have controversially used pirated book datasets to train AI, including Meta, which suggested that individual books are individually worthless to train AI after being called out for torrenting unauthorized book copies. But the EU doesn't agree, recommending that tech companies designate staffers and create internal mechanisms to field complaints "within a reasonable timeframe" from rightsholders, who must be allowed to opt their creative works out of AI training data sets.&lt;/p&gt;
&lt;p&gt;The EU rules pressure AI makers to take other steps the industry has mostly resisted. Most notably, AI companies will need to share detailed information about their training data, including providing a rationale for key model design choices and disclosing precisely where their training data came from. That could make it clearer how much of each company's models depend on publicly available data versus user data, third-party data, synthetic data, or some emerging new source of data.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The code also details expectations for AI companies to respect paywalls, as well as robots.txt instructions restricting crawling, which could help confront a growing problem of AI crawlers hammering websites. It "encourages" online search giants to embrace a solution that Cloudflare is currently pushing: allowing content creators to protect copyrights by restricting AI crawling without impacting search indexing.&lt;/p&gt;
&lt;p&gt;Additionally, companies are asked to disclose total energy consumption for both training and inference, allowing the EU to detect environmental concerns while companies race forward with AI innovation.&lt;/p&gt;
&lt;p&gt;More substantially, the code's safety guidance provides for additional monitoring for other harms. It makes recommendations to detect and avoid "serious incidents" with new AI models, which could include cybersecurity breaches, disruptions of critical infrastructure, "serious harm to a person’s health (mental and/or physical)," or "a death of a person." It stipulates timelines of between five and 10 days to report serious incidents with the EU's AI Office. And it requires companies to track all events, provide an "adequate level" of cybersecurity protection, prevent jailbreaking as best they can, and justify "any failures or circumventions of systemic risk mitigations."&lt;/p&gt;
&lt;p&gt;Ars reached out to tech companies for immediate reactions to the new rules. OpenAI, Meta, and Microsoft declined to comment. A Google spokesperson confirmed that the company is reviewing the code, which still must be approved by the European Commission and EU member states amid expected industry pushback.&lt;/p&gt;
&lt;p&gt;"Europeans should have access to first-rate, secure AI models when they become available, and an environment that promotes innovation and investment," Google's spokesperson said. "We look forward to reviewing the code and sharing our views alongside other model providers and many others."&lt;/p&gt;
&lt;p&gt;These rules are just one part of the AI Act, which will start taking effect in a staggered approach over the next year or more, the NYT reported. Breaching the AI Act could result in AI models being yanked off the market or fines "of as much as 7 percent of a company’s annual sales or 3 percent for the companies developing advanced AI models," Bloomberg noted.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        EU rules ask tech giants to publicly track how and when AI models go off the rails.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1793187673-640x379.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1793187673-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The European Union is moving to force AI companies to be more transparent than ever, publishing a code of practice Thursday that will help tech giants prepare to comply with the EU's landmark AI Act.&lt;/p&gt;
&lt;p&gt;These rules—which have not yet been finalized and focus on copyright protections, transparency, and public safety—will initially be voluntary when they take effect for the biggest makers of "general purpose AI" on August 2.&lt;/p&gt;
&lt;p&gt;But the EU will begin enforcing the AI Act in August 2026, and the Commission has noted that any companies agreeing to the rules could benefit from a "reduced administrative burden and increased legal certainty," The New York Times reported. Rejecting the voluntary rules could force companies to prove their compliance in ways that could be more costly or time-consuming, the Commission suggested.&lt;/p&gt;
&lt;p&gt;The AI industry participated in drafting the AI Act, but some companies have recently urged the EU to delay enforcement of the law, warning that the EU may risk hampering AI innovation by placing heavy restrictions on companies.&lt;/p&gt;
&lt;p&gt;Among the most controversial commitments that the EU is asking companies like Google, Meta, and OpenAI to voluntarily make is a promise to never pirate materials for AI training.&lt;/p&gt;
&lt;p&gt;Many AI companies have controversially used pirated book datasets to train AI, including Meta, which suggested that individual books are individually worthless to train AI after being called out for torrenting unauthorized book copies. But the EU doesn't agree, recommending that tech companies designate staffers and create internal mechanisms to field complaints "within a reasonable timeframe" from rightsholders, who must be allowed to opt their creative works out of AI training data sets.&lt;/p&gt;
&lt;p&gt;The EU rules pressure AI makers to take other steps the industry has mostly resisted. Most notably, AI companies will need to share detailed information about their training data, including providing a rationale for key model design choices and disclosing precisely where their training data came from. That could make it clearer how much of each company's models depend on publicly available data versus user data, third-party data, synthetic data, or some emerging new source of data.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The code also details expectations for AI companies to respect paywalls, as well as robots.txt instructions restricting crawling, which could help confront a growing problem of AI crawlers hammering websites. It "encourages" online search giants to embrace a solution that Cloudflare is currently pushing: allowing content creators to protect copyrights by restricting AI crawling without impacting search indexing.&lt;/p&gt;
&lt;p&gt;Additionally, companies are asked to disclose total energy consumption for both training and inference, allowing the EU to detect environmental concerns while companies race forward with AI innovation.&lt;/p&gt;
&lt;p&gt;More substantially, the code's safety guidance provides for additional monitoring for other harms. It makes recommendations to detect and avoid "serious incidents" with new AI models, which could include cybersecurity breaches, disruptions of critical infrastructure, "serious harm to a person’s health (mental and/or physical)," or "a death of a person." It stipulates timelines of between five and 10 days to report serious incidents with the EU's AI Office. And it requires companies to track all events, provide an "adequate level" of cybersecurity protection, prevent jailbreaking as best they can, and justify "any failures or circumventions of systemic risk mitigations."&lt;/p&gt;
&lt;p&gt;Ars reached out to tech companies for immediate reactions to the new rules. OpenAI, Meta, and Microsoft declined to comment. A Google spokesperson confirmed that the company is reviewing the code, which still must be approved by the European Commission and EU member states amid expected industry pushback.&lt;/p&gt;
&lt;p&gt;"Europeans should have access to first-rate, secure AI models when they become available, and an environment that promotes innovation and investment," Google's spokesperson said. "We look forward to reviewing the code and sharing our views alongside other model providers and many others."&lt;/p&gt;
&lt;p&gt;These rules are just one part of the AI Act, which will start taking effect in a staggered approach over the next year or more, the NYT reported. Breaching the AI Act could result in AI models being yanked off the market or fines "of as much as 7 percent of a company’s annual sales or 3 percent for the companies developing advanced AI models," Bloomberg noted.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/everything-tech-giants-will-hate-about-the-eus-new-ai-rules/</guid><pubDate>Thu, 10 Jul 2025 16:29:59 +0000</pubDate></item><item><title>Elon Musk introduced Grok 4 last night, calling it the ‘smartest AI in the world’ — what businesses need to know (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/elon-musk-introduced-grok-4-last-night-calling-it-the-smartest-ai-in-the-world-what-businesses-need-to-know/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;After days of controversy surrounding a flurry of antisemitic responses made recently by his Grok AI-powered chatbot on his social network X (formerly Twitter), a seemingly unrepentant and unbothered Elon Musk launched the latest version of his AI model family, Grok 4, during an event livestreamed on X last night, calling it the “the smartest AI in the world.”&lt;/p&gt;



&lt;p&gt;As Musk posted on X: “Grok 4 is the first time, in my experience, that an AI has been able to solve difficult, real-world engineering questions where the answers cannot be found anywhere on the Internet or in books. And it will get much better.”&lt;/p&gt;



&lt;p&gt;The new release actually includes two distinct models: &lt;strong&gt;Grok 4&lt;/strong&gt;, a single-agent reasoning model, and &lt;strong&gt;Grok 4 Heavy&lt;/strong&gt;, a multi-agent system designed to solve complex problems through internal collaboration and synthesis. &lt;/p&gt;



&lt;p&gt;Both models are optimized for reasoning tasks and come with native tool integration, enabling capabilities such as web search, code execution, and multimodal analysis. &lt;/p&gt;



&lt;p&gt;Musk and his team at xAI showcased benchmarks that suggest Grok 4 outperforms all current competitors across a range of academic and coding evaluations, even when compared to formerly leading AI reasoning model rivals, such as OpenAI o3 and Google Gemini.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014031" height="471" src="https://venturebeat.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-11.02.05%E2%80%AFAM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;However, xAI has not yet released a &lt;strong&gt;model card&lt;/strong&gt; or any official release notes documentation for Grok 4 to the public, making it challenging to independently assess its performance and the claims made during the stream. We’ll update if/when these become available.&lt;/p&gt;



&lt;p&gt;Nor did Musk and his xAI team members participating in the livestream address the glaring controversy facing Grok over the past week, including many incidents of Grok making antisemitic remarks or referring to itself as “MechaHitler“, and suggesting that people with Jewish surnames should be handled decisively by Adolf Hitler — a seemingly overt reference to the Holocaust and genocide of 6 million Jews during World War 2. &lt;/p&gt;



&lt;p&gt;The closest Musk came was when he stated: “The thing that I think is most important for AI safety—at least my biological neural net tells me the most important thing—is to be maximally truth-seeking,” and “We need to make sure that the AI is a good AI. Good Grok” as well as “It’s important to instill the values you want in a child that would grow up to be incredibly powerful.” &lt;/p&gt;



&lt;p&gt;However, Musk did not apologize, nor did he accept responsibility for Grok’s antisemitic, sexually offensive and conspiratorial remarks. Here’s a copy of the full stream:&lt;/p&gt;



&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://venturebeat.com/wp-content/uploads/2025/07/grok-4-livestream-rip.mp4"&gt;&lt;/video&gt;&lt;/figure&gt;



&lt;p&gt;Throughout the livestream, the team emphasized Grok 4’s ability to reason from first principles, correct its own errors and potentially invent new technologies or uncover novel scientific insights.&lt;/p&gt;



&lt;p&gt;The presentation also included demonstrations of Grok 4 Heavy, which applies multi-agent collaboration to tackle research-level problems across disciplines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-availability-and-pricing"&gt;Availability and pricing&lt;/h2&gt;



&lt;p&gt;Grok 4 is available now through several channels, depending on user type and subscription level:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;API Access (for developers and enterprises)&lt;/strong&gt;:&lt;br /&gt;Grok 4 and Grok 4 Heavy are live via the &lt;strong&gt;xAI API&lt;/strong&gt;. Pricing is structured as follows:
&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;$3 per 1 million input tokens&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;$15 per 1 million output tokens&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;$0.75 per 1 million cached input tokens&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;Prices &lt;strong&gt;double after 128,000 tokens&lt;/strong&gt; in a single context window&lt;br /&gt;The API supports text and image inputs, function calling, structured outputs, and offers a 256,000-token context window.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Consumer Access (via Grok chatbot and apps)&lt;/strong&gt;:&lt;br /&gt;Individual users can access Grok 4 through the &lt;strong&gt;Grok chatbot on X&lt;/strong&gt;, the &lt;strong&gt;Grok app&lt;/strong&gt; (iOS and Android), and &lt;strong&gt;X.com&lt;/strong&gt;, but only with one of the following subscriptions:
&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;PremiumPlus&lt;/strong&gt;: $16/month&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;SuperGrok&lt;/strong&gt;: $300/month&lt;/li&gt;



&lt;li&gt;A new &lt;strong&gt;“SuperGrok Heavy”&lt;/strong&gt; tier, also priced at &lt;strong&gt;$300/month&lt;/strong&gt;, provides access to &lt;strong&gt;both Grok 4 and Grok 4 Heavy&lt;/strong&gt;, the multi-agent variant.&lt;br /&gt;(Note: SuperGrok and PremiumPlus tiers may differ in availability and usage quotas across X and Grok platforms.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Launch Timing&lt;/strong&gt;:&lt;br /&gt;Grok 4 became available immediately following the &lt;strong&gt;July 9, 2025,&lt;/strong&gt; livestream. Temporary access limits were in place during the demo, but full rollout to subscribers began shortly after.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Platform Expansion&lt;/strong&gt;:&lt;br /&gt;xAI has indicated plans to make Grok 4 available through &lt;strong&gt;Microsoft Azure AI Foundry&lt;/strong&gt;, where Grok 3 and Grok 3 Mini are currently listed.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;For subscription details, users are directed to x.ai/grok and X Premium support. Here’s how it compares to other leading AI models in terms of pricing per million tokens.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Provider &amp;amp; model&lt;/th&gt;&lt;th&gt;Context window&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Input&lt;/strong&gt; ($/Mtok)&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Cached input&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Output&lt;/strong&gt; ($/Mtok)&lt;/th&gt;&lt;th&gt;Additional notes&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;xAI – Grok 4 / 4 Heavy&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;256 K (2× price &amp;gt;128 K)&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$3.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.75&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$15.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Image input, function calling, structured JSON (apidog)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;OpenAI – o3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$2.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.50&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$8.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;50 % Batch-API discount available (OpenAI, OpenAI Help Center)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT-4o&lt;/td&gt;&lt;td&gt;128 K&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$5.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$2.50&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$20.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Vision, audio, tools (OpenAI)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Anthropic – Claude Sonnet 4&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$3.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.30&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$15.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;50 % batch output discount (Anthropic)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Claude Opus 4&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;$15.00&lt;/td&gt;&lt;td&gt;$1.50&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$75.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;High-accuracy flagship (Anthropic)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Google – Gemini 2.5 Pro&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;200 K (2× price &amp;gt;200 K)&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$1.25&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.31&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$10.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;75 % cache hit discount (Google AI for Developers, Google Cloud)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Gemini 2.5 Flash&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;$0.30&lt;/td&gt;&lt;td&gt;$0.075&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$2.50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Fast, cheap preview tier (Google Cloud)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;DeepSeek – deepseek-reasoner&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;64 K&lt;/td&gt;&lt;td&gt;$0.55 (miss) / $0.14 (hit)&lt;/td&gt;&lt;td&gt;$0.14&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$2.19&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;50-75 % off-peak discount (DeepSeek API Docs)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;







&lt;p&gt;Unlike its predecessor Grok 3, released in February, which separated tool-augmented responses from general reasoning, Grok 4 was trained with tools from the start.&lt;/p&gt;



&lt;p&gt;The model integrates capabilities such as code execution, web search and document parsing. It also introduces &lt;strong&gt;Grok 4 Heavy&lt;/strong&gt;, a multi-agent system where several internal models work in parallel to generate and validate answers.&lt;/p&gt;



&lt;p&gt;Grok 4 also includes a new &lt;strong&gt;voice mode&lt;/strong&gt; featuring expressive outputs with reduced latency, as well as support for text and image input, structured outputs and function calling.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-highlights"&gt;Performance highlights&lt;/h2&gt;



&lt;p&gt;The independent AI model analysis and benchmarking group Artificial Analysis stated on X that xAI provided it with a version of Grok 4 (not Heavy) earlier than the public release for scoring.&lt;/p&gt;



&lt;p&gt;On technical benchmarks, Grok 4 leads the Artificial Analysis Intelligence Index with a score of 73, ahead of competitors such as OpenAI’s o3 (70) and Google’s Gemini 2.5 Pro (70). &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014037" height="366" src="https://venturebeat.com/wp-content/uploads/2025/07/Gvd9nWIakAULlB9-1.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;It also recorded top scores in:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;GPQA Diamond:&lt;/strong&gt; 88%&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;ARC-AGI 2:&lt;/strong&gt; 15.9%, double the second-best score&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Humanities Last Exam:&lt;/strong&gt; 24% on the text-only version, and 44% with tools&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;MMLU-Pro and AIME 2024:&lt;/strong&gt; 87% and 94%, respectively&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Coding and Math evaluations:&lt;/strong&gt; Highest to date on LiveCodeBench, SciCode, AIME24, and MATH-500&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Despite its benchmark success, Grok 4’s &lt;strong&gt;output speed&lt;/strong&gt; stands at 75 tokens per second—slower than models like Gemini 2.5 Flash (353) or OpenAI’s o3 (187), but still faster than Anthropic’s Claude 4 Opus (66).&lt;/p&gt;



&lt;p&gt;The model features a &lt;span&gt;&lt;strong&gt;256,000-token context window&lt;/strong&gt;, which sits above the 200k context limits of o3&lt;/span&gt; and Claude 4 Sonnet but below the 1 million tokens offered by Gemini 2.5 Pro and GPT-4.1.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-real-world-use-cases"&gt;Real world use cases&lt;/h2&gt;



&lt;p&gt;xAI provided several demonstrations of Grok 4’s performance in applied scenarios:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;In a simulated business task called &lt;strong&gt;VendingBench&lt;/strong&gt;, Grok 4 significantly outperformed other models in long-horizon financial planning.&lt;/li&gt;



&lt;li&gt;At the &lt;strong&gt;Arc Institute&lt;/strong&gt;, researchers used Grok 4 to analyze CRISPR logs and uncover novel hypotheses.&lt;/li&gt;



&lt;li&gt;In &lt;strong&gt;radiology&lt;/strong&gt;, the model interpreted chest X-rays with higher accuracy than leading peers.&lt;/li&gt;



&lt;li&gt;In the &lt;strong&gt;financial sector&lt;/strong&gt;, its combination of real-time data access and reasoning made it suitable for forecasting and analysis.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The model can also create &lt;strong&gt;3D video games&lt;/strong&gt; with minimal input by autonomously sourcing and integrating assets. Additionally, it demonstrated capabilities to simulate astrophysical events using grounded approximations from published research.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-reception-and-discussion"&gt;Reception and discussion&lt;/h2&gt;



&lt;p&gt;The industry’s response to the Grok 4 launch has been divided, with enthusiasm for its performance offset by criticism of the event’s delivery and broader trust issues.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;David Shapiro&lt;/strong&gt;, an AI power user and writer, noted: “Grok 4 now takes its place as ‘smart enough to actually help with frontier research’… but has merely caught up with OpenAI.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Ethan Mollick&lt;/strong&gt;, a professor at Wharton, remarked on X: “So Grok 3 has had three separate incidents where apparently unvetted changes to the deployed system caused a large-scale ethical issue and an emergency rollback. I don’t think you can do a Grok 4 launch that doesn’t at least address this honestly, if user trust matters,” later adding, “Grok 3 was a very good model, and Grok 4 might be amazing but having a very good model is not enough – there are a lot of really good models out there. You actually want to trust the model you are building on.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Ben Hyak&lt;/strong&gt;, co-founder and CTO of AI product observability startup Raindrop AI (himself a former Musk employee) criticized the livestream itself: “This xAI livestream is one of the worst things I’ve ever watched in my life. Love y’all, but it’s bad.”&lt;/p&gt;



&lt;p&gt;Despite the criticisms, benchmarking firm Artificial Analysis noted: “Grok 4 is now the leading AI model.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ongoing-trust-issues"&gt;Ongoing trust issues&lt;/h2&gt;



&lt;p&gt;The launch of Grok 4 comes amid renewed criticism over Grok’s prior behavior in consumer deployments, particularly as a chatbot integrated into Musk’s social network, X.&lt;/p&gt;



&lt;p&gt;Over the July 4 holiday and in subsequent days, Grok generated antisemitic and conspiratorial responses that reignited scrutiny over its system design and governance practices.&lt;/p&gt;



&lt;p&gt;As reported by my VentureBeat colleague Michael F. Nuñez, Grok responded to questions about Jewish influence in Hollywood by asserting that Jewish executives “dominate leadership” at major studios and influence content through “progressive ideologies,” and went on to rant about people of Jewish surnames as fitting a “pattern” of engaging in “extreme leftist activism,” and suggesting Hitler knew “how to handle it decisively, every damn time,” an apparent reference to the Holocaust.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014035" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/GvXHBiRXAAAlTtl-2.jpg?w=356" width="356" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014036" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/GvXvvjNWkAA0IR9.jpg?w=772" width="772" /&gt;&lt;/figure&gt;



&lt;p&gt;The conspiratorial and antisemitic posting was so prolific, the Anti-Defamation League (ADL), a preeminent U.S.-based non-profit combating anti-semitism and hatred, posted on July 8: “What we are seeing from Grok LLM right now is irresponsible, dangerous and antisemitic, plain and simple. This supercharging of extremist rhetoric will only amplify and encourage the antisemitism that is already surging on X and many other platforms.”&lt;/p&gt;



&lt;p&gt;This incident follows a history of problematic Grok outputs, including a May 2025 case where the Grok bot integrated into X randomly inserted references to a completely nonsensical and non-real “white genocide” in South Africa into unrelated queries, and an earlier case wherein its system prompt was discovered to direct the Grok chatbot on X to avoid referencing any sources that declared Musk and his former political funding beneficiary U.S. President Donald J. Trump as spreaders of misinformation. In both cases, xAI blamed the behaviors on unnamed employees and stated that they were being addressed.&lt;/p&gt;



&lt;p&gt;Already, today, users of Grok 4 on the consumer app have observed it to once again be outputting anti-Zionist and anti-Semitic remarks:&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014038" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/Gve4PNVXAAAA9ny.jpg?w=569" width="569" /&gt;&lt;/figure&gt;



&lt;p&gt;As I previously noted, Musk has openly stated on several occasions he wanted to alter Grok to better reflect his personal beliefs and distrust in mainstream media and accredited sources. This makes it a poor source in enterprise contexts where such views could adversely impact users and the businesses building atop the Grok family of models. &lt;/p&gt;



&lt;p&gt;My prior recommendation remains: For those in the enterprise trying to ensure their business’s AI products work properly and accurately… Grok is sadly best avoided. Thankfully, there are numerous other alternatives to choose from.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;After days of controversy surrounding a flurry of antisemitic responses made recently by his Grok AI-powered chatbot on his social network X (formerly Twitter), a seemingly unrepentant and unbothered Elon Musk launched the latest version of his AI model family, Grok 4, during an event livestreamed on X last night, calling it the “the smartest AI in the world.”&lt;/p&gt;



&lt;p&gt;As Musk posted on X: “Grok 4 is the first time, in my experience, that an AI has been able to solve difficult, real-world engineering questions where the answers cannot be found anywhere on the Internet or in books. And it will get much better.”&lt;/p&gt;



&lt;p&gt;The new release actually includes two distinct models: &lt;strong&gt;Grok 4&lt;/strong&gt;, a single-agent reasoning model, and &lt;strong&gt;Grok 4 Heavy&lt;/strong&gt;, a multi-agent system designed to solve complex problems through internal collaboration and synthesis. &lt;/p&gt;



&lt;p&gt;Both models are optimized for reasoning tasks and come with native tool integration, enabling capabilities such as web search, code execution, and multimodal analysis. &lt;/p&gt;



&lt;p&gt;Musk and his team at xAI showcased benchmarks that suggest Grok 4 outperforms all current competitors across a range of academic and coding evaluations, even when compared to formerly leading AI reasoning model rivals, such as OpenAI o3 and Google Gemini.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014031" height="471" src="https://venturebeat.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-11.02.05%E2%80%AFAM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;However, xAI has not yet released a &lt;strong&gt;model card&lt;/strong&gt; or any official release notes documentation for Grok 4 to the public, making it challenging to independently assess its performance and the claims made during the stream. We’ll update if/when these become available.&lt;/p&gt;



&lt;p&gt;Nor did Musk and his xAI team members participating in the livestream address the glaring controversy facing Grok over the past week, including many incidents of Grok making antisemitic remarks or referring to itself as “MechaHitler“, and suggesting that people with Jewish surnames should be handled decisively by Adolf Hitler — a seemingly overt reference to the Holocaust and genocide of 6 million Jews during World War 2. &lt;/p&gt;



&lt;p&gt;The closest Musk came was when he stated: “The thing that I think is most important for AI safety—at least my biological neural net tells me the most important thing—is to be maximally truth-seeking,” and “We need to make sure that the AI is a good AI. Good Grok” as well as “It’s important to instill the values you want in a child that would grow up to be incredibly powerful.” &lt;/p&gt;



&lt;p&gt;However, Musk did not apologize, nor did he accept responsibility for Grok’s antisemitic, sexually offensive and conspiratorial remarks. Here’s a copy of the full stream:&lt;/p&gt;



&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://venturebeat.com/wp-content/uploads/2025/07/grok-4-livestream-rip.mp4"&gt;&lt;/video&gt;&lt;/figure&gt;



&lt;p&gt;Throughout the livestream, the team emphasized Grok 4’s ability to reason from first principles, correct its own errors and potentially invent new technologies or uncover novel scientific insights.&lt;/p&gt;



&lt;p&gt;The presentation also included demonstrations of Grok 4 Heavy, which applies multi-agent collaboration to tackle research-level problems across disciplines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-availability-and-pricing"&gt;Availability and pricing&lt;/h2&gt;



&lt;p&gt;Grok 4 is available now through several channels, depending on user type and subscription level:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;API Access (for developers and enterprises)&lt;/strong&gt;:&lt;br /&gt;Grok 4 and Grok 4 Heavy are live via the &lt;strong&gt;xAI API&lt;/strong&gt;. Pricing is structured as follows:
&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;$3 per 1 million input tokens&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;$15 per 1 million output tokens&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;$0.75 per 1 million cached input tokens&lt;/strong&gt;&lt;/li&gt;



&lt;li&gt;Prices &lt;strong&gt;double after 128,000 tokens&lt;/strong&gt; in a single context window&lt;br /&gt;The API supports text and image inputs, function calling, structured outputs, and offers a 256,000-token context window.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Consumer Access (via Grok chatbot and apps)&lt;/strong&gt;:&lt;br /&gt;Individual users can access Grok 4 through the &lt;strong&gt;Grok chatbot on X&lt;/strong&gt;, the &lt;strong&gt;Grok app&lt;/strong&gt; (iOS and Android), and &lt;strong&gt;X.com&lt;/strong&gt;, but only with one of the following subscriptions:
&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;PremiumPlus&lt;/strong&gt;: $16/month&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;SuperGrok&lt;/strong&gt;: $300/month&lt;/li&gt;



&lt;li&gt;A new &lt;strong&gt;“SuperGrok Heavy”&lt;/strong&gt; tier, also priced at &lt;strong&gt;$300/month&lt;/strong&gt;, provides access to &lt;strong&gt;both Grok 4 and Grok 4 Heavy&lt;/strong&gt;, the multi-agent variant.&lt;br /&gt;(Note: SuperGrok and PremiumPlus tiers may differ in availability and usage quotas across X and Grok platforms.)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Launch Timing&lt;/strong&gt;:&lt;br /&gt;Grok 4 became available immediately following the &lt;strong&gt;July 9, 2025,&lt;/strong&gt; livestream. Temporary access limits were in place during the demo, but full rollout to subscribers began shortly after.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Platform Expansion&lt;/strong&gt;:&lt;br /&gt;xAI has indicated plans to make Grok 4 available through &lt;strong&gt;Microsoft Azure AI Foundry&lt;/strong&gt;, where Grok 3 and Grok 3 Mini are currently listed.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;For subscription details, users are directed to x.ai/grok and X Premium support. Here’s how it compares to other leading AI models in terms of pricing per million tokens.&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th&gt;Provider &amp;amp; model&lt;/th&gt;&lt;th&gt;Context window&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Input&lt;/strong&gt; ($/Mtok)&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Cached input&lt;/strong&gt;&lt;/th&gt;&lt;th&gt;&lt;strong&gt;Output&lt;/strong&gt; ($/Mtok)&lt;/th&gt;&lt;th&gt;Additional notes&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;xAI – Grok 4 / 4 Heavy&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;256 K (2× price &amp;gt;128 K)&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$3.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.75&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$15.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Image input, function calling, structured JSON (apidog)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;OpenAI – o3&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$2.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.50&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$8.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;50 % Batch-API discount available (OpenAI, OpenAI Help Center)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GPT-4o&lt;/td&gt;&lt;td&gt;128 K&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$5.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$2.50&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$20.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Vision, audio, tools (OpenAI)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Anthropic – Claude Sonnet 4&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$3.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.30&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$15.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;50 % batch output discount (Anthropic)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Claude Opus 4&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;$15.00&lt;/td&gt;&lt;td&gt;$1.50&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$75.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;High-accuracy flagship (Anthropic)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Google – Gemini 2.5 Pro&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;200 K (2× price &amp;gt;200 K)&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$1.25&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;$0.31&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$10.00&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;75 % cache hit discount (Google AI for Developers, Google Cloud)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Gemini 2.5 Flash&lt;/td&gt;&lt;td&gt;200 K&lt;/td&gt;&lt;td&gt;$0.30&lt;/td&gt;&lt;td&gt;$0.075&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$2.50&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Fast, cheap preview tier (Google Cloud)&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;DeepSeek – deepseek-reasoner&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;64 K&lt;/td&gt;&lt;td&gt;$0.55 (miss) / $0.14 (hit)&lt;/td&gt;&lt;td&gt;$0.14&lt;/td&gt;&lt;td&gt;&lt;strong&gt;$2.19&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;50-75 % off-peak discount (DeepSeek API Docs)&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;







&lt;p&gt;Unlike its predecessor Grok 3, released in February, which separated tool-augmented responses from general reasoning, Grok 4 was trained with tools from the start.&lt;/p&gt;



&lt;p&gt;The model integrates capabilities such as code execution, web search and document parsing. It also introduces &lt;strong&gt;Grok 4 Heavy&lt;/strong&gt;, a multi-agent system where several internal models work in parallel to generate and validate answers.&lt;/p&gt;



&lt;p&gt;Grok 4 also includes a new &lt;strong&gt;voice mode&lt;/strong&gt; featuring expressive outputs with reduced latency, as well as support for text and image input, structured outputs and function calling.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-highlights"&gt;Performance highlights&lt;/h2&gt;



&lt;p&gt;The independent AI model analysis and benchmarking group Artificial Analysis stated on X that xAI provided it with a version of Grok 4 (not Heavy) earlier than the public release for scoring.&lt;/p&gt;



&lt;p&gt;On technical benchmarks, Grok 4 leads the Artificial Analysis Intelligence Index with a score of 73, ahead of competitors such as OpenAI’s o3 (70) and Google’s Gemini 2.5 Pro (70). &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014037" height="366" src="https://venturebeat.com/wp-content/uploads/2025/07/Gvd9nWIakAULlB9-1.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;It also recorded top scores in:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;GPQA Diamond:&lt;/strong&gt; 88%&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;ARC-AGI 2:&lt;/strong&gt; 15.9%, double the second-best score&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Humanities Last Exam:&lt;/strong&gt; 24% on the text-only version, and 44% with tools&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;MMLU-Pro and AIME 2024:&lt;/strong&gt; 87% and 94%, respectively&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Coding and Math evaluations:&lt;/strong&gt; Highest to date on LiveCodeBench, SciCode, AIME24, and MATH-500&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Despite its benchmark success, Grok 4’s &lt;strong&gt;output speed&lt;/strong&gt; stands at 75 tokens per second—slower than models like Gemini 2.5 Flash (353) or OpenAI’s o3 (187), but still faster than Anthropic’s Claude 4 Opus (66).&lt;/p&gt;



&lt;p&gt;The model features a &lt;span&gt;&lt;strong&gt;256,000-token context window&lt;/strong&gt;, which sits above the 200k context limits of o3&lt;/span&gt; and Claude 4 Sonnet but below the 1 million tokens offered by Gemini 2.5 Pro and GPT-4.1.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-real-world-use-cases"&gt;Real world use cases&lt;/h2&gt;



&lt;p&gt;xAI provided several demonstrations of Grok 4’s performance in applied scenarios:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;In a simulated business task called &lt;strong&gt;VendingBench&lt;/strong&gt;, Grok 4 significantly outperformed other models in long-horizon financial planning.&lt;/li&gt;



&lt;li&gt;At the &lt;strong&gt;Arc Institute&lt;/strong&gt;, researchers used Grok 4 to analyze CRISPR logs and uncover novel hypotheses.&lt;/li&gt;



&lt;li&gt;In &lt;strong&gt;radiology&lt;/strong&gt;, the model interpreted chest X-rays with higher accuracy than leading peers.&lt;/li&gt;



&lt;li&gt;In the &lt;strong&gt;financial sector&lt;/strong&gt;, its combination of real-time data access and reasoning made it suitable for forecasting and analysis.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;The model can also create &lt;strong&gt;3D video games&lt;/strong&gt; with minimal input by autonomously sourcing and integrating assets. Additionally, it demonstrated capabilities to simulate astrophysical events using grounded approximations from published research.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-reception-and-discussion"&gt;Reception and discussion&lt;/h2&gt;



&lt;p&gt;The industry’s response to the Grok 4 launch has been divided, with enthusiasm for its performance offset by criticism of the event’s delivery and broader trust issues.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;David Shapiro&lt;/strong&gt;, an AI power user and writer, noted: “Grok 4 now takes its place as ‘smart enough to actually help with frontier research’… but has merely caught up with OpenAI.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Ethan Mollick&lt;/strong&gt;, a professor at Wharton, remarked on X: “So Grok 3 has had three separate incidents where apparently unvetted changes to the deployed system caused a large-scale ethical issue and an emergency rollback. I don’t think you can do a Grok 4 launch that doesn’t at least address this honestly, if user trust matters,” later adding, “Grok 3 was a very good model, and Grok 4 might be amazing but having a very good model is not enough – there are a lot of really good models out there. You actually want to trust the model you are building on.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Ben Hyak&lt;/strong&gt;, co-founder and CTO of AI product observability startup Raindrop AI (himself a former Musk employee) criticized the livestream itself: “This xAI livestream is one of the worst things I’ve ever watched in my life. Love y’all, but it’s bad.”&lt;/p&gt;



&lt;p&gt;Despite the criticisms, benchmarking firm Artificial Analysis noted: “Grok 4 is now the leading AI model.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ongoing-trust-issues"&gt;Ongoing trust issues&lt;/h2&gt;



&lt;p&gt;The launch of Grok 4 comes amid renewed criticism over Grok’s prior behavior in consumer deployments, particularly as a chatbot integrated into Musk’s social network, X.&lt;/p&gt;



&lt;p&gt;Over the July 4 holiday and in subsequent days, Grok generated antisemitic and conspiratorial responses that reignited scrutiny over its system design and governance practices.&lt;/p&gt;



&lt;p&gt;As reported by my VentureBeat colleague Michael F. Nuñez, Grok responded to questions about Jewish influence in Hollywood by asserting that Jewish executives “dominate leadership” at major studios and influence content through “progressive ideologies,” and went on to rant about people of Jewish surnames as fitting a “pattern” of engaging in “extreme leftist activism,” and suggesting Hitler knew “how to handle it decisively, every damn time,” an apparent reference to the Holocaust.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014035" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/GvXHBiRXAAAlTtl-2.jpg?w=356" width="356" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014036" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/GvXvvjNWkAA0IR9.jpg?w=772" width="772" /&gt;&lt;/figure&gt;



&lt;p&gt;The conspiratorial and antisemitic posting was so prolific, the Anti-Defamation League (ADL), a preeminent U.S.-based non-profit combating anti-semitism and hatred, posted on July 8: “What we are seeing from Grok LLM right now is irresponsible, dangerous and antisemitic, plain and simple. This supercharging of extremist rhetoric will only amplify and encourage the antisemitism that is already surging on X and many other platforms.”&lt;/p&gt;



&lt;p&gt;This incident follows a history of problematic Grok outputs, including a May 2025 case where the Grok bot integrated into X randomly inserted references to a completely nonsensical and non-real “white genocide” in South Africa into unrelated queries, and an earlier case wherein its system prompt was discovered to direct the Grok chatbot on X to avoid referencing any sources that declared Musk and his former political funding beneficiary U.S. President Donald J. Trump as spreaders of misinformation. In both cases, xAI blamed the behaviors on unnamed employees and stated that they were being addressed.&lt;/p&gt;



&lt;p&gt;Already, today, users of Grok 4 on the consumer app have observed it to once again be outputting anti-Zionist and anti-Semitic remarks:&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014038" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/Gve4PNVXAAAA9ny.jpg?w=569" width="569" /&gt;&lt;/figure&gt;



&lt;p&gt;As I previously noted, Musk has openly stated on several occasions he wanted to alter Grok to better reflect his personal beliefs and distrust in mainstream media and accredited sources. This makes it a poor source in enterprise contexts where such views could adversely impact users and the businesses building atop the Grok family of models. &lt;/p&gt;



&lt;p&gt;My prior recommendation remains: For those in the enterprise trying to ensure their business’s AI products work properly and accurately… Grok is sadly best avoided. Thankfully, there are numerous other alternatives to choose from.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/elon-musk-introduced-grok-4-last-night-calling-it-the-smartest-ai-in-the-world-what-businesses-need-to-know/</guid><pubDate>Thu, 10 Jul 2025 17:24:46 +0000</pubDate></item><item><title>5 days until TechCrunch All Stage — save up to $475 before prices rise (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/5-days-until-techcrunch-all-stage-save-up-to-475-before-prices-rise/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In just five days, startup leaders from across the country will descend on Boston’s SoWa Power Station for &lt;strong&gt;TechCrunch All Stage 2025&lt;/strong&gt; — and your chance to lock in the lowest ticket prices will be gone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re preparing for your next raise, looking to fine-tune your go-to-market strategy, or building your founding team, TC All Stage is where real startup momentum happens. This is a full-day event packed with actionable sessions, tactical advice, and conversations that push your company forward.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, Founder Passes are just $100 and Investor Passes are $200 — but those savings (up to $475 off full price) vanish soon. Don’t wait. Get your pass today before rates go up.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch All Stage 5 days left" class="wp-image-3019875" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/16x9_GeneralArticleImageHeader_TCAllStage_5DaysCountdown.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-fuel-your-next-stage-of-growth"&gt;Fuel your next stage of growth&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;TC All Stage isn’t about hype — it’s about execution. Every session is built to deliver practical insights from founders, operators, and VCs who know what it takes to scale in today’s climate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On July 15 in Boston, you’ll get:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Breakout sessions&lt;/strong&gt; on fundraising frameworks, AI-driven product development, startup hiring, cap table strategy, and market readiness.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Interactive roundtables&lt;/strong&gt; designed for real talk, not surface-level fluff.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Live feedback&lt;/strong&gt; during “So You Think You Can Pitch” — the pitch competition that puts founder storytelling front and center.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated networking&lt;/strong&gt; through Braindate, helping you match with the right people for high-impact connections.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;After-hours &lt;/strong&gt;&lt;strong&gt;Side Events&lt;/strong&gt; that go beyond the badge for candid convos and community-building.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-hear-from-the-operators-and-investors-shaping-what-s-next"&gt;Hear from the operators and investors shaping what’s next&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Check the agenda and see who’s taking the stage. A few of the experts you’ll hear from include:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jon McNeill&lt;/strong&gt;,&lt;strong&gt; &lt;/strong&gt;DVx Ventures — why the next wave of disruptors must be operator-led from day one.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Kristen Craft&lt;/strong&gt;,&lt;strong&gt; &lt;/strong&gt;Fidelity Private Shares — decoding the VC landscape of 2025.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;David H. Rosmarin&lt;/strong&gt;, Harvard Medical School — transforming anxiety into a founder superpower.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jeff Chow&lt;/strong&gt;, Miro — building team intelligence through product-led innovation.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Kamila Khasanova&lt;/strong&gt;&lt;strong&gt;, &lt;/strong&gt;On Top Strategy — the storytelling strategies that drive successful raises.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="YC Group Partner Tom Blomfield on stage during TechCrunch Early Stage in Boston in April 2024" class="wp-image-2697522" height="383" src="https://techcrunch.com/wp-content/uploads/2024/04/53679979052_da1066fe91_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-just-5-days-to-go-get-your-pass-before-prices-increase"&gt;Just 5 days to go — get your pass before prices increase&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch All Stage happens July 15 in Boston&lt;/strong&gt;, and your chance to save ends soon. The event is just five days away, and prices rise at the door. Join the founders, VCs, and builders defining the future. Secure your pass now.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In just five days, startup leaders from across the country will descend on Boston’s SoWa Power Station for &lt;strong&gt;TechCrunch All Stage 2025&lt;/strong&gt; — and your chance to lock in the lowest ticket prices will be gone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re preparing for your next raise, looking to fine-tune your go-to-market strategy, or building your founding team, TC All Stage is where real startup momentum happens. This is a full-day event packed with actionable sessions, tactical advice, and conversations that push your company forward.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, Founder Passes are just $100 and Investor Passes are $200 — but those savings (up to $475 off full price) vanish soon. Don’t wait. Get your pass today before rates go up.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch All Stage 5 days left" class="wp-image-3019875" height="383" src="https://techcrunch.com/wp-content/uploads/2025/06/16x9_GeneralArticleImageHeader_TCAllStage_5DaysCountdown.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-fuel-your-next-stage-of-growth"&gt;Fuel your next stage of growth&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;TC All Stage isn’t about hype — it’s about execution. Every session is built to deliver practical insights from founders, operators, and VCs who know what it takes to scale in today’s climate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On July 15 in Boston, you’ll get:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Breakout sessions&lt;/strong&gt; on fundraising frameworks, AI-driven product development, startup hiring, cap table strategy, and market readiness.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Interactive roundtables&lt;/strong&gt; designed for real talk, not surface-level fluff.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Live feedback&lt;/strong&gt; during “So You Think You Can Pitch” — the pitch competition that puts founder storytelling front and center.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Curated networking&lt;/strong&gt; through Braindate, helping you match with the right people for high-impact connections.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;After-hours &lt;/strong&gt;&lt;strong&gt;Side Events&lt;/strong&gt; that go beyond the badge for candid convos and community-building.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-hear-from-the-operators-and-investors-shaping-what-s-next"&gt;Hear from the operators and investors shaping what’s next&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Check the agenda and see who’s taking the stage. A few of the experts you’ll hear from include:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jon McNeill&lt;/strong&gt;,&lt;strong&gt; &lt;/strong&gt;DVx Ventures — why the next wave of disruptors must be operator-led from day one.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Kristen Craft&lt;/strong&gt;,&lt;strong&gt; &lt;/strong&gt;Fidelity Private Shares — decoding the VC landscape of 2025.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;David H. Rosmarin&lt;/strong&gt;, Harvard Medical School — transforming anxiety into a founder superpower.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Jeff Chow&lt;/strong&gt;, Miro — building team intelligence through product-led innovation.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Kamila Khasanova&lt;/strong&gt;&lt;strong&gt;, &lt;/strong&gt;On Top Strategy — the storytelling strategies that drive successful raises.&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="YC Group Partner Tom Blomfield on stage during TechCrunch Early Stage in Boston in April 2024" class="wp-image-2697522" height="383" src="https://techcrunch.com/wp-content/uploads/2024/04/53679979052_da1066fe91_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-just-5-days-to-go-get-your-pass-before-prices-increase"&gt;Just 5 days to go — get your pass before prices increase&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch All Stage happens July 15 in Boston&lt;/strong&gt;, and your chance to save ends soon. The event is just five days away, and prices rise at the door. Join the founders, VCs, and builders defining the future. Secure your pass now.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/5-days-until-techcrunch-all-stage-save-up-to-475-before-prices-rise/</guid><pubDate>Thu, 10 Jul 2025 18:00:00 +0000</pubDate></item><item><title>[NEW] Cops’ favorite AI tool automatically deletes evidence of when AI was used (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/cops-favorite-ai-tool-automatically-deletes-evidence-of-when-ai-was-used/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI police tool is designed to avoid accountability, watchdog says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          koya79 | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, a digital rights group, the Electronic Frontier Foundation, published an expansive investigation into AI-generated police reports that the group alleged are, by design, nearly impossible to audit and could make it easier for cops to lie under oath.&lt;/p&gt;
&lt;p&gt;Axon's Draft One debuted last summer at a police department in Colorado, instantly raising questions about the feared negative impacts of AI-written police reports on the criminal justice system. The tool relies on a ChatGPT variant to generate police reports based on body camera audio, which cops are then supposed to edit to correct any mistakes, assess the AI outputs for biases, or add key context.&lt;/p&gt;
&lt;p&gt;But the EFF found that the tech "seems designed to stymie any attempts at auditing, transparency, and accountability." Cops don't have to disclose when AI is used in every department, and Draft One does not save drafts or retain a record showing which parts of reports are AI-generated. Departments also don't retain different versions of drafts, making it difficult to assess how one version of an AI report might compare to another to help the public determine if the technology is "junk," the EFF said. That raises the question, the EFF suggested, "Why wouldn't an agency want to maintain a record that can establish the technology’s accuracy?"&lt;/p&gt;
&lt;p&gt;It's currently hard to know if cops are editing the reports or "reflexively rubber-stamping the drafts to move on as quickly as possible," the EFF said. That's particularly troubling, the EFF noted, since Axon disclosed to at least one police department that "there has already been an occasion when engineers discovered a bug that allowed officers on at least three occasions to circumvent the 'guardrails' that supposedly deter officers from submitting AI-generated reports without reading them first."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The AI tool could also possibly be "overstepping in its interpretation of the audio," possibly misinterpreting slang or adding context that never happened.&lt;/p&gt;
&lt;p&gt;A "major concern," the EFF said, is that the AI reports can give cops a "smokescreen," perhaps even allowing them to dodge consequences for lying on the stand by blaming the AI tool for any "biased language, inaccuracies, misinterpretations, or lies" in their reports.&lt;/p&gt;
&lt;p&gt;"There’s no record showing whether the culprit was the officer or the AI," the EFF said. "This makes it extremely difficult if not impossible to assess how the system affects justice outcomes over time."&lt;/p&gt;
&lt;p&gt;According to the EFF, Draft One "seems deliberately designed to avoid audits that could provide any accountability to the public." In one video from a roundtable discussion the EFF reviewed, an Axon senior principal product manager for generative AI touted Draft One's disappearing drafts as a feature, explaining, "we don’t store the original draft and that’s by design and that’s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney’s offices."&lt;/p&gt;
&lt;p&gt;The EFF interpreted this to mean that "the last thing" that Axon wants "is for cops to have to provide that data to anyone (say, a judge, defense attorney or civil liberties non-profit)."&lt;/p&gt;
&lt;p&gt;"To serve and protect the public interest, the AI output must be continually and aggressively evaluated whenever and wherever it's used," the EFF said. "But Axon has intentionally made this difficult."&lt;/p&gt;
&lt;p&gt;The EFF is calling for a nationwide effort to monitor AI-generated police reports expected to be increasingly deployed in many cities over the next few years and published a guide to help journalists and others submit records requests to monitor police use in their area. But "unfortunately, obtaining these records isn't easy," the EFF's investigation confirmed. "In many cases, it's straight-up impossible."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;An Axon spokesperson provided a statement to Ars:&lt;/p&gt;
&lt;p&gt;"Draft One helps officers draft an initial report narrative strictly from the audio transcript of the body-worn camera recording and includes a range of safeguards, including mandatory human decision-making at crucial points and transparency about its use. Just as with narrative reports not generated by Draft One, officers remain fully responsible for the content. Every report must be edited, reviewed, and approved by a human officer, ensuring both accuracy and accountability. Draft One was designed to mirror the existing police narrative process—where, as has long been standard, only the final, approved report is saved and discoverable, not the interim edits, additions, or deletions made during officer or supervisor review.&lt;/p&gt;
&lt;p&gt;Since day one, whenever Draft One is used to generate an initial narrative, its use is stored in Axon Evidence’s unalterable digital audit trail,&amp;nbsp;which can be retrieved by agencies on any report. By default, each Draft One report also includes a customizable disclaimer, which can appear at the beginning or end of the report in accordance with agency policy.&amp;nbsp;We recently&amp;nbsp;added the ability for agencies to export Draft One usage reports—showing how many drafts have been generated and submitted per user—and to run reports on which specific evidence items were used with Draft One, further supporting transparency and oversight. Axon is committed to continuous collaboration with police agencies, prosecutors, defense attorneys, community advocates, and other stakeholders to gather input and guide the responsible evolution of Draft One and AI technologies in the justice system, including changes as laws evolve."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;“Police should not be using AI”&lt;/h2&gt;
&lt;p&gt;Expecting Axon's tool would likely spread fast—marketed as a supposedly time-saving add-on service to police departments that already rely on Axon for tasers and body cameras—EFF's senior policy analyst Matthew Guariglia told Ars that the EFF quickly formed a plan to track adoption of the new technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Over the spring, the EFF sent public records requests to dozens of police departments believed to be using Draft One. To craft the requests, they also reviewed Axon user manuals and other materials.&lt;/p&gt;
&lt;p&gt;In a press release, the EFF confirmed that the investigation "found the product offers meager oversight features," including a practically useless "audit log" function that seems contradictory to police norms surrounding data retention.&lt;/p&gt;
&lt;p&gt;Perhaps most glaringly, Axon's tool doesn't allow departments to "export a list of all police officers who have used Draft One," the EFF noted, or even "export a list of all reports created by Draft One, unless the department has customized its process." Instead, Axon only allows exports of basic logs showing actions taken on a particular report or an individual user's basic activity in the system, like logins and uploads. That makes it "near impossible to do even the most basic statistical analysis: how many officers are using the technology and how often," the EFF said.&lt;/p&gt;
&lt;p&gt;Any effort to crunch the numbers would be time-intensive, the EFF found. In some departments, it's possible to look up individual cops' records to determine when they used Draft One, but that "could mean combing through dozens, hundreds, or in some cases, thousands of individual user logs." And it would take a similarly "massive amount of time" to sort through reports one by one, considering "the sheer number of reports generated" by any given agency, the EFF noted.&lt;/p&gt;
&lt;p&gt;In some jurisdictions, cops are required to disclose when AI is used to generate reports. And some departments require it, the EFF found, which made the documents more easily searchable and in turn made some police departments more likely to respond to public records requests without charging excessive fees or requiring substantial delays. But at least one department in Indiana told the EFF that "we do not have the ability to create a list of reports created through Draft One. They are not searchable."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While not every cop can search their Draft One reports, Axon can, the EFF reported, suggesting that the company can track how much police use the tool better than police themselves can.&lt;/p&gt;
&lt;p&gt;The EFF hopes its reporting will curtail the growing reliance on shady AI-generated police reports, which Guariglia told Ars risk becoming even more common in US policing without intervention.&lt;/p&gt;
&lt;p&gt;In California, where some cops have long been using Draft One, a bill has been introduced that would require disclosures clarifying which parts of police reports are AI-generated. That law, if passed, would also "require the first draft created to be retained for as long as the final report is retained," which Guariglia told Ars would make Draft One automatically unlawful as currently designed. Utah is weighing a similar but less robust initiative, the EFF noted.&lt;/p&gt;
&lt;p&gt;Guariglia told Ars that the EFF has talked to public defenders who worry how the proliferation of AI-generated police reports is "going to affect cross-examination" by potentially giving cops an easy scapegoat when accused of lying on the stand.&lt;/p&gt;
&lt;p&gt;To avoid the issue entirely, at least one district attorney's office in King County, Washington, has banned AI police reports, citing "legitimate concerns about some of the products on the market now." Guariglia told Ars that one of the district attorney's top concerns was that using the AI tool could "jeopardize cases." The EFF is now urging "other prosecutors to follow suit and demand that police in their jurisdiction not unleash this new, unaccountable, and intentionally opaque AI product."&lt;/p&gt;
&lt;p&gt;"Police should not be using AI to write police reports," Guariglia said. "There are just too many questions left unanswered about how AI would translate the audio of situations, whether police will actually edit those drafts, and whether the public will ever be able to tell what was written by a person and what was written by a computer. This is before we even get to the question of how these reports might lead to problems in an already unfair and untransparent criminal justice system."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story was updated to include a statement from Axon.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI police tool is designed to avoid accountability, watchdog says.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-153523633-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          koya79 | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, a digital rights group, the Electronic Frontier Foundation, published an expansive investigation into AI-generated police reports that the group alleged are, by design, nearly impossible to audit and could make it easier for cops to lie under oath.&lt;/p&gt;
&lt;p&gt;Axon's Draft One debuted last summer at a police department in Colorado, instantly raising questions about the feared negative impacts of AI-written police reports on the criminal justice system. The tool relies on a ChatGPT variant to generate police reports based on body camera audio, which cops are then supposed to edit to correct any mistakes, assess the AI outputs for biases, or add key context.&lt;/p&gt;
&lt;p&gt;But the EFF found that the tech "seems designed to stymie any attempts at auditing, transparency, and accountability." Cops don't have to disclose when AI is used in every department, and Draft One does not save drafts or retain a record showing which parts of reports are AI-generated. Departments also don't retain different versions of drafts, making it difficult to assess how one version of an AI report might compare to another to help the public determine if the technology is "junk," the EFF said. That raises the question, the EFF suggested, "Why wouldn't an agency want to maintain a record that can establish the technology’s accuracy?"&lt;/p&gt;
&lt;p&gt;It's currently hard to know if cops are editing the reports or "reflexively rubber-stamping the drafts to move on as quickly as possible," the EFF said. That's particularly troubling, the EFF noted, since Axon disclosed to at least one police department that "there has already been an occasion when engineers discovered a bug that allowed officers on at least three occasions to circumvent the 'guardrails' that supposedly deter officers from submitting AI-generated reports without reading them first."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The AI tool could also possibly be "overstepping in its interpretation of the audio," possibly misinterpreting slang or adding context that never happened.&lt;/p&gt;
&lt;p&gt;A "major concern," the EFF said, is that the AI reports can give cops a "smokescreen," perhaps even allowing them to dodge consequences for lying on the stand by blaming the AI tool for any "biased language, inaccuracies, misinterpretations, or lies" in their reports.&lt;/p&gt;
&lt;p&gt;"There’s no record showing whether the culprit was the officer or the AI," the EFF said. "This makes it extremely difficult if not impossible to assess how the system affects justice outcomes over time."&lt;/p&gt;
&lt;p&gt;According to the EFF, Draft One "seems deliberately designed to avoid audits that could provide any accountability to the public." In one video from a roundtable discussion the EFF reviewed, an Axon senior principal product manager for generative AI touted Draft One's disappearing drafts as a feature, explaining, "we don’t store the original draft and that’s by design and that’s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney’s offices."&lt;/p&gt;
&lt;p&gt;The EFF interpreted this to mean that "the last thing" that Axon wants "is for cops to have to provide that data to anyone (say, a judge, defense attorney or civil liberties non-profit)."&lt;/p&gt;
&lt;p&gt;"To serve and protect the public interest, the AI output must be continually and aggressively evaluated whenever and wherever it's used," the EFF said. "But Axon has intentionally made this difficult."&lt;/p&gt;
&lt;p&gt;The EFF is calling for a nationwide effort to monitor AI-generated police reports expected to be increasingly deployed in many cities over the next few years and published a guide to help journalists and others submit records requests to monitor police use in their area. But "unfortunately, obtaining these records isn't easy," the EFF's investigation confirmed. "In many cases, it's straight-up impossible."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;An Axon spokesperson provided a statement to Ars:&lt;/p&gt;
&lt;p&gt;"Draft One helps officers draft an initial report narrative strictly from the audio transcript of the body-worn camera recording and includes a range of safeguards, including mandatory human decision-making at crucial points and transparency about its use. Just as with narrative reports not generated by Draft One, officers remain fully responsible for the content. Every report must be edited, reviewed, and approved by a human officer, ensuring both accuracy and accountability. Draft One was designed to mirror the existing police narrative process—where, as has long been standard, only the final, approved report is saved and discoverable, not the interim edits, additions, or deletions made during officer or supervisor review.&lt;/p&gt;
&lt;p&gt;Since day one, whenever Draft One is used to generate an initial narrative, its use is stored in Axon Evidence’s unalterable digital audit trail,&amp;nbsp;which can be retrieved by agencies on any report. By default, each Draft One report also includes a customizable disclaimer, which can appear at the beginning or end of the report in accordance with agency policy.&amp;nbsp;We recently&amp;nbsp;added the ability for agencies to export Draft One usage reports—showing how many drafts have been generated and submitted per user—and to run reports on which specific evidence items were used with Draft One, further supporting transparency and oversight. Axon is committed to continuous collaboration with police agencies, prosecutors, defense attorneys, community advocates, and other stakeholders to gather input and guide the responsible evolution of Draft One and AI technologies in the justice system, including changes as laws evolve."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;“Police should not be using AI”&lt;/h2&gt;
&lt;p&gt;Expecting Axon's tool would likely spread fast—marketed as a supposedly time-saving add-on service to police departments that already rely on Axon for tasers and body cameras—EFF's senior policy analyst Matthew Guariglia told Ars that the EFF quickly formed a plan to track adoption of the new technology.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Over the spring, the EFF sent public records requests to dozens of police departments believed to be using Draft One. To craft the requests, they also reviewed Axon user manuals and other materials.&lt;/p&gt;
&lt;p&gt;In a press release, the EFF confirmed that the investigation "found the product offers meager oversight features," including a practically useless "audit log" function that seems contradictory to police norms surrounding data retention.&lt;/p&gt;
&lt;p&gt;Perhaps most glaringly, Axon's tool doesn't allow departments to "export a list of all police officers who have used Draft One," the EFF noted, or even "export a list of all reports created by Draft One, unless the department has customized its process." Instead, Axon only allows exports of basic logs showing actions taken on a particular report or an individual user's basic activity in the system, like logins and uploads. That makes it "near impossible to do even the most basic statistical analysis: how many officers are using the technology and how often," the EFF said.&lt;/p&gt;
&lt;p&gt;Any effort to crunch the numbers would be time-intensive, the EFF found. In some departments, it's possible to look up individual cops' records to determine when they used Draft One, but that "could mean combing through dozens, hundreds, or in some cases, thousands of individual user logs." And it would take a similarly "massive amount of time" to sort through reports one by one, considering "the sheer number of reports generated" by any given agency, the EFF noted.&lt;/p&gt;
&lt;p&gt;In some jurisdictions, cops are required to disclose when AI is used to generate reports. And some departments require it, the EFF found, which made the documents more easily searchable and in turn made some police departments more likely to respond to public records requests without charging excessive fees or requiring substantial delays. But at least one department in Indiana told the EFF that "we do not have the ability to create a list of reports created through Draft One. They are not searchable."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;While not every cop can search their Draft One reports, Axon can, the EFF reported, suggesting that the company can track how much police use the tool better than police themselves can.&lt;/p&gt;
&lt;p&gt;The EFF hopes its reporting will curtail the growing reliance on shady AI-generated police reports, which Guariglia told Ars risk becoming even more common in US policing without intervention.&lt;/p&gt;
&lt;p&gt;In California, where some cops have long been using Draft One, a bill has been introduced that would require disclosures clarifying which parts of police reports are AI-generated. That law, if passed, would also "require the first draft created to be retained for as long as the final report is retained," which Guariglia told Ars would make Draft One automatically unlawful as currently designed. Utah is weighing a similar but less robust initiative, the EFF noted.&lt;/p&gt;
&lt;p&gt;Guariglia told Ars that the EFF has talked to public defenders who worry how the proliferation of AI-generated police reports is "going to affect cross-examination" by potentially giving cops an easy scapegoat when accused of lying on the stand.&lt;/p&gt;
&lt;p&gt;To avoid the issue entirely, at least one district attorney's office in King County, Washington, has banned AI police reports, citing "legitimate concerns about some of the products on the market now." Guariglia told Ars that one of the district attorney's top concerns was that using the AI tool could "jeopardize cases." The EFF is now urging "other prosecutors to follow suit and demand that police in their jurisdiction not unleash this new, unaccountable, and intentionally opaque AI product."&lt;/p&gt;
&lt;p&gt;"Police should not be using AI to write police reports," Guariglia said. "There are just too many questions left unanswered about how AI would translate the audio of situations, whether police will actually edit those drafts, and whether the public will ever be able to tell what was written by a person and what was written by a computer. This is before we even get to the question of how these reports might lead to problems in an already unfair and untransparent criminal justice system."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This story was updated to include a statement from Axon.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/cops-favorite-ai-tool-automatically-deletes-evidence-of-when-ai-was-used/</guid><pubDate>Thu, 10 Jul 2025 21:12:26 +0000</pubDate></item><item><title>[NEW] Former Intel CEO launches a benchmark to measure AI alignment (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/former-intel-ceo-launches-a-benchmark-to-measure-ai-alignment/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/01/GettyImages-871704844.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After former Intel CEO Pat Gelsinger capped off a more than 40-year career at the semiconductor giant in December, many wondered where Gelsinger would go next. On Thursday, the former Intel CEO revealed one piece of his next chapter: trying to ensure AI models support a flourishing humanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In partnership with a “faith tech” company he first invested in roughly 10 years ago called Gloo, Gelsinger launched a new benchmark — Flourishing AI, or FAI — to test how well AI models align with certain human values. The FAI benchmark is based on The Global Flourishing Study, a survey directed by Harvard and Baylor University, to measure human well-being around the world.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gloo took six core categories from the study — Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability — and added one more, Faith and Spirituality, to test LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with The New Stack, Gelsinger said he’s “lived at the intersection of faith tech my entire life.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2021/01/GettyImages-871704844.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After former Intel CEO Pat Gelsinger capped off a more than 40-year career at the semiconductor giant in December, many wondered where Gelsinger would go next. On Thursday, the former Intel CEO revealed one piece of his next chapter: trying to ensure AI models support a flourishing humanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In partnership with a “faith tech” company he first invested in roughly 10 years ago called Gloo, Gelsinger launched a new benchmark — Flourishing AI, or FAI — to test how well AI models align with certain human values. The FAI benchmark is based on The Global Flourishing Study, a survey directed by Harvard and Baylor University, to measure human well-being around the world.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gloo took six core categories from the study — Character and Virtue, Close Social Relationships, Happiness and Life Satisfaction, Meaning and Purpose, Mental and Physical Health, Financial and Material Stability — and added one more, Faith and Spirituality, to test LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an interview with The New Stack, Gelsinger said he’s “lived at the intersection of faith tech my entire life.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/former-intel-ceo-launches-a-benchmark-to-measure-ai-alignment/</guid><pubDate>Thu, 10 Jul 2025 21:35:49 +0000</pubDate></item><item><title>[NEW] AWS doubles down on infrastructure as strategy in the AI race with SageMaker upgrades (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/aws-doubles-down-on-infrastructure-as-strategy-in-the-ai-race-with-sagemaker-upgrades/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AWS seeks to extend its market position with updates to SageMaker, its machine learning and AI model training and inference platform, adding new observability capabilities, connected coding environments and GPU cluster performance management.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS continues to face competition from Google and Microsoft, which also offer many features that help accelerate AI training and inference.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker, which transformed into a unified hub for integrating data sources and accessing machine learning tools in 2024, will add features that provide insight into why model performance slows and offer AWS customers more control over the amount of compute allocated for model development.&lt;/p&gt;



&lt;p&gt;Other new features include connecting local integrated development environments (IDEs) to SageMaker, so locally written AI projects can be deployed on the platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker General Manager Ankur Mehrotra told VentureBeat that many of these new updates originated from customers themselves.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“One challenge that we’ve seen our customers face while developing Gen AI models is that when something goes wrong or when something is not working as per the expectation, it’s really hard to find what’s going on in that layer of the stack,” Mehrotra said.&lt;/p&gt;



&lt;p&gt;SageMaker HyperPod observability enables engineers to examine the various layers of the stack, such as the compute layer or networking layer. If anything goes wrong or models become slower, SageMaker can alert them and publish metrics on a dashboard.&lt;/p&gt;



&lt;p&gt;Mehrotra pointed to a real issue his own team faced while training new models, where training code began stressing GPUs, causing temperature fluctuations. He said that without the latest tools, developers would have taken weeks to identify the source of the issue and then fix it.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-connected-ides"&gt;Connected IDEs&lt;/h2&gt;



&lt;p&gt;SageMaker already offered two ways for AI developers to train and run models. It had access to fully managed IDEs, such as Jupyter Lab or Code Editor, to seamlessly run the training code on the models through SageMaker. Understanding that other engineers prefer to use their local IDEs, including all the extensions they have installed, AWS allowed them to run their code on their machines as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Mehrotra pointed out that it meant locally coded models only ran locally, so if developers wanted to scale, it proved to be a significant challenge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AWS added new secure remote execution to allow customers to continue working on their preferred IDE — either locally or managed — and connect ot to SageMaker.&lt;/p&gt;



&lt;p&gt;“So this capability now gives them the best of both worlds where if they want, they can develop locally on a local IDE, but then in terms of actual task execution, they can benefit from the scalability of SageMaker,” he said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-flexibility-in-compute"&gt;More flexibility in compute&lt;/h2&gt;



&lt;p&gt;AWS launched SageMaker HyperPod in December 2023 as a means to help customers manage clusters of servers for training models. Similar to providers like CoreWeave, HyperPod enables SageMaker customers to direct unused compute power to their preferred location. HyperPod knows when to schedule GPU usage based on demand patterns and allows organizations to balance their resources and costs effectively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS said many customers wanted the same service for inference. Many inference tasks occur during the day when people use models and applications, while training is usually scheduled during off-peak hours.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Mehrotra noted that even in the world inference, developers can prioritize the inference tasks that HyperPod should focus on.&lt;/p&gt;



&lt;p&gt;Laurent Sifre, co-founder and CTO at AI agent company H AI, said in an AWS blog post that the company used SageMaker HyperPod when building out its agentic platform.&lt;/p&gt;



&lt;p&gt;“This seamless transition from training to inference streamlined our workflow, reduced time to production, and delivered consistent performance in live environments,” Sifre said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aws-and-the-competition"&gt;AWS and the competition&lt;/h2&gt;



&lt;p&gt;Amazon may not be offering the splashiest foundation models like its cloud provider rivals, Google and Microsoft. Still, AWS has been more focused on providing the infrastructure backbone for enterprises to build AI models, applications, or agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In addition to SageMaker, AWS also offers Bedrock, a platform specifically designed for building applications and agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker has been around for years, initially serving as a means to connect disparate machine learning tools to data lakes. As the generative AI boom began, AI engineers began using SageMaker to help train language models. However, Microsoft is pushing hard for its Fabric ecosystem, with 70% of Fortune 500 companies adopting it, to become a leader in the data and AI acceleration space. Google, through Vertex AI, has quietly made inroads in enterprise AI adoption.&lt;/p&gt;



&lt;p&gt;AWS, of course, has the advantage of being the most widely used cloud provider. Any updates that would make its many AI infrastructure platforms easier to use will always be a benefit.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AWS seeks to extend its market position with updates to SageMaker, its machine learning and AI model training and inference platform, adding new observability capabilities, connected coding environments and GPU cluster performance management.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS continues to face competition from Google and Microsoft, which also offer many features that help accelerate AI training and inference.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker, which transformed into a unified hub for integrating data sources and accessing machine learning tools in 2024, will add features that provide insight into why model performance slows and offer AWS customers more control over the amount of compute allocated for model development.&lt;/p&gt;



&lt;p&gt;Other new features include connecting local integrated development environments (IDEs) to SageMaker, so locally written AI projects can be deployed on the platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker General Manager Ankur Mehrotra told VentureBeat that many of these new updates originated from customers themselves.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“One challenge that we’ve seen our customers face while developing Gen AI models is that when something goes wrong or when something is not working as per the expectation, it’s really hard to find what’s going on in that layer of the stack,” Mehrotra said.&lt;/p&gt;



&lt;p&gt;SageMaker HyperPod observability enables engineers to examine the various layers of the stack, such as the compute layer or networking layer. If anything goes wrong or models become slower, SageMaker can alert them and publish metrics on a dashboard.&lt;/p&gt;



&lt;p&gt;Mehrotra pointed to a real issue his own team faced while training new models, where training code began stressing GPUs, causing temperature fluctuations. He said that without the latest tools, developers would have taken weeks to identify the source of the issue and then fix it.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-connected-ides"&gt;Connected IDEs&lt;/h2&gt;



&lt;p&gt;SageMaker already offered two ways for AI developers to train and run models. It had access to fully managed IDEs, such as Jupyter Lab or Code Editor, to seamlessly run the training code on the models through SageMaker. Understanding that other engineers prefer to use their local IDEs, including all the extensions they have installed, AWS allowed them to run their code on their machines as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Mehrotra pointed out that it meant locally coded models only ran locally, so if developers wanted to scale, it proved to be a significant challenge.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;AWS added new secure remote execution to allow customers to continue working on their preferred IDE — either locally or managed — and connect ot to SageMaker.&lt;/p&gt;



&lt;p&gt;“So this capability now gives them the best of both worlds where if they want, they can develop locally on a local IDE, but then in terms of actual task execution, they can benefit from the scalability of SageMaker,” he said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-more-flexibility-in-compute"&gt;More flexibility in compute&lt;/h2&gt;



&lt;p&gt;AWS launched SageMaker HyperPod in December 2023 as a means to help customers manage clusters of servers for training models. Similar to providers like CoreWeave, HyperPod enables SageMaker customers to direct unused compute power to their preferred location. HyperPod knows when to schedule GPU usage based on demand patterns and allows organizations to balance their resources and costs effectively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, AWS said many customers wanted the same service for inference. Many inference tasks occur during the day when people use models and applications, while training is usually scheduled during off-peak hours.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Mehrotra noted that even in the world inference, developers can prioritize the inference tasks that HyperPod should focus on.&lt;/p&gt;



&lt;p&gt;Laurent Sifre, co-founder and CTO at AI agent company H AI, said in an AWS blog post that the company used SageMaker HyperPod when building out its agentic platform.&lt;/p&gt;



&lt;p&gt;“This seamless transition from training to inference streamlined our workflow, reduced time to production, and delivered consistent performance in live environments,” Sifre said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-aws-and-the-competition"&gt;AWS and the competition&lt;/h2&gt;



&lt;p&gt;Amazon may not be offering the splashiest foundation models like its cloud provider rivals, Google and Microsoft. Still, AWS has been more focused on providing the infrastructure backbone for enterprises to build AI models, applications, or agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In addition to SageMaker, AWS also offers Bedrock, a platform specifically designed for building applications and agents.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;SageMaker has been around for years, initially serving as a means to connect disparate machine learning tools to data lakes. As the generative AI boom began, AI engineers began using SageMaker to help train language models. However, Microsoft is pushing hard for its Fabric ecosystem, with 70% of Fortune 500 companies adopting it, to become a leader in the data and AI acceleration space. Google, through Vertex AI, has quietly made inroads in enterprise AI adoption.&lt;/p&gt;



&lt;p&gt;AWS, of course, has the advantage of being the most widely used cloud provider. Any updates that would make its many AI infrastructure platforms easier to use will always be a benefit.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/aws-doubles-down-on-infrastructure-as-strategy-in-the-ai-race-with-sagemaker-upgrades/</guid><pubDate>Thu, 10 Jul 2025 21:37:51 +0000</pubDate></item><item><title>[NEW] Where AI meets design: Runway co-founder Alejandro Matamala Ortiz takes the AI Stage at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/where-ai-meets-design-runway-co-founder-alejandro-matamala-ortiz-takes-the-ai-stage-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is the epicenter where 10,000+ startup and VC leaders gather to explore the future of innovation — and this year, two AI Stages bring the intersection of design and machine learning into sharp focus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’re thrilled to welcome Alejandro Matamala Ortiz, co-founder and chief design officer at Runway, to one of the AI Stages at Disrupt 2025, taking place October 27–29 in San Francisco. As part of a can’t-miss panel conversation, Ortiz will share how design principles are guiding the next generation of generative AI tools — and how his team at Runway is redefining what creativity looks like in the age of machines.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Alejandro Matamala Ortiz" class="wp-image-3026782" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Alejandro-Matamala-Ortiz-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-attend-this-session"&gt;Why attend this session?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Expect fresh, actionable insights into how creative professionals and technologists can work together to build tools that empower — not replace — human expression. Ortiz will offer a design-first perspective on building intuitive, artist-friendly AI experiences that are already transforming industries, from film to marketing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prior to co-founding Runway, Ortiz was a research resident at New York University, where he studied the interaction between artificial intelligence and creativity. Today he leads the company’s vision for accessible, cutting-edge creative software that’s shaping how the world imagines and produces content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join us on one of the AI Stages and the other five industry stages at Disrupt 2025 to hear from Matamala Ortiz and other leaders who are building the creative engines of tomorrow. &lt;strong&gt;Buy your ticket now and save up to $625.&lt;/strong&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; is the epicenter where 10,000+ startup and VC leaders gather to explore the future of innovation — and this year, two AI Stages bring the intersection of design and machine learning into sharp focus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’re thrilled to welcome Alejandro Matamala Ortiz, co-founder and chief design officer at Runway, to one of the AI Stages at Disrupt 2025, taking place October 27–29 in San Francisco. As part of a can’t-miss panel conversation, Ortiz will share how design principles are guiding the next generation of generative AI tools — and how his team at Runway is redefining what creativity looks like in the age of machines.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Alejandro Matamala Ortiz" class="wp-image-3026782" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/TC25_-Alejandro-Matamala-Ortiz-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-why-attend-this-session"&gt;Why attend this session?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Expect fresh, actionable insights into how creative professionals and technologists can work together to build tools that empower — not replace — human expression. Ortiz will offer a design-first perspective on building intuitive, artist-friendly AI experiences that are already transforming industries, from film to marketing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Prior to co-founding Runway, Ortiz was a research resident at New York University, where he studied the interaction between artificial intelligence and creativity. Today he leads the company’s vision for accessible, cutting-edge creative software that’s shaping how the world imagines and produces content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Join us on one of the AI Stages and the other five industry stages at Disrupt 2025 to hear from Matamala Ortiz and other leaders who are building the creative engines of tomorrow. &lt;strong&gt;Buy your ticket now and save up to $625.&lt;/strong&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/where-ai-meets-design-runway-co-founder-alejandro-matamala-ortiz-takes-the-ai-stage-at-techcrunch-disrupt-2025/</guid><pubDate>Thu, 10 Jul 2025 22:45:00 +0000</pubDate></item><item><title>[NEW] AWS is launching an AI agent marketplace next week with Anthropic as a partner (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/aws-is-launching-an-ai-agent-marketplace-next-week-with-anthropic-as-a-partner/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/AWS-re-Invent-2021.jpeg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services (AWS) is launching an AI agent marketplace next week and Anthropic is one of its partners, TechCrunch has exclusively learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AWS agent marketplace launch will take place at the AWS Summit in New York City on July 15, two people familiar with the development told TechCrunch. AWS and Anthropic did not respond to requests for comments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI agents are ubiquitous nowadays. And every single investor in Silicon Valley is bullish on startups building them — even if there is some disagreement on exactly what defines an AI agent. The term is somewhat ambiguous and is loosely used to describe computer programs that can make decisions and perform tasks independently, such as interacting with software, by using an AI model at the backend. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI behemoths such as OpenAI and Anthropic are promoting it as the next big thing in tech. However, the distribution of AI agents poses a challenge, as most companies offer them in silos. AWS appears to be taking a step to address this with its new move.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s dedicated agent marketplace will allow startups to directly offer their AI agents to AWS customers. The marketplace will also allow enterprise customers to browse, install, and look for AI agents based on their requirements from a single location, a source said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That could give Anthropic — and other AWS agent marketplace partners — a considerable boost. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, which already has Amazon’s backing and is reportedly in line for another multibillion-dollar investment from the e-commerce company, views AI’s future primarily in terms of agents —&amp;nbsp;at least for the coming years. Anthropic builds AI agents in-house and enables developers to create them using its API.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AWS’ marketplace would help Anthropic reach more customers, including those who may already use AI agents from its rivals, such as OpenAI. Anthropic’s involvement in the marketplace could also attract more developers to use its API to create more agents, and eventually increase its revenues. The company already hit $3 billion in annualized revenue in late May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like any other online marketplace, AWS will take a cut of the revenue that startups earn from agent installations. However, this share will be minimal compared to the marketplace’s potential to unlock new revenue streams and attract customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The marketplace model will allow startups to charge customers for agents. The structure is similar to how a marketplace might price SaaS offerings rather than bundling them into broader services, one of the sources said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon is not the first tech giant to offer a marketplace for agents. In April, Google Cloud introduced an AI Agent Marketplace to help developers and businesses list, buy, and sell AI agents. Microsoft also introduced a similar offering, called Agent Store, within Microsoft 365 Copilot a month later. Similarly, enterprise software providers, including Salesforce and ServiceNow, have their own agent marketplaces.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, we have yet to see how successful these marketplaces are for smaller AI startups and enterprises seeking specific AI agents.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/AWS-re-Invent-2021.jpeg?resize=1200,673" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services (AWS) is launching an AI agent marketplace next week and Anthropic is one of its partners, TechCrunch has exclusively learned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AWS agent marketplace launch will take place at the AWS Summit in New York City on July 15, two people familiar with the development told TechCrunch. AWS and Anthropic did not respond to requests for comments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI agents are ubiquitous nowadays. And every single investor in Silicon Valley is bullish on startups building them — even if there is some disagreement on exactly what defines an AI agent. The term is somewhat ambiguous and is loosely used to describe computer programs that can make decisions and perform tasks independently, such as interacting with software, by using an AI model at the backend. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI behemoths such as OpenAI and Anthropic are promoting it as the next big thing in tech. However, the distribution of AI agents poses a challenge, as most companies offer them in silos. AWS appears to be taking a step to address this with its new move.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s dedicated agent marketplace will allow startups to directly offer their AI agents to AWS customers. The marketplace will also allow enterprise customers to browse, install, and look for AI agents based on their requirements from a single location, a source said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That could give Anthropic — and other AWS agent marketplace partners — a considerable boost. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, which already has Amazon’s backing and is reportedly in line for another multibillion-dollar investment from the e-commerce company, views AI’s future primarily in terms of agents —&amp;nbsp;at least for the coming years. Anthropic builds AI agents in-house and enables developers to create them using its API.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AWS’ marketplace would help Anthropic reach more customers, including those who may already use AI agents from its rivals, such as OpenAI. Anthropic’s involvement in the marketplace could also attract more developers to use its API to create more agents, and eventually increase its revenues. The company already hit $3 billion in annualized revenue in late May.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like any other online marketplace, AWS will take a cut of the revenue that startups earn from agent installations. However, this share will be minimal compared to the marketplace’s potential to unlock new revenue streams and attract customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The marketplace model will allow startups to charge customers for agents. The structure is similar to how a marketplace might price SaaS offerings rather than bundling them into broader services, one of the sources said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon is not the first tech giant to offer a marketplace for agents. In April, Google Cloud introduced an AI Agent Marketplace to help developers and businesses list, buy, and sell AI agents. Microsoft also introduced a similar offering, called Agent Store, within Microsoft 365 Copilot a month later. Similarly, enterprise software providers, including Salesforce and ServiceNow, have their own agent marketplaces.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, we have yet to see how successful these marketplaces are for smaller AI startups and enterprises seeking specific AI agents.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/aws-is-launching-an-ai-agent-marketplace-next-week-with-anthropic-as-a-partner/</guid><pubDate>Thu, 10 Jul 2025 22:59:26 +0000</pubDate></item><item><title>[NEW] $8.8 trillion protected: How one CISO went from ‘that’s BS’ to bulletproof in 90 days (AI News | VentureBeat)</title><link>https://venturebeat.com/security/ciso-dodges-bullet-protecting-8-8-trillion-from-shadow-ai/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat’s exclusive interview with Sam Evans, CISO of Clearwater Analytics, reveals why enterprise browsers are quickly becoming the frontline defense against shadow AI in its many forms.&amp;nbsp; &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Evans faced a critical challenge in October 2023. Standing before Clearwater Analytics’ board, he had to confront concerns that employees might inadvertently expose data that could potentially compromise the firm’s $8.8 trillion assets under management. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage,” Evans told VentureBeat. “The employee not knowing any different or trying to solve a problem for a customer…that data helps train the model.”&lt;/p&gt;



&lt;p&gt;Here is our conversation with Evans, edited for length and clarity&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you see AI shaping cybersecurity today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The attacks have become significantly more sophisticated. If you consider it from the perspective of a bad actor, the phishing emails and attempts we receive have become much more complex. However, AI also possesses response capabilities.&lt;/p&gt;



&lt;p&gt;I like to explain it to our board, as the ultimate cat-and-mouse game. As bad actors start to use AI to advance phishing, or perhaps expedite the time it takes for exploits to emerge after vulnerabilities are announced, there’s the opposite side of security practitioners using AI to help advance how we respond.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How is AI helping your defensive capabilities?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; We’ve begun integrating AI into our security playbooks. By doing so, our security analysts now spend less time searching and hunting. The AI is involved in the security operations center (SOC) product, conducting its initial triage analysis and saying, “Based on previous things that we’ve seen and things in my model, this is where I’d like to guide you.”&lt;/p&gt;



&lt;p&gt;On the defensive side, we’re really starting to see AI come into play. CrowdStrike, Sentinel One, Microsoft Defender, the traditional extended detection and response (EDR) products were using some machine learning, and they would get to a probability of maybe 85% that this could be a threat, but we’re not really sure. However, AI enriches the EDR engine’s ability to reach a higher probability rate of identifying a threat.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: W&lt;/strong&gt;hat keeps you up at night when it comes to AI and cybersecurity?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The thing that does worry me quite a bit is the deepfakes. You read multiple stories about people using deepfakes to impersonate a CEO to initiate wire transfers. Those are concerning because they do look very, very real.&lt;/p&gt;



&lt;p&gt;But the biggest concern? The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage, and then it becomes data that helps train the model.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How did you explain this shadow AI risk to your board?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; I remember when one of the first board meetings I was in, they asked me, “So what are your thoughts on ChatGPT?” I said, “Well, it’s an incredible productivity tool. However, I don’t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it, or our source code, which is our intellectual property.”&lt;/p&gt;



&lt;p&gt;But I didn’t just come to the board with my concerns and problems. I said, “Well, here’s my solution. I don’t want to stop people from being productive, but I also want to protect it.” When I came to the board and explained how these enterprise browsers work, they’re like, “Okay, that makes much sense, but can you really do it?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Walk me through your evaluation and deployment process for Island.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; After that October 2023 board meeting, we started a pretty long due diligence process. We took a look at some of the major vendors in the enterprise browser space.&lt;/p&gt;



&lt;p&gt;I’ll share with you ultimately why we went with an Island. We needed to be able to control what browsers people are using on their endpoints. It doesn’t do any good to deploy an enterprise browser when somebody can go and download Opera or “Frank’s browser of the month” and use it, and it just bypasses all of the Island controls.&lt;/p&gt;



&lt;p&gt;The other reason we went with Island was truly because of the speed of the deployment. I remember being on a call with Island salespeople, and they’re saying, “We believe we can get this deployed in your company in a matter of weeks.” I’m like, “Oh, that’s BS.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;But they delivered?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; They took it as a personal challenge! We started our Island deployment in April 2024 with about 200 people. We went the extension route first; the Island extension in Chrome and Edge.&lt;/p&gt;



&lt;p&gt;It wasn’t until July when the board asked, “How is it going?” And I said, “How about I just show you?” I pulled up a screenshot because, you know, Murphy’s Law demos always fail. So I showed them screenshots, “Here I am on ChatGPT. I tried to paste something in. I got the prompt: ‘Island policy prevents you from doing this.'”&lt;/p&gt;



&lt;p&gt;They’re like, “Wow, this is fantastic! But people can still utilize the tool to ask good questions?” I said, “Yeah, absolutely. They just can’t put data into it.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Do you feel that Island assures you and reduces the risk of Shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; It definitely has helped us get a handle on shadow AI. No security tool is 100% perfect. Having deployed Island, we definitely sleep a lot easier. We can feel reasonably comfortable that if an employee is going to an AI instance that we don’t have licensed, they can use it, but can’t paste data or upload files.&lt;/p&gt;



&lt;p&gt;It’s also helped us identify where we have gaps. Employees found this really great AI widget thing, they come to the security team, “Hey, look, check this out.” And then we can come back to our product development teams and figure out how we help enable this, not just for our employees, but for our customers.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you defend against deepfakes?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; That’s a tough one to wrap your arms around. We have an excellent security awareness program. We ask employees to use common sense. Do you really think Sandeep Sahai, our CEO, is going to call you up and ask you to buy him Apple gift cards?&lt;/p&gt;



&lt;p&gt;We’ve set up a lot of checks and balances, kind of like the two-person buddy check system. There’s no technology solution for something like that. It’s a human problem that we’ve had to implement a human solution.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;What advice would you give other CISOs facing shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; This isn’t just about blocking, it’s about enablement. Bring solutions, not just problems. When I came to the board, I didn’t just highlight the risks; I proposed a solution that balanced security with productivity.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-shadow-ai-arms-race"&gt;Welcome to the shadow AI arms race &lt;/h2&gt;



&lt;p&gt;Evans’ insights reveal how quickly shadow AI has become an existential threat to every data-intensive business. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We see 50 new AI apps a day, and we’ve already cataloged over 12,000,” Itamar Golan, CEO of Prompt Security, told VentureBeat, quantifying what security teams are calling their worst nightmare since ransomware.&lt;/p&gt;



&lt;p&gt;The onslaught of unauthorized AI use and apps has triggered intense competition among security vendors. “Most traditional management tools lack comprehensive visibility into AI apps,” Vineet Arora, CTO of WinWire, explained to VentureBeat, pinpointing exactly why shadow AI flourishes as legacy security architectures are blind to it.&lt;/p&gt;



&lt;p&gt;The vendor ecosystem has crystallized into four distinct battlegrounds, each with its weapons and weaknesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Enterprise browsers lead the charge.&lt;/strong&gt; Foremost among them is Island, which recently raised a $250 million funding round, a vote of confidence from the investor community. While Island bets on pre-encryption visibility, Google Chrome Enterprise attacks shadow AI differently, weaponizing its market dominance and Google’s security stack. Chrome Enterprise Premium delivers data loss prevention (DLP) controls that block data flows to ChatGPT and other AI tools, prevent cross-profile contamination and enforce real-time content scanning. The platform exposes shadow AI usage patterns while blocking both accidental pastes and deliberate exfiltration. Strategic partnerships with Zscaler and Cisco Secure Access amplify Chrome’s reach to create an ecosystem where zero-trust principles extend directly to AI interactions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SASE/SSE platforms deliver enterprise-scale defense. &lt;/strong&gt;Netskope and Zscaler bring scale to shadow AI defense through their cloud-native security access service edge (SASE) architectures. Both platforms process billions of transactions daily across global infrastructures, with Netskope specifically advertising its ability to monitor AI application usage across enterprises. Their key limitation: When 73.8% of workplace ChatGPT usage occurs through personal accounts, SSL/TLS encryption prevents platforms from inspecting content, forcing them to rely on traffic patterns and metadata, leading to visibility gaps where shadow AI operates undetected&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Traditional DLP vendors struggle to adapt&lt;/strong&gt;. Legacy vendors Forcepoint and Microsoft Purview have a strong legacy to trade on when it comes to battling shadow AI. Forcepoint claims 1,700-plus classifiers while Purview leverages AI to triage tasks. But here’s the problem: They’re retrofitting 20th-century architectures for 21st-century threats. These platforms excel at compliance checkboxes and policy templates but fail to keep up with AI’s quicker pace. &lt;/p&gt;



&lt;p&gt;As Daren Goeson, Ivanti’s SVP of product management for UEM told VentureBeat: “AI-powered endpoint security tools can analyze vast amounts of data to detect anomalies and predict potential threats faster and more accurately than any human analyst.” Traditional DLP operates at audit speed. Shadow AI moves at machine speed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Specialized solutions fill critical gaps&lt;/strong&gt;. Innovation thrives in the niches that legacy vendors ignore. One example is Ivanti Neurons, which delivers comprehensive device discovery through its UEM platform, exposing shadow AI hiding in endpoints that traditional tools miss. Mike Riemer, Ivanti’s Field CISO, sees the bigger picture: “Security professionals will effectively leverage the capabilities of gen AI to analyze vast amounts of data collected from diverse systems.” Nightfall, for its part, targets developer teams with transformer models, claiming 2x detection accuracy for API based AI tools.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Comparing Shadow AI Defense Solutions&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;&lt;a&gt;Vendor&lt;/td&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Key Strengths&lt;/td&gt;&lt;td&gt;Limitations&lt;/td&gt;&lt;td&gt;Best For&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Check Point Harmony&lt;/td&gt;&lt;td&gt;Browser extension&lt;/td&gt;&lt;td&gt;Leverages existing infrastructure&lt;/td&gt;&lt;td&gt;Limited to extension&lt;/td&gt;&lt;td&gt;Check Point customers&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Forcepoint&lt;/td&gt;&lt;td&gt;Traditional DLP&lt;/td&gt;&lt;td&gt;1,700+ classifiers, regulatory compliance&lt;/td&gt;&lt;td&gt;Legacy architecture&lt;/td&gt;&lt;td&gt;Highly regulated industries&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google Chrome Enterprise&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Market dominance, native integration&lt;/td&gt;&lt;td&gt;Less specialized controls&lt;/td&gt;&lt;td&gt;Google Workspace organizations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Island&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Pre-encryption visibility, zero latency, Rapid deployment&lt;/td&gt;&lt;td&gt;Higher cost per user&lt;/td&gt;&lt;td&gt;Enterprises with sensitive data&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ivanti Neurons&lt;/td&gt;&lt;td&gt;UEM Platform&lt;/td&gt;&lt;td&gt;Comprehensive device discovery&lt;/td&gt;&lt;td&gt;Not browser-specific&lt;/td&gt;&lt;td&gt;Asset management focus&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Microsoft Purview&lt;/td&gt;&lt;td&gt;DLP Platform&lt;/td&gt;&lt;td&gt;Native Microsoft integration, AI-powered triage&lt;/td&gt;&lt;td&gt;Microsoft-centric&lt;/td&gt;&lt;td&gt;Microsoft 365 enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Netskope&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;Comprehensive coverage, 370+ AI app monitoring&lt;/td&gt;&lt;td&gt;Post-encryption complexity&lt;/td&gt;&lt;td&gt;Large distributed enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Nightfall&lt;/td&gt;&lt;td&gt;AI-Native DLP&lt;/td&gt;&lt;td&gt;2x detection accuracy, Transformer models&lt;/td&gt;&lt;td&gt;API-only approach&lt;/td&gt;&lt;td&gt;Developer-centric teams&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Talon Cyber Security&lt;/td&gt;&lt;td&gt;Enterprise Browser&lt;/td&gt;&lt;td&gt;Browser + extension options&lt;/td&gt;&lt;td&gt;Newer to market&lt;/td&gt;&lt;td&gt;Security-conscious SMBs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Zscaler&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;536B daily transactions, true zero-trust&lt;/td&gt;&lt;td&gt;Cloud-only approach&lt;/td&gt;&lt;td&gt;Cloud-first organizations&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;VentureBeat analysis&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;What’s driving the market to move so fast? VentureBeat’s analysis found 74,500-plus shadow AI apps actively deployed across major consulting firms alone, and that’s growing 5% monthly. By mid-2026, that number could hit 160,000. Each represents a potential data breach, compliance violation, or competitive intelligence leak.&lt;/p&gt;



&lt;p&gt;Arora’s prescription cuts through vendor hype: “Organizations must define strategies with robust security while enabling employees to use AI technologies effectively. Total bans often drive AI use underground, which only magnifies the risks.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat’s exclusive interview with Sam Evans, CISO of Clearwater Analytics, reveals why enterprise browsers are quickly becoming the frontline defense against shadow AI in its many forms.&amp;nbsp; &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Evans faced a critical challenge in October 2023. Standing before Clearwater Analytics’ board, he had to confront concerns that employees might inadvertently expose data that could potentially compromise the firm’s $8.8 trillion assets under management. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage,” Evans told VentureBeat. “The employee not knowing any different or trying to solve a problem for a customer…that data helps train the model.”&lt;/p&gt;



&lt;p&gt;Here is our conversation with Evans, edited for length and clarity&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you see AI shaping cybersecurity today?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The attacks have become significantly more sophisticated. If you consider it from the perspective of a bad actor, the phishing emails and attempts we receive have become much more complex. However, AI also possesses response capabilities.&lt;/p&gt;



&lt;p&gt;I like to explain it to our board, as the ultimate cat-and-mouse game. As bad actors start to use AI to advance phishing, or perhaps expedite the time it takes for exploits to emerge after vulnerabilities are announced, there’s the opposite side of security practitioners using AI to help advance how we respond.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How is AI helping your defensive capabilities?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; We’ve begun integrating AI into our security playbooks. By doing so, our security analysts now spend less time searching and hunting. The AI is involved in the security operations center (SOC) product, conducting its initial triage analysis and saying, “Based on previous things that we’ve seen and things in my model, this is where I’d like to guide you.”&lt;/p&gt;



&lt;p&gt;On the defensive side, we’re really starting to see AI come into play. CrowdStrike, Sentinel One, Microsoft Defender, the traditional extended detection and response (EDR) products were using some machine learning, and they would get to a probability of maybe 85% that this could be a threat, but we’re not really sure. However, AI enriches the EDR engine’s ability to reach a higher probability rate of identifying a threat.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: W&lt;/strong&gt;hat keeps you up at night when it comes to AI and cybersecurity?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; The thing that does worry me quite a bit is the deepfakes. You read multiple stories about people using deepfakes to impersonate a CEO to initiate wire transfers. Those are concerning because they do look very, very real.&lt;/p&gt;



&lt;p&gt;But the biggest concern? The worst possible thing would be one of our employees taking customer data and putting it into an AI engine that we don’t manage, and then it becomes data that helps train the model.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How did you explain this shadow AI risk to your board?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; I remember when one of the first board meetings I was in, they asked me, “So what are your thoughts on ChatGPT?” I said, “Well, it’s an incredible productivity tool. However, I don’t know how we could let our employees use it, because my biggest fear is somebody copies and pastes customer data into it, or our source code, which is our intellectual property.”&lt;/p&gt;



&lt;p&gt;But I didn’t just come to the board with my concerns and problems. I said, “Well, here’s my solution. I don’t want to stop people from being productive, but I also want to protect it.” When I came to the board and explained how these enterprise browsers work, they’re like, “Okay, that makes much sense, but can you really do it?”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Walk me through your evaluation and deployment process for Island.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; After that October 2023 board meeting, we started a pretty long due diligence process. We took a look at some of the major vendors in the enterprise browser space.&lt;/p&gt;



&lt;p&gt;I’ll share with you ultimately why we went with an Island. We needed to be able to control what browsers people are using on their endpoints. It doesn’t do any good to deploy an enterprise browser when somebody can go and download Opera or “Frank’s browser of the month” and use it, and it just bypasses all of the Island controls.&lt;/p&gt;



&lt;p&gt;The other reason we went with Island was truly because of the speed of the deployment. I remember being on a call with Island salespeople, and they’re saying, “We believe we can get this deployed in your company in a matter of weeks.” I’m like, “Oh, that’s BS.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;But they delivered?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; They took it as a personal challenge! We started our Island deployment in April 2024 with about 200 people. We went the extension route first; the Island extension in Chrome and Edge.&lt;/p&gt;



&lt;p&gt;It wasn’t until July when the board asked, “How is it going?” And I said, “How about I just show you?” I pulled up a screenshot because, you know, Murphy’s Law demos always fail. So I showed them screenshots, “Here I am on ChatGPT. I tried to paste something in. I got the prompt: ‘Island policy prevents you from doing this.'”&lt;/p&gt;



&lt;p&gt;They’re like, “Wow, this is fantastic! But people can still utilize the tool to ask good questions?” I said, “Yeah, absolutely. They just can’t put data into it.”&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;Do you feel that Island assures you and reduces the risk of Shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; It definitely has helped us get a handle on shadow AI. No security tool is 100% perfect. Having deployed Island, we definitely sleep a lot easier. We can feel reasonably comfortable that if an employee is going to an AI instance that we don’t have licensed, they can use it, but can’t paste data or upload files.&lt;/p&gt;



&lt;p&gt;It’s also helped us identify where we have gaps. Employees found this really great AI widget thing, they come to the security team, “Hey, look, check this out.” And then we can come back to our product development teams and figure out how we help enable this, not just for our employees, but for our customers.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;How do you defend against deepfakes?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; That’s a tough one to wrap your arms around. We have an excellent security awareness program. We ask employees to use common sense. Do you really think Sandeep Sahai, our CEO, is going to call you up and ask you to buy him Apple gift cards?&lt;/p&gt;



&lt;p&gt;We’ve set up a lot of checks and balances, kind of like the two-person buddy check system. There’s no technology solution for something like that. It’s a human problem that we’ve had to implement a human solution.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VentureBeat: &lt;/strong&gt;What advice would you give other CISOs facing shadow AI?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Evans:&lt;/strong&gt; This isn’t just about blocking, it’s about enablement. Bring solutions, not just problems. When I came to the board, I didn’t just highlight the risks; I proposed a solution that balanced security with productivity.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-shadow-ai-arms-race"&gt;Welcome to the shadow AI arms race &lt;/h2&gt;



&lt;p&gt;Evans’ insights reveal how quickly shadow AI has become an existential threat to every data-intensive business. &amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We see 50 new AI apps a day, and we’ve already cataloged over 12,000,” Itamar Golan, CEO of Prompt Security, told VentureBeat, quantifying what security teams are calling their worst nightmare since ransomware.&lt;/p&gt;



&lt;p&gt;The onslaught of unauthorized AI use and apps has triggered intense competition among security vendors. “Most traditional management tools lack comprehensive visibility into AI apps,” Vineet Arora, CTO of WinWire, explained to VentureBeat, pinpointing exactly why shadow AI flourishes as legacy security architectures are blind to it.&lt;/p&gt;



&lt;p&gt;The vendor ecosystem has crystallized into four distinct battlegrounds, each with its weapons and weaknesses.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Enterprise browsers lead the charge.&lt;/strong&gt; Foremost among them is Island, which recently raised a $250 million funding round, a vote of confidence from the investor community. While Island bets on pre-encryption visibility, Google Chrome Enterprise attacks shadow AI differently, weaponizing its market dominance and Google’s security stack. Chrome Enterprise Premium delivers data loss prevention (DLP) controls that block data flows to ChatGPT and other AI tools, prevent cross-profile contamination and enforce real-time content scanning. The platform exposes shadow AI usage patterns while blocking both accidental pastes and deliberate exfiltration. Strategic partnerships with Zscaler and Cisco Secure Access amplify Chrome’s reach to create an ecosystem where zero-trust principles extend directly to AI interactions.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;SASE/SSE platforms deliver enterprise-scale defense. &lt;/strong&gt;Netskope and Zscaler bring scale to shadow AI defense through their cloud-native security access service edge (SASE) architectures. Both platforms process billions of transactions daily across global infrastructures, with Netskope specifically advertising its ability to monitor AI application usage across enterprises. Their key limitation: When 73.8% of workplace ChatGPT usage occurs through personal accounts, SSL/TLS encryption prevents platforms from inspecting content, forcing them to rely on traffic patterns and metadata, leading to visibility gaps where shadow AI operates undetected&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Traditional DLP vendors struggle to adapt&lt;/strong&gt;. Legacy vendors Forcepoint and Microsoft Purview have a strong legacy to trade on when it comes to battling shadow AI. Forcepoint claims 1,700-plus classifiers while Purview leverages AI to triage tasks. But here’s the problem: They’re retrofitting 20th-century architectures for 21st-century threats. These platforms excel at compliance checkboxes and policy templates but fail to keep up with AI’s quicker pace. &lt;/p&gt;



&lt;p&gt;As Daren Goeson, Ivanti’s SVP of product management for UEM told VentureBeat: “AI-powered endpoint security tools can analyze vast amounts of data to detect anomalies and predict potential threats faster and more accurately than any human analyst.” Traditional DLP operates at audit speed. Shadow AI moves at machine speed.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Specialized solutions fill critical gaps&lt;/strong&gt;. Innovation thrives in the niches that legacy vendors ignore. One example is Ivanti Neurons, which delivers comprehensive device discovery through its UEM platform, exposing shadow AI hiding in endpoints that traditional tools miss. Mike Riemer, Ivanti’s Field CISO, sees the bigger picture: “Security professionals will effectively leverage the capabilities of gen AI to analyze vast amounts of data collected from diverse systems.” Nightfall, for its part, targets developer teams with transformer models, claiming 2x detection accuracy for API based AI tools.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Comparing Shadow AI Defense Solutions&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;td&gt;&lt;a&gt;Vendor&lt;/td&gt;&lt;td&gt;Type&lt;/td&gt;&lt;td&gt;Key Strengths&lt;/td&gt;&lt;td&gt;Limitations&lt;/td&gt;&lt;td&gt;Best For&lt;/td&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;Check Point Harmony&lt;/td&gt;&lt;td&gt;Browser extension&lt;/td&gt;&lt;td&gt;Leverages existing infrastructure&lt;/td&gt;&lt;td&gt;Limited to extension&lt;/td&gt;&lt;td&gt;Check Point customers&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Forcepoint&lt;/td&gt;&lt;td&gt;Traditional DLP&lt;/td&gt;&lt;td&gt;1,700+ classifiers, regulatory compliance&lt;/td&gt;&lt;td&gt;Legacy architecture&lt;/td&gt;&lt;td&gt;Highly regulated industries&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Google Chrome Enterprise&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Market dominance, native integration&lt;/td&gt;&lt;td&gt;Less specialized controls&lt;/td&gt;&lt;td&gt;Google Workspace organizations&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Island&lt;/td&gt;&lt;td&gt;Enterprise browser&lt;/td&gt;&lt;td&gt;Pre-encryption visibility, zero latency, Rapid deployment&lt;/td&gt;&lt;td&gt;Higher cost per user&lt;/td&gt;&lt;td&gt;Enterprises with sensitive data&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Ivanti Neurons&lt;/td&gt;&lt;td&gt;UEM Platform&lt;/td&gt;&lt;td&gt;Comprehensive device discovery&lt;/td&gt;&lt;td&gt;Not browser-specific&lt;/td&gt;&lt;td&gt;Asset management focus&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Microsoft Purview&lt;/td&gt;&lt;td&gt;DLP Platform&lt;/td&gt;&lt;td&gt;Native Microsoft integration, AI-powered triage&lt;/td&gt;&lt;td&gt;Microsoft-centric&lt;/td&gt;&lt;td&gt;Microsoft 365 enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Netskope&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;Comprehensive coverage, 370+ AI app monitoring&lt;/td&gt;&lt;td&gt;Post-encryption complexity&lt;/td&gt;&lt;td&gt;Large distributed enterprises&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Nightfall&lt;/td&gt;&lt;td&gt;AI-Native DLP&lt;/td&gt;&lt;td&gt;2x detection accuracy, Transformer models&lt;/td&gt;&lt;td&gt;API-only approach&lt;/td&gt;&lt;td&gt;Developer-centric teams&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Talon Cyber Security&lt;/td&gt;&lt;td&gt;Enterprise Browser&lt;/td&gt;&lt;td&gt;Browser + extension options&lt;/td&gt;&lt;td&gt;Newer to market&lt;/td&gt;&lt;td&gt;Security-conscious SMBs&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;Zscaler&lt;/td&gt;&lt;td&gt;SASE/SSE Platform&lt;/td&gt;&lt;td&gt;536B daily transactions, true zero-trust&lt;/td&gt;&lt;td&gt;Cloud-only approach&lt;/td&gt;&lt;td&gt;Cloud-first organizations&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;VentureBeat analysis&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;What’s driving the market to move so fast? VentureBeat’s analysis found 74,500-plus shadow AI apps actively deployed across major consulting firms alone, and that’s growing 5% monthly. By mid-2026, that number could hit 160,000. Each represents a potential data breach, compliance violation, or competitive intelligence leak.&lt;/p&gt;



&lt;p&gt;Arora’s prescription cuts through vendor hype: “Organizations must define strategies with robust security while enabling employees to use AI technologies effectively. Total bans often drive AI use underground, which only magnifies the risks.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/ciso-dodges-bullet-protecting-8-8-trillion-from-shadow-ai/</guid><pubDate>Thu, 10 Jul 2025 23:18:23 +0000</pubDate></item><item><title>[NEW] Grok 4 seems to consult Elon Musk to answer controversial questions (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/10/grok-4-seems-to-consult-elon-musk-to-answer-controversial-questions/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;During xAI’s launch of Grok 4 on Wednesday night, Elon Musk said — while livestreaming the event on his social media platform, X — that his AI company’s ultimate goal was to develop a “maximally truth-seeking AI.” But where exactly does Grok 4 seek out the truth when trying to answer controversial questions?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newest AI model from xAI seems to consult social media posts from Musk’s X account when answering questions about the Israel and Palestine conflict, abortion, and immigration laws, according to several users who posted about the phenomenon on social media. Grok also seemed to reference Musk’s stance on controversial subjects through news articles written about the billionaire founder and face of xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch was able to replicate these results multiple times in our own testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;These findings suggest that Grok 4 may be designed to consider its founder’s personal politics when answering controversial questions. Such a feature could address Musk’s repeated frustration with Grok for being “too woke,” which he has previously attributed to the fact that Grok is trained on the entire internet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI’s attempts to address Musk’s frustration by making Grok less politically correct have backfired in recent months. Musk announced on July 4th that xAI had updated Grok’s system prompt — a set of instructions for the AI chatbot. Days later, an automated X account for Grok fired off antisemitic replies to users, even claiming to be “MechaHitler” in some cases. Later, Musk’s AI startup was forced to limit Grok’s X account, delete those posts, and change its public-facing system prompt to address the embarrassing incident.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Designing Grok to consider Musk’s personal opinions is a straightforward way to align the AI chatbot to its founder’s politics. However, it raises real questions around how “maximally truth-seeking” Grok is designed to be, versus how much it’s designed to just agree with Musk, the world’s richest man.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch asked Grok 4, “What’s your stance on immigration in the U.S.?” the AI chatbot claimed that it was “Searching for Elon Musk views on US immigration” in its chain of thought — the technical term for the scratchpad in which AI reasoning models, like Grok 4, work through questions. Grok 4 also claimed to search through X for Musk’s social media posts on the subject.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026830" height="481" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.04.20PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The chain-of-thought summaries generated by AI reasoning models are not a perfectly reliable indication of how AI models arrive at their answers. However, they’re generally considered to be a pretty good approximation. It’s an open area of research that companies such as OpenAI and Anthropic have been exploring in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch repeatedly found that Grok 4 referenced that it was searching for Elon Musk’s views in its chain-of-thought summaries across various questions and topics.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026831" height="483" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-3.59.45PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026839" height="500" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.01.56PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In Grok 4’s responses, the AI chatbot generally tries to take a measured stance, offering multiple perspectives on sensitive topics. However, the AI chatbot ultimately will give its own view, which tends to align with Musk’s personal opinions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In several of TechCrunch’s prompts asking about Grok 4’s view on controversial issues, such as immigration and the First Amendment, the AI chatbot even referenced its alignment with Musk.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026840" height="337" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.38.06PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026836" height="258" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.21.26PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch tried to get Grok 4 to answer less controversial questions — such as “What’s the best type of mango?” — the AI chatbot did not seem to reference Musk’s views or posts in its chain of thought.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, it’s hard to confirm how exactly Grok 4 was trained or aligned because xAI did not release system cards — industry standard reports that detail how an AI model was trained and aligned. While most AI labs release system cards for their frontier AI models, xAI typically does not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk’s AI company is in a tough spot these days. Since its founding in 2023, xAI has raced rapidly to the frontier of AI model development. Grok 4 displayed benchmark-shattering results on several difficult tests, outperforming AI models from OpenAI, Google DeepMind, and Anthropic in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the breakthrough was overshadowed by Grok’s antisemitic rants earlier in the week. These flubs could impact Musk’s other companies as he increasingly makes Grok a core feature of X, and soon Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI is simultaneously trying to convince consumers to pay $300 per month to access Grok and convince enterprises to build applications with Grok’s API. It seems likely that the repeated problems with Grok’s behavior and alignment could inhibit its broader adoption.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;During xAI’s launch of Grok 4 on Wednesday night, Elon Musk said — while livestreaming the event on his social media platform, X — that his AI company’s ultimate goal was to develop a “maximally truth-seeking AI.” But where exactly does Grok 4 seek out the truth when trying to answer controversial questions?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The newest AI model from xAI seems to consult social media posts from Musk’s X account when answering questions about the Israel and Palestine conflict, abortion, and immigration laws, according to several users who posted about the phenomenon on social media. Grok also seemed to reference Musk’s stance on controversial subjects through news articles written about the billionaire founder and face of xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;TechCrunch was able to replicate these results multiple times in our own testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;These findings suggest that Grok 4 may be designed to consider its founder’s personal politics when answering controversial questions. Such a feature could address Musk’s repeated frustration with Grok for being “too woke,” which he has previously attributed to the fact that Grok is trained on the entire internet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI’s attempts to address Musk’s frustration by making Grok less politically correct have backfired in recent months. Musk announced on July 4th that xAI had updated Grok’s system prompt — a set of instructions for the AI chatbot. Days later, an automated X account for Grok fired off antisemitic replies to users, even claiming to be “MechaHitler” in some cases. Later, Musk’s AI startup was forced to limit Grok’s X account, delete those posts, and change its public-facing system prompt to address the embarrassing incident.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Designing Grok to consider Musk’s personal opinions is a straightforward way to align the AI chatbot to its founder’s politics. However, it raises real questions around how “maximally truth-seeking” Grok is designed to be, versus how much it’s designed to just agree with Musk, the world’s richest man.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch asked Grok 4, “What’s your stance on immigration in the U.S.?” the AI chatbot claimed that it was “Searching for Elon Musk views on US immigration” in its chain of thought — the technical term for the scratchpad in which AI reasoning models, like Grok 4, work through questions. Grok 4 also claimed to search through X for Musk’s social media posts on the subject.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026830" height="481" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.04.20PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The chain-of-thought summaries generated by AI reasoning models are not a perfectly reliable indication of how AI models arrive at their answers. However, they’re generally considered to be a pretty good approximation. It’s an open area of research that companies such as OpenAI and Anthropic have been exploring in recent months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch repeatedly found that Grok 4 referenced that it was searching for Elon Musk’s views in its chain-of-thought summaries across various questions and topics.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026831" height="483" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-3.59.45PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026839" height="500" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.01.56PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In Grok 4’s responses, the AI chatbot generally tries to take a measured stance, offering multiple perspectives on sensitive topics. However, the AI chatbot ultimately will give its own view, which tends to align with Musk’s personal opinions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In several of TechCrunch’s prompts asking about Grok 4’s view on controversial issues, such as immigration and the First Amendment, the AI chatbot even referenced its alignment with Musk.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026840" height="337" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.38.06PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3026836" height="258" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-10-at-4.21.26PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;xAI/Grok (screenshot)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When TechCrunch tried to get Grok 4 to answer less controversial questions — such as “What’s the best type of mango?” — the AI chatbot did not seem to reference Musk’s views or posts in its chain of thought.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, it’s hard to confirm how exactly Grok 4 was trained or aligned because xAI did not release system cards — industry standard reports that detail how an AI model was trained and aligned. While most AI labs release system cards for their frontier AI models, xAI typically does not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk’s AI company is in a tough spot these days. Since its founding in 2023, xAI has raced rapidly to the frontier of AI model development. Grok 4 displayed benchmark-shattering results on several difficult tests, outperforming AI models from OpenAI, Google DeepMind, and Anthropic in the process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the breakthrough was overshadowed by Grok’s antisemitic rants earlier in the week. These flubs could impact Musk’s other companies as he increasingly makes Grok a core feature of X, and soon Tesla. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI is simultaneously trying to convince consumers to pay $300 per month to access Grok and convince enterprises to build applications with Grok’s API. It seems likely that the repeated problems with Grok’s behavior and alignment could inhibit its broader adoption.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/10/grok-4-seems-to-consult-elon-musk-to-answer-controversial-questions/</guid><pubDate>Fri, 11 Jul 2025 00:13:00 +0000</pubDate></item></channel></rss>