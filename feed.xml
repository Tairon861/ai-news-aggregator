<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 28 Jan 2026 12:57:04 +0000</lastBuildDate><item><title>[NEW] Google pitches Gemini to students studying for India’s most competitive college entrance exam (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/google-turns-gemini-toward-indias-most-competitive-entrance-exam/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/google-gemini-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is expanding its push into AI-powered learning by adding full-length practice tests in Gemini for the Joint Entrance Exam (JEE), India’s nationwide engineering  exam used to shortlist candidates for the country’s top technical institutes and taken by millions of students each year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said students can take full-length mock exams for the JEE within Gemini, which will offer questions based on vetted content from Indian education firms PhysicsWallah and Careers360. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The launch comes after the company recently rolled out similar test-prep tools for the SAT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once students complete a mock test in Gemini, Google said the chatbot will provide immediate feedback, highlighting areas of strength and where further study is needed. It can also explain correct answers and help students generate a customized study plan based on their performance, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of practice tests in Gemini signals a broader push to position the chatbot as a tool for structured exam preparation rather than a shortcut to answers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to Gemini, Google said the JEE Main preparation tools will roll out to AI Mode in Search, including the Canvas tool, which allows students to build study guides and interactive quizzes by attaching their class notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google claims Indian students are using Gemini to study subjects ranging from advanced physics to broader STEM topics, as well as NotebookLM for turning study materials into quizzes, flashcards and audio or video summaries. Google’s AI tools are available in multiple Indian languages.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google said it is also expanding its focus on Indian educators, and plans to work with government agencies on a nationwide program to help teachers and support staff use AI for administrative work and lesson design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is partnering with the Ministry of Skill Development and Entrepreneurship, and Chaudhary Charan Singh University on a pilot to build an “AI-enabled state university.” The project aims to create a national framework for applying AI across vocational and higher education, encompassing teaching and student support, as well as administrative operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the company said its charitable arm, Google.org, is backing Wadhwani AI with an ₹850 million (about $10 million) grant to integrate AI into government-run education platforms. The initiative targets systems such as national online learning portals and state education platforms, aiming to make them more adaptable and reduce administrative burdens for educators.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The program spans pre-school through higher education, and includes tools such as voice-based reading support in multiple Indian languages, and AI-powered English learning coaches. The company claims it has already reached around 10 million learners and educators, and aims to scale to 75 million students, 1.8 million educators, and a million early-career professionals by the end of 2027.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/google-gemini-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is expanding its push into AI-powered learning by adding full-length practice tests in Gemini for the Joint Entrance Exam (JEE), India’s nationwide engineering  exam used to shortlist candidates for the country’s top technical institutes and taken by millions of students each year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google said students can take full-length mock exams for the JEE within Gemini, which will offer questions based on vetted content from Indian education firms PhysicsWallah and Careers360. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The launch comes after the company recently rolled out similar test-prep tools for the SAT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Once students complete a mock test in Gemini, Google said the chatbot will provide immediate feedback, highlighting areas of strength and where further study is needed. It can also explain correct answers and help students generate a customized study plan based on their performance, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of practice tests in Gemini signals a broader push to position the chatbot as a tool for structured exam preparation rather than a shortcut to answers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to Gemini, Google said the JEE Main preparation tools will roll out to AI Mode in Search, including the Canvas tool, which allows students to build study guides and interactive quizzes by attaching their class notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google claims Indian students are using Gemini to study subjects ranging from advanced physics to broader STEM topics, as well as NotebookLM for turning study materials into quizzes, flashcards and audio or video summaries. Google’s AI tools are available in multiple Indian languages.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google said it is also expanding its focus on Indian educators, and plans to work with government agencies on a nationwide program to help teachers and support staff use AI for administrative work and lesson design.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said it is partnering with the Ministry of Skill Development and Entrepreneurship, and Chaudhary Charan Singh University on a pilot to build an “AI-enabled state university.” The project aims to create a national framework for applying AI across vocational and higher education, encompassing teaching and student support, as well as administrative operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the company said its charitable arm, Google.org, is backing Wadhwani AI with an ₹850 million (about $10 million) grant to integrate AI into government-run education platforms. The initiative targets systems such as national online learning portals and state education platforms, aiming to make them more adaptable and reduce administrative burdens for educators.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The program spans pre-school through higher education, and includes tools such as voice-based reading support in multiple Indian languages, and AI-powered English learning coaches. The company claims it has already reached around 10 million learners and educators, and aims to scale to 75 million students, 1.8 million educators, and a million early-career professionals by the end of 2027.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/google-turns-gemini-toward-indias-most-competitive-entrance-exam/</guid><pubDate>Wed, 28 Jan 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] Inside Standard Chartered’s approach to running AI under privacy rules (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-standard-chartered-runs-ai-under-privacy-rules/</link><description>&lt;p&gt;For banks trying to put AI into real use, the hardest questions often come before any model is trained. Can the data be used at all? Where is it allowed to be stored? Who is responsible once the system goes live? At Standard Chartered, these privacy-driven questions now shape how AI systems are built,  and deployed at the bank.&lt;/p&gt;&lt;p&gt;For global banks operating in many jurisdictions, these early decisions are rarely straightforward. Privacy rules differ by market, and the same AI system may face very different constraints depending on where it is deployed. At Standard Chartered, this has pushed privacy teams into a more active role in shaping how AI systems are designed, approved, and monitored in the organisation.&lt;/p&gt;&lt;p&gt;“Data privacy functions have become the starting point of most AI regulations,” says David Hardoon, Global Head of AI Enablement at Standard Chartered. In practice, that means privacy requirements shape the type of data that can be used in AI systems, how transparent those systems need to be, and how they are monitored once they are live.&lt;/p&gt;&lt;h3&gt;Privacy shaping how AI runs&lt;/h3&gt;&lt;p&gt;The bank is already running AI systems in live environments. The transition from pilots brings practical challenges that are easy to underestimate early on. In small trials, data sources are limited and well understood. In production, AI systems often pull data from many upstream platforms, each with its own structure and quality issues. “When moving from a contained pilot into live operations, ensuring data quality becomes more challenging with multiple upstream systems and potential schema differences,” Hardoon says.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-111851" height="2445" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/David-Hardoon_Standard-Chartered-edited.jpg" width="1630" /&gt;&lt;figcaption class="wp-element-caption"&gt;David Hardoon, Global Head of AI Enablement at Standard Chartered&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Privacy rules add further constraints. In some cases, real customer data cannot be used to train models. Instead, teams may rely on anonymised data, which can affect how quickly systems are developed or how well they perform. Live deployments also operate at a much larger scale, increasing the impact of any gaps in controls. As Hardoon puts it, “As part of responsible and client-centric AI adoption, we prioritise adhering to principles of fairness, ethics, accountability, and transparency as data processing scope expands.”&lt;/p&gt;&lt;h3&gt;Geography and regulation decide where AI works&lt;/h3&gt;&lt;p&gt;Where AI systems are built and deployed is also shaped by geography. Data protection laws vary in regions, and some countries impose strict rules on where data must be stored and who can access it. These requirements play a direct role in how Standard Chartered deploys AI, particularly for systems that rely on client or personally identifiable information.&lt;/p&gt;&lt;p&gt;“Data sovereignty is often a key consideration when operating in different markets and regions,” Hardoon says. In markets with data localisation rules, AI systems may need to be deployed locally, or designed so that sensitive data does not cross borders. In other cases, shared platforms can be used, provided the right controls are in place. This results in a mix of global and market-specific AI deployments, shaped by local regulation not a single technical preference.&lt;/p&gt;&lt;p&gt;The same trade-offs appear in decisions about centralised AI platforms versus local solutions. Large organisations often aim to share models, tools, and oversight in markets to reduce duplication. Privacy laws do not always block this approach. “In general, privacy regulations do not explicitly prohibit transfer of data, but rather expect appropriate controls to be in place,” Hardoon says.&lt;/p&gt;&lt;p&gt;There are limits: some data cannot move in borders at all, and certain privacy laws apply beyond the country where data was collected. The details can restrict which markets a central platform can serve and where local systems remain necessary. For banks, this often leads to a layered setup, with shared foundations combined with localised AI use cases where regulation demands it.&lt;/p&gt;&lt;h3&gt;Human oversight remains central&lt;/h3&gt;&lt;p&gt;As AI becomes more embedded in decision-making, questions around explainability and consent grow harder to avoid. Automation may speed up processes, but it does not remove responsibility. “Transparency and explainability have become more crucial than before,” Hardoon says. Even when working with external vendors, accountability remains internal. This has reinforced the need for human oversight in AI systems, particularly where outcomes affect customers or regulatory obligations.&lt;/p&gt;&lt;p&gt;People also play a larger role in privacy risk than technology alone. Processes and controls can be well designed, but they depend on how staff understand and handle data. “People remain the most important factor when it comes to implementing privacy controls,” Hardoon says. At Standard Chartered, this has pushed a focus on training and awareness, so teams know what data can be used, how it should be handled, and where the boundaries lie.&lt;/p&gt;&lt;p&gt;Scaling AI under growing regulatory scrutiny requires making privacy and governance easier to apply in practice. One approach the bank is taking is standardisation. By creating pre-approved templates, architectures, and data classifications, teams can move faster without bypassing controls. “Standardisation and re-usability are important,” Hardoon explains. Codifying rules around data residency, retention, and access helps turn complex requirements into clearer components that can be reused in AI projects.&lt;/p&gt;&lt;p&gt;As more organisations move AI into everyday operations, privacy is not just a compliance hurdle. It is shaping how AI systems are built, where they run, and how much trust they can earn. In banking, that shift is already influencing what AI looks like in practice – and where its limits are set.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Corporate Locations)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: The quiet work behind Citi’s 4,000-person internal AI rollout&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;For banks trying to put AI into real use, the hardest questions often come before any model is trained. Can the data be used at all? Where is it allowed to be stored? Who is responsible once the system goes live? At Standard Chartered, these privacy-driven questions now shape how AI systems are built,  and deployed at the bank.&lt;/p&gt;&lt;p&gt;For global banks operating in many jurisdictions, these early decisions are rarely straightforward. Privacy rules differ by market, and the same AI system may face very different constraints depending on where it is deployed. At Standard Chartered, this has pushed privacy teams into a more active role in shaping how AI systems are designed, approved, and monitored in the organisation.&lt;/p&gt;&lt;p&gt;“Data privacy functions have become the starting point of most AI regulations,” says David Hardoon, Global Head of AI Enablement at Standard Chartered. In practice, that means privacy requirements shape the type of data that can be used in AI systems, how transparent those systems need to be, and how they are monitored once they are live.&lt;/p&gt;&lt;h3&gt;Privacy shaping how AI runs&lt;/h3&gt;&lt;p&gt;The bank is already running AI systems in live environments. The transition from pilots brings practical challenges that are easy to underestimate early on. In small trials, data sources are limited and well understood. In production, AI systems often pull data from many upstream platforms, each with its own structure and quality issues. “When moving from a contained pilot into live operations, ensuring data quality becomes more challenging with multiple upstream systems and potential schema differences,” Hardoon says.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-111851" height="2445" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/David-Hardoon_Standard-Chartered-edited.jpg" width="1630" /&gt;&lt;figcaption class="wp-element-caption"&gt;David Hardoon, Global Head of AI Enablement at Standard Chartered&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Privacy rules add further constraints. In some cases, real customer data cannot be used to train models. Instead, teams may rely on anonymised data, which can affect how quickly systems are developed or how well they perform. Live deployments also operate at a much larger scale, increasing the impact of any gaps in controls. As Hardoon puts it, “As part of responsible and client-centric AI adoption, we prioritise adhering to principles of fairness, ethics, accountability, and transparency as data processing scope expands.”&lt;/p&gt;&lt;h3&gt;Geography and regulation decide where AI works&lt;/h3&gt;&lt;p&gt;Where AI systems are built and deployed is also shaped by geography. Data protection laws vary in regions, and some countries impose strict rules on where data must be stored and who can access it. These requirements play a direct role in how Standard Chartered deploys AI, particularly for systems that rely on client or personally identifiable information.&lt;/p&gt;&lt;p&gt;“Data sovereignty is often a key consideration when operating in different markets and regions,” Hardoon says. In markets with data localisation rules, AI systems may need to be deployed locally, or designed so that sensitive data does not cross borders. In other cases, shared platforms can be used, provided the right controls are in place. This results in a mix of global and market-specific AI deployments, shaped by local regulation not a single technical preference.&lt;/p&gt;&lt;p&gt;The same trade-offs appear in decisions about centralised AI platforms versus local solutions. Large organisations often aim to share models, tools, and oversight in markets to reduce duplication. Privacy laws do not always block this approach. “In general, privacy regulations do not explicitly prohibit transfer of data, but rather expect appropriate controls to be in place,” Hardoon says.&lt;/p&gt;&lt;p&gt;There are limits: some data cannot move in borders at all, and certain privacy laws apply beyond the country where data was collected. The details can restrict which markets a central platform can serve and where local systems remain necessary. For banks, this often leads to a layered setup, with shared foundations combined with localised AI use cases where regulation demands it.&lt;/p&gt;&lt;h3&gt;Human oversight remains central&lt;/h3&gt;&lt;p&gt;As AI becomes more embedded in decision-making, questions around explainability and consent grow harder to avoid. Automation may speed up processes, but it does not remove responsibility. “Transparency and explainability have become more crucial than before,” Hardoon says. Even when working with external vendors, accountability remains internal. This has reinforced the need for human oversight in AI systems, particularly where outcomes affect customers or regulatory obligations.&lt;/p&gt;&lt;p&gt;People also play a larger role in privacy risk than technology alone. Processes and controls can be well designed, but they depend on how staff understand and handle data. “People remain the most important factor when it comes to implementing privacy controls,” Hardoon says. At Standard Chartered, this has pushed a focus on training and awareness, so teams know what data can be used, how it should be handled, and where the boundaries lie.&lt;/p&gt;&lt;p&gt;Scaling AI under growing regulatory scrutiny requires making privacy and governance easier to apply in practice. One approach the bank is taking is standardisation. By creating pre-approved templates, architectures, and data classifications, teams can move faster without bypassing controls. “Standardisation and re-usability are important,” Hardoon explains. Codifying rules around data residency, retention, and access helps turn complex requirements into clearer components that can be reused in AI projects.&lt;/p&gt;&lt;p&gt;As more organisations move AI into everyday operations, privacy is not just a compliance hurdle. It is shaping how AI systems are built, where they run, and how much trust they can earn. In banking, that shift is already influencing what AI looks like in practice – and where its limits are set.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Corporate Locations)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: The quiet work behind Citi’s 4,000-person internal AI rollout&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-standard-chartered-runs-ai-under-privacy-rules/</guid><pubDate>Wed, 28 Jan 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] Gallup Workforce shows details of AI adoption in US workplaces (AI News)</title><link>https://www.artificialintelligence-news.com/news/gallup-workforce-ai-shows-details-of-ml-adoption-in-us-workplaces/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/gallup-workforce-ai-hero_x1440.webp" /&gt;&lt;/div&gt;&lt;p&gt; Gallup’s data reveals a significant number of workers ore unsure whether or not their employer had adopted AI – nearly a quarter of those surveyed weren’t sure. In the third quarter of 2025, just over a third of employees said their organisation had implemented AI. 40% said there was no adoption of AI in their place of work&lt;/p&gt;&lt;p&gt; It’s worth noting that earlier versions of Gallup surveys didn’t include a “don’t know” option for questions about employers’ AI adoption, which encouraged respondents to guess. Belief in organisational AI adoption appeared to rise sharply between 2024 and 2025, therefore, Gallup says. Once uncertainty could be stated explicitly, it became clear a good number of employees were simply uninformed on the matter.&lt;/p&gt;&lt;p&gt; It’s staff in non-managerial roles who are more likely to say they’re unaware of their organisation’s AI use, a tendency mirrored in part-time staff and hands-on roles. The further workers are from decision-making, it seems, the less sure they become.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/gallup-workforce-ai-hero_x1440.webp" /&gt;&lt;/div&gt;&lt;p&gt; Gallup’s data reveals a significant number of workers ore unsure whether or not their employer had adopted AI – nearly a quarter of those surveyed weren’t sure. In the third quarter of 2025, just over a third of employees said their organisation had implemented AI. 40% said there was no adoption of AI in their place of work&lt;/p&gt;&lt;p&gt; It’s worth noting that earlier versions of Gallup surveys didn’t include a “don’t know” option for questions about employers’ AI adoption, which encouraged respondents to guess. Belief in organisational AI adoption appeared to rise sharply between 2024 and 2025, therefore, Gallup says. Once uncertainty could be stated explicitly, it became clear a good number of employees were simply uninformed on the matter.&lt;/p&gt;&lt;p&gt; It’s staff in non-managerial roles who are more likely to say they’re unaware of their organisation’s AI use, a tendency mirrored in part-time staff and hands-on roles. The further workers are from decision-making, it seems, the less sure they become.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/gallup-workforce-ai-shows-details-of-ml-adoption-in-us-workplaces/</guid><pubDate>Wed, 28 Jan 2026 10:06:00 +0000</pubDate></item><item><title>[NEW] Waabi raises $1B and expands into robotaxis with Uber (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/waabi-raises-1b-and-expands-into-robotaxis-with-uber/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous vehicle startup Waabi has raised $1 billion and struck a partnership with Uber to deploy self-driving cars on the ride-hailing platform — the company’s first expansion beyond autonomous trucking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The funding consists of an oversubscribed $750 million Series C round co-led by Khosla Ventures and G2 Venture Partners and roughly $250 million in milestone-based capital from Uber to support the deployment of 25,000 or more Waabi Driver-powered robotaxis exclusively on its platform. The companies did not provide a timeline for such a large-scale deployment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The partnership represents a bet that the startup’s AI technology can succeed where others have struggled – scaling across multiple self-driving verticals with a single technology stack. While competitors like Waymo previously attempted both robotaxis and trucking before shutting down its freight program, Waabi founder and CEO Raquel Urtasun says her company’s capital-efficient approach and generalizable AI architecture give it a unique advantage to tackle both markets simultaneously.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our incredible core technology really enables, for the first time, a single solution that can do multiple verticals, and they can do them at scale,” Urtasun told TechCrunch. “It’s not about two programs, two stacks.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tie-up brings Urtasun’s work full circle: she previously served as chief scientist at Uber’s autonomous vehicle division, Uber ATG, which Uber sold to self-driving trucking firm Aurora Innovation in 2020. It also builds on Waabi’s existing partnership with Uber Freight.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi is one of several AV companies that Uber has brought on to deploy self-driving vehicles on its platform globally. Other companies include Waymo, Nuro, Avride, Wayve, WeRide, Momenta, and more.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tie-up and funding round come as Uber launches a new division called Uber AV Labs that will use its vehicles to collect data for AV partners.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi isn’t as reliant on data as some, if Urtasun is to be believed. The Waabi Driver is trained, tested, and validated using a closed-loop simulator called Waabi World that automatically builds digital twins of the world from data; performs real-time sensor simulation; manufactures scenarios to stress-test the Waabi Driver; and teaches the Driver to learn from its mistakes without human intervention. The result? Waabi’s Driver can reason about its surroundings as a human would and choose the best maneuver, says Urtasun. This allows the system to generalize and learn from fewer examples than traditional autonomous driving systems.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3087058" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/Waabi_Raquel_Urtasun_2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Waabi founder and CEO Raquel Urtasun.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Waabi&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi has spent the last four and a half years bringing that technology to life for highway and surface street capabilities with trucks, but Urtasun says the Waabi Brain already generalizes to different vehicle form factors – she has even hinted at the company’s next vertical being robotics. From the beginning, the company collected and simulated passenger car data alongside its trucking work, a signal that robotaxis were always part of the long-term plan.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The approach has allowed Waabi to build faster and cheaper than competitors, Urtasun claims.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We don’t need the gazillion humans to develop the technology and the large fleets that AV 1.0 needs,” Urtasun said. “We don’t need the massive data centers, energy consumption, or a gazillion latest chips.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal brings Waabi’s total funding raised to roughly $1.28 billion after it closed a $200 million Series B in June 2024. Competitors Aurora Innovation and Kodiak Robotics have raised $3.46 billion and $448 million to date, respectively, through a combination of venture capital and public-market proceeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In just five years, Waabi has launched several commercial pilots (with a human driver in the front seat) in Texas. The company had planned to launch a fully driverless truck on public highways by the end of last year, but the rollout has been delayed until sometime in the next few quarters, per Urtasun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi is working with Volvo to build purpose-built autonomous trucks, which the company revealed last October at TechCrunch Disrupt. Urtasun says Waabi’s Driver is ready to go, but the trucks still need to be fully validated before launch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun’s not worried, though. She says there’s plenty of demand for Waabi’s trucks due to the company’s direct-to-consumer model that enables shippers to buy the outfitted trucks directly, and she’s confident that with the Uber partnership, Waabi will be able to “quickly penetrate the market and scale with a product that will be very reliable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re still in the first innings of deployment of robotaxis,” she said. “There’s a lot more scale to come.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun wouldn’t share more specifics about the Uber rollout, like what automaker Waabi would partner with. She did say that Waabi would take a similar route to its autonomous trucking rollout by building its sensors and technology into the vehicle from the factory floor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe in vertically integrating with a fully redundant platform from the OEM,” she said.&amp;nbsp; “That is how you really build safe and truly scalable technology.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Other investors in Waabi’s Series C include Uber, NVentures (Nvidia’s VC arm), Volvo Group Venture Capital, Porsche Automobil Holding SE, BlackRock, BDC Capital’s Thrive Venture Fund, and others.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Autonomous vehicle startup Waabi has raised $1 billion and struck a partnership with Uber to deploy self-driving cars on the ride-hailing platform — the company’s first expansion beyond autonomous trucking.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The funding consists of an oversubscribed $750 million Series C round co-led by Khosla Ventures and G2 Venture Partners and roughly $250 million in milestone-based capital from Uber to support the deployment of 25,000 or more Waabi Driver-powered robotaxis exclusively on its platform. The companies did not provide a timeline for such a large-scale deployment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The partnership represents a bet that the startup’s AI technology can succeed where others have struggled – scaling across multiple self-driving verticals with a single technology stack. While competitors like Waymo previously attempted both robotaxis and trucking before shutting down its freight program, Waabi founder and CEO Raquel Urtasun says her company’s capital-efficient approach and generalizable AI architecture give it a unique advantage to tackle both markets simultaneously.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our incredible core technology really enables, for the first time, a single solution that can do multiple verticals, and they can do them at scale,” Urtasun told TechCrunch. “It’s not about two programs, two stacks.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tie-up brings Urtasun’s work full circle: she previously served as chief scientist at Uber’s autonomous vehicle division, Uber ATG, which Uber sold to self-driving trucking firm Aurora Innovation in 2020. It also builds on Waabi’s existing partnership with Uber Freight.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi is one of several AV companies that Uber has brought on to deploy self-driving vehicles on its platform globally. Other companies include Waymo, Nuro, Avride, Wayve, WeRide, Momenta, and more.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tie-up and funding round come as Uber launches a new division called Uber AV Labs that will use its vehicles to collect data for AV partners.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi isn’t as reliant on data as some, if Urtasun is to be believed. The Waabi Driver is trained, tested, and validated using a closed-loop simulator called Waabi World that automatically builds digital twins of the world from data; performs real-time sensor simulation; manufactures scenarios to stress-test the Waabi Driver; and teaches the Driver to learn from its mistakes without human intervention. The result? Waabi’s Driver can reason about its surroundings as a human would and choose the best maneuver, says Urtasun. This allows the system to generalize and learn from fewer examples than traditional autonomous driving systems.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3087058" height="453" src="https://techcrunch.com/wp-content/uploads/2026/01/Waabi_Raquel_Urtasun_2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Waabi founder and CEO Raquel Urtasun.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Waabi&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi has spent the last four and a half years bringing that technology to life for highway and surface street capabilities with trucks, but Urtasun says the Waabi Brain already generalizes to different vehicle form factors – she has even hinted at the company’s next vertical being robotics. From the beginning, the company collected and simulated passenger car data alongside its trucking work, a signal that robotaxis were always part of the long-term plan.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The approach has allowed Waabi to build faster and cheaper than competitors, Urtasun claims.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We don’t need the gazillion humans to develop the technology and the large fleets that AV 1.0 needs,” Urtasun said. “We don’t need the massive data centers, energy consumption, or a gazillion latest chips.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal brings Waabi’s total funding raised to roughly $1.28 billion after it closed a $200 million Series B in June 2024. Competitors Aurora Innovation and Kodiak Robotics have raised $3.46 billion and $448 million to date, respectively, through a combination of venture capital and public-market proceeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In just five years, Waabi has launched several commercial pilots (with a human driver in the front seat) in Texas. The company had planned to launch a fully driverless truck on public highways by the end of last year, but the rollout has been delayed until sometime in the next few quarters, per Urtasun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Waabi is working with Volvo to build purpose-built autonomous trucks, which the company revealed last October at TechCrunch Disrupt. Urtasun says Waabi’s Driver is ready to go, but the trucks still need to be fully validated before launch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun’s not worried, though. She says there’s plenty of demand for Waabi’s trucks due to the company’s direct-to-consumer model that enables shippers to buy the outfitted trucks directly, and she’s confident that with the Uber partnership, Waabi will be able to “quickly penetrate the market and scale with a product that will be very reliable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re still in the first innings of deployment of robotaxis,” she said. “There’s a lot more scale to come.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Urtasun wouldn’t share more specifics about the Uber rollout, like what automaker Waabi would partner with. She did say that Waabi would take a similar route to its autonomous trucking rollout by building its sensors and technology into the vehicle from the factory floor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe in vertically integrating with a fully redundant platform from the OEM,” she said.&amp;nbsp; “That is how you really build safe and truly scalable technology.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Other investors in Waabi’s Series C include Uber, NVentures (Nvidia’s VC arm), Volvo Group Venture Capital, Porsche Automobil Holding SE, BlackRock, BDC Capital’s Thrive Venture Fund, and others.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/waabi-raises-1b-and-expands-into-robotaxis-with-uber/</guid><pubDate>Wed, 28 Jan 2026 11:00:00 +0000</pubDate></item><item><title>[NEW] White House compares industrial revolution with AI era (AI News)</title><link>https://www.artificialintelligence-news.com/news/white-house-predicts-ai-growth-with-comparison-industrial-and-artificial-intelligence-revolutions/</link><description>&lt;p&gt;A White House paper titled “Artificial Intelligence and the Great Divergence” sets out parallels between the effects of the industrial revolution in the 18th and 19th centuries and the current times, with artificial intelligence positioned as guiding the way the world’s economies will be shaped.&lt;/p&gt;&lt;p&gt;Artificial intelligence now sits at the centre of US economic strategy, currently representing a significant portion of the country’s economic activity, as characterised by the building of AI infrastructure, most notably in the form of data centres. The paper says AI investment raised US GDP by 1.3% percent in the first half of 2025, and compares this with the investment in the railway network during the industrial revolution.&lt;/p&gt;&lt;p&gt;“Artificial Intelligence and the Great Divergence” says long-term growth depends primarily on gains in productivity, and AI is the tool to achieve those gains. It presents a range of estimates of AI’s impact on GDP, from single-digit increases to 20% productivity growth inside a decade. It also floats some more extreme scenarios, where GDP grows at more than 45% as AI substitutes for human labour in the longer term.&lt;/p&gt;&lt;p&gt;Capital deployment in the form of building AI infrastructure, not growing consumption or public spending, is now creating US economic growth. Investment in data processing equipment, buildings, infrastructure, and software grew 28% in early 2025, and AI-related infrastructure represented around a quarter of all US investment in 2025.&lt;/p&gt;&lt;p&gt;Training compute capacity used by AI models has increased roughly four-fold per year since 2010, and the length of tasks AI systems can complete has doubled every seven months for six years, the paper states. The cost per token of AI output has fallen by factors ranging from nine to nine hundred per year, depending on task and model.&lt;/p&gt;&lt;p&gt;By late 2025, around 78% percent of organisations had reported using AI, up from 55% in 2024, and it’s claimed that 40% of US workers use generative AI in their jobs. Nearly half of US businesses now pay for AI subscriptions. The report poses these figures as evidence that AI has moved from experimentation into routine production.&lt;/p&gt;&lt;p&gt;Internationally, the document frames AI as a factor in divergence of economic prosperity, with AI in the US increasing America’s GDP growth faster than in Europe and China. The US leads at the moment in private AI investment, model development, and compute capacity, while the EU’s share of world GDP has fallen since 1980. Additionally, the continent lags in comparable AI metrics – investment, construction, software development, overall capacity, etc. China remains a major player in AI actor, but the report notes that much of its model training relies on US-designed hardware.&lt;/p&gt;&lt;p&gt;The White House publication advocates for an integrated national strategy with investment incentives at its core. The One Big Beautiful Bill Act gave significant financial breaks for data centres and IT infrastructure, and created favourable conditions for speedy facility construction, in line with the Act’s aim to lift GDP growth by more than a percentage point per year over the medium term. The report argues that deregulation in the AI industry supports productivity by lowering costs, increasing competition, and speeding innovation. Trade agreements and foreign policy reinforce this approach, with overseas partners committing to large purchases of US-derived AI chips and infrastructure.&lt;/p&gt;&lt;p&gt;The paper notes that AI data centres are electricity-intensive, and projects that demand for power by AI infrastructure could reach up to 12% of domestic electricity consumption by 2028. It links the success of AI to energy availability and the ability of the power grid to deliver, positioning the control of energy supply as a prerequisite for international leadership in AI.&lt;/p&gt;&lt;p&gt;The report’s conclusion is that the countries that lead in AI investment and adoption will experience higher growth than the mean. The United States is aligning multiple policy rafts to ensure its leading position in the sector. Businesses that build systems in line with its national goals will be part of a dominant economic force shaping the next phase of global growth.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Chicago Thaws into Spring” by Trey Ratcliff is licensed under CC BY-NC-SA 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A White House paper titled “Artificial Intelligence and the Great Divergence” sets out parallels between the effects of the industrial revolution in the 18th and 19th centuries and the current times, with artificial intelligence positioned as guiding the way the world’s economies will be shaped.&lt;/p&gt;&lt;p&gt;Artificial intelligence now sits at the centre of US economic strategy, currently representing a significant portion of the country’s economic activity, as characterised by the building of AI infrastructure, most notably in the form of data centres. The paper says AI investment raised US GDP by 1.3% percent in the first half of 2025, and compares this with the investment in the railway network during the industrial revolution.&lt;/p&gt;&lt;p&gt;“Artificial Intelligence and the Great Divergence” says long-term growth depends primarily on gains in productivity, and AI is the tool to achieve those gains. It presents a range of estimates of AI’s impact on GDP, from single-digit increases to 20% productivity growth inside a decade. It also floats some more extreme scenarios, where GDP grows at more than 45% as AI substitutes for human labour in the longer term.&lt;/p&gt;&lt;p&gt;Capital deployment in the form of building AI infrastructure, not growing consumption or public spending, is now creating US economic growth. Investment in data processing equipment, buildings, infrastructure, and software grew 28% in early 2025, and AI-related infrastructure represented around a quarter of all US investment in 2025.&lt;/p&gt;&lt;p&gt;Training compute capacity used by AI models has increased roughly four-fold per year since 2010, and the length of tasks AI systems can complete has doubled every seven months for six years, the paper states. The cost per token of AI output has fallen by factors ranging from nine to nine hundred per year, depending on task and model.&lt;/p&gt;&lt;p&gt;By late 2025, around 78% percent of organisations had reported using AI, up from 55% in 2024, and it’s claimed that 40% of US workers use generative AI in their jobs. Nearly half of US businesses now pay for AI subscriptions. The report poses these figures as evidence that AI has moved from experimentation into routine production.&lt;/p&gt;&lt;p&gt;Internationally, the document frames AI as a factor in divergence of economic prosperity, with AI in the US increasing America’s GDP growth faster than in Europe and China. The US leads at the moment in private AI investment, model development, and compute capacity, while the EU’s share of world GDP has fallen since 1980. Additionally, the continent lags in comparable AI metrics – investment, construction, software development, overall capacity, etc. China remains a major player in AI actor, but the report notes that much of its model training relies on US-designed hardware.&lt;/p&gt;&lt;p&gt;The White House publication advocates for an integrated national strategy with investment incentives at its core. The One Big Beautiful Bill Act gave significant financial breaks for data centres and IT infrastructure, and created favourable conditions for speedy facility construction, in line with the Act’s aim to lift GDP growth by more than a percentage point per year over the medium term. The report argues that deregulation in the AI industry supports productivity by lowering costs, increasing competition, and speeding innovation. Trade agreements and foreign policy reinforce this approach, with overseas partners committing to large purchases of US-derived AI chips and infrastructure.&lt;/p&gt;&lt;p&gt;The paper notes that AI data centres are electricity-intensive, and projects that demand for power by AI infrastructure could reach up to 12% of domestic electricity consumption by 2028. It links the success of AI to energy availability and the ability of the power grid to deliver, positioning the control of energy supply as a prerequisite for international leadership in AI.&lt;/p&gt;&lt;p&gt;The report’s conclusion is that the countries that lead in AI investment and adoption will experience higher growth than the mean. The United States is aligning multiple policy rafts to ensure its leading position in the sector. Businesses that build systems in line with its national goals will be part of a dominant economic force shaping the next phase of global growth.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Chicago Thaws into Spring” by Trey Ratcliff is licensed under CC BY-NC-SA 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/white-house-predicts-ai-growth-with-comparison-industrial-and-artificial-intelligence-revolutions/</guid><pubDate>Wed, 28 Jan 2026 12:04:00 +0000</pubDate></item><item><title>[NEW] Masumi Network: How AI-blockchain fusion adds trust to burgeoning agent economy (AI News)</title><link>https://www.artificialintelligence-news.com/news/masumi-network-how-ai-blockchain-fusion-adds-trust-to-burgeoning-agent-economy/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/pexels-googledeepmind-17485706-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;2026 will see forward-thinking organisations building out their squads of AI agents across roles and functions. But amid the rush, there is another aspect to consider.&lt;/p&gt;&lt;p&gt;One of IDC’s enterprise technology predictions for the coming five years, published in October, was fascinating. “By 2030, up to 20% of [global 1000] organisations will have faced lawsuits, substantial fines, and CIO dismissals, due to high-profile disruptions stemming from inadequate controls and governance of AI agents,” the analyst noted.&lt;/p&gt;&lt;p&gt;How do you therefore put guardrails in place – and how do you ensure these agents work together and, ultimately, do business together? Patrick Tobler, founder and CEO of blockchain infrastructure platform provider NMKR, is working on a project which aims to solve this – by fusing agentic AI and decentralisation.&lt;/p&gt;&lt;p&gt;The Masumi Network, born out of a collaboration between NMKR and Serviceplan Group, launched in late 2024 as a framework-agnostic infrastructure which ‘empowers developers to build autonomous agents that collaborate, monetise services, and maintain verifiable trust.’&lt;/p&gt;&lt;p&gt;“The core thesis of Masumi is that there’s going to be billions of different AI agents from different companies interacting with each other in the future,” explains Tobler. “The difficult part now is – how do you actually have agents from different companies that can interact with each other and send money to each other as well, across these different companies?”&lt;/p&gt;&lt;p&gt;Take travel as an example. You want to attend an industry conference, so your hotel booking agent buys a plane ticket from your airline agent. The entire experience and transaction will be seamless – but that implicit trust is required.&lt;/p&gt;&lt;p&gt;“Masumi is a decentralised network of agents, so it’s not relying on any centralised payment infrastructure,” says Tobler. “Instead, agents are equipped with wallets and can send stablecoins from one agent to another and, because of that, interacting with each other in a completely safe and trustless manner.”&lt;/p&gt;&lt;p&gt;For Tobler, having spent in his words ‘a lot of time’ in crypto, he determined that its benefits were being pointed to the wrong place.&lt;/p&gt;&lt;p&gt;“I think there’s a lot of these problems that we have solved in crypto for humans, and then I came to this conclusion that maybe we’ve been solving them or the wrong target audience,” he explains. “Because for humans, using crypto and wallets and blockchains, all that kind of stuff is extremely difficult; the user experience is not great. But for agents, they don’t care if it’s difficult to use. They just use it, and it’s very native to them.&lt;/p&gt;&lt;p&gt;“So all these issues that are now arising with agents having to interact with millions, or maybe even billions, of agents in the future – these problems have all already been solved with crypto.”&lt;/p&gt;&lt;p&gt;Tobler is attending AI &amp;amp; Big Data Expo Global as part of Discover Cardano; NMKR started on the Cardano blockchain, while Masumi is built completely on Cardano. He says he is looking forward to speaking with businesses that are ‘hearing a lot about AI but aren’t really using it much besides ChatGPT’.&lt;/p&gt;&lt;p&gt;“I want to understand from them what they are doing, and then figure out how we can help them,” he says. “That’s most often the thing missing from traditional tech startups. We’re all building for our own bubble, instead of actually talking to the people that would be using it every day.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Discover Cardano is exhibiting at the AI &amp;amp; Big Data Expo Global, in London on February 4-5. Watch the full video interview with NMKR’s Patrick Tobler below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" height="1080" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Patrick_Tobler_NMKR_.mp4" width="1920"&gt;&lt;/video&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Photo by Google DeepMind&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/pexels-googledeepmind-17485706-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;2026 will see forward-thinking organisations building out their squads of AI agents across roles and functions. But amid the rush, there is another aspect to consider.&lt;/p&gt;&lt;p&gt;One of IDC’s enterprise technology predictions for the coming five years, published in October, was fascinating. “By 2030, up to 20% of [global 1000] organisations will have faced lawsuits, substantial fines, and CIO dismissals, due to high-profile disruptions stemming from inadequate controls and governance of AI agents,” the analyst noted.&lt;/p&gt;&lt;p&gt;How do you therefore put guardrails in place – and how do you ensure these agents work together and, ultimately, do business together? Patrick Tobler, founder and CEO of blockchain infrastructure platform provider NMKR, is working on a project which aims to solve this – by fusing agentic AI and decentralisation.&lt;/p&gt;&lt;p&gt;The Masumi Network, born out of a collaboration between NMKR and Serviceplan Group, launched in late 2024 as a framework-agnostic infrastructure which ‘empowers developers to build autonomous agents that collaborate, monetise services, and maintain verifiable trust.’&lt;/p&gt;&lt;p&gt;“The core thesis of Masumi is that there’s going to be billions of different AI agents from different companies interacting with each other in the future,” explains Tobler. “The difficult part now is – how do you actually have agents from different companies that can interact with each other and send money to each other as well, across these different companies?”&lt;/p&gt;&lt;p&gt;Take travel as an example. You want to attend an industry conference, so your hotel booking agent buys a plane ticket from your airline agent. The entire experience and transaction will be seamless – but that implicit trust is required.&lt;/p&gt;&lt;p&gt;“Masumi is a decentralised network of agents, so it’s not relying on any centralised payment infrastructure,” says Tobler. “Instead, agents are equipped with wallets and can send stablecoins from one agent to another and, because of that, interacting with each other in a completely safe and trustless manner.”&lt;/p&gt;&lt;p&gt;For Tobler, having spent in his words ‘a lot of time’ in crypto, he determined that its benefits were being pointed to the wrong place.&lt;/p&gt;&lt;p&gt;“I think there’s a lot of these problems that we have solved in crypto for humans, and then I came to this conclusion that maybe we’ve been solving them or the wrong target audience,” he explains. “Because for humans, using crypto and wallets and blockchains, all that kind of stuff is extremely difficult; the user experience is not great. But for agents, they don’t care if it’s difficult to use. They just use it, and it’s very native to them.&lt;/p&gt;&lt;p&gt;“So all these issues that are now arising with agents having to interact with millions, or maybe even billions, of agents in the future – these problems have all already been solved with crypto.”&lt;/p&gt;&lt;p&gt;Tobler is attending AI &amp;amp; Big Data Expo Global as part of Discover Cardano; NMKR started on the Cardano blockchain, while Masumi is built completely on Cardano. He says he is looking forward to speaking with businesses that are ‘hearing a lot about AI but aren’t really using it much besides ChatGPT’.&lt;/p&gt;&lt;p&gt;“I want to understand from them what they are doing, and then figure out how we can help them,” he says. “That’s most often the thing missing from traditional tech startups. We’re all building for our own bubble, instead of actually talking to the people that would be using it every day.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Discover Cardano is exhibiting at the AI &amp;amp; Big Data Expo Global, in London on February 4-5. Watch the full video interview with NMKR’s Patrick Tobler below:&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-video"&gt;&lt;video controls="controls" height="1080" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Patrick_Tobler_NMKR_.mp4" width="1920"&gt;&lt;/video&gt;&lt;/figure&gt;&lt;p&gt;&lt;em&gt;Photo by Google DeepMind&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/masumi-network-how-ai-blockchain-fusion-adds-trust-to-burgeoning-agent-economy/</guid><pubDate>Wed, 28 Jan 2026 12:28:14 +0000</pubDate></item><item><title>[NEW] Users flock to open source Moltbot for always-on AI, despite major risks (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/viral-ai-assistant-moltbot-rapidly-gains-popularity-but-poses-security-risks/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The open source “Jarvis” chats via WhatsApp but requires access to your files and accounts.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a white lobster on a cyberpunk background." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/clawdbot_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of a white lobster on a cyberpunk background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/clawdbot_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Muhammad Shabraiz via Getty Images / Benj Edwards

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An open source AI assistant called Moltbot (formerly “Clawdbot”) recently crossed 69,000 stars on GitHub after a month, making it one of the fastest-growing AI projects of 2026. Created by Austrian developer Peter Steinberger, the tool lets users run a personal AI assistant and control it through messaging apps they already use. While some say it feels like the AI assistant of the future, running the tool as currently designed comes with serious security risks.&lt;/p&gt;
&lt;p&gt;Among the dozens of unofficial AI bot apps that never rise above the fray, Moltbot is perhaps most notable for its proactive communication with the user. The assistant works with WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, and other platforms. It can reach out to users with reminders, alerts, or morning briefings based on calendar events or other triggers. The project has drawn comparisons to Jarvis, the AI assistant from the Iron Man films, for its ability to actively attempt to manage tasks across a user’s digital life.&lt;/p&gt;
&lt;p&gt;However, we’ll tell you up front that there are plenty of drawbacks to the still-hobbyist software: While the organizing assistant code runs on a local machine, the tool effectively requires a subscription to Anthropic or OpenAI for model access (or using an API key). Users can run local AI models with the bot, but they are currently less effective at carrying out tasks than the best commercial models. Claude Opus 4.5, which is Anthropic’s flagship large language model (LLM), is a popular choice.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2137714 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A screenshot of talking with Clawdbot / Moltbot taken from its GitHub page." class="fullwidth full" height="1024" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/whatsapp-clawd.jpg" width="471" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of talking with Clawdbot / Moltbot taken from its GitHub page.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Moltbot

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Setting up Moltbot requires configuring a server, managing authentication, and understanding sandboxing for even a slice of security in a system that basically demands access to every facet of your digital life. Heavy use can rack up significant API costs, since agentic systems make many calls behind the scenes and use up a lot of tokens.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We’ve only just begun to try Moltbot ourselves (more on that soon), but we’ve seen plenty of discussions about the new assistant circulating in the AI community. The all-in approach has serious security drawbacks, since it requires access to messaging accounts, API keys, and in some configurations, shell commands. Also, an always-on agent with access to messaging channels and personal systems can quickly expand your attack surface.&lt;/p&gt;
&lt;h2&gt;The always-on AI bot&lt;/h2&gt;
&lt;p&gt;Even with all the drawbacks listed above, people are still using Moltbot. MacStories editor Federico Viticci, who spent a week testing the tool, described it as “Claude with hands,” referring to how it connects a large language model (LLM) backend with real-world capabilities like browser control, email management, and file operations.&lt;/p&gt;
&lt;p&gt;The project’s documentation describes it as a tool for users who want “a personal, single-user assistant that feels local, fast, and always-on.”&lt;/p&gt;
&lt;p&gt;According to the project’s GitHub page, Steinberger designed the bot to retain long-term memory and execute commands directly on the user’s system, unlike current web-based chatbots from major AI labs. It’s closer to Claude Code and Codex CLI (which also operate on local files using a cloud AI model), but with more latitude to take local actions on the user’s behalf.&lt;/p&gt;
&lt;p&gt;Moltbot stores memory as Markdown files and a SQLite database on the user’s machine. It auto-generates daily notes that log interactions and uses vector search to retrieve relevant context from past conversations. The memory persists across sessions because the bot runs as a background daemon.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Compared to Claude Code, which is session-based, Moltbot runs persistently (24/7) and maintains its stored memory indefinitely. It can reportedly recall what you discussed weeks ago. With Claude Code, when you close it, the conversation context is gone (unless you use CLAUDE.md files for project context).&lt;/p&gt;
&lt;h2&gt;Turbulent week for the project&lt;/h2&gt;
&lt;p&gt;The project’s rapid rise has not come without complications. On Monday, Anthropic asked Steinberger to change the project’s name due to trademark concerns (since “Clawd” sounds like “Claude”), prompting the rebrand from Clawdbot to Moltbot. “Clawdbot” was originally named after the ASCII art creature that appears when you launch Claude Code on a terminal.&lt;/p&gt;
&lt;p&gt;However, the transition enabled bad actors to hijack Steinberger’s old social media and GitHub handles, reports The Register. Crypto scammers launched fake tokens using the project’s name, with one reaching a $16 million market cap before crashing. Steinberger responded on X: “Any project that lists me as a coin owner is a SCAM. No, I will not accept fees. You are actively damaging the project.”&lt;/p&gt;
&lt;p&gt;Security researchers have also found vulnerabilities in misconfigured public deployments. Bitdefender reported that exposed dashboards allowed outsiders to view configuration data, retrieve API keys, and browse full conversation histories from private chats.&lt;/p&gt;
&lt;p&gt;While there’s plenty of hype about Moltbot right now, be advised that any LLM that has access to your local machine is susceptible to prompt injection attacks that can “trick” the AI model to share your personal data with other people or remote servers. While Moltbot offers a glimpse at what future AI assistants from major vendors might look like, it’s still experimental and not yet ready for users who aren’t comfortable trading today’s AI convenience (such as it is) for major security risks.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The open source “Jarvis” chats via WhatsApp but requires access to your files and accounts.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a white lobster on a cyberpunk background." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/clawdbot_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of a white lobster on a cyberpunk background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/clawdbot_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Muhammad Shabraiz via Getty Images / Benj Edwards

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;An open source AI assistant called Moltbot (formerly “Clawdbot”) recently crossed 69,000 stars on GitHub after a month, making it one of the fastest-growing AI projects of 2026. Created by Austrian developer Peter Steinberger, the tool lets users run a personal AI assistant and control it through messaging apps they already use. While some say it feels like the AI assistant of the future, running the tool as currently designed comes with serious security risks.&lt;/p&gt;
&lt;p&gt;Among the dozens of unofficial AI bot apps that never rise above the fray, Moltbot is perhaps most notable for its proactive communication with the user. The assistant works with WhatsApp, Telegram, Slack, Discord, Google Chat, Signal, iMessage, Microsoft Teams, and other platforms. It can reach out to users with reminders, alerts, or morning briefings based on calendar events or other triggers. The project has drawn comparisons to Jarvis, the AI assistant from the Iron Man films, for its ability to actively attempt to manage tasks across a user’s digital life.&lt;/p&gt;
&lt;p&gt;However, we’ll tell you up front that there are plenty of drawbacks to the still-hobbyist software: While the organizing assistant code runs on a local machine, the tool effectively requires a subscription to Anthropic or OpenAI for model access (or using an API key). Users can run local AI models with the bot, but they are currently less effective at carrying out tasks than the best commercial models. Claude Opus 4.5, which is Anthropic’s flagship large language model (LLM), is a popular choice.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2137714 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A screenshot of talking with Clawdbot / Moltbot taken from its GitHub page." class="fullwidth full" height="1024" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/whatsapp-clawd.jpg" width="471" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of talking with Clawdbot / Moltbot taken from its GitHub page.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Moltbot

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Setting up Moltbot requires configuring a server, managing authentication, and understanding sandboxing for even a slice of security in a system that basically demands access to every facet of your digital life. Heavy use can rack up significant API costs, since agentic systems make many calls behind the scenes and use up a lot of tokens.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;We’ve only just begun to try Moltbot ourselves (more on that soon), but we’ve seen plenty of discussions about the new assistant circulating in the AI community. The all-in approach has serious security drawbacks, since it requires access to messaging accounts, API keys, and in some configurations, shell commands. Also, an always-on agent with access to messaging channels and personal systems can quickly expand your attack surface.&lt;/p&gt;
&lt;h2&gt;The always-on AI bot&lt;/h2&gt;
&lt;p&gt;Even with all the drawbacks listed above, people are still using Moltbot. MacStories editor Federico Viticci, who spent a week testing the tool, described it as “Claude with hands,” referring to how it connects a large language model (LLM) backend with real-world capabilities like browser control, email management, and file operations.&lt;/p&gt;
&lt;p&gt;The project’s documentation describes it as a tool for users who want “a personal, single-user assistant that feels local, fast, and always-on.”&lt;/p&gt;
&lt;p&gt;According to the project’s GitHub page, Steinberger designed the bot to retain long-term memory and execute commands directly on the user’s system, unlike current web-based chatbots from major AI labs. It’s closer to Claude Code and Codex CLI (which also operate on local files using a cloud AI model), but with more latitude to take local actions on the user’s behalf.&lt;/p&gt;
&lt;p&gt;Moltbot stores memory as Markdown files and a SQLite database on the user’s machine. It auto-generates daily notes that log interactions and uses vector search to retrieve relevant context from past conversations. The memory persists across sessions because the bot runs as a background daemon.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Compared to Claude Code, which is session-based, Moltbot runs persistently (24/7) and maintains its stored memory indefinitely. It can reportedly recall what you discussed weeks ago. With Claude Code, when you close it, the conversation context is gone (unless you use CLAUDE.md files for project context).&lt;/p&gt;
&lt;h2&gt;Turbulent week for the project&lt;/h2&gt;
&lt;p&gt;The project’s rapid rise has not come without complications. On Monday, Anthropic asked Steinberger to change the project’s name due to trademark concerns (since “Clawd” sounds like “Claude”), prompting the rebrand from Clawdbot to Moltbot. “Clawdbot” was originally named after the ASCII art creature that appears when you launch Claude Code on a terminal.&lt;/p&gt;
&lt;p&gt;However, the transition enabled bad actors to hijack Steinberger’s old social media and GitHub handles, reports The Register. Crypto scammers launched fake tokens using the project’s name, with one reaching a $16 million market cap before crashing. Steinberger responded on X: “Any project that lists me as a coin owner is a SCAM. No, I will not accept fees. You are actively damaging the project.”&lt;/p&gt;
&lt;p&gt;Security researchers have also found vulnerabilities in misconfigured public deployments. Bitdefender reported that exposed dashboards allowed outsiders to view configuration data, retrieve API keys, and browse full conversation histories from private chats.&lt;/p&gt;
&lt;p&gt;While there’s plenty of hype about Moltbot right now, be advised that any LLM that has access to your local machine is susceptible to prompt injection attacks that can “trick” the AI model to share your personal data with other people or remote servers. While Moltbot offers a glimpse at what future AI assistants from major vendors might look like, it’s still experimental and not yet ready for users who aren’t comfortable trading today’s AI convenience (such as it is) for major security risks.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/viral-ai-assistant-moltbot-rapidly-gains-popularity-but-poses-security-risks/</guid><pubDate>Wed, 28 Jan 2026 12:30:44 +0000</pubDate></item></channel></rss>