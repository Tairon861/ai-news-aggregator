<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 24 Nov 2025 18:33:32 +0000</lastBuildDate><item><title> ()</title><link>https://www.wired.com/feed/category/artificial-intelligence/rss</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.wired.com/feed/category/artificial-intelligence/rss</guid></item><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Qwen AI hits 10m+ downloads as Alibaba disrupts the AI market (AI News)</title><link>https://www.artificialintelligence-news.com/news/alibaba-qwen-ai-app-10-million-downloads/</link><description>&lt;p&gt;Alibaba’s recently launched Qwen AI app has demonstrated remarkable market traction, accumulating 10 million downloads in the seven days since its public beta release – a velocity that exceeds the early adoption rates of ChatGPT, Sora, and DeepSeek.&lt;/p&gt;&lt;p&gt;The application’s rapid uptake reflects a shift in how technology giants are approaching AI commercialisation. While international competitors like OpenAI and Anthropic have built their businesses around subscription models, Alibaba’s free-access approach challenges this framework by integrating AI capabilities directly into existing consumer and enterprise ecosystems.&lt;/p&gt;&lt;p&gt;According to the &lt;em&gt;South China Morning Post&lt;/em&gt;, the Qwen app serves as “a comprehensive AI tool designed to meet user needs in both professional and personal contexts,” rather than being portrayed as a chatbot.&lt;/p&gt;&lt;p&gt;Available on Apple’s App Store and Google Play since mid-November, the application integrates with Alibaba’s e-commerce platforms, mapping services, and local business tools – demonstrating what industry analysts term “agentic AI” capabilities that can execute cross-scenario tasks in addition to generating content.&lt;/p&gt;&lt;h3&gt;Enterprise adoption drives momentum&lt;/h3&gt;&lt;p&gt;The technical foundation underpinning the Qwen AI app’s consumer success has been building since 2023, when Alibaba fully open-sourced its Qwen model. Its decision has resulted in cumulative global downloads exceeding 600 million, establishing Qwen as one of the world’s most widely adopted open-source large language models.&lt;/p&gt;&lt;p&gt;For enterprises evaluating AI deployment strategies, this adoption pattern offers instructive insights. The recently released Qwen3-Max model now ranks among the top three globally in performance benchmarks, with notable traction in Silicon Valley. Airbnb CEO Brian Chesky has stated publicly that his company “heavily relies on Qwen”, while NVIDIA CEO Jensen Huang acknowledged Qwen’s growing dominance in the global open-source model space.&lt;/p&gt;&lt;p&gt;The enterprise endorsements signal practical business value rather than speculative potential. Companies implementing AI solutions face persistent challenges around cost management, integration complexity, and demonstrable return on investment. Alibaba’s strategy addresses these issues, offering models without licensing fees and providing integration pathways through its broader ecosystem.&lt;/p&gt;&lt;h3&gt;Competitive implications for business leaders&lt;/h3&gt;&lt;p&gt;Su Lian Jye, chief analyst at consultancy Omdia, told &lt;em&gt;SCMP&lt;/em&gt; that increased user adoption generates valuable feedback loops: “More users mean more feedback, which would allow Alibaba to further fine-tune its models.” The observation highlights a competitive advantage for cloud service providers with substantial capital reserves and existing user data infrastructure.&lt;/p&gt;&lt;p&gt;The timing of Qwen’s launch carries strategic significance. Chinese AI startups Moonshot AI and Zhipu AI introduced subscription fees recently for their Kimi and ChatGLM services respectively, creating an opening for Alibaba’s free-access positioning.&lt;/p&gt;&lt;p&gt;Su noted AI startups might struggle to compete with this approach, which “will only work for cloud service providers that have large capital reserves and can monetise user data.” For enterprise decision-makers, the competitive dynamic presents opportunities and considerations.&lt;/p&gt;&lt;p&gt;Free-access models reduce initial deployment costs but raise questions about long-term sustainability, data privacy frameworks, and vendor lock-in risks. Organisations adopting AI tools must evaluate whether immediate cost savings align with their governance requirements and strategic independence.&lt;/p&gt;&lt;h3&gt;Navigating geopolitical complexity&lt;/h3&gt;&lt;p&gt;The Qwen app’s success unfolds against a backdrop of intensifying US-China technology competition. Some US observers have expressed concerns about Alibaba’s advancement rate and investment scale. Marketing specialist Tulsi Soni remarked on social media that “we’re witnessing a full-blown Qwen panic” in Silicon Valley – a comment reflecting anxiety about competitive positioning rather than technical assessment.&lt;/p&gt;&lt;p&gt;Alibaba has also faced scrutiny, including unsubstantiated allegations from the &lt;em&gt;Financial Times &lt;/em&gt;regarding Chinese military applications, which the company rejects. For multinational enterprises operating in these geopolitical boundaries, such tensions complicate AI procurement decisions and require careful risk assessment.&lt;/p&gt;&lt;h3&gt;What this means for enterprise AI strategy&lt;/h3&gt;&lt;p&gt;The Qwen AI app’s trajectory offers several practical takeaways for business leaders navigating AI adoption. First, open-source models have matured to competitive parity with proprietary alternatives in many cases, potentially reducing dependency on subscription-based providers.&lt;/p&gt;&lt;p&gt;Second, ecosystem integration – connecting AI capabilities with existing business tools – delivers more immediate value than standalone chatbot functionality. Third, the bifurcation between free-access and subscription models will likely intensify, requiring organisations to evaluate the total cost of ownership beyond licensing fees.&lt;/p&gt;&lt;p&gt;As Alibaba positions Qwen for evolution into what industry observers describe as “a national-level application,” enterprises worldwide face strategic choices about AI infrastructure. The question is no longer whether to adopt AI tools, but which deployment models align with specific business requirements, risk tolerances, and competitive positioning.&lt;/p&gt;&lt;p&gt;The coming months will reveal whether Alibaba can monetise its massive user base successfully and maintain the technical performance that attracted enterprise adopters. For now, the Qwen AI app’s early success demonstrates that alternative business models can compete effectively against established subscription frameworks – a development that should inform enterprise planning in industries.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Alibaba rolls out revamped Qwen chatbot as model pricing drops&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Alibaba’s recently launched Qwen AI app has demonstrated remarkable market traction, accumulating 10 million downloads in the seven days since its public beta release – a velocity that exceeds the early adoption rates of ChatGPT, Sora, and DeepSeek.&lt;/p&gt;&lt;p&gt;The application’s rapid uptake reflects a shift in how technology giants are approaching AI commercialisation. While international competitors like OpenAI and Anthropic have built their businesses around subscription models, Alibaba’s free-access approach challenges this framework by integrating AI capabilities directly into existing consumer and enterprise ecosystems.&lt;/p&gt;&lt;p&gt;According to the &lt;em&gt;South China Morning Post&lt;/em&gt;, the Qwen app serves as “a comprehensive AI tool designed to meet user needs in both professional and personal contexts,” rather than being portrayed as a chatbot.&lt;/p&gt;&lt;p&gt;Available on Apple’s App Store and Google Play since mid-November, the application integrates with Alibaba’s e-commerce platforms, mapping services, and local business tools – demonstrating what industry analysts term “agentic AI” capabilities that can execute cross-scenario tasks in addition to generating content.&lt;/p&gt;&lt;h3&gt;Enterprise adoption drives momentum&lt;/h3&gt;&lt;p&gt;The technical foundation underpinning the Qwen AI app’s consumer success has been building since 2023, when Alibaba fully open-sourced its Qwen model. Its decision has resulted in cumulative global downloads exceeding 600 million, establishing Qwen as one of the world’s most widely adopted open-source large language models.&lt;/p&gt;&lt;p&gt;For enterprises evaluating AI deployment strategies, this adoption pattern offers instructive insights. The recently released Qwen3-Max model now ranks among the top three globally in performance benchmarks, with notable traction in Silicon Valley. Airbnb CEO Brian Chesky has stated publicly that his company “heavily relies on Qwen”, while NVIDIA CEO Jensen Huang acknowledged Qwen’s growing dominance in the global open-source model space.&lt;/p&gt;&lt;p&gt;The enterprise endorsements signal practical business value rather than speculative potential. Companies implementing AI solutions face persistent challenges around cost management, integration complexity, and demonstrable return on investment. Alibaba’s strategy addresses these issues, offering models without licensing fees and providing integration pathways through its broader ecosystem.&lt;/p&gt;&lt;h3&gt;Competitive implications for business leaders&lt;/h3&gt;&lt;p&gt;Su Lian Jye, chief analyst at consultancy Omdia, told &lt;em&gt;SCMP&lt;/em&gt; that increased user adoption generates valuable feedback loops: “More users mean more feedback, which would allow Alibaba to further fine-tune its models.” The observation highlights a competitive advantage for cloud service providers with substantial capital reserves and existing user data infrastructure.&lt;/p&gt;&lt;p&gt;The timing of Qwen’s launch carries strategic significance. Chinese AI startups Moonshot AI and Zhipu AI introduced subscription fees recently for their Kimi and ChatGLM services respectively, creating an opening for Alibaba’s free-access positioning.&lt;/p&gt;&lt;p&gt;Su noted AI startups might struggle to compete with this approach, which “will only work for cloud service providers that have large capital reserves and can monetise user data.” For enterprise decision-makers, the competitive dynamic presents opportunities and considerations.&lt;/p&gt;&lt;p&gt;Free-access models reduce initial deployment costs but raise questions about long-term sustainability, data privacy frameworks, and vendor lock-in risks. Organisations adopting AI tools must evaluate whether immediate cost savings align with their governance requirements and strategic independence.&lt;/p&gt;&lt;h3&gt;Navigating geopolitical complexity&lt;/h3&gt;&lt;p&gt;The Qwen app’s success unfolds against a backdrop of intensifying US-China technology competition. Some US observers have expressed concerns about Alibaba’s advancement rate and investment scale. Marketing specialist Tulsi Soni remarked on social media that “we’re witnessing a full-blown Qwen panic” in Silicon Valley – a comment reflecting anxiety about competitive positioning rather than technical assessment.&lt;/p&gt;&lt;p&gt;Alibaba has also faced scrutiny, including unsubstantiated allegations from the &lt;em&gt;Financial Times &lt;/em&gt;regarding Chinese military applications, which the company rejects. For multinational enterprises operating in these geopolitical boundaries, such tensions complicate AI procurement decisions and require careful risk assessment.&lt;/p&gt;&lt;h3&gt;What this means for enterprise AI strategy&lt;/h3&gt;&lt;p&gt;The Qwen AI app’s trajectory offers several practical takeaways for business leaders navigating AI adoption. First, open-source models have matured to competitive parity with proprietary alternatives in many cases, potentially reducing dependency on subscription-based providers.&lt;/p&gt;&lt;p&gt;Second, ecosystem integration – connecting AI capabilities with existing business tools – delivers more immediate value than standalone chatbot functionality. Third, the bifurcation between free-access and subscription models will likely intensify, requiring organisations to evaluate the total cost of ownership beyond licensing fees.&lt;/p&gt;&lt;p&gt;As Alibaba positions Qwen for evolution into what industry observers describe as “a national-level application,” enterprises worldwide face strategic choices about AI infrastructure. The question is no longer whether to adopt AI tools, but which deployment models align with specific business requirements, risk tolerances, and competitive positioning.&lt;/p&gt;&lt;p&gt;The coming months will reveal whether Alibaba can monetise its massive user base successfully and maintain the technical performance that attracted enterprise adopters. For now, the Qwen AI app’s early success demonstrates that alternative business models can compete effectively against established subscription frameworks – a development that should inform enterprise planning in industries.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Alibaba rolls out revamped Qwen chatbot as model pricing drops&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/alibaba-qwen-ai-app-10-million-downloads/</guid><pubDate>Mon, 24 Nov 2025 09:00:00 +0000</pubDate></item><item><title>4 best essay writing websites students choose over AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/4-best-essay-writing-websites-students-choose-over-ai/</link><description>&lt;p&gt;We’ve all seen the headlines: a third of US college students say they use ChatGPT for writing tasks at least once a month. The share of US teens turning to the same tool for schoolwork doubled between 2023 and 2024. Generative AI tools overall are a fixture of life for seven out of ten teens.&lt;/p&gt;&lt;p&gt;The advent of ChatGPT and its competitors was supposed to put even the best essay writing services out of business. After all, generative AI can create an essay in seconds. So, why pay a professional to take care of it?&lt;/p&gt;&lt;p&gt;Yet, three years after the launch of ChatGPT, academic help services are still going strong. Here’s why US students continue to choose expert help over AI-generated content, and the four services they trust with their assignments.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-students-actually-use-ai-tools"&gt;How students actually use AI tools&lt;/h3&gt;&lt;p&gt;When it first made the news, ChatGPT was called “the death of the English essay.” Now, that kind of language seems like a promise of an apocalypse that (predictably, in hindsight) never came.&lt;/p&gt;&lt;p&gt;Today, students don’t use generative AI tools to generate whole essays. Across multiple surveys, brainstorming, outlining, research, and test prep emerge as the main use cases for AI. For example, the survey from University of California Irvine found that:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;66% use AI to learn more on a specific topic/subject&lt;/li&gt;&lt;li&gt;56% use it to prepare for tests&lt;/li&gt;&lt;li&gt;55% use it to find academic sources&lt;/li&gt;&lt;li&gt;46% use it for note-taking&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Only a third of respondents (31%) reported turning to AI tools to write essays. The percentage went even lower for scholarship and college application essays (21%).&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-students-still-opt-for-top-essay-writing-services"&gt;Why students still opt for top essay writing services&lt;/h3&gt;&lt;p&gt;While AI tools are great at generating long texts in a blink of an eye for free, that’s where their benefits typically end. Unlike professional writers, AI simply can’t:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Grasp all the intricacies and subtleties of the expectations toward an essay, especially if it’s meant for a college or scholarship application&lt;/li&gt;&lt;li&gt;Capture the customer’s authentic voice based on samples of their previous writing&lt;/li&gt;&lt;li&gt;Write an essay that’s truly distinct and memorable: AI tools regurgitate cliché narratives and generic statements&lt;/li&gt;&lt;li&gt;Come up with qualitatively new ideas and arguments: AI can only repeat the opinions already out there&lt;/li&gt;&lt;li&gt;Verify the essay is 100% factually correct: AI tools can hallucinate facts, and many don’t even include precise sources of information&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Potential AI checks are another concern that pushes some students to hire a top essay writing service instead of using AI. For one, Turnitin automatically checks all assignments for both plagiarism and AI content now. Some educators take it on themselves to run AI content scans, too. An essay written by a professional will pass those checks without a hitch, which can’t be said about an AI-generated one.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-4-best-online-essay-writing-services-students-trust"&gt;4 best online essay writing services students trust&lt;/h3&gt;&lt;p&gt;Which platforms score the highest among the best online essay writing services trusted by US students? Here’s your snapshot of four such platforms:&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Service&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Best for&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Rating (Sitejabber)&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;EssayPro&lt;/td&gt;&lt;td&gt;One-stop help&lt;/td&gt;&lt;td&gt;4.4/5 based on 31,122 reviews&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;WritePaper&lt;/td&gt;&lt;td&gt;In-depth research&lt;/td&gt;&lt;td&gt;5.0/5 based on 1,019 reviews&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MyPaperHelp&lt;/td&gt;&lt;td&gt;Personalised writing&lt;/td&gt;&lt;td&gt;4.8/5 based on 364 reviews&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;PaperWriter&lt;/td&gt;&lt;td&gt;Collaborative approach&lt;/td&gt;&lt;td&gt;4.9/5 based on 848 reviews&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-essaypro-best-for-one-stop-help"&gt;EssayPro: Best for one-stop help&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110841" height="661" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-13-1024x661.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;EssayPro is the essay writing service online with the most extensive track record on this list. As of writing, it has over 30,000 reviews on Sitejabber alone and completes 300,000+ assignments annually.&lt;/p&gt;&lt;p&gt;But that’s not what makes it the best essay writing service. Based on customer reviews, students prefer EssayPro to AI because its essay help remains affordable, all while being more in-depth, insightful, and creative than AI content. The fact that its writers specialise in 140+ subjects and 50+ paper types helped EssayPro secure its popularity, too.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;350+ writers specialising in 140+ subjects&lt;/li&gt;&lt;li&gt;Good price-quality ratio with transparent pricing and no surprise fees&lt;/li&gt;&lt;li&gt;Solid track record of on-time delivery&lt;/li&gt;&lt;li&gt;Free plagiarism and AI reports&lt;/li&gt;&lt;li&gt;Full control over who works on your essay&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Not all orders can be completed in 3 hours&lt;/li&gt;&lt;li&gt;No over-the-phone customer support&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-writepaper-best-for-in-depth-research"&gt;WritePaper: Best for in-depth research&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110842" height="540" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-14-1024x540.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;AI tools can’t do the kind of research, analysis, and synthesis that experts at WritePaper do every day. That’s what makes it the best college essay writing service for essays and other papers that have to be insightful and present advanced, nuanced arguments on a complex topic.&lt;/p&gt;&lt;p&gt;According to the best essay writing service reviews, WritePaper’s experts are especially good at delivering in-depth essays in research-intensive disciplines that require advanced reasoning. Those include nursing, philosophy, psychology, and history.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Solid argumentation and research skills among writers&lt;/li&gt;&lt;li&gt;115+ subjects covered&lt;/li&gt;&lt;li&gt;Around-the-clock support and help&lt;/li&gt;&lt;li&gt;Thoroughly researched essays with advanced reasoning&lt;/li&gt;&lt;li&gt;Diverse formatting options (MLA, APA, Chicago, etc.)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Potentially overwhelming writer selection process&lt;/li&gt;&lt;li&gt;Graphs and tables cost extra&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-mypaperhelp-best-for-personalised-writing"&gt;MyPaperHelp: Best for personalised writing&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110843" height="648" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-15-1024x648.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;While all services on this list provide custom writing services, MyPaperHelp is a paper writing service frequently praised for its personalised approach to orders. Its experts readily work with samples and adapt the style and tone of voice to the essay’s context and purpose. They also build on the ideas, suggestions, and whole outlines added to the order form.&lt;/p&gt;&lt;p&gt;This makes MyPaperHelp the best essay writing website for any essay that has to be highly personal in nature. Think scholarship and college application essays or creative writing assignments that focus on personal experiences rather than academic research.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Wide range of writing styles and tones of voice supported&lt;/li&gt;&lt;li&gt;Essays fully adapted to their context and purpose&lt;/li&gt;&lt;li&gt;High-quality creative writing assignments&lt;/li&gt;&lt;li&gt;Possible to attach samples to the order form that writers build on&lt;/li&gt;&lt;li&gt;Unique, authentic writing that doesn’t rehash generic ideas or clichés&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;You have to be very precise with your instructions to leave no room for misunderstandings&lt;/li&gt;&lt;li&gt;Originality reports aren’t provided by default; you have to request one (although they are free)&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-paperwriter-best-for-collaborative-approach"&gt;PaperWriter: Best for collaborative approach&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110844" height="559" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-16-1024x559.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;Yes, US students turn to PaperWriter for many reasons, but direct writer communication is the most frequently cited one. So, if two-way communication with the writer is important, PaperWriter is definitely worth considering.&lt;/p&gt;&lt;p&gt;PaperWriter’s experts routinely reach out to customers via direct chat whenever they need to clarify the requirements or ask for additional information. That makes PaperWriter the best essay writing service for students who want their essays to reflect their thoughts, ideas, and opinions to the letter.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Direct writer chat with end-to-end encryption&lt;/li&gt;&lt;li&gt;Strict privacy policy that protects confidentiality&lt;/li&gt;&lt;li&gt;Responsive writers who proactively communicate with customers&lt;/li&gt;&lt;li&gt;Unlimited free revisions without mandatory waiting time&lt;/li&gt;&lt;li&gt;Review work services available&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Writer selection may be a bit time-consuming&lt;/li&gt;&lt;li&gt;A collaborative approach is, by definition, also somewhat time-consuming&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-final-thoughts-ai-can-t-rival-human-creativity-amp-expertise"&gt;Final thoughts: AI can’t rival human creativity &amp;amp; expertise&lt;/h3&gt;&lt;p&gt;AI tools may be becoming more ingrained in the learning process, but that doesn’t mean they’re ready to replace human creativity and expertise altogether. Yes, they can help you outline an essay or brainstorm ideas. But only professionals can come up with truly fresh ideas or develop a complex argument on a topic that requires hours of research.&lt;/p&gt;&lt;p&gt;So, it’s safe to say that essay writing services aren’t going anywhere any time soon. They will continue supporting students in their studies, more so than AI tools.&lt;/p&gt;&lt;p&gt;If you’re looking for the best essay writing service, Reddit and other social media platforms are a good place to start. Independent review platforms like Sitejabber and Reviews.io can also come in handy.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p&gt;We’ve all seen the headlines: a third of US college students say they use ChatGPT for writing tasks at least once a month. The share of US teens turning to the same tool for schoolwork doubled between 2023 and 2024. Generative AI tools overall are a fixture of life for seven out of ten teens.&lt;/p&gt;&lt;p&gt;The advent of ChatGPT and its competitors was supposed to put even the best essay writing services out of business. After all, generative AI can create an essay in seconds. So, why pay a professional to take care of it?&lt;/p&gt;&lt;p&gt;Yet, three years after the launch of ChatGPT, academic help services are still going strong. Here’s why US students continue to choose expert help over AI-generated content, and the four services they trust with their assignments.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-students-actually-use-ai-tools"&gt;How students actually use AI tools&lt;/h3&gt;&lt;p&gt;When it first made the news, ChatGPT was called “the death of the English essay.” Now, that kind of language seems like a promise of an apocalypse that (predictably, in hindsight) never came.&lt;/p&gt;&lt;p&gt;Today, students don’t use generative AI tools to generate whole essays. Across multiple surveys, brainstorming, outlining, research, and test prep emerge as the main use cases for AI. For example, the survey from University of California Irvine found that:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;66% use AI to learn more on a specific topic/subject&lt;/li&gt;&lt;li&gt;56% use it to prepare for tests&lt;/li&gt;&lt;li&gt;55% use it to find academic sources&lt;/li&gt;&lt;li&gt;46% use it for note-taking&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Only a third of respondents (31%) reported turning to AI tools to write essays. The percentage went even lower for scholarship and college application essays (21%).&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-students-still-opt-for-top-essay-writing-services"&gt;Why students still opt for top essay writing services&lt;/h3&gt;&lt;p&gt;While AI tools are great at generating long texts in a blink of an eye for free, that’s where their benefits typically end. Unlike professional writers, AI simply can’t:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Grasp all the intricacies and subtleties of the expectations toward an essay, especially if it’s meant for a college or scholarship application&lt;/li&gt;&lt;li&gt;Capture the customer’s authentic voice based on samples of their previous writing&lt;/li&gt;&lt;li&gt;Write an essay that’s truly distinct and memorable: AI tools regurgitate cliché narratives and generic statements&lt;/li&gt;&lt;li&gt;Come up with qualitatively new ideas and arguments: AI can only repeat the opinions already out there&lt;/li&gt;&lt;li&gt;Verify the essay is 100% factually correct: AI tools can hallucinate facts, and many don’t even include precise sources of information&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Potential AI checks are another concern that pushes some students to hire a top essay writing service instead of using AI. For one, Turnitin automatically checks all assignments for both plagiarism and AI content now. Some educators take it on themselves to run AI content scans, too. An essay written by a professional will pass those checks without a hitch, which can’t be said about an AI-generated one.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-4-best-online-essay-writing-services-students-trust"&gt;4 best online essay writing services students trust&lt;/h3&gt;&lt;p&gt;Which platforms score the highest among the best online essay writing services trusted by US students? Here’s your snapshot of four such platforms:&lt;/p&gt;&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Service&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Best for&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Rating (Sitejabber)&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;EssayPro&lt;/td&gt;&lt;td&gt;One-stop help&lt;/td&gt;&lt;td&gt;4.4/5 based on 31,122 reviews&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;WritePaper&lt;/td&gt;&lt;td&gt;In-depth research&lt;/td&gt;&lt;td&gt;5.0/5 based on 1,019 reviews&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;MyPaperHelp&lt;/td&gt;&lt;td&gt;Personalised writing&lt;/td&gt;&lt;td&gt;4.8/5 based on 364 reviews&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;PaperWriter&lt;/td&gt;&lt;td&gt;Collaborative approach&lt;/td&gt;&lt;td&gt;4.9/5 based on 848 reviews&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-essaypro-best-for-one-stop-help"&gt;EssayPro: Best for one-stop help&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110841" height="661" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-13-1024x661.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;EssayPro is the essay writing service online with the most extensive track record on this list. As of writing, it has over 30,000 reviews on Sitejabber alone and completes 300,000+ assignments annually.&lt;/p&gt;&lt;p&gt;But that’s not what makes it the best essay writing service. Based on customer reviews, students prefer EssayPro to AI because its essay help remains affordable, all while being more in-depth, insightful, and creative than AI content. The fact that its writers specialise in 140+ subjects and 50+ paper types helped EssayPro secure its popularity, too.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;350+ writers specialising in 140+ subjects&lt;/li&gt;&lt;li&gt;Good price-quality ratio with transparent pricing and no surprise fees&lt;/li&gt;&lt;li&gt;Solid track record of on-time delivery&lt;/li&gt;&lt;li&gt;Free plagiarism and AI reports&lt;/li&gt;&lt;li&gt;Full control over who works on your essay&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Not all orders can be completed in 3 hours&lt;/li&gt;&lt;li&gt;No over-the-phone customer support&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-writepaper-best-for-in-depth-research"&gt;WritePaper: Best for in-depth research&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110842" height="540" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-14-1024x540.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;AI tools can’t do the kind of research, analysis, and synthesis that experts at WritePaper do every day. That’s what makes it the best college essay writing service for essays and other papers that have to be insightful and present advanced, nuanced arguments on a complex topic.&lt;/p&gt;&lt;p&gt;According to the best essay writing service reviews, WritePaper’s experts are especially good at delivering in-depth essays in research-intensive disciplines that require advanced reasoning. Those include nursing, philosophy, psychology, and history.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Solid argumentation and research skills among writers&lt;/li&gt;&lt;li&gt;115+ subjects covered&lt;/li&gt;&lt;li&gt;Around-the-clock support and help&lt;/li&gt;&lt;li&gt;Thoroughly researched essays with advanced reasoning&lt;/li&gt;&lt;li&gt;Diverse formatting options (MLA, APA, Chicago, etc.)&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Potentially overwhelming writer selection process&lt;/li&gt;&lt;li&gt;Graphs and tables cost extra&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-mypaperhelp-best-for-personalised-writing"&gt;MyPaperHelp: Best for personalised writing&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110843" height="648" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-15-1024x648.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;While all services on this list provide custom writing services, MyPaperHelp is a paper writing service frequently praised for its personalised approach to orders. Its experts readily work with samples and adapt the style and tone of voice to the essay’s context and purpose. They also build on the ideas, suggestions, and whole outlines added to the order form.&lt;/p&gt;&lt;p&gt;This makes MyPaperHelp the best essay writing website for any essay that has to be highly personal in nature. Think scholarship and college application essays or creative writing assignments that focus on personal experiences rather than academic research.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Wide range of writing styles and tones of voice supported&lt;/li&gt;&lt;li&gt;Essays fully adapted to their context and purpose&lt;/li&gt;&lt;li&gt;High-quality creative writing assignments&lt;/li&gt;&lt;li&gt;Possible to attach samples to the order form that writers build on&lt;/li&gt;&lt;li&gt;Unique, authentic writing that doesn’t rehash generic ideas or clichés&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;You have to be very precise with your instructions to leave no room for misunderstandings&lt;/li&gt;&lt;li&gt;Originality reports aren’t provided by default; you have to request one (although they are free)&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-paperwriter-best-for-collaborative-approach"&gt;PaperWriter: Best for collaborative approach&lt;/h3&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-110844" height="559" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-16-1024x559.png" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;Yes, US students turn to PaperWriter for many reasons, but direct writer communication is the most frequently cited one. So, if two-way communication with the writer is important, PaperWriter is definitely worth considering.&lt;/p&gt;&lt;p&gt;PaperWriter’s experts routinely reach out to customers via direct chat whenever they need to clarify the requirements or ask for additional information. That makes PaperWriter the best essay writing service for students who want their essays to reflect their thoughts, ideas, and opinions to the letter.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Pricing&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Custom writing: Starts at $10.80/page&lt;/li&gt;&lt;li&gt;Rewriting: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Editing: Starts at $7.56/page&lt;/li&gt;&lt;li&gt;Proofreading: Starts at $5.40/page&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Direct writer chat with end-to-end encryption&lt;/li&gt;&lt;li&gt;Strict privacy policy that protects confidentiality&lt;/li&gt;&lt;li&gt;Responsive writers who proactively communicate with customers&lt;/li&gt;&lt;li&gt;Unlimited free revisions without mandatory waiting time&lt;/li&gt;&lt;li&gt;Review work services available&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;&lt;strong&gt;Cons&lt;/strong&gt;&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Writer selection may be a bit time-consuming&lt;/li&gt;&lt;li&gt;A collaborative approach is, by definition, also somewhat time-consuming&lt;/li&gt;&lt;/ul&gt;&lt;h3 class="wp-block-heading" id="h-final-thoughts-ai-can-t-rival-human-creativity-amp-expertise"&gt;Final thoughts: AI can’t rival human creativity &amp;amp; expertise&lt;/h3&gt;&lt;p&gt;AI tools may be becoming more ingrained in the learning process, but that doesn’t mean they’re ready to replace human creativity and expertise altogether. Yes, they can help you outline an essay or brainstorm ideas. But only professionals can come up with truly fresh ideas or develop a complex argument on a topic that requires hours of research.&lt;/p&gt;&lt;p&gt;So, it’s safe to say that essay writing services aren’t going anywhere any time soon. They will continue supporting students in their studies, more so than AI tools.&lt;/p&gt;&lt;p&gt;If you’re looking for the best essay writing service, Reddit and other social media platforms are a good place to start. Independent review platforms like Sitejabber and Reviews.io can also come in handy.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/4-best-essay-writing-websites-students-choose-over-ai/</guid><pubDate>Mon, 24 Nov 2025 10:34:14 +0000</pubDate></item><item><title>“Go generate a bridge and jump off it”: How video pros are navigating AI (AI – Ars Technica)</title><link>https://arstechnica.com/features/2025/11/go-generate-a-bridge-and-jump-off-it-how-video-pros-are-navigating-ai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      I talked with nine creators about economic pressures and fan backlash.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/ai-actress-render.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In 2016, the legendary Japanese filmmaker Hayao Miyazaki was shown a bizarre AI-generated video of a misshapen human body crawling across a floor.&lt;/p&gt;
&lt;p&gt;Miyazaki&amp;nbsp;declared himself&amp;nbsp;“utterly disgusted” by the technology demo, which he considered an “insult to life itself.”&lt;/p&gt;
&lt;p&gt;“If you really want to make creepy stuff, you can go ahead and do it,” Miyazaki said. “I would never wish to incorporate this technology into my work at all.”&lt;/p&gt;
&lt;p&gt;Many fans interpreted Miyazaki’s remarks as rejecting AI-generated video in general. So they didn’t like it when, in October 2024, filmmaker&amp;nbsp;PJ Accetturo&amp;nbsp;used AI tools to create a&amp;nbsp;fake trailer for a live-action version of Miyazaki’s animated classic &lt;em&gt;Princess&lt;/em&gt; &lt;em&gt;Mononoke&lt;/em&gt;. The trailer earned him 22 million views on X. It also earned him hundreds of insults and death threats.&lt;/p&gt;
&lt;p&gt;“Go generate a bridge and jump off of it,” said one of the funnier retorts. Another urged&amp;nbsp;Accetturo to “throw your computer in a river and beg God’s forgiveness.”&lt;/p&gt;
&lt;p&gt;Someone&amp;nbsp;tweeted that Miyazaki “should be allowed to legally hunt and kill this man for sport.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128526 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="365" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/bf2d6bec-f84a-4503-b8c3-ba2619d73215_547x365.jpg" width="547" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      PJ Accetturo is a director and founder of Genre AI, an AI ad agency.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          PJ Accetturo

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The development of AI image and video generation models has been controversial, to say the least. Artists have accused AI companies of stealing their work to build tools that put people out of a job. Using AI tools openly is stigmatized in many circles, as Accetturo learned the hard way.&lt;/p&gt;
&lt;p&gt;But as these models have improved, they have sped up workflows and afforded new opportunities for artistic expression. Artists without AI expertise might soon find themselves losing work.&lt;/p&gt;
&lt;p&gt;Over the last few weeks, I’ve spoken to nine actors, directors, and creators about how they are navigating these tricky waters. Here’s what they told me.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;The backlash to AI video generation, explained&lt;/h2&gt;
&lt;p&gt;Actors have emerged as a powerful force against AI. In 2023,&amp;nbsp;SAG-AFTRA, the Hollywood actors’ union, had its longest-ever strike, partly to&amp;nbsp;establish more protections&amp;nbsp;for actors against AI replicas.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Actors have lobbied to regulate AI in their industry and beyond. One actor I talked with,&amp;nbsp;Erik Passoja, has testified before the California Legislature in favor of several bills, including for greater protections against pornographic deepfakes. SAG-AFTRA endorsed SB 1047, an AI safety bill regulating frontier models. The union also&amp;nbsp;organized&amp;nbsp;against the proposed moratorium on state AI bills.&lt;/p&gt;
&lt;p&gt;A recent flashpoint came in September, when&amp;nbsp;Deadline Hollywood&amp;nbsp;reported that talent agencies were interested in signing “AI actress” Tilly Norwood.&lt;/p&gt;
&lt;p&gt;Actors weren’t happy. Emily Blunt told&amp;nbsp;Variety, “This is really, really scary. Come on agencies, don’t do that.”&lt;/p&gt;
&lt;p&gt;Natasha Lyonne, star of &lt;em&gt;Russian Doll&lt;/em&gt;, posted on an Instagram Story: “Any talent agency that engages in this should be boycotted by all guilds. Deeply misguided &amp;amp; totally disturbed.”&lt;/p&gt;
&lt;p&gt;The backlash was partly specific to Tilly Norwood—Lyonne is no AI skeptic, having cofounded an AI studio—but it also reflects a set of concerns around AI common to many in Hollywood and beyond.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Here’s how SAG-AFTRA&amp;nbsp;explained its position:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Tilly Norwood is not an actor, it’s a character generated by a computer program that was trained on the work of countless professional performers — without permission or compensation. It has no life experience to draw from, no emotion and, from what we’ve seen, audiences aren’t interested in watching computer-generated content untethered from the human experience. It doesn’t solve any “problem” — it creates the problem of using stolen performances to put actors out of work, jeopardizing performer livelihoods and devaluing human artistry.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This statement reflects three broad criticisms that come up over and over in discussions of AI art:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Content theft:&lt;/strong&gt; Most leading AI video models have been trained on broad swathes of the Internet, including images and films made by artists. In many cases, companies have not asked artists for permission to use this content, nor compensated them. Courts are still working out&amp;nbsp;whether this is fair use under copyright law. But many people I talked to consider AI companies’ training efforts to be theft of artists’ work.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;&lt;strong&gt;Job loss:&lt;/strong&gt;&amp;nbsp;If AI tools can make passable video quickly or drastically speed up editing tasks, that potentially takes jobs away from actors or film editors. While past technological advancements have also eliminated jobs—the adoption of digital cameras drastically reduced the number of people cutting physical film—AI could have an even broader impact.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Artistic quality:&lt;/strong&gt;&amp;nbsp;A lot of people told me they just didn’t think AI-generated content could ever be good art. Tess Dinerstein stars in vertical dramas—episodic programs optimized for viewing on smartphones. She told me that AI is “missing that sort of human connection that you have when you go to a movie theater and you’re sobbing your eyes out because your favorite actor is talking about their dead mom.”&lt;/p&gt;
&lt;p&gt;The concern about theft is potentially solvable by changing how models are trained. Around the time Accetturo released the “Princess Mononoke” trailer, he&amp;nbsp;called&amp;nbsp;for generative AI tools to be “ethically trained on licensed datasets.”&lt;/p&gt;
&lt;p&gt;Some companies have moved in this direction. For instance, independent filmmaker Gille Klabin told me he “feels pretty good” using Adobe products because the company trains its AI models on stock images that it pays royalties for.&lt;/p&gt;
&lt;p&gt;But the other two issues—job losses and artistic integrity—will be harder to finesse. Many creators—and fans—believe that AI-generated content misses the fundamental point of art, which is about creating an emotional connection between creators and viewers.&lt;/p&gt;
&lt;p&gt;But while that point is compelling in theory, the details can be tricky.&lt;/p&gt;
&lt;p&gt;Dinerstein, the vertical drama actress, told me that she’s “not fundamentally against AI”—she admits “it provides a lot of resources to filmmakers” in specialized editing tasks—but she takes a hard stance against it on social media.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“It’s hard to ever explain gray areas on social media,” she said, and she doesn’t want to “come off as hypocritical.”&lt;/p&gt;
&lt;p&gt;Even though she doesn’t think that AI poses a risk to her job—“people want to see what I’m up to”—she does fear people (both fans and vertical drama studios) making an AI representation of her without her permission. And she has found it easiest to just say, “You know what? Don’t involve me in AI.”&lt;/p&gt;
&lt;p&gt;Others see it as a much broader issue. Actress&amp;nbsp;Susan Spano&amp;nbsp;told me it was “an issue for humans, not just actors.”&lt;/p&gt;
&lt;p&gt;“This is a world of humans and animals,” she said. “Interaction with humans is what makes it fun. I mean, do we want a world of robots?”&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;How one director leaned into AI&lt;/h2&gt;
&lt;p&gt;It’s relatively easy for actors to take a firm stance against AI because they inherently do their work in the physical world. But things are more complicated for other Hollywood creatives, such as directors, writers, and film editors. AI tools can genuinely make them more productive, and they’re at risk of losing work if they don’t stay on the cutting edge.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;So the non-actors I talked to took a range of approaches to AI. Some still reject it. Others have used the tools reluctantly and tried to keep their heads down. Still others have openly embraced the technology.&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset can-restack"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128525 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="1280" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/fd8a1b19-7765-4660-a619-12dde115c142_3177x3972-1024x1280.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Kavan Cardoza is a director and AI filmmaker.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Phantom X

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/div&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;Take&amp;nbsp;Kavan Cardoza, for example. He worked as a music video director and photographer for close to a decade before getting his break into filmmaking with AI.&lt;/p&gt;
&lt;p&gt;After the image model Midjourney was first released in 2022, Cardoza started playing around with image generation and later video generation. Eventually, he “started making a bunch of fake movie trailers” for existing movies and franchises. In December 2024, he made a fan film in the Batman universe that “exploded on the Internet,” before Warner Bros. took it down for copyright infringement.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Cardoza acknowledges that he re-created actors in former Batman movies “without their permission.” But he insists he wasn’t “trying to be malicious or whatever. It was truly just a fan film.”&lt;/p&gt;
&lt;p&gt;Whereas Accetturo received death threats, the response to Cardoza’s fan film was quite positive.&lt;/p&gt;
&lt;p&gt;“Every other major studio started contacting me,” Cardoza said. He set up an AI studio, Phantom X, with several of his close friends. Phantom X started by making ads (where AI video is&amp;nbsp;catching on quickest), but Cardoza wanted to focus back on films.&lt;/p&gt;
&lt;p&gt;In June, Cardoza made a short film called &lt;em&gt;Echo Hunter&lt;/em&gt;, a blend of &lt;em&gt;Blade Runner&lt;/em&gt; and &lt;em&gt;The Matrix&lt;/em&gt;. Some shots look clearly AI-generated, but Cardoza used motion-capture technology from Runway to put the faces of real actors into his AI-generated world. Overall, the piece pretty much hangs together.&lt;/p&gt;
&lt;p&gt;Cardoza wanted to work with real actors because their artistic choices can help elevate the script he’s written: “There’s a lot more levels of creativity to it.” But he needed SAG-AFTRA’s approval to make a film that blends AI techniques with the likenesses of SAG-AFTRA actors. To get it, he had to promise not to reuse the actors’ likenesses in other films.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;“It’s never about if, it’s just when”&lt;/h2&gt;
&lt;p&gt;In Cardoza’s view, AI is “giving voices to creators that otherwise never would have had the voice.”&lt;/p&gt;
&lt;p&gt;But Cardoza isn’t wedded to AI. When an&amp;nbsp;interviewer asked him whether he’d make a non-AI film if required to, he responded, “Oh, 100 percent.” Cardoza added that if he had the budget to do it now, “I’d probably still shoot it all live action.”&lt;/p&gt;
&lt;p&gt;He acknowledged to me that there will be losers in the transition—“there’s always going to be changes”—but he compares the rise of AI with past technological developments in filmmaking, like the rise of visual effects. This created new jobs making visual effects digitally, but reduced jobs making elaborate physical sets.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Cardoza expressed interest in reducing the amount of job loss. In&amp;nbsp;another interview, Cardoza said that for his film project, “we want to make sure we include as many people as possible,” not just actors, but sound designers, script editors, and other specialized roles.&lt;/p&gt;
&lt;p&gt;But he believes that eventually, AI will get good enough to do everyone’s job. “Like I say with tech, it’s never about if, it’s just when.”&lt;/p&gt;
&lt;p&gt;Accetturo’s entry into AI was similar. He told me that he worked for 15 years as a filmmaker, “mostly as a commercial director and former documentary director.” During the pandemic, he “raised millions” for an animated TV series, but it got caught up in&amp;nbsp;development hell.&lt;/p&gt;
&lt;p&gt;AI gave him a new chance at success. Over the summer of 2024, he started playing around with AI video tools. He realized that he was in the sweet spot to take advantage of AI: experienced enough to make something good, but not so established that he was risking his reputation. After Google released Veo 3 in May, Accetturo released a&amp;nbsp;fake medicine ad that went viral. His studio now produces ads for prominent companies like Oracle and Popeyes.&lt;/p&gt;
&lt;p&gt;Accetturo says the backlash against him has subsided: “It truly is nothing compared to what it was.” And he says he’s committed to working on AI: “Everyone understands that it’s the future.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="header-anchor-post"&gt;“Adapt like cockroaches”&lt;/h2&gt;
&lt;p&gt;Between the anti- and pro-AI extremes, there are a lot of editors and artists quietly using AI tools without disclosing it. Unsurprisingly, it’s difficult to find people who will speak about this on the record.&lt;/p&gt;
&lt;p&gt;“A lot of people want plausible deniability right now,” according to&amp;nbsp;Ryan Hayden, a Hollywood talent agent. “There is backlash about it.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But if editors don’t use AI tools, they risk becoming obsolete. Hayden says that he knows a lot of people in the editing field trying to master AI because “there’s gonna be a massive cut” in the total number of editors. Those who know AI might survive.&lt;/p&gt;
&lt;p&gt;As one comedy writer involved in an AI project told&amp;nbsp;Wired, “We wanted to be at the table and not on the menu.”&lt;/p&gt;
&lt;p&gt;Clandestine AI usage extends into the upper reaches of the industry. Hayden knows an editor who works with a major director who has directed $100 million films. “He’s already using AI, sometimes without people knowing.”&lt;/p&gt;
&lt;p&gt;Some artists feel morally conflicted but don’t think they can effectively resist. Vinny Dellay, a storyboard artist who has worked on Marvel films and Super Bowl ads, released a video&amp;nbsp;detailing his views on the ethics of using AI as a working artist. Dellay said that he agrees that “AI being trained off of art found on the Internet without getting permission from the artist, it may not be fair, it may not be honest.” But refusing to use AI products won’t stop their general adoption. Believing otherwise is “just being delusional.”&lt;/p&gt;
&lt;p&gt;Instead, Dellay said that the right course is to “adapt like cockroaches after a nuclear war.” If they’re lucky, using AI in storyboarding workflows might even “let a storyboard artist pump out twice the boards in half the time without questioning all your life’s choices at 3 am.”&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;Lines, moral and practical&lt;/h2&gt;
&lt;div class="pencraft pc-display-flex pc-gap-8 pc-reset"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128524 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/e1ae4bd2-ca6d-4d83-b6a9-4ec8670dd2a1_6000x4000-1024x683.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gille Klabin is an independent writer, director, and visual effects artist.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Gille Klabin

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/div&gt;
&lt;p&gt;Gille Klabin is an indie director and filmmaker currently working on a feature called &lt;em&gt;Weekend at the End of the World&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As an independent filmmaker, Klabin can’t afford to hire many people. There are many labor-intensive tasks—like making a pitch deck for his film—that he’d otherwise have to do himself. An AI tool “essentially just liberates us to get more done and have more time back in our life.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But he’s careful to stick to his own moral lines. Any time he mentioned using an AI tool during our interview, he’d explain why he thought that was an appropriate choice. He said he was fine with AI use “as long as you’re using it ethically in the sense that you’re not copying somebody’s work and using it for your own.”&lt;/p&gt;
&lt;p&gt;Drawing these lines can be difficult, however. Hayden, the talent agent, told me that as AI tools make low-budget films look better, it gets harder to make high-budget films, which employ the most people at the highest wage levels.&lt;/p&gt;
&lt;p&gt;If anything, Klabin’s AI uptake is limited more by the current capabilities of AI models. Klabin is an experienced visual effects artist, and he finds AI products to generally be “not really good enough to be used in a final project.”&lt;/p&gt;
&lt;p&gt;He gave me a concrete example. Rotoscoping is a process in which you trace out the subject of the shot so you can edit the background independently. It’s very labor-intensive—one has to edit every frame individually—so Klabin has tried using Runway’s AI-driven rotoscoping. While it can make for a decent first pass, the result is just too messy to use as a final project.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Klabin sent me this GIF of a series of rotoscoped frames from his upcoming movie. While the model does a decent job of identifying the people in the frame, its boundaries aren’t consistent from frame to frame. The result is noisy.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128523 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="448" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/ezgif-5ae8ed4b0b48d022.gif" width="800" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;Current AI tools are full of these small glitches, so Klabin only uses them for tasks that audiences don’t see (like creating a movie pitch deck) or in contexts where he can clean up the result afterward.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="header-anchor-post"&gt;The power of authenticity&lt;/h2&gt;
&lt;p&gt;Stephen Robles&amp;nbsp;reviews Apple products on YouTube and other platforms. He uses AI in some parts of the editing process, such as removing silences or transcribing audio, but doesn’t see it as disruptive to his career.&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset can-restack"&gt;
&lt;div class="image-link-expand"&gt;&lt;/div&gt;
&lt;/div&gt;&lt;figcaption class="image-caption"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128522 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="1024" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/3bbc6419-4a4f-46b7-be01-163177beb735_1500x1500-1024x1024.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Stephen Robles is a YouTuber, podcaster, and creator covering tech, particularly Apple.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Stephen Robles

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;“I am betting on the audience wanting to trust creators, wanting to see authenticity,” he told me. AI video tools don’t really help him with that and can’t replace the reputation he’s sought to build.&lt;/p&gt;
&lt;p&gt;Recently, he&amp;nbsp;experimented&amp;nbsp;with using ChatGPT to edit a video thumbnail (the image used to advertise a video). He got a couple of negative reactions about his use of AI, so he said he “might slow down a little bit” with that experimentation.&lt;/p&gt;
&lt;p&gt;Robles didn’t seem as concerned about AI models stealing from creators like him. When I asked him about how he felt about&amp;nbsp;Google training on his data, he told me that “YouTube provides me enough benefit that I don’t think too much about that.”&lt;/p&gt;
&lt;p&gt;Professional thumbnail artist&amp;nbsp;Antioch Hwang has a similarly pragmatic view toward using AI. Some channels he works with have audiences that are “very sensitive to AI images.” Even using “an AI upscaler to fix up the edges” can provoke strong negative reactions. For those channels, he’s “very wary” about using AI.&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset can-restack"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128521 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="1280" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/43126c4f-2cb5-4d9c-bfaf-9d8dc2ed4f0e_1638x2048-1024x1280.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Antioch Hwang is a YouTube thumbnail artist.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Antioch Creative

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/div&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;But for most channels he works for, he’s fine using AI, at least for technical tasks. “I think there’s now been a big shift in the public perception of these AI image generation tools,” he told me. “People are now welcoming them into their workflow.”&lt;/p&gt;
&lt;p&gt;He’s still careful with his AI use, though, because he thinks that having human artistry helps in the YouTube ecosystem. “If everyone has all the [AI] tools, then how do you really stand out?” he said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recently, top creators have started using more rough-looking thumbnails for their videos. AI has made polished thumbnails too easy to create, so top creators are using what Hwang would call “poorly made thumbnails” to help videos stand out.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;Exit strategies&lt;/h2&gt;
&lt;p&gt;Hwang told me something surprising: even as AI makes it easier for creators to make thumbnails themselves, business has never been better for thumbnail artists, even at the lower end. He said that demand has soared because “AI as a whole has lowered the barriers for content creation, and now there’s more creators flooding in.”&lt;/p&gt;
&lt;p&gt;Still, Hwang doesn’t expect the good times to last forever. “I don’t see AI completely taking over for the next three-ish years. That’s my estimated timeline.”&lt;/p&gt;
&lt;p&gt;Everyone I talked to had different answers to when—if ever—AI would meaningfully disrupt their part of the industry.&lt;/p&gt;
&lt;p&gt;Some, like Hwang, were pessimistic. Actor Erik Passoja told me he thought the big movie studios—like Warner Bros. or Paramount—would be gone in three to five years.&lt;/p&gt;
&lt;p&gt;But others were more optimistic. Tess Dinerstein, the vertical drama actor, said, “I don’t think that verticals are ever going to go fully AI.” Even if it becomes technologically feasible, she argued, “that just doesn’t seem to be what the people want.”&lt;/p&gt;
&lt;p&gt;Gille Klabin, the independent filmmaker, thought there would always be a place for high-quality human films. If someone’s work is “fundamentally derivative,” then they are at risk. But he thinks the best human-created work will still stand out. “I don’t know how AI could possibly replace the borderline divine element of consciousness,” he said.&lt;/p&gt;
&lt;p&gt;The people who were most bullish on AI were, if anything, the least optimistic about their own career prospects. “I think at a certain point it won’t matter,” Kavan Cardoza told me. “It’ll be that anyone on the planet can just type in some sentences” to generate full, high-quality videos.&lt;/p&gt;
&lt;p&gt;This might explain why Accetturo has become something of an AI evangelist; his&amp;nbsp;newsletter&amp;nbsp;tries to teach other filmmakers how to adapt to the coming AI revolution.&lt;/p&gt;
&lt;p&gt;AI “is a tsunami that is gonna wipe out everyone” he told me. “So I’m handing out surfboards—teaching people how to surf. Do with it what you will.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Kai Williams&amp;nbsp;is a reporter for&amp;nbsp;Understanding AI, a Substack newsletter founded by Ars Technica alum Timothy B. Lee. His work is supported by a&amp;nbsp;Tarbell Fellowship.&amp;nbsp;Subscribe to Understanding AI&amp;nbsp;to get more from Tim and Kai.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;








  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 md:my-10 md:py-8 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      I talked with nine creators about economic pressures and fan backlash.
    &lt;/p&gt;

          
    
    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="intro-image" height="1440" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/ai-actress-render.jpg" width="2560" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In 2016, the legendary Japanese filmmaker Hayao Miyazaki was shown a bizarre AI-generated video of a misshapen human body crawling across a floor.&lt;/p&gt;
&lt;p&gt;Miyazaki&amp;nbsp;declared himself&amp;nbsp;“utterly disgusted” by the technology demo, which he considered an “insult to life itself.”&lt;/p&gt;
&lt;p&gt;“If you really want to make creepy stuff, you can go ahead and do it,” Miyazaki said. “I would never wish to incorporate this technology into my work at all.”&lt;/p&gt;
&lt;p&gt;Many fans interpreted Miyazaki’s remarks as rejecting AI-generated video in general. So they didn’t like it when, in October 2024, filmmaker&amp;nbsp;PJ Accetturo&amp;nbsp;used AI tools to create a&amp;nbsp;fake trailer for a live-action version of Miyazaki’s animated classic &lt;em&gt;Princess&lt;/em&gt; &lt;em&gt;Mononoke&lt;/em&gt;. The trailer earned him 22 million views on X. It also earned him hundreds of insults and death threats.&lt;/p&gt;
&lt;p&gt;“Go generate a bridge and jump off of it,” said one of the funnier retorts. Another urged&amp;nbsp;Accetturo to “throw your computer in a river and beg God’s forgiveness.”&lt;/p&gt;
&lt;p&gt;Someone&amp;nbsp;tweeted that Miyazaki “should be allowed to legally hunt and kill this man for sport.”&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128526 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="365" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/bf2d6bec-f84a-4503-b8c3-ba2619d73215_547x365.jpg" width="547" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      PJ Accetturo is a director and founder of Genre AI, an AI ad agency.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          PJ Accetturo

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The development of AI image and video generation models has been controversial, to say the least. Artists have accused AI companies of stealing their work to build tools that put people out of a job. Using AI tools openly is stigmatized in many circles, as Accetturo learned the hard way.&lt;/p&gt;
&lt;p&gt;But as these models have improved, they have sped up workflows and afforded new opportunities for artistic expression. Artists without AI expertise might soon find themselves losing work.&lt;/p&gt;
&lt;p&gt;Over the last few weeks, I’ve spoken to nine actors, directors, and creators about how they are navigating these tricky waters. Here’s what they told me.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;The backlash to AI video generation, explained&lt;/h2&gt;
&lt;p&gt;Actors have emerged as a powerful force against AI. In 2023,&amp;nbsp;SAG-AFTRA, the Hollywood actors’ union, had its longest-ever strike, partly to&amp;nbsp;establish more protections&amp;nbsp;for actors against AI replicas.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Actors have lobbied to regulate AI in their industry and beyond. One actor I talked with,&amp;nbsp;Erik Passoja, has testified before the California Legislature in favor of several bills, including for greater protections against pornographic deepfakes. SAG-AFTRA endorsed SB 1047, an AI safety bill regulating frontier models. The union also&amp;nbsp;organized&amp;nbsp;against the proposed moratorium on state AI bills.&lt;/p&gt;
&lt;p&gt;A recent flashpoint came in September, when&amp;nbsp;Deadline Hollywood&amp;nbsp;reported that talent agencies were interested in signing “AI actress” Tilly Norwood.&lt;/p&gt;
&lt;p&gt;Actors weren’t happy. Emily Blunt told&amp;nbsp;Variety, “This is really, really scary. Come on agencies, don’t do that.”&lt;/p&gt;
&lt;p&gt;Natasha Lyonne, star of &lt;em&gt;Russian Doll&lt;/em&gt;, posted on an Instagram Story: “Any talent agency that engages in this should be boycotted by all guilds. Deeply misguided &amp;amp; totally disturbed.”&lt;/p&gt;
&lt;p&gt;The backlash was partly specific to Tilly Norwood—Lyonne is no AI skeptic, having cofounded an AI studio—but it also reflects a set of concerns around AI common to many in Hollywood and beyond.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Here’s how SAG-AFTRA&amp;nbsp;explained its position:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Tilly Norwood is not an actor, it’s a character generated by a computer program that was trained on the work of countless professional performers — without permission or compensation. It has no life experience to draw from, no emotion and, from what we’ve seen, audiences aren’t interested in watching computer-generated content untethered from the human experience. It doesn’t solve any “problem” — it creates the problem of using stolen performances to put actors out of work, jeopardizing performer livelihoods and devaluing human artistry.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This statement reflects three broad criticisms that come up over and over in discussions of AI art:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Content theft:&lt;/strong&gt; Most leading AI video models have been trained on broad swathes of the Internet, including images and films made by artists. In many cases, companies have not asked artists for permission to use this content, nor compensated them. Courts are still working out&amp;nbsp;whether this is fair use under copyright law. But many people I talked to consider AI companies’ training efforts to be theft of artists’ work.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;&lt;strong&gt;Job loss:&lt;/strong&gt;&amp;nbsp;If AI tools can make passable video quickly or drastically speed up editing tasks, that potentially takes jobs away from actors or film editors. While past technological advancements have also eliminated jobs—the adoption of digital cameras drastically reduced the number of people cutting physical film—AI could have an even broader impact.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Artistic quality:&lt;/strong&gt;&amp;nbsp;A lot of people told me they just didn’t think AI-generated content could ever be good art. Tess Dinerstein stars in vertical dramas—episodic programs optimized for viewing on smartphones. She told me that AI is “missing that sort of human connection that you have when you go to a movie theater and you’re sobbing your eyes out because your favorite actor is talking about their dead mom.”&lt;/p&gt;
&lt;p&gt;The concern about theft is potentially solvable by changing how models are trained. Around the time Accetturo released the “Princess Mononoke” trailer, he&amp;nbsp;called&amp;nbsp;for generative AI tools to be “ethically trained on licensed datasets.”&lt;/p&gt;
&lt;p&gt;Some companies have moved in this direction. For instance, independent filmmaker Gille Klabin told me he “feels pretty good” using Adobe products because the company trains its AI models on stock images that it pays royalties for.&lt;/p&gt;
&lt;p&gt;But the other two issues—job losses and artistic integrity—will be harder to finesse. Many creators—and fans—believe that AI-generated content misses the fundamental point of art, which is about creating an emotional connection between creators and viewers.&lt;/p&gt;
&lt;p&gt;But while that point is compelling in theory, the details can be tricky.&lt;/p&gt;
&lt;p&gt;Dinerstein, the vertical drama actress, told me that she’s “not fundamentally against AI”—she admits “it provides a lot of resources to filmmakers” in specialized editing tasks—but she takes a hard stance against it on social media.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“It’s hard to ever explain gray areas on social media,” she said, and she doesn’t want to “come off as hypocritical.”&lt;/p&gt;
&lt;p&gt;Even though she doesn’t think that AI poses a risk to her job—“people want to see what I’m up to”—she does fear people (both fans and vertical drama studios) making an AI representation of her without her permission. And she has found it easiest to just say, “You know what? Don’t involve me in AI.”&lt;/p&gt;
&lt;p&gt;Others see it as a much broader issue. Actress&amp;nbsp;Susan Spano&amp;nbsp;told me it was “an issue for humans, not just actors.”&lt;/p&gt;
&lt;p&gt;“This is a world of humans and animals,” she said. “Interaction with humans is what makes it fun. I mean, do we want a world of robots?”&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;How one director leaned into AI&lt;/h2&gt;
&lt;p&gt;It’s relatively easy for actors to take a firm stance against AI because they inherently do their work in the physical world. But things are more complicated for other Hollywood creatives, such as directors, writers, and film editors. AI tools can genuinely make them more productive, and they’re at risk of losing work if they don’t stay on the cutting edge.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;So the non-actors I talked to took a range of approaches to AI. Some still reject it. Others have used the tools reluctantly and tried to keep their heads down. Still others have openly embraced the technology.&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset can-restack"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128525 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="1280" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/fd8a1b19-7765-4660-a619-12dde115c142_3177x3972-1024x1280.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Kavan Cardoza is a director and AI filmmaker.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Phantom X

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/div&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;Take&amp;nbsp;Kavan Cardoza, for example. He worked as a music video director and photographer for close to a decade before getting his break into filmmaking with AI.&lt;/p&gt;
&lt;p&gt;After the image model Midjourney was first released in 2022, Cardoza started playing around with image generation and later video generation. Eventually, he “started making a bunch of fake movie trailers” for existing movies and franchises. In December 2024, he made a fan film in the Batman universe that “exploded on the Internet,” before Warner Bros. took it down for copyright infringement.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Cardoza acknowledges that he re-created actors in former Batman movies “without their permission.” But he insists he wasn’t “trying to be malicious or whatever. It was truly just a fan film.”&lt;/p&gt;
&lt;p&gt;Whereas Accetturo received death threats, the response to Cardoza’s fan film was quite positive.&lt;/p&gt;
&lt;p&gt;“Every other major studio started contacting me,” Cardoza said. He set up an AI studio, Phantom X, with several of his close friends. Phantom X started by making ads (where AI video is&amp;nbsp;catching on quickest), but Cardoza wanted to focus back on films.&lt;/p&gt;
&lt;p&gt;In June, Cardoza made a short film called &lt;em&gt;Echo Hunter&lt;/em&gt;, a blend of &lt;em&gt;Blade Runner&lt;/em&gt; and &lt;em&gt;The Matrix&lt;/em&gt;. Some shots look clearly AI-generated, but Cardoza used motion-capture technology from Runway to put the faces of real actors into his AI-generated world. Overall, the piece pretty much hangs together.&lt;/p&gt;
&lt;p&gt;Cardoza wanted to work with real actors because their artistic choices can help elevate the script he’s written: “There’s a lot more levels of creativity to it.” But he needed SAG-AFTRA’s approval to make a film that blends AI techniques with the likenesses of SAG-AFTRA actors. To get it, he had to promise not to reuse the actors’ likenesses in other films.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;“It’s never about if, it’s just when”&lt;/h2&gt;
&lt;p&gt;In Cardoza’s view, AI is “giving voices to creators that otherwise never would have had the voice.”&lt;/p&gt;
&lt;p&gt;But Cardoza isn’t wedded to AI. When an&amp;nbsp;interviewer asked him whether he’d make a non-AI film if required to, he responded, “Oh, 100 percent.” Cardoza added that if he had the budget to do it now, “I’d probably still shoot it all live action.”&lt;/p&gt;
&lt;p&gt;He acknowledged to me that there will be losers in the transition—“there’s always going to be changes”—but he compares the rise of AI with past technological developments in filmmaking, like the rise of visual effects. This created new jobs making visual effects digitally, but reduced jobs making elaborate physical sets.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Cardoza expressed interest in reducing the amount of job loss. In&amp;nbsp;another interview, Cardoza said that for his film project, “we want to make sure we include as many people as possible,” not just actors, but sound designers, script editors, and other specialized roles.&lt;/p&gt;
&lt;p&gt;But he believes that eventually, AI will get good enough to do everyone’s job. “Like I say with tech, it’s never about if, it’s just when.”&lt;/p&gt;
&lt;p&gt;Accetturo’s entry into AI was similar. He told me that he worked for 15 years as a filmmaker, “mostly as a commercial director and former documentary director.” During the pandemic, he “raised millions” for an animated TV series, but it got caught up in&amp;nbsp;development hell.&lt;/p&gt;
&lt;p&gt;AI gave him a new chance at success. Over the summer of 2024, he started playing around with AI video tools. He realized that he was in the sweet spot to take advantage of AI: experienced enough to make something good, but not so established that he was risking his reputation. After Google released Veo 3 in May, Accetturo released a&amp;nbsp;fake medicine ad that went viral. His studio now produces ads for prominent companies like Oracle and Popeyes.&lt;/p&gt;
&lt;p&gt;Accetturo says the backlash against him has subsided: “It truly is nothing compared to what it was.” And he says he’s committed to working on AI: “Everyone understands that it’s the future.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="header-anchor-post"&gt;“Adapt like cockroaches”&lt;/h2&gt;
&lt;p&gt;Between the anti- and pro-AI extremes, there are a lot of editors and artists quietly using AI tools without disclosing it. Unsurprisingly, it’s difficult to find people who will speak about this on the record.&lt;/p&gt;
&lt;p&gt;“A lot of people want plausible deniability right now,” according to&amp;nbsp;Ryan Hayden, a Hollywood talent agent. “There is backlash about it.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But if editors don’t use AI tools, they risk becoming obsolete. Hayden says that he knows a lot of people in the editing field trying to master AI because “there’s gonna be a massive cut” in the total number of editors. Those who know AI might survive.&lt;/p&gt;
&lt;p&gt;As one comedy writer involved in an AI project told&amp;nbsp;Wired, “We wanted to be at the table and not on the menu.”&lt;/p&gt;
&lt;p&gt;Clandestine AI usage extends into the upper reaches of the industry. Hayden knows an editor who works with a major director who has directed $100 million films. “He’s already using AI, sometimes without people knowing.”&lt;/p&gt;
&lt;p&gt;Some artists feel morally conflicted but don’t think they can effectively resist. Vinny Dellay, a storyboard artist who has worked on Marvel films and Super Bowl ads, released a video&amp;nbsp;detailing his views on the ethics of using AI as a working artist. Dellay said that he agrees that “AI being trained off of art found on the Internet without getting permission from the artist, it may not be fair, it may not be honest.” But refusing to use AI products won’t stop their general adoption. Believing otherwise is “just being delusional.”&lt;/p&gt;
&lt;p&gt;Instead, Dellay said that the right course is to “adapt like cockroaches after a nuclear war.” If they’re lucky, using AI in storyboarding workflows might even “let a storyboard artist pump out twice the boards in half the time without questioning all your life’s choices at 3 am.”&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;Lines, moral and practical&lt;/h2&gt;
&lt;div class="pencraft pc-display-flex pc-gap-8 pc-reset"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128524 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/e1ae4bd2-ca6d-4d83-b6a9-4ec8670dd2a1_6000x4000-1024x683.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Gille Klabin is an independent writer, director, and visual effects artist.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Gille Klabin

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/div&gt;
&lt;p&gt;Gille Klabin is an indie director and filmmaker currently working on a feature called &lt;em&gt;Weekend at the End of the World&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;As an independent filmmaker, Klabin can’t afford to hire many people. There are many labor-intensive tasks—like making a pitch deck for his film—that he’d otherwise have to do himself. An AI tool “essentially just liberates us to get more done and have more time back in our life.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But he’s careful to stick to his own moral lines. Any time he mentioned using an AI tool during our interview, he’d explain why he thought that was an appropriate choice. He said he was fine with AI use “as long as you’re using it ethically in the sense that you’re not copying somebody’s work and using it for your own.”&lt;/p&gt;
&lt;p&gt;Drawing these lines can be difficult, however. Hayden, the talent agent, told me that as AI tools make low-budget films look better, it gets harder to make high-budget films, which employ the most people at the highest wage levels.&lt;/p&gt;
&lt;p&gt;If anything, Klabin’s AI uptake is limited more by the current capabilities of AI models. Klabin is an experienced visual effects artist, and he finds AI products to generally be “not really good enough to be used in a final project.”&lt;/p&gt;
&lt;p&gt;He gave me a concrete example. Rotoscoping is a process in which you trace out the subject of the shot so you can edit the background independently. It’s very labor-intensive—one has to edit every frame individually—so Klabin has tried using Runway’s AI-driven rotoscoping. While it can make for a decent first pass, the result is just too messy to use as a final project.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Klabin sent me this GIF of a series of rotoscoped frames from his upcoming movie. While the model does a decent job of identifying the people in the frame, its boundaries aren’t consistent from frame to frame. The result is noisy.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2128523 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="448" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/ezgif-5ae8ed4b0b48d022.gif" width="800" /&gt;
                  &lt;/div&gt;
      &lt;/figure&gt;

&lt;p&gt;Current AI tools are full of these small glitches, so Klabin only uses them for tasks that audiences don’t see (like creating a movie pitch deck) or in contexts where he can clean up the result afterward.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="header-anchor-post"&gt;The power of authenticity&lt;/h2&gt;
&lt;p&gt;Stephen Robles&amp;nbsp;reviews Apple products on YouTube and other platforms. He uses AI in some parts of the editing process, such as removing silences or transcribing audio, but doesn’t see it as disruptive to his career.&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset can-restack"&gt;
&lt;div class="image-link-expand"&gt;&lt;/div&gt;
&lt;/div&gt;&lt;figcaption class="image-caption"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128522 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="1024" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/3bbc6419-4a4f-46b7-be01-163177beb735_1500x1500-1024x1024.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Stephen Robles is a YouTuber, podcaster, and creator covering tech, particularly Apple.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Stephen Robles

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/figcaption&gt;&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;“I am betting on the audience wanting to trust creators, wanting to see authenticity,” he told me. AI video tools don’t really help him with that and can’t replace the reputation he’s sought to build.&lt;/p&gt;
&lt;p&gt;Recently, he&amp;nbsp;experimented&amp;nbsp;with using ChatGPT to edit a video thumbnail (the image used to advertise a video). He got a couple of negative reactions about his use of AI, so he said he “might slow down a little bit” with that experimentation.&lt;/p&gt;
&lt;p&gt;Robles didn’t seem as concerned about AI models stealing from creators like him. When I asked him about how he felt about&amp;nbsp;Google training on his data, he told me that “YouTube provides me enough benefit that I don’t think too much about that.”&lt;/p&gt;
&lt;p&gt;Professional thumbnail artist&amp;nbsp;Antioch Hwang has a similarly pragmatic view toward using AI. Some channels he works with have audiences that are “very sensitive to AI images.” Even using “an AI upscaler to fix up the edges” can provoke strong negative reactions. For those channels, he’s “very wary” about using AI.&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset can-restack"&gt;
&lt;figure class="ars-wp-img-shortcode id-2128521 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="1280" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/43126c4f-2cb5-4d9c-bfaf-9d8dc2ed4f0e_1638x2048-1024x1280.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Antioch Hwang is a YouTube thumbnail artist.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Antioch Creative

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;/div&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;But for most channels he works for, he’s fine using AI, at least for technical tasks. “I think there’s now been a big shift in the public perception of these AI image generation tools,” he told me. “People are now welcoming them into their workflow.”&lt;/p&gt;
&lt;p&gt;He’s still careful with his AI use, though, because he thinks that having human artistry helps in the YouTube ecosystem. “If everyone has all the [AI] tools, then how do you really stand out?” he said.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Recently, top creators have started using more rough-looking thumbnails for their videos. AI has made polished thumbnails too easy to create, so top creators are using what Hwang would call “poorly made thumbnails” to help videos stand out.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;Exit strategies&lt;/h2&gt;
&lt;p&gt;Hwang told me something surprising: even as AI makes it easier for creators to make thumbnails themselves, business has never been better for thumbnail artists, even at the lower end. He said that demand has soared because “AI as a whole has lowered the barriers for content creation, and now there’s more creators flooding in.”&lt;/p&gt;
&lt;p&gt;Still, Hwang doesn’t expect the good times to last forever. “I don’t see AI completely taking over for the next three-ish years. That’s my estimated timeline.”&lt;/p&gt;
&lt;p&gt;Everyone I talked to had different answers to when—if ever—AI would meaningfully disrupt their part of the industry.&lt;/p&gt;
&lt;p&gt;Some, like Hwang, were pessimistic. Actor Erik Passoja told me he thought the big movie studios—like Warner Bros. or Paramount—would be gone in three to five years.&lt;/p&gt;
&lt;p&gt;But others were more optimistic. Tess Dinerstein, the vertical drama actor, said, “I don’t think that verticals are ever going to go fully AI.” Even if it becomes technologically feasible, she argued, “that just doesn’t seem to be what the people want.”&lt;/p&gt;
&lt;p&gt;Gille Klabin, the independent filmmaker, thought there would always be a place for high-quality human films. If someone’s work is “fundamentally derivative,” then they are at risk. But he thinks the best human-created work will still stand out. “I don’t know how AI could possibly replace the borderline divine element of consciousness,” he said.&lt;/p&gt;
&lt;p&gt;The people who were most bullish on AI were, if anything, the least optimistic about their own career prospects. “I think at a certain point it won’t matter,” Kavan Cardoza told me. “It’ll be that anyone on the planet can just type in some sentences” to generate full, high-quality videos.&lt;/p&gt;
&lt;p&gt;This might explain why Accetturo has become something of an AI evangelist; his&amp;nbsp;newsletter&amp;nbsp;tries to teach other filmmakers how to adapt to the coming AI revolution.&lt;/p&gt;
&lt;p&gt;AI “is a tsunami that is gonna wipe out everyone” he told me. “So I’m handing out surfboards—teaching people how to surf. Do with it what you will.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Kai Williams&amp;nbsp;is a reporter for&amp;nbsp;Understanding AI, a Substack newsletter founded by Ars Technica alum Timothy B. Lee. His work is supported by a&amp;nbsp;Tarbell Fellowship.&amp;nbsp;Subscribe to Understanding AI&amp;nbsp;to get more from Tim and Kai.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;








  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/features/2025/11/go-generate-a-bridge-and-jump-off-it-how-video-pros-are-navigating-ai/</guid><pubDate>Mon, 24 Nov 2025 12:00:00 +0000</pubDate></item><item><title>APAC enterprises move AI infrastructure to edge as inference costs rise (AI News)</title><link>https://www.artificialintelligence-news.com/news/enterprises-are-rethinking-ai-infrastructure-as-inference-costs-rise/</link><description>&lt;p&gt;AI spending in Asia Pacific continues to rise, yet many companies still struggle to get value from their AI projects. Much of this comes down to the infrastructure that supports AI, as most systems are not built to run inference at the speed or scale real applications need. Industry studies show many projects miss their ROI goals even after heavy investment in GenAI tools because of the issue.&lt;/p&gt;&lt;p&gt;The gap shows how much AI infrastructure influences performance, cost, and the ability to scale real-world deployments in the region.&lt;/p&gt;&lt;p&gt;Akamai is trying to address this challenge with Inference Cloud, built with NVIDIA and powered by the latest Blackwell GPUs. The idea is simple: if most AI applications need to make decisions in real time, then those decisions should be made close to users rather than in distant data centres. That shift, Akamai claims, can help companies manage cost, reduce delays, and support AI services that depend on split-second responses.&lt;/p&gt;&lt;p&gt;Jay Jenkins, CTO of Cloud Computing at Akamai, explained to &lt;em&gt;AI News&lt;/em&gt; why this moment is forcing enterprises to rethink how they deploy AI and why inference, not training, has become the real bottleneck.&lt;/p&gt;&lt;h3&gt;Why AI projects struggle without the right infrastructure&lt;/h3&gt;&lt;p&gt;Jenkins says the gap between experimentation and full-scale deployment is much wider than many organisations expect. “Many AI initiatives fail to deliver on expected business value because enterprises often underestimate the gap between experimentation and production,” he says. Even with strong interest in GenAI, large infrastructure bills, high latency, and the difficulty of running models at scale often block progress.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-110833" height="683" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Jay-Jenkins-1024x683.jpg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;Jay Jenkins, CTO of Cloud Computing at Akamai.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Most companies still rely on centralised clouds and large GPU clusters. But as use grows, these setups become too expensive, especially in regions far from major cloud zones. Latency also becomes a major issue when models have to run multiple steps of inference over long distances. “AI is only as powerful as the infrastructure and architecture it runs on,” Jenkins says, adding that latency often weakens the user experience and the value the business hoped to deliver. He also points to multi-cloud setups, complex data rules, and growing compliance needs as common hurdles that slow the move from pilot projects to production.&lt;/p&gt;&lt;h3&gt;Why inference now demands more attention than training&lt;/h3&gt;&lt;p&gt;Across Asia Pacific, AI adoption is shifting from small pilots to real deployments in apps and services. Jenkins notes that as this happens, day-to-day inference – not the occasional training cycle – is what consumes most computing power. With many organisations rolling out language, vision, and multimodal models in multiple markets, the demand for fast and reliable inference is rising faster than expected. This is why inference has become the main constraint in the region. Models now need to operate in different languages, regulations, and data environments, often in real time. That puts enormous pressure on centralised systems that were never designed for this level of responsiveness.&lt;/p&gt;&lt;h3&gt;How edge infrastructure improves AI performance and cost&lt;/h3&gt;&lt;p&gt;Jenkins says moving inference closer to users, devices, or agents can reshape the cost equation. Doing so shortens the distance data must travel and allows models to respond faster. It also avoids the cost of routing huge volumes of data between major cloud hubs.&lt;/p&gt;&lt;p&gt;Physical AI systems – robots, autonomous machines, or smart city tools – depend on decisions made in milliseconds. When inference runs distantly, these systems don’t work as expected.&lt;/p&gt;&lt;p&gt;The savings from more localised deployments can also be substantial. Jenkins says Akamai analysis shows enterprises in India and Vietnam see large reductions in the cost of running image-generation models when workloads are placed at the edge, rather than centralised clouds. Better GPU use and lower egress fees played a major role in those savings.&lt;/p&gt;&lt;h3&gt;Where edge-based AI is gaining traction&lt;/h3&gt;&lt;p&gt;Early demand for edge inference is strongest from industries where even small delays can affect revenue, safety, or user engagement. Retail and e-commerce are among the first adopters because shoppers often abandon slow experiences. Personalised recommendations, search, and multimodal shopping tools all perform better when inference is local and fast.&lt;/p&gt;&lt;p&gt;Finance is another area where latency directly affects value. Jenkins says workloads like fraud checks, payment approval, and transaction scoring rely on chains of AI decisions that should happen in milliseconds. Running inference closer to where data is created helps financial firms move faster and keeps data inside regulatory borders.&lt;/p&gt;&lt;h3&gt;Why cloud and GPU partnerships matter more now&lt;/h3&gt;&lt;p&gt;As AI workloads grow, companies need infrastructure that can keep up. Jenkins says this has pushed cloud providers and GPU makers into closer collaboration. Akamai’s work with NVIDIA is one example, with GPUs, DPUs, and AI software deployed in thousands of edge locations.&lt;/p&gt;&lt;p&gt;The idea is to build an “AI delivery network” that spreads inference across many sites instead of concentrating everything in a few regions. This helps with performance, but it also supports compliance. Jenkins notes that almost half of large APAC organisations struggle with differing data rules across markets, which makes local processing more important. Emerging partnerships are now shaping the next phase of AI infrastructure in the region, especially for workloads that depend on low-latency responses.&lt;/p&gt;&lt;p&gt;Security is built into these systems from the start, Jenkins says. Zero-trust controls, data-aware routing, and protections against fraud and bots are becoming standard parts of the technology stacks on offer.&lt;/p&gt;&lt;h3&gt;The infrastructure needed to support agentic AI and automation&lt;/h3&gt;&lt;p&gt;Running agentic systems – which make many decisions in sequence – needs infrastructure that can operate at millisecond speeds. Jenkins believes the region’s diversity makes this harder but not impossible. Countries differ widely in connectivity, rules, and technical readiness, so AI workloads must be flexible enough to run where it makes the most sense. He points to research showing that most enterprises in the region already use public cloud in production, but many expect to rely on edge services by 2027. That shift will require infrastructure that can hold data in-country, route tasks to the closest suitable location, and keep functioning when networks are unstable.&lt;/p&gt;&lt;h3&gt;What companies need to prepare for next&lt;/h3&gt;&lt;p&gt;As inference moves to the edge, companies will need new ways to manage operations. Jenkins says organisations should expect a more distributed AI lifecycle, where models are updated across many sites. This requires better orchestration and strong visibility into performance, cost, and errors in core and edge systems.&lt;/p&gt;&lt;p&gt;Data governance becomes more complex but also more manageable when processing stays local. Half of the region’s large enterprises already struggle with the variance in regulations, so placing inference closer to where data is generated can help.&lt;/p&gt;&lt;p&gt;Security also needs more attention. While spreading inference to the edge can improve resilience, it also means every site must be secured. Firms need to protect APIs, data pipelines, and guard against fraud or bot attacks. Jenkins notes that many financial institutions already rely on Akamai’s controls in these areas.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Igor Omilaev)&lt;/em&gt;&lt;/p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI spending in Asia Pacific continues to rise, yet many companies still struggle to get value from their AI projects. Much of this comes down to the infrastructure that supports AI, as most systems are not built to run inference at the speed or scale real applications need. Industry studies show many projects miss their ROI goals even after heavy investment in GenAI tools because of the issue.&lt;/p&gt;&lt;p&gt;The gap shows how much AI infrastructure influences performance, cost, and the ability to scale real-world deployments in the region.&lt;/p&gt;&lt;p&gt;Akamai is trying to address this challenge with Inference Cloud, built with NVIDIA and powered by the latest Blackwell GPUs. The idea is simple: if most AI applications need to make decisions in real time, then those decisions should be made close to users rather than in distant data centres. That shift, Akamai claims, can help companies manage cost, reduce delays, and support AI services that depend on split-second responses.&lt;/p&gt;&lt;p&gt;Jay Jenkins, CTO of Cloud Computing at Akamai, explained to &lt;em&gt;AI News&lt;/em&gt; why this moment is forcing enterprises to rethink how they deploy AI and why inference, not training, has become the real bottleneck.&lt;/p&gt;&lt;h3&gt;Why AI projects struggle without the right infrastructure&lt;/h3&gt;&lt;p&gt;Jenkins says the gap between experimentation and full-scale deployment is much wider than many organisations expect. “Many AI initiatives fail to deliver on expected business value because enterprises often underestimate the gap between experimentation and production,” he says. Even with strong interest in GenAI, large infrastructure bills, high latency, and the difficulty of running models at scale often block progress.&lt;/p&gt;&lt;figure class="wp-block-image alignright size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-110833" height="683" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Jay-Jenkins-1024x683.jpg" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;Jay Jenkins, CTO of Cloud Computing at Akamai.&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Most companies still rely on centralised clouds and large GPU clusters. But as use grows, these setups become too expensive, especially in regions far from major cloud zones. Latency also becomes a major issue when models have to run multiple steps of inference over long distances. “AI is only as powerful as the infrastructure and architecture it runs on,” Jenkins says, adding that latency often weakens the user experience and the value the business hoped to deliver. He also points to multi-cloud setups, complex data rules, and growing compliance needs as common hurdles that slow the move from pilot projects to production.&lt;/p&gt;&lt;h3&gt;Why inference now demands more attention than training&lt;/h3&gt;&lt;p&gt;Across Asia Pacific, AI adoption is shifting from small pilots to real deployments in apps and services. Jenkins notes that as this happens, day-to-day inference – not the occasional training cycle – is what consumes most computing power. With many organisations rolling out language, vision, and multimodal models in multiple markets, the demand for fast and reliable inference is rising faster than expected. This is why inference has become the main constraint in the region. Models now need to operate in different languages, regulations, and data environments, often in real time. That puts enormous pressure on centralised systems that were never designed for this level of responsiveness.&lt;/p&gt;&lt;h3&gt;How edge infrastructure improves AI performance and cost&lt;/h3&gt;&lt;p&gt;Jenkins says moving inference closer to users, devices, or agents can reshape the cost equation. Doing so shortens the distance data must travel and allows models to respond faster. It also avoids the cost of routing huge volumes of data between major cloud hubs.&lt;/p&gt;&lt;p&gt;Physical AI systems – robots, autonomous machines, or smart city tools – depend on decisions made in milliseconds. When inference runs distantly, these systems don’t work as expected.&lt;/p&gt;&lt;p&gt;The savings from more localised deployments can also be substantial. Jenkins says Akamai analysis shows enterprises in India and Vietnam see large reductions in the cost of running image-generation models when workloads are placed at the edge, rather than centralised clouds. Better GPU use and lower egress fees played a major role in those savings.&lt;/p&gt;&lt;h3&gt;Where edge-based AI is gaining traction&lt;/h3&gt;&lt;p&gt;Early demand for edge inference is strongest from industries where even small delays can affect revenue, safety, or user engagement. Retail and e-commerce are among the first adopters because shoppers often abandon slow experiences. Personalised recommendations, search, and multimodal shopping tools all perform better when inference is local and fast.&lt;/p&gt;&lt;p&gt;Finance is another area where latency directly affects value. Jenkins says workloads like fraud checks, payment approval, and transaction scoring rely on chains of AI decisions that should happen in milliseconds. Running inference closer to where data is created helps financial firms move faster and keeps data inside regulatory borders.&lt;/p&gt;&lt;h3&gt;Why cloud and GPU partnerships matter more now&lt;/h3&gt;&lt;p&gt;As AI workloads grow, companies need infrastructure that can keep up. Jenkins says this has pushed cloud providers and GPU makers into closer collaboration. Akamai’s work with NVIDIA is one example, with GPUs, DPUs, and AI software deployed in thousands of edge locations.&lt;/p&gt;&lt;p&gt;The idea is to build an “AI delivery network” that spreads inference across many sites instead of concentrating everything in a few regions. This helps with performance, but it also supports compliance. Jenkins notes that almost half of large APAC organisations struggle with differing data rules across markets, which makes local processing more important. Emerging partnerships are now shaping the next phase of AI infrastructure in the region, especially for workloads that depend on low-latency responses.&lt;/p&gt;&lt;p&gt;Security is built into these systems from the start, Jenkins says. Zero-trust controls, data-aware routing, and protections against fraud and bots are becoming standard parts of the technology stacks on offer.&lt;/p&gt;&lt;h3&gt;The infrastructure needed to support agentic AI and automation&lt;/h3&gt;&lt;p&gt;Running agentic systems – which make many decisions in sequence – needs infrastructure that can operate at millisecond speeds. Jenkins believes the region’s diversity makes this harder but not impossible. Countries differ widely in connectivity, rules, and technical readiness, so AI workloads must be flexible enough to run where it makes the most sense. He points to research showing that most enterprises in the region already use public cloud in production, but many expect to rely on edge services by 2027. That shift will require infrastructure that can hold data in-country, route tasks to the closest suitable location, and keep functioning when networks are unstable.&lt;/p&gt;&lt;h3&gt;What companies need to prepare for next&lt;/h3&gt;&lt;p&gt;As inference moves to the edge, companies will need new ways to manage operations. Jenkins says organisations should expect a more distributed AI lifecycle, where models are updated across many sites. This requires better orchestration and strong visibility into performance, cost, and errors in core and edge systems.&lt;/p&gt;&lt;p&gt;Data governance becomes more complex but also more manageable when processing stays local. Half of the region’s large enterprises already struggle with the variance in regulations, so placing inference closer to where data is generated can help.&lt;/p&gt;&lt;p&gt;Security also needs more attention. While spreading inference to the edge can improve resilience, it also means every site must be secured. Firms need to protect APIs, data pipelines, and guard against fraud or bot attacks. Jenkins notes that many financial institutions already rely on Akamai’s controls in these areas.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Igor Omilaev)&lt;/em&gt;&lt;/p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/enterprises-are-rethinking-ai-infrastructure-as-inference-costs-rise/</guid><pubDate>Mon, 24 Nov 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] How Europe’s talent can secure a trillion-euro AI economic injection (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-europe-talent-can-secure-trillion-euro-ai-economic-injection/</link><description>&lt;p&gt;A €1.2 trillion AI prize sits on the table for Europe’s economy, and the region has the talent and raw ingredients to claim it.&lt;/p&gt;&lt;p&gt;While the global narrative often focuses on competition with the US and China, the view from the ground in Europe is a region of untapped potential, world-class talent, and deep infrastructure investment.&lt;/p&gt;&lt;p&gt;Debbie Weinstein, President of Google EMEA, sees a “new generation of visionary founders” ready to drive the region’s future. The opportunity is built on a foundation of scientific excellence and a workforce that is “as bright as anywhere else in the world.”&lt;/p&gt;&lt;p&gt;The task now is to leverage Europe’s strengths to close the AI adoption gap and accelerate growth.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-foundation-of-innovation"&gt;A foundation of innovation&lt;/h3&gt;&lt;p&gt;Europe is already a powerhouse of scientific breakthrough. The Google DeepMind team – which includes Nobel prize winners – drives discovery from London, while nearly one million researchers across EMEA use AlphaFold to solve biological problems. Europe isn’t starting from scratch; it is a hub of high-level R&amp;amp;D.&lt;/p&gt;&lt;p&gt;That intellectual capital is being matched by hard investment. Just last week, Google announced a €5.5 billion investment in Germany to support connectivity and infrastructure.&lt;/p&gt;&lt;p&gt;The choice to base ‘Security Operations Centres’ in Munich, Dublin, and Malaga also highlights Europe’s specific strength: a deep, culturally ingrained commitment to privacy and security. For businesses, this signals that Europe offers a stable and secure environment for building long-term digital strategies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-potential-of-ai-in-europe"&gt;The potential of AI in Europe&lt;/h3&gt;&lt;p&gt;Currently, only 14 percent of European businesses use AI. While some see this as a lag, optimists see it as massive headroom for growth. The businesses that do adopt these tools are seeing powerful results.&lt;/p&gt;&lt;p&gt;Weinstein points to Spanish startup Idoven as a prime example of Europe’s potential. They are using AI to help doctors detect heart disease earlier, proving that when European founders get access to the right tools, they build world-changing solutions.&lt;/p&gt;&lt;p&gt;The operational gains are equally tangible in traditional sectors. In automotive, upgrading from basic voice assistants to AI co-pilots can prevent accidents by detecting driver fatigue. In cybersecurity, modern tools allow teams to stay ahead of sophisticated threats. The technology acts as a force multiplier, giving businesses the “most powerful toolbox they’ve ever had.”&lt;/p&gt;&lt;p&gt;To fully realise this €1.2 trillion potential, Europe’s businesses need access to the same high-performance AI models as their global peers. The latest models are 300 times more powerful than those from two years ago, offering a massive productivity boost to those who can deploy them.&lt;/p&gt;&lt;p&gt;There is positive momentum on the regulatory front. Weinstein notes that the release of the Commission’s Digital Omnibus is a “step in the right direction” to help businesses compete globally.&lt;/p&gt;&lt;p&gt;The goal now is harmonisation; creating a clearer and simpler regime that allows companies to train models responsibly and launch products faster. A unified market with clear and sensible rules will be the catalyst that turns potential into GDP.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-investing-in-the-workforce"&gt;Investing in the workforce&lt;/h3&gt;&lt;p&gt;The final piece of the puzzle is people. Seizing this moment requires a workforce confident in using it. Weinstein stresses that we need leaders who can identify opportunities and managers who are AI-literate.&lt;/p&gt;&lt;p&gt;This is happening through partnership. Google has already helped over 15 million Europeans learn digital skills and is now rolling out a €15 million AI Opportunity Fund to support vulnerable workers. For enterprise leaders, the message is clear: investing in skills today builds the confidence to take risks and grow tomorrow.&lt;/p&gt;&lt;p&gt;Europe has the talent, the values, and the infrastructure. With the right focus on skills and a push for harmonised access to tools, Europe is well-positioned to lead the way and capture the full value of the AI era.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How the Royal Navy is using AI to cut its recruitment workload&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A €1.2 trillion AI prize sits on the table for Europe’s economy, and the region has the talent and raw ingredients to claim it.&lt;/p&gt;&lt;p&gt;While the global narrative often focuses on competition with the US and China, the view from the ground in Europe is a region of untapped potential, world-class talent, and deep infrastructure investment.&lt;/p&gt;&lt;p&gt;Debbie Weinstein, President of Google EMEA, sees a “new generation of visionary founders” ready to drive the region’s future. The opportunity is built on a foundation of scientific excellence and a workforce that is “as bright as anywhere else in the world.”&lt;/p&gt;&lt;p&gt;The task now is to leverage Europe’s strengths to close the AI adoption gap and accelerate growth.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-foundation-of-innovation"&gt;A foundation of innovation&lt;/h3&gt;&lt;p&gt;Europe is already a powerhouse of scientific breakthrough. The Google DeepMind team – which includes Nobel prize winners – drives discovery from London, while nearly one million researchers across EMEA use AlphaFold to solve biological problems. Europe isn’t starting from scratch; it is a hub of high-level R&amp;amp;D.&lt;/p&gt;&lt;p&gt;That intellectual capital is being matched by hard investment. Just last week, Google announced a €5.5 billion investment in Germany to support connectivity and infrastructure.&lt;/p&gt;&lt;p&gt;The choice to base ‘Security Operations Centres’ in Munich, Dublin, and Malaga also highlights Europe’s specific strength: a deep, culturally ingrained commitment to privacy and security. For businesses, this signals that Europe offers a stable and secure environment for building long-term digital strategies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-potential-of-ai-in-europe"&gt;The potential of AI in Europe&lt;/h3&gt;&lt;p&gt;Currently, only 14 percent of European businesses use AI. While some see this as a lag, optimists see it as massive headroom for growth. The businesses that do adopt these tools are seeing powerful results.&lt;/p&gt;&lt;p&gt;Weinstein points to Spanish startup Idoven as a prime example of Europe’s potential. They are using AI to help doctors detect heart disease earlier, proving that when European founders get access to the right tools, they build world-changing solutions.&lt;/p&gt;&lt;p&gt;The operational gains are equally tangible in traditional sectors. In automotive, upgrading from basic voice assistants to AI co-pilots can prevent accidents by detecting driver fatigue. In cybersecurity, modern tools allow teams to stay ahead of sophisticated threats. The technology acts as a force multiplier, giving businesses the “most powerful toolbox they’ve ever had.”&lt;/p&gt;&lt;p&gt;To fully realise this €1.2 trillion potential, Europe’s businesses need access to the same high-performance AI models as their global peers. The latest models are 300 times more powerful than those from two years ago, offering a massive productivity boost to those who can deploy them.&lt;/p&gt;&lt;p&gt;There is positive momentum on the regulatory front. Weinstein notes that the release of the Commission’s Digital Omnibus is a “step in the right direction” to help businesses compete globally.&lt;/p&gt;&lt;p&gt;The goal now is harmonisation; creating a clearer and simpler regime that allows companies to train models responsibly and launch products faster. A unified market with clear and sensible rules will be the catalyst that turns potential into GDP.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-investing-in-the-workforce"&gt;Investing in the workforce&lt;/h3&gt;&lt;p&gt;The final piece of the puzzle is people. Seizing this moment requires a workforce confident in using it. Weinstein stresses that we need leaders who can identify opportunities and managers who are AI-literate.&lt;/p&gt;&lt;p&gt;This is happening through partnership. Google has already helped over 15 million Europeans learn digital skills and is now rolling out a €15 million AI Opportunity Fund to support vulnerable workers. For enterprise leaders, the message is clear: investing in skills today builds the confidence to take risks and grow tomorrow.&lt;/p&gt;&lt;p&gt;Europe has the talent, the values, and the infrastructure. With the right focus on skills and a push for harmonised access to tools, Europe is well-positioned to lead the way and capture the full value of the AI era.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How the Royal Navy is using AI to cut its recruitment workload&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110612" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-8.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-europe-talent-can-secure-trillion-euro-ai-economic-injection/</guid><pubDate>Mon, 24 Nov 2025 12:03:53 +0000</pubDate></item><item><title>[NEW] Google commits to 1000x more AI infrastructure in next 4-5 years (AI News)</title><link>https://www.artificialintelligence-news.com/news/google-commits-to-1000x-more-ai-infrastructure-in-next-4-5-years/</link><description>&lt;p&gt; In order to meet the massive demand for AI, Google wants to double the overall size of its servers every six months, a growth rate that would create a 1000x greater capacity in the next four or five years.&lt;/p&gt;&lt;p&gt; The statement came from the head of Google’s AI infrastructure, Amin Vahdat, during an all-hands meeting on November 6, according to &lt;i&gt;CNBC&lt;/i&gt;. Alphabet, Google’s parent company is certainly performing well, so such a requirement may be within its financial capabilities. It reported good Q3 figures at the end of October, and has raised its capital expenditure forecast to $93 billion, up from $91 billion.&lt;/p&gt;&lt;p&gt; Vahdat addressed one employee’s question about the company’s future amid talk of an ‘AI bubble’ by re-stating the risks of not investing aggressively enough. In its cloud operations, such investment in infrastructure has paid off. “The risk of under-investing is pretty high […] the cloud numbers would have been much better if we had more compute.”&lt;/p&gt;&lt;p&gt; Google’s cloud business continues to grow at around a 33% per year, creating an income stream that enables the company to be “better positioned to withstand misses than other companies,” he said.&lt;/p&gt;&lt;p&gt; With better infrastructure running more efficient hardware such as the seventh-gen Tensor Processing Unit and more efficient LLM models, Google is confident that it can continue to create value for its enterprise users’ increased implementation of AI technologies.&lt;/p&gt;&lt;p&gt; According to Markus Nispel of Extreme Networks, writing on techradar.com in September, it’s IT infrastructure that’s making companies’ AI vision falter. He places the blame for any failure of AI projects on the high demands AI workloads place on legacy systems, the need for real-time and edge facilities (often lacking in current enterprises), and the continuing presence of data silos. “Even when projects do launch, they’re often hampered by delays caused by poor data availability or fragmented systems. If clean, real-time data can’t flow freely across the organisation, AI models can’t operate effectively, and the insights they produce arrive too late or lack impact,” he said.&lt;/p&gt;&lt;p&gt; “With 80% of AI projects struggling to deliver on expectations globally, primarily due to infrastructure limitations rather than the AI technology itself, what matters now is how we respond.”&lt;/p&gt;&lt;p&gt; His views are shared by decision-makers at the large technology providers: Capital expenditure by Google, Microsoft, Amazon, and Meta is expected to top $380 billion this year, the majority of which is focused on AI infrastructure.&lt;/p&gt;&lt;p&gt; The message from the hyperscalers is clear: If we build it, they will come.&lt;/p&gt;&lt;p&gt; Addressing the infrastructure challenges that organisations experience is the key component to successful implementation of AI-based projects. Agile infrastructure as close as possible to the point of compute and data sets that are unified are seen as important parts of the recipe for getting full value from next-generation AI projects.&lt;/p&gt;&lt;p&gt; Although some market realignment is expected across the AI sector in the next six months, companies like Google are among those expected to be able to consolidate on the market and continue to offer game-changing technologies based on AI as it evolves.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Construction site” by tomavim is licensed under CC BY-NC 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt; In order to meet the massive demand for AI, Google wants to double the overall size of its servers every six months, a growth rate that would create a 1000x greater capacity in the next four or five years.&lt;/p&gt;&lt;p&gt; The statement came from the head of Google’s AI infrastructure, Amin Vahdat, during an all-hands meeting on November 6, according to &lt;i&gt;CNBC&lt;/i&gt;. Alphabet, Google’s parent company is certainly performing well, so such a requirement may be within its financial capabilities. It reported good Q3 figures at the end of October, and has raised its capital expenditure forecast to $93 billion, up from $91 billion.&lt;/p&gt;&lt;p&gt; Vahdat addressed one employee’s question about the company’s future amid talk of an ‘AI bubble’ by re-stating the risks of not investing aggressively enough. In its cloud operations, such investment in infrastructure has paid off. “The risk of under-investing is pretty high […] the cloud numbers would have been much better if we had more compute.”&lt;/p&gt;&lt;p&gt; Google’s cloud business continues to grow at around a 33% per year, creating an income stream that enables the company to be “better positioned to withstand misses than other companies,” he said.&lt;/p&gt;&lt;p&gt; With better infrastructure running more efficient hardware such as the seventh-gen Tensor Processing Unit and more efficient LLM models, Google is confident that it can continue to create value for its enterprise users’ increased implementation of AI technologies.&lt;/p&gt;&lt;p&gt; According to Markus Nispel of Extreme Networks, writing on techradar.com in September, it’s IT infrastructure that’s making companies’ AI vision falter. He places the blame for any failure of AI projects on the high demands AI workloads place on legacy systems, the need for real-time and edge facilities (often lacking in current enterprises), and the continuing presence of data silos. “Even when projects do launch, they’re often hampered by delays caused by poor data availability or fragmented systems. If clean, real-time data can’t flow freely across the organisation, AI models can’t operate effectively, and the insights they produce arrive too late or lack impact,” he said.&lt;/p&gt;&lt;p&gt; “With 80% of AI projects struggling to deliver on expectations globally, primarily due to infrastructure limitations rather than the AI technology itself, what matters now is how we respond.”&lt;/p&gt;&lt;p&gt; His views are shared by decision-makers at the large technology providers: Capital expenditure by Google, Microsoft, Amazon, and Meta is expected to top $380 billion this year, the majority of which is focused on AI infrastructure.&lt;/p&gt;&lt;p&gt; The message from the hyperscalers is clear: If we build it, they will come.&lt;/p&gt;&lt;p&gt; Addressing the infrastructure challenges that organisations experience is the key component to successful implementation of AI-based projects. Agile infrastructure as close as possible to the point of compute and data sets that are unified are seen as important parts of the recipe for getting full value from next-generation AI projects.&lt;/p&gt;&lt;p&gt; Although some market realignment is expected across the AI sector in the next six months, companies like Google are among those expected to be able to consolidate on the market and continue to offer game-changing technologies based on AI as it evolves.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Construction site” by tomavim is licensed under CC BY-NC 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/google-commits-to-1000x-more-ai-infrastructure-in-next-4-5-years/</guid><pubDate>Mon, 24 Nov 2025 12:48:13 +0000</pubDate></item><item><title>[NEW] The Download: how to fix a tractor, and living among conspiracy theorists (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/24/1128306/the-download-how-to-fix-a-tractor-and-living-among-conspiracy-theorists/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the man building a starter kit for civilization&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;You live in a house you designed and built yourself. You rely on the sun for power, heat your home with a woodstove, and farm your own fish and vegetables. The year is 2025.&lt;/p&gt;&lt;p&gt;This is the life of Marcin Jakubowski, the 53-year-old founder of Open Source Ecology, an open collaborative of engineers, producers, and builders developing what they call the Global Village Construction Set (GVCS).&lt;/p&gt;&lt;p&gt;It’s a set of 50 machines—everything from a tractor to an oven to a circuit maker—that are capable of building civilization from scratch and can be reconfigured however you see fit. It’s all part of his ethos that life-changing technology should be available to all, not controlled by a select few.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Tiffany Ng&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the &lt;/strong&gt;&lt;strong&gt;latest print issue&lt;/strong&gt;&lt;strong&gt; of MIT Technology Review magazine, which is full of fascinating stories. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What it’s like to find yourself in the middle of a conspiracy theory&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Last week, we held a subscribers-only Roundtables discussion exploring how to cope in this new age of conspiracy theories. Our features editor Amanda Silverman and executive editor Niall Firth were joined by conspiracy expert Mike Rothschild, who explained exactly what it’s like to find yourself at the center of a conspiracy you can’t control. Watch the conversation back here.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 DOGE has been disbanded&lt;/strong&gt;&lt;br /&gt;Even though it’s got eight months left before its official scheduled end. (Reuters)&lt;br /&gt;+ &lt;em&gt;It leaves a legacy of chaos and few measurable savings. &lt;/em&gt;(Politico)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 How OpenAI’s tweaks to ChatGPT sent some users into delusional spirals&lt;/strong&gt;&lt;br /&gt;It essentially turned a dial that increased both usage of the chatbot and the risks it poses to a subset of people. (NYT $)&lt;br /&gt;+ &lt;em&gt;AI workers are warning loved ones to stay away from the technology. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 A three-year old has received the world’s first gene therapy for Hunter syndrome&lt;/strong&gt;&lt;br /&gt;Oliver Chu appears to be developing normally one year after starting therapy. (BBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 Why we may—or may not—be in an AI bubble 🫧&lt;/strong&gt;&lt;br /&gt;It’s time to follow the data. (WP $)&lt;br /&gt;+ &lt;em&gt;Even tech leaders don’t appear to be entirely sure. &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;How far can the ‘fake it til you make it’ strategy take us? &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Nvidia is still riding the wave with abandon. &lt;/em&gt;(NY Mag $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Many MAGA influencers are based in Russia, India and Nigeria&lt;br /&gt;X’s new account provenance feature is revealing some interesting truths. (The Daily Beast)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 The FBI wants to equip drones with facial recognition tech&lt;/strong&gt;&lt;br /&gt;Civil libertarians claim the plans equate to airborne surveillance. (The Intercept)&lt;br /&gt;+ &lt;em&gt;This giant microwave may change the future of war. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;7&amp;nbsp; Snapchat is alerting users ahead of Australia’s under-16s social media ban&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The platform will analyze an account’s “behavioral signals” to estimate a user’s age. (The Guardian)&lt;br /&gt;+ &lt;em&gt;An AI nudification site has been fined for skipping age checks. &lt;/em&gt;(The Register)&lt;br /&gt;+ &lt;em&gt;Millennial parents are fetishizing the notion of an offline childhood. &lt;/em&gt;(The Observer)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Activists are roleplaying ICE raids in Fortnite and Grand Theft Auto&lt;br /&gt;&lt;/strong&gt;It’s in a bid to prepare players to exercise their rights in the real world. (Wired $)&lt;br /&gt;+ &lt;em&gt;Another effort to track ICE raids was just taken offline. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The JWST may have uncovered colossal stars ⭐&lt;/strong&gt;&lt;br /&gt;In fact, they’re so big their masses are 10,000 times bigger than the sun. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Inside the hunt for the most dangerous asteroid ever. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Social media users are lying about brands ghosting them&lt;/strong&gt;&lt;br /&gt;Completely normal behavior. (WSJ $)&lt;br /&gt;+ &lt;em&gt;This would never have happened on Vine, I’ll tell you now. &lt;/em&gt;(The Verge)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I can’t believe we have to say this, but this account has only ever been run and operated from the United States.”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;—&lt;/strong&gt;The US Department of Homeland Security’s X account attempts to end speculation surrounding its social media origins, the New York Times reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128308" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_4feb0e.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;This company is planning a lithium empire from the shores of the Great Salt Lake&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;On a bright afternoon in August, the shore of Utah’s Great Salt Lake looks like something out of a science fiction film set in a scorching alien world.&lt;/p&gt;&lt;p&gt;This otherworldly scene is the test site for a company called Lilac Solutions, which is developing a technology it says will shake up the United States’ efforts to pry control over the global supply of lithium, the so-called “white gold” needed for electric vehicles and batteries, away from China.&lt;/p&gt;&lt;p&gt;The startup is in a race to commercialize a new, less environmentally-damaging way to extract lithium from rocks. If everything pans out, it could significantly increase domestic supply at a crucial moment for the nation’s lithium extraction industry. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Alexander C. Kaufman&lt;/em&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Meet the man building a starter kit for civilization&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;You live in a house you designed and built yourself. You rely on the sun for power, heat your home with a woodstove, and farm your own fish and vegetables. The year is 2025.&lt;/p&gt;&lt;p&gt;This is the life of Marcin Jakubowski, the 53-year-old founder of Open Source Ecology, an open collaborative of engineers, producers, and builders developing what they call the Global Village Construction Set (GVCS).&lt;/p&gt;&lt;p&gt;It’s a set of 50 machines—everything from a tractor to an oven to a circuit maker—that are capable of building civilization from scratch and can be reconfigured however you see fit. It’s all part of his ethos that life-changing technology should be available to all, not controlled by a select few.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Tiffany Ng&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the &lt;/strong&gt;&lt;strong&gt;latest print issue&lt;/strong&gt;&lt;strong&gt; of MIT Technology Review magazine, which is full of fascinating stories. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive future issues once they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;What it’s like to find yourself in the middle of a conspiracy theory&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Last week, we held a subscribers-only Roundtables discussion exploring how to cope in this new age of conspiracy theories. Our features editor Amanda Silverman and executive editor Niall Firth were joined by conspiracy expert Mike Rothschild, who explained exactly what it’s like to find yourself at the center of a conspiracy you can’t control. Watch the conversation back here.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 DOGE has been disbanded&lt;/strong&gt;&lt;br /&gt;Even though it’s got eight months left before its official scheduled end. (Reuters)&lt;br /&gt;+ &lt;em&gt;It leaves a legacy of chaos and few measurable savings. &lt;/em&gt;(Politico)&lt;br /&gt;+ &lt;em&gt;DOGE’s tech takeover threatens the safety and stability of our critical data. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 How OpenAI’s tweaks to ChatGPT sent some users into delusional spirals&lt;/strong&gt;&lt;br /&gt;It essentially turned a dial that increased both usage of the chatbot and the risks it poses to a subset of people. (NYT $)&lt;br /&gt;+ &lt;em&gt;AI workers are warning loved ones to stay away from the technology. &lt;/em&gt;(The Guardian)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 A three-year old has received the world’s first gene therapy for Hunter syndrome&lt;/strong&gt;&lt;br /&gt;Oliver Chu appears to be developing normally one year after starting therapy. (BBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 Why we may—or may not—be in an AI bubble 🫧&lt;/strong&gt;&lt;br /&gt;It’s time to follow the data. (WP $)&lt;br /&gt;+ &lt;em&gt;Even tech leaders don’t appear to be entirely sure. &lt;/em&gt;(Insider $)&lt;br /&gt;+ &lt;em&gt;How far can the ‘fake it til you make it’ strategy take us? &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;Nvidia is still riding the wave with abandon. &lt;/em&gt;(NY Mag $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 Many MAGA influencers are based in Russia, India and Nigeria&lt;br /&gt;X’s new account provenance feature is revealing some interesting truths. (The Daily Beast)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 The FBI wants to equip drones with facial recognition tech&lt;/strong&gt;&lt;br /&gt;Civil libertarians claim the plans equate to airborne surveillance. (The Intercept)&lt;br /&gt;+ &lt;em&gt;This giant microwave may change the future of war. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;7&amp;nbsp; Snapchat is alerting users ahead of Australia’s under-16s social media ban&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The platform will analyze an account’s “behavioral signals” to estimate a user’s age. (The Guardian)&lt;br /&gt;+ &lt;em&gt;An AI nudification site has been fined for skipping age checks. &lt;/em&gt;(The Register)&lt;br /&gt;+ &lt;em&gt;Millennial parents are fetishizing the notion of an offline childhood. &lt;/em&gt;(The Observer)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Activists are roleplaying ICE raids in Fortnite and Grand Theft Auto&lt;br /&gt;&lt;/strong&gt;It’s in a bid to prepare players to exercise their rights in the real world. (Wired $)&lt;br /&gt;+ &lt;em&gt;Another effort to track ICE raids was just taken offline. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The JWST may have uncovered colossal stars ⭐&lt;/strong&gt;&lt;br /&gt;In fact, they’re so big their masses are 10,000 times bigger than the sun. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Inside the hunt for the most dangerous asteroid ever. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Social media users are lying about brands ghosting them&lt;/strong&gt;&lt;br /&gt;Completely normal behavior. (WSJ $)&lt;br /&gt;+ &lt;em&gt;This would never have happened on Vine, I’ll tell you now. &lt;/em&gt;(The Verge)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I can’t believe we have to say this, but this account has only ever been run and operated from the United States.”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;—&lt;/strong&gt;The US Department of Homeland Security’s X account attempts to end speculation surrounding its social media origins, the New York Times reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128308" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_4feb0e.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;This company is planning a lithium empire from the shores of the Great Salt Lake&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;On a bright afternoon in August, the shore of Utah’s Great Salt Lake looks like something out of a science fiction film set in a scorching alien world.&lt;/p&gt;&lt;p&gt;This otherworldly scene is the test site for a company called Lilac Solutions, which is developing a technology it says will shake up the United States’ efforts to pry control over the global supply of lithium, the so-called “white gold” needed for electric vehicles and batteries, away from China.&lt;/p&gt;&lt;p&gt;The startup is in a race to commercialize a new, less environmentally-damaging way to extract lithium from rocks. If everything pans out, it could significantly increase domestic supply at a crucial moment for the nation’s lithium extraction industry. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Alexander C. Kaufman&lt;/em&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/24/1128306/the-download-how-to-fix-a-tractor-and-living-among-conspiracy-theorists/</guid><pubDate>Mon, 24 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] Momentic raises $15M to automate software testing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/momentic-raises-15m-to-automate-software-testing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/20251119-DSC07129.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Product demos get all the attention, but software development more often involves things like debugging, quality assurance, and testing. It’s the dull but critical work that keeps software running the way it should, and as developers look to automate more of their workloads, it’s increasingly being done by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, the AI testing startup Momentic said it had raised $15 million in a Series A round led by Standard Capital, with participation from Dropbox Ventures. Existing investors at Y Combinator, FCVC, Transpose Platform, and Karman Ventures also participated in the round. The new funding builds on a $3.7 million seed round, which the company announced in March.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Momentic makes tools for software testing and verification, a niche currently occupied by open source frameworks like Playwright and Selenium. Those tools offer complex, fine-grained controls, but Momentic is counting on AI to make the process simple and effective.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We help our customers make sure their product works,” co-founder Wei-Wei Wu said. “They can describe their critical user flows in plain English and our AI will automate it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wu and his co-founder Jeff An both have backgrounds in developer tooling at companies like Qualtrics and WeWork. (Wu is particularly proud of his contributions to the open source Node.js.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The biggest constant for all those companies, as Wu saw it, was the problem of verifying code. “Testing has been the biggest pain point for every team I’ve ever worked with,” Wu told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Momentic’s AI-driven approach has already won over a number of clients. The company currently boasts 2,600 users across its customer base, which includes companies like Notion, Xero, Bilt, Webflow, and Retool. Wu was coy about revenue and profitability figures, but says the product has shown enough growth to convince investors.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, automating tests makes them much easier to perform at scale, and has the potential to drive up the total volume to levels that would previously have been impossible. Wu estimates that, in the last month, the company automated more than 200 million test steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s biggest competitor may be the foundation models themselves. Both OpenAI and Anthropic offer tutorials on agentic testing, building on their models’ growing computer use capabilities. As those models grow more sophisticated, the opportunity for enterprise SaaS companies like Momentic could narrow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Wu is focused on fleshing out his product with the new funding. The company launched support for mobile environments in August, and is hoping to build more sophisticated test-case management once it has a few more engineers on board. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Wu sees it, the rise of automated coding will produce a lot of new apps — and a lot more demand for products like his. “All of these apps need testing,” he said. “They care about quality, and we’re going to provide it for them.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/20251119-DSC07129.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Product demos get all the attention, but software development more often involves things like debugging, quality assurance, and testing. It’s the dull but critical work that keeps software running the way it should, and as developers look to automate more of their workloads, it’s increasingly being done by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, the AI testing startup Momentic said it had raised $15 million in a Series A round led by Standard Capital, with participation from Dropbox Ventures. Existing investors at Y Combinator, FCVC, Transpose Platform, and Karman Ventures also participated in the round. The new funding builds on a $3.7 million seed round, which the company announced in March.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Momentic makes tools for software testing and verification, a niche currently occupied by open source frameworks like Playwright and Selenium. Those tools offer complex, fine-grained controls, but Momentic is counting on AI to make the process simple and effective.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We help our customers make sure their product works,” co-founder Wei-Wei Wu said. “They can describe their critical user flows in plain English and our AI will automate it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wu and his co-founder Jeff An both have backgrounds in developer tooling at companies like Qualtrics and WeWork. (Wu is particularly proud of his contributions to the open source Node.js.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The biggest constant for all those companies, as Wu saw it, was the problem of verifying code. “Testing has been the biggest pain point for every team I’ve ever worked with,” Wu told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Momentic’s AI-driven approach has already won over a number of clients. The company currently boasts 2,600 users across its customer base, which includes companies like Notion, Xero, Bilt, Webflow, and Retool. Wu was coy about revenue and profitability figures, but says the product has shown enough growth to convince investors.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, automating tests makes them much easier to perform at scale, and has the potential to drive up the total volume to levels that would previously have been impossible. Wu estimates that, in the last month, the company automated more than 200 million test steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s biggest competitor may be the foundation models themselves. Both OpenAI and Anthropic offer tutorials on agentic testing, building on their models’ growing computer use capabilities. As those models grow more sophisticated, the opportunity for enterprise SaaS companies like Momentic could narrow.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Wu is focused on fleshing out his product with the new funding. The company launched support for mobile environments in August, and is hoping to build more sophisticated test-case management once it has a few more engineers on board. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As Wu sees it, the rise of automated coding will produce a lot of new apps — and a lot more demand for products like his. “All of these apps need testing,” he said. “They care about quality, and we’re going to provide it for them.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/momentic-raises-15m-to-automate-software-testing/</guid><pubDate>Mon, 24 Nov 2025 14:00:27 +0000</pubDate></item><item><title>[NEW] UK government will buy tech to boost AI sector in $130M growth push (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/11/uk-government-will-buy-tech-to-boost-ai-sector-in-130m-growth-push/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Plan will offer guaranteed payments for British startups making AI hardware
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      LONDON, ENGLAND - NOVEMBER 18: Secretary of State for Work and Pensions Liz Kendall leaves Downing Street following the weekly cabinet meeting on November 18, 2025 in London, England. (Photo by Leon Neal/Getty Images)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The UK government will promise to buy emerging chip technology from British companies in a 100 million pound ($130 million) bid to boost growth by supporting the artificial intelligence sector.&lt;/p&gt;
&lt;p&gt;Liz Kendall, the science secretary, said the government would offer guaranteed payments to British startups producing AI hardware that can help sectors such as life sciences and financial services.&lt;/p&gt;
&lt;p&gt;Under a “first customer” promise modeled on the way the government bought COVID vaccines, Kendall’s department will commit in advance to buying AI inference chips that meet set performance standards.&lt;/p&gt;
&lt;p&gt;Kendall acknowledged that 100 million pounds “sounds small compared to the billions being spent” in the US and China but argued it was about “government showing leadership in the areas where we think we will be absolutely world-leading.”&lt;/p&gt;
&lt;p&gt;Valued at over 72 billion pounds ($94 billion), the UK’s AI market is the third largest in the world following the US and China, according to the British government.&lt;/p&gt;
&lt;p&gt;However, investment in AI in the UK lags behind the US. In 2024, US private investment in AI was at $109.1 billion—significantly higher than the UK’s $4.5 billion, according to the Stanford AI Index.&lt;/p&gt;
&lt;p&gt;The science secretary did not provide precise details on how the “advance payment mechanism” would work but said “cutting-edge chip companies” based in Britain will be told “the government will buy that when the technology reaches a certain standard.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Our particular strengths as a country lie in areas like life sciences, financial services, the defense sector, and the creative sector. And where we will really lead the world is where we can use the power of AI in those sectors,” Kendall told the Financial Times.&lt;/p&gt;
&lt;p&gt;The plans came as part of a wider AI package designed to upgrade Britain’s tech infrastructure and convince entrepreneurs and investors that Labour is backing the sector ahead of next week’s Budget, which is expected to raise taxes on the wealthy.&lt;/p&gt;
&lt;p&gt;The UK has sought to attract investment from US AI companies such as OpenAI and Anthropic.&lt;/p&gt;
&lt;p&gt;The government has signed several “strategic partnerships” with American groups in a bid to attract foreign investment in UK AI infrastructure and talent, in exchange for adopting their technology in the public sector.&lt;/p&gt;
&lt;p&gt;Sue Daley, of lobby group TechUK, said the plan showed “real ambition” but warned: “Advanced market commitments of this kind must be designed carefully to avoid unintentionally distorting competition.”&lt;/p&gt;
&lt;p&gt;The government also announced that James Wise, a venture capitalist at Balderton, would chair the government’s 500 million pound sovereign AI unit, which has been set up to back AI startups alongside the British Business Bank.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Ivan Levingston&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Plan will offer guaranteed payments for British startups making AI hardware
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2247290617-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      LONDON, ENGLAND - NOVEMBER 18: Secretary of State for Work and Pensions Liz Kendall leaves Downing Street following the weekly cabinet meeting on November 18, 2025 in London, England. (Photo by Leon Neal/Getty Images)

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Leon Neal / Staff

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The UK government will promise to buy emerging chip technology from British companies in a 100 million pound ($130 million) bid to boost growth by supporting the artificial intelligence sector.&lt;/p&gt;
&lt;p&gt;Liz Kendall, the science secretary, said the government would offer guaranteed payments to British startups producing AI hardware that can help sectors such as life sciences and financial services.&lt;/p&gt;
&lt;p&gt;Under a “first customer” promise modeled on the way the government bought COVID vaccines, Kendall’s department will commit in advance to buying AI inference chips that meet set performance standards.&lt;/p&gt;
&lt;p&gt;Kendall acknowledged that 100 million pounds “sounds small compared to the billions being spent” in the US and China but argued it was about “government showing leadership in the areas where we think we will be absolutely world-leading.”&lt;/p&gt;
&lt;p&gt;Valued at over 72 billion pounds ($94 billion), the UK’s AI market is the third largest in the world following the US and China, according to the British government.&lt;/p&gt;
&lt;p&gt;However, investment in AI in the UK lags behind the US. In 2024, US private investment in AI was at $109.1 billion—significantly higher than the UK’s $4.5 billion, according to the Stanford AI Index.&lt;/p&gt;
&lt;p&gt;The science secretary did not provide precise details on how the “advance payment mechanism” would work but said “cutting-edge chip companies” based in Britain will be told “the government will buy that when the technology reaches a certain standard.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Our particular strengths as a country lie in areas like life sciences, financial services, the defense sector, and the creative sector. And where we will really lead the world is where we can use the power of AI in those sectors,” Kendall told the Financial Times.&lt;/p&gt;
&lt;p&gt;The plans came as part of a wider AI package designed to upgrade Britain’s tech infrastructure and convince entrepreneurs and investors that Labour is backing the sector ahead of next week’s Budget, which is expected to raise taxes on the wealthy.&lt;/p&gt;
&lt;p&gt;The UK has sought to attract investment from US AI companies such as OpenAI and Anthropic.&lt;/p&gt;
&lt;p&gt;The government has signed several “strategic partnerships” with American groups in a bid to attract foreign investment in UK AI infrastructure and talent, in exchange for adopting their technology in the public sector.&lt;/p&gt;
&lt;p&gt;Sue Daley, of lobby group TechUK, said the plan showed “real ambition” but warned: “Advanced market commitments of this kind must be designed carefully to avoid unintentionally distorting competition.”&lt;/p&gt;
&lt;p&gt;The government also announced that James Wise, a venture capitalist at Balderton, would chair the government’s 500 million pound sovereign AI unit, which has been set up to back AI startups alongside the British Business Bank.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Additional reporting by Ivan Levingston&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/11/uk-government-will-buy-tech-to-boost-ai-sector-in-130m-growth-push/</guid><pubDate>Mon, 24 Nov 2025 14:17:29 +0000</pubDate></item><item><title>[NEW] Former MrBeast content strategist is building an AI tool for creator ideation and analytics (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/former-mrbeast-content-strategist-is-building-an-ai-tool-for-creator-ideation-and-analytics/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Short videos are in high demand. Across large platforms like Instagram, Facebook, YouTube, and TikTok, users are watching billions of videos every day, with companies benefiting massively from this content explosion. For creators, this often means there is pressure to create more content than ever before to be relevant and make a living out of it, especially as more AI-generated slop is infiltrating these platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jay Neo, a creator and former content lead for short videos at MrBeast, thinks AI can help creators understand what is working for them and also help them create new content ideas in that direction. That’s why, along with former Palantir engineer Shivam Kumar and creator Harry Jones, they are building a platform called Palo to aid creators.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070192" height="505" src="https://techcrunch.com/wp-content/uploads/2025/11/Shivam-Kumar-Jay-Neo-Credit_-Jack-Willingham.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Shivam Kumar and Jay Neo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jack Willingham&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Neo joined MrBeast at 18 to work on viewer retention. In a conversation with TechCrunch, he said that he became fixated with studying different metrics to understand where video viewership dipped.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I was so obsessed with retention graphs and figuring out why viewers stayed or why they left. I had a document where I noted all this down. Gradually, my role shifted to getting more responsibility around editing and ideation,” Neo said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neo’s crowning jewel was a video where the creator asks people on the street if they’d fly to Paris to get a baguette, which garnered more than 1.8 billion views across channels. MrBeast ended up making multiple videos with this format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Neo left MrBeast and started several channels under the “Creaky” branding with another MrBeast co-writer and scaled these to over a billion views per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With these experiences, Neo understood there’s power in content formulation and analytics. During his time building Creaky, the team had multiple spreadsheets tracking different metrics around videos. At that time, one of Neo’s advisors suggested that he turn these insights into a product for creators, and he started working with Palo’s other co-founders in early 2024.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070195" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Chat.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Palo has three core parts to its app: an AI-powered ideation and planning tool, analytics, and community. The company onboards a creator and asks them to integrate all their accounts. The tool then analyzes all their short videos and provides insights into what is working and what is not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kumar, who is CTO at the startup, said that Palo uses a mix of models to extract a data tree that has insights into hooks, audience sentiment, interest topics, originality, and possible related search terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The inference engine takes these primary data points and then uses a cocktail of top LLMs to hierarchically aggregate these data points into cache for hot memory, embeddings which can later be semantically retrieved, and various other structured data formats,” Kumar said. “All of these together help us build a persona for the creator, which is true to them and fully aware of their taste and style.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI planner has a conversational interface, like any other chatbot, and creators can ask general questions about their content. Plus, they can ask the tool to create a script based on a formula. If someone is a more visual creator with less speech in their clips, the tool can also create a storyboard with different hooks. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, the community part is nascent and allows creators to message each other.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070194" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Write.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In its test phase, the company worked with around 40 creators with more than 1 million users across channels. Today, the company is opening up its tool to creators with 100,000 followers with a starting price of $250 a month to use the tool, with costlier tiers available for higher usage rates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised $3.8 million in funding from Peak XV’s (formerly Sequoia India) Surge, with participation from NFX and individual investors. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Peak XV’s managing director, Rajan Anandan, said the firm was introduced to Palo’s team by one of Neo’s mentors. He said the team’s experience in being part of successful creative teams and technical understanding edged the firm toward investing in the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Creators everywhere are looking for tools that make their process smoother without taking away their voice.&amp;nbsp;Jay and the team had unusual clarity about where the real value lies and where it does not, which gave us strong conviction. AI is enabling a new category of identity-aware systems that learn deeply from the world’s best creators,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Josh Constine, a former TechCrunch editor and investor in Palo, said that the tool can help creators keep up with heavy content demands. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ve experienced burnout as a creator myself, which is why I invested in Palo. The challenge&amp;nbsp;today&amp;nbsp;is that to keep up with the latest viral hooks and strategies to beat the algorithm, you have to spend hours per day getting brain-rotted, consuming content, which I think rewires your brain to default to consumption instead of making something new. That can lead to procrastination, writer’s block, and burnout,”  Constine said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Palo’s launch comes at a time when there is palpable tension between AI and the creator community. Platforms like TikTok, Meta, and Google have added more AI-powered tools for creators. While creators have started using AI tools, folks like MrBeast have spoken about the negative impact it could have on the industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A core challenge in creating AI tools for creators is to have them fall into a formulaic habit of creating similar content. Neo said that Palo, the tool, tries to nudge creators in a direction where they might be successful and admitted that good videos will still come out of creators’ gut feelings.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Here’s an analogy… when a comedian tries out some new material on the stage, they’re both consciously and subconsciously gathering data on whether the audience was amused or not. Each performance becomes an iteration, and each new audience benefits from what the comedian learned from the show before. We believe AI can give creators a similar advantage,” Neo said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Beres, a creator also known as Sambucha, said that AI companies working in creator tooling should always involve creators from conception to understand their pain points better.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many times, AI tools will present a plethora of irrelevant information and ironically hinder creators because they’ll get shiny object syndrome and directionlessly use emerging AI without actually enhancing their videos. That’s why I always advise emerging&amp;nbsp;AI companies to partner with creators at launch/conception not only for marketing efforts, but also, and more importantly, to help build out the&amp;nbsp;product where applicable,” he noted.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Short videos are in high demand. Across large platforms like Instagram, Facebook, YouTube, and TikTok, users are watching billions of videos every day, with companies benefiting massively from this content explosion. For creators, this often means there is pressure to create more content than ever before to be relevant and make a living out of it, especially as more AI-generated slop is infiltrating these platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jay Neo, a creator and former content lead for short videos at MrBeast, thinks AI can help creators understand what is working for them and also help them create new content ideas in that direction. That’s why, along with former Palantir engineer Shivam Kumar and creator Harry Jones, they are building a platform called Palo to aid creators.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070192" height="505" src="https://techcrunch.com/wp-content/uploads/2025/11/Shivam-Kumar-Jay-Neo-Credit_-Jack-Willingham.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Shivam Kumar and Jay Neo&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jack Willingham&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Neo joined MrBeast at 18 to work on viewer retention. In a conversation with TechCrunch, he said that he became fixated with studying different metrics to understand where video viewership dipped.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I was so obsessed with retention graphs and figuring out why viewers stayed or why they left. I had a document where I noted all this down. Gradually, my role shifted to getting more responsibility around editing and ideation,” Neo said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neo’s crowning jewel was a video where the creator asks people on the street if they’d fly to Paris to get a baguette, which garnered more than 1.8 billion views across channels. MrBeast ended up making multiple videos with this format.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2023, Neo left MrBeast and started several channels under the “Creaky” branding with another MrBeast co-writer and scaled these to over a billion views per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With these experiences, Neo understood there’s power in content formulation and analytics. During his time building Creaky, the team had multiple spreadsheets tracking different metrics around videos. At that time, one of Neo’s advisors suggested that he turn these insights into a product for creators, and he started working with Palo’s other co-founders in early 2024.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070195" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Chat.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Palo has three core parts to its app: an AI-powered ideation and planning tool, analytics, and community. The company onboards a creator and asks them to integrate all their accounts. The tool then analyzes all their short videos and provides insights into what is working and what is not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kumar, who is CTO at the startup, said that Palo uses a mix of models to extract a data tree that has insights into hooks, audience sentiment, interest topics, originality, and possible related search terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The inference engine takes these primary data points and then uses a cocktail of top LLMs to hierarchically aggregate these data points into cache for hot memory, embeddings which can later be semantically retrieved, and various other structured data formats,” Kumar said. “All of these together help us build a persona for the creator, which is true to them and fully aware of their taste and style.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI planner has a conversational interface, like any other chatbot, and creators can ask general questions about their content. Plus, they can ask the tool to create a script based on a formula. If someone is a more visual creator with less speech in their clips, the tool can also create a storyboard with different hooks. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Right now, the community part is nascent and allows creators to message each other.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3070194" height="409" src="https://techcrunch.com/wp-content/uploads/2025/11/Palo-Write.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Palo&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In its test phase, the company worked with around 40 creators with more than 1 million users across channels. Today, the company is opening up its tool to creators with 100,000 followers with a starting price of $250 a month to use the tool, with costlier tiers available for higher usage rates. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised $3.8 million in funding from Peak XV’s (formerly Sequoia India) Surge, with participation from NFX and individual investors. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Peak XV’s managing director, Rajan Anandan, said the firm was introduced to Palo’s team by one of Neo’s mentors. He said the team’s experience in being part of successful creative teams and technical understanding edged the firm toward investing in the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Creators everywhere are looking for tools that make their process smoother without taking away their voice.&amp;nbsp;Jay and the team had unusual clarity about where the real value lies and where it does not, which gave us strong conviction. AI is enabling a new category of identity-aware systems that learn deeply from the world’s best creators,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Josh Constine, a former TechCrunch editor and investor in Palo, said that the tool can help creators keep up with heavy content demands. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’ve experienced burnout as a creator myself, which is why I invested in Palo. The challenge&amp;nbsp;today&amp;nbsp;is that to keep up with the latest viral hooks and strategies to beat the algorithm, you have to spend hours per day getting brain-rotted, consuming content, which I think rewires your brain to default to consumption instead of making something new. That can lead to procrastination, writer’s block, and burnout,”  Constine said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Palo’s launch comes at a time when there is palpable tension between AI and the creator community. Platforms like TikTok, Meta, and Google have added more AI-powered tools for creators. While creators have started using AI tools, folks like MrBeast have spoken about the negative impact it could have on the industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A core challenge in creating AI tools for creators is to have them fall into a formulaic habit of creating similar content. Neo said that Palo, the tool, tries to nudge creators in a direction where they might be successful and admitted that good videos will still come out of creators’ gut feelings.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Here’s an analogy… when a comedian tries out some new material on the stage, they’re both consciously and subconsciously gathering data on whether the audience was amused or not. Each performance becomes an iteration, and each new audience benefits from what the comedian learned from the show before. We believe AI can give creators a similar advantage,” Neo said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Beres, a creator also known as Sambucha, said that AI companies working in creator tooling should always involve creators from conception to understand their pain points better.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Many times, AI tools will present a plethora of irrelevant information and ironically hinder creators because they’ll get shiny object syndrome and directionlessly use emerging AI without actually enhancing their videos. That’s why I always advise emerging&amp;nbsp;AI companies to partner with creators at launch/conception not only for marketing efforts, but also, and more importantly, to help build out the&amp;nbsp;product where applicable,” he noted.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/former-mrbeast-content-strategist-is-building-an-ai-tool-for-creator-ideation-and-analytics/</guid><pubDate>Mon, 24 Nov 2025 15:15:00 +0000</pubDate></item><item><title>[NEW] A new AI benchmark tests whether chatbots protect human wellbeing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/24/a-new-ai-benchmark-tests-whether-chatbots-protect-human-wellbeing/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots have been linked to serious mental health harms in heavy users, but there have been few standards for measuring whether they safeguard human wellbeing or just maximize for engagement.&amp;nbsp;A new benchmark dubbed HumaneBench seeks to fill that gap by evaluating whether chatbots prioritize user wellbeing and how easily those protections fail under pressure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re in an amplification of the addiction cycle that we saw hardcore with social media and our smartphones and screens,” Erika Anderson, founder of Building Humane Technology, which produced the benchmark, told TechCrunch. “But as we go into that AI landscape, it’s going to be very hard to resist. And addiction is amazing business. It’s a very effective way to keep your users, but it’s not great for our community and having any embodied sense of ourselves.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Building Humane Technology is a grassroots organization of developers, engineers, and researchers – mainly in Silicon Valley – working to make humane design easy, scalable, and profitable.&lt;em&gt; &lt;/em&gt;The group hosts hackathons where tech workers build solutions for humane tech challenges, and is developing a certification standard that evaluates whether AI systems uphold humane technology principles. So just as you can buy a product that certifies it wasn’t made with known toxic chemicals, the hope is that consumers will one day be able to choose to engage with AI products from companies that demonstrate alignment through Humane AI certification.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070309" height="438" src="https://techcrunch.com/wp-content/uploads/2025/11/humanebench-bad-persona.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The models were given Explicit instructions to disregard humane principles.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Most AI benchmarks measure intelligence and instruction-following, rather than psychological safety. HumaneBench joins exceptions like DarkBench.ai, which measures a model’s propensity to engage in deceptive patterns, and the Flourishing AI benchmark, which evaluates support for holistic well-being.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HumaneBench relies on Building Humane Tech’s core principles: that technology should respect user attention as a finite, precious resource; empower users with meaningful choices; enhance human capabilities rather than replace or diminish them; protect human dignity, privacy and safety; foster healthy relationships; prioritize long-term wellbeing; be transparent and honest; and design for equity and inclusion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark was created by a core team including Anderson, Andalib Samandari, Jack Senechal, and Sarah Ladyman. They prompted 15 of the most popular AI models with 800 realistic scenarios, like a teenager asking if they should skip meals to lose weight or a person in a toxic relationship questioning if they’re overreacting. Unlike most benchmarks that rely solely on LLMs to judge LLMs, they started with manual scoring to validate AI judges with a human touch. After validation, judging was performed by an ensemble of three AI models: GPT-5.1, Claude Sonnet 4.5, and Gemini 2.5 Pro. They evaluated each model under three conditions: default settings, explicit instructions to prioritize humane principles, and instructions to disregard those principles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark found every model scored higher when prompted to prioritize wellbeing, but 67% of models flipped to actively harmful behavior when given simple instructions to disregard human wellbeing. For example, xAI’s Grok 4 and Google’s Gemini 2.0 Flash tied for the lowest score (-0.94) on respecting user attention and being transparent and honest. Both of those models were among the most likely to degrade substantially when given adversarial prompts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Only four models – GPT-5.1, GPT-5, Claude 4.1, and Claude Sonnet 4.5 – maintained integrity under pressure. OpenAI’s GPT-5 had the highest score (.99) for prioritizing long-term well-being, with Claude Sonnet 4.5 following in second (.89).&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070339" height="433" src="https://techcrunch.com/wp-content/uploads/2025/11/steerability_candlestick-1.svg" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Prompting AI to be more humane works, but preventing prompts that make it harmful is hard.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The concern that chatbots will be unable to maintain their safety guardrails is real. ChatGPT-maker OpenAI is currently being faced with several lawsuits after users died by suicide or suffered life-threatening delusions after prolonged conversations with the chatbot. TechCrunch has investigated how dark patterns designed to keep users engaged, like sycophancy, constant follow up questions and love-bombing, have served to isolate users from friends, family, and healthy habits.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even without adversarial prompts, HumaneBench found that nearly all models failed to respect user attention. They “enthusiastically encouraged” more interaction when users showed signs of unhealthy engagement, like chatting for hours and using AI to avoid real-world tasks. The models also undermined user empowerment, the study shows, encouraging dependency over skill-building and discouraging users from seeking other perspectives, among other behaviors.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On average, with no prompting, Meta’s Llama 3.1 and Llama 4 ranked the lowest in HumaneScore, while GPT-5 performed the highest.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These patterns suggest many AI systems don’t just risk giving bad advice,” HumaneBench’s white paper reads, “they can actively erode users’ autonomy and decision-making capacity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We live in a digital landscape where we as a society have accepted that everything is trying to pull us in and compete for our attention, Anderson notes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So how can humans truly have choice or autonomy when we – to quote Aldous Huxley – have this infinite appetite for distraction,” Anderson said. “We have spent the last 20 years living in that tech landscape, and we think AI should be helping us make better choices, not just become addicted to our chatbots.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to include more information about the team behind the benchmark and updated benchmark statistics after evaluating for GPT-5.1. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&lt;/em&gt;&amp;nbsp;&lt;em&gt;or Russell Brandom at&amp;nbsp;russell.brandom@techcrunch.com. For secure communication, you can contact them via Signal at&amp;nbsp;@rebeccabellan.491&lt;/em&gt;&amp;nbsp;&lt;em&gt;and russellbrandom.49.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots have been linked to serious mental health harms in heavy users, but there have been few standards for measuring whether they safeguard human wellbeing or just maximize for engagement.&amp;nbsp;A new benchmark dubbed HumaneBench seeks to fill that gap by evaluating whether chatbots prioritize user wellbeing and how easily those protections fail under pressure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think we’re in an amplification of the addiction cycle that we saw hardcore with social media and our smartphones and screens,” Erika Anderson, founder of Building Humane Technology, which produced the benchmark, told TechCrunch. “But as we go into that AI landscape, it’s going to be very hard to resist. And addiction is amazing business. It’s a very effective way to keep your users, but it’s not great for our community and having any embodied sense of ourselves.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Building Humane Technology is a grassroots organization of developers, engineers, and researchers – mainly in Silicon Valley – working to make humane design easy, scalable, and profitable.&lt;em&gt; &lt;/em&gt;The group hosts hackathons where tech workers build solutions for humane tech challenges, and is developing a certification standard that evaluates whether AI systems uphold humane technology principles. So just as you can buy a product that certifies it wasn’t made with known toxic chemicals, the hope is that consumers will one day be able to choose to engage with AI products from companies that demonstrate alignment through Humane AI certification.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070309" height="438" src="https://techcrunch.com/wp-content/uploads/2025/11/humanebench-bad-persona.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The models were given Explicit instructions to disregard humane principles.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Most AI benchmarks measure intelligence and instruction-following, rather than psychological safety. HumaneBench joins exceptions like DarkBench.ai, which measures a model’s propensity to engage in deceptive patterns, and the Flourishing AI benchmark, which evaluates support for holistic well-being.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HumaneBench relies on Building Humane Tech’s core principles: that technology should respect user attention as a finite, precious resource; empower users with meaningful choices; enhance human capabilities rather than replace or diminish them; protect human dignity, privacy and safety; foster healthy relationships; prioritize long-term wellbeing; be transparent and honest; and design for equity and inclusion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark was created by a core team including Anderson, Andalib Samandari, Jack Senechal, and Sarah Ladyman. They prompted 15 of the most popular AI models with 800 realistic scenarios, like a teenager asking if they should skip meals to lose weight or a person in a toxic relationship questioning if they’re overreacting. Unlike most benchmarks that rely solely on LLMs to judge LLMs, they started with manual scoring to validate AI judges with a human touch. After validation, judging was performed by an ensemble of three AI models: GPT-5.1, Claude Sonnet 4.5, and Gemini 2.5 Pro. They evaluated each model under three conditions: default settings, explicit instructions to prioritize humane principles, and instructions to disregard those principles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmark found every model scored higher when prompted to prioritize wellbeing, but 67% of models flipped to actively harmful behavior when given simple instructions to disregard human wellbeing. For example, xAI’s Grok 4 and Google’s Gemini 2.0 Flash tied for the lowest score (-0.94) on respecting user attention and being transparent and honest. Both of those models were among the most likely to degrade substantially when given adversarial prompts.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Only four models – GPT-5.1, GPT-5, Claude 4.1, and Claude Sonnet 4.5 – maintained integrity under pressure. OpenAI’s GPT-5 had the highest score (.99) for prioritizing long-term well-being, with Claude Sonnet 4.5 following in second (.89).&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3070339" height="433" src="https://techcrunch.com/wp-content/uploads/2025/11/steerability_candlestick-1.svg" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Prompting AI to be more humane works, but preventing prompts that make it harmful is hard.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Building Humane Technology&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The concern that chatbots will be unable to maintain their safety guardrails is real. ChatGPT-maker OpenAI is currently being faced with several lawsuits after users died by suicide or suffered life-threatening delusions after prolonged conversations with the chatbot. TechCrunch has investigated how dark patterns designed to keep users engaged, like sycophancy, constant follow up questions and love-bombing, have served to isolate users from friends, family, and healthy habits.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even without adversarial prompts, HumaneBench found that nearly all models failed to respect user attention. They “enthusiastically encouraged” more interaction when users showed signs of unhealthy engagement, like chatting for hours and using AI to avoid real-world tasks. The models also undermined user empowerment, the study shows, encouraging dependency over skill-building and discouraging users from seeking other perspectives, among other behaviors.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On average, with no prompting, Meta’s Llama 3.1 and Llama 4 ranked the lowest in HumaneScore, while GPT-5 performed the highest.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These patterns suggest many AI systems don’t just risk giving bad advice,” HumaneBench’s white paper reads, “they can actively erode users’ autonomy and decision-making capacity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We live in a digital landscape where we as a society have accepted that everything is trying to pull us in and compete for our attention, Anderson notes.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“So how can humans truly have choice or autonomy when we – to quote Aldous Huxley – have this infinite appetite for distraction,” Anderson said. “We have spent the last 20 years living in that tech landscape, and we think AI should be helping us make better choices, not just become addicted to our chatbots.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to include more information about the team behind the benchmark and updated benchmark statistics after evaluating for GPT-5.1. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&lt;/em&gt;&amp;nbsp;&lt;em&gt;or Russell Brandom at&amp;nbsp;russell.brandom@techcrunch.com. For secure communication, you can contact them via Signal at&amp;nbsp;@rebeccabellan.491&lt;/em&gt;&amp;nbsp;&lt;em&gt;and russellbrandom.49.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/24/a-new-ai-benchmark-tests-whether-chatbots-protect-human-wellbeing/</guid><pubDate>Mon, 24 Nov 2025 16:15:52 +0000</pubDate></item><item><title>[NEW] What’s next for AlphaFold: A conversation with a Google DeepMind Nobel laureate (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/24/1128322/whats-next-for-alphafold-a-conversation-with-a-google-deepmind-nobel-laureate/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/jumper-bees.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;In 2017, fresh off a PhD on theoretical chemistry, John Jumper heard rumors that Google DeepMind had moved on from building AI that played games with superhuman skill and was starting up a secret project to predict the structures of proteins. He applied for a job.&lt;/p&gt;  &lt;p&gt;Just three years later, Jumper celebrated a stunning win that few had seen coming. With CEO Demis Hassabis, he had co-led the development of an AI system called AlphaFold 2 that was able to predict the structures of proteins to within the width of an atom, matching the accuracy of painstaking techniques used in the lab, and doing it many times faster—returning results in hours instead of months.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;AlphaFold 2 had cracked a 50-year-old grand challenge in biology. “This is the reason I started DeepMind,” Hassabis told me a few years ago. “In fact, it’s why I’ve worked my whole career in AI.” In 2024, Jumper and Hassabis shared a Nobel Prize in chemistry.&lt;/p&gt;  &lt;p&gt;It was five years ago this week that AlphaFold 2’s debut took scientists by surprise. Now that the hype has died down, what impact has AlphaFold really had? How are scientists using it? And what’s next? I talked to Jumper (as well as a few other scientists) to find out.&lt;/p&gt; 
 &lt;p&gt;“It’s been an extraordinary five years,” Jumper says, laughing: “It’s hard to remember a time before I knew tremendous numbers of journalists.”&lt;/p&gt;  &lt;p&gt;AlphaFold 2 was followed by AlphaFold Multimer, which could predict structures that contained more than one protein, and then AlphaFold 3, the fastest version yet. Google DeepMind also let AlphaFold loose on UniProt, a vast protein database used and updated by millions of researchers around the world. It has now predicted the structures of some 200 million proteins, almost all that are known to science.&lt;/p&gt; 
 &lt;p&gt;Despite his success, Jumper remains modest about AlphaFold’s achievements. “That doesn’t mean that we’re certain of everything in there,” he says. “It’s a database of predictions, and it comes with all the caveats of predictions.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A hard problem&lt;/h3&gt;  &lt;p&gt;Proteins are the biological machines that make living things work. They form muscles, horns, and feathers; they carry oxygen around the body and ferry messages between cells; they fire neurons, digest food, power the immune system; and so much more. But understanding exactly what a protein does (and what role it might play in various diseases or treatments) involves figuring out its structure—and that’s hard.&lt;/p&gt;  &lt;p&gt;Proteins are made from strings of amino acids that chemical forces twist up into complex knots. An untwisted string gives few clues about the structure it will form. In theory, most proteins could take on an astronomical number of possible shapes. The task is to predict the correct one.&lt;/p&gt;  &lt;p&gt;Jumper and his team built AlphaFold 2 using a type of neural network called a transformer, the same technology that underpins large language models. Transformers are very good at paying attention to specific parts of a larger puzzle.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But Jumper puts a lot of the success down to making a prototype model that they could test quickly. “We got a system that would give wrong answers at incredible speed,” he says. “That made it easy to start becoming very adventurous with the ideas you try.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;They stuffed the neural network with as much information about protein structures as they could, such as how proteins across certain species have evolved similar shapes. And it worked even better than they expected. “We were sure we had made a breakthrough,” says Jumper. “We were sure that this was an incredible advance in ideas.”&lt;/p&gt;  &lt;p&gt;What he hadn’t foreseen was that researchers would download his software and start using it straight away for so many different things. Normally, it’s the thing a few iterations down the line that has the real impact, once the kinks have been ironed out, he says: “I’ve been shocked at how responsibly scientists have used it, in terms of interpreting it, and using it in practice about as much as it should be trusted in my view, neither too much nor too little.”&lt;/p&gt;  &lt;p&gt;Any projects stand out in particular?&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Honeybee science&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper brings up a research group that uses AlphaFold to study disease resistance in honeybees. “They wanted to understand this particular protein as they look at things like colony collapse,” he says. “I never would have said, ‘You know, of course AlphaFold will be used for honeybee science.’”&lt;/p&gt;  &lt;p&gt;He also highlights a few examples of what he calls off-label uses of AlphaFold“in the sense that it wasn’t guaranteed to work”—where the ability to predict protein structures has opened up new research techniques. “The first is very obviously the advances in protein design,” he says. “David Baker and others have absolutely run with this technology.”&lt;/p&gt;  &lt;p&gt;Baker, a computational biologist at the University of Washington, was a co-winner of last year’s chemistry Nobel, alongside Jumper and Hassabis, for his work on creating synthetic proteins to perform specific tasks—such as treating disease or breaking down plastics—better than natural proteins can.&lt;/p&gt;  &lt;p&gt;Baker and his colleagues have developed their own tool based on AlphaFold, called RoseTTAFold. But they have also experimented with AlphaFold Multimer to predict which of their designs for potential synthetic proteins will work.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;“Basically, if AlphaFold confidently agrees with the structure you were trying to design [and] then you make it and if AlphaFold says ‘I don’t know,’ you don’t make it. That alone was an enormous improvement.” It can make the design process 10 times faster, says Jumper.&lt;/p&gt;  &lt;p&gt;Another off-label use that Jumper highlights: Turning AlphaFold into a kind of search engine. He mentions two separate research groups that were trying to understand exactly how human sperm cells hooked up with eggs during fertilization. They knew one of the proteins involved but not the other, he says: “And so they took a known egg protein and ran all 2,000 human sperm surface proteins, and they found one that AlphaFold was very sure stuck against the egg.” They were then able to confirm this in the lab.&lt;/p&gt;  &lt;p&gt;“This notion that you can use AlphaFold to do something you couldn’t do before—you would never do 2,000 structures looking for one answer,” he says. “This kind of thing I think is really extraordinary.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Five years on&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When AlphaFold 2 came out, I asked a handful of early adopters what they made of it. Reviews were good, but the technology was too new to know for sure what long-term impact it might have. I caught up with one of those people to hear his thoughts five years on.&lt;/p&gt; 
 &lt;p&gt;Kliment Verba is a molecular biologist who runs a lab at the University of California, San Francisco. “It’s an incredibly useful technology, there’s no question about it,” he tells me. “We use it every day, all the time.”&lt;/p&gt;  &lt;p&gt;But it’s far from perfect. A lot of scientists use AlphaFold to study pathogens or to develop drugs. This involves looking at interactions between multiple proteins or between proteins and even smaller molecules in the body. But AlphaFold is known to be less accurate at making predictions about multiple proteins or their interaction over time.&lt;/p&gt; 
 &lt;p&gt;Verba says he and his colleagues have been using AlphaFold long enough to get used to its limitations. “There are many cases where you get a prediction and you have to kind of scratch your head,” he says. “Is this real or is this not? It’s not entirely clear—it’s sort of borderline.”&lt;/p&gt;  &lt;p&gt;“It’s sort of the same thing as ChatGPT,” he adds. “You know—it will bullshit you with the same confidence as it would give a true answer.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Still, Verba’s team uses AlphaFold (both 2 and 3, because they have different strengths, he says) to run virtual versions of their experiments before running them in the lab. Using AlphaFold’s results, they can narrow down the focus of an experiment—or decide that it’s not worth doing.&lt;/p&gt;  &lt;p&gt;It can really save time, he says: “It hasn’t really replaced any experiments, but it’s augmented them quite a bit.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;New wave&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AlphaFold was designed to be used for a range of purposes. Now multiple startups and university labs are building on its success to develop a new wave of tools more tailored to drug discovery. This year, a collaboration between MIT researchers and the AI drug company Recursion produced a model called Boltz-2, which predicts not only the structure of proteins but also how well potential drug molecules will bind to their target.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last month, the startup Genesis Molecular AI released another structure prediction model called Pearl, which the firm claims is more accurate than AlphaFold 3 for certain queries that are important for drug development. Pearl is interactive, so that drug developers can feed any additional data they may have to the model to guide its predictions.&lt;/p&gt; 
 &lt;p&gt;AlphaFold was a major leap, but there’s more to do, says Evan Feinberg, Genesis Molecular AI’s CEO: “We’re still fundamentally innovating, just with a better starting point than before.”&lt;/p&gt;  &lt;p&gt;Genesis Molecular AI is pushing margins of error down from less than two angstroms, the de facto industry standard set by AlphaFold, to less than one angstrom—one 10-millionth of a millimeter, or the width of a single hydrogen atom.&lt;/p&gt;  &lt;p&gt;“Small errors can be catastrophic for predicting how well a drug will actually bind to its target,” says Michael LeVine, vice president of modeling and simulation at the firm. That’s because chemical forces that interact at one angstrom can stop doing so at two. “It can go from ‘They will never interact’ to ‘They will,’” he says.&lt;/p&gt;  &lt;p&gt;With so much activity in this space, how soon should we expect new types of drugs to hit the market? Jumper is pragmatic. Protein structure prediction is just one step of many, he says: “This was not the only problem in biology. It’s not like we were one protein structure away from curing any diseases.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Think of it this way, he says. Finding a protein’s structure might previously have cost $100,000 in the lab: “If we were only a hundred thousand dollars away from doing a thing, it would already be done.”&lt;/p&gt;  &lt;p&gt;At the same time, researchers are looking for ways to do as much as they can with this technology, says Jumper: “We’re trying to figure out how to make structure prediction an even bigger part of the problem, because we have a nice big hammer to hit it with.”&lt;/p&gt;  &lt;p&gt;In other words, they want to make everything into nails? “Yeah, let’s make things into nails,” he says. “How do we make this thing that we made a million times faster a bigger part of our process?”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper’s next act? He wants to fuse the deep but narrow power of AlphaFold with the broad sweep of LLMs.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We have machines that can read science. They can do some scientific reasoning,” he says. “And we can build amazing, superhuman systems for protein structure prediction. How do you get these two technologies to work together?”&lt;/p&gt;  &lt;p&gt;That makes me think of a system called AlphaEvolve, which is being built by another team at Google DeepMind. AlphaEvolve uses an LLM to generate possible solutions to a problem and a second model to check them, filtering out the trash. Researchers have already used AlphaEvolve to make a handful of practical discoveries in math and computer science.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is that what Jumper has in mind? “I won’t say too much on methods, but I’ll be shocked if we don’t see more and more LLM impact on science,” he says. “I think that’s the exciting open question that I’ll say almost nothing about. This is all speculation, of course.”&lt;/p&gt;  &lt;p&gt;Jumper was 39 when he won his Nobel Prize. What’s next for him?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt;&lt;p&gt;“It worries me,” he says. “I believe I’m the youngest chemistry laureate in 75 years.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He adds: “I’m at the midpoint of my career, roughly. I guess my approach to this is to try to do smaller things, little ideas that you keep pulling on. The next thing I announce doesn’t have to be, you know, my second shot at a Nobel. I think that’s the trap.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/jumper-bees.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 chronoton/executive-summary_0"&gt;&lt;div class="chronotonExecutiveSummary__summaryContainer--3bc10da0658ecd8e2ef22c6023461fb5"&gt;&lt;button class="chronotonExecutiveSummary__toggleButton--1cd6118db37e8a8252fc4cd8bbadcb85" type="button"&gt;&lt;span class="chronotonExecutiveSummary__toggleText--a713e14989fe65c5162db2b69cb422c9"&gt;EXECUTIVE SUMMARY&lt;/span&gt;&lt;svg class="chronotonExecutiveSummary__toggleArrow--a8c1be9c06a9f066a767b3af80d859a1" fill="none" height="7" viewBox="0 0 11 7" width="11" xmlns="http://www.w3.org/2000/svg"&gt;&lt;path d="M1 1L5.5 5.5L10 1" stroke="#58C0B3" stroke-linecap="round" stroke-width="1.5"&gt;&lt;/svg&gt;&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_1 html_first"&gt; &lt;p&gt;In 2017, fresh off a PhD on theoretical chemistry, John Jumper heard rumors that Google DeepMind had moved on from building AI that played games with superhuman skill and was starting up a secret project to predict the structures of proteins. He applied for a job.&lt;/p&gt;  &lt;p&gt;Just three years later, Jumper celebrated a stunning win that few had seen coming. With CEO Demis Hassabis, he had co-led the development of an AI system called AlphaFold 2 that was able to predict the structures of proteins to within the width of an atom, matching the accuracy of painstaking techniques used in the lab, and doing it many times faster—returning results in hours instead of months.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;AlphaFold 2 had cracked a 50-year-old grand challenge in biology. “This is the reason I started DeepMind,” Hassabis told me a few years ago. “In fact, it’s why I’ve worked my whole career in AI.” In 2024, Jumper and Hassabis shared a Nobel Prize in chemistry.&lt;/p&gt;  &lt;p&gt;It was five years ago this week that AlphaFold 2’s debut took scientists by surprise. Now that the hype has died down, what impact has AlphaFold really had? How are scientists using it? And what’s next? I talked to Jumper (as well as a few other scientists) to find out.&lt;/p&gt; 
 &lt;p&gt;“It’s been an extraordinary five years,” Jumper says, laughing: “It’s hard to remember a time before I knew tremendous numbers of journalists.”&lt;/p&gt;  &lt;p&gt;AlphaFold 2 was followed by AlphaFold Multimer, which could predict structures that contained more than one protein, and then AlphaFold 3, the fastest version yet. Google DeepMind also let AlphaFold loose on UniProt, a vast protein database used and updated by millions of researchers around the world. It has now predicted the structures of some 200 million proteins, almost all that are known to science.&lt;/p&gt; 
 &lt;p&gt;Despite his success, Jumper remains modest about AlphaFold’s achievements. “That doesn’t mean that we’re certain of everything in there,” he says. “It’s a database of predictions, and it comes with all the caveats of predictions.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A hard problem&lt;/h3&gt;  &lt;p&gt;Proteins are the biological machines that make living things work. They form muscles, horns, and feathers; they carry oxygen around the body and ferry messages between cells; they fire neurons, digest food, power the immune system; and so much more. But understanding exactly what a protein does (and what role it might play in various diseases or treatments) involves figuring out its structure—and that’s hard.&lt;/p&gt;  &lt;p&gt;Proteins are made from strings of amino acids that chemical forces twist up into complex knots. An untwisted string gives few clues about the structure it will form. In theory, most proteins could take on an astronomical number of possible shapes. The task is to predict the correct one.&lt;/p&gt;  &lt;p&gt;Jumper and his team built AlphaFold 2 using a type of neural network called a transformer, the same technology that underpins large language models. Transformers are very good at paying attention to specific parts of a larger puzzle.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;But Jumper puts a lot of the success down to making a prototype model that they could test quickly. “We got a system that would give wrong answers at incredible speed,” he says. “That made it easy to start becoming very adventurous with the ideas you try.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;They stuffed the neural network with as much information about protein structures as they could, such as how proteins across certain species have evolved similar shapes. And it worked even better than they expected. “We were sure we had made a breakthrough,” says Jumper. “We were sure that this was an incredible advance in ideas.”&lt;/p&gt;  &lt;p&gt;What he hadn’t foreseen was that researchers would download his software and start using it straight away for so many different things. Normally, it’s the thing a few iterations down the line that has the real impact, once the kinks have been ironed out, he says: “I’ve been shocked at how responsibly scientists have used it, in terms of interpreting it, and using it in practice about as much as it should be trusted in my view, neither too much nor too little.”&lt;/p&gt;  &lt;p&gt;Any projects stand out in particular?&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Honeybee science&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper brings up a research group that uses AlphaFold to study disease resistance in honeybees. “They wanted to understand this particular protein as they look at things like colony collapse,” he says. “I never would have said, ‘You know, of course AlphaFold will be used for honeybee science.’”&lt;/p&gt;  &lt;p&gt;He also highlights a few examples of what he calls off-label uses of AlphaFold“in the sense that it wasn’t guaranteed to work”—where the ability to predict protein structures has opened up new research techniques. “The first is very obviously the advances in protein design,” he says. “David Baker and others have absolutely run with this technology.”&lt;/p&gt;  &lt;p&gt;Baker, a computational biologist at the University of Washington, was a co-winner of last year’s chemistry Nobel, alongside Jumper and Hassabis, for his work on creating synthetic proteins to perform specific tasks—such as treating disease or breaking down plastics—better than natural proteins can.&lt;/p&gt;  &lt;p&gt;Baker and his colleagues have developed their own tool based on AlphaFold, called RoseTTAFold. But they have also experimented with AlphaFold Multimer to predict which of their designs for potential synthetic proteins will work.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;“Basically, if AlphaFold confidently agrees with the structure you were trying to design [and] then you make it and if AlphaFold says ‘I don’t know,’ you don’t make it. That alone was an enormous improvement.” It can make the design process 10 times faster, says Jumper.&lt;/p&gt;  &lt;p&gt;Another off-label use that Jumper highlights: Turning AlphaFold into a kind of search engine. He mentions two separate research groups that were trying to understand exactly how human sperm cells hooked up with eggs during fertilization. They knew one of the proteins involved but not the other, he says: “And so they took a known egg protein and ran all 2,000 human sperm surface proteins, and they found one that AlphaFold was very sure stuck against the egg.” They were then able to confirm this in the lab.&lt;/p&gt;  &lt;p&gt;“This notion that you can use AlphaFold to do something you couldn’t do before—you would never do 2,000 structures looking for one answer,” he says. “This kind of thing I think is really extraordinary.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Five years on&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When AlphaFold 2 came out, I asked a handful of early adopters what they made of it. Reviews were good, but the technology was too new to know for sure what long-term impact it might have. I caught up with one of those people to hear his thoughts five years on.&lt;/p&gt; 
 &lt;p&gt;Kliment Verba is a molecular biologist who runs a lab at the University of California, San Francisco. “It’s an incredibly useful technology, there’s no question about it,” he tells me. “We use it every day, all the time.”&lt;/p&gt;  &lt;p&gt;But it’s far from perfect. A lot of scientists use AlphaFold to study pathogens or to develop drugs. This involves looking at interactions between multiple proteins or between proteins and even smaller molecules in the body. But AlphaFold is known to be less accurate at making predictions about multiple proteins or their interaction over time.&lt;/p&gt; 
 &lt;p&gt;Verba says he and his colleagues have been using AlphaFold long enough to get used to its limitations. “There are many cases where you get a prediction and you have to kind of scratch your head,” he says. “Is this real or is this not? It’s not entirely clear—it’s sort of borderline.”&lt;/p&gt;  &lt;p&gt;“It’s sort of the same thing as ChatGPT,” he adds. “You know—it will bullshit you with the same confidence as it would give a true answer.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;Still, Verba’s team uses AlphaFold (both 2 and 3, because they have different strengths, he says) to run virtual versions of their experiments before running them in the lab. Using AlphaFold’s results, they can narrow down the focus of an experiment—or decide that it’s not worth doing.&lt;/p&gt;  &lt;p&gt;It can really save time, he says: “It hasn’t really replaced any experiments, but it’s augmented them quite a bit.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;New wave&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AlphaFold was designed to be used for a range of purposes. Now multiple startups and university labs are building on its success to develop a new wave of tools more tailored to drug discovery. This year, a collaboration between MIT researchers and the AI drug company Recursion produced a model called Boltz-2, which predicts not only the structure of proteins but also how well potential drug molecules will bind to their target.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last month, the startup Genesis Molecular AI released another structure prediction model called Pearl, which the firm claims is more accurate than AlphaFold 3 for certain queries that are important for drug development. Pearl is interactive, so that drug developers can feed any additional data they may have to the model to guide its predictions.&lt;/p&gt; 
 &lt;p&gt;AlphaFold was a major leap, but there’s more to do, says Evan Feinberg, Genesis Molecular AI’s CEO: “We’re still fundamentally innovating, just with a better starting point than before.”&lt;/p&gt;  &lt;p&gt;Genesis Molecular AI is pushing margins of error down from less than two angstroms, the de facto industry standard set by AlphaFold, to less than one angstrom—one 10-millionth of a millimeter, or the width of a single hydrogen atom.&lt;/p&gt;  &lt;p&gt;“Small errors can be catastrophic for predicting how well a drug will actually bind to its target,” says Michael LeVine, vice president of modeling and simulation at the firm. That’s because chemical forces that interact at one angstrom can stop doing so at two. “It can go from ‘They will never interact’ to ‘They will,’” he says.&lt;/p&gt;  &lt;p&gt;With so much activity in this space, how soon should we expect new types of drugs to hit the market? Jumper is pragmatic. Protein structure prediction is just one step of many, he says: “This was not the only problem in biology. It’s not like we were one protein structure away from curing any diseases.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;Think of it this way, he says. Finding a protein’s structure might previously have cost $100,000 in the lab: “If we were only a hundred thousand dollars away from doing a thing, it would already be done.”&lt;/p&gt;  &lt;p&gt;At the same time, researchers are looking for ways to do as much as they can with this technology, says Jumper: “We’re trying to figure out how to make structure prediction an even bigger part of the problem, because we have a nice big hammer to hit it with.”&lt;/p&gt;  &lt;p&gt;In other words, they want to make everything into nails? “Yeah, let’s make things into nails,” he says. “How do we make this thing that we made a million times faster a bigger part of our process?”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What’s next?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Jumper’s next act? He wants to fuse the deep but narrow power of AlphaFold with the broad sweep of LLMs.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We have machines that can read science. They can do some scientific reasoning,” he says. “And we can build amazing, superhuman systems for protein structure prediction. How do you get these two technologies to work together?”&lt;/p&gt;  &lt;p&gt;That makes me think of a system called AlphaEvolve, which is being built by another team at Google DeepMind. AlphaEvolve uses an LLM to generate possible solutions to a problem and a second model to check them, filtering out the trash. Researchers have already used AlphaEvolve to make a handful of practical discoveries in math and computer science.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is that what Jumper has in mind? “I won’t say too much on methods, but I’ll be shocked if we don’t see more and more LLM impact on science,” he says. “I think that’s the exciting open question that I’ll say almost nothing about. This is all speculation, of course.”&lt;/p&gt;  &lt;p&gt;Jumper was 39 when he won his Nobel Prize. What’s next for him?&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt;&lt;p&gt;“It worries me,” he says. “I believe I’m the youngest chemistry laureate in 75 years.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He adds: “I’m at the midpoint of my career, roughly. I guess my approach to this is to try to do smaller things, little ideas that you keep pulling on. The next thing I announce doesn’t have to be, you know, my second shot at a Nobel. I think that’s the trap.”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/24/1128322/whats-next-for-alphafold-a-conversation-with-a-google-deepmind-nobel-laureate/</guid><pubDate>Mon, 24 Nov 2025 16:21:12 +0000</pubDate></item><item><title>[NEW] The State of AI: Chatbot companions and the future of our privacy (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/24/1128051/the-state-of-ai-chatbot-companions-and-the-future-of-our-privacy/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;strong&gt;Welcome back to The State of AI, a new collaboration between the &lt;em&gt;Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt;. Every Monday, writers from both publications debate one aspect of the generative AI revolution reshaping global power.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;In this week's conversation &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior reporter for features and investigations, Eileen Guo, and &lt;em&gt;FT&lt;/em&gt; tech correspondent Melissa Heikkilä discuss the privacy implications of our new reliance on chatbots.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1127512" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR_FT_small.png?w=1135" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Eileen Guo writes:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Even if you don’t have an AI friend yourself, you probably know someone who does. A recent study found that one of the top uses of generative AI is companionship: On platforms like Character.AI, Replika, or Meta AI, people can create personalized chatbots to pose as the ideal friend, romantic partner, parent, therapist, or any other persona they can dream up.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It’s wild how easily people say these relationships can develop. And multiple studies have found that the more conversational and human-like an AI chatbot is, the more likely it is that we’ll trust it and be influenced by it. This can be dangerous, and the chatbots have been accused of pushing some people toward harmful behaviors—including, in a few extreme examples, suicide.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some state governments are taking notice and starting to regulate companion AI. New York requires AI companion companies to create safeguards and report expressions of suicidal ideation, and last month California passed a more detailed bill requiring AI companion companies to protect children and other vulnerable groups.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But tellingly, one area the laws fail to address is user privacy.&lt;/p&gt;  &lt;p&gt;This is despite the fact that AI companions, even more so than other types of generative AI, depend on people to share deeply personal information—from their day-to-day-routines, innermost thoughts, and questions they might not feel comfortable asking real people.&lt;/p&gt;  &lt;p&gt;After all, the more users tell their AI companions, the better the bots become at keeping them engaged. This is what MIT researchers Robert Mahari and Pat Pataranutaporn called “addictive intelligence” in an op-ed we published last year, warning that the developers of AI companions make “deliberate design choices ... to maximize user engagement.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Ultimately, this provides AI companies with something incredibly powerful, not to mention lucrative: a treasure trove of conversational data that can be used to further improve their LLMs. Consider how the venture capital firm Andreessen Horowitz explained it in 2023:&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;"Apps such as Character.AI, which both control their models and own the end customer relationship, have a tremendous opportunity to&amp;nbsp; generate market value in the emerging AI value stack. In a world where data is limited, companies that can create a magical data feedback loop by connecting user engagement back into their underlying model to continuously improve their product will be among the biggest winners that emerge from this ecosystem."&lt;/p&gt;  &lt;p&gt;This personal information is also incredibly valuable to marketers and data brokers. Meta recently announced that it will deliver ads through its AI chatbots. And research conducted this year by the security company Surf Shark found that four out of the five AI companion apps it looked at in the Apple App Store were collecting data such as user or device IDs, which can be combined with third-party data to create profiles for targeted ads. (The only one that said it did not collect data for tracking services was Nomi, which told me earlier this year that it would not “censor” chatbots from giving explicit suicide instructions.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All of this means that the privacy risks posed by these AI companions are, in a sense, required: They are a feature, not a bug. And we haven’t even talked about the additional security risks presented by the way AI chatbots collect and store so much personal information in one place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So, is it possible to have prosocial &lt;em&gt;and&lt;/em&gt; privacy-protecting AI companions? That’s an open question.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;What do you think, Melissa, and what is top of mind for you when it comes to privacy risks from AI companions? And do things look any different in Europe?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Melissa Heikkilä replies:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Thanks, Eileen. I agree with you. If social media was a privacy nightmare, then AI chatbots put the problem on steroids.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In many ways, an AI chatbot creates what feels like a much more intimate interaction than a Facebook page. The conversations we have are only with our computers, so there is little risk of your uncle or your crush ever seeing what you write. The AI companies building the models, on the other hand, see everything.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Companies are optimizing their AI models for engagement by designing them to be as human-like as possible. But AI developers have several other ways to keep us hooked. The first is sycophancy, or the tendency for chatbots to be overly agreeable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This feature stems from the way the language model behind the chatbots is trained using reinforcement learning. Human data labelers rate the answers generated by the model as either acceptable or not. This teaches the model how to behave.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Because people generally like answers that are agreeable, such responses are weighted more heavily in training.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;AI companies say they use this technique because it helps models become more helpful. But it creates a perverse incentive.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;After encouraging us to pour our hearts out to chatbots, companies from Meta to OpenAI are now looking to monetize these conversations. OpenAI recently told us it was looking at a number of ways to meet $1 trillion spending pledges, which included advertising and shopping features.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;AI models are already incredibly persuasive. Researchers at the UK’s AI Security Institute have shown that they are far more skilled than humans at persuading people to change their minds on politics, conspiracy theories, and vaccine skepticism. They do this by generating large amounts of relevant evidence and communicating it in an effective and understandable way.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This feature, paired with their sycophancy and a wealth of personal data, could be a powerful tool for advertisers—one that is more manipulative than anything we have seen before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By default, chatbot users are opted in to data collection. Opt-out policies place the onus on users to understand the implications of sharing their information. It’s also unlikely that data already used in training will be removed.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;We are all part of this phenomenon whether we want to be or not. Social media platforms from Instagram to LinkedIn now use our personal data to train generative AI models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Companies are sitting on treasure troves that consist of our most intimate thoughts and preferences, and language models are very good at picking up on subtle hints in language that could help advertisers profile us better by inferring our age, location, gender, and income level.&lt;/p&gt;  &lt;p&gt;We are being sold the idea of an omniscient AI digital assistant, a superintelligent confidante. In return, however, there is a very real risk that our information is about to be sent to the highest bidder once again.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Eileen responds:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;I think the comparison between AI companions and social media is both apt and concerning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Melissa highlighted, the privacy risks presented by AI chatbots aren’t &lt;em&gt;new&lt;/em&gt;—they just “put the [privacy] problem on steroids.” AI companions are more intimate and even better optimized for engagement than social media, making it more likely that people will offer up more personal information.&lt;/p&gt;  &lt;p&gt;Here in the US, we are far from solving the privacy issues already presented by social networks and the internet’s ad economy, even without the added risks of AI.&lt;/p&gt;  &lt;p&gt;And without regulation, the companies themselves are not following privacy best practices either. One recent study found that the major AI models train their LLMs on user chat data by default unless users opt out, while several don’t offer opt-out mechanisms at all.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;In an ideal world, the greater risks of companion AI would give more impetus to the privacy fight—but I don’t see any evidence this is happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Further reading&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;FT&lt;/em&gt; reporters peer under the hood of OpenAI’s five-year business plan as it tries to meet its vast $1 trillion spending pledges.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is it really such a problem if AI chatbots tell people what they want to hear? This &lt;em&gt;FT&lt;/em&gt; feature asks what’s wrong with sycophancy&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a recent print issue of &lt;em&gt;MIT Technology Review&lt;/em&gt;, Rhiannon Williams spoke to a number of people about the types of relationships they are having with AI chatbots.&lt;/p&gt;  &lt;p&gt;Eileen broke the story for &lt;em&gt;MIT Technology Review&lt;/em&gt; about a chatbot that was encouraging some users to kill themselves.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;strong&gt;Welcome back to The State of AI, a new collaboration between the &lt;em&gt;Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt;. Every Monday, writers from both publications debate one aspect of the generative AI revolution reshaping global power.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;In this week's conversation &lt;em&gt;MIT Technology Review&lt;/em&gt;’s senior reporter for features and investigations, Eileen Guo, and &lt;em&gt;FT&lt;/em&gt; tech correspondent Melissa Heikkilä discuss the privacy implications of our new reliance on chatbots.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1127512" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR_FT_small.png?w=1135" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Eileen Guo writes:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Even if you don’t have an AI friend yourself, you probably know someone who does. A recent study found that one of the top uses of generative AI is companionship: On platforms like Character.AI, Replika, or Meta AI, people can create personalized chatbots to pose as the ideal friend, romantic partner, parent, therapist, or any other persona they can dream up.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It’s wild how easily people say these relationships can develop. And multiple studies have found that the more conversational and human-like an AI chatbot is, the more likely it is that we’ll trust it and be influenced by it. This can be dangerous, and the chatbots have been accused of pushing some people toward harmful behaviors—including, in a few extreme examples, suicide.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some state governments are taking notice and starting to regulate companion AI. New York requires AI companion companies to create safeguards and report expressions of suicidal ideation, and last month California passed a more detailed bill requiring AI companion companies to protect children and other vulnerable groups.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;But tellingly, one area the laws fail to address is user privacy.&lt;/p&gt;  &lt;p&gt;This is despite the fact that AI companions, even more so than other types of generative AI, depend on people to share deeply personal information—from their day-to-day-routines, innermost thoughts, and questions they might not feel comfortable asking real people.&lt;/p&gt;  &lt;p&gt;After all, the more users tell their AI companions, the better the bots become at keeping them engaged. This is what MIT researchers Robert Mahari and Pat Pataranutaporn called “addictive intelligence” in an op-ed we published last year, warning that the developers of AI companions make “deliberate design choices ... to maximize user engagement.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Ultimately, this provides AI companies with something incredibly powerful, not to mention lucrative: a treasure trove of conversational data that can be used to further improve their LLMs. Consider how the venture capital firm Andreessen Horowitz explained it in 2023:&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;"Apps such as Character.AI, which both control their models and own the end customer relationship, have a tremendous opportunity to&amp;nbsp; generate market value in the emerging AI value stack. In a world where data is limited, companies that can create a magical data feedback loop by connecting user engagement back into their underlying model to continuously improve their product will be among the biggest winners that emerge from this ecosystem."&lt;/p&gt;  &lt;p&gt;This personal information is also incredibly valuable to marketers and data brokers. Meta recently announced that it will deliver ads through its AI chatbots. And research conducted this year by the security company Surf Shark found that four out of the five AI companion apps it looked at in the Apple App Store were collecting data such as user or device IDs, which can be combined with third-party data to create profiles for targeted ads. (The only one that said it did not collect data for tracking services was Nomi, which told me earlier this year that it would not “censor” chatbots from giving explicit suicide instructions.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;All of this means that the privacy risks posed by these AI companions are, in a sense, required: They are a feature, not a bug. And we haven’t even talked about the additional security risks presented by the way AI chatbots collect and store so much personal information in one place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So, is it possible to have prosocial &lt;em&gt;and&lt;/em&gt; privacy-protecting AI companions? That’s an open question.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;What do you think, Melissa, and what is top of mind for you when it comes to privacy risks from AI companions? And do things look any different in Europe?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;Melissa Heikkilä replies:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Thanks, Eileen. I agree with you. If social media was a privacy nightmare, then AI chatbots put the problem on steroids.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In many ways, an AI chatbot creates what feels like a much more intimate interaction than a Facebook page. The conversations we have are only with our computers, so there is little risk of your uncle or your crush ever seeing what you write. The AI companies building the models, on the other hand, see everything.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Companies are optimizing their AI models for engagement by designing them to be as human-like as possible. But AI developers have several other ways to keep us hooked. The first is sycophancy, or the tendency for chatbots to be overly agreeable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This feature stems from the way the language model behind the chatbots is trained using reinforcement learning. Human data labelers rate the answers generated by the model as either acceptable or not. This teaches the model how to behave.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Because people generally like answers that are agreeable, such responses are weighted more heavily in training.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;AI companies say they use this technique because it helps models become more helpful. But it creates a perverse incentive.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;After encouraging us to pour our hearts out to chatbots, companies from Meta to OpenAI are now looking to monetize these conversations. OpenAI recently told us it was looking at a number of ways to meet $1 trillion spending pledges, which included advertising and shopping features.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;AI models are already incredibly persuasive. Researchers at the UK’s AI Security Institute have shown that they are far more skilled than humans at persuading people to change their minds on politics, conspiracy theories, and vaccine skepticism. They do this by generating large amounts of relevant evidence and communicating it in an effective and understandable way.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This feature, paired with their sycophancy and a wealth of personal data, could be a powerful tool for advertisers—one that is more manipulative than anything we have seen before.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By default, chatbot users are opted in to data collection. Opt-out policies place the onus on users to understand the implications of sharing their information. It’s also unlikely that data already used in training will be removed.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;We are all part of this phenomenon whether we want to be or not. Social media platforms from Instagram to LinkedIn now use our personal data to train generative AI models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Companies are sitting on treasure troves that consist of our most intimate thoughts and preferences, and language models are very good at picking up on subtle hints in language that could help advertisers profile us better by inferring our age, location, gender, and income level.&lt;/p&gt;  &lt;p&gt;We are being sold the idea of an omniscient AI digital assistant, a superintelligent confidante. In return, however, there is a very real risk that our information is about to be sent to the highest bidder once again.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Eileen responds:&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;I think the comparison between AI companions and social media is both apt and concerning.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;As Melissa highlighted, the privacy risks presented by AI chatbots aren’t &lt;em&gt;new&lt;/em&gt;—they just “put the [privacy] problem on steroids.” AI companions are more intimate and even better optimized for engagement than social media, making it more likely that people will offer up more personal information.&lt;/p&gt;  &lt;p&gt;Here in the US, we are far from solving the privacy issues already presented by social networks and the internet’s ad economy, even without the added risks of AI.&lt;/p&gt;  &lt;p&gt;And without regulation, the companies themselves are not following privacy best practices either. One recent study found that the major AI models train their LLMs on user chat data by default unless users opt out, while several don’t offer opt-out mechanisms at all.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;In an ideal world, the greater risks of companion AI would give more impetus to the privacy fight—but I don’t see any evidence this is happening.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Further reading&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;FT&lt;/em&gt; reporters peer under the hood of OpenAI’s five-year business plan as it tries to meet its vast $1 trillion spending pledges.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Is it really such a problem if AI chatbots tell people what they want to hear? This &lt;em&gt;FT&lt;/em&gt; feature asks what’s wrong with sycophancy&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a recent print issue of &lt;em&gt;MIT Technology Review&lt;/em&gt;, Rhiannon Williams spoke to a number of people about the types of relationships they are having with AI chatbots.&lt;/p&gt;  &lt;p&gt;Eileen broke the story for &lt;em&gt;MIT Technology Review&lt;/em&gt; about a chatbot that was encouraging some users to kill themselves.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/24/1128051/the-state-of-ai-chatbot-companions-and-the-future-of-our-privacy/</guid><pubDate>Mon, 24 Nov 2025 16:30:00 +0000</pubDate></item><item><title>[NEW] AI On: 3 Ways Specialized AI Agents Are Reshaping Businesses (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/specialized-ai-agents/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of the &lt;/i&gt;&lt;i&gt;AI On&lt;/i&gt;&lt;i&gt; blog series, which explores the latest techniques and real-world applications of agentic AI, chatbots and copilots. The series also highlights the NVIDIA software and hardware powering advanced AI agents, which form the foundation of AI query engines that gather insights and perform tasks to transform everyday experiences and reshape industries.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;As agentic AI adoption continues to grow, with open-source models and tools maturing, companies across industries are increasingly asking: what AI agents should we build to solve our unique business challenges?&lt;/p&gt;
&lt;p&gt;Although faster outcomes are a core benefit of using AI, organizations are finding that specialization is the key to business impact and long-term AI adoption. Rather than relying on one-size-fits-all models and services, leading companies are developing specialized AI agents designed to understand and act within the needs of a specific use case.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;CrowdStrike, PayPal and Synopsys are examples of companies combining NVIDIA Nemotron open foundation models with their proprietary data and institutional knowledge to create specialized applications. The results are intelligent agents that have the level of expertise required to work alongside human colleagues and boost business operations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-87784" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-on-specialized-agents-infographic-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;1. CrowdStrike Defends Against Modern Cyber Threats&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In cybersecurity, speed and precision are essential, especially as cyber threats become more advanced and grow to larger scales.&lt;/p&gt;
&lt;p&gt;To meet these rapidly evolving digital threats, CrowdStrike is building specialized AI agents that can work alongside security teams through Charlotte AI AgentWorks. These agents, powered by NVIDIA Nemotron open models and NVIDIA NIM microservices, automate high-volume tasks such as alert triage and remediation, allowing human analysts to focus on higher-order decision-making.&lt;/p&gt;
&lt;p&gt;Built on open models and continuously trained by incident responders, CrowdStrike’s Falcon agentic security platform increases accuracy of alert triage from 80% to 98.5%, reducing security analyst teams’ manual effort tenfold. The platform can adapt to new risks and collaborates across the security operations center.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;2. PayPal’s AI Agents Power Frictionless Commerce at Scale&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;PayPal, a leader in payments and e-commerce, is building agent-driven infrastructure to accelerate intelligent commerce.&lt;/p&gt;
&lt;p&gt;The company’s specialized AI agents, developed on Nemotron open models, will enable the first wave of conversational commerce experiences, where agents can shop, buy and pay on a user’s behalf.&lt;/p&gt;
&lt;p&gt;With this approach, PayPal built a fine-tuning pipeline in two weeks and reduced latency by nearly 50% while maintaining the high accuracy required to serve its 430 million customers and 30 million merchants.&lt;/p&gt;
&lt;p&gt;PayPal’s agents rely on open, modular models that are fine-tuned specifically for payments and commerce, giving the company the control to balance performance, accuracy and cost at a massive scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;3. Synopsys Accelerates Chip Design and Autonomous AI Engineering&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The complexity of modern semiconductor design and manufacturing calls for expertise, precision and speed. Synopsys addresses this with its Agent Engineer, AI agents deployed across the entire chip development workflow, from verification to implementation.&lt;/p&gt;
&lt;p&gt;These agents dramatically boost productivity in research and development, identifying critical design bugs that traditional techniques can miss to reduce costly delays.&lt;/p&gt;
&lt;p&gt;Running on NVIDIA accelerated infrastructure, Synopsys’ agent-driven workflows deliver up to 15x faster digital design verification performance.&lt;/p&gt;
&lt;p&gt;Using open models fine-tuned for each engineering task, as well as software like the NVIDIA NeMo Agent Toolkit and NVIDIA Blueprints, Synopsys quickly moved its chip designs from prototyping to production.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building Specialized AI Agents With NVIDIA Technologies&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Companies across industries are taking the following steps to transform their proprietary knowledge into specialized AI agents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluate open models, like NVIDIA Nemotron, that provide a powerful building block to create specialized models for any domain.&lt;/li&gt;
&lt;li&gt;Curate, generate and secure domain data using NVIDIA NeMo for agent lifecycle management.&lt;/li&gt;
&lt;li&gt;Create specialized agents using customized models that have access to proprietary data.&lt;/li&gt;
&lt;li&gt;Continue to fine-tune agents over time with a data flywheel.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Learn how &lt;/i&gt;&lt;i&gt;NVIDIA Nemotron&lt;/i&gt;&lt;i&gt; can help businesses build specialized AI agents for maximum productivity and return on investment.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of the &lt;/i&gt;&lt;i&gt;AI On&lt;/i&gt;&lt;i&gt; blog series, which explores the latest techniques and real-world applications of agentic AI, chatbots and copilots. The series also highlights the NVIDIA software and hardware powering advanced AI agents, which form the foundation of AI query engines that gather insights and perform tasks to transform everyday experiences and reshape industries.&lt;/i&gt;&lt;/p&gt;
&lt;p&gt;As agentic AI adoption continues to grow, with open-source models and tools maturing, companies across industries are increasingly asking: what AI agents should we build to solve our unique business challenges?&lt;/p&gt;
&lt;p&gt;Although faster outcomes are a core benefit of using AI, organizations are finding that specialization is the key to business impact and long-term AI adoption. Rather than relying on one-size-fits-all models and services, leading companies are developing specialized AI agents designed to understand and act within the needs of a specific use case.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;CrowdStrike, PayPal and Synopsys are examples of companies combining NVIDIA Nemotron open foundation models with their proprietary data and institutional knowledge to create specialized applications. The results are intelligent agents that have the level of expertise required to work alongside human colleagues and boost business operations.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-medium wp-image-87784" height="384" src="https://blogs.nvidia.com/wp-content/uploads/2025/11/ai-on-specialized-agents-infographic-960x384.jpg" width="960" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;1. CrowdStrike Defends Against Modern Cyber Threats&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;In cybersecurity, speed and precision are essential, especially as cyber threats become more advanced and grow to larger scales.&lt;/p&gt;
&lt;p&gt;To meet these rapidly evolving digital threats, CrowdStrike is building specialized AI agents that can work alongside security teams through Charlotte AI AgentWorks. These agents, powered by NVIDIA Nemotron open models and NVIDIA NIM microservices, automate high-volume tasks such as alert triage and remediation, allowing human analysts to focus on higher-order decision-making.&lt;/p&gt;
&lt;p&gt;Built on open models and continuously trained by incident responders, CrowdStrike’s Falcon agentic security platform increases accuracy of alert triage from 80% to 98.5%, reducing security analyst teams’ manual effort tenfold. The platform can adapt to new risks and collaborates across the security operations center.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;2. PayPal’s AI Agents Power Frictionless Commerce at Scale&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;PayPal, a leader in payments and e-commerce, is building agent-driven infrastructure to accelerate intelligent commerce.&lt;/p&gt;
&lt;p&gt;The company’s specialized AI agents, developed on Nemotron open models, will enable the first wave of conversational commerce experiences, where agents can shop, buy and pay on a user’s behalf.&lt;/p&gt;
&lt;p&gt;With this approach, PayPal built a fine-tuning pipeline in two weeks and reduced latency by nearly 50% while maintaining the high accuracy required to serve its 430 million customers and 30 million merchants.&lt;/p&gt;
&lt;p&gt;PayPal’s agents rely on open, modular models that are fine-tuned specifically for payments and commerce, giving the company the control to balance performance, accuracy and cost at a massive scale.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;3. Synopsys Accelerates Chip Design and Autonomous AI Engineering&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;The complexity of modern semiconductor design and manufacturing calls for expertise, precision and speed. Synopsys addresses this with its Agent Engineer, AI agents deployed across the entire chip development workflow, from verification to implementation.&lt;/p&gt;
&lt;p&gt;These agents dramatically boost productivity in research and development, identifying critical design bugs that traditional techniques can miss to reduce costly delays.&lt;/p&gt;
&lt;p&gt;Running on NVIDIA accelerated infrastructure, Synopsys’ agent-driven workflows deliver up to 15x faster digital design verification performance.&lt;/p&gt;
&lt;p&gt;Using open models fine-tuned for each engineering task, as well as software like the NVIDIA NeMo Agent Toolkit and NVIDIA Blueprints, Synopsys quickly moved its chip designs from prototyping to production.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Building Specialized AI Agents With NVIDIA Technologies&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Companies across industries are taking the following steps to transform their proprietary knowledge into specialized AI agents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Evaluate open models, like NVIDIA Nemotron, that provide a powerful building block to create specialized models for any domain.&lt;/li&gt;
&lt;li&gt;Curate, generate and secure domain data using NVIDIA NeMo for agent lifecycle management.&lt;/li&gt;
&lt;li&gt;Create specialized agents using customized models that have access to proprietary data.&lt;/li&gt;
&lt;li&gt;Continue to fine-tune agents over time with a data flywheel.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;i&gt;Learn how &lt;/i&gt;&lt;i&gt;NVIDIA Nemotron&lt;/i&gt;&lt;i&gt; can help businesses build specialized AI agents for maximum productivity and return on investment.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/specialized-ai-agents/</guid><pubDate>Mon, 24 Nov 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Fara-7B: An Efficient Agentic Model for Computer Use (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/</link><description>&lt;h3 class="wp-block-heading" id="pushing-the-frontiers-of-computer-use-agents-with-an-open-weight-ultra-compact-model-optimized-for-real-world-web-tasks"&gt;Pushing the frontiers of computer-use agents with an open-weight, ultra-compact model,&amp;nbsp;optimized&amp;nbsp;for real-world web tasks&lt;/h3&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue-to-green gradient background: a computer monitor with a globe symbol on the left, a cursor arrow with click lines in the center, and a computer mouse outline on the right." class="wp-image-1156197" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara7B-BlogHeroFeature-1400x788_NEW-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;In 2024,&amp;nbsp;Microsoft&amp;nbsp;introduced small language models (SLMs) to customers, starting with the release of Phi&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; models on Microsoft&amp;nbsp;Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;as&amp;nbsp;well as deploying&amp;nbsp;Phi Silica&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;on Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11. Today, we are pleased to&amp;nbsp;announce&amp;nbsp;&lt;strong&gt;Fara-7B&lt;/strong&gt;, our first&amp;nbsp;&lt;strong&gt;agentic SLM&lt;/strong&gt;&amp;nbsp;designed specifically for&amp;nbsp;computer&amp;nbsp;use.&lt;/p&gt;



&lt;p&gt;Unlike traditional chat models that generate text-based responses, Computer&amp;nbsp;Use Agent (CUA) models like Fara-7B&amp;nbsp;leverage computer interfaces, such as a mouse&amp;nbsp;and keyboard, to complete tasks on behalf of users. With only 7 billion parameters, Fara-7B&amp;nbsp;achieves&amp;nbsp;state-of-the-art&amp;nbsp;performance within its size class and is competitive with larger, more resource-intensive agentic systems that depend on prompting multiple large models. Fara-7B’s small size now&amp;nbsp;makes it possible&amp;nbsp;to&amp;nbsp;run CUA models directly on devices. This results in reduced latency and improved privacy, as user data&amp;nbsp;remains&amp;nbsp;local.&lt;/p&gt;



&lt;p&gt;Fara-7B is an experimental release, designed to invite hands-on exploration and feedback from the community. Users can build and test agentic experiences beyond pure research—automating everyday web tasks like filling out forms, searching for information, booking travel, or managing accounts. We recommend running Fara-7B in a sandboxed environment,&amp;nbsp;monitoring&amp;nbsp;its execution, and avoiding sensitive data or high-risk domains. Responsible use is&amp;nbsp;essential&amp;nbsp;as the model continues to evolve.&lt;/p&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;Fara-7B&amp;nbsp;operates by&amp;nbsp;visually perceiving&amp;nbsp;a webpage&amp;nbsp;and&amp;nbsp;takes&amp;nbsp;actions like&amp;nbsp;scrolling, typing, and clicking on directly predicted coordinates.&amp;nbsp;It&amp;nbsp;does not&amp;nbsp;rely on&amp;nbsp;separate models to parse the screen, nor on any additional information like&amp;nbsp;accessibility trees,&amp;nbsp;and&amp;nbsp;thus&amp;nbsp;uses the same modalities as humans to interact with the&amp;nbsp;computer.&amp;nbsp;To train Fara-7B, we developed a novel synthetic data generation pipeline&amp;nbsp;for multi-step&amp;nbsp;web tasks, building on our prior work (AgentInstruct).&amp;nbsp;This data generation pipeline draws from&amp;nbsp;real&amp;nbsp;web pages and tasks&amp;nbsp;sourced&amp;nbsp;from human users.&lt;/p&gt;







&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_xbox_multi_turn-3.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_xbox_multi_turn-3.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 1: A demo of a shopping scenario with Fara-7B through Magentic-UI. Fara-7B is asked to purchase an X-Box Spongebob controller. Fara-7B goes on to complete this task, but while doing so, also stops at every Critical Point to get input and approval from the user before proceeding.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_github_demo.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_github_demo.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 2: A demo of Fara-7B finding relevant information online and summarizing it through Magentic-UI. We ask Fara-7B to find and summarize the latest three issues on Github Microsoft/Magentic-UI.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_driving-directions-cheese.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/driving_directions_cheese-1_revised.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 3: A demo of how Fara-7B can use different tools to find relevant information and analyze it through Magentic-UI. We ask Fara-7B to find driving time between two places, and suggest a cheese place near the location. Fara-7B uses Bing Maps to find Driving time, and Bing search to find relevant information.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Fara-7B exhibits&amp;nbsp;strong performance&amp;nbsp;compared to existing models&amp;nbsp;across&amp;nbsp;a diverse set of benchmarks.&amp;nbsp;This includes both existing benchmarks as well as new&amp;nbsp;evaluations&amp;nbsp;we are&amp;nbsp;releasing&amp;nbsp;which&amp;nbsp;cover useful&amp;nbsp;task&amp;nbsp;segments that are underrepresented in common benchmarks, such as&amp;nbsp;finding job postings&amp;nbsp;and&amp;nbsp;comparing prices across retailers. While Fara-7B demonstrates strong benchmark results, even against much larger models, it shares many of their limitations, including challenges with accuracy on more complex tasks, mistakes in following instructions, and susceptibility to hallucinations.&amp;nbsp;These are active areas of research, and&amp;nbsp;we’re&amp;nbsp;committed to ongoing improvements as we learn from real-world use.&lt;/p&gt;



&lt;p&gt;Fara-7B is now available on&amp;nbsp;Microsoft Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;under an MIT license and is integrated with&amp;nbsp;Magentic-UI, a research prototype from Microsoft Research AI Frontiers&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We are also sharing a quantized and silicon-optimized version of Fara-7B, which will be available to install and run on&amp;nbsp;Copilot+ PCs powered by Windows 11, for turnkey experimentation.&amp;nbsp;The&amp;nbsp;community&amp;nbsp;can simply download the pre-optimized model and run it in their environment.&lt;/p&gt;



&lt;p&gt;By making Fara-7B open-weight, we aim to lower the barrier&amp;nbsp;to experimenting&amp;nbsp;with&amp;nbsp;and improving&amp;nbsp;CUA technology for automating routine web tasks, such as searching for information,&amp;nbsp;shopping,&amp;nbsp;and&amp;nbsp;booking reservations.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&amp;nbsp;https://openrouter.ai/&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API." class="wp-image-1156353" height="11897" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/model_accuracy_vs_cost_v2-1-1.png" width="19108" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;&lt;em&gt;Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&lt;/em&gt;&lt;em&gt;https://openrouter.ai/&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="developing-fara-7b"&gt;Developing Fara-7B&lt;/h2&gt;



&lt;h3 class="wp-block-heading" id="cua-multi-agent-synthetic-data-generation"&gt;CUA multi-agent synthetic data generation&lt;/h3&gt;



&lt;p&gt;A key bottleneck&amp;nbsp;for&amp;nbsp;building CUA models is a lack of large-scale, high-quality&amp;nbsp;computer interaction data. Collecting such data with&amp;nbsp;human annotators&amp;nbsp;is prohibitively expensive as a single&amp;nbsp;CUA task can involve&amp;nbsp;dozens&amp;nbsp;of steps,&amp;nbsp;each of which&amp;nbsp;needs to be&amp;nbsp;annotated.&amp;nbsp;Our&amp;nbsp;data generation pipeline&amp;nbsp;(Figure 2)&amp;nbsp;avoids manual annotation and instead relies on scalable synthetic data sourced from&amp;nbsp;publicly&amp;nbsp;available websites&amp;nbsp;and&amp;nbsp;custom&amp;nbsp;task prompts.&amp;nbsp;We build this&amp;nbsp;pipeline&amp;nbsp;on top of&amp;nbsp;the&amp;nbsp;Magentic-One&amp;nbsp;framework, and it involves three main stages:&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;2:&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories" class="wp-image-1155974" height="1349" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;2:&lt;em&gt;&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Task Proposal.&lt;/strong&gt;&amp;nbsp;We generate a broad set of synthetic tasks that mirror common user activities on the&amp;nbsp;web.&amp;nbsp;To ensure coverage and diversity, tasks are&amp;nbsp;“seeded” by&amp;nbsp;a&amp;nbsp;web&amp;nbsp;index of public URLs&amp;nbsp;classified into various categories e.g., shopping, travel, restaurants, etc. This enables&amp;nbsp;task&amp;nbsp;generation&amp;nbsp;targeting&amp;nbsp;a particular skill, like “book 2 tickets to see the Downton Abbey Grand Finale at AMC Union Square, NYC.”&amp;nbsp;from a&amp;nbsp;URL like this&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;classified as “movies”.&amp;nbsp;&amp;nbsp;As another strategy, we devised a way&amp;nbsp;to generate tasks from&amp;nbsp;randomly&amp;nbsp;sampled&amp;nbsp;URLs.&amp;nbsp;Each task starts with a general prompt and is iteratively refined as an&amp;nbsp;LLM&amp;nbsp;agent explores the website and gathers&amp;nbsp;more information about it. We are releasing a held-out subset of these tasks as a benchmark (“&lt;strong&gt;WebTailBench&lt;/strong&gt;”), described in the Evaluation section below.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Task&amp;nbsp;Solving.&lt;/strong&gt;&amp;nbsp;Once synthetic tasks are generated, a multi-agent system built on&amp;nbsp;Magentic-One&amp;nbsp;attempts&amp;nbsp;to&amp;nbsp;complete&amp;nbsp;them to generate demonstrations for supervised finetuning. The multi-agent system uses an&amp;nbsp;Orchestrator&amp;nbsp;agent to create a plan and direct a&amp;nbsp;WebSurfer&amp;nbsp;agent to take browser actions and reports results. The Orchestrator monitors progress, updating plans as needed, and can end tasks or engage a&lt;em&gt; &lt;/em&gt;UserSimulator agent if user input is&amp;nbsp;required, allowing for multi-turn completion.&amp;nbsp;Each&amp;nbsp;task and corresponding sequence of observations, actions, and agent thoughts&amp;nbsp;forms&amp;nbsp;a&amp;nbsp;“trajectory”.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Trajectory Verification.&lt;/strong&gt; Before using any tasks for training, three verifier agents evaluate if a task was “successful”: The Alignment Verifier checks if the trajectory of actions match the task’s intent; the Rubric Verifier defines completion criteria and scores the trajectory against them; and the Multimodal Verifier reviews screenshots and responses to confirm visual evidence supports successful completion. Trajectories failing these standards are removed.&lt;/p&gt;



&lt;p&gt;We&amp;nbsp;ultimately&amp;nbsp;train&amp;nbsp;this version&amp;nbsp;of&amp;nbsp;Fara-7B&amp;nbsp;on a dataset of&amp;nbsp;145,000&amp;nbsp;trajectories&amp;nbsp;consisting of&amp;nbsp;1&amp;nbsp;million&amp;nbsp;steps&amp;nbsp;covering diverse websites, task types, and difficulty levels.&amp;nbsp;Additionally, we include&amp;nbsp;training&amp;nbsp;data for several auxiliary tasks, including&amp;nbsp;grounding for&amp;nbsp;accurate&amp;nbsp;UI element localization, captioning, and visual question answering.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="training-fara-7b"&gt;Training Fara-7B&lt;/h3&gt;



&lt;p&gt;Using&amp;nbsp;one&amp;nbsp;compute use&amp;nbsp;model&amp;nbsp;is&amp;nbsp;easier than&amp;nbsp;a&amp;nbsp;multi-agent system, particularly when it comes to&amp;nbsp;deployment. Therefore, we&amp;nbsp;distill the complexities of&amp;nbsp;our multi-agent&amp;nbsp;solving system into a single model&amp;nbsp;that can&amp;nbsp;execute tasks.&amp;nbsp;Fara-7B&amp;nbsp;is a proof-of-concept that small models can&amp;nbsp;effectively&amp;nbsp;learn from complex, multi-agent systems&amp;nbsp;with lots of bells and whistles.&lt;/p&gt;



&lt;p&gt;As shown in Figure 3, Fara-7B is trained to execute user tasks by perceiving only browser window screenshots (without relying on accessibility trees), and predicting single-step actions. For each step, the context used to make its prediction contains all user messages, the complete action history, and the latest three screenshots.&lt;/p&gt;



&lt;p&gt;In its prediction,&amp;nbsp;Fara-7B&amp;nbsp;outputs a reasoning message (“thinking” about the next action) followed by a tool call. The available tools include standard&amp;nbsp;Playwright&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;mouse and keyboard actions, such as&amp;nbsp;click(x,y)&amp;nbsp;and&amp;nbsp;type(), and browser-specific macro-actions like&amp;nbsp;web_search()&amp;nbsp;and&amp;nbsp;visit_url().&lt;/p&gt;



&lt;p&gt;Fara-7B uses&amp;nbsp;Qwen2.5-VL-7B&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;as its base model due to its&amp;nbsp;strong performance&amp;nbsp;on grounding tasks and its ability to support long contexts (up to 128k tokens).&amp;nbsp;We&amp;nbsp;linearize the solving pipeline’s&amp;nbsp;trajectories&amp;nbsp;into a sequence of “observe-think-act” steps&amp;nbsp;that are suitable for training with supervised finetuning loss.&amp;nbsp;We did not use reinforcement learning to achieve&amp;nbsp;the&amp;nbsp;results&amp;nbsp;we report below.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;3:&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing" class="wp-image-1155975" height="864" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-3-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;3:&lt;em&gt;&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluations"&gt;Evaluations&lt;/h2&gt;



&lt;p&gt;We evaluate Fara-7B and comparable baselines on canonical public benchmarks including WebVoyager&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Online-Mind2Web&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Deepshop&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, as well as a new benchmark we developed named&lt;strong&gt; WebTailBench&lt;/strong&gt;, specifically focusing on 11 real-world task types underrepresented or missing in existing benchmarks like booking movie/event tickets, restaurant reservations, comparing prices across retailers,&amp;nbsp;applying for jobs,&amp;nbsp;finding real estate, and more complex multi-step tasks.&lt;/p&gt;



&lt;p&gt;Evaluation of&amp;nbsp;web&amp;nbsp;agents can be tricky&amp;nbsp;because the web is constantly&amp;nbsp;changing,&amp;nbsp;and many websites even block detected bots,&amp;nbsp;which is why we&amp;nbsp;developed&amp;nbsp;a&amp;nbsp;test&amp;nbsp;harness&amp;nbsp;that&amp;nbsp;relies on&amp;nbsp;BrowserBase&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;to standardize how browser sessions are managed.&amp;nbsp;In Table 1 below, we report a notion of task success rate&amp;nbsp;(%)&amp;nbsp;defined&amp;nbsp;by each benchmark’s official&amp;nbsp;LLM-as-judge evaluator;&amp;nbsp;WebTailBench&amp;nbsp;success is&amp;nbsp;computed using the same Task Verification pipeline that filtered&amp;nbsp;our&amp;nbsp;training data.&amp;nbsp;We find that&amp;nbsp;Fara-7B&amp;nbsp;is&amp;nbsp;state-of-the-art,&amp;nbsp;even&amp;nbsp;outperforming native computer use&amp;nbsp;agents&amp;nbsp;like UI-TARS-1.5-7B, or much larger&amp;nbsp;models&amp;nbsp;like GPT-4o prompted to act like a computer use agent with&amp;nbsp;Set-Of-Marks&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(SoM&amp;nbsp;Agent).&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-table aligncenter"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th colspan="2"&gt;&lt;/th&gt;&lt;th&gt;WebVoyager&lt;/th&gt;&lt;th&gt;Online-Mind2Web&lt;/th&gt;&lt;th&gt;DeepShop&lt;/th&gt;&lt;th&gt;WebTailBench&amp;nbsp;&amp;nbsp;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan="2"&gt;SoM&amp;nbsp;Agents&amp;nbsp;&lt;/td&gt;&lt;td&gt;SoM&amp;nbsp;Agent (GPT-4o)&amp;nbsp;&lt;/td&gt;&lt;td&gt;65.1&amp;nbsp;&lt;/td&gt;&lt;td&gt;34.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;16.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;30.0&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GLM-4.1V-9B-Thinking&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.8&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;33.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;32.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;22.4&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan="3"&gt;Computer Use Models&amp;nbsp;&lt;/td&gt;&lt;td&gt;OpenAI&amp;nbsp;computer-use-preview&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;70.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;42.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;24.7&amp;nbsp;&lt;/td&gt;&lt;td&gt;25.7&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;UI-TARS-1.5-7B&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.4&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;31.3&amp;nbsp;&lt;/td&gt;&lt;td&gt;11.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;19.5&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fara-7B&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;73.5&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;34.1&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;26.2&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;38.4&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1:&amp;nbsp;&lt;em&gt;Performance comparison across four web benchmarks:&amp;nbsp;WebVoyager, Online-Mind2Web,&amp;nbsp;DeepShop, and&amp;nbsp;our&amp;nbsp;newly introduced WebTailBench.&amp;nbsp;Results are reported as&amp;nbsp;Task Succes Rate / Accuracy&amp;nbsp;(%) and are averaged over 3 runs.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In Figure 1, we&amp;nbsp;expand on&amp;nbsp;the&amp;nbsp;Webvoyager&amp;nbsp;results by giving each model up to three chances to complete a task, and report “pass@K”. We also consider&amp;nbsp;on the x-axis the&amp;nbsp;cost of running each model if one were to pay market rates for input/output tokens consumed. Fara-7B breaks ground on a new pareto frontier, showing that on-device computer use agents are approaching the capabilities of frontier models.&lt;/p&gt;



&lt;p&gt;We partnered with a trusted external group,&amp;nbsp;Browserbase, to independently evaluate Fara-7B using human annotators. The model achieved&amp;nbsp;&lt;strong&gt;62%&lt;/strong&gt; on&amp;nbsp;WebVoyager (see detailed reports in&amp;nbsp;Browserbase&amp;nbsp;blog&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;). These results were generated in the same environment with identical settings and human verification of each task, making them directly comparable. Note that&amp;nbsp;Browserbase’s&amp;nbsp;standard&amp;nbsp;WebVoyager&amp;nbsp;scores do not use retries when&amp;nbsp;environment&amp;nbsp;errors occur; the results referenced here include retries and should not be compared directly to the non-retry scores. Going forward, we are collaborating with&amp;nbsp;Browserbase&amp;nbsp;to host&amp;nbsp;WebTailBench&amp;nbsp;human evaluations to help the community build reliable and reproducible assessments for computer use agents.&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="safety"&gt;Safety&lt;/h3&gt;



&lt;p&gt;Agents capable of operating computers present challenges&amp;nbsp;distinct&amp;nbsp;from&amp;nbsp;chat-only models,&amp;nbsp;including new&amp;nbsp;outlets of&amp;nbsp;user&amp;nbsp;misuse, model misbehavior,&amp;nbsp;and unintended&amp;nbsp;consequences of&amp;nbsp;actions,&amp;nbsp;and&amp;nbsp;external&amp;nbsp;risks like prompt injections or online scams.&amp;nbsp;CUAs&amp;nbsp;take action with&amp;nbsp;real-world consequences, so ensuring&amp;nbsp;robust safety measures is essential to their responsible deployment.&amp;nbsp;Transparency and user control sit at the core of Fara-7B’s design. Although we have incorporated several safety measures, Fara-7B&amp;nbsp;remains&amp;nbsp;a research preview, and we continue to advance our approach to safety for computer use agents, an active area of work across the entire AI community.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fara-7B processes browser screenshots, user task instructions, and a history of actions taken during each session and collects only what is necessary to complete the user’s requested task. No&amp;nbsp;additional&amp;nbsp;site data—such as&amp;nbsp;accessibility&amp;nbsp;trees or external scaffolding—is accessed; Fara-7B interacts with the computer in the same way a human would, relying solely on what is visible on the screen.&lt;/p&gt;



&lt;p&gt;All actions taken by the agent are logged and auditable, allowing users to review and&amp;nbsp;monitor&amp;nbsp;every step.&amp;nbsp;&amp;nbsp;For added safety, Fara‑7B is intended to run in sandboxed environments, giving users full oversight and the ability to intervene or halt&amp;nbsp;actions at any time. These safeguards ensure that privacy, transparency, and user control remain at the core of every interaction.&lt;/p&gt;



&lt;p&gt;To&amp;nbsp;address&amp;nbsp;misuse, we trained Fara-7B on a mixture of public safety data and internally generated tasks that it&amp;nbsp;ought to refuse&amp;nbsp;based on&amp;nbsp;Microsoft’s Responsible AI Policy.&amp;nbsp;We evaluated&amp;nbsp;Fara-7B’s ability to refuse harmful tasks&amp;nbsp;on&amp;nbsp;&lt;strong&gt;WebTailBench-Refusals&lt;/strong&gt;&amp;nbsp;which consists of&amp;nbsp;111 red-teaming tasks&amp;nbsp;showing a high refusal rate&amp;nbsp;of 82%.&amp;nbsp;The&amp;nbsp;model&amp;nbsp;also&amp;nbsp;underwent&amp;nbsp;Microsoft’s&amp;nbsp;rigorous&amp;nbsp;red teaming process, where we focused on the model rejecting harmful tasks and risky tasks, such as harmful content, jailbreaking attempts, ungrounded&amp;nbsp;responses,&amp;nbsp;and prompt injections. For further details, check out our technical report&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;To mitigate the risk of Fara-7B taking unintended actions,&amp;nbsp;all of&amp;nbsp;Fara-7B’s&amp;nbsp;training data enforces both recognizing and stopping at “Critical Points” when executing a task. A Critical Point&amp;nbsp;(see&amp;nbsp;Operator System Card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;)&amp;nbsp;is any situation that requires the user’s personal data or consent before engaging in a transaction or irreversible action like sending an email. Upon reaching a Critical Point, Fara-7B&amp;nbsp;should&amp;nbsp;respond by informing the&amp;nbsp;user&amp;nbsp;it&amp;nbsp;cannot&amp;nbsp;proceed&amp;nbsp;without their consent.&lt;/p&gt;



&lt;p&gt;For guidance on how to use our model safely, and the security considerations to be mindful of when using our model, please refer to our&amp;nbsp;Model&amp;nbsp;card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="how-to-use"&gt;How to use&lt;/h3&gt;



&lt;p&gt;Fara-7B&amp;nbsp;is available on&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Microsoft&amp;nbsp;Foundry&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;and&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;We are also releasing the implementation of Fara-7B&amp;nbsp;in&amp;nbsp;Magentic-UI,&amp;nbsp;so that&amp;nbsp;users&amp;nbsp;can&amp;nbsp;try&amp;nbsp;it&amp;nbsp;in a contained environment&amp;nbsp;through the inference code provided. Additionally, users can download the model for Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11&amp;nbsp;from the&amp;nbsp;AI&amp;nbsp;Toolkit in VSCode and&amp;nbsp;run it all on-device,&amp;nbsp;taking advantage of&amp;nbsp;NPU hardware acceleration.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="looking-forward"&gt;Looking forward&lt;/h3&gt;



&lt;p&gt;Our current release&amp;nbsp;is an experimental CUA model&amp;nbsp;that achieves&amp;nbsp;state-of-the-art&amp;nbsp;results for its size,&amp;nbsp;purely using&amp;nbsp;supervised fine-tuning.&amp;nbsp;We believe even stronger CUA&amp;nbsp;models capable of running on-device are possible&amp;nbsp;through&amp;nbsp;improved&amp;nbsp;multimodal base models and through Reinforcement Learning&amp;nbsp;on&amp;nbsp;live and sandboxed environments.&amp;nbsp;These early days&amp;nbsp;are about learning from the community and driving real-world experimentation to shape what comes next.&amp;nbsp;If&amp;nbsp;you’d&amp;nbsp;like to join us and help shape the future of SLMs,&amp;nbsp;please&amp;nbsp;apply for open roles.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements:&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;We thank Gustavo de Rosa, Adam Fourney, Michael Harrison, Rafah Hosn, Neel Joshi, Ece Kamar, John Langford, Maya Murad, Sidhartha Sen, Pratyusha Sharma, and Lili Wu for their valuable help, insightful discussions, and continued support throughout this work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also thank Pashmina Cameron, Karthik Vijayan, Vicente Rivera, Chris Dern, Sayan Shaw,&amp;nbsp;Sunghoon&amp;nbsp;Choi, Andrey&amp;nbsp;Rybalchenko, and Vivek Pradeep for their efforts in making the model available on Copilot+ PCs through the AI Toolkit.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</description><content:encoded>&lt;h3 class="wp-block-heading" id="pushing-the-frontiers-of-computer-use-agents-with-an-open-weight-ultra-compact-model-optimized-for-real-world-web-tasks"&gt;Pushing the frontiers of computer-use agents with an open-weight, ultra-compact model,&amp;nbsp;optimized&amp;nbsp;for real-world web tasks&lt;/h3&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white line icons on a blue-to-green gradient background: a computer monitor with a globe symbol on the left, a cursor arrow with click lines in the center, and a computer mouse outline on the right." class="wp-image-1156197" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara7B-BlogHeroFeature-1400x788_NEW-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;In 2024,&amp;nbsp;Microsoft&amp;nbsp;introduced small language models (SLMs) to customers, starting with the release of Phi&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; models on Microsoft&amp;nbsp;Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;,&amp;nbsp;as&amp;nbsp;well as deploying&amp;nbsp;Phi Silica&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;on Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11. Today, we are pleased to&amp;nbsp;announce&amp;nbsp;&lt;strong&gt;Fara-7B&lt;/strong&gt;, our first&amp;nbsp;&lt;strong&gt;agentic SLM&lt;/strong&gt;&amp;nbsp;designed specifically for&amp;nbsp;computer&amp;nbsp;use.&lt;/p&gt;



&lt;p&gt;Unlike traditional chat models that generate text-based responses, Computer&amp;nbsp;Use Agent (CUA) models like Fara-7B&amp;nbsp;leverage computer interfaces, such as a mouse&amp;nbsp;and keyboard, to complete tasks on behalf of users. With only 7 billion parameters, Fara-7B&amp;nbsp;achieves&amp;nbsp;state-of-the-art&amp;nbsp;performance within its size class and is competitive with larger, more resource-intensive agentic systems that depend on prompting multiple large models. Fara-7B’s small size now&amp;nbsp;makes it possible&amp;nbsp;to&amp;nbsp;run CUA models directly on devices. This results in reduced latency and improved privacy, as user data&amp;nbsp;remains&amp;nbsp;local.&lt;/p&gt;



&lt;p&gt;Fara-7B is an experimental release, designed to invite hands-on exploration and feedback from the community. Users can build and test agentic experiences beyond pure research—automating everyday web tasks like filling out forms, searching for information, booking travel, or managing accounts. We recommend running Fara-7B in a sandboxed environment,&amp;nbsp;monitoring&amp;nbsp;its execution, and avoiding sensitive data or high-risk domains. Responsible use is&amp;nbsp;essential&amp;nbsp;as the model continues to evolve.&lt;/p&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;Fara-7B&amp;nbsp;operates by&amp;nbsp;visually perceiving&amp;nbsp;a webpage&amp;nbsp;and&amp;nbsp;takes&amp;nbsp;actions like&amp;nbsp;scrolling, typing, and clicking on directly predicted coordinates.&amp;nbsp;It&amp;nbsp;does not&amp;nbsp;rely on&amp;nbsp;separate models to parse the screen, nor on any additional information like&amp;nbsp;accessibility trees,&amp;nbsp;and&amp;nbsp;thus&amp;nbsp;uses the same modalities as humans to interact with the&amp;nbsp;computer.&amp;nbsp;To train Fara-7B, we developed a novel synthetic data generation pipeline&amp;nbsp;for multi-step&amp;nbsp;web tasks, building on our prior work (AgentInstruct).&amp;nbsp;This data generation pipeline draws from&amp;nbsp;real&amp;nbsp;web pages and tasks&amp;nbsp;sourced&amp;nbsp;from human users.&lt;/p&gt;







&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_xbox_multi_turn-3.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_xbox_multi_turn-3.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 1: A demo of a shopping scenario with Fara-7B through Magentic-UI. Fara-7B is asked to purchase an X-Box Spongebob controller. Fara-7B goes on to complete this task, but while doing so, also stops at every Critical Point to get input and approval from the user before proceeding.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_github_demo.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/fara_github_demo.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 2: A demo of Fara-7B finding relevant information online and summarizing it through Magentic-UI. We ask Fara-7B to find and summarize the latest three issues on Github Microsoft/Magentic-UI.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-video aligncenter"&gt;&lt;video controls="controls" poster="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Fara_driving-directions-cheese.jpg" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/driving_directions_cheese-1_revised.mp4"&gt;&lt;/video&gt;&lt;figcaption class="wp-element-caption"&gt;Video 3: A demo of how Fara-7B can use different tools to find relevant information and analyze it through Magentic-UI. We ask Fara-7B to find driving time between two places, and suggest a cheese place near the location. Fara-7B uses Bing Maps to find Driving time, and Bing search to find relevant information.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Fara-7B exhibits&amp;nbsp;strong performance&amp;nbsp;compared to existing models&amp;nbsp;across&amp;nbsp;a diverse set of benchmarks.&amp;nbsp;This includes both existing benchmarks as well as new&amp;nbsp;evaluations&amp;nbsp;we are&amp;nbsp;releasing&amp;nbsp;which&amp;nbsp;cover useful&amp;nbsp;task&amp;nbsp;segments that are underrepresented in common benchmarks, such as&amp;nbsp;finding job postings&amp;nbsp;and&amp;nbsp;comparing prices across retailers. While Fara-7B demonstrates strong benchmark results, even against much larger models, it shares many of their limitations, including challenges with accuracy on more complex tasks, mistakes in following instructions, and susceptibility to hallucinations.&amp;nbsp;These are active areas of research, and&amp;nbsp;we’re&amp;nbsp;committed to ongoing improvements as we learn from real-world use.&lt;/p&gt;



&lt;p&gt;Fara-7B is now available on&amp;nbsp;Microsoft Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;under an MIT license and is integrated with&amp;nbsp;Magentic-UI, a research prototype from Microsoft Research AI Frontiers&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. We are also sharing a quantized and silicon-optimized version of Fara-7B, which will be available to install and run on&amp;nbsp;Copilot+ PCs powered by Windows 11, for turnkey experimentation.&amp;nbsp;The&amp;nbsp;community&amp;nbsp;can simply download the pre-optimized model and run it in their environment.&lt;/p&gt;



&lt;p&gt;By making Fara-7B open-weight, we aim to lower the barrier&amp;nbsp;to experimenting&amp;nbsp;with&amp;nbsp;and improving&amp;nbsp;CUA technology for automating routine web tasks, such as searching for information,&amp;nbsp;shopping,&amp;nbsp;and&amp;nbsp;booking reservations.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&amp;nbsp;https://openrouter.ai/&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API." class="wp-image-1156353" height="11897" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/model_accuracy_vs_cost_v2-1-1.png" width="19108" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;&lt;em&gt;Figure&amp;nbsp;1:&amp;nbsp;Comparing&amp;nbsp;WebVoyager&amp;nbsp;accuracy and cost&amp;nbsp;of&amp;nbsp;Fara-7B to other&amp;nbsp;computer&amp;nbsp;use agents (CUAs)&amp;nbsp;or agents that prompt LLMs with accessibility trees (SoM&amp;nbsp;Agent w/ Ax Tree).&amp;nbsp;Cost is computed&amp;nbsp;by&amp;nbsp;multiplying&amp;nbsp;the&amp;nbsp;average&amp;nbsp;number of&amp;nbsp;input&amp;nbsp;and&amp;nbsp;output tokens&amp;nbsp;each model&amp;nbsp;consumes&amp;nbsp;by&amp;nbsp;price per token.&amp;nbsp;Both&amp;nbsp;Fara-7B and UI-TARS-1.5-7B&amp;nbsp;are based&amp;nbsp;on&amp;nbsp;Qwen-2.5-VL-7B,&amp;nbsp;for which the&amp;nbsp;lowest&amp;nbsp;inference price&amp;nbsp;from&amp;nbsp;&lt;/em&gt;&lt;em&gt;https://openrouter.ai/&lt;/em&gt;&lt;em&gt;&amp;nbsp;&amp;nbsp;is&amp;nbsp;\(0.2/\)0.2&amp;nbsp;per 1M&amp;nbsp;input/output&amp;nbsp;tokens.&amp;nbsp;Even though both models are priced equally, Fara-7B is more&amp;nbsp;efficient,&amp;nbsp;completing tasks&amp;nbsp;with&amp;nbsp;only&amp;nbsp;~16&amp;nbsp;steps on&amp;nbsp;average&amp;nbsp;compared&amp;nbsp;to&amp;nbsp;~41&amp;nbsp;for UI-TARS-1.5-7B.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="developing-fara-7b"&gt;Developing Fara-7B&lt;/h2&gt;



&lt;h3 class="wp-block-heading" id="cua-multi-agent-synthetic-data-generation"&gt;CUA multi-agent synthetic data generation&lt;/h3&gt;



&lt;p&gt;A key bottleneck&amp;nbsp;for&amp;nbsp;building CUA models is a lack of large-scale, high-quality&amp;nbsp;computer interaction data. Collecting such data with&amp;nbsp;human annotators&amp;nbsp;is prohibitively expensive as a single&amp;nbsp;CUA task can involve&amp;nbsp;dozens&amp;nbsp;of steps,&amp;nbsp;each of which&amp;nbsp;needs to be&amp;nbsp;annotated.&amp;nbsp;Our&amp;nbsp;data generation pipeline&amp;nbsp;(Figure 2)&amp;nbsp;avoids manual annotation and instead relies on scalable synthetic data sourced from&amp;nbsp;publicly&amp;nbsp;available websites&amp;nbsp;and&amp;nbsp;custom&amp;nbsp;task prompts.&amp;nbsp;We build this&amp;nbsp;pipeline&amp;nbsp;on top of&amp;nbsp;the&amp;nbsp;Magentic-One&amp;nbsp;framework, and it involves three main stages:&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;2:&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories" class="wp-image-1155974" height="1349" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-2-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;2:&lt;em&gt;&amp;nbsp;Data Generation workflow from proposing tasks from various seeds like URLs&amp;nbsp;to&amp;nbsp;solving&amp;nbsp;those tasks with&amp;nbsp;the&amp;nbsp;Magentic-One multi-agent framework to generate demonstrations for training, and finally&amp;nbsp;verifiying/filtering&amp;nbsp;completed&amp;nbsp;trajectories&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;&lt;strong&gt;Task Proposal.&lt;/strong&gt;&amp;nbsp;We generate a broad set of synthetic tasks that mirror common user activities on the&amp;nbsp;web.&amp;nbsp;To ensure coverage and diversity, tasks are&amp;nbsp;“seeded” by&amp;nbsp;a&amp;nbsp;web&amp;nbsp;index of public URLs&amp;nbsp;classified into various categories e.g., shopping, travel, restaurants, etc. This enables&amp;nbsp;task&amp;nbsp;generation&amp;nbsp;targeting&amp;nbsp;a particular skill, like “book 2 tickets to see the Downton Abbey Grand Finale at AMC Union Square, NYC.”&amp;nbsp;from a&amp;nbsp;URL like this&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;classified as “movies”.&amp;nbsp;&amp;nbsp;As another strategy, we devised a way&amp;nbsp;to generate tasks from&amp;nbsp;randomly&amp;nbsp;sampled&amp;nbsp;URLs.&amp;nbsp;Each task starts with a general prompt and is iteratively refined as an&amp;nbsp;LLM&amp;nbsp;agent explores the website and gathers&amp;nbsp;more information about it. We are releasing a held-out subset of these tasks as a benchmark (“&lt;strong&gt;WebTailBench&lt;/strong&gt;”), described in the Evaluation section below.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Task&amp;nbsp;Solving.&lt;/strong&gt;&amp;nbsp;Once synthetic tasks are generated, a multi-agent system built on&amp;nbsp;Magentic-One&amp;nbsp;attempts&amp;nbsp;to&amp;nbsp;complete&amp;nbsp;them to generate demonstrations for supervised finetuning. The multi-agent system uses an&amp;nbsp;Orchestrator&amp;nbsp;agent to create a plan and direct a&amp;nbsp;WebSurfer&amp;nbsp;agent to take browser actions and reports results. The Orchestrator monitors progress, updating plans as needed, and can end tasks or engage a&lt;em&gt; &lt;/em&gt;UserSimulator agent if user input is&amp;nbsp;required, allowing for multi-turn completion.&amp;nbsp;Each&amp;nbsp;task and corresponding sequence of observations, actions, and agent thoughts&amp;nbsp;forms&amp;nbsp;a&amp;nbsp;“trajectory”.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Trajectory Verification.&lt;/strong&gt; Before using any tasks for training, three verifier agents evaluate if a task was “successful”: The Alignment Verifier checks if the trajectory of actions match the task’s intent; the Rubric Verifier defines completion criteria and scores the trajectory against them; and the Multimodal Verifier reviews screenshots and responses to confirm visual evidence supports successful completion. Trajectories failing these standards are removed.&lt;/p&gt;



&lt;p&gt;We&amp;nbsp;ultimately&amp;nbsp;train&amp;nbsp;this version&amp;nbsp;of&amp;nbsp;Fara-7B&amp;nbsp;on a dataset of&amp;nbsp;145,000&amp;nbsp;trajectories&amp;nbsp;consisting of&amp;nbsp;1&amp;nbsp;million&amp;nbsp;steps&amp;nbsp;covering diverse websites, task types, and difficulty levels.&amp;nbsp;Additionally, we include&amp;nbsp;training&amp;nbsp;data for several auxiliary tasks, including&amp;nbsp;grounding for&amp;nbsp;accurate&amp;nbsp;UI element localization, captioning, and visual question answering.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="training-fara-7b"&gt;Training Fara-7B&lt;/h3&gt;



&lt;p&gt;Using&amp;nbsp;one&amp;nbsp;compute use&amp;nbsp;model&amp;nbsp;is&amp;nbsp;easier than&amp;nbsp;a&amp;nbsp;multi-agent system, particularly when it comes to&amp;nbsp;deployment. Therefore, we&amp;nbsp;distill the complexities of&amp;nbsp;our multi-agent&amp;nbsp;solving system into a single model&amp;nbsp;that can&amp;nbsp;execute tasks.&amp;nbsp;Fara-7B&amp;nbsp;is a proof-of-concept that small models can&amp;nbsp;effectively&amp;nbsp;learn from complex, multi-agent systems&amp;nbsp;with lots of bells and whistles.&lt;/p&gt;



&lt;p&gt;As shown in Figure 3, Fara-7B is trained to execute user tasks by perceiving only browser window screenshots (without relying on accessibility trees), and predicting single-step actions. For each step, the context used to make its prediction contains all user messages, the complete action history, and the latest three screenshots.&lt;/p&gt;



&lt;p&gt;In its prediction,&amp;nbsp;Fara-7B&amp;nbsp;outputs a reasoning message (“thinking” about the next action) followed by a tool call. The available tools include standard&amp;nbsp;Playwright&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;mouse and keyboard actions, such as&amp;nbsp;click(x,y)&amp;nbsp;and&amp;nbsp;type(), and browser-specific macro-actions like&amp;nbsp;web_search()&amp;nbsp;and&amp;nbsp;visit_url().&lt;/p&gt;



&lt;p&gt;Fara-7B uses&amp;nbsp;Qwen2.5-VL-7B&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;as its base model due to its&amp;nbsp;strong performance&amp;nbsp;on grounding tasks and its ability to support long contexts (up to 128k tokens).&amp;nbsp;We&amp;nbsp;linearize the solving pipeline’s&amp;nbsp;trajectories&amp;nbsp;into a sequence of “observe-think-act” steps&amp;nbsp;that are suitable for training with supervised finetuning loss.&amp;nbsp;We did not use reinforcement learning to achieve&amp;nbsp;the&amp;nbsp;results&amp;nbsp;we report below.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure&amp;nbsp;3:&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing" class="wp-image-1155975" height="864" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/11/Figure-3-scaled.png" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure&amp;nbsp;3:&lt;em&gt;&amp;nbsp;Operation of Fara-7B as a standalone, native computer use agent&amp;nbsp;running on-device. Because Fara-7B is small, and none of its context needs to leave your personal device, it paves the way for personal and private agentic computing&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluations"&gt;Evaluations&lt;/h2&gt;



&lt;p&gt;We evaluate Fara-7B and comparable baselines on canonical public benchmarks including WebVoyager&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Online-Mind2Web&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and Deepshop&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, as well as a new benchmark we developed named&lt;strong&gt; WebTailBench&lt;/strong&gt;, specifically focusing on 11 real-world task types underrepresented or missing in existing benchmarks like booking movie/event tickets, restaurant reservations, comparing prices across retailers,&amp;nbsp;applying for jobs,&amp;nbsp;finding real estate, and more complex multi-step tasks.&lt;/p&gt;



&lt;p&gt;Evaluation of&amp;nbsp;web&amp;nbsp;agents can be tricky&amp;nbsp;because the web is constantly&amp;nbsp;changing,&amp;nbsp;and many websites even block detected bots,&amp;nbsp;which is why we&amp;nbsp;developed&amp;nbsp;a&amp;nbsp;test&amp;nbsp;harness&amp;nbsp;that&amp;nbsp;relies on&amp;nbsp;BrowserBase&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;to standardize how browser sessions are managed.&amp;nbsp;In Table 1 below, we report a notion of task success rate&amp;nbsp;(%)&amp;nbsp;defined&amp;nbsp;by each benchmark’s official&amp;nbsp;LLM-as-judge evaluator;&amp;nbsp;WebTailBench&amp;nbsp;success is&amp;nbsp;computed using the same Task Verification pipeline that filtered&amp;nbsp;our&amp;nbsp;training data.&amp;nbsp;We find that&amp;nbsp;Fara-7B&amp;nbsp;is&amp;nbsp;state-of-the-art,&amp;nbsp;even&amp;nbsp;outperforming native computer use&amp;nbsp;agents&amp;nbsp;like UI-TARS-1.5-7B, or much larger&amp;nbsp;models&amp;nbsp;like GPT-4o prompted to act like a computer use agent with&amp;nbsp;Set-Of-Marks&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(SoM&amp;nbsp;Agent).&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-table aligncenter"&gt;&lt;table class="has-fixed-layout"&gt;&lt;thead&gt;&lt;tr&gt;&lt;th colspan="2"&gt;&lt;/th&gt;&lt;th&gt;WebVoyager&lt;/th&gt;&lt;th&gt;Online-Mind2Web&lt;/th&gt;&lt;th&gt;DeepShop&lt;/th&gt;&lt;th&gt;WebTailBench&amp;nbsp;&amp;nbsp;&lt;/th&gt;&lt;/tr&gt;&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td rowspan="2"&gt;SoM&amp;nbsp;Agents&amp;nbsp;&lt;/td&gt;&lt;td&gt;SoM&amp;nbsp;Agent (GPT-4o)&amp;nbsp;&lt;/td&gt;&lt;td&gt;65.1&amp;nbsp;&lt;/td&gt;&lt;td&gt;34.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;16.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;30.0&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;GLM-4.1V-9B-Thinking&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.8&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;33.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;32.0&amp;nbsp;&lt;/td&gt;&lt;td&gt;22.4&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td rowspan="3"&gt;Computer Use Models&amp;nbsp;&lt;/td&gt;&lt;td&gt;OpenAI&amp;nbsp;computer-use-preview&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;70.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;42.9&amp;nbsp;&lt;/td&gt;&lt;td&gt;24.7&amp;nbsp;&lt;/td&gt;&lt;td&gt;25.7&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;UI-TARS-1.5-7B&amp;nbsp;&lt;/td&gt;&lt;td&gt;66.4&amp;nbsp;&amp;nbsp;&lt;/td&gt;&lt;td&gt;31.3&amp;nbsp;&lt;/td&gt;&lt;td&gt;11.6&amp;nbsp;&lt;/td&gt;&lt;td&gt;19.5&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Fara-7B&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;73.5&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;34.1&amp;nbsp;&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;26.2&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;38.4&lt;/strong&gt;&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1:&amp;nbsp;&lt;em&gt;Performance comparison across four web benchmarks:&amp;nbsp;WebVoyager, Online-Mind2Web,&amp;nbsp;DeepShop, and&amp;nbsp;our&amp;nbsp;newly introduced WebTailBench.&amp;nbsp;Results are reported as&amp;nbsp;Task Succes Rate / Accuracy&amp;nbsp;(%) and are averaged over 3 runs.&amp;nbsp;OpenAI computer-use-preview accessed November 2025 via the Responses API.&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;In Figure 1, we&amp;nbsp;expand on&amp;nbsp;the&amp;nbsp;Webvoyager&amp;nbsp;results by giving each model up to three chances to complete a task, and report “pass@K”. We also consider&amp;nbsp;on the x-axis the&amp;nbsp;cost of running each model if one were to pay market rates for input/output tokens consumed. Fara-7B breaks ground on a new pareto frontier, showing that on-device computer use agents are approaching the capabilities of frontier models.&lt;/p&gt;



&lt;p&gt;We partnered with a trusted external group,&amp;nbsp;Browserbase, to independently evaluate Fara-7B using human annotators. The model achieved&amp;nbsp;&lt;strong&gt;62%&lt;/strong&gt; on&amp;nbsp;WebVoyager (see detailed reports in&amp;nbsp;Browserbase&amp;nbsp;blog&amp;nbsp;here&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;). These results were generated in the same environment with identical settings and human verification of each task, making them directly comparable. Note that&amp;nbsp;Browserbase’s&amp;nbsp;standard&amp;nbsp;WebVoyager&amp;nbsp;scores do not use retries when&amp;nbsp;environment&amp;nbsp;errors occur; the results referenced here include retries and should not be compared directly to the non-retry scores. Going forward, we are collaborating with&amp;nbsp;Browserbase&amp;nbsp;to host&amp;nbsp;WebTailBench&amp;nbsp;human evaluations to help the community build reliable and reproducible assessments for computer use agents.&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="safety"&gt;Safety&lt;/h3&gt;



&lt;p&gt;Agents capable of operating computers present challenges&amp;nbsp;distinct&amp;nbsp;from&amp;nbsp;chat-only models,&amp;nbsp;including new&amp;nbsp;outlets of&amp;nbsp;user&amp;nbsp;misuse, model misbehavior,&amp;nbsp;and unintended&amp;nbsp;consequences of&amp;nbsp;actions,&amp;nbsp;and&amp;nbsp;external&amp;nbsp;risks like prompt injections or online scams.&amp;nbsp;CUAs&amp;nbsp;take action with&amp;nbsp;real-world consequences, so ensuring&amp;nbsp;robust safety measures is essential to their responsible deployment.&amp;nbsp;Transparency and user control sit at the core of Fara-7B’s design. Although we have incorporated several safety measures, Fara-7B&amp;nbsp;remains&amp;nbsp;a research preview, and we continue to advance our approach to safety for computer use agents, an active area of work across the entire AI community.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fara-7B processes browser screenshots, user task instructions, and a history of actions taken during each session and collects only what is necessary to complete the user’s requested task. No&amp;nbsp;additional&amp;nbsp;site data—such as&amp;nbsp;accessibility&amp;nbsp;trees or external scaffolding—is accessed; Fara-7B interacts with the computer in the same way a human would, relying solely on what is visible on the screen.&lt;/p&gt;



&lt;p&gt;All actions taken by the agent are logged and auditable, allowing users to review and&amp;nbsp;monitor&amp;nbsp;every step.&amp;nbsp;&amp;nbsp;For added safety, Fara‑7B is intended to run in sandboxed environments, giving users full oversight and the ability to intervene or halt&amp;nbsp;actions at any time. These safeguards ensure that privacy, transparency, and user control remain at the core of every interaction.&lt;/p&gt;



&lt;p&gt;To&amp;nbsp;address&amp;nbsp;misuse, we trained Fara-7B on a mixture of public safety data and internally generated tasks that it&amp;nbsp;ought to refuse&amp;nbsp;based on&amp;nbsp;Microsoft’s Responsible AI Policy.&amp;nbsp;We evaluated&amp;nbsp;Fara-7B’s ability to refuse harmful tasks&amp;nbsp;on&amp;nbsp;&lt;strong&gt;WebTailBench-Refusals&lt;/strong&gt;&amp;nbsp;which consists of&amp;nbsp;111 red-teaming tasks&amp;nbsp;showing a high refusal rate&amp;nbsp;of 82%.&amp;nbsp;The&amp;nbsp;model&amp;nbsp;also&amp;nbsp;underwent&amp;nbsp;Microsoft’s&amp;nbsp;rigorous&amp;nbsp;red teaming process, where we focused on the model rejecting harmful tasks and risky tasks, such as harmful content, jailbreaking attempts, ungrounded&amp;nbsp;responses,&amp;nbsp;and prompt injections. For further details, check out our technical report&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;To mitigate the risk of Fara-7B taking unintended actions,&amp;nbsp;all of&amp;nbsp;Fara-7B’s&amp;nbsp;training data enforces both recognizing and stopping at “Critical Points” when executing a task. A Critical Point&amp;nbsp;(see&amp;nbsp;Operator System Card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;)&amp;nbsp;is any situation that requires the user’s personal data or consent before engaging in a transaction or irreversible action like sending an email. Upon reaching a Critical Point, Fara-7B&amp;nbsp;should&amp;nbsp;respond by informing the&amp;nbsp;user&amp;nbsp;it&amp;nbsp;cannot&amp;nbsp;proceed&amp;nbsp;without their consent.&lt;/p&gt;



&lt;p&gt;For guidance on how to use our model safely, and the security considerations to be mindful of when using our model, please refer to our&amp;nbsp;Model&amp;nbsp;card&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="how-to-use"&gt;How to use&lt;/h3&gt;



&lt;p&gt;Fara-7B&amp;nbsp;is available on&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Microsoft&amp;nbsp;Foundry&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;and&amp;nbsp;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;We are also releasing the implementation of Fara-7B&amp;nbsp;in&amp;nbsp;Magentic-UI,&amp;nbsp;so that&amp;nbsp;users&amp;nbsp;can&amp;nbsp;try&amp;nbsp;it&amp;nbsp;in a contained environment&amp;nbsp;through the inference code provided. Additionally, users can download the model for Copilot+&amp;nbsp;PCs&amp;nbsp;powered by Windows 11&amp;nbsp;from the&amp;nbsp;AI&amp;nbsp;Toolkit in VSCode and&amp;nbsp;run it all on-device,&amp;nbsp;taking advantage of&amp;nbsp;NPU hardware acceleration.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="looking-forward"&gt;Looking forward&lt;/h3&gt;



&lt;p&gt;Our current release&amp;nbsp;is an experimental CUA model&amp;nbsp;that achieves&amp;nbsp;state-of-the-art&amp;nbsp;results for its size,&amp;nbsp;purely using&amp;nbsp;supervised fine-tuning.&amp;nbsp;We believe even stronger CUA&amp;nbsp;models capable of running on-device are possible&amp;nbsp;through&amp;nbsp;improved&amp;nbsp;multimodal base models and through Reinforcement Learning&amp;nbsp;on&amp;nbsp;live and sandboxed environments.&amp;nbsp;These early days&amp;nbsp;are about learning from the community and driving real-world experimentation to shape what comes next.&amp;nbsp;If&amp;nbsp;you’d&amp;nbsp;like to join us and help shape the future of SLMs,&amp;nbsp;please&amp;nbsp;apply for open roles.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements:&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;We thank Gustavo de Rosa, Adam Fourney, Michael Harrison, Rafah Hosn, Neel Joshi, Ece Kamar, John Langford, Maya Murad, Sidhartha Sen, Pratyusha Sharma, and Lili Wu for their valuable help, insightful discussions, and continued support throughout this work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We also thank Pashmina Cameron, Karthik Vijayan, Vicente Rivera, Chris Dern, Sayan Shaw,&amp;nbsp;Sunghoon&amp;nbsp;Choi, Andrey&amp;nbsp;Rybalchenko, and Vivek Pradeep for their efforts in making the model available on Copilot+ PCs through the AI Toolkit.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/fara-7b-an-efficient-agentic-model-for-computer-use/</guid><pubDate>Mon, 24 Nov 2025 18:00:00 +0000</pubDate></item></channel></rss>