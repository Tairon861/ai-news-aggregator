<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 30 Jul 2025 06:37:27 +0000</lastBuildDate><item><title>Positron believes it has found the secret to take on Nvidia in AI inference chips — here’s how it could benefit enterprises (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/positron-believes-it-has-found-the-secret-to-take-on-nvidia-in-ai-inference-chips-heres-how-it-could-benefit-enterprises/</link><description>&lt;p&gt;As demand for large-scale AI deployment skyrockets, the lesser-known,&lt;strong&gt; private chip startup Positron is positioning itself as a direct challenger to market leader Nvidia &lt;/strong&gt;by offering dedicated, energy-efficient, memory-optimized inference chips aimed at relieving the industry’s mounting cost, power, and availability bottlenecks. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;“A key differentiator is our ability to run frontier AI models with better efficiency—achieving 2x to 5x performance per watt and dollar compared to Nvidia,” said Thomas Sohmers, Positron co-founder and CTO,&lt;/strong&gt; in a recent video call interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Obviously, that’s good news for big AI model providers, but Positron’s leadership contends it is helpful for many more enterprises beyond, including those using AI models in their workflows, not as service offerings to customers.&lt;/p&gt;&lt;p&gt;“We build chips that can be deployed in hundreds of existing data centers because they don’t require liquid cooling or extreme power densities,” &lt;strong&gt;pointed out Mitesh Agrawal, Positron’s CEO and the former chief operating officer of AI cloud inference provider Lambda&lt;/strong&gt;, also in the same video call interview with VentureBeat. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Venture capitalists and early users seem to agree.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Positron yesterday announced an oversubscribed $51.6 million Series A funding round&lt;/strong&gt;&amp;nbsp;led by Valor Equity Partners, Atreides Management and DFJ Growth, with support from Flume Ventures, Resilience Reserve, 1517 Fund and Unless.&lt;/p&gt;



&lt;p&gt;As for Positron’s early customer base, that includes both name-brand enterprises and companies operating in inference-heavy sectors. Confirmed deployments include the major security and cloud content networking provider &lt;strong&gt;Cloudflare&lt;/strong&gt;, which uses Positron’s Atlas hardware in its globally distributed, power-constrained data centers, and &lt;strong&gt;Parasail&lt;/strong&gt;, via its AI-native data infrastructure platform SnapServe. &lt;/p&gt;



&lt;p&gt;Beyond these, Positron reports adoption across several key verticals where efficient inference is critical, such as &lt;strong&gt;networking, gaming, content moderation, content delivery networks (CDNs), and Token-as-a-Service providers&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;These early users are reportedly drawn in by Atlas’s ability to deliver high throughput and lower power consumption without requiring specialized cooling or reworked infrastructure, making it an attractive drop-in option for AI workloads across enterprise environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-entering-a-challenging-market-that-is-decreasing-ai-model-size-and-increasing-efficiency"&gt;Entering a challenging market that is decreasing AI model size and increasing efficiency&lt;/h2&gt;



&lt;p&gt;But Positron is also entering a challenging market. &lt;em&gt;The Information&lt;/em&gt; just reported that r&lt;strong&gt;ival buzzy AI inference chip startup Groq&lt;/strong&gt; — &lt;strong&gt;where Sohmers previously worked as Director of Technology Strategy&lt;/strong&gt; — has reduced its 2025 revenue projection from $2 billion+ to $500 million,  highlighting just how volatile the AI hardware space can be. &lt;/p&gt;



&lt;p&gt;Even well-funded firms face headwinds as they compete for data center capacity and enterprise mindshare against entrenched GPU providers like Nvidia, not to mention the elephant in the room: the rise of more efficient, smaller large language models (LLMs) and specialized small language models (SLMs) that can even run on devices as small and low-powered as smartphones.&lt;/p&gt;



&lt;p&gt;Yet Positron’s leadership is for now embracing the trend and shrugging off the possible impacts on its growth trajectory.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“There’s always been this duality—lightweight applications on local devices and heavyweight processing in centralized infrastructure,” said Agrawal. “We believe both will keep growing.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Sohmers agreed, stating: “We see a future where every person might have a capable model on their phone, but those will still rely on large models in data centers to generate deeper insights.”&lt;/strong&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-atlas-is-an-inference-first-ai-chip"&gt;Atlas is an inference-first AI chip&lt;/h2&gt;



&lt;p&gt;While Nvidia GPUs helped catalyze the deep learning boom by accelerating model training, Positron argues that inference — the stage where models generate output in production — is now the true bottleneck. &lt;/p&gt;



&lt;p&gt;Its founders call it the most under-optimized part of the “AI stack,” especially for generative AI workloads that depend on fast, efficient model serving.&lt;/p&gt;



&lt;p&gt;Positron’s solution is &lt;strong&gt;Atlas, its first-generation inference accelerator built specifically to handle large transformer models. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Unlike general-purpose GPUs, Atlas is optimized for the unique memory and throughput needs of modern inference tasks. &lt;/p&gt;



&lt;p&gt;The company claims Atlas delivers 3.5x better performance per dollar and up to 66% lower power usage than Nvidia’s H100, while also achieving 93% memory bandwidth utilization—far above the typical 10–30% range seen in GPUs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-atlas-to-titan-supporting-multi-trillion-parameter-models"&gt;From Atlas to Titan, supporting multi-trillion parameter models&lt;/h2&gt;



&lt;p&gt;Launched just 15 months after founding — and with only $12.5 million in seed capital — Atlas is already shipping and in production.&lt;/p&gt;



&lt;p&gt; The system supports up to 0.5 trillion-parameter models in a single 2kW server and is compatible with Hugging Face transformer models via an OpenAI API-compatible endpoint.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Positron is now preparing to launch its next-generation platform, Titan, in 2026. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Built on custom-designed “Asimov” silicon, &lt;strong&gt;Titan will feature up to two terabytes of high-speed memory per accelerator and support models up to 16 trillion parameters&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;Today’s frontier models are in the hundred billions and single digit trillions of parameters, but newer models like OpenAI’s GPT-5 are presumed to be in the multi-trillions, and larger models are currently thought to be required to reach artificial general intelligence (AGI), AI that outperforms humans on most economically valuable work, and superintelligence, AI that exceeds the ability for humans to understand and control. &lt;/p&gt;



&lt;p&gt;Crucially, Titan is designed to operate with standard air cooling in conventional data center environments, avoiding the high-density, liquid-cooled configurations that next-gen GPUs increasingly require.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-engineering-for-efficiency-and-compatibility"&gt;Engineering for efficiency and compatibility&lt;/h2&gt;



&lt;p&gt;From the start, Positron designed its system to be a drop-in replacement, allowing customers to use existing model binaries without code rewrites. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“If a customer had to change their behavior or their actions in any way, shape or form, that was a barrier,” said Sohmers.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Sohmers explained that instead of building a complex compiler stack or rearchitecting software ecosystems, Positron focused narrowly on inference, designing hardware that ingests Nvidia-trained models directly.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“CUDA mode isn’t something to fight,” said Agrawal. “It’s an ecosystem to participate in.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This pragmatic approach helped the company ship its first product quickly, validate performance with real enterprise users, and secure significant follow-on investment. In addition, its focus on air cooling versus liquid cooling makes its Atlas chips the only option for some deployments. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“We’re focused entirely on purely air-cooled deployments… all these Nvidia Hopper- and Blackwell-based solutions going forward are required liquid cooling&lt;/strong&gt;… The only place you can put those racks are in data centers that are being newly built now in the middle of nowhere,” said Sohmers.&lt;/p&gt;



&lt;p&gt;All told, Positron’s ability to execute quickly and capital-efficiently has helped distinguish it in a crowded AI hardware market.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-memory-is-what-you-need"&gt;Memory is what you need&lt;/h2&gt;



&lt;p&gt;Sohmers and Agrawal point to a fundamental shift in AI workloads: from compute-bound convolutional neural networks to memory-bound transformer architectures. &lt;/p&gt;



&lt;p&gt;Whereas older models demanded high FLOPs (floating-point operations), modern transformers require massive memory capacity and bandwidth to run efficiently.&lt;/p&gt;



&lt;p&gt;While Nvidia and others continue to focus on compute scaling, Positron is betting on memory-first design. &lt;/p&gt;



&lt;p&gt;Sohmers noted that with transformer inference, the ratio of compute to memory operations flips to near 1:1, meaning that boosting memory utilization has a direct and dramatic impact on performance and power efficiency.&lt;/p&gt;



&lt;p&gt;With Atlas already outperforming contemporary GPUs on key efficiency metrics, Titan aims to take this further by offering the highest memory capacity per chip in the industry. &lt;/p&gt;



&lt;p&gt;At launch, Titan is expected to offer an order-of-magnitude increase over typical GPU memory configurations — without demanding specialized cooling or boutique networking setups.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-u-s-built-chips"&gt;U.S.-built chips&lt;/h2&gt;



&lt;p&gt;Positron’s production pipeline is proudly domestic. The company’s first-generation chips were fabricated in the U.S. using Intel facilities, with final server assembly and integration also based domestically. &lt;/p&gt;



&lt;p&gt;For the Asimov chip, fabrication will shift to TSMC, though the team is aiming to keep as much of the rest of the production chain in the U.S. as possible, depending on foundry capacity.&lt;/p&gt;



&lt;p&gt;Geopolitical resilience and supply chain stability are becoming key purchasing criteria for many customers — another reason Positron believes its U.S.-made hardware offers a compelling alternative.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;What’s next?&lt;/h2&gt;



&lt;p&gt;Agrawal noted that Positron’s silicon targets not just broad compatibility but maximum utility for enterprise, cloud, and research labs alike. &lt;/p&gt;



&lt;p&gt;While the company has not named any frontier model providers as customers yet, he confirmed that outreach and conversations are underway.&lt;/p&gt;



&lt;p&gt;Agrawal emphasized that selling physical infrastructure based on economics and performance—not bundling it with proprietary APIs or business models—is part of what gives Positron credibility in a skeptical market.&lt;/p&gt;



&lt;p&gt;“If you can’t convince a customer to deploy your hardware based on its economics, you’re not going to be profitable,” he said.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;As demand for large-scale AI deployment skyrockets, the lesser-known,&lt;strong&gt; private chip startup Positron is positioning itself as a direct challenger to market leader Nvidia &lt;/strong&gt;by offering dedicated, energy-efficient, memory-optimized inference chips aimed at relieving the industry’s mounting cost, power, and availability bottlenecks. &lt;/p&gt;&lt;p&gt;&lt;strong&gt;“A key differentiator is our ability to run frontier AI models with better efficiency—achieving 2x to 5x performance per watt and dollar compared to Nvidia,” said Thomas Sohmers, Positron co-founder and CTO,&lt;/strong&gt; in a recent video call interview with VentureBeat.&lt;/p&gt;&lt;p&gt;Obviously, that’s good news for big AI model providers, but Positron’s leadership contends it is helpful for many more enterprises beyond, including those using AI models in their workflows, not as service offerings to customers.&lt;/p&gt;&lt;p&gt;“We build chips that can be deployed in hundreds of existing data centers because they don’t require liquid cooling or extreme power densities,” &lt;strong&gt;pointed out Mitesh Agrawal, Positron’s CEO and the former chief operating officer of AI cloud inference provider Lambda&lt;/strong&gt;, also in the same video call interview with VentureBeat. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Venture capitalists and early users seem to agree.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Positron yesterday announced an oversubscribed $51.6 million Series A funding round&lt;/strong&gt;&amp;nbsp;led by Valor Equity Partners, Atreides Management and DFJ Growth, with support from Flume Ventures, Resilience Reserve, 1517 Fund and Unless.&lt;/p&gt;



&lt;p&gt;As for Positron’s early customer base, that includes both name-brand enterprises and companies operating in inference-heavy sectors. Confirmed deployments include the major security and cloud content networking provider &lt;strong&gt;Cloudflare&lt;/strong&gt;, which uses Positron’s Atlas hardware in its globally distributed, power-constrained data centers, and &lt;strong&gt;Parasail&lt;/strong&gt;, via its AI-native data infrastructure platform SnapServe. &lt;/p&gt;



&lt;p&gt;Beyond these, Positron reports adoption across several key verticals where efficient inference is critical, such as &lt;strong&gt;networking, gaming, content moderation, content delivery networks (CDNs), and Token-as-a-Service providers&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;These early users are reportedly drawn in by Atlas’s ability to deliver high throughput and lower power consumption without requiring specialized cooling or reworked infrastructure, making it an attractive drop-in option for AI workloads across enterprise environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-entering-a-challenging-market-that-is-decreasing-ai-model-size-and-increasing-efficiency"&gt;Entering a challenging market that is decreasing AI model size and increasing efficiency&lt;/h2&gt;



&lt;p&gt;But Positron is also entering a challenging market. &lt;em&gt;The Information&lt;/em&gt; just reported that r&lt;strong&gt;ival buzzy AI inference chip startup Groq&lt;/strong&gt; — &lt;strong&gt;where Sohmers previously worked as Director of Technology Strategy&lt;/strong&gt; — has reduced its 2025 revenue projection from $2 billion+ to $500 million,  highlighting just how volatile the AI hardware space can be. &lt;/p&gt;



&lt;p&gt;Even well-funded firms face headwinds as they compete for data center capacity and enterprise mindshare against entrenched GPU providers like Nvidia, not to mention the elephant in the room: the rise of more efficient, smaller large language models (LLMs) and specialized small language models (SLMs) that can even run on devices as small and low-powered as smartphones.&lt;/p&gt;



&lt;p&gt;Yet Positron’s leadership is for now embracing the trend and shrugging off the possible impacts on its growth trajectory.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“There’s always been this duality—lightweight applications on local devices and heavyweight processing in centralized infrastructure,” said Agrawal. “We believe both will keep growing.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Sohmers agreed, stating: “We see a future where every person might have a capable model on their phone, but those will still rely on large models in data centers to generate deeper insights.”&lt;/strong&gt;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-atlas-is-an-inference-first-ai-chip"&gt;Atlas is an inference-first AI chip&lt;/h2&gt;



&lt;p&gt;While Nvidia GPUs helped catalyze the deep learning boom by accelerating model training, Positron argues that inference — the stage where models generate output in production — is now the true bottleneck. &lt;/p&gt;



&lt;p&gt;Its founders call it the most under-optimized part of the “AI stack,” especially for generative AI workloads that depend on fast, efficient model serving.&lt;/p&gt;



&lt;p&gt;Positron’s solution is &lt;strong&gt;Atlas, its first-generation inference accelerator built specifically to handle large transformer models. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Unlike general-purpose GPUs, Atlas is optimized for the unique memory and throughput needs of modern inference tasks. &lt;/p&gt;



&lt;p&gt;The company claims Atlas delivers 3.5x better performance per dollar and up to 66% lower power usage than Nvidia’s H100, while also achieving 93% memory bandwidth utilization—far above the typical 10–30% range seen in GPUs.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-atlas-to-titan-supporting-multi-trillion-parameter-models"&gt;From Atlas to Titan, supporting multi-trillion parameter models&lt;/h2&gt;



&lt;p&gt;Launched just 15 months after founding — and with only $12.5 million in seed capital — Atlas is already shipping and in production.&lt;/p&gt;



&lt;p&gt; The system supports up to 0.5 trillion-parameter models in a single 2kW server and is compatible with Hugging Face transformer models via an OpenAI API-compatible endpoint.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Positron is now preparing to launch its next-generation platform, Titan, in 2026. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Built on custom-designed “Asimov” silicon, &lt;strong&gt;Titan will feature up to two terabytes of high-speed memory per accelerator and support models up to 16 trillion parameters&lt;/strong&gt;. &lt;/p&gt;



&lt;p&gt;Today’s frontier models are in the hundred billions and single digit trillions of parameters, but newer models like OpenAI’s GPT-5 are presumed to be in the multi-trillions, and larger models are currently thought to be required to reach artificial general intelligence (AGI), AI that outperforms humans on most economically valuable work, and superintelligence, AI that exceeds the ability for humans to understand and control. &lt;/p&gt;



&lt;p&gt;Crucially, Titan is designed to operate with standard air cooling in conventional data center environments, avoiding the high-density, liquid-cooled configurations that next-gen GPUs increasingly require.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-engineering-for-efficiency-and-compatibility"&gt;Engineering for efficiency and compatibility&lt;/h2&gt;



&lt;p&gt;From the start, Positron designed its system to be a drop-in replacement, allowing customers to use existing model binaries without code rewrites. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“If a customer had to change their behavior or their actions in any way, shape or form, that was a barrier,” said Sohmers.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Sohmers explained that instead of building a complex compiler stack or rearchitecting software ecosystems, Positron focused narrowly on inference, designing hardware that ingests Nvidia-trained models directly.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“CUDA mode isn’t something to fight,” said Agrawal. “It’s an ecosystem to participate in.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This pragmatic approach helped the company ship its first product quickly, validate performance with real enterprise users, and secure significant follow-on investment. In addition, its focus on air cooling versus liquid cooling makes its Atlas chips the only option for some deployments. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“We’re focused entirely on purely air-cooled deployments… all these Nvidia Hopper- and Blackwell-based solutions going forward are required liquid cooling&lt;/strong&gt;… The only place you can put those racks are in data centers that are being newly built now in the middle of nowhere,” said Sohmers.&lt;/p&gt;



&lt;p&gt;All told, Positron’s ability to execute quickly and capital-efficiently has helped distinguish it in a crowded AI hardware market.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-memory-is-what-you-need"&gt;Memory is what you need&lt;/h2&gt;



&lt;p&gt;Sohmers and Agrawal point to a fundamental shift in AI workloads: from compute-bound convolutional neural networks to memory-bound transformer architectures. &lt;/p&gt;



&lt;p&gt;Whereas older models demanded high FLOPs (floating-point operations), modern transformers require massive memory capacity and bandwidth to run efficiently.&lt;/p&gt;



&lt;p&gt;While Nvidia and others continue to focus on compute scaling, Positron is betting on memory-first design. &lt;/p&gt;



&lt;p&gt;Sohmers noted that with transformer inference, the ratio of compute to memory operations flips to near 1:1, meaning that boosting memory utilization has a direct and dramatic impact on performance and power efficiency.&lt;/p&gt;



&lt;p&gt;With Atlas already outperforming contemporary GPUs on key efficiency metrics, Titan aims to take this further by offering the highest memory capacity per chip in the industry. &lt;/p&gt;



&lt;p&gt;At launch, Titan is expected to offer an order-of-magnitude increase over typical GPU memory configurations — without demanding specialized cooling or boutique networking setups.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-u-s-built-chips"&gt;U.S.-built chips&lt;/h2&gt;



&lt;p&gt;Positron’s production pipeline is proudly domestic. The company’s first-generation chips were fabricated in the U.S. using Intel facilities, with final server assembly and integration also based domestically. &lt;/p&gt;



&lt;p&gt;For the Asimov chip, fabrication will shift to TSMC, though the team is aiming to keep as much of the rest of the production chain in the U.S. as possible, depending on foundry capacity.&lt;/p&gt;



&lt;p&gt;Geopolitical resilience and supply chain stability are becoming key purchasing criteria for many customers — another reason Positron believes its U.S.-made hardware offers a compelling alternative.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next"&gt;What’s next?&lt;/h2&gt;



&lt;p&gt;Agrawal noted that Positron’s silicon targets not just broad compatibility but maximum utility for enterprise, cloud, and research labs alike. &lt;/p&gt;



&lt;p&gt;While the company has not named any frontier model providers as customers yet, he confirmed that outreach and conversations are underway.&lt;/p&gt;



&lt;p&gt;Agrawal emphasized that selling physical infrastructure based on economics and performance—not bundling it with proprietary APIs or business models—is part of what gives Positron credibility in a skeptical market.&lt;/p&gt;



&lt;p&gt;“If you can’t convince a customer to deploy your hardware based on its economics, you’re not going to be profitable,” he said.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/positron-believes-it-has-found-the-secret-to-take-on-nvidia-in-ai-inference-chips-heres-how-it-could-benefit-enterprises/</guid><pubDate>Tue, 29 Jul 2025 18:45:40 +0000</pubDate></item><item><title>Anthropic reportedly nears $170B valuation with potential $5B round (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/29/anthropic-reportedly-nears-170b-valuation-with-potential-5b-round/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2153561878.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is nearing a deal to raise between $3 billion and $5 billion in funding, valuing the large language model developer at $170 billion, Bloomberg reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Iconiq Capital is leading this funding round, but there’s a possibility of a second lead investor joining the deal. The company has also been in talks with Qatar Investment Authority and GIC, Singapore’s sovereign wealth fund, according to the report.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If finalized, the deal would nearly triple Anthropic’s valuation, which was $61.5 billion after a $3.5 billion funding round led by Lightspeed Venture Partners announced in March. Other participants in the startup’s last round included Bessemer Venture Partners, Cisco Investments, D1 Capital Partners, Fidelity Management &amp;amp; Research Company, General Catalyst, Jane Street, Menlo Ventures, and Salesforce Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite Anthropic’s mission as a safety-conscious AI model developer, the company’s CEO, Dario Amodei, recently confessed in a memo to employees, reported by Wired, that he’s “not thrilled” about taking money from sovereign wealth funds of dictatorial governments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To keep pace with the massive capital requirements of developing AI models, the company has been forced to turn to Middle Eastern capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Unfortunately, I think ‘No bad person should ever benefit from our success’ is a pretty difficult principle to run a business on,” Amodei wrote in a leaked memo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic didn’t immediately respond to a request for comment.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2153561878.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is nearing a deal to raise between $3 billion and $5 billion in funding, valuing the large language model developer at $170 billion, Bloomberg reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Iconiq Capital is leading this funding round, but there’s a possibility of a second lead investor joining the deal. The company has also been in talks with Qatar Investment Authority and GIC, Singapore’s sovereign wealth fund, according to the report.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If finalized, the deal would nearly triple Anthropic’s valuation, which was $61.5 billion after a $3.5 billion funding round led by Lightspeed Venture Partners announced in March. Other participants in the startup’s last round included Bessemer Venture Partners, Cisco Investments, D1 Capital Partners, Fidelity Management &amp;amp; Research Company, General Catalyst, Jane Street, Menlo Ventures, and Salesforce Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite Anthropic’s mission as a safety-conscious AI model developer, the company’s CEO, Dario Amodei, recently confessed in a memo to employees, reported by Wired, that he’s “not thrilled” about taking money from sovereign wealth funds of dictatorial governments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To keep pace with the massive capital requirements of developing AI models, the company has been forced to turn to Middle Eastern capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Unfortunately, I think ‘No bad person should ever benefit from our success’ is a pretty difficult principle to run a business on,” Amodei wrote in a leaked memo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic didn’t immediately respond to a request for comment.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/29/anthropic-reportedly-nears-170b-valuation-with-potential-5b-round/</guid><pubDate>Tue, 29 Jul 2025 18:59:36 +0000</pubDate></item><item><title>Luma and Runway expect robotics to eventually be a big revenue driver for them (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/29/luma-and-runway-expect-robotics-to-eventually-be-a-big-revenue-driver-for-them/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/06/GettyImages-1474076387.jpg?resize=1200,768" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI video-generating startups Luma and Runway are looking beyond movie studios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These video-generating AI companies have their sights set on other markets for future revenue streams and have been in talks with both robotics and self-driving car companies, according to reporting from The Information. The report didn’t identify which companies Luma and Runway are in talks with.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This potential revenue stream makes sense for Luma in particular. The company announced it was looking to build 3D AI world models in early 2024 with the goal of having these models understand how to see and interact with the world around them, TechCrunch reported at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Runway is also targeting video games as a potential future revenue stream, too, according to The Information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Luma and Runway for more information.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/06/GettyImages-1474076387.jpg?resize=1200,768" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI video-generating startups Luma and Runway are looking beyond movie studios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These video-generating AI companies have their sights set on other markets for future revenue streams and have been in talks with both robotics and self-driving car companies, according to reporting from The Information. The report didn’t identify which companies Luma and Runway are in talks with.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This potential revenue stream makes sense for Luma in particular. The company announced it was looking to build 3D AI world models in early 2024 with the goal of having these models understand how to see and interact with the world around them, TechCrunch reported at the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Runway is also targeting video games as a potential future revenue stream, too, according to The Information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch reached out to Luma and Runway for more information.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/29/luma-and-runway-expect-robotics-to-eventually-be-a-big-revenue-driver-for-them/</guid><pubDate>Tue, 29 Jul 2025 20:12:43 +0000</pubDate></item><item><title>“FUTURE PHASES” showcases new frontiers in music technology and interactive performance (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/future-phases-showcase-new-frontiers-music-technology-interactive-performance-0729</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT-MTA-6-13-25-335_0.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Music technology took center stage at MIT during “FUTURE PHASES,” an evening of works for string orchestra and electronics, presented by the&amp;nbsp;MIT Music Technology and Computation Graduate Program as part of the 2025 International Computer Music Conference (ICMC).&amp;nbsp;&lt;/p&gt;&lt;p&gt;The well-attended event was held last month in the Thomas Tull Concert Hall within the new Edward and Joyce Linde Music Building. Produced in collaboration with the MIT Media Lab’s Opera of the Future Group and Boston’s self-conducted chamber orchestra A Far Cry, “FUTURE PHASES” was the first event to be presented by the MIT Music Technology and Computation Graduate Program in MIT Music’s new space.&lt;/p&gt;&lt;p&gt;“FUTURE PHASES” offerings included two new works by MIT composers: the world premiere of&amp;nbsp;“EV6,” by MIT Music’s Kenan Sahin Distinguished Professor Evan Ziporyn and professor of the practice Eran Egozy; and the U.S. premiere of&amp;nbsp;“FLOW Symphony,” by the MIT Media Lab’s Muriel R. Cooper Professor of Music and Media Tod Machover. Three additional works were selected by a jury from&amp;nbsp;an open call for works:&amp;nbsp;“The Wind Will Carry Us Away,” by Ali Balighi; “A Blank Page,” by Celeste Betancur&amp;nbsp;Gutiérrez and Luna Valentin; and “Coastal Portrait: Cycles and Thresholds,”&amp;nbsp;by Peter Lane. Each work was performed by&amp;nbsp;Boston’s own&amp;nbsp;multi-Grammy-nominated string orchestra, A Far Cry.&lt;/p&gt;&lt;p&gt;“The ICMC is all about presenting the latest research, compositions, and performances in electronic music,” says Egozy,&amp;nbsp;director of the new Music Technology and Computation Graduate Program at MIT. When approached to be a part of this year’s conference, “it seemed the perfect opportunity to showcase MIT’s commitment&amp;nbsp;to music technology, and in particular the exciting new areas being developed right now: a new master’s program in music technology and computation, the new Edward and Joyce Linde Music Building with its enhanced music technology facilities, and new faculty arriving at MIT with joint appointments between MIT Music and Theater Arts (MTA) and the Department of Electrical Engineering and Computer Science (EECS).” These recently hired professors include Anna Huang, a keynote speaker for the conference and creator of the machine learning model&amp;nbsp;Coconet that powered Google’s first AI Doodle, the Bach Doodle.&lt;/p&gt;&lt;p&gt;Egozy emphasizes the uniqueness of this occasion: “You have to understand that this is a very special situation. Having a full 18-member string orchestra [A Far Cry] perform new works that include electronics does not happen very often. In most cases, ICMC performances consist either entirely of electronics and computer-generated music, or perhaps a small ensemble of two-to-four musicians. So the opportunity we could present to the larger community of music technology was particularly exciting.”&lt;/p&gt;&lt;p&gt;To take advantage of this exciting opportunity, an open call was put out internationally to select the other pieces that would accompany Ziporyn and Egozy’s “EV6” and Machover’s “FLOW Symphony.” Three pieces were selected from a total of 46 entries to be a part of the evening’s program by a panel of judges that included Egozy, Machover, and other distinguished composers and technologists.&lt;/p&gt;&lt;p&gt;“We received a huge variety of works from this call,” says Egozy. “We saw all kinds of musical styles and ways that electronics would be used. No two pieces were very similar to each other, and I think because of that, our audience got a sense of how varied and interesting a concert can be for this format. A Far Cry was really the unifying presence. They played all pieces with great passion and nuance. They have a way of really drawing audiences into the music. And, of course, with the Thomas Tull Concert Hall being in the round, the audience felt even more connected to the music.”&lt;/p&gt;&lt;p&gt;Egozy continues, “we took advantage of the technology built into the Thomas Tull Concert Hall, which has 24 built-in speakers for surround sound allowing us to broadcast unique, amplified sound to every seat in the house. Chances are that every person might have experienced the sound slightly differently, but there was always some sense of a multidimensional evolution of sound and music as the pieces unfolded.”&lt;/p&gt;&lt;p&gt;The five works of the evening employed a range of technological components that included playing synthesized, prerecorded, or electronically manipulated sounds; attaching microphones to instruments for use in real-time signal processing algorithms; broadcasting custom-generated musical notation to&amp;nbsp;the musicians; utilizing generative AI to process live sound and play it back in interesting and unpredictable ways; and audience participation, where spectators use their cellphones as musical instruments to become a part of the ensemble.&lt;/p&gt;&lt;p&gt;Ziporyn and Egozy’s piece, “EV6&lt;em&gt;,”&lt;/em&gt; took particular advantage of this last innovation: “Evan and I had previously collaborated on a system called&amp;nbsp;Tutti, which means ‘together’ in Italian. Tutti gives an audience the ability to use their smartphones as musical instruments so that we can all play together.” Egozy developed the technology, which was first used in the MIT Campaign for a Better World in 2017. The original application involved a three-minute piece for cellphones only. “But for this concert,” Egozy explains, “Evan had the idea that we could use the same technology to write a new piece — this time, for audience phones and a live string orchestra as well.”&lt;/p&gt;&lt;p&gt;To explain the piece’s title, Ziporyn says, “I drive an EV6; it’s my first electric car, and when I first got it, it felt like I was driving an iPhone. But of course it’s still just a car: it’s got wheels and an engine, and it gets me from one place to another. It seemed like a good metaphor for this piece, in which a lot of the sound is literally played on cellphones, but still has to work like any other piece of music. It’s also a bit of an homage to David Bowie’s song ‘TVC 15,’ which is about falling in love with a robot.”&lt;/p&gt;&lt;p&gt;Egozy adds, “We wanted audience members to feel what it is like to play together in an orchestra. Through this technology, each audience member becomes a part of an orchestral section (winds, brass, strings, etc.). As they play together, they can hear their whole section playing similar music while also hearing other sections in different parts of the hall play different music. This allows an audience to feel a responsibility to their section, hear how music can move between different sections of an orchestra, and experience the thrill of live performance. In ‘EV6,’ this experience was even more electrifying because everyone in the audience got to play with a live string orchestra — perhaps for the first time in recorded history.”&lt;/p&gt;&lt;p&gt;After the concert, guests were treated to six music technology demonstrations that showcased the research of undergraduate and graduate students from both the MIT Music program and the MIT Media Lab. These included a gamified interface for harnessing just intonation systems (Antonis Christou); insights from a human-AI co-created concert (Lancelot Blanchard and Perry Naseck); a system for analyzing piano playing data across campus (Ayyub Abdulrezak ’24, MEng ’25); capturing music features from audio using latent frequency-masked autoencoders (Mason Wang); a device that turns any surface into a drum machine (Matthew Caren ’25); and a play-along interface for learning traditional Senegalese rhythms (Mariano Salcedo ’25). This last example led to the creation of Senegroove, a drumming-based application specifically designed for an upcoming edX online course taught by ethnomusicologist and MIT associate professor in music Patricia Tang, and world-renowned Senegalese drummer and MIT lecturer in music Lamine Touré, who provided performance videos of the foundational rhythms used in the system.&lt;/p&gt;&lt;p&gt;Ultimately, Egozy muses, “'FUTURE PHASES' showed how having the right space — in this case, the new Edward and Joyce Linde Music Building — really can be a driving force for new ways of thinking, new projects, and new ways of collaborating. My hope is that everyone in the MIT community, the Boston area, and beyond soon discovers what a truly amazing place and space we have built, and are still building here, for music and music technology at MIT.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT-MTA-6-13-25-335_0.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Music technology took center stage at MIT during “FUTURE PHASES,” an evening of works for string orchestra and electronics, presented by the&amp;nbsp;MIT Music Technology and Computation Graduate Program as part of the 2025 International Computer Music Conference (ICMC).&amp;nbsp;&lt;/p&gt;&lt;p&gt;The well-attended event was held last month in the Thomas Tull Concert Hall within the new Edward and Joyce Linde Music Building. Produced in collaboration with the MIT Media Lab’s Opera of the Future Group and Boston’s self-conducted chamber orchestra A Far Cry, “FUTURE PHASES” was the first event to be presented by the MIT Music Technology and Computation Graduate Program in MIT Music’s new space.&lt;/p&gt;&lt;p&gt;“FUTURE PHASES” offerings included two new works by MIT composers: the world premiere of&amp;nbsp;“EV6,” by MIT Music’s Kenan Sahin Distinguished Professor Evan Ziporyn and professor of the practice Eran Egozy; and the U.S. premiere of&amp;nbsp;“FLOW Symphony,” by the MIT Media Lab’s Muriel R. Cooper Professor of Music and Media Tod Machover. Three additional works were selected by a jury from&amp;nbsp;an open call for works:&amp;nbsp;“The Wind Will Carry Us Away,” by Ali Balighi; “A Blank Page,” by Celeste Betancur&amp;nbsp;Gutiérrez and Luna Valentin; and “Coastal Portrait: Cycles and Thresholds,”&amp;nbsp;by Peter Lane. Each work was performed by&amp;nbsp;Boston’s own&amp;nbsp;multi-Grammy-nominated string orchestra, A Far Cry.&lt;/p&gt;&lt;p&gt;“The ICMC is all about presenting the latest research, compositions, and performances in electronic music,” says Egozy,&amp;nbsp;director of the new Music Technology and Computation Graduate Program at MIT. When approached to be a part of this year’s conference, “it seemed the perfect opportunity to showcase MIT’s commitment&amp;nbsp;to music technology, and in particular the exciting new areas being developed right now: a new master’s program in music technology and computation, the new Edward and Joyce Linde Music Building with its enhanced music technology facilities, and new faculty arriving at MIT with joint appointments between MIT Music and Theater Arts (MTA) and the Department of Electrical Engineering and Computer Science (EECS).” These recently hired professors include Anna Huang, a keynote speaker for the conference and creator of the machine learning model&amp;nbsp;Coconet that powered Google’s first AI Doodle, the Bach Doodle.&lt;/p&gt;&lt;p&gt;Egozy emphasizes the uniqueness of this occasion: “You have to understand that this is a very special situation. Having a full 18-member string orchestra [A Far Cry] perform new works that include electronics does not happen very often. In most cases, ICMC performances consist either entirely of electronics and computer-generated music, or perhaps a small ensemble of two-to-four musicians. So the opportunity we could present to the larger community of music technology was particularly exciting.”&lt;/p&gt;&lt;p&gt;To take advantage of this exciting opportunity, an open call was put out internationally to select the other pieces that would accompany Ziporyn and Egozy’s “EV6” and Machover’s “FLOW Symphony.” Three pieces were selected from a total of 46 entries to be a part of the evening’s program by a panel of judges that included Egozy, Machover, and other distinguished composers and technologists.&lt;/p&gt;&lt;p&gt;“We received a huge variety of works from this call,” says Egozy. “We saw all kinds of musical styles and ways that electronics would be used. No two pieces were very similar to each other, and I think because of that, our audience got a sense of how varied and interesting a concert can be for this format. A Far Cry was really the unifying presence. They played all pieces with great passion and nuance. They have a way of really drawing audiences into the music. And, of course, with the Thomas Tull Concert Hall being in the round, the audience felt even more connected to the music.”&lt;/p&gt;&lt;p&gt;Egozy continues, “we took advantage of the technology built into the Thomas Tull Concert Hall, which has 24 built-in speakers for surround sound allowing us to broadcast unique, amplified sound to every seat in the house. Chances are that every person might have experienced the sound slightly differently, but there was always some sense of a multidimensional evolution of sound and music as the pieces unfolded.”&lt;/p&gt;&lt;p&gt;The five works of the evening employed a range of technological components that included playing synthesized, prerecorded, or electronically manipulated sounds; attaching microphones to instruments for use in real-time signal processing algorithms; broadcasting custom-generated musical notation to&amp;nbsp;the musicians; utilizing generative AI to process live sound and play it back in interesting and unpredictable ways; and audience participation, where spectators use their cellphones as musical instruments to become a part of the ensemble.&lt;/p&gt;&lt;p&gt;Ziporyn and Egozy’s piece, “EV6&lt;em&gt;,”&lt;/em&gt; took particular advantage of this last innovation: “Evan and I had previously collaborated on a system called&amp;nbsp;Tutti, which means ‘together’ in Italian. Tutti gives an audience the ability to use their smartphones as musical instruments so that we can all play together.” Egozy developed the technology, which was first used in the MIT Campaign for a Better World in 2017. The original application involved a three-minute piece for cellphones only. “But for this concert,” Egozy explains, “Evan had the idea that we could use the same technology to write a new piece — this time, for audience phones and a live string orchestra as well.”&lt;/p&gt;&lt;p&gt;To explain the piece’s title, Ziporyn says, “I drive an EV6; it’s my first electric car, and when I first got it, it felt like I was driving an iPhone. But of course it’s still just a car: it’s got wheels and an engine, and it gets me from one place to another. It seemed like a good metaphor for this piece, in which a lot of the sound is literally played on cellphones, but still has to work like any other piece of music. It’s also a bit of an homage to David Bowie’s song ‘TVC 15,’ which is about falling in love with a robot.”&lt;/p&gt;&lt;p&gt;Egozy adds, “We wanted audience members to feel what it is like to play together in an orchestra. Through this technology, each audience member becomes a part of an orchestral section (winds, brass, strings, etc.). As they play together, they can hear their whole section playing similar music while also hearing other sections in different parts of the hall play different music. This allows an audience to feel a responsibility to their section, hear how music can move between different sections of an orchestra, and experience the thrill of live performance. In ‘EV6,’ this experience was even more electrifying because everyone in the audience got to play with a live string orchestra — perhaps for the first time in recorded history.”&lt;/p&gt;&lt;p&gt;After the concert, guests were treated to six music technology demonstrations that showcased the research of undergraduate and graduate students from both the MIT Music program and the MIT Media Lab. These included a gamified interface for harnessing just intonation systems (Antonis Christou); insights from a human-AI co-created concert (Lancelot Blanchard and Perry Naseck); a system for analyzing piano playing data across campus (Ayyub Abdulrezak ’24, MEng ’25); capturing music features from audio using latent frequency-masked autoencoders (Mason Wang); a device that turns any surface into a drum machine (Matthew Caren ’25); and a play-along interface for learning traditional Senegalese rhythms (Mariano Salcedo ’25). This last example led to the creation of Senegroove, a drumming-based application specifically designed for an upcoming edX online course taught by ethnomusicologist and MIT associate professor in music Patricia Tang, and world-renowned Senegalese drummer and MIT lecturer in music Lamine Touré, who provided performance videos of the foundational rhythms used in the system.&lt;/p&gt;&lt;p&gt;Ultimately, Egozy muses, “'FUTURE PHASES' showed how having the right space — in this case, the new Edward and Joyce Linde Music Building — really can be a driving force for new ways of thinking, new projects, and new ways of collaborating. My hope is that everyone in the MIT community, the Boston area, and beyond soon discovers what a truly amazing place and space we have built, and are still building here, for music and music technology at MIT.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/future-phases-showcase-new-frontiers-music-technology-interactive-performance-0729</guid><pubDate>Tue, 29 Jul 2025 21:00:00 +0000</pubDate></item><item><title>AI in Wyoming may soon use more electricity than state’s human residents (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/07/ai-in-wyoming-may-soon-use-more-electricity-than-states-human-residents/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Proposed datacenter would demand 5x Wyoming's current power use at full deployment.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/delivs_tower_1-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/delivs_tower_1-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, Mayor Patrick Collins of Cheyenne, Wyoming, announced plans for an AI data center that would consume more electricity than all homes in the state combined, according to the Associated Press. The facility, a joint venture between energy infrastructure company Tallgrass and AI data center developer Crusoe, would start at 1.8 gigawatts and scale up to 10 gigawatts of power use.&lt;/p&gt;
&lt;p&gt;The project's energy demands are difficult to overstate for Wyoming, the least populous US state. The initial 1.8-gigawatt phase, consuming 15.8 terawatt-hours (TWh) annually, is more than five times the electricity used by every household in the state combined. That figure represents 91 percent of the 17.3 TWh currently consumed by all of Wyoming's residential, commercial, and industrial sectors combined. At its full 10-gigawatt capacity, the proposed data center would consume 87.6 TWh of electricity annually—double the 43.2 TWh the entire state currently generates.&lt;/p&gt;
&lt;p&gt;Because drawing this much power from the public grid is untenable, the project will rely on its own dedicated gas generation and renewable energy sources, according to Collins and company officials. However, this massive local demand for electricity—even if self-generated—represents a fundamental shift for a state that currently sends nearly 60 percent of its generated power to other states.&lt;/p&gt;
&lt;p&gt;Wyoming Governor Mark Gordon praised the project's potential benefits for the state's natural gas industry in a company statement. "This is exciting news for Wyoming and for Wyoming natural gas producers," Gordon said.&lt;/p&gt;
&lt;p&gt;The proposed site for the new datacenter sits several miles south of Cheyenne near the Colorado border off US Route 85. While state and local regulators still need to approve the project, Collins expressed optimism about a quick start. "I believe their plans are to go sooner rather than later," he said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Wyoming’s data center boom&lt;/h2&gt;
&lt;p&gt;Cheyenne is no stranger to data centers, having attracted facilities from Microsoft and Meta since 2012 due to its cool climate and energy access. However, the new project pushes the state into uncharted territory. While Wyoming is the nation's third-biggest net energy supplier, producing 12 times more total energy than it consumes (dominated by fossil fuels), its electricity supply is finite.&lt;/p&gt;
&lt;p&gt;While Tallgrass and Crusoe have announced the partnership, they haven't revealed who will ultimately use all this computing power—leading to speculation about potential tenants.&lt;/p&gt;
&lt;p&gt;A potential connection to OpenAI's Stargate AI infrastructure project, announced in January, remains a subject of speculation. When asked by the Associated Press if the Cheyenne project was part of this effort, Crusoe spokesperson Andrew Schmitt was noncommittal. "We are not at a stage that we are ready to announce our tenant there," Schmitt said. "I can't confirm or deny that is going to be one of the Stargate."&lt;/p&gt;
&lt;p&gt;OpenAI recently activated the first phase of a Crusoe-built data center complex in Abilene, Texas, in partnership with Oracle. Chris Lehane, OpenAI's chief global affairs officer, told the Associated Press last week that the Texas facility generates "roughly and depending how you count, about a gigawatt of energy" and represents "the largest data center—we think of it as a campus—in the world."&lt;/p&gt;
&lt;p&gt;OpenAI has committed to developing an additional 4.5 gigawatts of data center capacity through an agreement with Oracle. "We're now in a position where we have, in a really concrete way, identified over five gigawatts of energy that we're going to be able to build around," Lehane told the AP. The company has not disclosed locations for these expansions, and Wyoming was not among the 16 states where OpenAI said it was searching for data center sites earlier this year.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;


  &lt;div class="listing-credit my-2"&gt;
    &lt;p class="text-gray-350 font-impact text-sm font-semibold"&gt;
    Listing image:
    
      Greg Meland via Getty Images
    
  &lt;/p&gt;
  &lt;/div&gt;




  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Proposed datacenter would demand 5x Wyoming's current power use at full deployment.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/delivs_tower_1-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/delivs_tower_1-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, Mayor Patrick Collins of Cheyenne, Wyoming, announced plans for an AI data center that would consume more electricity than all homes in the state combined, according to the Associated Press. The facility, a joint venture between energy infrastructure company Tallgrass and AI data center developer Crusoe, would start at 1.8 gigawatts and scale up to 10 gigawatts of power use.&lt;/p&gt;
&lt;p&gt;The project's energy demands are difficult to overstate for Wyoming, the least populous US state. The initial 1.8-gigawatt phase, consuming 15.8 terawatt-hours (TWh) annually, is more than five times the electricity used by every household in the state combined. That figure represents 91 percent of the 17.3 TWh currently consumed by all of Wyoming's residential, commercial, and industrial sectors combined. At its full 10-gigawatt capacity, the proposed data center would consume 87.6 TWh of electricity annually—double the 43.2 TWh the entire state currently generates.&lt;/p&gt;
&lt;p&gt;Because drawing this much power from the public grid is untenable, the project will rely on its own dedicated gas generation and renewable energy sources, according to Collins and company officials. However, this massive local demand for electricity—even if self-generated—represents a fundamental shift for a state that currently sends nearly 60 percent of its generated power to other states.&lt;/p&gt;
&lt;p&gt;Wyoming Governor Mark Gordon praised the project's potential benefits for the state's natural gas industry in a company statement. "This is exciting news for Wyoming and for Wyoming natural gas producers," Gordon said.&lt;/p&gt;
&lt;p&gt;The proposed site for the new datacenter sits several miles south of Cheyenne near the Colorado border off US Route 85. While state and local regulators still need to approve the project, Collins expressed optimism about a quick start. "I believe their plans are to go sooner rather than later," he said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Wyoming’s data center boom&lt;/h2&gt;
&lt;p&gt;Cheyenne is no stranger to data centers, having attracted facilities from Microsoft and Meta since 2012 due to its cool climate and energy access. However, the new project pushes the state into uncharted territory. While Wyoming is the nation's third-biggest net energy supplier, producing 12 times more total energy than it consumes (dominated by fossil fuels), its electricity supply is finite.&lt;/p&gt;
&lt;p&gt;While Tallgrass and Crusoe have announced the partnership, they haven't revealed who will ultimately use all this computing power—leading to speculation about potential tenants.&lt;/p&gt;
&lt;p&gt;A potential connection to OpenAI's Stargate AI infrastructure project, announced in January, remains a subject of speculation. When asked by the Associated Press if the Cheyenne project was part of this effort, Crusoe spokesperson Andrew Schmitt was noncommittal. "We are not at a stage that we are ready to announce our tenant there," Schmitt said. "I can't confirm or deny that is going to be one of the Stargate."&lt;/p&gt;
&lt;p&gt;OpenAI recently activated the first phase of a Crusoe-built data center complex in Abilene, Texas, in partnership with Oracle. Chris Lehane, OpenAI's chief global affairs officer, told the Associated Press last week that the Texas facility generates "roughly and depending how you count, about a gigawatt of energy" and represents "the largest data center—we think of it as a campus—in the world."&lt;/p&gt;
&lt;p&gt;OpenAI has committed to developing an additional 4.5 gigawatts of data center capacity through an agreement with Oracle. "We're now in a position where we have, in a really concrete way, identified over five gigawatts of energy that we're going to be able to build around," Lehane told the AP. The company has not disclosed locations for these expansions, and Wyoming was not among the 16 states where OpenAI said it was searching for data center sites earlier this year.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;


  &lt;div class="listing-credit my-2"&gt;
    &lt;p class="text-gray-350 font-impact text-sm font-semibold"&gt;
    Listing image:
    
      Greg Meland via Getty Images
    
  &lt;/p&gt;
  &lt;/div&gt;




  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/07/ai-in-wyoming-may-soon-use-more-electricity-than-states-human-residents/</guid><pubDate>Tue, 29 Jul 2025 21:24:16 +0000</pubDate></item><item><title>Acree opens up new enterprise-focused, customizable AI model AFM-4.5B trained on ‘clean, rigorously filtered data’ (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/acree-opens-up-new-enterprise-focused-customizable-ai-model-afm-4-5b-trained-on-clean-rigorously-filtered-data/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Designed for real-world enterprise use, the 4.5-billion-parameter model — much smaller than the tens of billions to trillions of leading frontier models — combines cost efficiency, regulatory compliance, and strong performance in a compact footprint. &lt;/p&gt;&lt;p&gt;AFM-4.5B was one of a two part release made by Acree last month, and is already “instruction tuned,” or an “instruct” model, which is designed for chat, retrieval, and creative writing and can be deployed immediately for these use cases in enterprises. Another base model was also released at the time that was not instruction tuned, only pre-trained, allowing more customizability by customers. However, both were only available through commercial licensing terms — until now.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Acree’s chief technology officer (CTO) Lucas Atkins&lt;/strong&gt; also noted in a post on X that more &lt;strong&gt;“dedicated models for reasoning and tool use are on the way,” as well. &lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“Building AFM-4.5B has been a huge team effort, and we’re deeply grateful to everyone who supported us We can’t wait to see what you build with it,” he wrote in another post. “We’re just getting started. If you have feedback or ideas, please don’t hesitate to reach out at any time.”&lt;/p&gt;



&lt;p&gt;The model is available now for deployment across a variety of environments —from cloud to smartphones to edge hardware. &lt;/p&gt;



&lt;p&gt;It’s also geared toward Acree’s growing list of enterprise customers and their needs and wants — specifically, a model trained without violating intellectual property. &lt;/p&gt;



&lt;p&gt;As Acree wrote in its initial AFM-4.5B announcement post last month: “Tremendous effort was put towards excluding copyrighted books and material with unclear licensing.” &lt;/p&gt;



&lt;p&gt;Acree notes it worked with third-party data curation firm DatologyAI to apply techniques like source mixing, embedding-based filtering, and quality control — all aimed at minimizing hallucinations and IP risks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-focused-on-enterprise-customer-needs"&gt;Focused on enterprise customer needs&lt;/h2&gt;



&lt;p&gt;AFM-4.5B is Arcee.ai’s response to what it sees as major pain points in enterprise adoption of generative AI: high cost, limited customizability, and regulatory concerns around proprietary large language models (LLMs). &lt;/p&gt;



&lt;p&gt;Over the past year, the Arcee team held discussions with more than 150 organizations, ranging from startups to Fortune 100 companies, to understand the limitations of existing LLMs and define their own model goals.&lt;/p&gt;



&lt;p&gt;According to the company, many businesses found mainstream LLMs — such as those from OpenAI, Anthropic, or DeepSeek — too expensive and difficult to tailor to industry-specific needs. Meanwhile, while smaller open-weight models like Llama, Mistral, and Qwen offered more flexibility, they introduced concerns around licensing, IP provenance, and geopolitical risk.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFM-4.5B was developed as a “no-trade-offs” alternative: customizable, compliant, and cost-efficient without sacrificing model quality or usability.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;AFM-4.5B is designed with deployment flexibility in mind. It can operate in cloud, on-premise, hybrid, or even edge environments—thanks to its efficiency and compatibility with open frameworks such as Hugging Face Transformers, llama.cpp, and (pending release) vLLM. &lt;/p&gt;



&lt;p&gt;The model supports quantized formats, allowing it to run on lower-RAM GPUs or even CPUs, making it practical for applications with constrained resources.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-company-vision-secures-backing"&gt;Company vision secures backing&lt;/h2&gt;



&lt;p&gt;Arcee.ai’s broader strategy focuses on building domain-adaptable, small language models (SLMs) that can power &lt;strong&gt;many use cases within the same organization. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;As CEO Mark McQuade explained in a VentureBeat interview last year, “You don’t need to go that big for business use cases.” The company emphasizes fast iteration and model customization as core to its offering.&lt;/p&gt;



&lt;p&gt;This vision gained investor backing with a $24 million Series A round back in 2024. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-afm-4-5b-s-architecture-and-training-process"&gt;Inside AFM-4.5B’s architecture and training process&lt;/h2&gt;



&lt;p&gt;The AFM-4.5B model uses a decoder-only transformer architecture with several optimizations for performance and deployment flexibility. &lt;/p&gt;



&lt;p&gt;It incorporates grouped query attention for faster inference and ReLU² activations in place of SwiGLU to support sparsification without degrading accuracy.&lt;/p&gt;



&lt;p&gt;Training followed a three-phase approach:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Pretraining on 6.5 trillion tokens of general data&lt;/li&gt;



&lt;li&gt;Midtraining on 1.5 trillion tokens emphasizing math and code&lt;/li&gt;



&lt;li&gt;Instruction tuning using high-quality instruction-following datasets and reinforcement learning with verifiable and preference-based feedback&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;To meet strict compliance and IP standards, the model was trained on nearly 7 trillion tokens of data curated for cleanliness and licensing safety. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-competitive-model-but-not-a-leader"&gt;A competitive model, but not a leader&lt;/h2&gt;



&lt;p&gt;Despite its smaller size, AFM-4.5B performs competitively across a broad range of benchmarks. The instruction-tuned version averages a score of 50.13 across evaluation suites such as MMLU, MixEval, TriviaQA, and Agieval—matching or outperforming similar-sized models like Gemma-3 4B-it, Qwen3-4B, and SmolLM3-3B.&lt;/p&gt;



&lt;p&gt;Multilingual testing shows the model delivers strong performance across more than 10 languages, including Arabic, Mandarin, German, and Portuguese. &lt;/p&gt;



&lt;p&gt;According to Arcee, adding support for additional dialects is straightforward due to its modular architecture.&lt;/p&gt;



&lt;p&gt;AFM-4.5B has also shown strong early traction in public evaluation environments. In a leaderboard that ranks conversational model quality by user votes and win rate, the model ranks third overall, trailing only Claude Opus 4 and Gemini 2.5 Pro. &lt;/p&gt;



&lt;p&gt;It boasts a win rate of 59.2% and the fastest latency of any top model at 0.2 seconds, paired with a generation speed of 179 tokens per second.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-built-in-support-for-agents"&gt;Built-in support for agents&lt;/h2&gt;



&lt;p&gt;In addition to general capabilities, AFM-4.5B comes with built-in support for function calling and agentic reasoning. &lt;/p&gt;



&lt;p&gt;These &lt;strong&gt;features aim to simplify the process of building AI agents and workflow automation tools&lt;/strong&gt;, reducing the need for complex prompt engineering or orchestration layers.&lt;/p&gt;



&lt;p&gt;This functionality aligns with Arcee’s broader strategy of enabling enterprises to build custom, production-ready models faster, with lower total cost of ownership (TCO) and easier integration into business operations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next-for-acree"&gt;What’s next for Acree?&lt;/h2&gt;



&lt;p&gt;AFM-4.5B represents &lt;strong&gt;Arcee.ai’s push to define a new category of enterprise-ready language models: small, performant, and fully customizable,&lt;/strong&gt; without the compromises that often come with either proprietary LLMs or open-weight SLMs. &lt;/p&gt;



&lt;p&gt;With competitive benchmarks, multilingual support, strong compliance standards, and flexible deployment options, the model aims to meet enterprise needs for speed, sovereignty, and scale.&lt;/p&gt;



&lt;p&gt;Whether Arcee can carve out a lasting role in the rapidly shifting generative AI landscape will depend on its ability to deliver on this promise. But with AFM-4.5B, the company has made a confident first move.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Designed for real-world enterprise use, the 4.5-billion-parameter model — much smaller than the tens of billions to trillions of leading frontier models — combines cost efficiency, regulatory compliance, and strong performance in a compact footprint. &lt;/p&gt;&lt;p&gt;AFM-4.5B was one of a two part release made by Acree last month, and is already “instruction tuned,” or an “instruct” model, which is designed for chat, retrieval, and creative writing and can be deployed immediately for these use cases in enterprises. Another base model was also released at the time that was not instruction tuned, only pre-trained, allowing more customizability by customers. However, both were only available through commercial licensing terms — until now.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Acree’s chief technology officer (CTO) Lucas Atkins&lt;/strong&gt; also noted in a post on X that more &lt;strong&gt;“dedicated models for reasoning and tool use are on the way,” as well. &lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;“Building AFM-4.5B has been a huge team effort, and we’re deeply grateful to everyone who supported us We can’t wait to see what you build with it,” he wrote in another post. “We’re just getting started. If you have feedback or ideas, please don’t hesitate to reach out at any time.”&lt;/p&gt;



&lt;p&gt;The model is available now for deployment across a variety of environments —from cloud to smartphones to edge hardware. &lt;/p&gt;



&lt;p&gt;It’s also geared toward Acree’s growing list of enterprise customers and their needs and wants — specifically, a model trained without violating intellectual property. &lt;/p&gt;



&lt;p&gt;As Acree wrote in its initial AFM-4.5B announcement post last month: “Tremendous effort was put towards excluding copyrighted books and material with unclear licensing.” &lt;/p&gt;



&lt;p&gt;Acree notes it worked with third-party data curation firm DatologyAI to apply techniques like source mixing, embedding-based filtering, and quality control — all aimed at minimizing hallucinations and IP risks.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-focused-on-enterprise-customer-needs"&gt;Focused on enterprise customer needs&lt;/h2&gt;



&lt;p&gt;AFM-4.5B is Arcee.ai’s response to what it sees as major pain points in enterprise adoption of generative AI: high cost, limited customizability, and regulatory concerns around proprietary large language models (LLMs). &lt;/p&gt;



&lt;p&gt;Over the past year, the Arcee team held discussions with more than 150 organizations, ranging from startups to Fortune 100 companies, to understand the limitations of existing LLMs and define their own model goals.&lt;/p&gt;



&lt;p&gt;According to the company, many businesses found mainstream LLMs — such as those from OpenAI, Anthropic, or DeepSeek — too expensive and difficult to tailor to industry-specific needs. Meanwhile, while smaller open-weight models like Llama, Mistral, and Qwen offered more flexibility, they introduced concerns around licensing, IP provenance, and geopolitical risk.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;AFM-4.5B was developed as a “no-trade-offs” alternative: customizable, compliant, and cost-efficient without sacrificing model quality or usability.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;AFM-4.5B is designed with deployment flexibility in mind. It can operate in cloud, on-premise, hybrid, or even edge environments—thanks to its efficiency and compatibility with open frameworks such as Hugging Face Transformers, llama.cpp, and (pending release) vLLM. &lt;/p&gt;



&lt;p&gt;The model supports quantized formats, allowing it to run on lower-RAM GPUs or even CPUs, making it practical for applications with constrained resources.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-company-vision-secures-backing"&gt;Company vision secures backing&lt;/h2&gt;



&lt;p&gt;Arcee.ai’s broader strategy focuses on building domain-adaptable, small language models (SLMs) that can power &lt;strong&gt;many use cases within the same organization. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;As CEO Mark McQuade explained in a VentureBeat interview last year, “You don’t need to go that big for business use cases.” The company emphasizes fast iteration and model customization as core to its offering.&lt;/p&gt;



&lt;p&gt;This vision gained investor backing with a $24 million Series A round back in 2024. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-inside-afm-4-5b-s-architecture-and-training-process"&gt;Inside AFM-4.5B’s architecture and training process&lt;/h2&gt;



&lt;p&gt;The AFM-4.5B model uses a decoder-only transformer architecture with several optimizations for performance and deployment flexibility. &lt;/p&gt;



&lt;p&gt;It incorporates grouped query attention for faster inference and ReLU² activations in place of SwiGLU to support sparsification without degrading accuracy.&lt;/p&gt;



&lt;p&gt;Training followed a three-phase approach:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Pretraining on 6.5 trillion tokens of general data&lt;/li&gt;



&lt;li&gt;Midtraining on 1.5 trillion tokens emphasizing math and code&lt;/li&gt;



&lt;li&gt;Instruction tuning using high-quality instruction-following datasets and reinforcement learning with verifiable and preference-based feedback&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;To meet strict compliance and IP standards, the model was trained on nearly 7 trillion tokens of data curated for cleanliness and licensing safety. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-competitive-model-but-not-a-leader"&gt;A competitive model, but not a leader&lt;/h2&gt;



&lt;p&gt;Despite its smaller size, AFM-4.5B performs competitively across a broad range of benchmarks. The instruction-tuned version averages a score of 50.13 across evaluation suites such as MMLU, MixEval, TriviaQA, and Agieval—matching or outperforming similar-sized models like Gemma-3 4B-it, Qwen3-4B, and SmolLM3-3B.&lt;/p&gt;



&lt;p&gt;Multilingual testing shows the model delivers strong performance across more than 10 languages, including Arabic, Mandarin, German, and Portuguese. &lt;/p&gt;



&lt;p&gt;According to Arcee, adding support for additional dialects is straightforward due to its modular architecture.&lt;/p&gt;



&lt;p&gt;AFM-4.5B has also shown strong early traction in public evaluation environments. In a leaderboard that ranks conversational model quality by user votes and win rate, the model ranks third overall, trailing only Claude Opus 4 and Gemini 2.5 Pro. &lt;/p&gt;



&lt;p&gt;It boasts a win rate of 59.2% and the fastest latency of any top model at 0.2 seconds, paired with a generation speed of 179 tokens per second.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-built-in-support-for-agents"&gt;Built-in support for agents&lt;/h2&gt;



&lt;p&gt;In addition to general capabilities, AFM-4.5B comes with built-in support for function calling and agentic reasoning. &lt;/p&gt;



&lt;p&gt;These &lt;strong&gt;features aim to simplify the process of building AI agents and workflow automation tools&lt;/strong&gt;, reducing the need for complex prompt engineering or orchestration layers.&lt;/p&gt;



&lt;p&gt;This functionality aligns with Arcee’s broader strategy of enabling enterprises to build custom, production-ready models faster, with lower total cost of ownership (TCO) and easier integration into business operations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next-for-acree"&gt;What’s next for Acree?&lt;/h2&gt;



&lt;p&gt;AFM-4.5B represents &lt;strong&gt;Arcee.ai’s push to define a new category of enterprise-ready language models: small, performant, and fully customizable,&lt;/strong&gt; without the compromises that often come with either proprietary LLMs or open-weight SLMs. &lt;/p&gt;



&lt;p&gt;With competitive benchmarks, multilingual support, strong compliance standards, and flexible deployment options, the model aims to meet enterprise needs for speed, sovereignty, and scale.&lt;/p&gt;



&lt;p&gt;Whether Arcee can carve out a lasting role in the rapidly shifting generative AI landscape will depend on its ability to deliver on this promise. But with AFM-4.5B, the company has made a confident first move.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/acree-opens-up-new-enterprise-focused-customizable-ai-model-afm-4-5b-trained-on-clean-rigorously-filtered-data/</guid><pubDate>Tue, 29 Jul 2025 21:26:29 +0000</pubDate></item><item><title>AI vs. AI: Prophet Security raises $30M to replace human analysts with autonomous defenders (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/ai-vs-ai-prophet-security-raises-30m-to-replace-human-analysts-with-autonomous-defenders/</link><description>&lt;p&gt;Prophet Security, a startup developing autonomous artificial intelligence systems for cybersecurity defense, announced Tuesday it has raised $30 million in Series A funding to accelerate what its founders describe as a fundamental shift from human-versus-human to “agent-versus-agent” warfare in cybersecurity.&lt;/p&gt;&lt;p&gt;The Menlo Park-based company’s funding round, led by venture capital firm Accel with participation from Bain Capital Ventures, comes as organizations struggle with an overwhelming volume of security alerts while sophisticated attackers increasingly leverage AI to scale and automate their operations. Prophet’s approach represents a marked departure from the “copilot” AI tools that have dominated the market, instead deploying fully autonomous agents that can investigate and respond to threats without human intervention.&lt;/p&gt;&lt;p&gt;“Every security operations team is faced with a dual mandate of reducing risk while driving operational efficiency,” said Kamal Shah, Prophet Security’s co-founder and CEO, in an exclusive interview with VentureBeat. “Our Agentic AI SOC Platform addresses both challenges by automating manual, repetitive tasks in security operations with speed, accuracy and explainability.”&lt;/p&gt;&lt;p&gt;The funding announcement coincides with Prophet’s launch of what it calls the industry’s most comprehensive Agentic AI SOC Platform, expanding beyond its initial Prophet AI SOC Analyst to include Prophet AI Threat Hunter and Prophet AI Detection Advisor. The platform represents a significant evolution from traditional Security Operations Center (SOC) automation tools, which typically rely on rigid, pre-programmed playbooks.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-security-teams-drowning-in-960-daily-alerts-face-unprecedented-capacity-crisis"&gt;Security teams drowning in 960 daily alerts face unprecedented capacity crisis&lt;/h2&gt;



&lt;p&gt;The cybersecurity industry faces a crisis of capacity and capability. Shah, who previously served as CEO of container security company StackRox before its acquisition by Red Hat, experienced these challenges firsthand. According to his observations, organizations receive an average of 960 security alerts daily, with up to 40% going uninvestigated due to resource constraints.&lt;/p&gt;



&lt;p&gt;“The number one complaint that I see from customers every single day is too many alerts, too many false positives,” Shah explained. “If you think about the world that we live in today, on average, a company gets 960 alerts a day from all the security tools that they have in their environment, and 40% of those alerts are ignored because they just don’t have the capacity to go and investigate all those alerts.”&lt;/p&gt;



&lt;p&gt;The problem is compounded by a severe shortage of skilled cybersecurity professionals. Shah points to what he calls a critical talent gap, noting there are 5 million open positions in cybersecurity globally, creating a situation where even organizations with budget to hire cannot find qualified personnel.&lt;/p&gt;



&lt;p&gt;Prophet’s solution directly addresses this capacity crunch. Over the past six months, the company’s AI SOC Analyst has performed more than 1 million autonomous investigations across its customer base, saving an estimated 360,000 hours of investigation time while delivering 10 times faster response times and reducing false positives by 96%.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-autonomous-ai-agents-differ-from-reactive-copilot-systems-transforming-cybersecurity"&gt;How autonomous AI agents differ from reactive copilot systems transforming cybersecurity&lt;/h2&gt;



&lt;p&gt;The distinction between Prophet’s “agentic” AI and the copilot models deployed by larger cybersecurity vendors like CrowdStrike, Microsoft, and Sentinel One is fundamental to understanding the company’s value proposition. Traditional copilot systems require human analysts to initiate queries and interpret responses, essentially serving as sophisticated search interfaces for security data.&lt;/p&gt;



&lt;p&gt;“Copilot is reactive,” Shah explained. “You have an alert come in and a security analyst has to go and write questions, ask the question to say, hey, what does this mean? And you have to know what questions to ask. The analyst is still in the loop for every single alert that comes in because they’re interacting with it.”&lt;/p&gt;



&lt;p&gt;By contrast, Prophet’s agentic AI proactively initiates investigations the moment an alert is triggered, autonomously gathering evidence, reasoning through the data, and reaching conclusions without human intervention. The system documents every step of its investigation process, creating an audit trail that allows security teams to understand and verify its reasoning.&lt;/p&gt;



&lt;p&gt;“What Prophet AI is able to do is immediately, once an alert is triggered, it proactively goes and completes the investigation,” Shah said. “Within a matter of minutes, your investigation is complete and it knows what questions to ask, and it’s been trained to act like an expert analyst.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-enterprise-trust-through-transparent-ai-decision-making-and-data-protection"&gt;Building enterprise trust through transparent AI decision-making and data protection&lt;/h2&gt;



&lt;p&gt;Prophet’s system leverages multiple frontier AI models, including offerings from OpenAI, Anthropic, and others, selecting the most appropriate model for each specific task. The company has built what Shah describes as an “evals framework” to ensure accuracy, repeatability, and consistency while preventing AI hallucinations—a critical concern in security contexts where false information can lead to inappropriate responses.&lt;/p&gt;



&lt;p&gt;“In security, you are in a trust building exercise with the security teams, and if you hallucinate, you’re going to lose trust and they’re not going to use your product,” Shah emphasized. The company employs a retrieval-augmented generation (RAG) architecture combined with rigorous evaluation processes to maintain what Shah calls “a high bar for security teams.”&lt;/p&gt;



&lt;p&gt;Data privacy and security represent paramount concerns for Prophet’s enterprise customers. The company employs a single-tenant architecture ensuring customer data remains isolated, and maintains contractual agreements with AI model providers preventing customer data from being used to train or fine-tune models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-early-customers-report-dramatic-efficiency-gains-as-ai-handles-thousands-of-security-alerts"&gt;Early customers report dramatic efficiency gains as AI handles thousands of security alerts&lt;/h2&gt;



&lt;p&gt;Prophet’s customer base includes Docker, which provided a testimonial for the funding announcement. Tushar Jain, Docker’s EVP of Engineering and Product, noted that “Prophet AI is already helping streamline parts of our security workflow, and we’re just getting started. With the recent release of Threat Hunter and growing integration with our systems, we see a clear path to faster response times, reduced noise, and a more focused security team.”&lt;/p&gt;



&lt;p&gt;The company has also published case studies demonstrating dramatic improvements in SOC efficiency. Eric Wille, CISO at Cabinet Works, reported reducing his team’s alert volume from 33,200 down to just six alerts requiring human attention, effectively allowing his small team to operate with the efficiency of a much larger organization.&lt;/p&gt;



&lt;p&gt;“Prophet AI cut our alert queue from thousands to dozens,” Wille said in a video testimonial. “It’s a force multiplier that removes investigation bottlenecks, improves analyst focus, and helps us respond to real threats faster.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-rising-cyber-threats-and-evolving-attack-methods-drive-demand-for-ai-powered-defense"&gt;Rising cyber threats and evolving attack methods drive demand for AI-powered defense&lt;/h2&gt;



&lt;p&gt;Prophet’s emergence occurs against a backdrop of rapidly evolving cyber threats. CrowdStrike’s 2025 Global Threat Report documented a 150% increase in China-nexus cyber activity and a 442% growth in voice phishing operations, while noting that 79% of detected threats were malware-free, making them harder to identify through traditional signature-based detection methods.&lt;/p&gt;



&lt;p&gt;The company’s approach to integration across existing security tools provides a key competitive advantage. Rather than requiring organizations to replace their current security stack, Prophet integrates with existing Security Information and Event Management (SIEM) systems, Endpoint Detection and Response (EDR) platforms, and other security tools.&lt;/p&gt;



&lt;p&gt;“If you’ve got to go get five or six different copilots to use within your organization, it’s going to be very confusing,” Shah explained. “What customers are telling us is that, hey, I want an independent AI SOC platform that can help me triage, investigate and respond to alerts from all of my security tools, not just one or two.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-accel-s-preemptive-investment-signals-growing-confidence-in-autonomous-security-systems"&gt;Accel’s preemptive investment signals growing confidence in autonomous security systems&lt;/h2&gt;



&lt;p&gt;Eric Wolford, Partner at Accel, emphasized the combination of technical innovation and proven market traction that drove the investment decision. “What stood out to us about Prophet wasn’t just the technical ambition, but the real-world traction: they’re delivering autonomy and speed while showing their work—a critical differentiator in an industry that runs on trust,” Wolford said in a statement.&lt;/p&gt;



&lt;p&gt;Accel’s cybersecurity investment portfolio includes CrowdStrike, Tenable, and BlackPoint Cyber, providing the firm with deep expertise in evaluating security technologies. The preemptive nature of the funding round — Prophet was not actively seeking capital — underscores investor confidence in the company’s trajectory.&lt;/p&gt;



&lt;p&gt;The funding will primarily support engineering expansion and go-to-market acceleration as Prophet scales its platform capabilities. The company plans to continue expanding its agentic AI platform, potentially adding new modules for additional security operations workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-industry-experts-predict-widespread-adoption-of-ai-agents-will-reshape-cybersecurity-landscape"&gt;Industry experts predict widespread adoption of AI agents will reshape cybersecurity landscape&lt;/h2&gt;



&lt;p&gt;Prophet’s success reflects broader trends reshaping cybersecurity. Deloitte’s 2025 cybersecurity forecasts predict widespread adoption of agentic AI systems, with 40% of large enterprises expected to deploy such systems in their SOCs by 2025. The consulting firm characterizes this shift as moving from “automation that follows instructions to automation that thinks.”&lt;/p&gt;



&lt;p&gt;The company’s “role elevation” philosophy — enhancing rather than replacing human analysts — addresses concerns about AI displacing cybersecurity professionals. Shah emphasized that automation should free analysts from repetitive tasks to focus on higher-value security work.&lt;/p&gt;



&lt;p&gt;“This is not about eliminating jobs,” Shah said. “It’s about ensuring an analyst doesn’t have to spend time triaging and investigating alerts, because who wants to do that all day, every day? Instead, they can focus on the 4% of issues that truly matter to an organization. They’re advancing their careers and doing more higher-order security work.”&lt;/p&gt;



&lt;p&gt;As cyber threats continue evolving and incorporating AI capabilities, the arms race between attackers and defenders increasingly relies on technological sophistication rather than human capacity alone. Prophet’s approach suggests a future where cybersecurity becomes primarily a contest between AI systems, with human expertise focused on strategic oversight and complex decision-making.&lt;/p&gt;



&lt;p&gt;The company’s ability to demonstrate measurable improvements in SOC efficiency while maintaining transparency and explainability positions it to capture market share as organizations grapple with the dual pressures of increasing threats and persistent talent shortages. With the new funding, Prophet Security aims to accelerate this transition, potentially setting the standard for how organizations defend against AI-powered attacks in an era where the speed and scale of threats exceed human capacity to respond manually.&lt;/p&gt;



&lt;p&gt;But perhaps the most telling indicator of this shift isn’t Prophet’s technology or funding — it’s what happened when Shah’s team wasn’t actively seeking investment. Accel approached them anyway, recognizing that in a world where attackers launch AI-powered assaults at machine speed, the old playbook of human-driven defense isn’t just insufficient — it’s obsolete.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Prophet Security, a startup developing autonomous artificial intelligence systems for cybersecurity defense, announced Tuesday it has raised $30 million in Series A funding to accelerate what its founders describe as a fundamental shift from human-versus-human to “agent-versus-agent” warfare in cybersecurity.&lt;/p&gt;&lt;p&gt;The Menlo Park-based company’s funding round, led by venture capital firm Accel with participation from Bain Capital Ventures, comes as organizations struggle with an overwhelming volume of security alerts while sophisticated attackers increasingly leverage AI to scale and automate their operations. Prophet’s approach represents a marked departure from the “copilot” AI tools that have dominated the market, instead deploying fully autonomous agents that can investigate and respond to threats without human intervention.&lt;/p&gt;&lt;p&gt;“Every security operations team is faced with a dual mandate of reducing risk while driving operational efficiency,” said Kamal Shah, Prophet Security’s co-founder and CEO, in an exclusive interview with VentureBeat. “Our Agentic AI SOC Platform addresses both challenges by automating manual, repetitive tasks in security operations with speed, accuracy and explainability.”&lt;/p&gt;&lt;p&gt;The funding announcement coincides with Prophet’s launch of what it calls the industry’s most comprehensive Agentic AI SOC Platform, expanding beyond its initial Prophet AI SOC Analyst to include Prophet AI Threat Hunter and Prophet AI Detection Advisor. The platform represents a significant evolution from traditional Security Operations Center (SOC) automation tools, which typically rely on rigid, pre-programmed playbooks.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-security-teams-drowning-in-960-daily-alerts-face-unprecedented-capacity-crisis"&gt;Security teams drowning in 960 daily alerts face unprecedented capacity crisis&lt;/h2&gt;



&lt;p&gt;The cybersecurity industry faces a crisis of capacity and capability. Shah, who previously served as CEO of container security company StackRox before its acquisition by Red Hat, experienced these challenges firsthand. According to his observations, organizations receive an average of 960 security alerts daily, with up to 40% going uninvestigated due to resource constraints.&lt;/p&gt;



&lt;p&gt;“The number one complaint that I see from customers every single day is too many alerts, too many false positives,” Shah explained. “If you think about the world that we live in today, on average, a company gets 960 alerts a day from all the security tools that they have in their environment, and 40% of those alerts are ignored because they just don’t have the capacity to go and investigate all those alerts.”&lt;/p&gt;



&lt;p&gt;The problem is compounded by a severe shortage of skilled cybersecurity professionals. Shah points to what he calls a critical talent gap, noting there are 5 million open positions in cybersecurity globally, creating a situation where even organizations with budget to hire cannot find qualified personnel.&lt;/p&gt;



&lt;p&gt;Prophet’s solution directly addresses this capacity crunch. Over the past six months, the company’s AI SOC Analyst has performed more than 1 million autonomous investigations across its customer base, saving an estimated 360,000 hours of investigation time while delivering 10 times faster response times and reducing false positives by 96%.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-autonomous-ai-agents-differ-from-reactive-copilot-systems-transforming-cybersecurity"&gt;How autonomous AI agents differ from reactive copilot systems transforming cybersecurity&lt;/h2&gt;



&lt;p&gt;The distinction between Prophet’s “agentic” AI and the copilot models deployed by larger cybersecurity vendors like CrowdStrike, Microsoft, and Sentinel One is fundamental to understanding the company’s value proposition. Traditional copilot systems require human analysts to initiate queries and interpret responses, essentially serving as sophisticated search interfaces for security data.&lt;/p&gt;



&lt;p&gt;“Copilot is reactive,” Shah explained. “You have an alert come in and a security analyst has to go and write questions, ask the question to say, hey, what does this mean? And you have to know what questions to ask. The analyst is still in the loop for every single alert that comes in because they’re interacting with it.”&lt;/p&gt;



&lt;p&gt;By contrast, Prophet’s agentic AI proactively initiates investigations the moment an alert is triggered, autonomously gathering evidence, reasoning through the data, and reaching conclusions without human intervention. The system documents every step of its investigation process, creating an audit trail that allows security teams to understand and verify its reasoning.&lt;/p&gt;



&lt;p&gt;“What Prophet AI is able to do is immediately, once an alert is triggered, it proactively goes and completes the investigation,” Shah said. “Within a matter of minutes, your investigation is complete and it knows what questions to ask, and it’s been trained to act like an expert analyst.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-enterprise-trust-through-transparent-ai-decision-making-and-data-protection"&gt;Building enterprise trust through transparent AI decision-making and data protection&lt;/h2&gt;



&lt;p&gt;Prophet’s system leverages multiple frontier AI models, including offerings from OpenAI, Anthropic, and others, selecting the most appropriate model for each specific task. The company has built what Shah describes as an “evals framework” to ensure accuracy, repeatability, and consistency while preventing AI hallucinations—a critical concern in security contexts where false information can lead to inappropriate responses.&lt;/p&gt;



&lt;p&gt;“In security, you are in a trust building exercise with the security teams, and if you hallucinate, you’re going to lose trust and they’re not going to use your product,” Shah emphasized. The company employs a retrieval-augmented generation (RAG) architecture combined with rigorous evaluation processes to maintain what Shah calls “a high bar for security teams.”&lt;/p&gt;



&lt;p&gt;Data privacy and security represent paramount concerns for Prophet’s enterprise customers. The company employs a single-tenant architecture ensuring customer data remains isolated, and maintains contractual agreements with AI model providers preventing customer data from being used to train or fine-tune models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-early-customers-report-dramatic-efficiency-gains-as-ai-handles-thousands-of-security-alerts"&gt;Early customers report dramatic efficiency gains as AI handles thousands of security alerts&lt;/h2&gt;



&lt;p&gt;Prophet’s customer base includes Docker, which provided a testimonial for the funding announcement. Tushar Jain, Docker’s EVP of Engineering and Product, noted that “Prophet AI is already helping streamline parts of our security workflow, and we’re just getting started. With the recent release of Threat Hunter and growing integration with our systems, we see a clear path to faster response times, reduced noise, and a more focused security team.”&lt;/p&gt;



&lt;p&gt;The company has also published case studies demonstrating dramatic improvements in SOC efficiency. Eric Wille, CISO at Cabinet Works, reported reducing his team’s alert volume from 33,200 down to just six alerts requiring human attention, effectively allowing his small team to operate with the efficiency of a much larger organization.&lt;/p&gt;



&lt;p&gt;“Prophet AI cut our alert queue from thousands to dozens,” Wille said in a video testimonial. “It’s a force multiplier that removes investigation bottlenecks, improves analyst focus, and helps us respond to real threats faster.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-rising-cyber-threats-and-evolving-attack-methods-drive-demand-for-ai-powered-defense"&gt;Rising cyber threats and evolving attack methods drive demand for AI-powered defense&lt;/h2&gt;



&lt;p&gt;Prophet’s emergence occurs against a backdrop of rapidly evolving cyber threats. CrowdStrike’s 2025 Global Threat Report documented a 150% increase in China-nexus cyber activity and a 442% growth in voice phishing operations, while noting that 79% of detected threats were malware-free, making them harder to identify through traditional signature-based detection methods.&lt;/p&gt;



&lt;p&gt;The company’s approach to integration across existing security tools provides a key competitive advantage. Rather than requiring organizations to replace their current security stack, Prophet integrates with existing Security Information and Event Management (SIEM) systems, Endpoint Detection and Response (EDR) platforms, and other security tools.&lt;/p&gt;



&lt;p&gt;“If you’ve got to go get five or six different copilots to use within your organization, it’s going to be very confusing,” Shah explained. “What customers are telling us is that, hey, I want an independent AI SOC platform that can help me triage, investigate and respond to alerts from all of my security tools, not just one or two.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-accel-s-preemptive-investment-signals-growing-confidence-in-autonomous-security-systems"&gt;Accel’s preemptive investment signals growing confidence in autonomous security systems&lt;/h2&gt;



&lt;p&gt;Eric Wolford, Partner at Accel, emphasized the combination of technical innovation and proven market traction that drove the investment decision. “What stood out to us about Prophet wasn’t just the technical ambition, but the real-world traction: they’re delivering autonomy and speed while showing their work—a critical differentiator in an industry that runs on trust,” Wolford said in a statement.&lt;/p&gt;



&lt;p&gt;Accel’s cybersecurity investment portfolio includes CrowdStrike, Tenable, and BlackPoint Cyber, providing the firm with deep expertise in evaluating security technologies. The preemptive nature of the funding round — Prophet was not actively seeking capital — underscores investor confidence in the company’s trajectory.&lt;/p&gt;



&lt;p&gt;The funding will primarily support engineering expansion and go-to-market acceleration as Prophet scales its platform capabilities. The company plans to continue expanding its agentic AI platform, potentially adding new modules for additional security operations workflows.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-industry-experts-predict-widespread-adoption-of-ai-agents-will-reshape-cybersecurity-landscape"&gt;Industry experts predict widespread adoption of AI agents will reshape cybersecurity landscape&lt;/h2&gt;



&lt;p&gt;Prophet’s success reflects broader trends reshaping cybersecurity. Deloitte’s 2025 cybersecurity forecasts predict widespread adoption of agentic AI systems, with 40% of large enterprises expected to deploy such systems in their SOCs by 2025. The consulting firm characterizes this shift as moving from “automation that follows instructions to automation that thinks.”&lt;/p&gt;



&lt;p&gt;The company’s “role elevation” philosophy — enhancing rather than replacing human analysts — addresses concerns about AI displacing cybersecurity professionals. Shah emphasized that automation should free analysts from repetitive tasks to focus on higher-value security work.&lt;/p&gt;



&lt;p&gt;“This is not about eliminating jobs,” Shah said. “It’s about ensuring an analyst doesn’t have to spend time triaging and investigating alerts, because who wants to do that all day, every day? Instead, they can focus on the 4% of issues that truly matter to an organization. They’re advancing their careers and doing more higher-order security work.”&lt;/p&gt;



&lt;p&gt;As cyber threats continue evolving and incorporating AI capabilities, the arms race between attackers and defenders increasingly relies on technological sophistication rather than human capacity alone. Prophet’s approach suggests a future where cybersecurity becomes primarily a contest between AI systems, with human expertise focused on strategic oversight and complex decision-making.&lt;/p&gt;



&lt;p&gt;The company’s ability to demonstrate measurable improvements in SOC efficiency while maintaining transparency and explainability positions it to capture market share as organizations grapple with the dual pressures of increasing threats and persistent talent shortages. With the new funding, Prophet Security aims to accelerate this transition, potentially setting the standard for how organizations defend against AI-powered attacks in an era where the speed and scale of threats exceed human capacity to respond manually.&lt;/p&gt;



&lt;p&gt;But perhaps the most telling indicator of this shift isn’t Prophet’s technology or funding — it’s what happened when Shah’s team wasn’t actively seeking investment. Accel approached them anyway, recognizing that in a world where attackers launch AI-powered assaults at machine speed, the old playbook of human-driven defense isn’t just insufficient — it’s obsolete.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ai-vs-ai-prophet-security-raises-30m-to-replace-human-analysts-with-autonomous-defenders/</guid><pubDate>Tue, 29 Jul 2025 21:39:24 +0000</pubDate></item><item><title>Nvidia AI chip challenger Groq said to be nearing new fundraising at $6B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/29/nvidia-ai-chip-challenger-groq-said-to-be-nearing-new-fundraising-at-6b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/1_byjKY2ta4_34GHPvmN9Suw.jpg?resize=1200,640" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chip startup Groq is in talks to raise a fresh $600 million at a near $6 billion valuation, sources tell Bloomberg, although the deal isn’t yet final and terms could change.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Groq raised $640 million at a $2.8 billion valuation in August 2024, making this double the valuation in about a year. Groq previously raised about $1 billion.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new round is led by Austin-based firm Disruptive, Bloomberg reports. The November round was led by BlackRock, with participation from Neuberger Berman, Type One Ventures, Cisco, KDDI, and Samsung Catalyst Fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Groq was founded by Jonathan Ross, who previously worked at Google developing its Tensor Processing Unit chip. The startup emerged from stealth in 2016.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This new raise comes after Groq announced in May an exclusive partnership with Bell Canada to power the telco’s large AI infrastructure project. In April, Groq partnered with Meta to offer AI infrastructure to speed Llama 4 inference. Neither Disruptive nor Groq immediately returned our request for comment.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Correction: This story originally incorrectly reported the date of the last raise. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/1_byjKY2ta4_34GHPvmN9Suw.jpg?resize=1200,640" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chip startup Groq is in talks to raise a fresh $600 million at a near $6 billion valuation, sources tell Bloomberg, although the deal isn’t yet final and terms could change.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Groq raised $640 million at a $2.8 billion valuation in August 2024, making this double the valuation in about a year. Groq previously raised about $1 billion.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new round is led by Austin-based firm Disruptive, Bloomberg reports. The November round was led by BlackRock, with participation from Neuberger Berman, Type One Ventures, Cisco, KDDI, and Samsung Catalyst Fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Groq was founded by Jonathan Ross, who previously worked at Google developing its Tensor Processing Unit chip. The startup emerged from stealth in 2016.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This new raise comes after Groq announced in May an exclusive partnership with Bell Canada to power the telco’s large AI infrastructure project. In April, Groq partnered with Meta to offer AI infrastructure to speed Llama 4 inference. Neither Disruptive nor Groq immediately returned our request for comment.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Correction: This story originally incorrectly reported the date of the last raise. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/29/nvidia-ai-chip-challenger-groq-said-to-be-nearing-new-fundraising-at-6b-valuation/</guid><pubDate>Tue, 29 Jul 2025 22:02:51 +0000</pubDate></item><item><title>[NEW] New algorithms enable efficient machine learning with symmetric data (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/new-algorithms-enable-efficient-machine-learning-with-symmetric-data-0730</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT_Learning-Symmetric-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;If you rotate an image of a molecular structure, a human can tell the rotated image is still the same molecule, but a machine-learning model might think it is a new data point. In computer science parlance, the molecule is “symmetric,” meaning the fundamental structure of that molecule remains the same if it undergoes certain transformations, like rotation.&lt;/p&gt;&lt;p&gt;If a drug discovery model doesn’t understand symmetry, it could make inaccurate predictions about molecular properties. But despite some empirical successes, it’s been unclear whether there is a computationally efficient method to train a good model that is guaranteed to respect symmetry.&lt;/p&gt;&lt;p&gt;A new study by MIT researchers answers this question, and shows the first method for machine learning with symmetry that is provably efficient in terms of both the amount of computation and data needed.&lt;/p&gt;&lt;p&gt;These results clarify a foundational question, and they could aid researchers in the development of more powerful machine-learning models that are designed to handle symmetry. Such models would be useful in a variety of applications, from discovering new materials to identifying astronomical anomalies to unraveling complex climate patterns.&lt;/p&gt;&lt;p&gt;“These symmetries are important because they are some sort of information that nature is telling us about the data, and we should take it into account in our machine-learning models. We’ve now shown that it is possible to do machine-learning with symmetric data in an efficient way,” says Behrooz Tahmasebi, an MIT graduate student and co-lead author of this study.&lt;/p&gt;&lt;p&gt;He is joined on the paper by co-lead author and MIT graduate student Ashkan Soleymani; Stefanie Jegelka, an associate professor of electrical engineering and computer science (EECS) and a member of the Institute for Data, Systems, and Society (IDSS) and the Computer Science and Artificial Intelligence Laboratory (CSAIL); and senior author Patrick Jaillet, the Dugald C. Jackson Professor of Electrical Engineering and Computer Science and a principal investigator in the Laboratory for Information and Decision Systems (LIDS). The research was recently presented at the International Conference on Machine Learning.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Studying symmetry&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Symmetric data appear in many domains, especially the natural sciences and physics. A model that recognizes symmetries is able to identify an object, like a car, no matter where that object is placed in an image, for example.&lt;/p&gt;&lt;p&gt;Unless a machine-learning model is designed to handle symmetry, it could be less accurate and prone to failure when faced with new symmetric data in real-world situations. On the flip side, models that take advantage of symmetry could be faster and require fewer data for training.&lt;/p&gt;&lt;p&gt;But training a model to process symmetric data is no easy task.&lt;/p&gt;&lt;p&gt;One common approach is called data augmentation, where researchers transform each symmetric data point into multiple data points to help the model generalize better to new data. For instance, one could rotate a molecular structure many times to produce new training data, but if researchers want the model to be guaranteed to respect symmetry, this can be computationally prohibitive.&lt;/p&gt;&lt;p&gt;An alternative approach is to encode symmetry into the model’s architecture. A well-known example of this is a graph neural network (GNN), which inherently handles symmetric data because of how it is designed.&lt;/p&gt;&lt;p&gt;“Graph neural networks are fast and efficient, and they take care of symmetry quite well, but nobody really knows what these models are learning or why they work. Understanding GNNs is a main motivation of our work, so we started with a theoretical evaluation of what happens when data are symmetric,” Tahmasebi says.&lt;/p&gt;&lt;p&gt;They explored the statistical-computational tradeoff in machine learning with symmetric data. This tradeoff means methods that require fewer data can be more computationally expensive, so researchers need to find the right balance.&lt;/p&gt;&lt;p&gt;Building on this theoretical evaluation, the researchers designed an efficient algorithm for machine learning with symmetric data.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mathematical combinations&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To do this, they borrowed ideas from algebra to shrink and simplify the problem. Then, they reformulated the problem using ideas from geometry that effectively capture symmetry.&lt;/p&gt;&lt;p&gt;Finally, they combined the algebra and the geometry into an optimization problem that can be solved efficiently, resulting in their new algorithm.&lt;/p&gt;&lt;p&gt;“Most of the theory and applications were focusing on either algebra or geometry. Here we just combined them,” Tahmasebi says.&lt;/p&gt;&lt;p&gt;The algorithm requires fewer data samples for training than classical approaches, which would improve a model’s accuracy and ability to adapt to new applications.&lt;/p&gt;&lt;p&gt;By proving that scientists can develop efficient algorithms for machine learning with symmetry, and demonstrating how it can be done, these results could lead to the development of new neural network architectures that could be more accurate and less resource-intensive than current models.&lt;/p&gt;&lt;p&gt;Scientists could also use this analysis as a starting point to examine the inner workings of GNNs, and how their operations differ from the algorithm the MIT researchers developed.&lt;/p&gt;&lt;p&gt;“Once we know that better, we can design more interpretable, more robust, and more efficient neural network architectures,” adds Soleymani.&lt;/p&gt;&lt;p&gt;This research is funded, in part, by the National Research Foundation of Singapore, DSO National Laboratories of Singapore, the U.S. Office of Naval Research, the U.S. National Science Foundation, and an Alexander von Humboldt Professorship.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT_Learning-Symmetric-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;If you rotate an image of a molecular structure, a human can tell the rotated image is still the same molecule, but a machine-learning model might think it is a new data point. In computer science parlance, the molecule is “symmetric,” meaning the fundamental structure of that molecule remains the same if it undergoes certain transformations, like rotation.&lt;/p&gt;&lt;p&gt;If a drug discovery model doesn’t understand symmetry, it could make inaccurate predictions about molecular properties. But despite some empirical successes, it’s been unclear whether there is a computationally efficient method to train a good model that is guaranteed to respect symmetry.&lt;/p&gt;&lt;p&gt;A new study by MIT researchers answers this question, and shows the first method for machine learning with symmetry that is provably efficient in terms of both the amount of computation and data needed.&lt;/p&gt;&lt;p&gt;These results clarify a foundational question, and they could aid researchers in the development of more powerful machine-learning models that are designed to handle symmetry. Such models would be useful in a variety of applications, from discovering new materials to identifying astronomical anomalies to unraveling complex climate patterns.&lt;/p&gt;&lt;p&gt;“These symmetries are important because they are some sort of information that nature is telling us about the data, and we should take it into account in our machine-learning models. We’ve now shown that it is possible to do machine-learning with symmetric data in an efficient way,” says Behrooz Tahmasebi, an MIT graduate student and co-lead author of this study.&lt;/p&gt;&lt;p&gt;He is joined on the paper by co-lead author and MIT graduate student Ashkan Soleymani; Stefanie Jegelka, an associate professor of electrical engineering and computer science (EECS) and a member of the Institute for Data, Systems, and Society (IDSS) and the Computer Science and Artificial Intelligence Laboratory (CSAIL); and senior author Patrick Jaillet, the Dugald C. Jackson Professor of Electrical Engineering and Computer Science and a principal investigator in the Laboratory for Information and Decision Systems (LIDS). The research was recently presented at the International Conference on Machine Learning.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Studying symmetry&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Symmetric data appear in many domains, especially the natural sciences and physics. A model that recognizes symmetries is able to identify an object, like a car, no matter where that object is placed in an image, for example.&lt;/p&gt;&lt;p&gt;Unless a machine-learning model is designed to handle symmetry, it could be less accurate and prone to failure when faced with new symmetric data in real-world situations. On the flip side, models that take advantage of symmetry could be faster and require fewer data for training.&lt;/p&gt;&lt;p&gt;But training a model to process symmetric data is no easy task.&lt;/p&gt;&lt;p&gt;One common approach is called data augmentation, where researchers transform each symmetric data point into multiple data points to help the model generalize better to new data. For instance, one could rotate a molecular structure many times to produce new training data, but if researchers want the model to be guaranteed to respect symmetry, this can be computationally prohibitive.&lt;/p&gt;&lt;p&gt;An alternative approach is to encode symmetry into the model’s architecture. A well-known example of this is a graph neural network (GNN), which inherently handles symmetric data because of how it is designed.&lt;/p&gt;&lt;p&gt;“Graph neural networks are fast and efficient, and they take care of symmetry quite well, but nobody really knows what these models are learning or why they work. Understanding GNNs is a main motivation of our work, so we started with a theoretical evaluation of what happens when data are symmetric,” Tahmasebi says.&lt;/p&gt;&lt;p&gt;They explored the statistical-computational tradeoff in machine learning with symmetric data. This tradeoff means methods that require fewer data can be more computationally expensive, so researchers need to find the right balance.&lt;/p&gt;&lt;p&gt;Building on this theoretical evaluation, the researchers designed an efficient algorithm for machine learning with symmetric data.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Mathematical combinations&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;To do this, they borrowed ideas from algebra to shrink and simplify the problem. Then, they reformulated the problem using ideas from geometry that effectively capture symmetry.&lt;/p&gt;&lt;p&gt;Finally, they combined the algebra and the geometry into an optimization problem that can be solved efficiently, resulting in their new algorithm.&lt;/p&gt;&lt;p&gt;“Most of the theory and applications were focusing on either algebra or geometry. Here we just combined them,” Tahmasebi says.&lt;/p&gt;&lt;p&gt;The algorithm requires fewer data samples for training than classical approaches, which would improve a model’s accuracy and ability to adapt to new applications.&lt;/p&gt;&lt;p&gt;By proving that scientists can develop efficient algorithms for machine learning with symmetry, and demonstrating how it can be done, these results could lead to the development of new neural network architectures that could be more accurate and less resource-intensive than current models.&lt;/p&gt;&lt;p&gt;Scientists could also use this analysis as a starting point to examine the inner workings of GNNs, and how their operations differ from the algorithm the MIT researchers developed.&lt;/p&gt;&lt;p&gt;“Once we know that better, we can design more interpretable, more robust, and more efficient neural network architectures,” adds Soleymani.&lt;/p&gt;&lt;p&gt;This research is funded, in part, by the National Research Foundation of Singapore, DSO National Laboratories of Singapore, the U.S. Office of Naval Research, the U.S. National Science Foundation, and an Alexander von Humboldt Professorship.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/new-algorithms-enable-efficient-machine-learning-with-symmetric-data-0730</guid><pubDate>Wed, 30 Jul 2025 04:00:00 +0000</pubDate></item></channel></rss>