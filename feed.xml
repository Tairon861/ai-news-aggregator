<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 08 Jan 2026 06:38:33 +0000</lastBuildDate><item><title>Where VCs think AI startups can win, even with OpenAI in the game (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/where-vcs-think-ai-startups-can-win-even-with-openai-in-the-game/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/meta-oakley.jpg?resize=1200,890" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30808021"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Vanessa Larco, partner at Premise and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco, who’s been investing in consumer and prosumer for years, thinks we’re about to see a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps, or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for themselves?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as TechCrunch’s ⁠Rebecca Bellan sat down with Larco on Equity to talk about why consumer is back, what OpenAI &lt;em&gt;won’t &lt;/em&gt;kill, and where the real opportunities are hiding.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on YouTube, Apple Podcasts, Overcast, Spotify, and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/meta-oakley.jpg?resize=1200,890" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30808021"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Vanessa Larco, partner at Premise and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco, who’s been investing in consumer and prosumer for years, thinks we’re about to see a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps, or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for themselves?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as TechCrunch’s ⁠Rebecca Bellan sat down with Larco on Equity to talk about why consumer is back, what OpenAI &lt;em&gt;won’t &lt;/em&gt;kill, and where the real opportunities are hiding.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on YouTube, Apple Podcasts, Overcast, Spotify, and all the casts. You also can follow Equity on X and Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/where-vcs-think-ai-startups-can-win-even-with-openai-in-the-game/</guid><pubDate>Wed, 07 Jan 2026 18:53:35 +0000</pubDate></item><item><title>Nous Research's NousCoder-14B is an open-source coding model landing right in the Claude Code moment (AI | VentureBeat)</title><link>https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://nousresearch.com/"&gt;Nous Research&lt;/a&gt;, the open-source artificial intelligence startup backed by crypto venture firm &lt;a href="https://www.paradigm.xyz/"&gt;Paradigm&lt;/a&gt;, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&amp;#x27;s latest &lt;a href="https://www.nvidia.com/en-us/data-center/dgx-b200/"&gt;B200 graphics processors&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The model, called &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: &lt;a href="https://claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&amp;#x27;s Day, with developers posting &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;breathless&lt;/a&gt; &lt;a href="https://x.com/hayesdev_/status/2008043379805048948"&gt;testimonials&lt;/a&gt; &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;about its capabilities&lt;/a&gt;. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.&lt;/p&gt;&lt;p&gt;&lt;span&gt;type: &lt;!-- --&gt;embedded-entry-inline&lt;!-- --&gt; id: &lt;!-- --&gt;74cSyrq6OUrp9SEQ5zOUSl&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;NousCoder-14B&lt;/a&gt; achieves a 67.87 percent accuracy rate on &lt;a href="https://livecodebench.github.io/"&gt;LiveCodeBench v6&lt;/a&gt;, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&amp;#x27;s &lt;a href="https://huggingface.co/Qwen/Qwen3-14B"&gt;Qwen3-14B&lt;/a&gt;, according to Nous Research&amp;#x27;s technical report published alongside the release.&lt;/p&gt;&lt;p&gt;&amp;quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&amp;quot; &lt;a href="https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/"&gt;wrote Jaana Dogan&lt;/a&gt;, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.&lt;/p&gt;&lt;p&gt;The juxtaposition is instructive: while Anthropic&amp;#x27;s &lt;a href="https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are"&gt;Claude Code has captured imaginations&lt;/a&gt; with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;How Nous Research built an AI coding model that anyone can replicate&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; release from many competitor announcements is its radical openness. Nous Research published not just the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;model weights&lt;/a&gt; but the &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;complete reinforcement learning environment&lt;/a&gt;, benchmark suite, and training harness — built on the company&amp;#x27;s &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos framework &lt;/a&gt;— enabling any researcher with sufficient compute to &lt;a href="https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o"&gt;reproduce or extend the work&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&amp;quot; &lt;a href="https://x.com/o_mega___/status/2008907268700475450?s=20"&gt;noted one observer on X&lt;/a&gt;, summarizing the significance for the academic and open-source communities.&lt;/p&gt;&lt;p&gt;The model was trained by &lt;a href="https://x.com/JoeLi5050"&gt;Joe Li&lt;/a&gt;, a researcher in residence at Nous Research and a former competitive programmer himself. Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report &lt;/a&gt;reveals an unexpectedly personal dimension: he compared the model&amp;#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.&lt;/p&gt;&lt;p&gt;Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&amp;#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.&lt;/p&gt;&lt;p&gt;&amp;quot;Watching that final training run unfold was quite a surreal experience,&amp;quot; Li wrote in the technical report.&lt;/p&gt;&lt;p&gt;But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;Inside the reinforcement learning system that trains on 24,000 competitive programming problems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;&amp;#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.&lt;/p&gt;&lt;p&gt;The approach relies on what researchers call &amp;quot;verifiable rewards&amp;quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.&lt;/p&gt;&lt;p&gt;Nous Research used &lt;a href="https://modal.com/"&gt;Modal&lt;/a&gt;, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.&lt;/p&gt;&lt;p&gt;The training employed a technique called &lt;a href="https://dapo-sia.github.io/"&gt;DAPO (Dynamic Sampling Policy Optimization)&lt;/a&gt;, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &amp;quot;dynamic sampling&amp;quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.&lt;/p&gt;&lt;p&gt;The researchers also adopted &amp;quot;iterative context extension,&amp;quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.&lt;/p&gt;&lt;p&gt;Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;The looming data shortage that could slow AI coding model progress&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Buried in Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report&lt;/a&gt; is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &amp;quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&amp;quot;&lt;/p&gt;&lt;p&gt;In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.&lt;/p&gt;&lt;p&gt;&amp;quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&amp;quot; Li wrote, referring to the 24,000 problems used for training. &amp;quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &amp;quot;increasingly finite,&amp;quot; as Li put it.&lt;/p&gt;&lt;p&gt;&amp;quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&amp;quot; he concluded.&lt;/p&gt;&lt;p&gt;The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&amp;#x27;t — making synthetic data generation considerably more difficult.&lt;/p&gt;&lt;p&gt;Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &amp;quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&amp;quot; he wrote.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;A $65 million bet that open-source AI can compete with Big Tech&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Nous Research has carved out a distinctive position in the AI landscape: a company committed to &lt;a href="https://nousresearch.com/"&gt;open-source releases&lt;/a&gt; that compete with — and sometimes exceed — proprietary alternatives.&lt;/p&gt;&lt;p&gt;The company raised&lt;a href="https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/"&gt; $50 million in April 2025&lt;/a&gt; in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its &lt;a href="https://psyche.network/"&gt;Psyche platform&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Previous releases include &lt;a href="https://hermes4.nousresearch.com/"&gt;Hermes 4&lt;/a&gt;, a family of models that we reported &amp;quot;&lt;a href="https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions"&gt;outperform ChatGPT without content restrictions&lt;/a&gt;,&amp;quot; and DeepHermes-3, which the company described as the first &amp;quot;&lt;a href="https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3"&gt;toggle-on reasoning model&lt;/a&gt;&amp;quot; — allowing users to activate extended thinking capabilities on demand.&lt;/p&gt;&lt;p&gt;The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &amp;quot;Ofc i&amp;#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&amp;quot; &lt;a href="https://x.com/shydev69/status/2008654826356535510?s=20"&gt;wrote one critic on X&lt;/a&gt;, referring to Nous Research&amp;#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.&lt;/p&gt;&lt;p&gt;Others raised technical questions. &amp;quot;&lt;a href="https://x.com/yehor_smoliakov/status/2008659681489940757?s=20"&gt;Based on the benchmark, Nemotron is better&lt;/a&gt;,&amp;quot; noted one commenter, referring to Nvidia&amp;#x27;s family of language models. Another asked whether &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; is &amp;quot;agentic focused or just &amp;#x27;one shot&amp;#x27; coding&amp;quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;What researchers say must happen next for AI coding tools to keep improving&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The release includes several directions for future work that hint at where AI coding research may be heading.&lt;/p&gt;&lt;p&gt;Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.&lt;/p&gt;&lt;p&gt;Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.&lt;/p&gt;&lt;p&gt;Perhaps most ambitiously, Li proposed &amp;quot;problem generation and self-play&amp;quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.&lt;/p&gt;&lt;p&gt;&amp;quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&amp;quot; Li wrote.&lt;/p&gt;&lt;p&gt;The model is &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;available now on Hugging Face&lt;/a&gt; under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos training stack&lt;/a&gt; alongside it.&lt;/p&gt;&lt;p&gt;What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.&lt;/p&gt;&lt;p&gt;The question is no longer whether machines can learn to code. It&amp;#x27;s whether they&amp;#x27;ll soon be better teachers than we ever were.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://nousresearch.com/"&gt;Nous Research&lt;/a&gt;, the open-source artificial intelligence startup backed by crypto venture firm &lt;a href="https://www.paradigm.xyz/"&gt;Paradigm&lt;/a&gt;, released a new competitive programming model on Monday that it says matches or exceeds several larger proprietary systems — trained in just four days using 48 of Nvidia&amp;#x27;s latest &lt;a href="https://www.nvidia.com/en-us/data-center/dgx-b200/"&gt;B200 graphics processors&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The model, called &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;, is another entry in a crowded field of AI coding assistants, but arrives at a particularly charged moment: &lt;a href="https://claude.com/product/claude-code"&gt;Claude Code&lt;/a&gt;, the agentic programming tool from rival Anthropic, has dominated social media discussion since New Year&amp;#x27;s Day, with developers posting &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;breathless&lt;/a&gt; &lt;a href="https://x.com/hayesdev_/status/2008043379805048948"&gt;testimonials&lt;/a&gt; &lt;a href="https://x.com/0xDesigner/status/2008202211738648767?s=20"&gt;about its capabilities&lt;/a&gt;. The simultaneous developments underscore how quickly AI-assisted software development is evolving — and how fiercely companies large and small are competing to capture what many believe will become a foundational technology for how software gets written.&lt;/p&gt;&lt;p&gt;&lt;span&gt;type: &lt;!-- --&gt;embedded-entry-inline&lt;!-- --&gt; id: &lt;!-- --&gt;74cSyrq6OUrp9SEQ5zOUSl&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;NousCoder-14B&lt;/a&gt; achieves a 67.87 percent accuracy rate on &lt;a href="https://livecodebench.github.io/"&gt;LiveCodeBench v6&lt;/a&gt;, a standardized evaluation that tests models on competitive programming problems published between August 2024 and May 2025. That figure represents a 7.08 percentage point improvement over the base model it was trained from, Alibaba&amp;#x27;s &lt;a href="https://huggingface.co/Qwen/Qwen3-14B"&gt;Qwen3-14B&lt;/a&gt;, according to Nous Research&amp;#x27;s technical report published alongside the release.&lt;/p&gt;&lt;p&gt;&amp;quot;I gave Claude Code a description of the problem, it generated what we built last year in an hour,&amp;quot; &lt;a href="https://www.reddit.com/r/OpenAI/comments/1q2uuil/google_engineer_im_not_joking_and_this_isnt_funny/"&gt;wrote Jaana Dogan&lt;/a&gt;, a principal engineer at Google responsible for the Gemini API, in a viral post on X last week that captured the prevailing mood around AI coding tools. Dogan was describing a distributed agent orchestration system her team had spent a year developing — a system Claude Code approximated from a three-paragraph prompt.&lt;/p&gt;&lt;p&gt;The juxtaposition is instructive: while Anthropic&amp;#x27;s &lt;a href="https://venturebeat.com/technology/the-creator-of-claude-code-just-revealed-his-workflow-and-developers-are"&gt;Claude Code has captured imaginations&lt;/a&gt; with demonstrations of end-to-end software development, Nous Research is betting that open-source alternatives trained on verifiable problems can close the gap — and that transparency in how these models are built matters as much as raw capability.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;How Nous Research built an AI coding model that anyone can replicate&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;What distinguishes the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; release from many competitor announcements is its radical openness. Nous Research published not just the &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;model weights&lt;/a&gt; but the &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;complete reinforcement learning environment&lt;/a&gt;, benchmark suite, and training harness — built on the company&amp;#x27;s &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos framework &lt;/a&gt;— enabling any researcher with sufficient compute to &lt;a href="https://wandb.ai/jli505/qwen14b/reports/HermesCoder-14B--VmlldzoxNTQ5Nzc0MQ?accessToken=4pt3stwyh4x83zqe2jgoo5j9b7j07jbe5omf2n40lray3tih17vfkavjootvnw8o"&gt;reproduce or extend the work&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Open-sourcing the Atropos stack provides the necessary infrastructure for reproducible olympiad-level reasoning research,&amp;quot; &lt;a href="https://x.com/o_mega___/status/2008907268700475450?s=20"&gt;noted one observer on X&lt;/a&gt;, summarizing the significance for the academic and open-source communities.&lt;/p&gt;&lt;p&gt;The model was trained by &lt;a href="https://x.com/JoeLi5050"&gt;Joe Li&lt;/a&gt;, a researcher in residence at Nous Research and a former competitive programmer himself. Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report &lt;/a&gt;reveals an unexpectedly personal dimension: he compared the model&amp;#x27;s improvement trajectory to his own journey on Codeforces, the competitive programming platform where participants earn ratings based on contest performance.&lt;/p&gt;&lt;p&gt;Based on rough estimates mapping LiveCodeBench scores to Codeforces ratings, Li calculated that NousCoder-14B&amp;#x27;s improvemen t— from approximately the 1600-1750 rating range to 2100-2200 — mirrors a leap that took him nearly two years of sustained practice between ages 14 and 16. The model accomplished the equivalent in four days.&lt;/p&gt;&lt;p&gt;&amp;quot;Watching that final training run unfold was quite a surreal experience,&amp;quot; Li wrote in the technical report.&lt;/p&gt;&lt;p&gt;But Li was quick to note an important caveat that speaks to broader questions about AI efficiency: he solved roughly 1,000 problems during those two years, while the model required 24,000. Humans, at least for now, remain dramatically more sample-efficient learners.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;Inside the reinforcement learning system that trains on 24,000 competitive programming problems&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt;&amp;#x27;s training process offers a window into the increasingly sophisticated techniques researchers use to improve AI reasoning capabilities through reinforcement learning.&lt;/p&gt;&lt;p&gt;The approach relies on what researchers call &amp;quot;verifiable rewards&amp;quot; — a system where the model generates code solutions, those solutions are executed against test cases, and the model receives a simple binary signal: correct or incorrect. This feedback loop, while conceptually straightforward, requires significant infrastructure to execute at scale.&lt;/p&gt;&lt;p&gt;Nous Research used &lt;a href="https://modal.com/"&gt;Modal&lt;/a&gt;, a cloud computing platform, to run sandboxed code execution in parallel. Each of the 24,000 training problems contains hundreds of test cases on average, and the system must verify that generated code produces correct outputs within time and memory constraints — 15 seconds and 4 gigabytes, respectively.&lt;/p&gt;&lt;p&gt;The training employed a technique called &lt;a href="https://dapo-sia.github.io/"&gt;DAPO (Dynamic Sampling Policy Optimization)&lt;/a&gt;, which the researchers found performed slightly better than alternatives in their experiments. A key innovation involves &amp;quot;dynamic sampling&amp;quot; — discarding training examples where the model either solves all attempts or fails all attempts, since these provide no useful gradient signal for learning.&lt;/p&gt;&lt;p&gt;The researchers also adopted &amp;quot;iterative context extension,&amp;quot; first training the model with a 32,000-token context window before expanding to 40,000 tokens. During evaluation, extending the context further to approximately 80,000 tokens produced the best results, with accuracy reaching 67.87 percent.&lt;/p&gt;&lt;p&gt;Perhaps most significantly, the training pipeline overlaps inference and verification — as soon as the model generates a solution, it begins work on the next problem while the previous solution is being checked. This pipelining, combined with asynchronous training where multiple model instances work in parallel, maximizes hardware utilization on expensive GPU clusters.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;The looming data shortage that could slow AI coding model progress&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Buried in Li&amp;#x27;s &lt;a href="https://nousresearch.com/nouscoder-14b-a-competitive-olympiad-programming-model/"&gt;technical report&lt;/a&gt; is a finding with significant implications for the future of AI development: the training dataset for NousCoder-14B encompasses &amp;quot;a significant portion of all readily available, verifiable competitive programming problems in a standardized dataset format.&amp;quot;&lt;/p&gt;&lt;p&gt;In other words, for this particular domain, the researchers are approaching the limits of high-quality training data.&lt;/p&gt;&lt;p&gt;&amp;quot;The total number of competitive programming problems on the Internet is roughly the same order of magnitude,&amp;quot; Li wrote, referring to the 24,000 problems used for training. &amp;quot;This suggests that within the competitive programming domain, we have approached the limits of high-quality data.&amp;quot;&lt;/p&gt;&lt;p&gt;This observation echoes growing concern across the AI industry about data constraints. While compute continues to scale according to well-understood economic and engineering principles, training data is &amp;quot;increasingly finite,&amp;quot; as Li put it.&lt;/p&gt;&lt;p&gt;&amp;quot;It appears that some of the most important research that needs to be done in the future will be in the areas of synthetic data generation and data efficient algorithms and architectures,&amp;quot; he concluded.&lt;/p&gt;&lt;p&gt;The challenge is particularly acute for competitive programming because the domain requires problems with known correct solutions that can be verified automatically. Unlike natural language tasks where human evaluation or proxy metrics suffice, code either works or it doesn&amp;#x27;t — making synthetic data generation considerably more difficult.&lt;/p&gt;&lt;p&gt;Li identified one potential avenue: training models not just to solve problems but to generate solvable problems, enabling a form of self-play similar to techniques that proved successful in game-playing AI systems. &amp;quot;Once synthetic problem generation is solved, self-play becomes a very interesting direction,&amp;quot; he wrote.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;A $65 million bet that open-source AI can compete with Big Tech&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Nous Research has carved out a distinctive position in the AI landscape: a company committed to &lt;a href="https://nousresearch.com/"&gt;open-source releases&lt;/a&gt; that compete with — and sometimes exceed — proprietary alternatives.&lt;/p&gt;&lt;p&gt;The company raised&lt;a href="https://fortune.com/crypto/2025/04/25/paradigm-nous-research-crypto-ai-venture-capital-deepseek-openai-blockchain/"&gt; $50 million in April 2025&lt;/a&gt; in a round led by Paradigm, the cryptocurrency-focused venture firm founded by Coinbase co-founder Fred Ehrsam. Total funding reached $65 million, according to some reports. The investment reflected growing interest in decentralized approaches to AI training, an area where Nous Research has developed its &lt;a href="https://psyche.network/"&gt;Psyche platform&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Previous releases include &lt;a href="https://hermes4.nousresearch.com/"&gt;Hermes 4&lt;/a&gt;, a family of models that we reported &amp;quot;&lt;a href="https://venturebeat.com/ai/nous-research-drops-hermes-4-ai-models-that-outperform-chatgpt-without-content-restrictions"&gt;outperform ChatGPT without content restrictions&lt;/a&gt;,&amp;quot; and DeepHermes-3, which the company described as the first &amp;quot;&lt;a href="https://venturebeat.com/ai/personalized-unrestricted-ai-lab-nous-research-launches-first-toggle-on-reasoning-model-deephermes-3"&gt;toggle-on reasoning model&lt;/a&gt;&amp;quot; — allowing users to activate extended thinking capabilities on demand.&lt;/p&gt;&lt;p&gt;The company has cultivated a distinctive aesthetic and community, prompting some skepticism about whether style might overshadow substance. &amp;quot;Ofc i&amp;#x27;m gonna believe an anime pfp company. stop benchmarkmaxxing ffs,&amp;quot; &lt;a href="https://x.com/shydev69/status/2008654826356535510?s=20"&gt;wrote one critic on X&lt;/a&gt;, referring to Nous Research&amp;#x27;s anime-style branding and the industry practice of optimizing for benchmark performance.&lt;/p&gt;&lt;p&gt;Others raised technical questions. &amp;quot;&lt;a href="https://x.com/yehor_smoliakov/status/2008659681489940757?s=20"&gt;Based on the benchmark, Nemotron is better&lt;/a&gt;,&amp;quot; noted one commenter, referring to Nvidia&amp;#x27;s family of language models. Another asked whether &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;NousCoder-14B&lt;/a&gt; is &amp;quot;agentic focused or just &amp;#x27;one shot&amp;#x27; coding&amp;quot; — a distinction that matters for practical software development, where iterating on feedback typically produces better results than single attempts.&lt;/p&gt;&lt;hr /&gt;&lt;h2&gt;&lt;b&gt;What researchers say must happen next for AI coding tools to keep improving&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The release includes several directions for future work that hint at where AI coding research may be heading.&lt;/p&gt;&lt;p&gt;Multi-turn reinforcement learning tops the list. Currently, the model receives only a final binary reward — pass or fail — after generating a solution. But competitive programming problems typically include public test cases that provide intermediate feedback: compilation errors, incorrect outputs, time limit violations. Training models to incorporate this feedback across multiple attempts could significantly improve performance.&lt;/p&gt;&lt;p&gt;Controlling response length also remains a challenge. The researchers found that incorrect solutions tended to be longer than correct ones, and response lengths quickly saturated available context windows during training — a pattern that various algorithmic modifications failed to resolve.&lt;/p&gt;&lt;p&gt;Perhaps most ambitiously, Li proposed &amp;quot;problem generation and self-play&amp;quot; — training models to both solve and create programming problems. This would address the data scarcity problem directly by enabling models to generate their own training curricula.&lt;/p&gt;&lt;p&gt;&amp;quot;Humans are great at generating interesting and useful problems for other competitive programmers, but it appears that there still exists a significant gap in LLM capabilities in creative problem generation,&amp;quot; Li wrote.&lt;/p&gt;&lt;p&gt;The model is &lt;a href="https://huggingface.co/NousResearch/NousCoder-14B"&gt;available now on Hugging Face&lt;/a&gt; under an Apache 2.0 license. For researchers and developers who want to build on the work, Nous Research has published the complete &lt;a href="https://github.com/NousResearch/atropos/pull/296"&gt;Atropos training stack&lt;/a&gt; alongside it.&lt;/p&gt;&lt;p&gt;What took Li two years of adolescent dedication to achieve—climbing from a 1600-level novice to a 2100-rated competitor on Codeforces—an AI replicated in 96 hours. He needed 1,000 problems. The model needed 24,000. But soon enough, these systems may learn to write their own problems, teach themselves, and leave human benchmarks behind entirely.&lt;/p&gt;&lt;p&gt;The question is no longer whether machines can learn to code. It&amp;#x27;s whether they&amp;#x27;ll soon be better teachers than we ever were.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/technology/nous-researchs-nouscoder-14b-is-an-open-source-coding-model-landing-right-in</guid><pubDate>Wed, 07 Jan 2026 20:00:00 +0000</pubDate></item><item><title>Stone Center on Inequality and Shaping the Future of Work Launches at MIT (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/stone-center-inequality-shaping-future-work-launches-0107</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-stone-center-launch.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work officially&amp;nbsp;launched on Nov. 3, 2025, bringing together scholars, policymakers, and practitioners to explore critical questions about economic opportunity, technology, and democracy.&lt;/p&gt;&lt;p&gt;Co-directed by MIT professors&amp;nbsp;Daron Acemoglu,&amp;nbsp;David Autor, and&amp;nbsp;Simon Johnson, the new&amp;nbsp;Stone Center analyzes the forces that contribute to growing income and wealth inequality through the erosion of job quality and labor market opportunities for workers without a college degree. The center identifies innovative ways to move the economy onto a more equitable trajectory.&lt;/p&gt;&lt;p&gt;MIT Provost&amp;nbsp;Anantha Chandrakasan&amp;nbsp;opened the launch event by emphasizing the urgency and importance of the center's mission. “As artificial intelligence tools become more powerful, and as they are deployed more broadly,” he said, “we will need to strive to ensure that people from all kinds of backgrounds can find opportunity in the economy.”&lt;/p&gt;&lt;p&gt;Here are some of the key takeaways from participants in the afternoon’s discussions on&amp;nbsp;wealth inequality,&amp;nbsp;liberalism, and&amp;nbsp;pro-worker AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Wealth inequality is driven by private business and public policy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Owen Zidar of Princeton University stressed that owners of businesses like car dealerships, construction firms, and franchises make up a significant portion of the top 1 percent. “For every public company CEO that gets a lot of attention,” he explained, “there are a thousand private business owners who have at least $25 million in wealth.” These business owners have outsized political influence through overrepresentation, lobbying, and donations.&lt;/p&gt;&lt;p&gt;Atif Mian of Princeton University connected high inequality to the U.S. debt crisis, arguing that massive savings at the top aren’t being channeled into productive investment. Instead, falling interest rates push the government to run increasingly large fiscal deficits.&lt;/p&gt;&lt;p&gt;To mitigate wealth inequality, speakers highlighted policy proposals including rolling back the 20 percent deduction for private business owners and increasing taxes on wealth.&lt;/p&gt;&lt;p&gt;However, policies must be carefully designed.&amp;nbsp;Antoinette Schoar of the MIT Sloan School of Management explained how mortgage subsidy policies after the 2008 financial crisis actually worsened inequality by disadvantaging poorer potential homeowners.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Governments must provide basic public goods and economic security&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Marc Dunkelman of the Watson School of International and Public Affairs at Brown University identified excessive red tape as a key problem for modern liberal democracy. “We can’t build high-speed rail. You can’t build enough housing,” he explained. “That spurs ordinary people who want government to work into the populist camp. We did this to ourselves.”&lt;/p&gt;&lt;p&gt;Josh Cohen of Apple University/the University of California at Berkeley emphasized that liberalism must deliver shared prosperity and fair opportunities, not just protect individual freedoms. When people lack economic security, they may turn to leaders who abandon liberal principles altogether.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Liberal democracy needs to adapt while keeping its core values&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Helena Rosenblatt Dhar of the City University of New York Graduate Center noted that liberalism and democracy have not always been allies. Historically, “civil equality was very important, but not political equality,” she said. “Liberals were very wary of the masses.”&lt;/p&gt;&lt;p&gt;Speakers emphasized that liberalism’s challenge today is maintaining its commitments to limiting authoritarian power and protecting fundamental freedoms, while addressing its failures.&lt;/p&gt;&lt;p&gt;Doing so, in Dunkelman’s view, would mean working to “eliminate the sowing [of] the seeds of populism by making government properly balance individual rights and the will of the many.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;People-centric politics requires regulating social media&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In&amp;nbsp;his keynote at the launch, U.S. Representative&amp;nbsp;Jake Auchincloss (Massachusetts 4th District) connected these notions of government effectiveness and public trust to the influence of technology. He emphasized the need to regulate social media platforms.&lt;/p&gt;&lt;p&gt;“In my opinion, media is upstream of culture, which is upstream of politics,” he said. “If we want a better culture, and certainly if we want a better politics, we need a better media.”&lt;/p&gt;&lt;p&gt;Auchincloss proposed that regulation should include holding social media companies liable for content and banning targeted advertising to minors.&lt;/p&gt;&lt;p&gt;He also echoed the urgency and importance of the center’s research agenda, particularly to understand whether AI will augment or replace labor.&lt;/p&gt;&lt;p&gt;“My bias has always been: Technology creates more jobs,” he said. “Maybe it’s different this time. Maybe I’m wrong.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Augmentation is key to pro-worker AI — but it may require alternative AI architectures&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Stone Center co-director Daron Acemoglu argued that expanding what humans can do, rather than automating their tasks, is essential for achieving pro-worker AI.&lt;/p&gt;&lt;p&gt;However, Acemoglu cautioned that this won’t happen by itself, noting that the business models of tech companies and their focus on artificial general intelligence are not aligned with a pro-worker vision for AI. This vision may require public investment in alternative AI architectures focused on “domain-specific, reliable knowledge.”&lt;/p&gt;&lt;p&gt;Ethan Mollick of the Wharton School of the University of Pennsylvania noted that AI labs are explicitly trying to “replace people at everything” and are “absolutely convinced that they can do this in the very near term.”&lt;/p&gt;&lt;p&gt;Meanwhile, companies have “no model for AI adoption,” Mollick explained. “There is absolute confusion.” Even so, “there’s enough money at stake [that] the machine keeps moving forward,” underscoring the urgency of intervention.&lt;/p&gt;&lt;p&gt;In a glimpse of what such intervention could look like,&amp;nbsp;Zana Buçinca of Microsoft shared research findings that accounting for workers’ values and cognition in AI design can enable better complementarity.&lt;/p&gt;&lt;p&gt;“The impact of AI on human work is not destiny,” she emphasized. “It’s design.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/mit-stone-center-launch.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The James M. and Cathleen D. Stone Center on Inequality and Shaping the Future of Work officially&amp;nbsp;launched on Nov. 3, 2025, bringing together scholars, policymakers, and practitioners to explore critical questions about economic opportunity, technology, and democracy.&lt;/p&gt;&lt;p&gt;Co-directed by MIT professors&amp;nbsp;Daron Acemoglu,&amp;nbsp;David Autor, and&amp;nbsp;Simon Johnson, the new&amp;nbsp;Stone Center analyzes the forces that contribute to growing income and wealth inequality through the erosion of job quality and labor market opportunities for workers without a college degree. The center identifies innovative ways to move the economy onto a more equitable trajectory.&lt;/p&gt;&lt;p&gt;MIT Provost&amp;nbsp;Anantha Chandrakasan&amp;nbsp;opened the launch event by emphasizing the urgency and importance of the center's mission. “As artificial intelligence tools become more powerful, and as they are deployed more broadly,” he said, “we will need to strive to ensure that people from all kinds of backgrounds can find opportunity in the economy.”&lt;/p&gt;&lt;p&gt;Here are some of the key takeaways from participants in the afternoon’s discussions on&amp;nbsp;wealth inequality,&amp;nbsp;liberalism, and&amp;nbsp;pro-worker AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Wealth inequality is driven by private business and public policy&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Owen Zidar of Princeton University stressed that owners of businesses like car dealerships, construction firms, and franchises make up a significant portion of the top 1 percent. “For every public company CEO that gets a lot of attention,” he explained, “there are a thousand private business owners who have at least $25 million in wealth.” These business owners have outsized political influence through overrepresentation, lobbying, and donations.&lt;/p&gt;&lt;p&gt;Atif Mian of Princeton University connected high inequality to the U.S. debt crisis, arguing that massive savings at the top aren’t being channeled into productive investment. Instead, falling interest rates push the government to run increasingly large fiscal deficits.&lt;/p&gt;&lt;p&gt;To mitigate wealth inequality, speakers highlighted policy proposals including rolling back the 20 percent deduction for private business owners and increasing taxes on wealth.&lt;/p&gt;&lt;p&gt;However, policies must be carefully designed.&amp;nbsp;Antoinette Schoar of the MIT Sloan School of Management explained how mortgage subsidy policies after the 2008 financial crisis actually worsened inequality by disadvantaging poorer potential homeowners.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Governments must provide basic public goods and economic security&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Marc Dunkelman of the Watson School of International and Public Affairs at Brown University identified excessive red tape as a key problem for modern liberal democracy. “We can’t build high-speed rail. You can’t build enough housing,” he explained. “That spurs ordinary people who want government to work into the populist camp. We did this to ourselves.”&lt;/p&gt;&lt;p&gt;Josh Cohen of Apple University/the University of California at Berkeley emphasized that liberalism must deliver shared prosperity and fair opportunities, not just protect individual freedoms. When people lack economic security, they may turn to leaders who abandon liberal principles altogether.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Liberal democracy needs to adapt while keeping its core values&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Helena Rosenblatt Dhar of the City University of New York Graduate Center noted that liberalism and democracy have not always been allies. Historically, “civil equality was very important, but not political equality,” she said. “Liberals were very wary of the masses.”&lt;/p&gt;&lt;p&gt;Speakers emphasized that liberalism’s challenge today is maintaining its commitments to limiting authoritarian power and protecting fundamental freedoms, while addressing its failures.&lt;/p&gt;&lt;p&gt;Doing so, in Dunkelman’s view, would mean working to “eliminate the sowing [of] the seeds of populism by making government properly balance individual rights and the will of the many.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;People-centric politics requires regulating social media&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In&amp;nbsp;his keynote at the launch, U.S. Representative&amp;nbsp;Jake Auchincloss (Massachusetts 4th District) connected these notions of government effectiveness and public trust to the influence of technology. He emphasized the need to regulate social media platforms.&lt;/p&gt;&lt;p&gt;“In my opinion, media is upstream of culture, which is upstream of politics,” he said. “If we want a better culture, and certainly if we want a better politics, we need a better media.”&lt;/p&gt;&lt;p&gt;Auchincloss proposed that regulation should include holding social media companies liable for content and banning targeted advertising to minors.&lt;/p&gt;&lt;p&gt;He also echoed the urgency and importance of the center’s research agenda, particularly to understand whether AI will augment or replace labor.&lt;/p&gt;&lt;p&gt;“My bias has always been: Technology creates more jobs,” he said. “Maybe it’s different this time. Maybe I’m wrong.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Augmentation is key to pro-worker AI — but it may require alternative AI architectures&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Stone Center co-director Daron Acemoglu argued that expanding what humans can do, rather than automating their tasks, is essential for achieving pro-worker AI.&lt;/p&gt;&lt;p&gt;However, Acemoglu cautioned that this won’t happen by itself, noting that the business models of tech companies and their focus on artificial general intelligence are not aligned with a pro-worker vision for AI. This vision may require public investment in alternative AI architectures focused on “domain-specific, reliable knowledge.”&lt;/p&gt;&lt;p&gt;Ethan Mollick of the Wharton School of the University of Pennsylvania noted that AI labs are explicitly trying to “replace people at everything” and are “absolutely convinced that they can do this in the very near term.”&lt;/p&gt;&lt;p&gt;Meanwhile, companies have “no model for AI adoption,” Mollick explained. “There is absolute confusion.” Even so, “there’s enough money at stake [that] the machine keeps moving forward,” underscoring the urgency of intervention.&lt;/p&gt;&lt;p&gt;In a glimpse of what such intervention could look like,&amp;nbsp;Zana Buçinca of Microsoft shared research findings that accounting for workers’ values and cognition in AI design can enable better complementarity.&lt;/p&gt;&lt;p&gt;“The impact of AI on human work is not destiny,” she emphasized. “It’s design.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/stone-center-inequality-shaping-future-work-launches-0107</guid><pubDate>Wed, 07 Jan 2026 20:30:00 +0000</pubDate></item><item><title>OpenAI unveils ChatGPT Health, says 230 million users ask about health each week (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/openai-unveils-chatgpt-health-says-230-million-users-ask-about-health-each-week/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/chatgpt-health1.webp?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced ChatGPT Health on Wednesday, which the company said will offer a dedicated space for users to have conversations with ChatGPT about their health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;People already use ChatGPT to ask about medical issues; OpenAI says that over 230 million people ask health and wellness questions on the platform each week. But the ChatGPT Health product silos these conversations away from your other chats. That way, the context of your health won’t come up in standard conversations with ChatGPT. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If people start chats about their health outside of the Health section, then the AI aims to nudge them to switch over.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within Health, the AI might reference things you’ve discussed in its standard experience. If you ask ChatGPT for help constructing a marathon training plan, for example, then the AI would know you’re a runner when you talk in Health about your fitness goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT Health will also be able to integrate with your personal information or medical records from wellness apps like Apple Health, Function, and MyFitnessPal. OpenAI notes that it will not use Health conversations to train its models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO of Applications at OpenAI, Fidji Simo, wrote in a blog post that she sees ChatGPT Health as a response to existing issues in the healthcare space, like cost and access barriers, overbooked doctors, and a lack of continuity in care.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the healthcare system has its drawbacks, using AI chatbots for medical advice creates a new slew of challenges. Large language models (LLMs) like ChatGPT operate by predicting the most likely response to prompts, not the most correct answer, since LLMs don’t have a concept of what is true or not. AI models are also prone to hallucinations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its own terms of service, OpenAI states that it is “not intended for use in the diagnosis or treatment of any health condition.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is expected to roll out in the coming weeks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/chatgpt-health1.webp?resize=1200,857" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced ChatGPT Health on Wednesday, which the company said will offer a dedicated space for users to have conversations with ChatGPT about their health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;People already use ChatGPT to ask about medical issues; OpenAI says that over 230 million people ask health and wellness questions on the platform each week. But the ChatGPT Health product silos these conversations away from your other chats. That way, the context of your health won’t come up in standard conversations with ChatGPT. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;If people start chats about their health outside of the Health section, then the AI aims to nudge them to switch over.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Within Health, the AI might reference things you’ve discussed in its standard experience. If you ask ChatGPT for help constructing a marathon training plan, for example, then the AI would know you’re a runner when you talk in Health about your fitness goals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT Health will also be able to integrate with your personal information or medical records from wellness apps like Apple Health, Function, and MyFitnessPal. OpenAI notes that it will not use Health conversations to train its models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The CEO of Applications at OpenAI, Fidji Simo, wrote in a blog post that she sees ChatGPT Health as a response to existing issues in the healthcare space, like cost and access barriers, overbooked doctors, and a lack of continuity in care.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the healthcare system has its drawbacks, using AI chatbots for medical advice creates a new slew of challenges. Large language models (LLMs) like ChatGPT operate by predicting the most likely response to prompts, not the most correct answer, since LLMs don’t have a concept of what is true or not. AI models are also prone to hallucinations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its own terms of service, OpenAI states that it is “not intended for use in the diagnosis or treatment of any health condition.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is expected to roll out in the coming weeks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/openai-unveils-chatgpt-health-says-230-million-users-ask-about-health-each-week/</guid><pubDate>Wed, 07 Jan 2026 21:08:23 +0000</pubDate></item><item><title>AI starts autonomously writing prescription refills in Utah (AI - Ars Technica)</title><link>https://arstechnica.com/health/2026/01/utah-allows-ai-to-autonomously-prescribe-medication-refills/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The program allows patients in the state to get prescription refills for 190 common meds.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty | Roberto Machado Noa

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The state of Utah is allowing artificial intelligence to prescribe medication refills to patients without direct human oversight in a pilot program public advocates call “dangerous.”&lt;/p&gt;
&lt;p&gt;The program is through the state’s “regulatory sandbox” framework, which allows businesses to trial “innovative” products or services with state regulations temporarily waived. The Utah Department of Commerce partnered with Doctronic, a telehealth startup with an AI chatbot.&lt;/p&gt;
&lt;p&gt;Doctronic offers a nationwide service that allows patients to chat with its “AI doctor” for free, then, for $39, book a virtual appointment with a real doctor licensed in their state. But patients must go through the AI chatbot first to get an appointment.&lt;/p&gt;
&lt;p&gt;According to a non-peer-reviewed preprint article from Doctronic, which looked at 500 telehealth cases in its service, the company claims its AI’s diagnosis matched the diagnosis made by a real clinician in 81 percent of cases. The AI’s treatment plan was “consistent” with that of a doctor’s in 99 percent of the cases.&lt;/p&gt;
&lt;p&gt;Now, for patients in Utah, Doctronic’s chatbot can refill a prescription without a doctor, for a $4 service fee . After a patient signs in and verifies state residency, the AI chatbot can pull up the patient’s prescription history and offer a list of prescription medications eligible for a refill. According to Politico, the chatbot will only be able to renew prescriptions for 190 common medications for chronic conditions, with key exclusions, such as medications for pain and ADHD, and those that are injected.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Caution&lt;/h2&gt;
&lt;p&gt;The first 250 renewals for each drug class will be reviewed by real doctors, but after that, the AI chatbot will be on its own. Adam Oskowitz, Doctronic co-founder and a professor at the University of California, San Francisco, told Politico that the AI chatbot is designed to err on the side of safety and escalate any case with uncertainty to a real doctor.&lt;/p&gt;
&lt;p&gt;“Utah’s approach to regulatory mitigation strikes a vital balance between fostering innovation and ensuring consumer safety,” Margaret Woolley Busse, executive director of the Utah Department of Commerce, said in a statement.&lt;/p&gt;
&lt;p&gt;For now, it’s unclear if the Food and Drug Administration will step in to regulate AI prescribing. On the one hand, prescription renewals are a matter of practicing medicine, which falls under state governance. However, Politico notes that the FDA has said that it has the authority to regulate medical devices used to diagnose, treat, or prevent disease.&lt;/p&gt;
&lt;p&gt;In a statement, Robert Steinbrook, health research group director at watchdog Public Citizen, blasted Doctronic’s program and the lack of oversight. “AI should not be autonomously refilling prescriptions, nor identifying itself as an ‘AI doctor,'” Steinbrook said.&lt;/p&gt;
&lt;p&gt;“Although the thoughtful application of AI can help to improve aspects of medical care, the Utah pilot program is a dangerous first step toward more autonomous medical practice,” he said."The FDA and other federal regulatory agencies cannot look the other way when AI applications undermine the essential human clinician role in prescribing and renewing medications.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The program allows patients in the state to get prescription refills for 190 common meds.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2017/05/GettyImages-513084906-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty | Roberto Machado Noa

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The state of Utah is allowing artificial intelligence to prescribe medication refills to patients without direct human oversight in a pilot program public advocates call “dangerous.”&lt;/p&gt;
&lt;p&gt;The program is through the state’s “regulatory sandbox” framework, which allows businesses to trial “innovative” products or services with state regulations temporarily waived. The Utah Department of Commerce partnered with Doctronic, a telehealth startup with an AI chatbot.&lt;/p&gt;
&lt;p&gt;Doctronic offers a nationwide service that allows patients to chat with its “AI doctor” for free, then, for $39, book a virtual appointment with a real doctor licensed in their state. But patients must go through the AI chatbot first to get an appointment.&lt;/p&gt;
&lt;p&gt;According to a non-peer-reviewed preprint article from Doctronic, which looked at 500 telehealth cases in its service, the company claims its AI’s diagnosis matched the diagnosis made by a real clinician in 81 percent of cases. The AI’s treatment plan was “consistent” with that of a doctor’s in 99 percent of the cases.&lt;/p&gt;
&lt;p&gt;Now, for patients in Utah, Doctronic’s chatbot can refill a prescription without a doctor, for a $4 service fee . After a patient signs in and verifies state residency, the AI chatbot can pull up the patient’s prescription history and offer a list of prescription medications eligible for a refill. According to Politico, the chatbot will only be able to renew prescriptions for 190 common medications for chronic conditions, with key exclusions, such as medications for pain and ADHD, and those that are injected.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Caution&lt;/h2&gt;
&lt;p&gt;The first 250 renewals for each drug class will be reviewed by real doctors, but after that, the AI chatbot will be on its own. Adam Oskowitz, Doctronic co-founder and a professor at the University of California, San Francisco, told Politico that the AI chatbot is designed to err on the side of safety and escalate any case with uncertainty to a real doctor.&lt;/p&gt;
&lt;p&gt;“Utah’s approach to regulatory mitigation strikes a vital balance between fostering innovation and ensuring consumer safety,” Margaret Woolley Busse, executive director of the Utah Department of Commerce, said in a statement.&lt;/p&gt;
&lt;p&gt;For now, it’s unclear if the Food and Drug Administration will step in to regulate AI prescribing. On the one hand, prescription renewals are a matter of practicing medicine, which falls under state governance. However, Politico notes that the FDA has said that it has the authority to regulate medical devices used to diagnose, treat, or prevent disease.&lt;/p&gt;
&lt;p&gt;In a statement, Robert Steinbrook, health research group director at watchdog Public Citizen, blasted Doctronic’s program and the lack of oversight. “AI should not be autonomously refilling prescriptions, nor identifying itself as an ‘AI doctor,'” Steinbrook said.&lt;/p&gt;
&lt;p&gt;“Although the thoughtful application of AI can help to improve aspects of medical care, the Utah pilot program is a dangerous first step toward more autonomous medical practice,” he said."The FDA and other federal regulatory agencies cannot look the other way when AI applications undermine the essential human clinician role in prescribing and renewing medications.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/health/2026/01/utah-allows-ai-to-autonomously-prescribe-medication-refills/</guid><pubDate>Wed, 07 Jan 2026 22:20:08 +0000</pubDate></item><item><title>Ford has an AI assistant and new hands-free BlueCruise tech on the way (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/ford-has-an-ai-assistant-and-new-hands-free-bluecruise-tech-on-the-way/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ford-ai-assistant.jpg?w=589" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ford is developing an AI assistant that will debut in the company’s smartphone app, before expanding to its vehicles in 2027, the company announced Wednesday at the 2026 Consumer Electronics Show. The company also teased a next-generation of its BlueCruise advanced driver assistance system that is both cheaper to make and more capable — ultimately leading to eyes-off driving in 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wednesday’s announcement was one of the only ones to come from a major automaker at CES, marking a sharp turnaround from the late 2010s when they dominated the show. And it wasn’t made at a flashy keynote event; rather, Ford discussed the news at a speaker session called “Great Minds” that was meant to “explore the intersection of technology and humanity.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ford says it digital assistant is hosted by Google Cloud and will be built using off-the-shelf LLMs, and the company is giving it deep access to vehicle-specific information. That means the assistant can answer high-level questions like “how many bags of mulch can my truck bed support?” But it also means owners will be able to ask for granular, real-time information like oil life. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is rolling the assistant out to its newly revamped Ford app in early 2026. A native, in-vehicle integration will come in 2027, though the company wouldn’t specify which models it’s prioritizing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ford didn’t go into great detail about what the in-car experience will look like, but it’s not hard to imagine the possibilities when looking at some of the more tech-forward automakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just last month, Rivian showed off its own digital assistant sending and receiving text messages, handling complex navigation requests, and changing climate controls. Tesla has integrated Elon Musk’s chatbot Grok in its vehicles, which customers have used to generate on-the-spot sightseeing tours. Some of those capabilities may eclipse what Ford has in mind, but the automaker also has a full year to hammer out the in-car integration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new BlueCruise system teased on Wednesday is 30% cheaper to build than the current technology, according to Ford. It will debut in 2027 on the first EV to be built on the company’s low-cost “Universal Electric Vehicle” platform, which is expected to be a mid-sized pickup.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is promising more with this next-generation BlueCruise system, including eyes-off driving in 2028. But it also claims the system will be capable of handling “point-to-point autonomy,” similar to what Tesla offers with its Full Self-Driving (Supervised) software. Rivian has also teased a point-to-point system coming later this year. All of these systems require the drivers to be ready to take control of the car at any moment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ford-ai-assistant.jpg?w=589" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ford is developing an AI assistant that will debut in the company’s smartphone app, before expanding to its vehicles in 2027, the company announced Wednesday at the 2026 Consumer Electronics Show. The company also teased a next-generation of its BlueCruise advanced driver assistance system that is both cheaper to make and more capable — ultimately leading to eyes-off driving in 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wednesday’s announcement was one of the only ones to come from a major automaker at CES, marking a sharp turnaround from the late 2010s when they dominated the show. And it wasn’t made at a flashy keynote event; rather, Ford discussed the news at a speaker session called “Great Minds” that was meant to “explore the intersection of technology and humanity.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ford says it digital assistant is hosted by Google Cloud and will be built using off-the-shelf LLMs, and the company is giving it deep access to vehicle-specific information. That means the assistant can answer high-level questions like “how many bags of mulch can my truck bed support?” But it also means owners will be able to ask for granular, real-time information like oil life. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is rolling the assistant out to its newly revamped Ford app in early 2026. A native, in-vehicle integration will come in 2027, though the company wouldn’t specify which models it’s prioritizing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ford didn’t go into great detail about what the in-car experience will look like, but it’s not hard to imagine the possibilities when looking at some of the more tech-forward automakers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just last month, Rivian showed off its own digital assistant sending and receiving text messages, handling complex navigation requests, and changing climate controls. Tesla has integrated Elon Musk’s chatbot Grok in its vehicles, which customers have used to generate on-the-spot sightseeing tours. Some of those capabilities may eclipse what Ford has in mind, but the automaker also has a full year to hammer out the in-car integration.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new BlueCruise system teased on Wednesday is 30% cheaper to build than the current technology, according to Ford. It will debut in 2027 on the first EV to be built on the company’s low-cost “Universal Electric Vehicle” platform, which is expected to be a mid-sized pickup.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Ford is promising more with this next-generation BlueCruise system, including eyes-off driving in 2028. But it also claims the system will be capable of handling “point-to-point autonomy,” similar to what Tesla offers with its Full Self-Driving (Supervised) software. Rivian has also teased a point-to-point system coming later this year. All of these systems require the drivers to be ready to take control of the car at any moment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/ford-has-an-ai-assistant-and-new-hands-free-bluecruise-tech-on-the-way/</guid><pubDate>Thu, 08 Jan 2026 00:00:00 +0000</pubDate></item><item><title>Ford is getting ready to put AI assistants in its cars (AI - Ars Technica)</title><link>https://arstechnica.com/cars/2026/01/in-car-ai-assistant-coming-to-fords-and-lincolns-in-2027/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Blue Oval is also working on new hands-free driver assists.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A car infotainment screen that has AI on it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A car infotainment screen that has AI on it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The annual Consumer Electronics Show is currently raging in Las Vegas, and as has become traditional over the past decade, automakers and their suppliers now use the conference to announce their technology plans. Tonight it was Ford’s turn, and it is very on-trend for 2026. If you guessed that means AI is coming to the Ford in-car experience, congratulations, you guessed right.&lt;/p&gt;
&lt;p&gt;Even though the company owes everything to mass-producing identical vehicles, it says that it wants AI to personalize your car to you. “Our vision for the customer is simple, but not elementary: a seamless layer of intelligence that travels with you between your phone and your vehicle,” said Doug Field, Ford’s chief EV, design, and digital officer.&lt;/p&gt;
&lt;p&gt;“Not generic intelligence—many people can do that better than we can. What customers need is intelligence that understands where you are, what you’re doing, and what your vehicle is capable of, and then makes the next decision simpler,” Field wrote in a blog post Ford shared ahead of time with Ars.&lt;/p&gt;
&lt;p&gt;As an example, Field suggests you could take a photo of something you want to load onto your truck, upload it to the AI, and find out whether it will fit in the bed.&lt;/p&gt;
&lt;p&gt;At first, Ford’s AI assistant will just show up in the Ford and Lincoln smartphone apps. Expect that rollout to happen starting early this year. From 2027, the AI assistant will become a native experience as new or refreshed models are able to include it, possibly starting with the cheap electric truck that the automaker tells us is due next year, but also gas models like the Expedition and Navigator.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Also expect those new or refreshed models to become software-defined vehicles, where dozens of discrete electronic control units have been replaced by a handful of powerful multitasking computers. This is one of the latest trends in automotive design, and at CES this year, Ford is showing off what it calls its “High Performance Compute Center"—perhaps high-performance computer sounded too pedestrian for something with four wheels.&lt;/p&gt;
&lt;p&gt;The new computer was designed in-house and is in charge of infotainment, the advanced driver assistance systems, audio, and networking. Ford says the new computer is much cheaper than previous solutions, while taking up half the volume, even as it offers much better performance. “Our upcoming Universal Electric Vehicle (UEV) architecture incorporates a fivefold increase for the in-house module design, giving us 5X more control over critical semiconductors,” said Paul Costa, executive director of electronics platforms at Ford.&lt;/p&gt;
&lt;p&gt;Moving to a software-defined vehicle architecture, with much more powerful processing for things like perception, means Ford can get a little more ambitious with its partially automated driver assists. According to Field, next year will see the debut of a new generation of its BlueCruise assist that has “significantly more capability at a 30 percent lower cost.” And in 2028, Ford plans to start offering a so-called “level 3” assist, where the driver can give up situational awareness completely under certain circumstances, like heavy highway traffic.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Blue Oval is also working on new hands-free driver assists.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A car infotainment screen that has AI on it" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-640x427.jpg" width="640" /&gt;
                  &lt;img alt="A car infotainment screen that has AI on it" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2222907242-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The annual Consumer Electronics Show is currently raging in Las Vegas, and as has become traditional over the past decade, automakers and their suppliers now use the conference to announce their technology plans. Tonight it was Ford’s turn, and it is very on-trend for 2026. If you guessed that means AI is coming to the Ford in-car experience, congratulations, you guessed right.&lt;/p&gt;
&lt;p&gt;Even though the company owes everything to mass-producing identical vehicles, it says that it wants AI to personalize your car to you. “Our vision for the customer is simple, but not elementary: a seamless layer of intelligence that travels with you between your phone and your vehicle,” said Doug Field, Ford’s chief EV, design, and digital officer.&lt;/p&gt;
&lt;p&gt;“Not generic intelligence—many people can do that better than we can. What customers need is intelligence that understands where you are, what you’re doing, and what your vehicle is capable of, and then makes the next decision simpler,” Field wrote in a blog post Ford shared ahead of time with Ars.&lt;/p&gt;
&lt;p&gt;As an example, Field suggests you could take a photo of something you want to load onto your truck, upload it to the AI, and find out whether it will fit in the bed.&lt;/p&gt;
&lt;p&gt;At first, Ford’s AI assistant will just show up in the Ford and Lincoln smartphone apps. Expect that rollout to happen starting early this year. From 2027, the AI assistant will become a native experience as new or refreshed models are able to include it, possibly starting with the cheap electric truck that the automaker tells us is due next year, but also gas models like the Expedition and Navigator.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Also expect those new or refreshed models to become software-defined vehicles, where dozens of discrete electronic control units have been replaced by a handful of powerful multitasking computers. This is one of the latest trends in automotive design, and at CES this year, Ford is showing off what it calls its “High Performance Compute Center"—perhaps high-performance computer sounded too pedestrian for something with four wheels.&lt;/p&gt;
&lt;p&gt;The new computer was designed in-house and is in charge of infotainment, the advanced driver assistance systems, audio, and networking. Ford says the new computer is much cheaper than previous solutions, while taking up half the volume, even as it offers much better performance. “Our upcoming Universal Electric Vehicle (UEV) architecture incorporates a fivefold increase for the in-house module design, giving us 5X more control over critical semiconductors,” said Paul Costa, executive director of electronics platforms at Ford.&lt;/p&gt;
&lt;p&gt;Moving to a software-defined vehicle architecture, with much more powerful processing for things like perception, means Ford can get a little more ambitious with its partially automated driver assists. According to Field, next year will see the debut of a new generation of its BlueCruise assist that has “significantly more capability at a 30 percent lower cost.” And in 2028, Ford plans to start offering a so-called “level 3” assist, where the driver can give up situational awareness completely under certain circumstances, like heavy highway traffic.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/cars/2026/01/in-car-ai-assistant-coming-to-fords-and-lincolns-in-2027/</guid><pubDate>Thu, 08 Jan 2026 00:00:33 +0000</pubDate></item><item><title>Google and Character.AI negotiate first major settlements in teen chatbot death cases (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/google-and-character-ai-negotiate-first-major-settlements-in-teen-chatbot-death-cases/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1224612965.jpg?resize=1200,842" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In what may mark the tech industry’s first significant legal settlement over AI-related harm, Google and the startup Character.AI are negotiating terms with families whose teenagers died by suicide or harmed themselves after interacting with Character.AI’s chatbot companions. The parties have agreed in principle to settle; now comes the harder work of finalizing the details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These are among the first settlements in lawsuits accusing AI companies of harming users, a legal frontier that must have OpenAI and Meta watching nervously from the wings as they defend themselves against similar lawsuits. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Character.AI founded in 2021 by ex-Google engineers who returned to their former employer in 2024 in a $2.7 billion deal, invites users to chat with AI personas. The most haunting case involves Sewell Setzer III, who at age 14 conducted sexualized conversations with a “Daenerys Targaryen” bot before killing himself. His mother, Megan Garcia, has told the Senate that companies must be “legally accountable when they knowingly design harmful AI technologies that kill kids.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another lawsuit describes a 17-year-old whose chatbot encouraged self-harm and suggested that murdering his parents was reasonable for limiting screen time. Character.AI banned minors last October, it told TechCrunch. The settlements will likely include monetary damages, though no liability was admitted in court filings made available Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI declined to comment, redirecting TechCrunch instead to the filings. Google has not responded to a request for comment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/05/GettyImages-1224612965.jpg?resize=1200,842" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In what may mark the tech industry’s first significant legal settlement over AI-related harm, Google and the startup Character.AI are negotiating terms with families whose teenagers died by suicide or harmed themselves after interacting with Character.AI’s chatbot companions. The parties have agreed in principle to settle; now comes the harder work of finalizing the details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These are among the first settlements in lawsuits accusing AI companies of harming users, a legal frontier that must have OpenAI and Meta watching nervously from the wings as they defend themselves against similar lawsuits. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Character.AI founded in 2021 by ex-Google engineers who returned to their former employer in 2024 in a $2.7 billion deal, invites users to chat with AI personas. The most haunting case involves Sewell Setzer III, who at age 14 conducted sexualized conversations with a “Daenerys Targaryen” bot before killing himself. His mother, Megan Garcia, has told the Senate that companies must be “legally accountable when they knowingly design harmful AI technologies that kill kids.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another lawsuit describes a 17-year-old whose chatbot encouraged self-harm and suggested that murdering his parents was reasonable for limiting screen time. Character.AI banned minors last October, it told TechCrunch. The settlements will likely include monetary damages, though no liability was admitted in court filings made available Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI declined to comment, redirecting TechCrunch instead to the filings. Google has not responded to a request for comment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/google-and-character-ai-negotiate-first-major-settlements-in-teen-chatbot-death-cases/</guid><pubDate>Thu, 08 Jan 2026 01:32:00 +0000</pubDate></item></channel></rss>