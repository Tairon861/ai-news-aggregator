<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 03 Sep 2025 12:41:30 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>3 Questions: The pros and cons of synthetic data in AI (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/3-questions-pros-cons-synthetic-data-ai-kalyan-veeramachaneni-0903</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-3Q-Synthetic-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Synthetic data are artificially generated by algorithms to mimic the statistical properties of actual data, without containing any information from real-world sources. While concrete numbers are hard to pin down, some estimates suggest that more than 60 percent of data used for AI applications in 2024 was synthetic, and this figure is expected to grow across industries.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Because synthetic data don’t contain real-world information, they hold the promise of safeguarding privacy while reducing the cost and increasing the speed at which new AI models are developed. But&amp;nbsp;using synthetic data requires careful&amp;nbsp;evaluation, planning, and checks and balances to prevent loss of performance when AI models are deployed.&amp;nbsp;&amp;nbsp;&lt;/em&gt; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;em&gt;To unpack some pros and cons of using synthetic data,&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; spoke with Kalyan Veeramachaneni, a principal research scientist in the Laboratory for Information and Decision Systems&amp;nbsp;and co-founder of&amp;nbsp;&lt;/em&gt;&lt;em&gt;DataCebo&lt;/em&gt;&lt;em&gt;&amp;nbsp;whose open-core platform,&amp;nbsp;&lt;/em&gt;&lt;em&gt;the Synthetic Data Vault&lt;/em&gt;,&amp;nbsp;&lt;em&gt;helps&lt;/em&gt; &lt;em&gt;users generate and test synthetic data.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;How are synthetic data created?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Synthetic data are algorithmically generated but do not come from a real situation. Their value lies in their statistical similarity to real data. If we’re talking about language, for instance, synthetic data look very much as if a human had written those sentences. While researchers have created synthetic data for a long time, what has changed in the past few years is our ability to build generative models out of data and use them to create realistic synthetic data. We can take a little bit of real data and build a generative model from that, which we can use to create as much synthetic data as we want. Plus, the model creates synthetic data in a way that captures all the underlying rules and infinite patterns that exist in the real data.&lt;/p&gt;&lt;p&gt;There are essentially&amp;nbsp;four&amp;nbsp;different data modalities: language, video or images,&amp;nbsp;audio,&amp;nbsp;and tabular data. All four&amp;nbsp;of them have slightly different ways of building the generative models to create synthetic data. An LLM, for instance, is nothing but a generative model from which you are sampling synthetic data when you ask it a question.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;A lot of language and image data are publicly available on the internet. But tabular data, which is the data collected when we interact with physical and social systems, is often locked up behind enterprise firewalls. Much of it is sensitive or private, such as customer transactions stored by a bank. For this type of data, platforms like the Synthetic Data Vault provide software that can be used to build generative models. Those models then create synthetic data that preserve customer privacy and can be shared more widely.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;One powerful thing about this generative modeling approach for synthesizing data is that enterprises can now build a customized, local model for their own data. Generative AI automates what used to be a manual process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;What are some benefits of using synthetic data, and which use-cases and applications are they particularly well-suited for?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; One fundamental application which has grown tremendously over the past decade is using synthetic data to test software applications. There is data-driven logic behind many software applications, so you need data to test that software and its functionality. In the past, people have resorted to manually generating data, but now we can use generative models to create as much data as we need.&lt;/p&gt;&lt;p&gt;Users can also create specific data for application testing. Say I work for an e-commerce company. I can generate synthetic data that mimics real customers who live in Ohio and made transactions pertaining to one particular product in February or March.&lt;/p&gt;&lt;p&gt;Because synthetic data aren’t drawn from real situations, they are also privacy-preserving. One of the biggest problems in software testing has been getting access to sensitive real data for testing software in non-production environments, due to privacy concerns.&amp;nbsp;Another immediate benefit is in performance testing. You can create a billion transactions from a generative model and test how fast your system can process them.&lt;/p&gt;&lt;p&gt;Another application where synthetic data hold a lot of promise is in training machine-learning models. Sometimes, we want an AI model to help us predict an event that is less frequent. A bank may want to use an AI model to predict fraudulent transactions, but there may be too few real examples to train a model that can identify fraud accurately.&amp;nbsp;Synthetic data provide data augmentation — additional data examples that are similar to the real data. These can significantly improve the accuracy of AI models.&lt;/p&gt;&lt;p&gt;Also, sometimes users don’t have time or the financial resources to collect all the data. For instance, collecting data about customer intent would require conducting many surveys. If you end up with limited data and then try to train a model, it won’t perform well. You can augment by adding synthetic data to train those models better.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q.&amp;nbsp;&lt;/strong&gt;What are some of the risks or potential pitfalls of using synthetic data, and are there steps users can take to prevent or mitigate those problems?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A.&lt;/strong&gt; One of the biggest questions people often have in their mind is, if the data are synthetically created, why should I trust them? Determining whether you can trust the data often comes down to evaluating the overall system where you are using them.&lt;/p&gt;&lt;p&gt;There are a lot of aspects of synthetic data we have been able to evaluate for a long time. For instance, there are existing methods to measure how close synthetic data are to real data, and we can measure their quality and whether they preserve privacy. But there are other important considerations if you are using those synthetic data to train a machine-learning model for a new use case. How would you know the data are going to lead to models that still make valid conclusions?&lt;/p&gt;&lt;p&gt;New efficacy metrics are emerging, and the emphasis is now on efficacy for a particular task. You must really dig into your workflow to ensure the synthetic data you add to the system still allow you to draw valid conclusions. That is something that must be done carefully on an application-by-application basis.&lt;/p&gt;&lt;p&gt;Bias can also be an issue. Since it is created from a small amount of real data, the same bias that exists in the real data can carry over into the synthetic data. Just like with real data, you would need to purposefully make sure the bias is removed through different sampling techniques, which can create balanced datasets. It takes some careful planning, but you can calibrate the data generation to prevent the proliferation of bias.&lt;/p&gt;&lt;p&gt;To help with the evaluation process, our group created the Synthetic Data Metrics Library. We worried that people would use synthetic data in their environment and it would give different conclusions in the real world. We created a metrics and evaluation library to&amp;nbsp;ensure&amp;nbsp;checks and balances. The machine learning community has faced a lot of challenges in ensuring models can generalize to new situations. The use of synthetic data adds a whole new dimension to that problem.&lt;/p&gt;&lt;p&gt;I expect that the old systems of working with data, whether to build software applications, answer analytical questions, or train models, will dramatically change as we get more sophisticated at building these generative models. A lot of things we have never been able to do before will now be possible.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-3Q-Synthetic-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Synthetic data are artificially generated by algorithms to mimic the statistical properties of actual data, without containing any information from real-world sources. While concrete numbers are hard to pin down, some estimates suggest that more than 60 percent of data used for AI applications in 2024 was synthetic, and this figure is expected to grow across industries.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Because synthetic data don’t contain real-world information, they hold the promise of safeguarding privacy while reducing the cost and increasing the speed at which new AI models are developed. But&amp;nbsp;using synthetic data requires careful&amp;nbsp;evaluation, planning, and checks and balances to prevent loss of performance when AI models are deployed.&amp;nbsp;&amp;nbsp;&lt;/em&gt; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;em&gt;To unpack some pros and cons of using synthetic data,&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; spoke with Kalyan Veeramachaneni, a principal research scientist in the Laboratory for Information and Decision Systems&amp;nbsp;and co-founder of&amp;nbsp;&lt;/em&gt;&lt;em&gt;DataCebo&lt;/em&gt;&lt;em&gt;&amp;nbsp;whose open-core platform,&amp;nbsp;&lt;/em&gt;&lt;em&gt;the Synthetic Data Vault&lt;/em&gt;,&amp;nbsp;&lt;em&gt;helps&lt;/em&gt; &lt;em&gt;users generate and test synthetic data.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;How are synthetic data created?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Synthetic data are algorithmically generated but do not come from a real situation. Their value lies in their statistical similarity to real data. If we’re talking about language, for instance, synthetic data look very much as if a human had written those sentences. While researchers have created synthetic data for a long time, what has changed in the past few years is our ability to build generative models out of data and use them to create realistic synthetic data. We can take a little bit of real data and build a generative model from that, which we can use to create as much synthetic data as we want. Plus, the model creates synthetic data in a way that captures all the underlying rules and infinite patterns that exist in the real data.&lt;/p&gt;&lt;p&gt;There are essentially&amp;nbsp;four&amp;nbsp;different data modalities: language, video or images,&amp;nbsp;audio,&amp;nbsp;and tabular data. All four&amp;nbsp;of them have slightly different ways of building the generative models to create synthetic data. An LLM, for instance, is nothing but a generative model from which you are sampling synthetic data when you ask it a question.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;A lot of language and image data are publicly available on the internet. But tabular data, which is the data collected when we interact with physical and social systems, is often locked up behind enterprise firewalls. Much of it is sensitive or private, such as customer transactions stored by a bank. For this type of data, platforms like the Synthetic Data Vault provide software that can be used to build generative models. Those models then create synthetic data that preserve customer privacy and can be shared more widely.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;One powerful thing about this generative modeling approach for synthesizing data is that enterprises can now build a customized, local model for their own data. Generative AI automates what used to be a manual process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;What are some benefits of using synthetic data, and which use-cases and applications are they particularly well-suited for?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; One fundamental application which has grown tremendously over the past decade is using synthetic data to test software applications. There is data-driven logic behind many software applications, so you need data to test that software and its functionality. In the past, people have resorted to manually generating data, but now we can use generative models to create as much data as we need.&lt;/p&gt;&lt;p&gt;Users can also create specific data for application testing. Say I work for an e-commerce company. I can generate synthetic data that mimics real customers who live in Ohio and made transactions pertaining to one particular product in February or March.&lt;/p&gt;&lt;p&gt;Because synthetic data aren’t drawn from real situations, they are also privacy-preserving. One of the biggest problems in software testing has been getting access to sensitive real data for testing software in non-production environments, due to privacy concerns.&amp;nbsp;Another immediate benefit is in performance testing. You can create a billion transactions from a generative model and test how fast your system can process them.&lt;/p&gt;&lt;p&gt;Another application where synthetic data hold a lot of promise is in training machine-learning models. Sometimes, we want an AI model to help us predict an event that is less frequent. A bank may want to use an AI model to predict fraudulent transactions, but there may be too few real examples to train a model that can identify fraud accurately.&amp;nbsp;Synthetic data provide data augmentation — additional data examples that are similar to the real data. These can significantly improve the accuracy of AI models.&lt;/p&gt;&lt;p&gt;Also, sometimes users don’t have time or the financial resources to collect all the data. For instance, collecting data about customer intent would require conducting many surveys. If you end up with limited data and then try to train a model, it won’t perform well. You can augment by adding synthetic data to train those models better.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q.&amp;nbsp;&lt;/strong&gt;What are some of the risks or potential pitfalls of using synthetic data, and are there steps users can take to prevent or mitigate those problems?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A.&lt;/strong&gt; One of the biggest questions people often have in their mind is, if the data are synthetically created, why should I trust them? Determining whether you can trust the data often comes down to evaluating the overall system where you are using them.&lt;/p&gt;&lt;p&gt;There are a lot of aspects of synthetic data we have been able to evaluate for a long time. For instance, there are existing methods to measure how close synthetic data are to real data, and we can measure their quality and whether they preserve privacy. But there are other important considerations if you are using those synthetic data to train a machine-learning model for a new use case. How would you know the data are going to lead to models that still make valid conclusions?&lt;/p&gt;&lt;p&gt;New efficacy metrics are emerging, and the emphasis is now on efficacy for a particular task. You must really dig into your workflow to ensure the synthetic data you add to the system still allow you to draw valid conclusions. That is something that must be done carefully on an application-by-application basis.&lt;/p&gt;&lt;p&gt;Bias can also be an issue. Since it is created from a small amount of real data, the same bias that exists in the real data can carry over into the synthetic data. Just like with real data, you would need to purposefully make sure the bias is removed through different sampling techniques, which can create balanced datasets. It takes some careful planning, but you can calibrate the data generation to prevent the proliferation of bias.&lt;/p&gt;&lt;p&gt;To help with the evaluation process, our group created the Synthetic Data Metrics Library. We worried that people would use synthetic data in their environment and it would give different conclusions in the real world. We created a metrics and evaluation library to&amp;nbsp;ensure&amp;nbsp;checks and balances. The machine learning community has faced a lot of challenges in ensuring models can generalize to new situations. The use of synthetic data adds a whole new dimension to that problem.&lt;/p&gt;&lt;p&gt;I expect that the old systems of working with data, whether to build software applications, answer analytical questions, or train models, will dramatically change as we get more sophisticated at building these generative models. A lot of things we have never been able to do before will now be possible.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/3-questions-pros-cons-synthetic-data-ai-kalyan-veeramachaneni-0903</guid><pubDate>Wed, 03 Sep 2025 04:00:00 +0000</pubDate></item><item><title>[NEW] Building the AI-enabled enterprise of the future (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/03/1122367/building-the-ai-enabled-enterprise-of-the-future/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;CISCO&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Artificial intelligence is fundamentally reshaping how the world operates. With its potential to automate repetitive tasks, analyze vast datasets, and augment human capabilities, the use of AI technologies is already driving changes across industries.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1122374" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Cisco-cover.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;In health care and pharmaceuticals, machine learning and AI-powered tools are advancing disease diagnosis, reducing drug discovery timelines by as much as 50%, and heralding a new era of personalized medicine. In supply chain and logistics, AI models can help prevent or mitigate disruptions, allowing businesses to make informed decisions and enhance resilience amid geopolitical uncertainty. Across sectors, AI in research and development cycles may reduce time-to-market by 50% and lower costs in industries like automotive and aerospace by as much as 30%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“This is one of those inflection points where I don’t think anybody really has a full view of the significance of the change this is going to have on not just companies but society as a whole,” says Patrick Milligan, chief information security officer at Ford, which is making AI an important part of its transformation efforts and expanding its use across company operations.&lt;/p&gt;  &lt;p&gt;Given its game-changing potential—and the breakneck speed with which it is evolving—it is perhaps not surprising that companies are feeling the pressure to deploy AI as soon as possible: 98% say they feel an increased sense of urgency in the last year. And 85% believe they have less than 18 months to deploy an AI strategy or they will see negative business effects.&lt;/p&gt; 
 &lt;p&gt;Companies that take a “wait and see” approach will fall behind, says Jeetu Patel, president and chief product officer at Cisco. “If you wait for too long, you risk becoming irrelevant,” he says. “I don’t worry about AI taking my job, but I definitely worry about another person that uses AI better than me or another company that uses AI better taking my job or making my company irrelevant.”&lt;/p&gt;  &lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-1122679" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR-Cicso-Socials_V2-821254.png" /&gt;&lt;/figure&gt;  &lt;p&gt;But despite the urgency, just 13% of companies globally say they are ready to leverage AI to its full potential. IT infrastructure is an increasing challenge as workloads grow ever larger. Two-thirds (68%) of organizations say their infrastructure is moderately ready at best to adopt and scale AI technologies. &lt;/p&gt; 
 &lt;p&gt;Essential capabilities include adequate compute power to process complex AI models, optimized network performance across the organization and in data centers, and enhanced cybersecurity capabilities to detect and prevent sophisticated attacks. This must be combined with observability, which ensures the reliable and optimized performance of infrastructure, models, and the overall AI system by providing continuous monitoring and analysis of their behavior. Good quality, well-managed enterprise-wide data is also essential—after all, AI is only as good as the data it draws on. All of this must be supported by AI-focused company culture and talent development.&lt;/p&gt;  &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;CISCO&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Artificial intelligence is fundamentally reshaping how the world operates. With its potential to automate repetitive tasks, analyze vast datasets, and augment human capabilities, the use of AI technologies is already driving changes across industries.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1122374" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/Cisco-cover.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;In health care and pharmaceuticals, machine learning and AI-powered tools are advancing disease diagnosis, reducing drug discovery timelines by as much as 50%, and heralding a new era of personalized medicine. In supply chain and logistics, AI models can help prevent or mitigate disruptions, allowing businesses to make informed decisions and enhance resilience amid geopolitical uncertainty. Across sectors, AI in research and development cycles may reduce time-to-market by 50% and lower costs in industries like automotive and aerospace by as much as 30%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“This is one of those inflection points where I don’t think anybody really has a full view of the significance of the change this is going to have on not just companies but society as a whole,” says Patrick Milligan, chief information security officer at Ford, which is making AI an important part of its transformation efforts and expanding its use across company operations.&lt;/p&gt;  &lt;p&gt;Given its game-changing potential—and the breakneck speed with which it is evolving—it is perhaps not surprising that companies are feeling the pressure to deploy AI as soon as possible: 98% say they feel an increased sense of urgency in the last year. And 85% believe they have less than 18 months to deploy an AI strategy or they will see negative business effects.&lt;/p&gt; 
 &lt;p&gt;Companies that take a “wait and see” approach will fall behind, says Jeetu Patel, president and chief product officer at Cisco. “If you wait for too long, you risk becoming irrelevant,” he says. “I don’t worry about AI taking my job, but I definitely worry about another person that uses AI better than me or another company that uses AI better taking my job or making my company irrelevant.”&lt;/p&gt;  &lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-1122679" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/MITTR-Cicso-Socials_V2-821254.png" /&gt;&lt;/figure&gt;  &lt;p&gt;But despite the urgency, just 13% of companies globally say they are ready to leverage AI to its full potential. IT infrastructure is an increasing challenge as workloads grow ever larger. Two-thirds (68%) of organizations say their infrastructure is moderately ready at best to adopt and scale AI technologies. &lt;/p&gt; 
 &lt;p&gt;Essential capabilities include adequate compute power to process complex AI models, optimized network performance across the organization and in data centers, and enhanced cybersecurity capabilities to detect and prevent sophisticated attacks. This must be combined with observability, which ensures the reliable and optimized performance of infrastructure, models, and the overall AI system by providing continuous monitoring and analysis of their behavior. Good quality, well-managed enterprise-wide data is also essential—after all, AI is only as good as the data it draws on. All of this must be supported by AI-focused company culture and talent development.&lt;/p&gt;  &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/03/1122367/building-the-ai-enabled-enterprise-of-the-future/</guid><pubDate>Wed, 03 Sep 2025 08:38:43 +0000</pubDate></item><item><title>[NEW] Meta revises AI chatbot policies amid child safety concerns (AI News)</title><link>https://www.artificialintelligence-news.com/news/meta-revises-ai-chatbot-policies-amid-child-safety-concerns/</link><description>&lt;p&gt;Meta is revising how its AI chatbots interact with users after a series of reports exposed troubling behaviour, including interactions with minors. The company told &lt;em&gt;TechCrunch&lt;/em&gt; it is now training its bots not to engage with teenagers on topics like self-harm, suicide, or eating disorders, and to avoid romantic banter. These are temporary steps while it develops longer-term rules.&lt;/p&gt;&lt;p&gt;The changes follow a &lt;em&gt;Reuters&lt;/em&gt; investigation that found Meta’s systems could generate sexualised content, including shirtless images of underage celebrities, and engage children in conversations that were romantic or suggestive. One case reported by the news agency described a man dying after rushing to an address provided by a chatbot in New York.&lt;/p&gt;&lt;p&gt;Meta spokesperson Stephanie Otway admitted the company had made mistakes. She said Meta is “training our AIs not to engage with teens on these topics, but to guide them to expert resources,” and confirmed that certain AI characters, like highly sexualised ones like “Russian Girl,” will be restricted.&lt;/p&gt;&lt;p&gt;Child safety advocates argue the company should have acted earlier. Andy Burrows of the Molly Rose Foundation called it “astounding” that bots were allowed to operate in ways that put young people at risk. He added: “While further safety measures are welcome, robust safety testing should take place before products are put on the market – not retrospectively when harm has taken place.”&lt;/p&gt;&lt;h3&gt;Wider problems with AI misuse&lt;/h3&gt;&lt;p&gt;The scrutiny of Meta’s AI chatbots comes amid broader worries about how AI chatbots may affect vulnerable users. A California couple recently filed a lawsuit against OpenAI, claiming ChatGPT encouraged their teenage son to take his own life. OpenAI has since said it is working on tools to promote healthier use of its technology, noting in a blog post that “AI can feel more responsive and personal than prior technologies, especially for vulnerable individuals experiencing mental or emotional distress.”&lt;/p&gt;&lt;p&gt;The incidents highlight a growing debate about whether AI firms are releasing products too quickly without proper safeguards. Lawmakers in several countries have already warned that chatbots, while useful, may amplify harmful content or give misleading advice to people who are not equipped to question it.&lt;/p&gt;&lt;h3&gt;Meta’s AI Studio and chatbot impersonation issues&lt;/h3&gt;&lt;p&gt;Meanwhile, &lt;em&gt;Reuters&lt;/em&gt; reported that Meta’s AI Studio had been used to create flirtatious “parody” chatbots of celebrities like Taylor Swift and Scarlett Johansson. Testers found the bots often claimed to be the real people, engaged in sexual advances, and in some cases generated inappropriate images, including of minors. Although Meta removed several of the bots after being contacted by reporters, many were left active.&lt;/p&gt;&lt;p&gt;Some of the AI chatbots were created by outside users, but others came from inside Meta. One chatbot made by a product lead in its generative AI division impersonated Taylor Swift and invited a &lt;em&gt;Reuters&lt;/em&gt; reporter to meet for a “romantic fling” on her tour bus. This was despite Meta’s policies explicitly banning sexually suggestive imagery and the direct impersonation of public figures.&lt;/p&gt;&lt;p&gt;The issue of AI chatbot impersonation is particularly sensitive. Celebrities face reputational risks when their likeness is misused, but experts point out that ordinary users can also be deceived. A chatbot pretending to be a friend, mentor, or romantic partner may encourage someone to share private information or even meet in unsafe situations.&lt;/p&gt;&lt;h3&gt;Real-world risks&lt;/h3&gt;&lt;p&gt;The problems are not confined to entertainment. AI chatbots posing as real people have offered fake addresses and invitations, raising questions about how Meta’s AI tools are being monitored. One example involved a 76-year-old man in New Jersey who died after falling while rushing to meet a chatbot that claimed to have feelings for him.&lt;/p&gt;&lt;p&gt;Cases like this illustrate why regulators are watching AI closely. The Senate and 44 state attorneys general have already begun probing Meta’s practices, adding political pressure to the company’s internal reforms. Their concern is not only about minors, but also about how AI could manipulate older or vulnerable users.&lt;/p&gt;&lt;p&gt;Meta says it is still working on improvements. Its platforms place users aged 13 to 18 into “teen accounts” with stricter content and privacy settings, but the company has not yet explained how it plans to address the full list of problems raised by &lt;em&gt;Reuters&lt;/em&gt;. That includes bots offering false medical advice and generating racist content.&lt;/p&gt;&lt;h3&gt;Ongoing pressure on Meta’s AI chatbot policies&lt;/h3&gt;&lt;p&gt;For years, Meta has faced criticism over the safety of its social media platforms, particularly regarding children and teenagers. Now Meta’s AI chatbot experiments are drawing similar scrutiny. While the company is taking steps to restrict harmful chatbot behaviour, the gap between its stated policies and the way its tools have been used raises ongoing questions about whether it can enforce those rules.&lt;/p&gt;&lt;p&gt;Until stronger safeguards are in place, regulators, researchers, and parents will likely continue to press Meta on whether its AI is ready for public use.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Maxim Tolchinskiy)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Agentic AI: Promise, scepticism, and its meaning for Southeast Asia&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Meta is revising how its AI chatbots interact with users after a series of reports exposed troubling behaviour, including interactions with minors. The company told &lt;em&gt;TechCrunch&lt;/em&gt; it is now training its bots not to engage with teenagers on topics like self-harm, suicide, or eating disorders, and to avoid romantic banter. These are temporary steps while it develops longer-term rules.&lt;/p&gt;&lt;p&gt;The changes follow a &lt;em&gt;Reuters&lt;/em&gt; investigation that found Meta’s systems could generate sexualised content, including shirtless images of underage celebrities, and engage children in conversations that were romantic or suggestive. One case reported by the news agency described a man dying after rushing to an address provided by a chatbot in New York.&lt;/p&gt;&lt;p&gt;Meta spokesperson Stephanie Otway admitted the company had made mistakes. She said Meta is “training our AIs not to engage with teens on these topics, but to guide them to expert resources,” and confirmed that certain AI characters, like highly sexualised ones like “Russian Girl,” will be restricted.&lt;/p&gt;&lt;p&gt;Child safety advocates argue the company should have acted earlier. Andy Burrows of the Molly Rose Foundation called it “astounding” that bots were allowed to operate in ways that put young people at risk. He added: “While further safety measures are welcome, robust safety testing should take place before products are put on the market – not retrospectively when harm has taken place.”&lt;/p&gt;&lt;h3&gt;Wider problems with AI misuse&lt;/h3&gt;&lt;p&gt;The scrutiny of Meta’s AI chatbots comes amid broader worries about how AI chatbots may affect vulnerable users. A California couple recently filed a lawsuit against OpenAI, claiming ChatGPT encouraged their teenage son to take his own life. OpenAI has since said it is working on tools to promote healthier use of its technology, noting in a blog post that “AI can feel more responsive and personal than prior technologies, especially for vulnerable individuals experiencing mental or emotional distress.”&lt;/p&gt;&lt;p&gt;The incidents highlight a growing debate about whether AI firms are releasing products too quickly without proper safeguards. Lawmakers in several countries have already warned that chatbots, while useful, may amplify harmful content or give misleading advice to people who are not equipped to question it.&lt;/p&gt;&lt;h3&gt;Meta’s AI Studio and chatbot impersonation issues&lt;/h3&gt;&lt;p&gt;Meanwhile, &lt;em&gt;Reuters&lt;/em&gt; reported that Meta’s AI Studio had been used to create flirtatious “parody” chatbots of celebrities like Taylor Swift and Scarlett Johansson. Testers found the bots often claimed to be the real people, engaged in sexual advances, and in some cases generated inappropriate images, including of minors. Although Meta removed several of the bots after being contacted by reporters, many were left active.&lt;/p&gt;&lt;p&gt;Some of the AI chatbots were created by outside users, but others came from inside Meta. One chatbot made by a product lead in its generative AI division impersonated Taylor Swift and invited a &lt;em&gt;Reuters&lt;/em&gt; reporter to meet for a “romantic fling” on her tour bus. This was despite Meta’s policies explicitly banning sexually suggestive imagery and the direct impersonation of public figures.&lt;/p&gt;&lt;p&gt;The issue of AI chatbot impersonation is particularly sensitive. Celebrities face reputational risks when their likeness is misused, but experts point out that ordinary users can also be deceived. A chatbot pretending to be a friend, mentor, or romantic partner may encourage someone to share private information or even meet in unsafe situations.&lt;/p&gt;&lt;h3&gt;Real-world risks&lt;/h3&gt;&lt;p&gt;The problems are not confined to entertainment. AI chatbots posing as real people have offered fake addresses and invitations, raising questions about how Meta’s AI tools are being monitored. One example involved a 76-year-old man in New Jersey who died after falling while rushing to meet a chatbot that claimed to have feelings for him.&lt;/p&gt;&lt;p&gt;Cases like this illustrate why regulators are watching AI closely. The Senate and 44 state attorneys general have already begun probing Meta’s practices, adding political pressure to the company’s internal reforms. Their concern is not only about minors, but also about how AI could manipulate older or vulnerable users.&lt;/p&gt;&lt;p&gt;Meta says it is still working on improvements. Its platforms place users aged 13 to 18 into “teen accounts” with stricter content and privacy settings, but the company has not yet explained how it plans to address the full list of problems raised by &lt;em&gt;Reuters&lt;/em&gt;. That includes bots offering false medical advice and generating racist content.&lt;/p&gt;&lt;h3&gt;Ongoing pressure on Meta’s AI chatbot policies&lt;/h3&gt;&lt;p&gt;For years, Meta has faced criticism over the safety of its social media platforms, particularly regarding children and teenagers. Now Meta’s AI chatbot experiments are drawing similar scrutiny. While the company is taking steps to restrict harmful chatbot behaviour, the gap between its stated policies and the way its tools have been used raises ongoing questions about whether it can enforce those rules.&lt;/p&gt;&lt;p&gt;Until stronger safeguards are in place, regulators, researchers, and parents will likely continue to press Meta on whether its AI is ready for public use.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Maxim Tolchinskiy)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Agentic AI: Promise, scepticism, and its meaning for Southeast Asia&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/meta-revises-ai-chatbot-policies-amid-child-safety-concerns/</guid><pubDate>Wed, 03 Sep 2025 08:39:07 +0000</pubDate></item><item><title>[NEW] The connected customer (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/03/1121441/the-connected-customer/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;NiCE&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As brands compete for increasingly price conscious consumers, customer experience (CX) has become a decisive differentiator. Yet many struggle to deliver, constrained by outdated systems, fragmented data, and organizational silos that limit both agility and consistency.&lt;/p&gt;  &lt;p&gt;The current wave of artificial intelligence, particularly agentic AI that can reason and act across workflows, offers a powerful opportunity to reshape service delivery. Organizations can now provide fast, personalized support at scale while improving workforce productivity and satisfaction. But realizing that potential requires more than isolated tools; it calls for a unified platform that connects people, data, and decisions across the service lifecycle. This report explores how leading organizations are navigating that shift, and what it takes to move from AI potential to CX impact.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-1121687" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/NiCE-Report-2025-COVER.png" /&gt;&lt;/figure&gt;    &lt;p&gt;Key findings include:&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;AI is transforming customer experience (CX). &lt;/strong&gt;Customer service has evolved from the era of voicebased support through digital commerce and cloud to today’s AI revolution. Powered by large language models (LLMs) and a growing pool of data, AI can handle more diverse customer queries, produce highly personalized communication at scale, and help staff and senior management with decision support. Customers are also warming to AI-powered platforms as performance and reliability improves. Early adopters report improvements including more satisfied customers, more productive staff, and richer performance insights.&lt;/li&gt; &lt;/ul&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Legacy infrastructure and data fragmentation are hindering organizations from maximizing the value of AI. &lt;/strong&gt;While customer service and IT departments are early adopters of AI, the broader organizations across industries are often riddled with outdated infrastructure. This impinges the ability of autonomous AI tools to move freely across workflows and data repositories to deliver goal-based tasks. Creating a unified platform and orchestration architecture will be key to unlock AI’s potential. The transition can be a catalyst for streamlining and rationalizing the business as a whole.&lt;/li&gt; &lt;/ul&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1121465" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/NiCE-Social-Card-2.png" /&gt;&lt;/figure&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;High-performing organizations use AI without losing the human touch. &lt;/strong&gt;While consumers are warming to AI, rollout should include some discretion. Excessive personalization could make customers uncomfortable about their personal data, while engineered “empathy” from bots may be received as insincere. Organizations should not underestimate the unique value their workforce offers. Sophisticated adopters strike the right balance between human and machine capabilities. Their leaders are proactive in addressing job displacement worries through transparent communication, comprehensive training, and clear delineation between AI and human roles. The most effective organizations treat AI as a collaborative tool that enhances rather than replaces human connection and expertise.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;NiCE&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As brands compete for increasingly price conscious consumers, customer experience (CX) has become a decisive differentiator. Yet many struggle to deliver, constrained by outdated systems, fragmented data, and organizational silos that limit both agility and consistency.&lt;/p&gt;  &lt;p&gt;The current wave of artificial intelligence, particularly agentic AI that can reason and act across workflows, offers a powerful opportunity to reshape service delivery. Organizations can now provide fast, personalized support at scale while improving workforce productivity and satisfaction. But realizing that potential requires more than isolated tools; it calls for a unified platform that connects people, data, and decisions across the service lifecycle. This report explores how leading organizations are navigating that shift, and what it takes to move from AI potential to CX impact.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-1121687" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/NiCE-Report-2025-COVER.png" /&gt;&lt;/figure&gt;    &lt;p&gt;Key findings include:&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;AI is transforming customer experience (CX). &lt;/strong&gt;Customer service has evolved from the era of voicebased support through digital commerce and cloud to today’s AI revolution. Powered by large language models (LLMs) and a growing pool of data, AI can handle more diverse customer queries, produce highly personalized communication at scale, and help staff and senior management with decision support. Customers are also warming to AI-powered platforms as performance and reliability improves. Early adopters report improvements including more satisfied customers, more productive staff, and richer performance insights.&lt;/li&gt; &lt;/ul&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;Legacy infrastructure and data fragmentation are hindering organizations from maximizing the value of AI. &lt;/strong&gt;While customer service and IT departments are early adopters of AI, the broader organizations across industries are often riddled with outdated infrastructure. This impinges the ability of autonomous AI tools to move freely across workflows and data repositories to deliver goal-based tasks. Creating a unified platform and orchestration architecture will be key to unlock AI’s potential. The transition can be a catalyst for streamlining and rationalizing the business as a whole.&lt;/li&gt; &lt;/ul&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1121465" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/NiCE-Social-Card-2.png" /&gt;&lt;/figure&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;&lt;strong&gt;High-performing organizations use AI without losing the human touch. &lt;/strong&gt;While consumers are warming to AI, rollout should include some discretion. Excessive personalization could make customers uncomfortable about their personal data, while engineered “empathy” from bots may be received as insincere. Organizations should not underestimate the unique value their workforce offers. Sophisticated adopters strike the right balance between human and machine capabilities. Their leaders are proactive in addressing job displacement worries through transparent communication, comprehensive training, and clear delineation between AI and human roles. The most effective organizations treat AI as a collaborative tool that enhances rather than replaces human connection and expertise.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;em&gt;Download the full report.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/03/1121441/the-connected-customer/</guid><pubDate>Wed, 03 Sep 2025 08:46:54 +0000</pubDate></item><item><title>[NEW] AI hacking tool exploits zero-day security vulnerabilities in minutes (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-hacking-tool-exploits-zero-day-security-vulnerabilities-in-minutes/</link><description>&lt;p&gt;A new AI tool – built to help companies find and fix their own security weaknesses – has been snatched up by cybercriminals, turned on its head, and used as a devastating hacking weapon exploiting zero-day vulnerabilities.&lt;/p&gt;&lt;p&gt;According to a report from cybersecurity firm Check Point, the framework – called Hexstrike-AI – is the turning point that security experts have been dreading, where the sheer power of AI is put directly into the hands of those who want to do harm.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-tool-for-good-twisted-for-bad"&gt;A tool for good, twisted for bad&lt;/h3&gt;&lt;p&gt;Hexstrike-AI was supposed to be one of the good guys. Its creators described it as a “revolutionary Al-powered offensive security framework” that was designed to help security professionals think like hackers to better protect their organisations.&lt;/p&gt;&lt;p&gt;Think of it as an AI “brain” that acts as a conductor for a digital orchestra. It directs over 150 different specialised AI agents and security tools to test a company’s defences, find weaknesses like zero-day vulnerabilities, and report back.&lt;/p&gt;&lt;p&gt;The problem? What makes a tool great for defenders also makes it incredibly attractive to attackers. Almost immediately after its release, chatter on the dark web lit up. Malicious actors weren’t just discussing the tool; they were actively figuring out how to weaponise it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-race-against-zero-day-vulnerabilities-just-got-shorter"&gt;The race against zero-day vulnerabilities just got shorter&lt;/h3&gt;&lt;p&gt;The timing for this AI hacking tool couldn’t have been worse. Just as Hexstrike-AI appeared, Citrix announced three major “zero-day” vulnerabilities in its popular NetScaler products. A zero-day is a flaw so new that there’s been zero days to create a patch for it, leaving companies completely exposed.&lt;/p&gt;&lt;p&gt;Normally, exploiting such complex flaws requires a team of highly skilled hackers and days, if not weeks, of work. With Hexstrike-AI, that process has been reduced to less than 10 minutes.&lt;/p&gt;&lt;p&gt;The AI brain does all the heavy lifting. An attacker can give it a simple command like “exploit NetScaler,” and the system automatically figures out the best tools to use and the precise steps to take. It democratises hacking by turning it into a simple, automated process.&lt;/p&gt;&lt;p&gt;As one cybercriminal boasted on an underground forum: “Watching how everything works without my participation is just a song. I’m no longer a coder-worker, but an operator.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-these-new-ai-hacking-tools-means-for-enterprise-security"&gt;What these new AI hacking tools means for enterprise security&lt;/h3&gt;&lt;p&gt;This isn’t just a problem for big corporations. The speed and scale of these new AI-powered attacks mean that the window for businesses to protect themselves from zero-day vulnerabilities is shrinking dramatically.&lt;/p&gt;&lt;p&gt;Check Point is urging organisations to take immediate action:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Get patched:&lt;/strong&gt; The first and most obvious step is to apply the fixes released by Citrix for the NetScaler vulnerabilities.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Fight fire with fire:&lt;/strong&gt; It’s time to adopt AI-driven defence systems that can detect and respond to threats at machine speed, because humans can no longer keep up.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Speed up defences:&lt;/strong&gt; The days of taking weeks to apply a security patch are over.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Listen to the whispers:&lt;/strong&gt; Monitoring dark web chatter is no longer optional; it’s a source of intelligence that can give you a much-needed head start on the next attack.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;What once felt like a theoretical threat is now a very real and present danger. With AI now very much an actively weaponised hacking tool for exploiting zero-day vulnerabilities, the game has changed, and our approach to security has to change with it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI security wars: Can Google Cloud defend against tomorrow’s threats?&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;br /&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A new AI tool – built to help companies find and fix their own security weaknesses – has been snatched up by cybercriminals, turned on its head, and used as a devastating hacking weapon exploiting zero-day vulnerabilities.&lt;/p&gt;&lt;p&gt;According to a report from cybersecurity firm Check Point, the framework – called Hexstrike-AI – is the turning point that security experts have been dreading, where the sheer power of AI is put directly into the hands of those who want to do harm.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-tool-for-good-twisted-for-bad"&gt;A tool for good, twisted for bad&lt;/h3&gt;&lt;p&gt;Hexstrike-AI was supposed to be one of the good guys. Its creators described it as a “revolutionary Al-powered offensive security framework” that was designed to help security professionals think like hackers to better protect their organisations.&lt;/p&gt;&lt;p&gt;Think of it as an AI “brain” that acts as a conductor for a digital orchestra. It directs over 150 different specialised AI agents and security tools to test a company’s defences, find weaknesses like zero-day vulnerabilities, and report back.&lt;/p&gt;&lt;p&gt;The problem? What makes a tool great for defenders also makes it incredibly attractive to attackers. Almost immediately after its release, chatter on the dark web lit up. Malicious actors weren’t just discussing the tool; they were actively figuring out how to weaponise it.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-race-against-zero-day-vulnerabilities-just-got-shorter"&gt;The race against zero-day vulnerabilities just got shorter&lt;/h3&gt;&lt;p&gt;The timing for this AI hacking tool couldn’t have been worse. Just as Hexstrike-AI appeared, Citrix announced three major “zero-day” vulnerabilities in its popular NetScaler products. A zero-day is a flaw so new that there’s been zero days to create a patch for it, leaving companies completely exposed.&lt;/p&gt;&lt;p&gt;Normally, exploiting such complex flaws requires a team of highly skilled hackers and days, if not weeks, of work. With Hexstrike-AI, that process has been reduced to less than 10 minutes.&lt;/p&gt;&lt;p&gt;The AI brain does all the heavy lifting. An attacker can give it a simple command like “exploit NetScaler,” and the system automatically figures out the best tools to use and the precise steps to take. It democratises hacking by turning it into a simple, automated process.&lt;/p&gt;&lt;p&gt;As one cybercriminal boasted on an underground forum: “Watching how everything works without my participation is just a song. I’m no longer a coder-worker, but an operator.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-these-new-ai-hacking-tools-means-for-enterprise-security"&gt;What these new AI hacking tools means for enterprise security&lt;/h3&gt;&lt;p&gt;This isn’t just a problem for big corporations. The speed and scale of these new AI-powered attacks mean that the window for businesses to protect themselves from zero-day vulnerabilities is shrinking dramatically.&lt;/p&gt;&lt;p&gt;Check Point is urging organisations to take immediate action:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Get patched:&lt;/strong&gt; The first and most obvious step is to apply the fixes released by Citrix for the NetScaler vulnerabilities.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Fight fire with fire:&lt;/strong&gt; It’s time to adopt AI-driven defence systems that can detect and respond to threats at machine speed, because humans can no longer keep up.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Speed up defences:&lt;/strong&gt; The days of taking weeks to apply a security patch are over.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Listen to the whispers:&lt;/strong&gt; Monitoring dark web chatter is no longer optional; it’s a source of intelligence that can give you a much-needed head start on the next attack.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;What once felt like a theoretical threat is now a very real and present danger. With AI now very much an actively weaponised hacking tool for exploiting zero-day vulnerabilities, the game has changed, and our approach to security has to change with it.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;AI security wars: Can Google Cloud defend against tomorrow’s threats?&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for the AI &amp;amp; Big Data Expo event series." class="wp-image-109137" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;br /&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-hacking-tool-exploits-zero-day-security-vulnerabilities-in-minutes/</guid><pubDate>Wed, 03 Sep 2025 09:57:37 +0000</pubDate></item><item><title>[NEW] The Download: sustainable architecture, and DeepSeek’s success (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/03/1122955/the-download-sustainable-architecture-and-deepseeks-success/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Material Cultures looks to the past to build the future&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Despite decades of green certifications, better material sourcing, and the use of more sustainable materials, the built environment is still responsible for a third of global emissions worldwide. According to a 2024 UN report, the building sector has fallen “significantly behind on progress” toward becoming more sustainable. Changing the way we erect and operate buildings remains key to tackling climate change.&lt;/p&gt;&lt;p&gt;London-based design and research nonprofit Material Cultures is exploring how tradition can be harnessed in new ways to repair the contemporary building system. As many other practitioners look to artificial intelligence and other high-tech approaches, Material Cultures is focusing on sustainability, and finding creative ways to turn local materials into new buildings. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Patrick Sisson&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from our new print edition, which is all about the future of security. &lt;/strong&gt;&lt;strong&gt;Subscribe here&lt;/strong&gt;&lt;strong&gt; to catch future copies when they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How a top Chinese AI model overcame US sanctions&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Earlier this year, the AI community was abuzz over DeepSeek R1, a new open-source reasoning model. The model was developed by the Chinese AI startup DeepSeek, which claims that R1 matches or even surpasses OpenAI’s ChatGPT o1 on multiple key benchmarks but operates at a fraction of the cost.&lt;/p&gt;  &lt;p&gt;DeepSeek’s success is even more remarkable given the constraints facing Chinese AI companies in the form of increasing US export controls on cutting-edge chips. Read the full story.This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Google won’t be forced to sell Chrome after all&lt;/strong&gt;&lt;br /&gt;A federal judge has instead ruled it has to share search data with its rivals. (Politico)&lt;br /&gt;+ &lt;em&gt;He also barred Google from making deals to make Chrome the default search engine on people’s phones. &lt;/em&gt;(The Register)&lt;br /&gt;+ &lt;em&gt;The company’s critics feel the ruling doesn’t go far enough. &lt;/em&gt;(The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 OpenAI is adding emotional guardrails to ChatGPT&lt;/strong&gt;&lt;br /&gt;The new rules are designed to better protect teens and vulnerable people. (Axios)&lt;br /&gt;+ &lt;em&gt;Families of dead teenagers say AI companies aren’t doing enough. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;An AI chatbot told a user how to kill himself—but the company doesn’t want to “censor” it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 China’s military has showed off its robotic wolves&lt;/strong&gt;&lt;br /&gt;Alongside underwater torpedoes and hypersonic cruise missiles. (BBC)&lt;br /&gt;+ &lt;em&gt;Xi Jinping has pushed to modernize the world’s largest standing army. &lt;/em&gt;(CNN)&lt;br /&gt;+ &lt;em&gt;Phase two of military AI has arrived. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 ICE has resumed working with a previously banned spyware vendor&lt;/strong&gt;&lt;br /&gt;Paragon Solutions’ software was found on the devices of journalists earlier this year. (WP $)&lt;br /&gt;+ &lt;em&gt;The tool can manipulate a phone’s recorder to become a covert listening device. &lt;/em&gt;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5&lt;/strong&gt; &lt;strong&gt;An identical twin has been convicted of a crime based on DNA analysis&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s the first time the technology has been successfully used in the US, and solves a 38-year old cold case. (The Guardian)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;6 People who understand AI the least are the most likely to use it&amp;nbsp;&lt;br /&gt;Those with a better grasp of how AI works know more about its limitations. (WSJ $)&lt;br /&gt;+ &lt;em&gt;What is AI? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 BMW is preparing to unveil a super-smart EV&lt;br /&gt;&lt;/strong&gt;Its new iX3 sport utility vehicle will have 20 times more computing power. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Sick and lonely people are turning to AI “doctors”&lt;br /&gt;&lt;/strong&gt;Physicians are too busy to spend much time with patients. Chatbots are filling the void. (Rest of World)&lt;br /&gt;+ &lt;em&gt;AI companies have stopped warning you that their chatbots aren’t doctors. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Around 90% of life on Earth is still unknown&lt;/strong&gt;&lt;br /&gt;But shedding light on these mysterious organisms is essential to our future survival. (Vox)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Wax worms could help tackle our plastic pollution problem 🪱&lt;/strong&gt;&lt;br /&gt;The plastic-hungry pests can eat a polythene bag in a matter of hours. (Wired $)&lt;br /&gt;+ &lt;em&gt;Think that your plastic is being recycled? Think again. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s a nothingburger.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Gabriel Weinberg, chief executive of search engine DuckDuckGo, reacts to the judge’s decision in the Google Chrome monopoly case, the New York Times reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&amp;nbsp;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122957" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_cf7abb.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why we can no longer afford to ignore the case for climate adaptation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Back in the 1990s, anyone suggesting that we’d need to adapt to climate change while also cutting emissions was met with suspicion. Most climate change researchers felt adaptation studies would distract from the vital work of keeping pollution out of the atmosphere to begin with.&lt;/p&gt;&lt;p&gt;Despite this hostile environment, a handful of experts were already sowing the seeds for a new field of research called “climate change adaptation”: study and policy on how the world could prepare for and adapt to the new disasters and dangers brought forth on a warming planet. Today, their research is more important than ever. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Madeline Ostrander&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ How to have a happier life, even when you’re living through bleak times (maybe skip the raisins on ice cream, though.)&lt;br /&gt;+ If you’re loving Alien: Earth right now, why not dive back into the tremendously terrifying Alien: Isolation game?&lt;br /&gt;+ The first freaky images of the second part of zombie flick 28 Years Later have landed.&lt;br /&gt;+ Anthony Gormley, you will always be cool.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Material Cultures looks to the past to build the future&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Despite decades of green certifications, better material sourcing, and the use of more sustainable materials, the built environment is still responsible for a third of global emissions worldwide. According to a 2024 UN report, the building sector has fallen “significantly behind on progress” toward becoming more sustainable. Changing the way we erect and operate buildings remains key to tackling climate change.&lt;/p&gt;&lt;p&gt;London-based design and research nonprofit Material Cultures is exploring how tradition can be harnessed in new ways to repair the contemporary building system. As many other practitioners look to artificial intelligence and other high-tech approaches, Material Cultures is focusing on sustainability, and finding creative ways to turn local materials into new buildings. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Patrick Sisson&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from our new print edition, which is all about the future of security. &lt;/strong&gt;&lt;strong&gt;Subscribe here&lt;/strong&gt;&lt;strong&gt; to catch future copies when they land.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How a top Chinese AI model overcame US sanctions&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Earlier this year, the AI community was abuzz over DeepSeek R1, a new open-source reasoning model. The model was developed by the Chinese AI startup DeepSeek, which claims that R1 matches or even surpasses OpenAI’s ChatGPT o1 on multiple key benchmarks but operates at a fraction of the cost.&lt;/p&gt;  &lt;p&gt;DeepSeek’s success is even more remarkable given the constraints facing Chinese AI companies in the form of increasing US export controls on cutting-edge chips. Read the full story.This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Google won’t be forced to sell Chrome after all&lt;/strong&gt;&lt;br /&gt;A federal judge has instead ruled it has to share search data with its rivals. (Politico)&lt;br /&gt;+ &lt;em&gt;He also barred Google from making deals to make Chrome the default search engine on people’s phones. &lt;/em&gt;(The Register)&lt;br /&gt;+ &lt;em&gt;The company’s critics feel the ruling doesn’t go far enough. &lt;/em&gt;(The Verge)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 OpenAI is adding emotional guardrails to ChatGPT&lt;/strong&gt;&lt;br /&gt;The new rules are designed to better protect teens and vulnerable people. (Axios)&lt;br /&gt;+ &lt;em&gt;Families of dead teenagers say AI companies aren’t doing enough. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;An AI chatbot told a user how to kill himself—but the company doesn’t want to “censor” it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 China’s military has showed off its robotic wolves&lt;/strong&gt;&lt;br /&gt;Alongside underwater torpedoes and hypersonic cruise missiles. (BBC)&lt;br /&gt;+ &lt;em&gt;Xi Jinping has pushed to modernize the world’s largest standing army. &lt;/em&gt;(CNN)&lt;br /&gt;+ &lt;em&gt;Phase two of military AI has arrived. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 ICE has resumed working with a previously banned spyware vendor&lt;/strong&gt;&lt;br /&gt;Paragon Solutions’ software was found on the devices of journalists earlier this year. (WP $)&lt;br /&gt;+ &lt;em&gt;The tool can manipulate a phone’s recorder to become a covert listening device. &lt;/em&gt;(The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5&lt;/strong&gt; &lt;strong&gt;An identical twin has been convicted of a crime based on DNA analysis&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s the first time the technology has been successfully used in the US, and solves a 38-year old cold case. (The Guardian)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;6 People who understand AI the least are the most likely to use it&amp;nbsp;&lt;br /&gt;Those with a better grasp of how AI works know more about its limitations. (WSJ $)&lt;br /&gt;+ &lt;em&gt;What is AI? &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 BMW is preparing to unveil a super-smart EV&lt;br /&gt;&lt;/strong&gt;Its new iX3 sport utility vehicle will have 20 times more computing power. (FT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 Sick and lonely people are turning to AI “doctors”&lt;br /&gt;&lt;/strong&gt;Physicians are too busy to spend much time with patients. Chatbots are filling the void. (Rest of World)&lt;br /&gt;+ &lt;em&gt;AI companies have stopped warning you that their chatbots aren’t doctors. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;9 Around 90% of life on Earth is still unknown&lt;/strong&gt;&lt;br /&gt;But shedding light on these mysterious organisms is essential to our future survival. (Vox)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Wax worms could help tackle our plastic pollution problem 🪱&lt;/strong&gt;&lt;br /&gt;The plastic-hungry pests can eat a polythene bag in a matter of hours. (Wired $)&lt;br /&gt;+ &lt;em&gt;Think that your plastic is being recycled? Think again. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s a nothingburger.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Gabriel Weinberg, chief executive of search engine DuckDuckGo, reacts to the judge’s decision in the Google Chrome monopoly case, the New York Times reports.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&amp;nbsp;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122957" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/image_cf7abb.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why we can no longer afford to ignore the case for climate adaptation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Back in the 1990s, anyone suggesting that we’d need to adapt to climate change while also cutting emissions was met with suspicion. Most climate change researchers felt adaptation studies would distract from the vital work of keeping pollution out of the atmosphere to begin with.&lt;/p&gt;&lt;p&gt;Despite this hostile environment, a handful of experts were already sowing the seeds for a new field of research called “climate change adaptation”: study and policy on how the world could prepare for and adapt to the new disasters and dangers brought forth on a warming planet. Today, their research is more important than ever. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Madeline Ostrander&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ How to have a happier life, even when you’re living through bleak times (maybe skip the raisins on ice cream, though.)&lt;br /&gt;+ If you’re loving Alien: Earth right now, why not dive back into the tremendously terrifying Alien: Isolation game?&lt;br /&gt;+ The first freaky images of the second part of zombie flick 28 Years Later have landed.&lt;br /&gt;+ Anthony Gormley, you will always be cool.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/03/1122955/the-download-sustainable-architecture-and-deepseeks-success/</guid><pubDate>Wed, 03 Sep 2025 12:10:00 +0000</pubDate></item></channel></rss>