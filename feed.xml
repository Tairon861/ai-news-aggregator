<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 31 Jul 2025 01:59:22 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>AlphaEarth Foundations helps map our planet in unprecedented detail (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/</link><description>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Science&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-07-30"&gt;30 July 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The AlphaEarth Foundations team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="False-color imagery from AlphaEarth Foundations revealing diverse land patterns and structures." class="picture__image" height="603" src="https://lh3.googleusercontent.com/HDhR_jsZ6VhgwXTApMGZVLbHRE49liKtWC_4REPPFHUmiyRRbtKH9Bb5tjSEZrPoWLm-yu69vpBvEzwOf6oFKHawCUlANxD8djHP_DQQRpwI9JRwbA=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;New AI model integrates petabytes of Earth observation data to generate a unified data representation that revolutionizes global mapping and monitoring&lt;/p&gt;&lt;p&gt;Every day, satellites capture information-rich images and measurements, providing scientists and experts with a nearly real-time view of our planet. While this data has been incredibly impactful, its complexity, multimodality and refresh rate creates a new challenge: connecting disparate datasets and making use of them all effectively.&lt;/p&gt;&lt;p&gt;Today, we’re introducing AlphaEarth Foundations, an artificial intelligence (AI) model that functions like a virtual satellite. It accurately and efficiently characterizes the planet’s entire terrestrial land and coastal waters by integrating huge amounts of Earth observation data into a unified digital representation, or "embedding," that computer systems can easily process. This allows the model to provide scientists with a more complete and consistent picture of our planet's evolution, helping them make more informed decisions on critical issues like food security, deforestation, urban expansion, and water resources.&lt;/p&gt;&lt;p&gt;To accelerate research and unlock use cases, we are now releasing a collection of AlphaEarth Foundations’ annual embeddings as the Satellite Embedding dataset in Google Earth Engine. Over the past year, we’ve been working with more than 50 organizations to test this dataset on their real-world applications.&lt;/p&gt;&lt;p&gt;Our partners are already seeing significant benefits, using the data to better classify unmapped ecosystems, understand agricultural and environmental changes, and greatly increase the accuracy and speed of their mapping work. In this blog, we are excited to highlight some of their feedback and showcase the tangible impact of this new technology.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  



  
  &lt;div class="glue-carousel__viewport"&gt;
    &lt;div class="glue-carousel__list"&gt;


&lt;div class="glue-carousel__item" id="block-36c81d67-8c64-40e1-aaa0-25b09ee41c15"&gt;
  &lt;figure&gt;
    
    
    
    
      &lt;source height="600" media="(min-width: 1024px)" type="image/webp" width="1600" /&gt;&lt;source height="520" media="(min-width: 600px)" type="image/webp" width="1386" /&gt;&lt;source height="300" type="image/webp" width="800" /&gt;
      &lt;img alt="alt" class="picture__image" height="600" src="https://lh3.googleusercontent.com/tGgGK617ewZnppdZ4ynqsgPyudG1ZM5j7GsJRbcXLJlKddEycbKsbaCi2tbduD6pYvoanYGsZbYargYY84-i4vDtpmoB_PnWO3lzHsRrzNlbTDjo=h600" width="1600" /&gt;
    
    
  
    &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-36c81d67-8c64-40e1-aaa0-25b09ee41c15"&gt;
    &lt;p&gt;Visualizing the rich details of our world by assigning the colors red, green and blue to three of the 64 dimensions of AlphaEarth Foundations’ embedding fields. In Ecuador, the model sees through persistent cloud cover to detail agricultural plots in various stages of development. Elsewhere, it maps a complex surface in Antarctica—an area notoriously difficult to image due to irregular satellite imaging—in clear detail, and it makes apparent variations in Canadian agricultural land use that are invisible to the naked eye.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;div class="glue-carousel__item" id="block-0117e96b-7f40-4813-8042-8ca017ef82e8"&gt;
  &lt;figure&gt;
    
    
    
    
      &lt;source height="600" media="(min-width: 1024px)" type="image/webp" width="1600" /&gt;&lt;source height="520" media="(min-width: 600px)" type="image/webp" width="1386" /&gt;&lt;source height="300" type="image/webp" width="800" /&gt;
      &lt;img alt="alt" class="picture__image" height="600" src="https://lh3.googleusercontent.com/nGbd-Cl40BCmUvaxLJpqsUes27qpJLnXEpn7FGCpW4xhTYxn1I4hCLjZ3HMmkIYCTq4YPYqMyGrz7nrU9YL1YniEo2STdh4X-RqbwHOQUFsh9IV8mZY=h600" width="1600" /&gt;
    
    
  
    &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-0117e96b-7f40-4813-8042-8ca017ef82e8"&gt;
    &lt;p&gt;Visualizing the rich details of our world by assigning the colors red, green and blue to three of the 64 dimensions of AlphaEarth Foundations’ embedding fields. In Ecuador, the model sees through persistent cloud cover to detail agricultural plots in various stages of development. Elsewhere, it maps a complex surface in Antarctica—an area notoriously difficult to image due to irregular satellite imaging—in clear detail, and it makes apparent variations in Canadian agricultural land use that are invisible to the naked eye.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;div class="glue-carousel__item" id="block-1d674d91-39a1-4e10-a1eb-8ccf77faa3bc"&gt;
  &lt;figure&gt;
    
    
    
    
      &lt;source height="600" media="(min-width: 1024px)" type="image/webp" width="1600" /&gt;&lt;source height="520" media="(min-width: 600px)" type="image/webp" width="1386" /&gt;&lt;source height="300" type="image/webp" width="800" /&gt;
      &lt;img alt="alt" class="picture__image" height="600" src="https://lh3.googleusercontent.com/4jG104p4Nda6u96uNXWMPuhIswnj-n7IV83RomyYVzjk5wLFBuKm6jbA1cS_u_S23PzfM6vbOh_NLhx_khC5HMGNxuoS-tEvz4thj5lPGLXGmfvo=h600" width="1600" /&gt;
    
    
  
    &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-1d674d91-39a1-4e10-a1eb-8ccf77faa3bc"&gt;
    &lt;p&gt;Visualizing the rich details of our world by assigning the colors red, green and blue to three of the 64 dimensions of AlphaEarth Foundations’ embedding fields. In Ecuador, the model sees through persistent cloud cover to detail agricultural plots in various stages of development. Elsewhere, it maps a complex surface in Antarctica—an area notoriously difficult to image due to irregular satellite imaging—in clear detail, and it makes apparent variations in Canadian agricultural land use that are invisible to the naked eye.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;
  &lt;/div&gt;
  

                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;How AlphaEarth Foundations works&lt;/h2&gt;&lt;p&gt;AlphaEarth Foundations provides a powerful new lens for understanding our planet by solving two major challenges: data overload and inconsistent information.&lt;/p&gt;&lt;p&gt;First, it combines volumes of information from dozens of different public sources— optical satellite images, radar, 3D laser mapping, climate simulations, and more. It weaves all this information together to analyse the world's land and coastal waters in sharp, 10x10 meter squares, allowing it to track changes over time with remarkable precision.&lt;/p&gt;&lt;p&gt;Second, it makes this data practical to use. The system's key innovation is its ability to create a highly compact summary for each square. These summaries require 16 times less storage space than those produced by other AI systems that we tested and dramatically reduces the cost of planetary-scale analysis.&lt;/p&gt;&lt;p&gt;This breakthrough enables scientists to do something that was impossible until now: create detailed, consistent maps of our world, on-demand. Whether they are monitoring crop health, tracking deforestation, or observing new construction, they no longer have to rely on a single satellite passing overhead. They now have a new kind of foundation for geospatial data.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-783e0871-496e-4d7b-98a1-3e5abeaa3af1"&gt;
    &lt;p&gt;Diagram showing how AlphaEarth Foundations works, taking non-uniformly sampled frames from a video sequence to index any position in time. This helps the model create a continuous view of the location, while explaining numerous measurements.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;To ensure AlphaEarth Foundations was ready for real-world use, we rigorously tested its performance. When compared against both traditional methods and other AI mapping systems, AlphaEarth Foundations was consistently the most accurate. It excelled at a wide range of tasks over different time periods, including identifying land use and estimating surface properties. Crucially, it achieved this in scenarios when label data was scarce. On average, AlphaEarth Foundations had a 24% lower error rate than the models we tested, demonstrating its superior learning efficiency. Learn more in our paper.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-b5e9a4f3-60d6-4af0-a466-0a921c167c8d"&gt;
    &lt;p&gt;Diagram showing a global embedding field broken down into a single embedding, from left to right. Each embedding has 64 components which map to coordinates on a 64-dimensional sphere.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Generating custom maps with the Satellite Embedding dataset&lt;/h2&gt;&lt;p&gt;Powered by AlphaEarth Foundations, the Satellite Embedding dataset in Google Earth Engine is one of the largest of its kind with over 1.4 trillion embedding footprints per year. This collection of annual embeddings is already being used by organizations around the world, including the United Nations’ Food and Agriculture Organization, Harvard Forest, Group on Earth Observations, MapBiomas, Oregon State University, the Spatial Informatics Group and Stanford University, to create powerful custom maps that drive real-world insights.&lt;/p&gt;&lt;p&gt;For example, Global Ecosystems Atlas, an initiative aiming to create the first comprehensive resource to map and monitor the world’s ecosystems, is using this dataset to help countries classify unmapped ecosystems into categories like coastal shrublands and hyper-arid deserts. This first of its kind resource will play a critical role in helping countries better prioritize conservation areas, optimize restoration efforts, and combat the loss of biodiversity.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;The Satellite Embedding dataset is revolutionizing our work by helping countries map uncharted ecosystems - this is crucial for pinpointing where to focus their conservation efforts.&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Nick Murray, Director of the James Cook University Global Ecology Lab and Global Science Lead of Global Ecosystems Atlas&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;In Brazil, MapBiomas is testing the dataset to more deeply understand agricultural and environmental changes across the country. This type of map informs conservation strategies and sustainable development initiatives in critical ecosystems like the Amazon rainforest.&lt;/p&gt;&lt;p&gt;As Tasso Azevedo, founder of MapBiomas said, "The Satellite Embedding dataset can transform the way our team works - we now have new options to make maps that are more accurate, precise and fast to produce - something we would have never been able to do before."&lt;/p&gt;&lt;p&gt;Read more about the Satellite Embedding dataset and see tutorials in the Google Earth Engine blog .&lt;/p&gt;&lt;h2&gt;Empowering others with AI&lt;/h2&gt;&lt;p&gt;AlphaEarth Foundations represents a significant step forward in understanding the state and dynamics of our changing planet. We’re currently using AlphaEarth Foundations to generate annual embeddings and believe they could be even more useful in the future when combined together with general reasoning LLM agents like Gemini. We are continuing to explore the best ways to apply our model's time-based capabilities as part of Google Earth AI, our collection of geospatial models and datasets to help tackle the planet’s most critical needs.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more about AlphaEarth Foundations&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This work was a collaboration between teams at Google DeepMind and Google Earth Engine.&lt;/p&gt;&lt;p&gt;Christopher Brown, Michal Kazmierski, Valerie Pasquarella, William Rucklidge, Masha Samsikova, Olivia Wiles, Chenhui Zhang, Estefania Lahera, Evan Shelhamer, Simon Ilyushchenko, Noel Gorelick, Lihui Lydia Zhang, Sophia Alj, Emily Schechter, Sean Askay, Oliver Guinan, Rebecca Moore, Alexis Boukouvalas, Pushmeet Kohli&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</description><content:encoded>&lt;div class="article-cover article-cover--centered"&gt;
    &lt;div class="article-cover__header"&gt;
      &lt;p class="article-cover__eyebrow glue-label"&gt;Science&lt;/p&gt;
      

      
    &lt;dl class="article-cover__meta"&gt;
      
        &lt;dt class="glue-visually-hidden"&gt;Published&lt;/dt&gt;
        &lt;dd class="article-cover__date glue-label"&gt;&lt;time datetime="2025-07-30"&gt;30 July 2025&lt;/time&gt;&lt;/dd&gt;
      
      
        &lt;dt class="glue-visually-hidden"&gt;Authors&lt;/dt&gt;
        &lt;dd class="article-cover__authors"&gt;&lt;p&gt;The AlphaEarth Foundations team&lt;/p&gt;&lt;/dd&gt;
      
    &lt;/dl&gt;
  

      
    &lt;/div&gt;

    
      
    
    
    
      &lt;source height="603" media="(min-width: 1024px)" type="image/webp" width="1072" /&gt;&lt;source height="522" media="(min-width: 600px)" type="image/webp" width="928" /&gt;&lt;source height="297" type="image/webp" width="528" /&gt;
      &lt;img alt="False-color imagery from AlphaEarth Foundations revealing diverse land patterns and structures." class="picture__image" height="603" src="https://lh3.googleusercontent.com/HDhR_jsZ6VhgwXTApMGZVLbHRE49liKtWC_4REPPFHUmiyRRbtKH9Bb5tjSEZrPoWLm-yu69vpBvEzwOf6oFKHawCUlANxD8djHP_DQQRpwI9JRwbA=w1072-h603-n-nu" width="1072" /&gt;
    
    
  
    
  &lt;/div&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p class="gdm-rich-text__subtitle"&gt;New AI model integrates petabytes of Earth observation data to generate a unified data representation that revolutionizes global mapping and monitoring&lt;/p&gt;&lt;p&gt;Every day, satellites capture information-rich images and measurements, providing scientists and experts with a nearly real-time view of our planet. While this data has been incredibly impactful, its complexity, multimodality and refresh rate creates a new challenge: connecting disparate datasets and making use of them all effectively.&lt;/p&gt;&lt;p&gt;Today, we’re introducing AlphaEarth Foundations, an artificial intelligence (AI) model that functions like a virtual satellite. It accurately and efficiently characterizes the planet’s entire terrestrial land and coastal waters by integrating huge amounts of Earth observation data into a unified digital representation, or "embedding," that computer systems can easily process. This allows the model to provide scientists with a more complete and consistent picture of our planet's evolution, helping them make more informed decisions on critical issues like food security, deforestation, urban expansion, and water resources.&lt;/p&gt;&lt;p&gt;To accelerate research and unlock use cases, we are now releasing a collection of AlphaEarth Foundations’ annual embeddings as the Satellite Embedding dataset in Google Earth Engine. Over the past year, we’ve been working with more than 50 organizations to test this dataset on their real-world applications.&lt;/p&gt;&lt;p&gt;Our partners are already seeing significant benefits, using the data to better classify unmapped ecosystems, understand agricultural and environmental changes, and greatly increase the accuracy and speed of their mapping work. In this blog, we are excited to highlight some of their feedback and showcase the tangible impact of this new technology.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  



  
  &lt;div class="glue-carousel__viewport"&gt;
    &lt;div class="glue-carousel__list"&gt;


&lt;div class="glue-carousel__item" id="block-36c81d67-8c64-40e1-aaa0-25b09ee41c15"&gt;
  &lt;figure&gt;
    
    
    
    
      &lt;source height="600" media="(min-width: 1024px)" type="image/webp" width="1600" /&gt;&lt;source height="520" media="(min-width: 600px)" type="image/webp" width="1386" /&gt;&lt;source height="300" type="image/webp" width="800" /&gt;
      &lt;img alt="alt" class="picture__image" height="600" src="https://lh3.googleusercontent.com/tGgGK617ewZnppdZ4ynqsgPyudG1ZM5j7GsJRbcXLJlKddEycbKsbaCi2tbduD6pYvoanYGsZbYargYY84-i4vDtpmoB_PnWO3lzHsRrzNlbTDjo=h600" width="1600" /&gt;
    
    
  
    &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-36c81d67-8c64-40e1-aaa0-25b09ee41c15"&gt;
    &lt;p&gt;Visualizing the rich details of our world by assigning the colors red, green and blue to three of the 64 dimensions of AlphaEarth Foundations’ embedding fields. In Ecuador, the model sees through persistent cloud cover to detail agricultural plots in various stages of development. Elsewhere, it maps a complex surface in Antarctica—an area notoriously difficult to image due to irregular satellite imaging—in clear detail, and it makes apparent variations in Canadian agricultural land use that are invisible to the naked eye.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;div class="glue-carousel__item" id="block-0117e96b-7f40-4813-8042-8ca017ef82e8"&gt;
  &lt;figure&gt;
    
    
    
    
      &lt;source height="600" media="(min-width: 1024px)" type="image/webp" width="1600" /&gt;&lt;source height="520" media="(min-width: 600px)" type="image/webp" width="1386" /&gt;&lt;source height="300" type="image/webp" width="800" /&gt;
      &lt;img alt="alt" class="picture__image" height="600" src="https://lh3.googleusercontent.com/nGbd-Cl40BCmUvaxLJpqsUes27qpJLnXEpn7FGCpW4xhTYxn1I4hCLjZ3HMmkIYCTq4YPYqMyGrz7nrU9YL1YniEo2STdh4X-RqbwHOQUFsh9IV8mZY=h600" width="1600" /&gt;
    
    
  
    &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-0117e96b-7f40-4813-8042-8ca017ef82e8"&gt;
    &lt;p&gt;Visualizing the rich details of our world by assigning the colors red, green and blue to three of the 64 dimensions of AlphaEarth Foundations’ embedding fields. In Ecuador, the model sees through persistent cloud cover to detail agricultural plots in various stages of development. Elsewhere, it maps a complex surface in Antarctica—an area notoriously difficult to image due to irregular satellite imaging—in clear detail, and it makes apparent variations in Canadian agricultural land use that are invisible to the naked eye.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;


&lt;div class="glue-carousel__item" id="block-1d674d91-39a1-4e10-a1eb-8ccf77faa3bc"&gt;
  &lt;figure&gt;
    
    
    
    
      &lt;source height="600" media="(min-width: 1024px)" type="image/webp" width="1600" /&gt;&lt;source height="520" media="(min-width: 600px)" type="image/webp" width="1386" /&gt;&lt;source height="300" type="image/webp" width="800" /&gt;
      &lt;img alt="alt" class="picture__image" height="600" src="https://lh3.googleusercontent.com/4jG104p4Nda6u96uNXWMPuhIswnj-n7IV83RomyYVzjk5wLFBuKm6jbA1cS_u_S23PzfM6vbOh_NLhx_khC5HMGNxuoS-tEvz4thj5lPGLXGmfvo=h600" width="1600" /&gt;
    
    
  
    &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-1d674d91-39a1-4e10-a1eb-8ccf77faa3bc"&gt;
    &lt;p&gt;Visualizing the rich details of our world by assigning the colors red, green and blue to three of the 64 dimensions of AlphaEarth Foundations’ embedding fields. In Ecuador, the model sees through persistent cloud cover to detail agricultural plots in various stages of development. Elsewhere, it maps a complex surface in Antarctica—an area notoriously difficult to image due to irregular satellite imaging—in clear detail, and it makes apparent variations in Canadian agricultural land use that are invisible to the naked eye.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
  &lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;
  &lt;/div&gt;
  

                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;How AlphaEarth Foundations works&lt;/h2&gt;&lt;p&gt;AlphaEarth Foundations provides a powerful new lens for understanding our planet by solving two major challenges: data overload and inconsistent information.&lt;/p&gt;&lt;p&gt;First, it combines volumes of information from dozens of different public sources— optical satellite images, radar, 3D laser mapping, climate simulations, and more. It weaves all this information together to analyse the world's land and coastal waters in sharp, 10x10 meter squares, allowing it to track changes over time with remarkable precision.&lt;/p&gt;&lt;p&gt;Second, it makes this data practical to use. The system's key innovation is its ability to create a highly compact summary for each square. These summaries require 16 times less storage space than those produced by other AI systems that we tested and dramatically reduces the cost of planetary-scale analysis.&lt;/p&gt;&lt;p&gt;This breakthrough enables scientists to do something that was impossible until now: create detailed, consistent maps of our world, on-demand. Whether they are monitoring crop health, tracking deforestation, or observing new construction, they no longer have to rely on a single satellite passing overhead. They now have a new kind of foundation for geospatial data.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-783e0871-496e-4d7b-98a1-3e5abeaa3af1"&gt;
    &lt;p&gt;Diagram showing how AlphaEarth Foundations works, taking non-uniformly sampled frames from a video sequence to index any position in time. This helps the model create a continuous view of the location, while explaining numerous measurements.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;To ensure AlphaEarth Foundations was ready for real-world use, we rigorously tested its performance. When compared against both traditional methods and other AI mapping systems, AlphaEarth Foundations was consistently the most accurate. It excelled at a wide range of tasks over different time periods, including identifying land use and estimating surface properties. Crucially, it achieved this in scenarios when label data was scarce. On average, AlphaEarth Foundations had a 24% lower error rate than the models we tested, demonstrating its superior learning efficiency. Learn more in our paper.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  





&lt;figure class="single-media single-media--inline"&gt;
  

  &lt;figcaption class="caption"&gt;
      &lt;div class="caption__text glue-caption" id="caption-b5e9a4f3-60d6-4af0-a466-0a921c167c8d"&gt;
    &lt;p&gt;Diagram showing a global embedding field broken down into a single embedding, from left to right. Each embedding has 64 components which map to coordinates on a 64-dimensional sphere.&lt;/p&gt;
  &lt;/div&gt;
    &lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;h2&gt;Generating custom maps with the Satellite Embedding dataset&lt;/h2&gt;&lt;p&gt;Powered by AlphaEarth Foundations, the Satellite Embedding dataset in Google Earth Engine is one of the largest of its kind with over 1.4 trillion embedding footprints per year. This collection of annual embeddings is already being used by organizations around the world, including the United Nations’ Food and Agriculture Organization, Harvard Forest, Group on Earth Observations, MapBiomas, Oregon State University, the Spatial Informatics Group and Stanford University, to create powerful custom maps that drive real-world insights.&lt;/p&gt;&lt;p&gt;For example, Global Ecosystems Atlas, an initiative aiming to create the first comprehensive resource to map and monitor the world’s ecosystems, is using this dataset to help countries classify unmapped ecosystems into categories like coastal shrublands and hyper-arid deserts. This first of its kind resource will play a critical role in helping countries better prioritize conservation areas, optimize restoration efforts, and combat the loss of biodiversity.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  &lt;figure class="quote quote--inline"&gt;
  &lt;blockquote class="quote__text"&gt;
    &lt;p&gt;“&lt;/p&gt;
    &lt;p&gt;The Satellite Embedding dataset is revolutionizing our work by helping countries map uncharted ecosystems - this is crucial for pinpointing where to focus their conservation efforts.&lt;/p&gt;
  &lt;/blockquote&gt;
  &lt;figcaption class="quote__author"&gt;&lt;p&gt;Nick Murray, Director of the James Cook University Global Ecology Lab and Global Science Lead of Global Ecosystems Atlas&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
                
              
                
                
                  
                  &lt;div class="gdm-rich-text rich-text"&gt;
  &lt;p&gt;In Brazil, MapBiomas is testing the dataset to more deeply understand agricultural and environmental changes across the country. This type of map informs conservation strategies and sustainable development initiatives in critical ecosystems like the Amazon rainforest.&lt;/p&gt;&lt;p&gt;As Tasso Azevedo, founder of MapBiomas said, "The Satellite Embedding dataset can transform the way our team works - we now have new options to make maps that are more accurate, precise and fast to produce - something we would have never been able to do before."&lt;/p&gt;&lt;p&gt;Read more about the Satellite Embedding dataset and see tutorials in the Google Earth Engine blog .&lt;/p&gt;&lt;h2&gt;Empowering others with AI&lt;/h2&gt;&lt;p&gt;AlphaEarth Foundations represents a significant step forward in understanding the state and dynamics of our changing planet. We’re currently using AlphaEarth Foundations to generate annual embeddings and believe they could be even more useful in the future when combined together with general reasoning LLM agents like Gemini. We are continuing to explore the best ways to apply our model's time-based capabilities as part of Google Earth AI, our collection of geospatial models and datasets to help tackle the planet’s most critical needs.&lt;/p&gt;
&lt;/div&gt;
                
              
                
                
                  
                  

&lt;section class="button-group button-group--stacked"&gt;
  
    &lt;h2 class="glue-headline glue-headline--headline-6 button-group__title"&gt;Learn more about AlphaEarth Foundations&lt;/h2&gt;
  

  
&lt;/section&gt;
                
              
                
                
                  
                  &lt;section class="notes"&gt;
  &lt;div class="glue-page"&gt;
    &lt;div class="gdm-rich-text notes__inner"&gt;
      &lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;This work was a collaboration between teams at Google DeepMind and Google Earth Engine.&lt;/p&gt;&lt;p&gt;Christopher Brown, Michal Kazmierski, Valerie Pasquarella, William Rucklidge, Masha Samsikova, Olivia Wiles, Chenhui Zhang, Estefania Lahera, Evan Shelhamer, Simon Ilyushchenko, Noel Gorelick, Lihui Lydia Zhang, Sophia Alj, Emily Schechter, Sean Askay, Oliver Guinan, Rebecca Moore, Alexis Boukouvalas, Pushmeet Kohli&lt;/p&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/section&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/alphaearth-foundations-helps-map-our-planet-in-unprecedented-detail/</guid><pubDate>Wed, 30 Jul 2025 14:00:00 +0000</pubDate></item><item><title>Zuckerberg outlines Meta’s AI vision for ‘personal superintelligence’ (AI News)</title><link>https://www.artificialintelligence-news.com/news/zuckerberg-outlines-meta-ai-vision-personal-superintelligence/</link><description>&lt;p&gt;Meta CEO Mark Zuckerberg has laid out his blueprint for the future of AI, and it’s about giving you “personal superintelligence”.&lt;/p&gt;&lt;p&gt;In a letter, the Meta chief painted a picture of what’s coming next, and he believes it’s closer than we think. He says his teams are already seeing early signs of progress.&lt;/p&gt;&lt;p&gt;“Over the last few months we have begun to see glimpses of our AI systems improving themselves,” Zuckerberg wrote. “The improvement is slow for now, but undeniable. Developing superintelligence is now in sight.”&lt;/p&gt;&lt;p&gt;So, what does he want to do with it? Forget AI that just automates boring office work, Zuckerberg and Meta’s vision for personal superintelligence is far more intimate. He imagines a future where technology serves our individual growth, not just our productivity.&lt;/p&gt;&lt;p&gt;In his words, the real revolution will be “everyone having a personal superintelligence that helps you achieve your goals, create what you want to see in the world, experience any adventure, be a better friend to those you care about, and grow to become the person you aspire to be.”&lt;/p&gt;&lt;p&gt;But here’s where it gets interesting. He drew a clear line in the sand, contrasting his vision against a very different, almost dystopian alternative that he believes others are pursuing.&lt;/p&gt;&lt;p&gt;“This is distinct from others in the industry who believe superintelligence should be directed centrally towards automating all valuable work, and then humanity will live on a dole of its output,” he stated.&lt;/p&gt;&lt;p&gt;Meta, Zuckerberg says, is betting on the individual when it comes to AI superintelligence. The company believes that progress has always come from people chasing their own dreams, not from living off the scraps of a hyper-efficient machine.&lt;/p&gt;&lt;p&gt;If he’s right, we’ll spend less time wrestling with software and more time creating and connecting. This personal AI would live in devices like smart glasses, understanding our world because they can “see what we see, hear what we hear.”&lt;/p&gt;&lt;p&gt;Of course, he knows this is powerful, even dangerous, stuff. Zuckerberg admits that superintelligence will bring new safety concerns and that Meta will have to be careful about what they release to the world. Still, he argues that the goal must be to empower people as much as possible.&lt;/p&gt;&lt;p&gt;Zuckerberg believes we’re at a crossroads right now. The choices we make in the next few years will decide everything.&lt;/p&gt;&lt;p&gt;“The rest of this decade seems likely to be the decisive period for determining the path this technology will take,” he warned, framing it as a choice between “personal empowerment or a force focused on replacing large swaths of society.”&lt;/p&gt;&lt;p&gt;Zuckerberg has made his choice. He’s focusing Meta’s enormous resources on building this personal superintelligence future.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Forget the Turing Test, AI’s real challenge is communication&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Meta CEO Mark Zuckerberg has laid out his blueprint for the future of AI, and it’s about giving you “personal superintelligence”.&lt;/p&gt;&lt;p&gt;In a letter, the Meta chief painted a picture of what’s coming next, and he believes it’s closer than we think. He says his teams are already seeing early signs of progress.&lt;/p&gt;&lt;p&gt;“Over the last few months we have begun to see glimpses of our AI systems improving themselves,” Zuckerberg wrote. “The improvement is slow for now, but undeniable. Developing superintelligence is now in sight.”&lt;/p&gt;&lt;p&gt;So, what does he want to do with it? Forget AI that just automates boring office work, Zuckerberg and Meta’s vision for personal superintelligence is far more intimate. He imagines a future where technology serves our individual growth, not just our productivity.&lt;/p&gt;&lt;p&gt;In his words, the real revolution will be “everyone having a personal superintelligence that helps you achieve your goals, create what you want to see in the world, experience any adventure, be a better friend to those you care about, and grow to become the person you aspire to be.”&lt;/p&gt;&lt;p&gt;But here’s where it gets interesting. He drew a clear line in the sand, contrasting his vision against a very different, almost dystopian alternative that he believes others are pursuing.&lt;/p&gt;&lt;p&gt;“This is distinct from others in the industry who believe superintelligence should be directed centrally towards automating all valuable work, and then humanity will live on a dole of its output,” he stated.&lt;/p&gt;&lt;p&gt;Meta, Zuckerberg says, is betting on the individual when it comes to AI superintelligence. The company believes that progress has always come from people chasing their own dreams, not from living off the scraps of a hyper-efficient machine.&lt;/p&gt;&lt;p&gt;If he’s right, we’ll spend less time wrestling with software and more time creating and connecting. This personal AI would live in devices like smart glasses, understanding our world because they can “see what we see, hear what we hear.”&lt;/p&gt;&lt;p&gt;Of course, he knows this is powerful, even dangerous, stuff. Zuckerberg admits that superintelligence will bring new safety concerns and that Meta will have to be careful about what they release to the world. Still, he argues that the goal must be to empower people as much as possible.&lt;/p&gt;&lt;p&gt;Zuckerberg believes we’re at a crossroads right now. The choices we make in the next few years will decide everything.&lt;/p&gt;&lt;p&gt;“The rest of this decade seems likely to be the decisive period for determining the path this technology will take,” he warned, framing it as a choice between “personal empowerment or a force focused on replacing large swaths of society.”&lt;/p&gt;&lt;p&gt;Zuckerberg has made his choice. He’s focusing Meta’s enormous resources on building this personal superintelligence future.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Forget the Turing Test, AI’s real challenge is communication&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/zuckerberg-outlines-meta-ai-vision-personal-superintelligence/</guid><pubDate>Wed, 30 Jul 2025 14:05:42 +0000</pubDate></item><item><title>[NEW] Roundtables: Why It’s So Hard to Make Welfare AI Fair (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/30/1120275/roundtables-why-its-so-hard-to-make-welfare-ai-fair/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR-Roundtables-Zoom-Opening-Overlay-1920x1080-2.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Amsterdam tried using algorithms to fairly assess welfare applicants, but bias still crept in. Why did Amsterdam fail? And more important,&amp;nbsp;can this ever be done right? Hear from &lt;em&gt;MIT Technology Review&lt;/em&gt; editor Amanda Silverman, investigative reporter Eileen Guo, and Lighthouse Reports investigative reporter Gabriel Geiger as they explore if algorithms can ever be fair.&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;Speakers: &lt;strong&gt;Eileen Guo&lt;/strong&gt;, features &amp;amp; investigations reporter, &lt;strong&gt;Amanda Silverman&lt;/strong&gt;, features &amp;amp; investigations editor, and &lt;strong&gt;Gabriel Geiger&lt;/strong&gt; investigative reporter at Lighthouse Reports&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;strong&gt;Recorded on&lt;/strong&gt; July 30&lt;/strong&gt;, &lt;strong&gt;2025&lt;/strong&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/MITTR-Roundtables-Zoom-Opening-Overlay-1920x1080-2.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;
&lt;p&gt;&lt;em&gt;Available only for MIT Alumni and subscribers.&lt;/em&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Amsterdam tried using algorithms to fairly assess welfare applicants, but bias still crept in. Why did Amsterdam fail? And more important,&amp;nbsp;can this ever be done right? Hear from &lt;em&gt;MIT Technology Review&lt;/em&gt; editor Amanda Silverman, investigative reporter Eileen Guo, and Lighthouse Reports investigative reporter Gabriel Geiger as they explore if algorithms can ever be fair.&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;Speakers: &lt;strong&gt;Eileen Guo&lt;/strong&gt;, features &amp;amp; investigations reporter, &lt;strong&gt;Amanda Silverman&lt;/strong&gt;, features &amp;amp; investigations editor, and &lt;strong&gt;Gabriel Geiger&lt;/strong&gt; investigative reporter at Lighthouse Reports&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_1"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;&lt;em&gt;&lt;strong&gt;&lt;strong&gt;Recorded on&lt;/strong&gt; July 30&lt;/strong&gt;, &lt;strong&gt;2025&lt;/strong&gt;&lt;br /&gt;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Coverage: &lt;/strong&gt;&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/30/1120275/roundtables-why-its-so-hard-to-make-welfare-ai-fair/</guid><pubDate>Wed, 30 Jul 2025 14:53:40 +0000</pubDate></item><item><title>[NEW] How 2 UC Berkeley dropouts raised $28M for their AI marketing automation startup (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/30/how-2-uc-berkeley-dropouts-raised-28m-for-their-ai-marketing-automation-startup/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Conversion-founders-Neil-Tewari-James-Jiao.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered marketing automation startup Conversion, founded five years ago by two UC Berkeley dropouts, has raised a $28 million Series A led by Abstract, with participation from True Ventures and HOF Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s founding story sounds like it could have been an episode of the HBO show “Silicon Valley.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The story begins all the way back when co-founder and CEO Neil Tewari, now 24, was in high school. He got busted one day watching a TechCrunch Disrupt livestream during class, was sent to the principal’s office, and had to stay late.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Afraid to call his parents and tell them why they had to pick him up, he instead called one of their close friends. On the drive home, Tewari explained to the friend what got him in trouble. “I told him I had this interest [in entrepreneurship], and four years later, he was actually the first person to write us a check into the company,” Tewari told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;James Jiao, Tewari’s college roommate at Berkeley — now Conversion’s co-founder and CTO — also dreamed of founding his own company, so the two tried building various products, like one for helping marketeers buy product placement ads. They stumbled on the idea for Conversion when they signed up for HubSpot to help them with marketing tasks and decided to build a few extra automation features to layer on top of it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was originally for us,” Tewari said of his startup’s tech. The co-founders enjoyed building their internal marketing tool so much, they wondered if they could sell it and began reaching out to marketing executives for “customer discovery” interviews.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We actually spent like two months doing like 160 customer interviews with VPs of marketing, 50- to 500-employee businesses, and got a much more positive response than we could have imagined,” Tewari said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Marketing teams had these tools deeply embedded in their workflows, but everyone had similar complaints about the parts they couldn’t automate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The duo had found their idea. The family friend introduced them to more marketing execs, which helped them raise a $2 million seed round. At age 19, they dropped out of college to work full time on Conversion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders treated their raised funds so frugally they lived in a two-bedroom, one-bathroom apartment with five other roommates: two people to a room, with people sleeping on the couches and in the closet.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As they built their product, ChatGPT burst onto the scene. Many legacy marketing automation tools are adding various AI and chat integrations into their wares, but not all of their features support these integrations. Marketing teams wanted “to be able to enrich contacts, [be] able to automate workflows,” for instance, Tewari said. Conversion has baked AI in, which means it can do things like organize leads and automate personalized follow-up emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As AI interest has soared, so has the company’s prospects. Conversion is nearing $10 million ARR over the past two years, Tewari said, and about 90% of its customers are midsize businesses that have yanked out a legacy app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Conversion is also in a crowded field. Besides the legacy marketing automation tools like HubSpot, Adobe Marketo, or Salesforce Pardot, there are other AI native startups like Jasper, Writer AI, Iterable, Copy.ai, and many others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Tewari also has the classic Silicon Valley confidence of a founder in a crowded market. His game plan calls for targeting businesses that use the older marketing tools. Conversion is not, for instance, targeting startups choosing a tool for the first time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised a total of $30 million between its seed and Series A, the CEO says, and is doing well enough that the founders have each moved into separate apartments where they have their own rooms, and none of their roommates sleep in a closet.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Conversion-founders-Neil-Tewari-James-Jiao.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI-powered marketing automation startup Conversion, founded five years ago by two UC Berkeley dropouts, has raised a $28 million Series A led by Abstract, with participation from True Ventures and HOF Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s founding story sounds like it could have been an episode of the HBO show “Silicon Valley.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The story begins all the way back when co-founder and CEO Neil Tewari, now 24, was in high school. He got busted one day watching a TechCrunch Disrupt livestream during class, was sent to the principal’s office, and had to stay late.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Afraid to call his parents and tell them why they had to pick him up, he instead called one of their close friends. On the drive home, Tewari explained to the friend what got him in trouble. “I told him I had this interest [in entrepreneurship], and four years later, he was actually the first person to write us a check into the company,” Tewari told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;James Jiao, Tewari’s college roommate at Berkeley — now Conversion’s co-founder and CTO — also dreamed of founding his own company, so the two tried building various products, like one for helping marketeers buy product placement ads. They stumbled on the idea for Conversion when they signed up for HubSpot to help them with marketing tasks and decided to build a few extra automation features to layer on top of it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was originally for us,” Tewari said of his startup’s tech. The co-founders enjoyed building their internal marketing tool so much, they wondered if they could sell it and began reaching out to marketing executives for “customer discovery” interviews.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We actually spent like two months doing like 160 customer interviews with VPs of marketing, 50- to 500-employee businesses, and got a much more positive response than we could have imagined,” Tewari said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Marketing teams had these tools deeply embedded in their workflows, but everyone had similar complaints about the parts they couldn’t automate.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The duo had found their idea. The family friend introduced them to more marketing execs, which helped them raise a $2 million seed round. At age 19, they dropped out of college to work full time on Conversion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The founders treated their raised funds so frugally they lived in a two-bedroom, one-bathroom apartment with five other roommates: two people to a room, with people sleeping on the couches and in the closet.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As they built their product, ChatGPT burst onto the scene. Many legacy marketing automation tools are adding various AI and chat integrations into their wares, but not all of their features support these integrations. Marketing teams wanted “to be able to enrich contacts, [be] able to automate workflows,” for instance, Tewari said. Conversion has baked AI in, which means it can do things like organize leads and automate personalized follow-up emails.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As AI interest has soared, so has the company’s prospects. Conversion is nearing $10 million ARR over the past two years, Tewari said, and about 90% of its customers are midsize businesses that have yanked out a legacy app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Conversion is also in a crowded field. Besides the legacy marketing automation tools like HubSpot, Adobe Marketo, or Salesforce Pardot, there are other AI native startups like Jasper, Writer AI, Iterable, Copy.ai, and many others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Tewari also has the classic Silicon Valley confidence of a founder in a crowded market. His game plan calls for targeting businesses that use the older marketing tools. Conversion is not, for instance, targeting startups choosing a tool for the first time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has raised a total of $30 million between its seed and Series A, the CEO says, and is doing well enough that the founders have each moved into separate apartments where they have their own rooms, and none of their roommates sleep in a closet.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/30/how-2-uc-berkeley-dropouts-raised-28m-for-their-ai-marketing-automation-startup/</guid><pubDate>Wed, 30 Jul 2025 15:00:00 +0000</pubDate></item><item><title>An EPA rule change threatens to gut US climate regulations (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/30/1120849/epa-endangerment-finding/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/AP25162707332562.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This story is part of &lt;/em&gt;MIT Technology Review&lt;em&gt;’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat.&amp;nbsp;You can read the rest here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;The mechanism that allows the US federal government to regulate climate change is on the chopping block.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;On Tuesday, US Environmental Protection Agency administrator Lee Zeldin announced that the agency is taking aim at the endangerment finding, a 2009 rule that’s essentially the tentpole supporting federal greenhouse-gas regulations.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This might sound like an obscure legal situation, but it’s a really big deal for climate policy in the US.&lt;/strong&gt; So buckle up, and let’s look at what this rule says now, what the proposed change looks like, and what it all means.&lt;/p&gt; 
 &lt;p&gt;To set the stage, we have to go back to the Clean Air Act of 1970, the law that essentially gave the EPA the power to regulate air pollution. (Stick with me—I promise I’ll keep this short and not get too into the legal weeds.)&lt;/p&gt;  &lt;p&gt;There were some pollutants explicitly called out in this law and its amendments, including lead and sulfur dioxide. But it also required the EPA to regulate new pollutants that were found to be harmful. In the late 1990s and early 2000s, environmental groups and states started asking for the agency to include greenhouse-gas pollution.&lt;/p&gt; 
 &lt;p&gt;In 2007, the Supreme Court ruled that greenhouse gases qualify as air pollutants under the Clean Air Act, and that the EPA should study whether they’re a danger to public health. In 2009, the incoming Obama administration looked at the science and ruled that greenhouse gases pose a threat to public health because they cause climate change. &lt;strong&gt;That’s the endangerment finding, and it’s what allows the agency to pass rules to regulate greenhouse gases.&lt;/strong&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The original case and argument were specifically about vehicles and the emissions from tailpipes, but this finding was eventually used to allow the agency to set rules around power plants and factories, too. It essentially underpins climate regulations in the US.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Fast-forward to today, and the Trump administration wants to reverse the endangerment finding.&lt;/strong&gt; In a proposed rule released on Tuesday, the EPA argues that the Clean Air Act does not, in fact, authorize the agency to set emissions standards to address global climate change. Zeldin, in an appearance on the conservative politics and humor podcast &lt;em&gt;Ruthless&lt;/em&gt; that preceded the official announcement, called the proposal the “largest deregulatory action in the history of America.”&lt;/p&gt;  &lt;p&gt;The administration was already moving to undermine the climate regulations that rely on this rule. But this move directly targets a “fundamental building block of EPA’s climate policy,” says Deborah Sivas, an environmental-law professor at Stanford University.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;The proposed rule will go up for public comment, and the agency will then take that feedback and come up with a final version. It’ll almost certainly get hit with legal challenges and will likely wind up in front of the Supreme Court.&lt;/p&gt;  &lt;p&gt;One note here is that the EPA makes a mostly legal argument in the proposed rule reversal rather than focusing on going after the science of climate change, says Madison Condon, an associate law professor at Boston University. That could make it easier for the Supreme Court to eventually uphold it, she says, though this whole process is going to take a while.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;If the endangerment finding goes down, it would have wide-reaching ripple effects.&lt;/strong&gt; “We could find ourselves in a couple years with no legal tools to try and address climate change,” Sivas says.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;To take a step back for a moment, it’s wild that we’ve ended up in this place where a single rule is so central to regulating emissions. &lt;/strong&gt;US climate policy is held up by duct tape and a dream. Congress could have, at some point, passed a law that more directly allows the EPA to regulate greenhouse-gas emissions (the last time we got close was a 2009 bill that passed the House but never made it to the Senate). But here we are.&lt;/p&gt; 

 &lt;p&gt;This move isn’t a surprise, exactly. The Trump administration has made it very clear that it is going after climate policy in every way that it can. &lt;strong&gt;But what’s most striking to me is that we’re not operating in a shared reality anymore when it comes to this subject.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;While top officials tend to acknowledge that climate change is real, there’s often a “but” followed by talking points from climate denial’s list of greatest hits. (One of the more ridiculous examples is&amp;nbsp;the statement that carbon dioxide is good, actually, because it helps plants.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Climate change is real, and it’s a threat. And the US has emitted more greenhouse gases into the atmosphere than any other country in the world. It shouldn’t be controversial to expect the government to be doing something about it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&lt;/em&gt; &lt;em&gt;sign &lt;/em&gt;&lt;em&gt;up&lt;/em&gt;&lt;em&gt; here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/AP25162707332562.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This story is part of &lt;/em&gt;MIT Technology Review&lt;em&gt;’s “America Undone” series, examining how the foundations of US success in science and innovation are currently under threat.&amp;nbsp;You can read the rest here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;The mechanism that allows the US federal government to regulate climate change is on the chopping block.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;On Tuesday, US Environmental Protection Agency administrator Lee Zeldin announced that the agency is taking aim at the endangerment finding, a 2009 rule that’s essentially the tentpole supporting federal greenhouse-gas regulations.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This might sound like an obscure legal situation, but it’s a really big deal for climate policy in the US.&lt;/strong&gt; So buckle up, and let’s look at what this rule says now, what the proposed change looks like, and what it all means.&lt;/p&gt; 
 &lt;p&gt;To set the stage, we have to go back to the Clean Air Act of 1970, the law that essentially gave the EPA the power to regulate air pollution. (Stick with me—I promise I’ll keep this short and not get too into the legal weeds.)&lt;/p&gt;  &lt;p&gt;There were some pollutants explicitly called out in this law and its amendments, including lead and sulfur dioxide. But it also required the EPA to regulate new pollutants that were found to be harmful. In the late 1990s and early 2000s, environmental groups and states started asking for the agency to include greenhouse-gas pollution.&lt;/p&gt; 
 &lt;p&gt;In 2007, the Supreme Court ruled that greenhouse gases qualify as air pollutants under the Clean Air Act, and that the EPA should study whether they’re a danger to public health. In 2009, the incoming Obama administration looked at the science and ruled that greenhouse gases pose a threat to public health because they cause climate change. &lt;strong&gt;That’s the endangerment finding, and it’s what allows the agency to pass rules to regulate greenhouse gases.&lt;/strong&gt;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The original case and argument were specifically about vehicles and the emissions from tailpipes, but this finding was eventually used to allow the agency to set rules around power plants and factories, too. It essentially underpins climate regulations in the US.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Fast-forward to today, and the Trump administration wants to reverse the endangerment finding.&lt;/strong&gt; In a proposed rule released on Tuesday, the EPA argues that the Clean Air Act does not, in fact, authorize the agency to set emissions standards to address global climate change. Zeldin, in an appearance on the conservative politics and humor podcast &lt;em&gt;Ruthless&lt;/em&gt; that preceded the official announcement, called the proposal the “largest deregulatory action in the history of America.”&lt;/p&gt;  &lt;p&gt;The administration was already moving to undermine the climate regulations that rely on this rule. But this move directly targets a “fundamental building block of EPA’s climate policy,” says Deborah Sivas, an environmental-law professor at Stanford University.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;The proposed rule will go up for public comment, and the agency will then take that feedback and come up with a final version. It’ll almost certainly get hit with legal challenges and will likely wind up in front of the Supreme Court.&lt;/p&gt;  &lt;p&gt;One note here is that the EPA makes a mostly legal argument in the proposed rule reversal rather than focusing on going after the science of climate change, says Madison Condon, an associate law professor at Boston University. That could make it easier for the Supreme Court to eventually uphold it, she says, though this whole process is going to take a while.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;If the endangerment finding goes down, it would have wide-reaching ripple effects.&lt;/strong&gt; “We could find ourselves in a couple years with no legal tools to try and address climate change,” Sivas says.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;To take a step back for a moment, it’s wild that we’ve ended up in this place where a single rule is so central to regulating emissions. &lt;/strong&gt;US climate policy is held up by duct tape and a dream. Congress could have, at some point, passed a law that more directly allows the EPA to regulate greenhouse-gas emissions (the last time we got close was a 2009 bill that passed the House but never made it to the Senate). But here we are.&lt;/p&gt; 

 &lt;p&gt;This move isn’t a surprise, exactly. The Trump administration has made it very clear that it is going after climate policy in every way that it can. &lt;strong&gt;But what’s most striking to me is that we’re not operating in a shared reality anymore when it comes to this subject.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;While top officials tend to acknowledge that climate change is real, there’s often a “but” followed by talking points from climate denial’s list of greatest hits. (One of the more ridiculous examples is&amp;nbsp;the statement that carbon dioxide is good, actually, because it helps plants.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Climate change is real, and it’s a threat. And the US has emitted more greenhouse gases into the atmosphere than any other country in the world. It shouldn’t be controversial to expect the government to be doing something about it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday,&lt;/em&gt; &lt;em&gt;sign &lt;/em&gt;&lt;em&gt;up&lt;/em&gt;&lt;em&gt; here&lt;/em&gt;.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/30/1120849/epa-endangerment-finding/</guid><pubDate>Wed, 30 Jul 2025 15:29:49 +0000</pubDate></item><item><title>The AI Hype Index: The White House’s war on “woke AI” (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/30/1120783/the-ai-hype-index-the-white-houses-war-on-woke-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/July-Thumbv2.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.&lt;/p&gt;    &lt;p&gt;The Trump administration recently declared war on so-called “woke AI,” issuing an executive order aimed at preventing companies whose models exhibit a liberal bias from landing federal contracts. Simultaneously, the Pentagon inked a deal with Elon Musk’s xAI just days after its chatbot, Grok, spouted harmful antisemitic stereotypes on X, while the White House has partnered with an anti-DEI nonprofit to create AI slop videos of the Founding Fathers. What comes next is anyone’s guess.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/July-Thumbv2.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt;&lt;p&gt;Separating AI reality from hyped-up fiction isn’t always easy. That’s why we’ve created the AI Hype Index—a simple, at-a-glance summary of everything you need to know about the state of the industry.&lt;/p&gt;    &lt;p&gt;The Trump administration recently declared war on so-called “woke AI,” issuing an executive order aimed at preventing companies whose models exhibit a liberal bias from landing federal contracts. Simultaneously, the Pentagon inked a deal with Elon Musk’s xAI just days after its chatbot, Grok, spouted harmful antisemitic stereotypes on X, while the White House has partnered with an anti-DEI nonprofit to create AI slop videos of the Founding Fathers. What comes next is anyone’s guess.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/30/1120783/the-ai-hype-index-the-white-houses-war-on-woke-ai/</guid><pubDate>Wed, 30 Jul 2025 15:37:10 +0000</pubDate></item><item><title>PlayerZero raises $15M to prevent AI agents from shipping buggy code (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/30/playerzero-raises-15m-to-prevent-ai-agents-from-shipping-buggy-code/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/PlayerZero-Founder-and-CEO-Animesh-Koratana.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As Silicon Valley races toward a future where AI agents do most of the software programming, a new problem is created: finding the AI-generated bugs before they are put into production. Even OpenAI is dealing with such issues, a former employee has described.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Newly funded startup PlayerZero has created a solution: use AI agents trained to find and fix problems before the code is put into production, the startup’s CEO and sole founder, Animesh Koratana, tells TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Koratana created PlayerZero while he was at the Stanford DAWN lab for machine learning under his adviser and lab founder, Matei Zaharia. Zaharia is, of course, a famed developer and the co-founder of Databricks; he created its foundational technology while working on his own doctorate.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PlayerZero on Wednesday announced that it raised a $15 million Series A led by Foundation Capital’s Ashu Garg, an early Databricks backer. This follows a $5 million seed led by Green Bay Ventures and several noteworthy angels, including Zaharia, Dropbox CEO Drew Houston, Figma CEO Dylan Field, and Vercel CEO Guillermo Rauch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During his time at Stanford DAWN, Koratana, now 26, was working on AI model compression technology and “got exposed to language models really early on,” he says. He met the developers who crafted some of the first AI coding assistance tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It hit him then that “there’s this world in which computers are going to write the code. It’s not going to be humans anymore,” Koratana tells TechCrunch. ”What’s the world going to look like at that point?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He knew before the term “AI slop” was even coined that these agents were going to produce code that broke things just as their human overseers do.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That problem would also be exacerbated by so many agents cranking out so much more code than has ever been written before. It won’t always be practical for humans to check all AI-written code for bugs or hallucinations. And the issue becomes even more intense for the large, complex code bases that enterprises rely upon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PlayerZero trains models “that really deeply understand code bases, and we understand the way they’re built, the way they’re architected,” Koratana says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His tech studies the history of an enterprise’s bugs, issues, and solutions. When something breaks, his product can then “figure out why and fix it, and then learn from those mistakes to prevent them from ever happening again,” Koratana says. He likens his product to an immune system for large code bases.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Landing Zaharia, his adviser, as an angel was a first step to fundraising, but the moment that really validated his idea was when he showed a demo to another famous developer: Rauch. Rauch is the founder of triple-unicorn developer tool company Vercel and creator of the popular open source JavaScript framework Next.js.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rauch watched Koratana’s demo with interest but skepticism, asking how much of it was “real.” Koratana replied that this was code “running in production. Like, this is a real instance. And he was quiet,” Koratana says. Then his soon-to-be-angel investor responded, “If you can actually solve this the way that you’re imagining, it’s a really big deal.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, PlayerZero isn’t alone in attempting to solve the AI-generated bug problem. Just last week, Anysphere’s Cursor launched Bugbot to detect coding errors, as just one example.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, PlayerZero is already gaining traction for its emphasis on large codebases. While it was conceived for a world where agents are the coders, it is currently being used by several large enterprises that use coding co-pilots. For instance, subscription billing company Zuora is one of the startup’s marquee customers. Zuora is using the tech across its engineering teams, including to watchdog its most precious code, its billing systems, it said.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/PlayerZero-Founder-and-CEO-Animesh-Koratana.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As Silicon Valley races toward a future where AI agents do most of the software programming, a new problem is created: finding the AI-generated bugs before they are put into production. Even OpenAI is dealing with such issues, a former employee has described.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Newly funded startup PlayerZero has created a solution: use AI agents trained to find and fix problems before the code is put into production, the startup’s CEO and sole founder, Animesh Koratana, tells TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Koratana created PlayerZero while he was at the Stanford DAWN lab for machine learning under his adviser and lab founder, Matei Zaharia. Zaharia is, of course, a famed developer and the co-founder of Databricks; he created its foundational technology while working on his own doctorate.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PlayerZero on Wednesday announced that it raised a $15 million Series A led by Foundation Capital’s Ashu Garg, an early Databricks backer. This follows a $5 million seed led by Green Bay Ventures and several noteworthy angels, including Zaharia, Dropbox CEO Drew Houston, Figma CEO Dylan Field, and Vercel CEO Guillermo Rauch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;During his time at Stanford DAWN, Koratana, now 26, was working on AI model compression technology and “got exposed to language models really early on,” he says. He met the developers who crafted some of the first AI coding assistance tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It hit him then that “there’s this world in which computers are going to write the code. It’s not going to be humans anymore,” Koratana tells TechCrunch. ”What’s the world going to look like at that point?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He knew before the term “AI slop” was even coined that these agents were going to produce code that broke things just as their human overseers do.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That problem would also be exacerbated by so many agents cranking out so much more code than has ever been written before. It won’t always be practical for humans to check all AI-written code for bugs or hallucinations. And the issue becomes even more intense for the large, complex code bases that enterprises rely upon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;PlayerZero trains models “that really deeply understand code bases, and we understand the way they’re built, the way they’re architected,” Koratana says.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His tech studies the history of an enterprise’s bugs, issues, and solutions. When something breaks, his product can then “figure out why and fix it, and then learn from those mistakes to prevent them from ever happening again,” Koratana says. He likens his product to an immune system for large code bases.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Landing Zaharia, his adviser, as an angel was a first step to fundraising, but the moment that really validated his idea was when he showed a demo to another famous developer: Rauch. Rauch is the founder of triple-unicorn developer tool company Vercel and creator of the popular open source JavaScript framework Next.js.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Rauch watched Koratana’s demo with interest but skepticism, asking how much of it was “real.” Koratana replied that this was code “running in production. Like, this is a real instance. And he was quiet,” Koratana says. Then his soon-to-be-angel investor responded, “If you can actually solve this the way that you’re imagining, it’s a really big deal.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, PlayerZero isn’t alone in attempting to solve the AI-generated bug problem. Just last week, Anysphere’s Cursor launched Bugbot to detect coding errors, as just one example.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, PlayerZero is already gaining traction for its emphasis on large codebases. While it was conceived for a world where agents are the coders, it is currently being used by several large enterprises that use coding co-pilots. For instance, subscription billing company Zuora is one of the startup’s marquee customers. Zuora is using the tech across its engineering teams, including to watchdog its most precious code, its billing systems, it said.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/30/playerzero-raises-15m-to-prevent-ai-agents-from-shipping-buggy-code/</guid><pubDate>Wed, 30 Jul 2025 16:00:00 +0000</pubDate></item><item><title>Google confirms it will sign the EU AI Code of Practice (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/07/google-confirms-it-will-sign-the-eu-ai-code-of-practice/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The company is not looking to make new enemies in Europe.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a European flag composed of computer code" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2024/03/europe-flag-digital-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Illustration of a European flag composed of computer code" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/03/europe-flag-digital-1152x648-1742412347.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | BeeBright

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Big Tech is increasingly addicted to AI, but many companies are allergic to regulation, bucking suggestions that they adhere to copyright law and provide data on training. In a rare move, Google has confirmed it will sign the European Union's AI Code of Practice, a framework it initially opposed for being too harsh. However, Google isn't totally on board with Europe's efforts to rein in the AI explosion. The company's head of global affairs, Kent Walker, noted that the code could stifle innovation if it's not applied carefully, and that's something Google hopes to prevent.&lt;/p&gt;
&lt;p&gt;While Google was initially opposed to the Code of Practice, Walker says the input it has provided to the European Commission has been well-received, and the result is a legal framework it believes can provide Europe with access to "secure, first-rate AI tools." The company claims that the expansion of such tools on the continent could boost the economy by 8 percent (about 1.8 trillion euros) annually by 2034.&lt;/p&gt;
&lt;p&gt;These supposed economic gains are being dangled like bait to entice business interests in the EU to align with Google on the Code of Practice. While the company is signing the agreement, it appears interested in influencing the way it is implemented. Walker says Google remains concerned that tightening copyright guidelines and forced disclosure of possible trade secrets could slow innovation. Having a seat at the table could make it easier to bend the needle of regulation than if it followed some of its competitors in eschewing voluntary compliance.&lt;/p&gt;
&lt;p&gt;Google's position is in stark contrast to that of Meta, which has steadfastly refused to sign the agreement. The Facebook owner has claimed the voluntary Code of Practice could impose too many limits on frontier model development, an unsurprising position for the company to take as it looks to supercharge its so-called "superintelligence" project. Microsoft is still mulling the agreement and may eventually sign it, but ChatGPT maker OpenAI has signaled it will sign the code.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The regulation of AI systems could be the next hurdle as Big Tech aims to deploy technologies framed as transformative and vital to the future. Google products like search and Android have been in the sights of EU regulators for years, so getting in on the ground floor with the AI code would help it navigate what will surely be a tumultuous legal environment.&lt;/p&gt;
&lt;h2&gt;A comprehensive AI framework&lt;/h2&gt;
&lt;p&gt;The US has shied away from AI regulation, and the current administration is actively working to remove what few limits are in place. The White House even attempted to ban all state-level AI regulation for a period of 10 years in the recent tax bill. Europe, meanwhile, is taking the possible negative impacts of AI tools seriously with a rapidly evolving regulatory framework.&lt;/p&gt;
&lt;p&gt;The AI Code of Practice aims to provide AI firms with a bit more certainty in the face of a shifting landscape. It was developed with the input of more than 1,000 citizen groups, academics, and industry experts. The EU Commission says companies that adopt the voluntary code will enjoy a lower bureaucratic burden, easing compliance with the block's AI Act, which came into force last year.&lt;/p&gt;
&lt;p&gt;Under the terms of the code, Google will have to publish summaries of its model training data and disclose additional model features to regulators. The code also includes guidance on how firms should manage safety and security in compliance with the AI Act. Likewise, it includes paths to align a company's model development with EU copyright law as it pertains to AI, a sore spot for Google and others.&lt;/p&gt;
&lt;p&gt;Companies like Meta that don't sign the code will not escape regulation. All AI companies operating in Europe will have to abide by the AI Act, which includes the most detailed regulatory framework for generative AI systems in the world. The law bans high-risk uses of AI like intentional deception or manipulation of users, social scoring systems, and real-time biometric scanning in public spaces. Companies that violate the rules in the AI Act could be hit with fines as high as 35 million euros ($40.1 million) or up to 7 percent of the offender's global revenue.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The company is not looking to make new enemies in Europe.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a European flag composed of computer code" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2024/03/europe-flag-digital-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Illustration of a European flag composed of computer code" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/03/europe-flag-digital-1152x648-1742412347.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images | BeeBright

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Big Tech is increasingly addicted to AI, but many companies are allergic to regulation, bucking suggestions that they adhere to copyright law and provide data on training. In a rare move, Google has confirmed it will sign the European Union's AI Code of Practice, a framework it initially opposed for being too harsh. However, Google isn't totally on board with Europe's efforts to rein in the AI explosion. The company's head of global affairs, Kent Walker, noted that the code could stifle innovation if it's not applied carefully, and that's something Google hopes to prevent.&lt;/p&gt;
&lt;p&gt;While Google was initially opposed to the Code of Practice, Walker says the input it has provided to the European Commission has been well-received, and the result is a legal framework it believes can provide Europe with access to "secure, first-rate AI tools." The company claims that the expansion of such tools on the continent could boost the economy by 8 percent (about 1.8 trillion euros) annually by 2034.&lt;/p&gt;
&lt;p&gt;These supposed economic gains are being dangled like bait to entice business interests in the EU to align with Google on the Code of Practice. While the company is signing the agreement, it appears interested in influencing the way it is implemented. Walker says Google remains concerned that tightening copyright guidelines and forced disclosure of possible trade secrets could slow innovation. Having a seat at the table could make it easier to bend the needle of regulation than if it followed some of its competitors in eschewing voluntary compliance.&lt;/p&gt;
&lt;p&gt;Google's position is in stark contrast to that of Meta, which has steadfastly refused to sign the agreement. The Facebook owner has claimed the voluntary Code of Practice could impose too many limits on frontier model development, an unsurprising position for the company to take as it looks to supercharge its so-called "superintelligence" project. Microsoft is still mulling the agreement and may eventually sign it, but ChatGPT maker OpenAI has signaled it will sign the code.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The regulation of AI systems could be the next hurdle as Big Tech aims to deploy technologies framed as transformative and vital to the future. Google products like search and Android have been in the sights of EU regulators for years, so getting in on the ground floor with the AI code would help it navigate what will surely be a tumultuous legal environment.&lt;/p&gt;
&lt;h2&gt;A comprehensive AI framework&lt;/h2&gt;
&lt;p&gt;The US has shied away from AI regulation, and the current administration is actively working to remove what few limits are in place. The White House even attempted to ban all state-level AI regulation for a period of 10 years in the recent tax bill. Europe, meanwhile, is taking the possible negative impacts of AI tools seriously with a rapidly evolving regulatory framework.&lt;/p&gt;
&lt;p&gt;The AI Code of Practice aims to provide AI firms with a bit more certainty in the face of a shifting landscape. It was developed with the input of more than 1,000 citizen groups, academics, and industry experts. The EU Commission says companies that adopt the voluntary code will enjoy a lower bureaucratic burden, easing compliance with the block's AI Act, which came into force last year.&lt;/p&gt;
&lt;p&gt;Under the terms of the code, Google will have to publish summaries of its model training data and disclose additional model features to regulators. The code also includes guidance on how firms should manage safety and security in compliance with the AI Act. Likewise, it includes paths to align a company's model development with EU copyright law as it pertains to AI, a sore spot for Google and others.&lt;/p&gt;
&lt;p&gt;Companies like Meta that don't sign the code will not escape regulation. All AI companies operating in Europe will have to abide by the AI Act, which includes the most detailed regulatory framework for generative AI systems in the world. The law bans high-risk uses of AI like intentional deception or manipulation of users, social scoring systems, and real-time biometric scanning in public spaces. Companies that violate the rules in the AI Act could be hit with fines as high as 35 million euros ($40.1 million) or up to 7 percent of the offender's global revenue.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/07/google-confirms-it-will-sign-the-eu-ai-code-of-practice/</guid><pubDate>Wed, 30 Jul 2025 16:14:50 +0000</pubDate></item><item><title>Zuckerberg signals Meta won’t open source all of its ‘superintelligence’ AI models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/30/zuckerberg-says-meta-likely-wont-open-source-all-of-its-superintelligence-ai-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2170596427.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg shared his vision on Wednesday for “personal superintelligence,” the idea that people should be able to use AI to achieve their personal goals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Smuggled into the letter is a signal that Meta is shifting how it plans to release AI models as it pursues “superintelligence.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe the benefits of superintelligence should be shared with the world as broadly as possible,” wrote Zuckerberg. “That said, superintelligence will raise novel safety concerns. We’ll need to be rigorous about mitigating these risks and careful about what we choose to open source.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That wording about open source is significant. Zuckerberg has historically positioned Meta’s Llama family of open models as the company’s key differentiator from competitors like OpenAI, xAI, and Google DeepMind. Meta’s goal has been to create open AI models that were as good as or better than those closed models. In a 2024 letter, Zuckerberg wrote, “Starting next year, we expect future Llama models to become the most advanced in the industry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has previously left himself room to maneuver on this commitment. “If at some point however there’s some qualitative change in what the thing is capable of, and we feel like it’s not responsible to open source it, then we won’t,” he said in a podcast last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And while many say Llama doesn’t fit the strict definition of open source AI — partly because Meta hasn’t released its massive training datasets — Zuckerberg’s words point to a possible change in priority: Open source may no longer be the default for Meta’s cutting-edge AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a reason why Meta’s rivals keep their models closed. Closed models give companies more control over monetizing their products. Zuckerberg pointed out last year that Meta’s business isn’t reliant on selling access to AI models, so “releasing Llama doesn’t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers.”&amp;nbsp; Meta, of course, makes most of its money from selling internet advertising.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Still, that stated viewpoint on open models was &lt;em&gt;before&lt;/em&gt; Meta started to feel like it was falling behind competitors, and executives became obsessed with beating OpenAI’s GPT-4 model while developing Llama 3.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cut to June 2025, when Meta began its public AGI sprint in earnest by investing $14.3 billion in Scale AI, acquiring Scale’s founder and CEO, and restructuring its AI efforts under a new unit called Meta Superintelligence Labs. Meta has spent billions of dollars to acquire researchers and engineers from top AI firms and build out new data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Recent reports indicate that all that investment has led Meta to pause testing on its latest Llama model, Behemoth, and instead focus efforts on developing a closed model.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With Zuckerberg’s mission for introducing “personal superintelligence” to the world — a decided shift from the rivals he says are working on “automating all valuable work” — his AI monetization strategy is taking shape. It’s clear from Zuckerberg’s words today that Meta plans to deliver “personal superintelligence” through its own products like augmented reality glasses and virtual reality headsets.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Personal devices like glasses that understand our context because they can see what we see, hear what we hear, and interact with us throughout the day will become our primary computing devices,” Zuckerberg wrote in Wednesday’s letter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked about Meta potentially keeping its most advanced models closed, a Meta spokesperson said that the company remains committed to open source AI and said it also expects to train closed source models in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our position on open source AI is unchanged,” a spokesperson said. “We plan to continue releasing leading open source models. We haven’t released everything we’ve developed historically and we expect to continue training a mix of open and closed models going forward.”&lt;br /&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated with more information about Mark Zuckerberg’s stance on open AI models. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2170596427.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta CEO Mark Zuckerberg shared his vision on Wednesday for “personal superintelligence,” the idea that people should be able to use AI to achieve their personal goals.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Smuggled into the letter is a signal that Meta is shifting how it plans to release AI models as it pursues “superintelligence.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We believe the benefits of superintelligence should be shared with the world as broadly as possible,” wrote Zuckerberg. “That said, superintelligence will raise novel safety concerns. We’ll need to be rigorous about mitigating these risks and careful about what we choose to open source.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That wording about open source is significant. Zuckerberg has historically positioned Meta’s Llama family of open models as the company’s key differentiator from competitors like OpenAI, xAI, and Google DeepMind. Meta’s goal has been to create open AI models that were as good as or better than those closed models. In a 2024 letter, Zuckerberg wrote, “Starting next year, we expect future Llama models to become the most advanced in the industry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has previously left himself room to maneuver on this commitment. “If at some point however there’s some qualitative change in what the thing is capable of, and we feel like it’s not responsible to open source it, then we won’t,” he said in a podcast last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And while many say Llama doesn’t fit the strict definition of open source AI — partly because Meta hasn’t released its massive training datasets — Zuckerberg’s words point to a possible change in priority: Open source may no longer be the default for Meta’s cutting-edge AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a reason why Meta’s rivals keep their models closed. Closed models give companies more control over monetizing their products. Zuckerberg pointed out last year that Meta’s business isn’t reliant on selling access to AI models, so “releasing Llama doesn’t undercut our revenue, sustainability, or ability to invest in research like it does for closed providers.”&amp;nbsp; Meta, of course, makes most of its money from selling internet advertising.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Still, that stated viewpoint on open models was &lt;em&gt;before&lt;/em&gt; Meta started to feel like it was falling behind competitors, and executives became obsessed with beating OpenAI’s GPT-4 model while developing Llama 3.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cut to June 2025, when Meta began its public AGI sprint in earnest by investing $14.3 billion in Scale AI, acquiring Scale’s founder and CEO, and restructuring its AI efforts under a new unit called Meta Superintelligence Labs. Meta has spent billions of dollars to acquire researchers and engineers from top AI firms and build out new data centers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Recent reports indicate that all that investment has led Meta to pause testing on its latest Llama model, Behemoth, and instead focus efforts on developing a closed model.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With Zuckerberg’s mission for introducing “personal superintelligence” to the world — a decided shift from the rivals he says are working on “automating all valuable work” — his AI monetization strategy is taking shape. It’s clear from Zuckerberg’s words today that Meta plans to deliver “personal superintelligence” through its own products like augmented reality glasses and virtual reality headsets.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Personal devices like glasses that understand our context because they can see what we see, hear what we hear, and interact with us throughout the day will become our primary computing devices,” Zuckerberg wrote in Wednesday’s letter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked about Meta potentially keeping its most advanced models closed, a Meta spokesperson said that the company remains committed to open source AI and said it also expects to train closed source models in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our position on open source AI is unchanged,” a spokesperson said. “We plan to continue releasing leading open source models. We haven’t released everything we’ve developed historically and we expect to continue training a mix of open and closed models going forward.”&lt;br /&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated with more information about Mark Zuckerberg’s stance on open AI models. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/30/zuckerberg-says-meta-likely-wont-open-source-all-of-its-superintelligence-ai-models/</guid><pubDate>Wed, 30 Jul 2025 17:56:58 +0000</pubDate></item><item><title>[NEW] So far, only one-third of Americans have ever used AI for work (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/so-far-only-one-third-of-americans-have-ever-used-ai-for-work/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AP survey shows most Americans treat AI chatbots like a search engine replacement.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An illustration of a woman and a robot putting together two giant puzzle pieces." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_puzzle_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An illustration of a woman and a robot putting together two giant puzzle pieces." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_puzzle_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Arne Weitkaemper via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, The Associated Press released results from a new AP-NORC poll showing that 60 percent of US adults have used AI to search for information, while only 37 percent of all Americans have used AI for work tasks. Meanwhile, younger Americans are adopting AI tools at much higher rates across multiple categories, including brainstorming, work tasks, and companionship.&lt;/p&gt;
&lt;p&gt;The poll found AI companionship remains the least popular application overall, with just 16 percent of adults overall trying it—but the number jumps to a notable 25 percent among the under-30 crowd. AI companionship can have drawbacks that weren't reflected in the poll, such as excessive agreeability (called sycophancy) and mental health risks, like encouraging delusional thinking.&lt;/p&gt;
&lt;p&gt;The poll of 1,437 adults conducted July 10–14 reveals telling generational divides in AI adoption. While 74 percent of adults under 30 use AI for information searches at least some of the time, only the aforementioned 60 percent of all adults have done so. For brainstorming applications, 62 percent of adults under 30 have used AI to come up with ideas, compared with just 20 percent of those 60 or older.&lt;/p&gt;
&lt;p&gt;The findings suggest that despite years of tech industry promotion touting AI as a productivity revolution, most Americans' work lives remain untouched by AI assistants. Roughly one-third of survey respondents use AI for writing emails, creating or editing images, or entertainment. Only 26 percent report using AI for shopping.&lt;/p&gt;
&lt;p&gt;Search remains AI's most common application, though the poll may undercount actual usage since Google automatically generates AI responses at the top of search results, and users may not always recognize when they're interacting with AI-powered features.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Users navigate AI with caution and courtesy&lt;/h2&gt;
&lt;p&gt;The poll captured how Americans are selectively embracing AI while maintaining skepticism about its limitations. To dig into the implications, The Associated Press interviewed several people for comments about the poll results. For example, the AP talked to Courtney Thayer, a 34-year-old audiologist in Des Moines who turns to ChatGPT when planning weekly meals. They also interviewed Sanaa Wilson, a 28-year-old Los Angeles-area data scientist who depends on AI tools for debugging code.&lt;/p&gt;
&lt;p&gt;Wilson's relationship with AI has evolved over time, according to the AP interview. She experimented with ChatGPT for drafting emails before two concerns made her quit: perceptions about high energy consumption behind each query and worries about her own writing skills atrophying.&lt;/p&gt;
&lt;p&gt;Wilson attributes some of the companionship usage of AI to the social isolation many in her generation experienced during the COVID-19 pandemic, though she has no personal interest in AI companions.&lt;/p&gt;
&lt;p&gt;Even those uninterested in AI relationships sometimes hedge their bets. Thayer treats chatbots with careful courtesy, adding "please" and "thank you" to every request—a behavior that echoes concerns like Roko's basilisk, a thought experiment about a future AI model that might reward or punish people based on their past actions toward AI development.&lt;/p&gt;
&lt;p&gt;"I mean, I am nice to it, just because I've watched movies, right?" she told The Associated Press. "So I'll say, 'Can you make me a meal plan, please?' And, 'Can you modify this, please?' And then I'll say, 'Thank you.'"&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AP survey shows most Americans treat AI chatbots like a search engine replacement.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An illustration of a woman and a robot putting together two giant puzzle pieces." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_puzzle_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An illustration of a woman and a robot putting together two giant puzzle pieces." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/robot_puzzle_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Arne Weitkaemper via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, The Associated Press released results from a new AP-NORC poll showing that 60 percent of US adults have used AI to search for information, while only 37 percent of all Americans have used AI for work tasks. Meanwhile, younger Americans are adopting AI tools at much higher rates across multiple categories, including brainstorming, work tasks, and companionship.&lt;/p&gt;
&lt;p&gt;The poll found AI companionship remains the least popular application overall, with just 16 percent of adults overall trying it—but the number jumps to a notable 25 percent among the under-30 crowd. AI companionship can have drawbacks that weren't reflected in the poll, such as excessive agreeability (called sycophancy) and mental health risks, like encouraging delusional thinking.&lt;/p&gt;
&lt;p&gt;The poll of 1,437 adults conducted July 10–14 reveals telling generational divides in AI adoption. While 74 percent of adults under 30 use AI for information searches at least some of the time, only the aforementioned 60 percent of all adults have done so. For brainstorming applications, 62 percent of adults under 30 have used AI to come up with ideas, compared with just 20 percent of those 60 or older.&lt;/p&gt;
&lt;p&gt;The findings suggest that despite years of tech industry promotion touting AI as a productivity revolution, most Americans' work lives remain untouched by AI assistants. Roughly one-third of survey respondents use AI for writing emails, creating or editing images, or entertainment. Only 26 percent report using AI for shopping.&lt;/p&gt;
&lt;p&gt;Search remains AI's most common application, though the poll may undercount actual usage since Google automatically generates AI responses at the top of search results, and users may not always recognize when they're interacting with AI-powered features.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Users navigate AI with caution and courtesy&lt;/h2&gt;
&lt;p&gt;The poll captured how Americans are selectively embracing AI while maintaining skepticism about its limitations. To dig into the implications, The Associated Press interviewed several people for comments about the poll results. For example, the AP talked to Courtney Thayer, a 34-year-old audiologist in Des Moines who turns to ChatGPT when planning weekly meals. They also interviewed Sanaa Wilson, a 28-year-old Los Angeles-area data scientist who depends on AI tools for debugging code.&lt;/p&gt;
&lt;p&gt;Wilson's relationship with AI has evolved over time, according to the AP interview. She experimented with ChatGPT for drafting emails before two concerns made her quit: perceptions about high energy consumption behind each query and worries about her own writing skills atrophying.&lt;/p&gt;
&lt;p&gt;Wilson attributes some of the companionship usage of AI to the social isolation many in her generation experienced during the COVID-19 pandemic, though she has no personal interest in AI companions.&lt;/p&gt;
&lt;p&gt;Even those uninterested in AI relationships sometimes hedge their bets. Thayer treats chatbots with careful courtesy, adding "please" and "thank you" to every request—a behavior that echoes concerns like Roko's basilisk, a thought experiment about a future AI model that might reward or punish people based on their past actions toward AI development.&lt;/p&gt;
&lt;p&gt;"I mean, I am nice to it, just because I've watched movies, right?" she told The Associated Press. "So I'll say, 'Can you make me a meal plan, please?' And, 'Can you modify this, please?' And then I'll say, 'Thank you.'"&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/so-far-only-one-third-of-americans-have-ever-used-ai-for-work/</guid><pubDate>Wed, 30 Jul 2025 18:47:00 +0000</pubDate></item><item><title>[NEW] Who really benefits from the AI boom? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/who-really-benefits-from-the-ai-boom/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;If you’ve been hearing about Trump’s AI Action Plan and wondering who it actually benefits, you’re not alone.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan caught up with Amba Kak and Dr. Sarah Myers West from the AI Now Institute, a think tank focused on the social implications of AI and the consolidation of power in the tech industry. Their recent report, dubbed Artificial Power, lays out the political economy driving today’s AI frenzy and what’s at stake for everyone else.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Artificial Power pushes back on what AI Now calls the “too big to fail” myth, arguing that AI companies are pouring billions into massive compute infrastructure and foundational models, often with government support, despite shaky business models and limited public accountability.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;That push to scale and reach AGI, or artificial general intelligence, before 2030 has real-world consequences that don’t disappear with the promises that AI will someday solve humanity’s hardest problems. In the short term, societies are already facing environmental degradation, discriminatory algorithms, dismantled democratic institutions, lack of data privacy, and national security risk.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Kak and West say these outcomes are the result of a series of choices, not an unpreventable reality.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The future we’re being sold is not inevitable,” Kak explained.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI’s growing consolidation and how it mirrors Big Tech’s power dynamics.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Silicon Valley is cheering on Trump’s AI agenda, and the challenges of regulating AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The disconnect between AGI hype and current, real-world harms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What a democratic, just, and accountable AI future could look like.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;If you’ve been hearing about Trump’s AI Action Plan and wondering who it actually benefits, you’re not alone.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan caught up with Amba Kak and Dr. Sarah Myers West from the AI Now Institute, a think tank focused on the social implications of AI and the consolidation of power in the tech industry. Their recent report, dubbed Artificial Power, lays out the political economy driving today’s AI frenzy and what’s at stake for everyone else.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Artificial Power pushes back on what AI Now calls the “too big to fail” myth, arguing that AI companies are pouring billions into massive compute infrastructure and foundational models, often with government support, despite shaky business models and limited public accountability.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;That push to scale and reach AGI, or artificial general intelligence, before 2030 has real-world consequences that don’t disappear with the promises that AI will someday solve humanity’s hardest problems. In the short term, societies are already facing environmental degradation, discriminatory algorithms, dismantled democratic institutions, lack of data privacy, and national security risk.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Kak and West say these outcomes are the result of a series of choices, not an unpreventable reality.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The future we’re being sold is not inevitable,” Kak explained.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI’s growing consolidation and how it mirrors Big Tech’s power dynamics.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Silicon Valley is cheering on Trump’s AI agenda, and the challenges of regulating AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The disconnect between AGI hype and current, real-world harms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What a democratic, just, and accountable AI future could look like.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/who-really-benefits-from-the-ai-boom/</guid><pubDate>Wed, 30 Jul 2025 19:49:33 +0000</pubDate></item><item><title>[NEW] Meta to spend up to $72B on AI infrastructure in 2025 as compute arms race escalates (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/30/meta-to-spend-up-to-72b-on-ai-infrastructure-in-2025-as-compute-arms-race-escalates/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is pouring money into the physical and technical infrastructure needed to scale its AI ambitions. The company said Wednesday in its second-quarter earnings report that it plans to more than double its spend on building AI infrastructure, like data centers and servers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We currently expect 2025 capital expenditures, including principal payments on finance leases, to be in the range of $66-72 billion…up approximately $30 billion year-over-year at the midpoint,” Meta said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s an aggressive capex growth, and one that Meta plans to continue onwards to 2026. The company said it expects a similarly large increase in spend on AI infrastructure next year as the company continues to “aggressively [pursue] opportunities to bring additional capacity online to meet the needs of [its] artificial intelligence efforts and business operations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We expect that developing leading AI infrastructure will be a core advantage in developing the best AI models and product experiences, so we expect to ramp our investments significantly in 2026 to support that work,” said Susan Li, Meta CFO, during the company’s Wednesday earnings call. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Li also noted that while Meta expects to finance most of its AI spend on its own, the company is exploring ways to work with financial partners to co-develop data centers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t have any finalized transactions to announce, but we generally believe that there will be models here that will attract significant external financing to support large-scale data center projects that are developed using our ability to build world-class infrastructure, while providing us with flexibility should our infrastructure requirements change over time,” Li said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has announced two major AI “titan clusters.” The first is Prometheus in Ohio, which is poised to be among the first AI superclusters to hit 1 gigawatt of compute power when it comes online in 2026. Then there’s Hyperion, a cluster in Louisiana that Meta CEO Mark Zuckerberg has bragged would have a footprint the size of Manhattan and could scale up to 5 gigawatts over several years. On top of those, Meta has several other unnamed titan-scale clusters underway.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s data center projects promise to soak up enough energy to power millions of homes, pulling that electricity from nearby communities. One of the company’s projects in Newton County, Georgia, has already&amp;nbsp;caused the water taps to run dry in some residents’ homes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also noted in its earnings report that it expects its second-largest driver of growth to be employee compensation as the company spends millions, and possibly even billions, to poach talented AI engineers and researchers to work for Meta’s newly formed business unit, Superintelligence Labs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before earnings, Zuckerberg shared his vision for “personal superintelligence,” the idea that AI should help individual people live their best lives, mainly through the medium of Meta’s smart glasses and virtual reality headsets. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta’s stock surged 10% in after-hours as investors responded to Meta’s overall performance in the quarter and better-than-expected outlook for the third quarter. Meta reported revenue of $47.5 billion in the second quarter, with expectations to hit between $47.5 billion and $50.5 billion in Q3. Advertising drove Meta’s revenue gains, fueled by AI tools — like AI-powered translations and video generation — to help advertisers create more meaningful and targeted campaigns. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s Reality Labs segment, however, saw a $4.5 billion loss. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to reflect Meta’s additional paths to funding its AI infrastructure builds.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2194278734.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is pouring money into the physical and technical infrastructure needed to scale its AI ambitions. The company said Wednesday in its second-quarter earnings report that it plans to more than double its spend on building AI infrastructure, like data centers and servers.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We currently expect 2025 capital expenditures, including principal payments on finance leases, to be in the range of $66-72 billion…up approximately $30 billion year-over-year at the midpoint,” Meta said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That’s an aggressive capex growth, and one that Meta plans to continue onwards to 2026. The company said it expects a similarly large increase in spend on AI infrastructure next year as the company continues to “aggressively [pursue] opportunities to bring additional capacity online to meet the needs of [its] artificial intelligence efforts and business operations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We expect that developing leading AI infrastructure will be a core advantage in developing the best AI models and product experiences, so we expect to ramp our investments significantly in 2026 to support that work,” said Susan Li, Meta CFO, during the company’s Wednesday earnings call. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Li also noted that while Meta expects to finance most of its AI spend on its own, the company is exploring ways to work with financial partners to co-develop data centers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t have any finalized transactions to announce, but we generally believe that there will be models here that will attract significant external financing to support large-scale data center projects that are developed using our ability to build world-class infrastructure, while providing us with flexibility should our infrastructure requirements change over time,” Li said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has announced two major AI “titan clusters.” The first is Prometheus in Ohio, which is poised to be among the first AI superclusters to hit 1 gigawatt of compute power when it comes online in 2026. Then there’s Hyperion, a cluster in Louisiana that Meta CEO Mark Zuckerberg has bragged would have a footprint the size of Manhattan and could scale up to 5 gigawatts over several years. On top of those, Meta has several other unnamed titan-scale clusters underway.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s data center projects promise to soak up enough energy to power millions of homes, pulling that electricity from nearby communities. One of the company’s projects in Newton County, Georgia, has already&amp;nbsp;caused the water taps to run dry in some residents’ homes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta also noted in its earnings report that it expects its second-largest driver of growth to be employee compensation as the company spends millions, and possibly even billions, to poach talented AI engineers and researchers to work for Meta’s newly formed business unit, Superintelligence Labs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before earnings, Zuckerberg shared his vision for “personal superintelligence,” the idea that AI should help individual people live their best lives, mainly through the medium of Meta’s smart glasses and virtual reality headsets. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meta’s stock surged 10% in after-hours as investors responded to Meta’s overall performance in the quarter and better-than-expected outlook for the third quarter. Meta reported revenue of $47.5 billion in the second quarter, with expectations to hit between $47.5 billion and $50.5 billion in Q3. Advertising drove Meta’s revenue gains, fueled by AI tools — like AI-powered translations and video generation — to help advertisers create more meaningful and targeted campaigns. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s Reality Labs segment, however, saw a $4.5 billion loss. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated to reflect Meta’s additional paths to funding its AI infrastructure builds.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/30/meta-to-spend-up-to-72b-on-ai-infrastructure-in-2025-as-compute-arms-race-escalates/</guid><pubDate>Wed, 30 Jul 2025 21:31:42 +0000</pubDate></item><item><title>[NEW] Zuckerberg says people without AI glasses will be at a disadvantage in the future (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/30/zuckerberg-says-people-without-ai-glasses-will-be-at-a-disadvantage-in-the-future/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Echoing sentiments shared in his “superintelligence”-focused blog post this morning, Meta CEO Mark Zuckerberg expanded on his bullish ideas that glasses will be the primary way users interact with AI in the years ahead. During Meta’s second-quarter earnings call, the social networking exec told investors he believes people without AI glasses will be at a disadvantage in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I continue to think that glasses are basically going to be the ideal form factor for AI, because you can let an AI see what you see throughout the day, hear what you hear, [and] talk to you,” Zuckerberg said during the earnings call. Adding a display to those glasses will then unlock more value, he said, whether that’s a wider, holographic field of view, as with Meta’s next-gen Orion AR glasses, or a smaller display that might ship in everyday AI eyewear.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think in the future, if you don’t have glasses that have AI — or some way to interact with AI — I think you’re&amp;nbsp;…  probably [going to] be at a pretty significant cognitive disadvantage compared to other people,” Zuckerberg added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has been focused on building smart glasses, like its Ray-Ban Meta glasses and, more recently, Oakley Meta glasses. The glasses let users listen to music, take photos or videos, and ask Meta AI questions, including about what they’re seeing, among other things. These wearables have turned into a surprise hit for the company, as revenue from sales of the Ray-Ban Metas more than tripled year-over-year, according to glasses giant EssilorLuxottica. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Zuckerberg believes there’s more to be done with displays. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is&amp;nbsp;… what we’ve been maxing out with Reality Labs over the last 5 to 10 years — basically doing the research on all these different things,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Reality Labs division has been a money pit for the company, so it’s not surprising the exec wants to justify its cost to investors by positioning it as a bet on the future of AI and consumer computing in general. For example, Meta said Reality Labs’ operating loss was $4.53 billion in the second quarter. Since 2020, the unit has lost nearly $70 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the future of consumer AI may or may not be in the form of glasses. This spring, OpenAI acquired former Apple executive Jony Ive’s startup in a $6.5 billion deal to build new consumer devices for interacting with AI. Already, other startups have dabbled in this area as well, including in form factors like AI pins — such as with Humane’s flop — and pendents, like those from Limitless and Friend.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasses, for now, seem to make the most sense, as many people already wear them, and they’re more socially acceptable. But the world didn’t know it needed smartphones, either, until someone dreamed them up. The next AI device could be something we can’t even imagine yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Zuckerberg cheers the idea that glasses are going to be it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The other thing that’s awesome about glasses is they are going to be the ideal way to blend the physical and digital worlds together,” he said. “So the whole Metaverse vision, I think, is going to&amp;nbsp;… end up being extremely important, too, and AI is going to accelerate that.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/zuck-meta.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Echoing sentiments shared in his “superintelligence”-focused blog post this morning, Meta CEO Mark Zuckerberg expanded on his bullish ideas that glasses will be the primary way users interact with AI in the years ahead. During Meta’s second-quarter earnings call, the social networking exec told investors he believes people without AI glasses will be at a disadvantage in the future.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I continue to think that glasses are basically going to be the ideal form factor for AI, because you can let an AI see what you see throughout the day, hear what you hear, [and] talk to you,” Zuckerberg said during the earnings call. Adding a display to those glasses will then unlock more value, he said, whether that’s a wider, holographic field of view, as with Meta’s next-gen Orion AR glasses, or a smaller display that might ship in everyday AI eyewear.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think in the future, if you don’t have glasses that have AI — or some way to interact with AI — I think you’re&amp;nbsp;…  probably [going to] be at a pretty significant cognitive disadvantage compared to other people,” Zuckerberg added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has been focused on building smart glasses, like its Ray-Ban Meta glasses and, more recently, Oakley Meta glasses. The glasses let users listen to music, take photos or videos, and ask Meta AI questions, including about what they’re seeing, among other things. These wearables have turned into a surprise hit for the company, as revenue from sales of the Ray-Ban Metas more than tripled year-over-year, according to glasses giant EssilorLuxottica. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Zuckerberg believes there’s more to be done with displays. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is&amp;nbsp;… what we’ve been maxing out with Reality Labs over the last 5 to 10 years — basically doing the research on all these different things,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Reality Labs division has been a money pit for the company, so it’s not surprising the exec wants to justify its cost to investors by positioning it as a bet on the future of AI and consumer computing in general. For example, Meta said Reality Labs’ operating loss was $4.53 billion in the second quarter. Since 2020, the unit has lost nearly $70 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the future of consumer AI may or may not be in the form of glasses. This spring, OpenAI acquired former Apple executive Jony Ive’s startup in a $6.5 billion deal to build new consumer devices for interacting with AI. Already, other startups have dabbled in this area as well, including in form factors like AI pins — such as with Humane’s flop — and pendents, like those from Limitless and Friend.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Glasses, for now, seem to make the most sense, as many people already wear them, and they’re more socially acceptable. But the world didn’t know it needed smartphones, either, until someone dreamed them up. The next AI device could be something we can’t even imagine yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Zuckerberg cheers the idea that glasses are going to be it.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The other thing that’s awesome about glasses is they are going to be the ideal way to blend the physical and digital worlds together,” he said. “So the whole Metaverse vision, I think, is going to&amp;nbsp;… end up being extremely important, too, and AI is going to accelerate that.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/30/zuckerberg-says-people-without-ai-glasses-will-be-at-a-disadvantage-in-the-future/</guid><pubDate>Wed, 30 Jul 2025 22:47:30 +0000</pubDate></item><item><title>[NEW] Kleiner Perkins-backed Ambiq pops on IPO debut (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/30/kleiner-perkins-backed-ambiq-pops-on-ipo-debut/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2227082921.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ambiq Micro, a 15-year-old manufacturer of energy-efficient chips for wearable and medical devices, closed its first day of trading on Wednesday at $38.53 a share, a 61% increase from the $24 IPO price the company set the previous day.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The success of the IPO signals strong investor demand in the public market for new small-cap companies benefiting from AI innovation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ambiq closed its first day as a public company with a valuation of $656 million (excluding employee options). This represents a significant increase from its last private funding valuation of $450 million in 2023, according to PitchBook.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ambiq has pitched itself as well-positioned to capitalize on the growth driven by AI. “Because we’re so low energy, we can put more intelligence and more AI on board” of edge processors, the company’s CTO Scott Hanson told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For the three months that ended March 31, Ambiq posted a net loss of $8.3 million against revenues of $15.7 million, the company’s S1 filing shows. The Q1 results mark a slight improvement from the first quarter of 2024, when the company reported a $9.8 million loss on $15.2 million in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kleiner Perkins and EDB Investments, a Singaporean state-backed entity, are the largest outside backers of Ambiq, according to the filing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wen Hsieh, who was a general partner at Kleiner Perkins until 2023, first backed Ambiq when the company raised its Series C in 2014. Hsieh also invested in Ambiq after he launched his own venture firm, Matter Venture Partners, two years ago.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2227082921.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Ambiq Micro, a 15-year-old manufacturer of energy-efficient chips for wearable and medical devices, closed its first day of trading on Wednesday at $38.53 a share, a 61% increase from the $24 IPO price the company set the previous day.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The success of the IPO signals strong investor demand in the public market for new small-cap companies benefiting from AI innovation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ambiq closed its first day as a public company with a valuation of $656 million (excluding employee options). This represents a significant increase from its last private funding valuation of $450 million in 2023, according to PitchBook.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ambiq has pitched itself as well-positioned to capitalize on the growth driven by AI. “Because we’re so low energy, we can put more intelligence and more AI on board” of edge processors, the company’s CTO Scott Hanson told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For the three months that ended March 31, Ambiq posted a net loss of $8.3 million against revenues of $15.7 million, the company’s S1 filing shows. The Q1 results mark a slight improvement from the first quarter of 2024, when the company reported a $9.8 million loss on $15.2 million in revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kleiner Perkins and EDB Investments, a Singaporean state-backed entity, are the largest outside backers of Ambiq, according to the filing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wen Hsieh, who was a general partner at Kleiner Perkins until 2023, first backed Ambiq when the company raised its Series C in 2014. Hsieh also invested in Ambiq after he launched his own venture firm, Matter Venture Partners, two years ago.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/30/kleiner-perkins-backed-ambiq-pops-on-ipo-debut/</guid><pubDate>Thu, 31 Jul 2025 01:00:24 +0000</pubDate></item><item><title>[NEW] GitHub Copilot crosses 20 million all-time users (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/30/github-copilot-crosses-20-million-all-time-users/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1785159335.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;GitHub Copilot, an AI coding tool offered by Microsoft-owned GitHub, has now reached more than 20 million users, Microsoft CEO Satya Nadella said on the company’s earnings call Wednesday. A GitHub spokesperson confirmed to TechCrunch that this number represents “all-time users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That means five million people have tried out GitHub Copilot for the first time in the last three months; the company reported in April the tool had reached 15 million users. Microsoft and GitHub don’t report how many of these 20 million people have continued to use the AI coding tool on a monthly or daily basis — though those metrics are likely far lower.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Microsoft also reported GitHub Copilot, which is among the most popular AI coding tools offered today, is used by 90% of the Fortune 100. The product’s growth among enterprise customers has also grown about 75% compared to last quarter, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI coding tools are rising in popularity, and they seem to be one of the few AI products generating notable revenue. In 2024, Nadella said GitHub Copilot was a larger business than all of GitHub was when Microsoft acquired it in 2018. In the year since, it seems GitHub Copilot’s growth rate has continued in a positive direction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The world’s most popular AI coding tools still have tiny user bases compared to AI chatbots like ChatGPT and Gemini, which attract hundreds of millions of users every month. Of course, software engineering is more niche than the general informational queries offered by AI chatbots. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, software engineers and their employers seem to be willing to pay a premium for AI coding tools. And with Microsoft’s long list of enterprise customers and GitHub’s ecosystem of developers, GitHub Copilot is well positioned to dominate the market for enterprise AI coding tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cursor, another popular AI coding tool, wants to challenge GitHub Copilot in the enterprise, and it’s been scooping up talent from fledgling AI startups to do so. Cursor reportedly had more than a million people using its product every day in March, according to Bloomberg. At that time, the company generated about $200 million in annualized recurring revenue. Today, Cursor’s ARR is more than $500 million, suggesting there are now a lot more people using its products everyday.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While GitHub Copilot and Cursor initially sought to tackle different parts of the developer experience, they’re steadily converging into similar products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both companies have recently introduced AI agents to review code and catch bugs introduced by humans. Github and Cursor are also both trying to create AI agents that automate programmer workflows, allowing developers to offload tasks altogether. Nadella said during Wednesday’s earnings call that GitHub was seeing great momentum with their AI coding agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Cursor, GitHub has an array of well-capitalized competitors that would like to sell AI coding tools to the enterprise. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;There’s Google — which acquired the leaders of AI coding startup Windsurf — as well as Cognition, the maker of Devin that subsequently acquired the rest of Windsurf’s team. That’s not to mention OpenAI and Anthropic, which are both building out their own AI coding offerings powered by in-house AI models, Codex and Claude Code respectively, in an attempt to win the market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The nascent space is quickly heating up into one of AI’s most competitive markets. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1785159335.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;GitHub Copilot, an AI coding tool offered by Microsoft-owned GitHub, has now reached more than 20 million users, Microsoft CEO Satya Nadella said on the company’s earnings call Wednesday. A GitHub spokesperson confirmed to TechCrunch that this number represents “all-time users.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That means five million people have tried out GitHub Copilot for the first time in the last three months; the company reported in April the tool had reached 15 million users. Microsoft and GitHub don’t report how many of these 20 million people have continued to use the AI coding tool on a monthly or daily basis — though those metrics are likely far lower.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Microsoft also reported GitHub Copilot, which is among the most popular AI coding tools offered today, is used by 90% of the Fortune 100. The product’s growth among enterprise customers has also grown about 75% compared to last quarter, according to the company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI coding tools are rising in popularity, and they seem to be one of the few AI products generating notable revenue. In 2024, Nadella said GitHub Copilot was a larger business than all of GitHub was when Microsoft acquired it in 2018. In the year since, it seems GitHub Copilot’s growth rate has continued in a positive direction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The world’s most popular AI coding tools still have tiny user bases compared to AI chatbots like ChatGPT and Gemini, which attract hundreds of millions of users every month. Of course, software engineering is more niche than the general informational queries offered by AI chatbots. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, software engineers and their employers seem to be willing to pay a premium for AI coding tools. And with Microsoft’s long list of enterprise customers and GitHub’s ecosystem of developers, GitHub Copilot is well positioned to dominate the market for enterprise AI coding tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cursor, another popular AI coding tool, wants to challenge GitHub Copilot in the enterprise, and it’s been scooping up talent from fledgling AI startups to do so. Cursor reportedly had more than a million people using its product every day in March, according to Bloomberg. At that time, the company generated about $200 million in annualized recurring revenue. Today, Cursor’s ARR is more than $500 million, suggesting there are now a lot more people using its products everyday.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While GitHub Copilot and Cursor initially sought to tackle different parts of the developer experience, they’re steadily converging into similar products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both companies have recently introduced AI agents to review code and catch bugs introduced by humans. Github and Cursor are also both trying to create AI agents that automate programmer workflows, allowing developers to offload tasks altogether. Nadella said during Wednesday’s earnings call that GitHub was seeing great momentum with their AI coding agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Cursor, GitHub has an array of well-capitalized competitors that would like to sell AI coding tools to the enterprise. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;There’s Google — which acquired the leaders of AI coding startup Windsurf — as well as Cognition, the maker of Devin that subsequently acquired the rest of Windsurf’s team. That’s not to mention OpenAI and Anthropic, which are both building out their own AI coding offerings powered by in-house AI models, Codex and Claude Code respectively, in an attempt to win the market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The nascent space is quickly heating up into one of AI’s most competitive markets. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/30/github-copilot-crosses-20-million-all-time-users/</guid><pubDate>Thu, 31 Jul 2025 01:16:55 +0000</pubDate></item></channel></rss>