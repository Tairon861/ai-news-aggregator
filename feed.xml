<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 10 Jul 2025 06:34:23 +0000</lastBuildDate><item><title>AI mania pushes Nvidia to record $4 trillion valuation (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/ai-mania-pushes-nvidia-to-record-4-trillion-valuation/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI craze makes Nvidia the most valuable publicly traded company in history.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Nvidia logo on a green background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Nvidia logo on a green background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Nvidia / Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Nvidia became the first company in history to reach $4 trillion market valuation as shares rose more than 2 percent, reports CNBC. The GPU maker's stock has climbed 22 percent since the start of 2025, continuing a trend driven by demand for AI hardware following ChatGPT's late 2022 launch.&lt;/p&gt;
&lt;p&gt;The milestone marks the highest market cap ever recorded for a publicly traded company, surpassing Apple's previous record of $3.8 trillion set in December. Nvidia first crossed $2 trillion in February 2024 and reached $3 trillion just four months later in June. The $4 trillion valuation represents a market capitalization larger than the GDP of most countries.&lt;/p&gt;
&lt;p&gt;As we explained in 2023, Nvidia's continued success has been intimately tied to growth in demand for hardware that runs AI models as capably and efficiently as possible. The company's data center GPUs excel at performing billions of matrix multiplications necessary to train and run neural networks due to their parallel architecture—hardware architectures that originated as video game graphics accelerators now power the generative AI boom.&lt;/p&gt;
&lt;p&gt;Companies like OpenAI, Microsoft, and others need tens of thousands of these specialized chips to power services like ChatGPT, AI image generators, and enterprise AI applications. Meanwhile, Nvidia's CUDA platform (which makes developing AI applications that use GPUs easier) has become a de facto standard, creating a moat around its hardware ecosystem.&lt;/p&gt;
&lt;h2&gt;China restrictions and market resilience&lt;/h2&gt;
&lt;p&gt;It has been a roller-coaster year for Nvidia stock after multiple shocks. In January, a brief investor panic over the emergence of China's DeepSeek model had some analysts suggesting it might reduce future AI chip requirements. In April, Trump's "Liberation Day" tariff announcement caused Nvidia's shares to dive even more dramatically, but the company's valuation has gained more than 15 percent over the past month despite these episodes.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Beyond market volatility, Nvidia faces ongoing geopolitical challenges that threaten its access to one of its largest markets. Export controls on Nvidia's chips designed to keep advanced AI tech out of Chinese hands (that date back to 2022, during the early Biden era) have created a thorny obstacle for the company that it has tried to work around over time with new chip designs, including a special lower-speed chip called the H20.&lt;/p&gt;
&lt;p&gt;In April, the Trump administration imposed export restrictions on the H20, which require Nvidia to apply for licenses each time it wants to sell the chip to customers in China, costing the company $5.5 billion in charges and effectively shutting Nvidia out of what CEO Jensen Huang has described as a "$50 billion China market."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1877557 align-"&gt;
    &lt;div&gt;
                        &lt;img alt="The Nvidia logo superimposed over China's flag." class=" large" height="358" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/nvidia_china_hero_1-640x358.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Nvidia

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Simultaneously, Trump has also signaled that he may be willing to ease some restrictions after Nvidia promised the Trump administration new US investments in AI data centers. But the administration's approach remains unpredictable—Trump has continued to voice his desire for the US to remain an AI leader while trying to keep top tech out of the hands of China, creating a challenging environment for Nvidia to navigate.&lt;/p&gt;
&lt;p&gt;Meanwhile, Nvidia's continued success depends on the continued growth of the AI industry, which some critics consider unsustainable at current levels. Some analysts point to the massive capital expenditures by tech giants on AI infrastructure—with companies like Microsoft, Google, and Meta each spending tens of billions annually on data centers—and question whether the returns will justify the investment.&lt;/p&gt;
&lt;p&gt;For now, Nvidia sits atop the tech world as the most valuable company, but whether that position proves sustainable will depend on factors ranging from geopolitical tensions to the question of whether AI applications can actually deliver on the tech industry's promises.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI craze makes Nvidia the most valuable publicly traded company in history.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Nvidia logo on a green background." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Nvidia logo on a green background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/nvidia_green_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Nvidia / Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Nvidia became the first company in history to reach $4 trillion market valuation as shares rose more than 2 percent, reports CNBC. The GPU maker's stock has climbed 22 percent since the start of 2025, continuing a trend driven by demand for AI hardware following ChatGPT's late 2022 launch.&lt;/p&gt;
&lt;p&gt;The milestone marks the highest market cap ever recorded for a publicly traded company, surpassing Apple's previous record of $3.8 trillion set in December. Nvidia first crossed $2 trillion in February 2024 and reached $3 trillion just four months later in June. The $4 trillion valuation represents a market capitalization larger than the GDP of most countries.&lt;/p&gt;
&lt;p&gt;As we explained in 2023, Nvidia's continued success has been intimately tied to growth in demand for hardware that runs AI models as capably and efficiently as possible. The company's data center GPUs excel at performing billions of matrix multiplications necessary to train and run neural networks due to their parallel architecture—hardware architectures that originated as video game graphics accelerators now power the generative AI boom.&lt;/p&gt;
&lt;p&gt;Companies like OpenAI, Microsoft, and others need tens of thousands of these specialized chips to power services like ChatGPT, AI image generators, and enterprise AI applications. Meanwhile, Nvidia's CUDA platform (which makes developing AI applications that use GPUs easier) has become a de facto standard, creating a moat around its hardware ecosystem.&lt;/p&gt;
&lt;h2&gt;China restrictions and market resilience&lt;/h2&gt;
&lt;p&gt;It has been a roller-coaster year for Nvidia stock after multiple shocks. In January, a brief investor panic over the emergence of China's DeepSeek model had some analysts suggesting it might reduce future AI chip requirements. In April, Trump's "Liberation Day" tariff announcement caused Nvidia's shares to dive even more dramatically, but the company's valuation has gained more than 15 percent over the past month despite these episodes.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Beyond market volatility, Nvidia faces ongoing geopolitical challenges that threaten its access to one of its largest markets. Export controls on Nvidia's chips designed to keep advanced AI tech out of Chinese hands (that date back to 2022, during the early Biden era) have created a thorny obstacle for the company that it has tried to work around over time with new chip designs, including a special lower-speed chip called the H20.&lt;/p&gt;
&lt;p&gt;In April, the Trump administration imposed export restrictions on the H20, which require Nvidia to apply for licenses each time it wants to sell the chip to customers in China, costing the company $5.5 billion in charges and effectively shutting Nvidia out of what CEO Jensen Huang has described as a "$50 billion China market."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1877557 align-"&gt;
    &lt;div&gt;
                        &lt;img alt="The Nvidia logo superimposed over China's flag." class=" large" height="358" src="https://cdn.arstechnica.net/wp-content/uploads/2022/09/nvidia_china_hero_1-640x358.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Nvidia

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Simultaneously, Trump has also signaled that he may be willing to ease some restrictions after Nvidia promised the Trump administration new US investments in AI data centers. But the administration's approach remains unpredictable—Trump has continued to voice his desire for the US to remain an AI leader while trying to keep top tech out of the hands of China, creating a challenging environment for Nvidia to navigate.&lt;/p&gt;
&lt;p&gt;Meanwhile, Nvidia's continued success depends on the continued growth of the AI industry, which some critics consider unsustainable at current levels. Some analysts point to the massive capital expenditures by tech giants on AI infrastructure—with companies like Microsoft, Google, and Meta each spending tens of billions annually on data centers—and question whether the returns will justify the investment.&lt;/p&gt;
&lt;p&gt;For now, Nvidia sits atop the tech world as the most valuable company, but whether that position proves sustainable will depend on factors ranging from geopolitical tensions to the question of whether AI applications can actually deliver on the tech industry's promises.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/ai-mania-pushes-nvidia-to-record-4-trillion-valuation/</guid><pubDate>Wed, 09 Jul 2025 18:35:15 +0000</pubDate></item><item><title>OpenAI is reportedly releasing an AI browser in the coming weeks (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hot on the heels of Perplexity’s Comet launch, OpenAI is planning to release an AI-powered web browser of its own to challenge Google Chrome, according to a report from Reuters on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker reportedly aims to release its browser in the coming weeks. Much like Perplexity’s Comet and The Browser Company’s Dia, OpenAI’s browser is said to use AI to rethink how users browse the web. Supposedly, the browser keeps some user interactions inside ChatGPT instead of linking out to websites. Reuters reports that OpenAI’s browser may integrate Operator, the company’s web-browsing AI agent, as a key feature.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI had considered building a browser to compete with Google Chrome in 2024, according to The Information. Much like Perplexity, OpenAI likely wants to get direct access to user data and have the freedom to create novel user experiences that aren’t intermediated by Google.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hot on the heels of Perplexity’s Comet launch, OpenAI is planning to release an AI-powered web browser of its own to challenge Google Chrome, according to a report from Reuters on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker reportedly aims to release its browser in the coming weeks. Much like Perplexity’s Comet and The Browser Company’s Dia, OpenAI’s browser is said to use AI to rethink how users browse the web. Supposedly, the browser keeps some user interactions inside ChatGPT instead of linking out to websites. Reuters reports that OpenAI’s browser may integrate Operator, the company’s web-browsing AI agent, as a key feature.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI had considered building a browser to compete with Google Chrome in 2024, according to The Information. Much like Perplexity, OpenAI likely wants to get direct access to user data and have the freedom to create novel user experiences that aren’t intermediated by Google.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks/</guid><pubDate>Wed, 09 Jul 2025 18:48:06 +0000</pubDate></item><item><title>AI shapes autonomous underwater “gliders” (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/ai-shapes-autonomous-underwater-gliders-0709</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-auv-Gliders.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-cf34fa1c-7fff-d3f4-d4e3-35ce42aa6255"&gt;Marine scientists have long marveled at how animals like fish and seals swim so efficiently despite having different shapes. Their bodies are optimized for efficient, hydrodynamic aquatic navigation so they can exert minimal energy when traveling long distances.&lt;/p&gt;&lt;p&gt;Autonomous vehicles can drift through the ocean in a similar way, collecting data about vast underwater environments. However, the shapes of these gliding machines are less diverse than what we find in marine life — go-to designs often resemble tubes or torpedoes, since they’re fairly hydrodynamic as well. Plus, testing new builds requires lots of real-world trial-and-error.&lt;/p&gt;&lt;p&gt;Researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and the University of Wisconsin at Madison propose that AI could help us explore uncharted glider designs more conveniently. Their method uses machine learning to test different 3D designs in a physics simulator, then molds them into more hydrodynamic shapes. The resulting model can be fabricated via a 3D printer using significantly less energy than hand-made ones.&lt;/p&gt;&lt;p&gt;The MIT scientists say that this design pipeline could create new, more efficient machines that help oceanographers measure water temperature and salt levels, gather more detailed insights about currents, and monitor the impacts of climate change. The team demonstrated this potential by producing two gliders roughly the size of a boogie board: a two-winged machine resembling an airplane, and a unique, four-winged object resembling a flat fish with four fins.&lt;/p&gt;&lt;p dir="ltr"&gt;Peter Yichen Chen, MIT CSAIL postdoc and co-lead researcher on the project, notes that these designs are just a few of the novel shapes his team’s approach can generate. “We’ve developed a semi-automated process that can help us test unconventional designs that would be very taxing for humans to design,” he says. “This level of shape diversity hasn’t been explored previously, so most of these designs haven’t been tested in the real world.”&lt;/p&gt;&lt;p dir="ltr"&gt;But how did AI come up with these ideas in the first place? First, the researchers found 3D models of over 20 conventional sea exploration shapes, such as submarines, whales, manta rays, and sharks. Then, they enclosed these models in “deformation cages” that map out different articulation points that the researchers pulled around to create new shapes.&lt;/p&gt;&lt;p dir="ltr"&gt;The CSAIL-led team built a dataset of conventional and deformed shapes before simulating how they would perform at different “angles-of-attack” — the direction a vessel will tilt as it glides through the water. For example, a swimmer may want to dive at a -30 degree angle to retrieve an item from a pool.&lt;/p&gt;&lt;p dir="ltr"&gt;These diverse shapes and angles of attack were then used as inputs for a neural network that essentially anticipates how efficiently a glider shape will perform at particular angles and optimizes it as needed.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Giving gliding robots a lift&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The team’s neural network simulates how a particular glider would react to underwater physics, aiming to capture how it moves forward and the force that drags against it. The goal: find the best lift-to-drag ratio, representing how much the glider is being held up compared to how much it’s being held back. The higher the ratio, the more efficiently the vehicle travels; the lower it is, the more the glider will slow down during its voyage.&lt;/p&gt;&lt;p dir="ltr"&gt;Lift-to-drag ratios are key for flying planes: At takeoff, you want to maximize lift to ensure it can glide well against wind currents, and when landing, you need sufficient force to drag it to a full stop.&lt;/p&gt;&lt;p dir="ltr"&gt;Niklas Hagemann, an MIT graduate student in architecture and CSAIL affiliate, notes that this ratio is just as useful if you want a similar gliding motion in the ocean.&lt;/p&gt;&lt;p&gt;“Our pipeline modifies glider shapes to find the best lift-to-drag ratio, optimizing its performance underwater,” says Hagemann, who is also a co-lead author on a&amp;nbsp;paper that was presented at the International Conference on Robotics and Automation in June. “You can then export the top-performing designs so they can be 3D-printed.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Going for a quick glide&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While their AI pipeline seemed realistic, the researchers needed to ensure its predictions about glider performance were accurate by experimenting in more lifelike environments.&lt;/p&gt;&lt;p dir="ltr"&gt;They first fabricated their two-wing design as a scaled-down vehicle resembling a paper airplane. This glider was taken to MIT’s Wright Brothers Wind Tunnel, an indoor space with fans that simulate wind flow. Placed at different angles, the glider’s predicted lift-to-drag ratio was only about 5 percent higher on average than the ones recorded in the wind experiments — a small difference between simulation and reality.&lt;/p&gt;&lt;p&gt;A digital evaluation involving a visual, more complex physics simulator also supported the notion that the AI pipeline made fairly accurate predictions about how the gliders would move. It visualized how these machines would descend in 3D.&lt;/p&gt;&lt;p&gt;To truly evaluate these gliders in the real world, though, the team needed to see how their devices would fare underwater. They printed two designs that performed the best at specific points-of-attack for this test: a jet-like device at 9 degrees and the four-wing vehicle at 30 degrees.&lt;/p&gt;&lt;p dir="ltr"&gt;Both shapes were fabricated in a 3D printer as hollow shells with small holes that flood when fully submerged. This lightweight design makes the vehicle easier to handle outside of the water and requires less material to be fabricated. The researchers placed a tube-like device inside these shell coverings, which housed a range of hardware, including a pump to change the glider’s buoyancy, a mass shifter (a device that controls the machine’s angle-of-attack), and electronic components.&lt;/p&gt;&lt;p&gt;Each design outperformed a handmade torpedo-shaped glider by moving more efficiently across a pool. With higher lift-to-drag ratios than their counterpart, both AI-driven machines exerted less energy, similar to the effortless ways marine animals navigate the oceans.&lt;/p&gt;&lt;p&gt;As much as the project is an encouraging step forward for glider design, the researchers are looking to narrow the gap between simulation and real-world performance. They are also hoping to develop machines that can react to sudden changes in currents, making the gliders more adaptable to seas and oceans.&lt;/p&gt;&lt;p&gt;Chen adds that the team is looking to explore new types of shapes, particularly thinner glider designs. They intend to make their framework faster, perhaps bolstering it with new features that enable more customization, maneuverability, or even the creation of miniature vehicles.&lt;/p&gt;&lt;p&gt;Chen and Hagemann co-led research on this project with OpenAI researcher Pingchuan Ma SM ’23, PhD ’25. They authored the paper with Wei Wang, a University of Wisconsin at Madison assistant professor and recent CSAIL postdoc; John Romanishin ’12, SM ’18, PhD ’23; and two MIT professors and CSAIL members: lab director Daniela Rus and senior author Wojciech Matusik. Their work was supported, in part, by a Defense Advanced Research Projects Agency (DARPA) grant and the MIT-GIST Program.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-auv-Gliders.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-cf34fa1c-7fff-d3f4-d4e3-35ce42aa6255"&gt;Marine scientists have long marveled at how animals like fish and seals swim so efficiently despite having different shapes. Their bodies are optimized for efficient, hydrodynamic aquatic navigation so they can exert minimal energy when traveling long distances.&lt;/p&gt;&lt;p&gt;Autonomous vehicles can drift through the ocean in a similar way, collecting data about vast underwater environments. However, the shapes of these gliding machines are less diverse than what we find in marine life — go-to designs often resemble tubes or torpedoes, since they’re fairly hydrodynamic as well. Plus, testing new builds requires lots of real-world trial-and-error.&lt;/p&gt;&lt;p&gt;Researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) and the University of Wisconsin at Madison propose that AI could help us explore uncharted glider designs more conveniently. Their method uses machine learning to test different 3D designs in a physics simulator, then molds them into more hydrodynamic shapes. The resulting model can be fabricated via a 3D printer using significantly less energy than hand-made ones.&lt;/p&gt;&lt;p&gt;The MIT scientists say that this design pipeline could create new, more efficient machines that help oceanographers measure water temperature and salt levels, gather more detailed insights about currents, and monitor the impacts of climate change. The team demonstrated this potential by producing two gliders roughly the size of a boogie board: a two-winged machine resembling an airplane, and a unique, four-winged object resembling a flat fish with four fins.&lt;/p&gt;&lt;p dir="ltr"&gt;Peter Yichen Chen, MIT CSAIL postdoc and co-lead researcher on the project, notes that these designs are just a few of the novel shapes his team’s approach can generate. “We’ve developed a semi-automated process that can help us test unconventional designs that would be very taxing for humans to design,” he says. “This level of shape diversity hasn’t been explored previously, so most of these designs haven’t been tested in the real world.”&lt;/p&gt;&lt;p dir="ltr"&gt;But how did AI come up with these ideas in the first place? First, the researchers found 3D models of over 20 conventional sea exploration shapes, such as submarines, whales, manta rays, and sharks. Then, they enclosed these models in “deformation cages” that map out different articulation points that the researchers pulled around to create new shapes.&lt;/p&gt;&lt;p dir="ltr"&gt;The CSAIL-led team built a dataset of conventional and deformed shapes before simulating how they would perform at different “angles-of-attack” — the direction a vessel will tilt as it glides through the water. For example, a swimmer may want to dive at a -30 degree angle to retrieve an item from a pool.&lt;/p&gt;&lt;p dir="ltr"&gt;These diverse shapes and angles of attack were then used as inputs for a neural network that essentially anticipates how efficiently a glider shape will perform at particular angles and optimizes it as needed.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Giving gliding robots a lift&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;The team’s neural network simulates how a particular glider would react to underwater physics, aiming to capture how it moves forward and the force that drags against it. The goal: find the best lift-to-drag ratio, representing how much the glider is being held up compared to how much it’s being held back. The higher the ratio, the more efficiently the vehicle travels; the lower it is, the more the glider will slow down during its voyage.&lt;/p&gt;&lt;p dir="ltr"&gt;Lift-to-drag ratios are key for flying planes: At takeoff, you want to maximize lift to ensure it can glide well against wind currents, and when landing, you need sufficient force to drag it to a full stop.&lt;/p&gt;&lt;p dir="ltr"&gt;Niklas Hagemann, an MIT graduate student in architecture and CSAIL affiliate, notes that this ratio is just as useful if you want a similar gliding motion in the ocean.&lt;/p&gt;&lt;p&gt;“Our pipeline modifies glider shapes to find the best lift-to-drag ratio, optimizing its performance underwater,” says Hagemann, who is also a co-lead author on a&amp;nbsp;paper that was presented at the International Conference on Robotics and Automation in June. “You can then export the top-performing designs so they can be 3D-printed.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Going for a quick glide&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;While their AI pipeline seemed realistic, the researchers needed to ensure its predictions about glider performance were accurate by experimenting in more lifelike environments.&lt;/p&gt;&lt;p dir="ltr"&gt;They first fabricated their two-wing design as a scaled-down vehicle resembling a paper airplane. This glider was taken to MIT’s Wright Brothers Wind Tunnel, an indoor space with fans that simulate wind flow. Placed at different angles, the glider’s predicted lift-to-drag ratio was only about 5 percent higher on average than the ones recorded in the wind experiments — a small difference between simulation and reality.&lt;/p&gt;&lt;p&gt;A digital evaluation involving a visual, more complex physics simulator also supported the notion that the AI pipeline made fairly accurate predictions about how the gliders would move. It visualized how these machines would descend in 3D.&lt;/p&gt;&lt;p&gt;To truly evaluate these gliders in the real world, though, the team needed to see how their devices would fare underwater. They printed two designs that performed the best at specific points-of-attack for this test: a jet-like device at 9 degrees and the four-wing vehicle at 30 degrees.&lt;/p&gt;&lt;p dir="ltr"&gt;Both shapes were fabricated in a 3D printer as hollow shells with small holes that flood when fully submerged. This lightweight design makes the vehicle easier to handle outside of the water and requires less material to be fabricated. The researchers placed a tube-like device inside these shell coverings, which housed a range of hardware, including a pump to change the glider’s buoyancy, a mass shifter (a device that controls the machine’s angle-of-attack), and electronic components.&lt;/p&gt;&lt;p&gt;Each design outperformed a handmade torpedo-shaped glider by moving more efficiently across a pool. With higher lift-to-drag ratios than their counterpart, both AI-driven machines exerted less energy, similar to the effortless ways marine animals navigate the oceans.&lt;/p&gt;&lt;p&gt;As much as the project is an encouraging step forward for glider design, the researchers are looking to narrow the gap between simulation and real-world performance. They are also hoping to develop machines that can react to sudden changes in currents, making the gliders more adaptable to seas and oceans.&lt;/p&gt;&lt;p&gt;Chen adds that the team is looking to explore new types of shapes, particularly thinner glider designs. They intend to make their framework faster, perhaps bolstering it with new features that enable more customization, maneuverability, or even the creation of miniature vehicles.&lt;/p&gt;&lt;p&gt;Chen and Hagemann co-led research on this project with OpenAI researcher Pingchuan Ma SM ’23, PhD ’25. They authored the paper with Wei Wang, a University of Wisconsin at Madison assistant professor and recent CSAIL postdoc; John Romanishin ’12, SM ’18, PhD ’23; and two MIT professors and CSAIL members: lab director Daniela Rus and senior author Wojciech Matusik. Their work was supported, in part, by a Defense Advanced Research Projects Agency (DARPA) grant and the MIT-GIST Program.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/ai-shapes-autonomous-underwater-gliders-0709</guid><pubDate>Wed, 09 Jul 2025 20:35:00 +0000</pubDate></item><item><title>Changing the conversation in health care (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/changing-conversation-health-care-0709</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-language-ai-incubator.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Generative artificial intelligence is transforming the ways humans write, read, speak, think, empathize, and act within and across languages and cultures. In health care, gaps in communication between patients and practitioners can worsen patient outcomes and prevent improvements in practice and care. The Language/AI Incubator, made possible through funding from the&amp;nbsp;MIT Human Insight Collaborative (MITHIC), offers a potential response to these challenges.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The project envisions a research community rooted in the humanities that will foster interdisciplinary collaboration across MIT to deepen understanding of generative AI’s impact on cross-linguistic and cross-cultural communication. The project’s focus on health care and communication seeks to build bridges across socioeconomic, cultural, and linguistic strata.&lt;/p&gt;&lt;p dir="ltr"&gt;The incubator is co-led by&amp;nbsp;Leo Celi, a physician and the research director and senior research scientist with the&amp;nbsp;Institute for Medical Engineering and Science (IMES), and&amp;nbsp;Per Urlaub, professor of the practice in German and second language studies and director of MIT’s&amp;nbsp;Global Languages program.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“The basis of health care delivery is the knowledge of health and disease,” Celi says. “We’re seeing poor outcomes despite massive investments because our knowledge system is broken.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A chance collaboration&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Urlaub and Celi met during a MITHIC launch event. Conversations during the event reception revealed a shared interest in exploring improvements in medical communication and practice with AI.&lt;/p&gt;&lt;p dir="ltr"&gt;“We’re trying to incorporate data science into health-care delivery,” Celi says. “We’ve been recruiting social scientists [at IMES] to help advance our work, because the science we create isn’t neutral.”&lt;/p&gt;&lt;p dir="ltr"&gt;Language is a non-neutral mediator in health care delivery, the team believes, and can be a boon or barrier to effective treatment. “Later, after we met, I joined one of his working groups whose focus was metaphors for pain: the language we use to describe it and its measurement,” Urlaub continues. “One of the questions we considered was how effective communication can occur between doctors and patients.”&lt;/p&gt;&lt;p dir="ltr"&gt;Technology, they argue, impacts casual communication, and its impact depends on both users and creators. As AI and large language models (LLMs) gain power and prominence, their use is broadening to include fields like health care and wellness.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Rodrigo Gameiro, a physician and researcher with MIT’s Laboratory for Computational Physiology, is another program participant. He notes that work at the laboratory centers responsible AI development and implementation. Designing systems that leverage AI effectively, particularly when considering challenges related to communicating across linguistic and cultural divides that can occur in health care, demands a nuanced approach.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“When we build AI systems that interact with human language, we’re not just teaching machines how to process words; we’re teaching them to navigate the complex web of meaning embedded in language,” Gameiro says.&lt;/p&gt;&lt;p dir="ltr"&gt;Language’s complexities can impact treatment and patient care. “Pain can only be communicated through metaphor,” Urlaub continues, “but metaphors don’t always match, linguistically and culturally.” Smiley faces and one-to-10 scales — pain measurement tools English-speaking medical professionals may use to assess their patients — may not travel well across racial, ethnic, cultural, and language boundaries.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“Science has to have a heart”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;LLMs can potentially help scientists improve health care, although there are some systemic and pedagogical challenges to consider. Science can focus on outcomes to the exclusion of the people it’s meant to help, Celi argues. “Science has to have a heart,” he says. “Measuring students’ effectiveness by counting the number of papers they publish or patents they produce misses the point.”&lt;/p&gt;&lt;p dir="ltr"&gt;The point, Urlaub says, is to investigate carefully while simultaneously acknowledging what we don’t know, citing what philosophers call Epistemic Humility. Knowledge, the investigators argue, is provisional, and always incomplete. Deeply held beliefs may require revision in light of new evidence.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“No one’s mental view of the world is complete,” Celi says. “You need to create an environment in which people are comfortable acknowledging their biases.”&lt;/p&gt;&lt;p dir="ltr"&gt;“How do we share concerns between language educators and others interested in AI?” Urlaub asks. “How do we identify and investigate the relationship between medical professionals and language educators interested in AI’s potential to aid in the elimination of gaps in communication between doctors and patients?”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Language, in Gameiro’s estimation, is more than just a tool for communication. “It reflects culture, identity, and power dynamics,” he says. In situations where a patient might not be comfortable describing pain or discomfort because of the physician’s position as an authority, or because their culture demands yielding to those perceived as authority figures, misunderstandings can be dangerous.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Changing the conversation&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;AI’s facility with language can help medical professionals navigate these areas more carefully, providing digital frameworks offering valuable cultural and linguistic contexts in which patient and practitioner can rely on data-driven, research-supported tools to improve dialogue. Institutions need to reconsider how they educate medical professionals and invite the communities they serve into the conversation, the team says.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‘We need to ask ourselves what we truly want,” Celi says. “Why are we measuring what we’re measuring?” The biases we bring with us to these interactions — doctors, patients, their families, and their communities — remain barriers to improved care, Urlaub and Gameiro say.&lt;/p&gt;&lt;p dir="ltr"&gt;“We want to connect people who think differently, and make AI work for everyone,” Gameiro continues. “Technology without purpose is just exclusion at scale.”&lt;/p&gt;&lt;p dir="ltr"&gt;“Collaborations like these can allow for deep processing and better ideas,” Urlaub says.&lt;/p&gt;&lt;p dir="ltr"&gt;Creating spaces where ideas about AI and health care can potentially become actions is a key element of the project. The Language/AI Incubator hosted its first colloquium at MIT in May, which was led by Mena Ramos, a physician and the co-founder and CEO of the&amp;nbsp;Global Ultrasound Institute.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The colloquium also featured presentations from Celi, as well as Alfred Spector, a visiting scholar in MIT’s&amp;nbsp;Department of Electrical Engineering and Computer Science, and Douglas Jones, a senior staff member in the MIT Lincoln Laboratory’s Human Language Technology Group. A second Language/AI Incubator colloquium is planned for August.&lt;/p&gt;&lt;p dir="ltr"&gt;Greater integration between the social and hard sciences can potentially increase the likelihood of developing viable solutions and reducing biases. Allowing for shifts in the ways patients and doctors view the relationship, while offering each shared ownership of the interaction, can help improve outcomes. Facilitating these conversations with AI may speed the integration of these perspectives.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“Community advocates have a voice and should be included in these conversations,” Celi says. “AI and statistical modeling can’t collect all the data needed to treat all the people who need it.”&lt;/p&gt;&lt;p dir="ltr"&gt;Community needs and improved educational opportunities and practices should be coupled with cross-disciplinary approaches to knowledge acquisition and transfer. The ways people see things are limited by their perceptions and other factors. “Whose language are we modeling?” Gameiro asks about building LLMs. “Which varieties of speech are being included or excluded?” Since meaning and intent can shift across those contexts, it’s important to remember these when designing AI tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“AI is our chance to rewrite the rules”&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;While there’s lots of potential in the collaboration, there are serious challenges to overcome, including establishing and scaling the technological means to improve patient-provider communication with AI, extending opportunities for collaboration to marginalized and underserved communities, and reconsidering and revamping patient care.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;But the team isn’t daunted.&lt;/p&gt;&lt;p dir="ltr"&gt;Celi believes there are opportunities to address the widening gap between people and practitioners while addressing gaps in health care. “Our intent is to reattach the string that’s been cut between society and science,” he says. “We can empower scientists and the public to investigate the world together while also acknowledging the limitations engendered in overcoming their biases.”&lt;/p&gt;&lt;p dir="ltr"&gt;Gameiro is a passionate advocate for AI’s ability to change everything we know about medicine. “I’m a medical doctor, and I don’t think I’m being hyperbolic when I say I believe AI is our chance to rewrite the rules of what medicine can do and who we can reach,” he says.&lt;/p&gt;&lt;p dir="ltr"&gt;“Education changes humans from objects to subjects,” Urlaub argues, describing the difference between disinterested observers and active and engaged participants in the new care model he hopes to build. “We need to better understand technology’s impact on the lines between these states of being.”&lt;/p&gt;&lt;p dir="ltr"&gt;Celi, Gameiro, and Urlaub each advocate for MITHIC-like spaces across health care, places where innovation and collaboration are allowed to occur without the kinds of arbitrary benchmarks institutions have previously used to mark success.&lt;/p&gt;&lt;p dir="ltr"&gt;“AI will transform all these sectors,” Urlaub believes. “MITHIC is a generous framework that allows us to embrace uncertainty with flexibility.”&lt;/p&gt;&lt;p dir="ltr"&gt;“We want to employ our power to build community among disparate audiences while admitting we don’t have all the answers,” Celi says. “If we fail, it’s because we failed to dream big enough about how a reimagined world could look.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202506/mit-language-ai-incubator.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Generative artificial intelligence is transforming the ways humans write, read, speak, think, empathize, and act within and across languages and cultures. In health care, gaps in communication between patients and practitioners can worsen patient outcomes and prevent improvements in practice and care. The Language/AI Incubator, made possible through funding from the&amp;nbsp;MIT Human Insight Collaborative (MITHIC), offers a potential response to these challenges.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The project envisions a research community rooted in the humanities that will foster interdisciplinary collaboration across MIT to deepen understanding of generative AI’s impact on cross-linguistic and cross-cultural communication. The project’s focus on health care and communication seeks to build bridges across socioeconomic, cultural, and linguistic strata.&lt;/p&gt;&lt;p dir="ltr"&gt;The incubator is co-led by&amp;nbsp;Leo Celi, a physician and the research director and senior research scientist with the&amp;nbsp;Institute for Medical Engineering and Science (IMES), and&amp;nbsp;Per Urlaub, professor of the practice in German and second language studies and director of MIT’s&amp;nbsp;Global Languages program.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“The basis of health care delivery is the knowledge of health and disease,” Celi says. “We’re seeing poor outcomes despite massive investments because our knowledge system is broken.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A chance collaboration&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;Urlaub and Celi met during a MITHIC launch event. Conversations during the event reception revealed a shared interest in exploring improvements in medical communication and practice with AI.&lt;/p&gt;&lt;p dir="ltr"&gt;“We’re trying to incorporate data science into health-care delivery,” Celi says. “We’ve been recruiting social scientists [at IMES] to help advance our work, because the science we create isn’t neutral.”&lt;/p&gt;&lt;p dir="ltr"&gt;Language is a non-neutral mediator in health care delivery, the team believes, and can be a boon or barrier to effective treatment. “Later, after we met, I joined one of his working groups whose focus was metaphors for pain: the language we use to describe it and its measurement,” Urlaub continues. “One of the questions we considered was how effective communication can occur between doctors and patients.”&lt;/p&gt;&lt;p dir="ltr"&gt;Technology, they argue, impacts casual communication, and its impact depends on both users and creators. As AI and large language models (LLMs) gain power and prominence, their use is broadening to include fields like health care and wellness.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Rodrigo Gameiro, a physician and researcher with MIT’s Laboratory for Computational Physiology, is another program participant. He notes that work at the laboratory centers responsible AI development and implementation. Designing systems that leverage AI effectively, particularly when considering challenges related to communicating across linguistic and cultural divides that can occur in health care, demands a nuanced approach.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“When we build AI systems that interact with human language, we’re not just teaching machines how to process words; we’re teaching them to navigate the complex web of meaning embedded in language,” Gameiro says.&lt;/p&gt;&lt;p dir="ltr"&gt;Language’s complexities can impact treatment and patient care. “Pain can only be communicated through metaphor,” Urlaub continues, “but metaphors don’t always match, linguistically and culturally.” Smiley faces and one-to-10 scales — pain measurement tools English-speaking medical professionals may use to assess their patients — may not travel well across racial, ethnic, cultural, and language boundaries.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“Science has to have a heart”&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;LLMs can potentially help scientists improve health care, although there are some systemic and pedagogical challenges to consider. Science can focus on outcomes to the exclusion of the people it’s meant to help, Celi argues. “Science has to have a heart,” he says. “Measuring students’ effectiveness by counting the number of papers they publish or patents they produce misses the point.”&lt;/p&gt;&lt;p dir="ltr"&gt;The point, Urlaub says, is to investigate carefully while simultaneously acknowledging what we don’t know, citing what philosophers call Epistemic Humility. Knowledge, the investigators argue, is provisional, and always incomplete. Deeply held beliefs may require revision in light of new evidence.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“No one’s mental view of the world is complete,” Celi says. “You need to create an environment in which people are comfortable acknowledging their biases.”&lt;/p&gt;&lt;p dir="ltr"&gt;“How do we share concerns between language educators and others interested in AI?” Urlaub asks. “How do we identify and investigate the relationship between medical professionals and language educators interested in AI’s potential to aid in the elimination of gaps in communication between doctors and patients?”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;Language, in Gameiro’s estimation, is more than just a tool for communication. “It reflects culture, identity, and power dynamics,” he says. In situations where a patient might not be comfortable describing pain or discomfort because of the physician’s position as an authority, or because their culture demands yielding to those perceived as authority figures, misunderstandings can be dangerous.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Changing the conversation&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;AI’s facility with language can help medical professionals navigate these areas more carefully, providing digital frameworks offering valuable cultural and linguistic contexts in which patient and practitioner can rely on data-driven, research-supported tools to improve dialogue. Institutions need to reconsider how they educate medical professionals and invite the communities they serve into the conversation, the team says.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;‘We need to ask ourselves what we truly want,” Celi says. “Why are we measuring what we’re measuring?” The biases we bring with us to these interactions — doctors, patients, their families, and their communities — remain barriers to improved care, Urlaub and Gameiro say.&lt;/p&gt;&lt;p dir="ltr"&gt;“We want to connect people who think differently, and make AI work for everyone,” Gameiro continues. “Technology without purpose is just exclusion at scale.”&lt;/p&gt;&lt;p dir="ltr"&gt;“Collaborations like these can allow for deep processing and better ideas,” Urlaub says.&lt;/p&gt;&lt;p dir="ltr"&gt;Creating spaces where ideas about AI and health care can potentially become actions is a key element of the project. The Language/AI Incubator hosted its first colloquium at MIT in May, which was led by Mena Ramos, a physician and the co-founder and CEO of the&amp;nbsp;Global Ultrasound Institute.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;The colloquium also featured presentations from Celi, as well as Alfred Spector, a visiting scholar in MIT’s&amp;nbsp;Department of Electrical Engineering and Computer Science, and Douglas Jones, a senior staff member in the MIT Lincoln Laboratory’s Human Language Technology Group. A second Language/AI Incubator colloquium is planned for August.&lt;/p&gt;&lt;p dir="ltr"&gt;Greater integration between the social and hard sciences can potentially increase the likelihood of developing viable solutions and reducing biases. Allowing for shifts in the ways patients and doctors view the relationship, while offering each shared ownership of the interaction, can help improve outcomes. Facilitating these conversations with AI may speed the integration of these perspectives.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“Community advocates have a voice and should be included in these conversations,” Celi says. “AI and statistical modeling can’t collect all the data needed to treat all the people who need it.”&lt;/p&gt;&lt;p dir="ltr"&gt;Community needs and improved educational opportunities and practices should be coupled with cross-disciplinary approaches to knowledge acquisition and transfer. The ways people see things are limited by their perceptions and other factors. “Whose language are we modeling?” Gameiro asks about building LLMs. “Which varieties of speech are being included or excluded?” Since meaning and intent can shift across those contexts, it’s important to remember these when designing AI tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;“AI is our chance to rewrite the rules”&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;While there’s lots of potential in the collaboration, there are serious challenges to overcome, including establishing and scaling the technological means to improve patient-provider communication with AI, extending opportunities for collaboration to marginalized and underserved communities, and reconsidering and revamping patient care.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;But the team isn’t daunted.&lt;/p&gt;&lt;p dir="ltr"&gt;Celi believes there are opportunities to address the widening gap between people and practitioners while addressing gaps in health care. “Our intent is to reattach the string that’s been cut between society and science,” he says. “We can empower scientists and the public to investigate the world together while also acknowledging the limitations engendered in overcoming their biases.”&lt;/p&gt;&lt;p dir="ltr"&gt;Gameiro is a passionate advocate for AI’s ability to change everything we know about medicine. “I’m a medical doctor, and I don’t think I’m being hyperbolic when I say I believe AI is our chance to rewrite the rules of what medicine can do and who we can reach,” he says.&lt;/p&gt;&lt;p dir="ltr"&gt;“Education changes humans from objects to subjects,” Urlaub argues, describing the difference between disinterested observers and active and engaged participants in the new care model he hopes to build. “We need to better understand technology’s impact on the lines between these states of being.”&lt;/p&gt;&lt;p dir="ltr"&gt;Celi, Gameiro, and Urlaub each advocate for MITHIC-like spaces across health care, places where innovation and collaboration are allowed to occur without the kinds of arbitrary benchmarks institutions have previously used to mark success.&lt;/p&gt;&lt;p dir="ltr"&gt;“AI will transform all these sectors,” Urlaub believes. “MITHIC is a generous framework that allows us to embrace uncertainty with flexibility.”&lt;/p&gt;&lt;p dir="ltr"&gt;“We want to employ our power to build community among disparate audiences while admitting we don’t have all the answers,” Celi says. “If we fail, it’s because we failed to dream big enough about how a reimagined world could look.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/changing-conversation-health-care-0709</guid><pubDate>Wed, 09 Jul 2025 20:50:00 +0000</pubDate></item><item><title>California lawmaker behind SB 1047 reignites push for mandated AI safety reports (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/california-lawmaker-behind-sb-1047-reignites-push-for-mandated-ai-safety-reports/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-950173010.jpg?resize=1200,861" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California State Senator Scott Wiener on Wednesday introduced new amendments to his latest bill, SB 53, that would require the world’s largest AI companies to publish safety and security protocols and issue reports when safety incidents occur.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If signed into law, California would be the first state to impose meaningful transparency requirements onto leading AI developers, likely including OpenAI, Google, Anthropic, and xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Senator Wiener’s previous AI bill, SB 1047, included similar requirements for AI model developers to publish safety reports. However, Silicon Valley fought ferociously against that bill, and it was ultimately vetoed by Governor Gavin Newsom. California’s governor then called for a group of AI leaders — including the leading Stanford researcher and co-founder of World Labs, Fei-Fei Li — to form a policy group and set goals for the state’s AI safety efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;California’s AI policy group recently published their final recommendations, citing a need for “requirements on industry to publish information about their systems” in order to establish a “robust and transparent evidence environment.” Senator Wiener’s office said in a press release that SB 53’s amendments were heavily influenced by this report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The bill continues to be a work in progress, and I look forward to working with all stakeholders in the coming weeks to refine this proposal into the most scientific and fair law it can be,” Senator Wiener said in the release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 aims to strike a balance that Governor Newsom claimed SB 1047 failed to achieve — ideally, creating meaningful transparency requirements for the largest AI developers without thwarting the rapid growth of California’s AI industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These are concerns that my organization and others have been talking about for a while,” said Nathan Calvin, VP of State Affairs for the nonprofit AI safety group, Encode, in an interview with TechCrunch. “Having companies explain to the public and government what measures they’re taking to address these risks feels like a bare minimum, reasonable step to take.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The bill also creates whistleblower protections for employees of AI labs who believe their company’s technology poses a “critical risk” to society — defined in the bill as contributing to the death or injury of more than 100 people, or more than $1 billion in damage. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the bill aims to create CalCompute, a public cloud computing cluster to support startups and researchers developing large-scale AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike SB 1047, Senator Wiener’s new bill does not make AI model developers liable for the harms of their AI models. SB 53 was also designed not to pose a burden on startups and researchers that fine-tune AI models from leading AI developers, or use open source models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new amendments, SB 53 is now headed to the California State Assembly Committee on Privacy and Consumer Protection for approval. Should it pass there, the bill will also need to pass through several other legislative bodies before reaching Governor Newsom’s desk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the other side of the U.S., New York Governor Kathy Hochul is now considering a similar AI safety bill, the RAISE Act, which would also require large AI developers to publish safety and security reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fate of state AI laws like the RAISE Act and SB 53 were briefly in jeopardy as federal lawmakers considered a 10-year AI moratorium on state AI regulation — an attempt to limit a “patchwork” of AI laws that companies would have to navigate. However, that proposal failed in a 99-1 Senate vote earlier in July.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ensuring AI is developed safely should not be controversial — it should be foundational,” said Geoff Ralston, the former president of Y Combinator, in a statement to TechCrunch. “Congress should be leading, demanding transparency and accountability from the companies building frontier models. But with no serious federal action in sight, states must step up. California’s SB 53 is a thoughtful, well-structured example of state leadership.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up to this point, lawmakers have failed to get AI companies on board with state-mandated transparency requirements. Anthropic has broadly endorsed the need for increased transparency into AI companies, and even expressed modest optimism about the recommendations from California’s AI policy group. But companies such as OpenAI, Google, and Meta have been more resistant to these efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading AI model developers typically publish safety reports for their AI models, but they’ve been less consistent in recent months. Google, for example, decided not to publish a safety report for its most advanced AI model ever released, Gemini 2.5 Pro, until months after it was made available. OpenAI also decided not to publish a safety report for its GPT-4.1 model. Later, a third-party study came out that suggested it may be less aligned than previous AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 represents a toned-down version of previous AI safety bills, but it still could force AI companies to publish more information than they do today. For now, they’ll be watching closely as Senator Wiener once again tests those boundaries.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-950173010.jpg?resize=1200,861" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California State Senator Scott Wiener on Wednesday introduced new amendments to his latest bill, SB 53, that would require the world’s largest AI companies to publish safety and security protocols and issue reports when safety incidents occur.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If signed into law, California would be the first state to impose meaningful transparency requirements onto leading AI developers, likely including OpenAI, Google, Anthropic, and xAI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Senator Wiener’s previous AI bill, SB 1047, included similar requirements for AI model developers to publish safety reports. However, Silicon Valley fought ferociously against that bill, and it was ultimately vetoed by Governor Gavin Newsom. California’s governor then called for a group of AI leaders — including the leading Stanford researcher and co-founder of World Labs, Fei-Fei Li — to form a policy group and set goals for the state’s AI safety efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;California’s AI policy group recently published their final recommendations, citing a need for “requirements on industry to publish information about their systems” in order to establish a “robust and transparent evidence environment.” Senator Wiener’s office said in a press release that SB 53’s amendments were heavily influenced by this report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The bill continues to be a work in progress, and I look forward to working with all stakeholders in the coming weeks to refine this proposal into the most scientific and fair law it can be,” Senator Wiener said in the release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 aims to strike a balance that Governor Newsom claimed SB 1047 failed to achieve — ideally, creating meaningful transparency requirements for the largest AI developers without thwarting the rapid growth of California’s AI industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These are concerns that my organization and others have been talking about for a while,” said Nathan Calvin, VP of State Affairs for the nonprofit AI safety group, Encode, in an interview with TechCrunch. “Having companies explain to the public and government what measures they’re taking to address these risks feels like a bare minimum, reasonable step to take.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The bill also creates whistleblower protections for employees of AI labs who believe their company’s technology poses a “critical risk” to society — defined in the bill as contributing to the death or injury of more than 100 people, or more than $1 billion in damage. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the bill aims to create CalCompute, a public cloud computing cluster to support startups and researchers developing large-scale AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike SB 1047, Senator Wiener’s new bill does not make AI model developers liable for the harms of their AI models. SB 53 was also designed not to pose a burden on startups and researchers that fine-tune AI models from leading AI developers, or use open source models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With the new amendments, SB 53 is now headed to the California State Assembly Committee on Privacy and Consumer Protection for approval. Should it pass there, the bill will also need to pass through several other legislative bodies before reaching Governor Newsom’s desk.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the other side of the U.S., New York Governor Kathy Hochul is now considering a similar AI safety bill, the RAISE Act, which would also require large AI developers to publish safety and security reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fate of state AI laws like the RAISE Act and SB 53 were briefly in jeopardy as federal lawmakers considered a 10-year AI moratorium on state AI regulation — an attempt to limit a “patchwork” of AI laws that companies would have to navigate. However, that proposal failed in a 99-1 Senate vote earlier in July.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ensuring AI is developed safely should not be controversial — it should be foundational,” said Geoff Ralston, the former president of Y Combinator, in a statement to TechCrunch. “Congress should be leading, demanding transparency and accountability from the companies building frontier models. But with no serious federal action in sight, states must step up. California’s SB 53 is a thoughtful, well-structured example of state leadership.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up to this point, lawmakers have failed to get AI companies on board with state-mandated transparency requirements. Anthropic has broadly endorsed the need for increased transparency into AI companies, and even expressed modest optimism about the recommendations from California’s AI policy group. But companies such as OpenAI, Google, and Meta have been more resistant to these efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading AI model developers typically publish safety reports for their AI models, but they’ve been less consistent in recent months. Google, for example, decided not to publish a safety report for its most advanced AI model ever released, Gemini 2.5 Pro, until months after it was made available. OpenAI also decided not to publish a safety report for its GPT-4.1 model. Later, a third-party study came out that suggested it may be less aligned than previous AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SB 53 represents a toned-down version of previous AI safety bills, but it still could force AI companies to publish more information than they do today. For now, they’ll be watching closely as Senator Wiener once again tests those boundaries.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/california-lawmaker-behind-sb-1047-reignites-push-for-mandated-ai-safety-reports/</guid><pubDate>Wed, 09 Jul 2025 20:54:30 +0000</pubDate></item><item><title>Cloudflare wants Google to change its AI search crawling. Google likely won’t. (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/cloudflare-wants-google-to-change-its-ai-search-crawling-google-likely-wont/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cloudflare pushes Google to separate bots for AI Overviews and search indexing.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After Cloudflare started testing new features that would allow websites to block AI crawlers or require payment for scraping, the tech company immediately faced questions over the logistics of the plan.&lt;/p&gt;
&lt;p&gt;In particular, website owners and SEO experts wanted to know how Cloudflare planned to block Google's bot from scraping sites to fuel AI overviews without risking blocking the same bot from crawling for valuable search engine placements.&lt;/p&gt;
&lt;p&gt;Last week, a travel blogger raised questions about the blocking and so-called pay-per-crawl features pushed Cloudflare CEO Matthew Prince to respond on X (formerly Twitter).&lt;/p&gt;
&lt;p&gt;"We will get Google to provide ways to block Answer Box and AI Overview, without blocking classic search indexing, as well," Prince said. Asked if that was even possible, Prince doubled down, responding, "it is. #staytuned"&lt;/p&gt;
&lt;p&gt;In another post responding to a search engine optimization specialist, he claimed that Cloudflare was in "encouraging" talks with Google that he hopes will result in Google separating its crawlers to better work in Cloudflare's system. But if those talks go nowhere, he revealed Cloudflare is pushing for a law to be passed that's considered a "very viable option" in "many jurisdictions."&lt;/p&gt;
&lt;p&gt;"Worst case we’ll pass a law somewhere that requires them to break out their crawlers and then announce all routes to their crawlers from there," Prince said. "And that wouldn’t be hard. But I’m hopeful it won’t need to come to that."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ars could not immediately find any legislation that seemed to match Prince's description, and Cloudflare did not respond to Ars' request to comment. Passing tech laws is notoriously hard, though, partly because technology keeps advancing as policy debates drag on, and challenges with regulating artificial intelligence are an obvious example of that pattern today.&lt;/p&gt;
&lt;p&gt;Google declined Ars' request to confirm whether talks were underway or if the company was open to separating its crawlers.&lt;/p&gt;
&lt;p&gt;Although Cloudflare singled out Google, other search engines that view AI search features as part of their search products also use the same bots for training as they do for search indexing. It seems likely that Cloudflare's proposed legislation would face resistance from tech companies in a similar position to Google, as The Wall Street Journal reported that the tech companies "have few incentives to work with intermediaries."&lt;/p&gt;
&lt;p&gt;Additionally, Cloudflare's initiative faces criticism from those who "worry that academic research, security scans, and other types of benign web crawling will get elbowed out of websites as barriers are built around more sites" through Cloudflare's blocks and paywalls, the WSJ reported. Cloudflare's system could also threaten web projects like The Internet Archive, which notably played a crucial role in helping track data deleted from government websites after Donald Trump took office.&lt;/p&gt;
&lt;p&gt;Among commenters discussing Cloudflare's claims about Google on Search Engine Round Table, one user suggested Cloudflare may risk a lawsuit or other penalties from Google for poking the bear.&lt;/p&gt;
&lt;p&gt;Ars will continue monitoring for updates on Cloudflare's attempts to get Google on board with its plan.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Cloudflare pushes Google to separate bots for AI Overviews and search indexing.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-1186369127-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Sundry Photography | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;After Cloudflare started testing new features that would allow websites to block AI crawlers or require payment for scraping, the tech company immediately faced questions over the logistics of the plan.&lt;/p&gt;
&lt;p&gt;In particular, website owners and SEO experts wanted to know how Cloudflare planned to block Google's bot from scraping sites to fuel AI overviews without risking blocking the same bot from crawling for valuable search engine placements.&lt;/p&gt;
&lt;p&gt;Last week, a travel blogger raised questions about the blocking and so-called pay-per-crawl features pushed Cloudflare CEO Matthew Prince to respond on X (formerly Twitter).&lt;/p&gt;
&lt;p&gt;"We will get Google to provide ways to block Answer Box and AI Overview, without blocking classic search indexing, as well," Prince said. Asked if that was even possible, Prince doubled down, responding, "it is. #staytuned"&lt;/p&gt;
&lt;p&gt;In another post responding to a search engine optimization specialist, he claimed that Cloudflare was in "encouraging" talks with Google that he hopes will result in Google separating its crawlers to better work in Cloudflare's system. But if those talks go nowhere, he revealed Cloudflare is pushing for a law to be passed that's considered a "very viable option" in "many jurisdictions."&lt;/p&gt;
&lt;p&gt;"Worst case we’ll pass a law somewhere that requires them to break out their crawlers and then announce all routes to their crawlers from there," Prince said. "And that wouldn’t be hard. But I’m hopeful it won’t need to come to that."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ars could not immediately find any legislation that seemed to match Prince's description, and Cloudflare did not respond to Ars' request to comment. Passing tech laws is notoriously hard, though, partly because technology keeps advancing as policy debates drag on, and challenges with regulating artificial intelligence are an obvious example of that pattern today.&lt;/p&gt;
&lt;p&gt;Google declined Ars' request to confirm whether talks were underway or if the company was open to separating its crawlers.&lt;/p&gt;
&lt;p&gt;Although Cloudflare singled out Google, other search engines that view AI search features as part of their search products also use the same bots for training as they do for search indexing. It seems likely that Cloudflare's proposed legislation would face resistance from tech companies in a similar position to Google, as The Wall Street Journal reported that the tech companies "have few incentives to work with intermediaries."&lt;/p&gt;
&lt;p&gt;Additionally, Cloudflare's initiative faces criticism from those who "worry that academic research, security scans, and other types of benign web crawling will get elbowed out of websites as barriers are built around more sites" through Cloudflare's blocks and paywalls, the WSJ reported. Cloudflare's system could also threaten web projects like The Internet Archive, which notably played a crucial role in helping track data deleted from government websites after Donald Trump took office.&lt;/p&gt;
&lt;p&gt;Among commenters discussing Cloudflare's claims about Google on Search Engine Round Table, one user suggested Cloudflare may risk a lawsuit or other penalties from Google for poking the bear.&lt;/p&gt;
&lt;p&gt;Ars will continue monitoring for updates on Cloudflare's attempts to get Google on board with its plan.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/cloudflare-wants-google-to-change-its-ai-search-crawling-google-likely-wont/</guid><pubDate>Wed, 09 Jul 2025 21:00:00 +0000</pubDate></item><item><title>ChatGPT made up a product feature out of thin air, so this company created it (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/chatgpt-made-up-a-product-feature-out-of-thin-air-so-this-company-created-it/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Soundslice caught OpenAI's bot telling users about a fake music notation feature—then built it.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, sheet music platform Soundslice says it developed a new feature after discovering that ChatGPT was incorrectly telling users the service could import ASCII tablature—a text-based guitar notation format the company had never supported. The incident reportedly marks what might be the first case of a business building functionality in direct response to an AI model's confabulation.&lt;/p&gt;
&lt;p&gt;Typically, Soundslice digitizes sheet music from photos or PDFs and syncs the notation with audio or video recordings, allowing musicians to see the music scroll by as they hear it played. The platform also includes tools for slowing down playback and practicing difficult passages.&lt;/p&gt;
&lt;p&gt;Adrian Holovaty, co-founder of Soundslice, wrote in a recent blog post that the recent feature development process began as a complete mystery. A few months ago, Holovaty began noticing unusual&amp;nbsp;activity in the company's error logs. Instead of typical sheet music uploads, users were submitting screenshots of ChatGPT conversations containing ASCII tablature—simple text representations of guitar music that look like strings with numbers indicating fret positions.&lt;/p&gt;
&lt;p&gt;"Our scanning system wasn't intended to support this style of notation," wrote Holovaty in the blog post. "Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks—until I messed around with ChatGPT myself."&lt;/p&gt;
&lt;p&gt;When Holovaty tested ChatGPT, he discovered the source of the confusion: The AI model was instructing users to create Soundslice accounts and use the platform to import ASCII tabs for audio playback—a feature that didn't exist. "We've never supported ASCII tab; ChatGPT was outright lying to people," Holovaty wrote. "And making us look bad in the process, setting false expectations about our service."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105045 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of Soundslice's new ASCII tab importer documentation." class="center large" height="723" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-1024x723.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of Soundslice's new ASCII tab importer documentation, hallucinated by ChatGPT and made real later.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          https://www.soundslice.com/help/en/creating/importing/331/ascii-tab/

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;When AI models like ChatGPT generate false information with apparent confidence, AI researchers call it a "hallucination" or&amp;nbsp; "confabulation." The problem of AI models confabulating false information has plagued AI models since ChatGPT's public release in November 2022, when people began erroneously using the chatbot as a replacement for a search engine.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As prediction machines, large language models trained on massive text datasets can easily produce outputs that seem plausible but are completely inaccurate. The models statistically improvise to fill "knowledge" gaps on topics poorly represented in their training data, generating text based on statistical patterns rather than factual accuracy. In this way, ChatGPT told its users what they wanted to hear by making up a Soundslice feature that made sense but didn't exist.&lt;/p&gt;
&lt;p&gt;Usually, confabulations get people in trouble. In one notable case from 2023, lawyers faced sanctions after submitting legal briefs containing ChatGPT-generated citations to non-existent court cases. In February 2024, Canada's Civil Resolution Tribunal ordered Air Canada to pay damages to a customer and honor a bereavement fare policy that was hallucinated by a support chatbot, which incorrectly stated that customers could retroactively request a bereavement discount within 90 days of the date the ticket was issued.&lt;/p&gt;
&lt;h2&gt;From bug to feature&lt;/h2&gt;
&lt;p&gt;The discovery presented Soundslice with an unusual dilemma. The company could have posted disclaimers warning users to ignore ChatGPT's claims, but instead chose a different path. "We ended up deciding: what the heck, we might as well meet the market demand," Holovaty explained. The team built an ASCII tab importer—a feature that had been "near the bottom of my 'Software I expected to write in 2025' list"—and updated their user interface to inform users about the new capability.&lt;/p&gt;
&lt;p&gt;Soundslice's solution presents an interesting case of making lemonade from lemons, but for Holovaty, the situation raises philosophical questions about product development. "My feelings on this are conflicted," he wrote. "I'm happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?"&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Soundslice caught OpenAI's bot telling users about a fake music notation feature—then built it.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Orchestra conductor watching AI robot conduct music notes on beige background - stock illustration" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/surprise_music_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Malte Mueller via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, sheet music platform Soundslice says it developed a new feature after discovering that ChatGPT was incorrectly telling users the service could import ASCII tablature—a text-based guitar notation format the company had never supported. The incident reportedly marks what might be the first case of a business building functionality in direct response to an AI model's confabulation.&lt;/p&gt;
&lt;p&gt;Typically, Soundslice digitizes sheet music from photos or PDFs and syncs the notation with audio or video recordings, allowing musicians to see the music scroll by as they hear it played. The platform also includes tools for slowing down playback and practicing difficult passages.&lt;/p&gt;
&lt;p&gt;Adrian Holovaty, co-founder of Soundslice, wrote in a recent blog post that the recent feature development process began as a complete mystery. A few months ago, Holovaty began noticing unusual&amp;nbsp;activity in the company's error logs. Instead of typical sheet music uploads, users were submitting screenshots of ChatGPT conversations containing ASCII tablature—simple text representations of guitar music that look like strings with numbers indicating fret positions.&lt;/p&gt;
&lt;p&gt;"Our scanning system wasn't intended to support this style of notation," wrote Holovaty in the blog post. "Why, then, were we being bombarded with so many ASCII tab ChatGPT screenshots? I was mystified for weeks—until I messed around with ChatGPT myself."&lt;/p&gt;
&lt;p&gt;When Holovaty tested ChatGPT, he discovered the source of the confusion: The AI model was instructing users to create Soundslice accounts and use the platform to import ASCII tabs for audio playback—a feature that didn't exist. "We've never supported ASCII tab; ChatGPT was outright lying to people," Holovaty wrote. "And making us look bad in the process, setting false expectations about our service."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2105045 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of Soundslice's new ASCII tab importer documentation." class="center large" height="723" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/ascii_tabs-1024x723.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of Soundslice's new ASCII tab importer documentation, hallucinated by ChatGPT and made real later.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          https://www.soundslice.com/help/en/creating/importing/331/ascii-tab/

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;When AI models like ChatGPT generate false information with apparent confidence, AI researchers call it a "hallucination" or&amp;nbsp; "confabulation." The problem of AI models confabulating false information has plagued AI models since ChatGPT's public release in November 2022, when people began erroneously using the chatbot as a replacement for a search engine.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As prediction machines, large language models trained on massive text datasets can easily produce outputs that seem plausible but are completely inaccurate. The models statistically improvise to fill "knowledge" gaps on topics poorly represented in their training data, generating text based on statistical patterns rather than factual accuracy. In this way, ChatGPT told its users what they wanted to hear by making up a Soundslice feature that made sense but didn't exist.&lt;/p&gt;
&lt;p&gt;Usually, confabulations get people in trouble. In one notable case from 2023, lawyers faced sanctions after submitting legal briefs containing ChatGPT-generated citations to non-existent court cases. In February 2024, Canada's Civil Resolution Tribunal ordered Air Canada to pay damages to a customer and honor a bereavement fare policy that was hallucinated by a support chatbot, which incorrectly stated that customers could retroactively request a bereavement discount within 90 days of the date the ticket was issued.&lt;/p&gt;
&lt;h2&gt;From bug to feature&lt;/h2&gt;
&lt;p&gt;The discovery presented Soundslice with an unusual dilemma. The company could have posted disclaimers warning users to ignore ChatGPT's claims, but instead chose a different path. "We ended up deciding: what the heck, we might as well meet the market demand," Holovaty explained. The team built an ASCII tab importer—a feature that had been "near the bottom of my 'Software I expected to write in 2025' list"—and updated their user interface to inform users about the new capability.&lt;/p&gt;
&lt;p&gt;Soundslice's solution presents an interesting case of making lemonade from lemons, but for Holovaty, the situation raises philosophical questions about product development. "My feelings on this are conflicted," he wrote. "I'm happy to add a tool that helps people. But I feel like our hand was forced in a weird way. Should we really be developing features in response to misinformation?"&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/chatgpt-made-up-a-product-feature-out-of-thin-air-so-this-company-created-it/</guid><pubDate>Wed, 09 Jul 2025 21:59:25 +0000</pubDate></item><item><title>Microsoft shares $500M in AI savings internally days after cutting 9,000 jobs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/microsoft-shares-500m-in-ai-savings-internally-days-after-cutting-9000-jobs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Copilot-Hero-Image.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft’s chief commercial officer Judson Althoff said during a presentation this week that AI tools are boosting productivity across sales, customer service, and software engineering, Bloomberg reports. Althoff noted AI has been so useful that Microsoft was able to save more than $500 million last year in its call center alone.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The internal remarks come a week after Microsoft laid off more than 9,000 workers, the company’s third round of layoffs this year that put the total number of affected employees somewhere around 15,000.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For employees who lost their jobs while working at a company that is reporting impressive cost-savings and recording one of its most profitable quarters yet, Althoff’s remarks might come off as tone deaf.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The situation had already been complicated by a now-deleted LinkedIn post from Xbox Game Studios’ producer Matt Turnbull, who last week suggested that workers feeling “overwhelmed” by Microsoft’s layoffs — which included job cuts across Xbox — might find support through AI tools like ChatGPT and Copilot to help manage the cognitive load that comes with job loss.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not clear whether the thousands of workers who lost their jobs this year were replaced by AI or whether the layoffs represent post-pandemic right-sizing. What is clear is that workforce adjustments during a period of record profitability creates a challenging dynamic that, for some, has to sting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft closed out the first quarter with $26 billion in profit and $70 billion in revenue. The company’s market capitalization has also surged in recent months to around $3.74 trillion, displacing Apple and trailing only Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft has signaled that much of that profit will flow directly into AI. The company said in January it would invest $80 billion into AI infrastructure across 2025. While Microsoft continues to hire talent, too, the company appears positioned to more actively participate in the industrywide competition of “Who Can Pay Top AI Researchers The Most?” In short, it’s more likely we’ll see Microsoft spend millions of dollars on top AI researchers rather than middle managers and other employees.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Copilot-Hero-Image.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft’s chief commercial officer Judson Althoff said during a presentation this week that AI tools are boosting productivity across sales, customer service, and software engineering, Bloomberg reports. Althoff noted AI has been so useful that Microsoft was able to save more than $500 million last year in its call center alone.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The internal remarks come a week after Microsoft laid off more than 9,000 workers, the company’s third round of layoffs this year that put the total number of affected employees somewhere around 15,000.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For employees who lost their jobs while working at a company that is reporting impressive cost-savings and recording one of its most profitable quarters yet, Althoff’s remarks might come off as tone deaf.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The situation had already been complicated by a now-deleted LinkedIn post from Xbox Game Studios’ producer Matt Turnbull, who last week suggested that workers feeling “overwhelmed” by Microsoft’s layoffs — which included job cuts across Xbox — might find support through AI tools like ChatGPT and Copilot to help manage the cognitive load that comes with job loss.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not clear whether the thousands of workers who lost their jobs this year were replaced by AI or whether the layoffs represent post-pandemic right-sizing. What is clear is that workforce adjustments during a period of record profitability creates a challenging dynamic that, for some, has to sting. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft closed out the first quarter with $26 billion in profit and $70 billion in revenue. The company’s market capitalization has also surged in recent months to around $3.74 trillion, displacing Apple and trailing only Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft has signaled that much of that profit will flow directly into AI. The company said in January it would invest $80 billion into AI infrastructure across 2025. While Microsoft continues to hire talent, too, the company appears positioned to more actively participate in the industrywide competition of “Who Can Pay Top AI Researchers The Most?” In short, it’s more likely we’ll see Microsoft spend millions of dollars on top AI researchers rather than middle managers and other employees.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/microsoft-shares-500m-in-ai-savings-internally-days-after-cutting-9000-jobs/</guid><pubDate>Wed, 09 Jul 2025 23:06:01 +0000</pubDate></item><item><title>[NEW] Announcing the winners of VentureBeat’s 7th Annual Women in AI awards (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/announcing-the-winners-of-venturebeats-7th-annual-women-in-ai-awards/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat announced the winners of the seventh annual Women in AI Awards at VB Transform in San Francisco on June 25.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The awards recognize and honor the women leaders and changemakers in the field of AI. The nominees were submitted by the public and chosen by a VentureBeat committee based on their commitment to the industry, their work to increase inclusivity in the field and their positive influence in the community.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Winners were presented with awards by VentureBeat’s senior AI writer Emilia David and myself (associate managing editor).&lt;/p&gt;



&lt;p&gt;“We’re thrilled to be here to present the seventh annual Women in AI awards,” David said in her opening remarks. “We want to offer praise for all the people who are behind the scenes and helping transform the industry.”&lt;/p&gt;







&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;This award honors a woman who launched companies now showing great promise in AI. Judges considered factors such as business traction, technology and impact in the AI space.&lt;/p&gt;



&lt;p&gt;This year’s winner is Natalya Lopareva, CEO and founder at Algorized. Her technology, originally developed from research at the University of Zurich, helps locate people after earthquakes and can now help save lives in various applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“At Algorized we utilize AI for people sensing, so we enable physical AI, we are at the intersection of human and machine,” Lopareva said in her acceptance speech. The award went to her entire team and all the amazing women working at the company.&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;






&lt;p&gt;This award honors a woman who has made a significant impact in AI research, helping accelerate progress either within her organization, as part of academic research or impacting AI generally.&lt;/p&gt;



&lt;p&gt;This year’s winner is Lindsay Richman, CEO at Vibrissa AI (formerly Innerverse AI). Richman and her team are focused on sensor and biometric data and their applications. They are developing research around longevity, cellular orchestration, mitochondrial health and biophotonics.&lt;/p&gt;



&lt;p&gt;“A vibrissa is actually a whisker, a hair, that actually detects vibration,” Richman said in her acceptance speech. “And my company had done a lot of work in sensor research and finding ways to use vibrations to record events to hopefully do a lot of sensor-based recording without a lot of hardware that currently slows processes down.” &lt;/p&gt;



&lt;p&gt;She said she was thrilled to be back at Transform and “support so many great people, including great women, at this conference.”&lt;/p&gt;







&lt;p&gt;This award honors a female leader who has helped mentor other women in the field of AI, providing guidance and support and/or encouraging more women to enter the field.&lt;/p&gt;



&lt;p&gt;This year’s winner is Suruchi Shah, engineering manager for the model serving team at LinkedIn. She spearheads the development of cutting-edge infrastructure for large language model (LLM) serving, helping revolutionize the way AI models are deployed across LinkedIn’s ecosystem.&lt;/p&gt;



&lt;p&gt;Shah was not able to accept the award in person, however, she said in a statement after: “I’m deeply honored by this recognition — it belongs as much to the brilliant women I’ve been privileged to mentor as it does to me. Together we’re proving that an inclusive, supportive community is the fastest path to breakthrough AI innovation.”&lt;/p&gt;







&lt;p&gt;This award honors a woman who demonstrates exemplary leadership and progress in the emerging field of responsible AI.&lt;/p&gt;



&lt;p&gt;This year’s winner is Stephanie Cohen, chief strategy officer at Cloudflare. She is leading efforts to redefine the economic model of the internet, and creating a sustainable future for content creators, publishers, AI companies and the internet at large.&lt;/p&gt;



&lt;p&gt;Cohen could not accept her award in person, but she sent in a video acceptance, saying she was honored to be recognized. “Here at Cloudflare, we are on a mission to help build a better internet, and a better internet is one where we are using AI responsibly, and that is a world where content creators of all shapes and sizes are flourishing in this amazing world that’s in front of us with AI.”&lt;/p&gt;



&lt;p&gt;She added after the event: “I joined Cloudflare just over a year ago to help build a better Internet. Our global network now has GPUs in over 190 cities, making AI fast and accessible to everyone around the world, and we’re building tools to help foster a future where AI innovation thrives while respecting content ownership. And as our co-founders like to say, ‘we’re just getting started’.”&lt;/p&gt;







&lt;p&gt;This award honors a woman in the early stage of her AI career who has demonstrated exemplary leadership traits.&lt;/p&gt;



&lt;p&gt;This year’s winner is Arina Vlasova, CEO at DataGPT. The company offers a conversational AI data analyst that allows users to interact with their data using natural language and receive immediate, analyst-level insights.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This award truly means a lot to me,” Vlasova said during her acceptance speech. “DataGPT was started as a bold idea to build the world’s first AI data analyst. A lot of people questioned us. Some thought that it might be too ambitious, even beyond my and my team’s potential. But we pushed harder and today we are leading the way. What is truly meaningful in life is always hard, and what matters is to have vision, grit and to keep going. To all the women out there, go over it, lead it, build it. You’ve got it.”&lt;/p&gt;



&lt;p&gt;We’d like to congratulate all of the women who were nominated to receive a Women in AI Award and to our winners. Thanks to everyone for their nominations and for contributing to the growing awareness of women who are making a significant difference in AI.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;VentureBeat announced the winners of the seventh annual Women in AI Awards at VB Transform in San Francisco on June 25.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The awards recognize and honor the women leaders and changemakers in the field of AI. The nominees were submitted by the public and chosen by a VentureBeat committee based on their commitment to the industry, their work to increase inclusivity in the field and their positive influence in the community.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Winners were presented with awards by VentureBeat’s senior AI writer Emilia David and myself (associate managing editor).&lt;/p&gt;



&lt;p&gt;“We’re thrilled to be here to present the seventh annual Women in AI awards,” David said in her opening remarks. “We want to offer praise for all the people who are behind the scenes and helping transform the industry.”&lt;/p&gt;







&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;This award honors a woman who launched companies now showing great promise in AI. Judges considered factors such as business traction, technology and impact in the AI space.&lt;/p&gt;



&lt;p&gt;This year’s winner is Natalya Lopareva, CEO and founder at Algorized. Her technology, originally developed from research at the University of Zurich, helps locate people after earthquakes and can now help save lives in various applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“At Algorized we utilize AI for people sensing, so we enable physical AI, we are at the intersection of human and machine,” Lopareva said in her acceptance speech. The award went to her entire team and all the amazing women working at the company.&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;






&lt;p&gt;This award honors a woman who has made a significant impact in AI research, helping accelerate progress either within her organization, as part of academic research or impacting AI generally.&lt;/p&gt;



&lt;p&gt;This year’s winner is Lindsay Richman, CEO at Vibrissa AI (formerly Innerverse AI). Richman and her team are focused on sensor and biometric data and their applications. They are developing research around longevity, cellular orchestration, mitochondrial health and biophotonics.&lt;/p&gt;



&lt;p&gt;“A vibrissa is actually a whisker, a hair, that actually detects vibration,” Richman said in her acceptance speech. “And my company had done a lot of work in sensor research and finding ways to use vibrations to record events to hopefully do a lot of sensor-based recording without a lot of hardware that currently slows processes down.” &lt;/p&gt;



&lt;p&gt;She said she was thrilled to be back at Transform and “support so many great people, including great women, at this conference.”&lt;/p&gt;







&lt;p&gt;This award honors a female leader who has helped mentor other women in the field of AI, providing guidance and support and/or encouraging more women to enter the field.&lt;/p&gt;



&lt;p&gt;This year’s winner is Suruchi Shah, engineering manager for the model serving team at LinkedIn. She spearheads the development of cutting-edge infrastructure for large language model (LLM) serving, helping revolutionize the way AI models are deployed across LinkedIn’s ecosystem.&lt;/p&gt;



&lt;p&gt;Shah was not able to accept the award in person, however, she said in a statement after: “I’m deeply honored by this recognition — it belongs as much to the brilliant women I’ve been privileged to mentor as it does to me. Together we’re proving that an inclusive, supportive community is the fastest path to breakthrough AI innovation.”&lt;/p&gt;







&lt;p&gt;This award honors a woman who demonstrates exemplary leadership and progress in the emerging field of responsible AI.&lt;/p&gt;



&lt;p&gt;This year’s winner is Stephanie Cohen, chief strategy officer at Cloudflare. She is leading efforts to redefine the economic model of the internet, and creating a sustainable future for content creators, publishers, AI companies and the internet at large.&lt;/p&gt;



&lt;p&gt;Cohen could not accept her award in person, but she sent in a video acceptance, saying she was honored to be recognized. “Here at Cloudflare, we are on a mission to help build a better internet, and a better internet is one where we are using AI responsibly, and that is a world where content creators of all shapes and sizes are flourishing in this amazing world that’s in front of us with AI.”&lt;/p&gt;



&lt;p&gt;She added after the event: “I joined Cloudflare just over a year ago to help build a better Internet. Our global network now has GPUs in over 190 cities, making AI fast and accessible to everyone around the world, and we’re building tools to help foster a future where AI innovation thrives while respecting content ownership. And as our co-founders like to say, ‘we’re just getting started’.”&lt;/p&gt;







&lt;p&gt;This award honors a woman in the early stage of her AI career who has demonstrated exemplary leadership traits.&lt;/p&gt;



&lt;p&gt;This year’s winner is Arina Vlasova, CEO at DataGPT. The company offers a conversational AI data analyst that allows users to interact with their data using natural language and receive immediate, analyst-level insights.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This award truly means a lot to me,” Vlasova said during her acceptance speech. “DataGPT was started as a bold idea to build the world’s first AI data analyst. A lot of people questioned us. Some thought that it might be too ambitious, even beyond my and my team’s potential. But we pushed harder and today we are leading the way. What is truly meaningful in life is always hard, and what matters is to have vision, grit and to keep going. To all the women out there, go over it, lead it, build it. You’ve got it.”&lt;/p&gt;



&lt;p&gt;We’d like to congratulate all of the women who were nominated to receive a Women in AI Award and to our winners. Thanks to everyone for their nominations and for contributing to the growing awareness of women who are making a significant difference in AI.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/announcing-the-winners-of-venturebeats-7th-annual-women-in-ai-awards/</guid><pubDate>Wed, 09 Jul 2025 23:59:14 +0000</pubDate></item><item><title>Why Cluely’s Roy Lee isn’t sweating cheating detectors (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/why-cluelys-roy-lee-isnt-sweating-cheating-detectors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/IMG-0036-from-100CANON.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cluely, an AI startup that uses a hidden in-browser window to analyze online conversations, has shot to fame with the controversial claim that its ‘undetectability’ feature lets users “cheat on everything.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s co-founder, Roy Lee, was suspended from Columbia University for boasting that he used Cluely, originally called Interview Coder, to “cheat” on a coding test when he was applying for a developer job at Amazon.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Tuesday, another Columbia University student, Patrick Shen, announced on X that he had built Truely, a product designed to help catch “cheaters” who use Cluely. Marketing itself as an “anti-Cluely,” Truely claims it can detect the use of unauthorized applications by interviewees or others during online meetings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Truely’s launch didn’t faze Lee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t care if we’re able to be detected or not,” Lee told TechCrunch last week. “The invisibility function is not a core feature of Cluely. It’s a nifty add-on. In fact, most enterprises opt to disable the invisibility altogether because of legal implications.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee responded to Shen on X by praising Truely, but adding that Cluely “will likely start prompting our users to be much more transparent about usage.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since securing a $15 million Series A from Andreessen Horowitz last month, Cluely has shifted its marketing strategy away from promoting ‘cheating.’&amp;nbsp; The company’s tagline has recently been changed from “cheat on everything” to “Everything You Need. Before You Ask. … This feels like cheating.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Cluely’s marketing tactics have been described as rage-bait marketing, and now it seems that the company has baited us into thinking of its technology as a cheating tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Lee has much bigger ambitions for Cluely: to take the place of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Every time you would reach for chatgpt.com, our goal is to create a world where you instead reach for Cluely,” Lee said. “Cluely does functionally the same thing as ChatGPT. The only difference is that it also knows what’s on your screen and hears what’s going on in your audio.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/IMG-0036-from-100CANON.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Cluely, an AI startup that uses a hidden in-browser window to analyze online conversations, has shot to fame with the controversial claim that its ‘undetectability’ feature lets users “cheat on everything.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s co-founder, Roy Lee, was suspended from Columbia University for boasting that he used Cluely, originally called Interview Coder, to “cheat” on a coding test when he was applying for a developer job at Amazon.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Tuesday, another Columbia University student, Patrick Shen, announced on X that he had built Truely, a product designed to help catch “cheaters” who use Cluely. Marketing itself as an “anti-Cluely,” Truely claims it can detect the use of unauthorized applications by interviewees or others during online meetings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Truely’s launch didn’t faze Lee.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t care if we’re able to be detected or not,” Lee told TechCrunch last week. “The invisibility function is not a core feature of Cluely. It’s a nifty add-on. In fact, most enterprises opt to disable the invisibility altogether because of legal implications.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee responded to Shen on X by praising Truely, but adding that Cluely “will likely start prompting our users to be much more transparent about usage.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since securing a $15 million Series A from Andreessen Horowitz last month, Cluely has shifted its marketing strategy away from promoting ‘cheating.’&amp;nbsp; The company’s tagline has recently been changed from “cheat on everything” to “Everything You Need. Before You Ask. … This feels like cheating.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Cluely’s marketing tactics have been described as rage-bait marketing, and now it seems that the company has baited us into thinking of its technology as a cheating tool.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Lee has much bigger ambitions for Cluely: to take the place of ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Every time you would reach for chatgpt.com, our goal is to create a world where you instead reach for Cluely,” Lee said. “Cluely does functionally the same thing as ChatGPT. The only difference is that it also knows what’s on your screen and hears what’s going on in your audio.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/why-cluelys-roy-lee-isnt-sweating-cheating-detectors/</guid><pubDate>Thu, 10 Jul 2025 00:36:02 +0000</pubDate></item><item><title>[NEW] Skip the AI ‘bake-off’ and build autonomous agents: Lessons from Intuit and Amex (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/dont-wait-for-a-bake-off-how-intuit-and-amex-beat-competitors-to-production-ai-agents/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As generative AI matures, enterprises are shifting from experimentation to implementation—moving beyond chatbots and copilots into the realm of intelligent, autonomous agents. In a conversation with &lt;em&gt;VentureBeat’s &lt;/em&gt;Matt Marshall, Ashok Srivastava, SVP and Chief Data Officer at Intuit, and Hillary Packer, EVP and CTO at American Express at VB Transform, detailed how their companies are embracing agentic AI to transform customer experiences, internal workflows and core business operations.&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-from-models-to-missions-the-rise-of-intelligent-agents"&gt;From models to missions: the rise of intelligent agents&lt;/h2&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;At Intuit, agents aren’t just about answering questions—they’re about executing tasks. In TurboTax, for instance, agents help customers complete their taxes 12% faster, with nearly half finishing in under an hour. These intelligent systems draw data from multiple streams—including real-time and batch data—via Intuit’s internal bus and persistent services. Once processed, the agent analyzes the information to make a decision and take action.&lt;/p&gt;



&lt;p&gt;“This is the way we’re thinking about agents in the financial domain,”&amp;nbsp; said Srivastava. “We’re trying to make sure that as we build, they’re robust, scalable and actually anchored in reality. The agentic experiences we’re building are designed to get work done &lt;em&gt;for&lt;/em&gt; the customer, &lt;em&gt;with&lt;/em&gt; their permission. That’s key to building trust.”&lt;/p&gt;



&lt;p&gt;These capabilities are made possible by GenOS, Intuit’s custom generative AI operating system. At its heart is GenRuntime, which Srivastava likens to a CPU: it receives the data, reasons over it, and determines an action that’s then executed for the end user. The OS was designed to abstract away technical complexity, so developers don’t need to reinvent risk safeguards or security layers every time they build an agent.&lt;/p&gt;



&lt;p&gt;Across Intuit’s brands—from TurboTax and QuickBooks to Mailchimp and Credit Karma—GenOS helps create consistent, trusted experiences and ensure robustness, scalability and extensibility across use cases.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-the-agentic-stack-at-amex-trust-control-and-experimentation"&gt;Building the agentic stack at Amex: trust, control,and experimentation&lt;/h2&gt;



&lt;p&gt;For Packer and her team at Amex, the move into agentic AI builds on more than 15 years of experience with traditional AI and a mature, battle-tested big data infrastructure. As GenAI capabilities accelerate, Amex is reshaping its strategy to focus on how intelligent agents can drive internal workflows and power the next generation of customer experiences. For example, the company is focused on developing internal agents that boost employee productivity, like the APR agent that reviews software pull requests and advises engineers on whether code is ready to merge. This project reflects Amex’s broader approach: start with internal use cases, move quickly, and use early wins to refine the underlying infrastructure, tools, and governance standards.&lt;/p&gt;



&lt;p&gt;To support fast experimentation, strong security, and policy enforcement, Amex developed an “enablement layer”&amp;nbsp;that allows for rapid development without sacrificing oversight. “And so now as we think about agentic, we’ve got a nice control plane to plug in these additional, additional guardrails that we really do need to have in place,” said Packer.&lt;/p&gt;



&lt;p&gt;Within this system is Amex’s concept of modular “brains”—a framework in which agents are required to consult with specific “brains” before taking action. These brains serve as modular governance layers—covering brand values, privacy, security, and legal compliance—that every agent must engage with during decision-making. Each brain represents a domain-specific set of policies, such as brand voice, privacy rules, or legal constraints and functions as a consultable authority. By routing decisions through this system of constraints, agents remain accountable, aligned with enterprise standards and worthy of user trust.&lt;/p&gt;



&lt;p&gt;For instance, a dining reservation agent operating through Rezi, Amex’s restaurant booking platform, must validate that it’s selecting the right restaurant at the right time, matching the user’s intent while adhering to brand and policy guidelines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-architecture-that-enables-speed-and-safety"&gt;Architecture that enables speed and safety&lt;/h2&gt;



&lt;p&gt;Both AI leaders agreed that enabling rapid development at scale demands thoughtful architectural design. At Intuit, the creation of GenOS empowers hundreds of developers to build safely and consistently. The platform ensures each team can access shared infrastructure, common safeguards, and model flexibility without duplicating work.&lt;/p&gt;



&lt;p&gt;Amex took a similar approach with its enablement layer. Designed around a unified control plane, the layer lets teams rapidly develop AI-driven agents while enforcing centralized policies and guardrails. It ensures consistent implementation of risk and governance frameworks while encouraging speed. Developers can deploy experiments quickly, then evaluate and scale based on feedback and performance, all without compromising brand trust.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-lessons-in-agentic-ai-adoption"&gt;Lessons in agentic AI adoption&lt;/h2&gt;



&lt;p&gt;Both AI leaders stressed the need to move quickly, but with intent. “Don’t wait for a bake-off,” Packer advised. “It’s better to pick a direction, get something into production, and iterate quickly, rather than delaying for the perfect solution that may be outdated by launch time.” They also emphasized that measurement must be embedded from the very beginning. According to Srivastava, instrumentation isn’t something to bolt on later—it has to be an integral part of the stack. Tracking cost, latency, accuracy and user impact is essential for assessing value and maintaining accountability at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You have to be able to measure it. That’s where GenOS comes in—there’s a built-in capability that lets us instrument AI applications and track both the cost going in and the return coming out,” said Srivastava. “I review this every quarter with our CFO. We go line by line through every AI use case across the company, assessing exactly how much we’re spending and what value we’re getting in return.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-intelligent-agents-are-the-next-enterprise-platform-shift"&gt;Intelligent agents are the next enterprise platform shift&lt;/h2&gt;



&lt;p&gt;Intuit and American Express are among the leading enterprises adopting agentic AI not just as a technology layer, but as a new operating model. Their approach focuses on building the agentic platform, establishing governance, measuring impact, and moving quickly. As enterprise expectations evolve from simple chatbot functionality to autonomous execution, organizations that treat agentic AI as a first-class discipline—with control planes, observability, and modular governance—will be best positioned to lead the agentic race.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Editor’s note: As a thank-you to our readers, we’ve opened up early bird registration for VB Transform 2026 — just $200. This is where AI ambition meets operational reality, and you’re going to want to be in the room. Reserve your spot now.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;As generative AI matures, enterprises are shifting from experimentation to implementation—moving beyond chatbots and copilots into the realm of intelligent, autonomous agents. In a conversation with &lt;em&gt;VentureBeat’s &lt;/em&gt;Matt Marshall, Ashok Srivastava, SVP and Chief Data Officer at Intuit, and Hillary Packer, EVP and CTO at American Express at VB Transform, detailed how their companies are embracing agentic AI to transform customer experiences, internal workflows and core business operations.&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-from-models-to-missions-the-rise-of-intelligent-agents"&gt;From models to missions: the rise of intelligent agents&lt;/h2&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;At Intuit, agents aren’t just about answering questions—they’re about executing tasks. In TurboTax, for instance, agents help customers complete their taxes 12% faster, with nearly half finishing in under an hour. These intelligent systems draw data from multiple streams—including real-time and batch data—via Intuit’s internal bus and persistent services. Once processed, the agent analyzes the information to make a decision and take action.&lt;/p&gt;



&lt;p&gt;“This is the way we’re thinking about agents in the financial domain,”&amp;nbsp; said Srivastava. “We’re trying to make sure that as we build, they’re robust, scalable and actually anchored in reality. The agentic experiences we’re building are designed to get work done &lt;em&gt;for&lt;/em&gt; the customer, &lt;em&gt;with&lt;/em&gt; their permission. That’s key to building trust.”&lt;/p&gt;



&lt;p&gt;These capabilities are made possible by GenOS, Intuit’s custom generative AI operating system. At its heart is GenRuntime, which Srivastava likens to a CPU: it receives the data, reasons over it, and determines an action that’s then executed for the end user. The OS was designed to abstract away technical complexity, so developers don’t need to reinvent risk safeguards or security layers every time they build an agent.&lt;/p&gt;



&lt;p&gt;Across Intuit’s brands—from TurboTax and QuickBooks to Mailchimp and Credit Karma—GenOS helps create consistent, trusted experiences and ensure robustness, scalability and extensibility across use cases.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-the-agentic-stack-at-amex-trust-control-and-experimentation"&gt;Building the agentic stack at Amex: trust, control,and experimentation&lt;/h2&gt;



&lt;p&gt;For Packer and her team at Amex, the move into agentic AI builds on more than 15 years of experience with traditional AI and a mature, battle-tested big data infrastructure. As GenAI capabilities accelerate, Amex is reshaping its strategy to focus on how intelligent agents can drive internal workflows and power the next generation of customer experiences. For example, the company is focused on developing internal agents that boost employee productivity, like the APR agent that reviews software pull requests and advises engineers on whether code is ready to merge. This project reflects Amex’s broader approach: start with internal use cases, move quickly, and use early wins to refine the underlying infrastructure, tools, and governance standards.&lt;/p&gt;



&lt;p&gt;To support fast experimentation, strong security, and policy enforcement, Amex developed an “enablement layer”&amp;nbsp;that allows for rapid development without sacrificing oversight. “And so now as we think about agentic, we’ve got a nice control plane to plug in these additional, additional guardrails that we really do need to have in place,” said Packer.&lt;/p&gt;



&lt;p&gt;Within this system is Amex’s concept of modular “brains”—a framework in which agents are required to consult with specific “brains” before taking action. These brains serve as modular governance layers—covering brand values, privacy, security, and legal compliance—that every agent must engage with during decision-making. Each brain represents a domain-specific set of policies, such as brand voice, privacy rules, or legal constraints and functions as a consultable authority. By routing decisions through this system of constraints, agents remain accountable, aligned with enterprise standards and worthy of user trust.&lt;/p&gt;



&lt;p&gt;For instance, a dining reservation agent operating through Rezi, Amex’s restaurant booking platform, must validate that it’s selecting the right restaurant at the right time, matching the user’s intent while adhering to brand and policy guidelines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-architecture-that-enables-speed-and-safety"&gt;Architecture that enables speed and safety&lt;/h2&gt;



&lt;p&gt;Both AI leaders agreed that enabling rapid development at scale demands thoughtful architectural design. At Intuit, the creation of GenOS empowers hundreds of developers to build safely and consistently. The platform ensures each team can access shared infrastructure, common safeguards, and model flexibility without duplicating work.&lt;/p&gt;



&lt;p&gt;Amex took a similar approach with its enablement layer. Designed around a unified control plane, the layer lets teams rapidly develop AI-driven agents while enforcing centralized policies and guardrails. It ensures consistent implementation of risk and governance frameworks while encouraging speed. Developers can deploy experiments quickly, then evaluate and scale based on feedback and performance, all without compromising brand trust.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-lessons-in-agentic-ai-adoption"&gt;Lessons in agentic AI adoption&lt;/h2&gt;



&lt;p&gt;Both AI leaders stressed the need to move quickly, but with intent. “Don’t wait for a bake-off,” Packer advised. “It’s better to pick a direction, get something into production, and iterate quickly, rather than delaying for the perfect solution that may be outdated by launch time.” They also emphasized that measurement must be embedded from the very beginning. According to Srivastava, instrumentation isn’t something to bolt on later—it has to be an integral part of the stack. Tracking cost, latency, accuracy and user impact is essential for assessing value and maintaining accountability at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You have to be able to measure it. That’s where GenOS comes in—there’s a built-in capability that lets us instrument AI applications and track both the cost going in and the return coming out,” said Srivastava. “I review this every quarter with our CFO. We go line by line through every AI use case across the company, assessing exactly how much we’re spending and what value we’re getting in return.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-intelligent-agents-are-the-next-enterprise-platform-shift"&gt;Intelligent agents are the next enterprise platform shift&lt;/h2&gt;



&lt;p&gt;Intuit and American Express are among the leading enterprises adopting agentic AI not just as a technology layer, but as a new operating model. Their approach focuses on building the agentic platform, establishing governance, measuring impact, and moving quickly. As enterprise expectations evolve from simple chatbot functionality to autonomous execution, organizations that treat agentic AI as a first-class discipline—with control planes, observability, and modular governance—will be best positioned to lead the agentic race.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Editor’s note: As a thank-you to our readers, we’ve opened up early bird registration for VB Transform 2026 — just $200. This is where AI ambition meets operational reality, and you’re going to want to be in the room. Reserve your spot now.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/dont-wait-for-a-bake-off-how-intuit-and-amex-beat-competitors-to-production-ai-agents/</guid><pubDate>Thu, 10 Jul 2025 01:12:41 +0000</pubDate></item><item><title>[NEW] Open vs. closed models: AI leaders from GM, Zoom and IBM weigh trade-offs for enterprise use (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/open-vs-closed-models-ai-leaders-from-gm-zoom-and-ibm-weigh-trade-offs-for-enterprise-use/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Deciding on AI models is as much of a technical decision and it is a strategic one. But choosing open, closed or hybrid models all have trade-offs.&lt;/p&gt;



&lt;p&gt;While speaking at this year’s VB Transform, model architecture experts from General Motors, Zoom and IBM discussed how their companies and customers consider AI model selection.&lt;/p&gt;



&lt;p&gt;Barak Turovsky, who in March became GM’s first chief AI officer, said there’s a lot of noise with every new model release and every time the leaderboard changes. Long before leaderboards were a mainstream debate, Turovsky helped launch the first large language model (LLM) and recalled the ways open-sourcing AI model weights and training data led to major breakthroughs.&lt;/p&gt;



&lt;p&gt;“That was frankly probably one of the biggest breakthroughs that helped OpenAI and others to start launching,” Turovsky said. “So it’s actually a funny anecdote: Open-source actually helped create something that went closed and now maybe is back to being open.”&lt;/p&gt;



&lt;p&gt;Factors for decisions vary and include cost, performance, trust and safety. Turovsky said enterprises sometimes prefer a mixed strategy — using an open model for internal use and a closed model for production and customer facing or vice versa.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-ibm-s-ai-strategy"&gt;IBM’s AI strategy&lt;/h2&gt;



&lt;p&gt;Armand Ruiz, IBM’s VP of AI platform, said IBM initially started its platform with its own LLMs, but then realized that wouldn’t be enough — especially as more powerful models arrived on the market. The company then expanded to offer integrations with platforms like Hugging Face so customers could pick any open-source model. (The company recently debuted a new model gateway that gives enterprises an API for switching between LLMs.)&amp;nbsp;&lt;/p&gt;



&lt;p&gt;More enterprises are choosing to buy more models from multiple vendors. When Andreessen Horowitz surveyed 100 CIOs, 37% of respondents said they were using 5 or more models. Last year, only 29% were using the same amount.&lt;/p&gt;



&lt;p&gt;Choice is key, but sometimes too much choice creates confusion, said Ruiz. To help customers with their approach, IBM doesn’t worry too much about which LLM they’re using during the proof of concept or pilot phase; the main goal is feasibility. Only later they begin to look at whether to distill a model or customize one based on a customer’s needs.&lt;/p&gt;



&lt;p&gt;“First we try to simplify all that analysis paralysis with all those options and focus on the use case,” Ruiz said. “Then we figure out what is the best path for production.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-zoom-approaches-ai"&gt;How Zoom approaches AI&lt;/h2&gt;



&lt;p&gt;Zoom’s customers can choose between two configurations for its AI Companion, said Zoom CTO Xuedong Huang. One involves federating the company’s own LLM with other larger foundation models. Another configuration allows customers concerned about using too many models to use just Zoom’s model. (The company also recently partnered with Google Cloud to adopt an agent-to-agent protocol for AI Companion for enterprise workflows.)&lt;/p&gt;



&lt;p&gt;The company made its own small language model (SLM) without using customer data, Huang said. At 2 billion parameters, the LLM is actually very small, but it can still outperform other industry-specific models. The SLM works best on complex tasks when working alongside a larger model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This is really the power of a hybrid approach,” Huang said. “Our philosophy is very straightforward. Our company is leading the way very much like Mickey Mouse and the elephant dancing together. The small model will perform a very specific task. We are not saying a small model will be good enough…The Mickey Mouse and elephant will be working together as one team.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Deciding on AI models is as much of a technical decision and it is a strategic one. But choosing open, closed or hybrid models all have trade-offs.&lt;/p&gt;



&lt;p&gt;While speaking at this year’s VB Transform, model architecture experts from General Motors, Zoom and IBM discussed how their companies and customers consider AI model selection.&lt;/p&gt;



&lt;p&gt;Barak Turovsky, who in March became GM’s first chief AI officer, said there’s a lot of noise with every new model release and every time the leaderboard changes. Long before leaderboards were a mainstream debate, Turovsky helped launch the first large language model (LLM) and recalled the ways open-sourcing AI model weights and training data led to major breakthroughs.&lt;/p&gt;



&lt;p&gt;“That was frankly probably one of the biggest breakthroughs that helped OpenAI and others to start launching,” Turovsky said. “So it’s actually a funny anecdote: Open-source actually helped create something that went closed and now maybe is back to being open.”&lt;/p&gt;



&lt;p&gt;Factors for decisions vary and include cost, performance, trust and safety. Turovsky said enterprises sometimes prefer a mixed strategy — using an open model for internal use and a closed model for production and customer facing or vice versa.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-ibm-s-ai-strategy"&gt;IBM’s AI strategy&lt;/h2&gt;



&lt;p&gt;Armand Ruiz, IBM’s VP of AI platform, said IBM initially started its platform with its own LLMs, but then realized that wouldn’t be enough — especially as more powerful models arrived on the market. The company then expanded to offer integrations with platforms like Hugging Face so customers could pick any open-source model. (The company recently debuted a new model gateway that gives enterprises an API for switching between LLMs.)&amp;nbsp;&lt;/p&gt;



&lt;p&gt;More enterprises are choosing to buy more models from multiple vendors. When Andreessen Horowitz surveyed 100 CIOs, 37% of respondents said they were using 5 or more models. Last year, only 29% were using the same amount.&lt;/p&gt;



&lt;p&gt;Choice is key, but sometimes too much choice creates confusion, said Ruiz. To help customers with their approach, IBM doesn’t worry too much about which LLM they’re using during the proof of concept or pilot phase; the main goal is feasibility. Only later they begin to look at whether to distill a model or customize one based on a customer’s needs.&lt;/p&gt;



&lt;p&gt;“First we try to simplify all that analysis paralysis with all those options and focus on the use case,” Ruiz said. “Then we figure out what is the best path for production.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-zoom-approaches-ai"&gt;How Zoom approaches AI&lt;/h2&gt;



&lt;p&gt;Zoom’s customers can choose between two configurations for its AI Companion, said Zoom CTO Xuedong Huang. One involves federating the company’s own LLM with other larger foundation models. Another configuration allows customers concerned about using too many models to use just Zoom’s model. (The company also recently partnered with Google Cloud to adopt an agent-to-agent protocol for AI Companion for enterprise workflows.)&lt;/p&gt;



&lt;p&gt;The company made its own small language model (SLM) without using customer data, Huang said. At 2 billion parameters, the LLM is actually very small, but it can still outperform other industry-specific models. The SLM works best on complex tasks when working alongside a larger model.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This is really the power of a hybrid approach,” Huang said. “Our philosophy is very straightforward. Our company is leading the way very much like Mickey Mouse and the elephant dancing together. The small model will perform a very specific task. We are not saying a small model will be good enough…The Mickey Mouse and elephant will be working together as one team.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/open-vs-closed-models-ai-leaders-from-gm-zoom-and-ibm-weigh-trade-offs-for-enterprise-use/</guid><pubDate>Thu, 10 Jul 2025 01:19:35 +0000</pubDate></item><item><title>[NEW] Elon Musk’s xAI launches Grok 4 alongside a $300 monthly subscription (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/elon-musks-xai-launches-grok-4-alongside-a-300-monthly-subscription/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s AI company, xAI, late on Wednesday released its latest flagship AI model, Grok 4, and unveiled a new $300-per-month AI subscription plan, SuperGrok Heavy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok is xAI’s answer to models like OpenAI’s&amp;nbsp;ChatGPT&amp;nbsp;and Google’s&amp;nbsp;Gemini, and can analyze images and respond to questions. In recent months, Grok has become more deeply integrated into Musk’s social network, X, which was recently acquired by xAI. However, that has also put Grok’s misbehavior front and center for millions of users.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The expectations are high for Grok 4. The latest AI model from xAI will be stacked up against OpenAI’s forthcoming AI model, GPT-5, which is expected to launch later this summer.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“With respect to academic questions, Grok 4 is better than PhD level in every subject, no exceptions,” said Elon Musk during a livestream Wednesday night. “At times, it may lack common sense, and it has not yet invented new technologies or discovered new physics, but that is just a matter of time.”&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3026415" height="348" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-09-at-9.09.23PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Musk wore a leather jacket and sat besides xAI leaders to launch Grok 4 (Credit: xAI)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of Grok 4 comes amid a tumultuous week for Elon Musk’s companies. Earlier on Wednesday, Linda Yaccarino stepped down from her role as the CEO of X after roughly two years with the company. X has yet to announce her successor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yaccarino’s departure comes just days after Grok’s official, automated X account responded to users with antisemitic comments criticizing Hollywood’s “Jewish executives” and praising Hitler. xAI had to briefly limit Grok’s account and delete the offensive posts. In response to the incident, xAI appeared to have removed a recently added section from Grok’s public system prompt, a list of instructions for the AI chatbot to follow, that told it not to shy away from making “politically incorrect” claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk and xAI’s leaders largely avoided discussing the incident, instead focusing on Grok 4’s performance and capabilities.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;xAI launched two models on Wednesday: Grok 4 and Grok 4 Heavy — the latter being the company’s “multi-agent version” that offers increased performance. Musk claimed that Grok 4 Heavy spawns multiple agents to work on a problem simultaneously, and then they all compare their work “like a study group” to find the best answer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI claims that Grok 4 shows frontier level performance on several benchmarks, including Humanity’s Last Exam— a challenging test measuring AI’s ability to answer thousands of crowdsourced questions on subjects like math, humanities, and natural science. According to xAI, Grok 4 scored 25.4% on Humanity’s Last Exam without “tools,” outperforming Google’s Gemini 2.5 Pro, which scored 21.6%, and OpenAI’s o3 (high), which scored 21%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI claims that Grok 4 Heavy, with “tools,” was able to achieve a score of 44.4%, outperforming Gemini 2.5 Pro with tools, which scored 26.9%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The nonprofit Arc Prize says that Grok achieves a new state-of-the-art score on its ARC-AGI-2 test — another difficult benchmark that consists of puzzle-like problems where an AI has to identify visual patterns — scoring 16.2%. That’s nearly twice the score of the next best commercial AI model, Claude Opus 4.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3026417" height="367" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-09-at-9.34.45PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Grok 4’s performance on several academic benchmarks (Credit: xAI)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Grok 4 and Grok 4 Heavy, xAI launched its most expensive AI subscription plan yet, a $300-per-month subscription called SuperGrok Heavy. Subscribers to the plan will get an early preview to Grok 4 Heavy, as well as early access to new features. The plan is similar to ultra-premium tiers offered by OpenAI, Google, and Anthropic, but xAI now offers the most expensive subscription among major AI providers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SuperGrok Heavy subscribers may get early access to some new products xAI plans to launch in the coming months. The company said Wednesday that an AI coding model is coming in August, a multi-modal agent in September, and a video generation model in October.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI is releasing Grok 4 through its API in an effort to get developers to build applications with the model. The company notes that xAI’s enterprise sector is only two months old, however, it plans to work with hyperscalers to make Grok available through their cloud platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite Grok’s frontier-level performance on benchmarks, it may prove difficult for xAI to move past its recent mishaps as it tries to pitch Grok to businesses as a real contender to ChatGPT, Claude, and Gemini. Whether businesses are ready to adopt Grok, flaws and all, remains to be seen.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s AI company, xAI, late on Wednesday released its latest flagship AI model, Grok 4, and unveiled a new $300-per-month AI subscription plan, SuperGrok Heavy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok is xAI’s answer to models like OpenAI’s&amp;nbsp;ChatGPT&amp;nbsp;and Google’s&amp;nbsp;Gemini, and can analyze images and respond to questions. In recent months, Grok has become more deeply integrated into Musk’s social network, X, which was recently acquired by xAI. However, that has also put Grok’s misbehavior front and center for millions of users.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The expectations are high for Grok 4. The latest AI model from xAI will be stacked up against OpenAI’s forthcoming AI model, GPT-5, which is expected to launch later this summer.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“With respect to academic questions, Grok 4 is better than PhD level in every subject, no exceptions,” said Elon Musk during a livestream Wednesday night. “At times, it may lack common sense, and it has not yet invented new technologies or discovered new physics, but that is just a matter of time.”&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3026415" height="348" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-09-at-9.09.23PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Musk wore a leather jacket and sat besides xAI leaders to launch Grok 4 (Credit: xAI)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of Grok 4 comes amid a tumultuous week for Elon Musk’s companies. Earlier on Wednesday, Linda Yaccarino stepped down from her role as the CEO of X after roughly two years with the company. X has yet to announce her successor.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yaccarino’s departure comes just days after Grok’s official, automated X account responded to users with antisemitic comments criticizing Hollywood’s “Jewish executives” and praising Hitler. xAI had to briefly limit Grok’s account and delete the offensive posts. In response to the incident, xAI appeared to have removed a recently added section from Grok’s public system prompt, a list of instructions for the AI chatbot to follow, that told it not to shy away from making “politically incorrect” claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk and xAI’s leaders largely avoided discussing the incident, instead focusing on Grok 4’s performance and capabilities.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;xAI launched two models on Wednesday: Grok 4 and Grok 4 Heavy — the latter being the company’s “multi-agent version” that offers increased performance. Musk claimed that Grok 4 Heavy spawns multiple agents to work on a problem simultaneously, and then they all compare their work “like a study group” to find the best answer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI claims that Grok 4 shows frontier level performance on several benchmarks, including Humanity’s Last Exam— a challenging test measuring AI’s ability to answer thousands of crowdsourced questions on subjects like math, humanities, and natural science. According to xAI, Grok 4 scored 25.4% on Humanity’s Last Exam without “tools,” outperforming Google’s Gemini 2.5 Pro, which scored 21.6%, and OpenAI’s o3 (high), which scored 21%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI claims that Grok 4 Heavy, with “tools,” was able to achieve a score of 44.4%, outperforming Gemini 2.5 Pro with tools, which scored 26.9%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The nonprofit Arc Prize says that Grok achieves a new state-of-the-art score on its ARC-AGI-2 test — another difficult benchmark that consists of puzzle-like problems where an AI has to identify visual patterns — scoring 16.2%. That’s nearly twice the score of the next best commercial AI model, Claude Opus 4.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3026417" height="367" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-09-at-9.34.45PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Grok 4’s performance on several academic benchmarks (Credit: xAI)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside Grok 4 and Grok 4 Heavy, xAI launched its most expensive AI subscription plan yet, a $300-per-month subscription called SuperGrok Heavy. Subscribers to the plan will get an early preview to Grok 4 Heavy, as well as early access to new features. The plan is similar to ultra-premium tiers offered by OpenAI, Google, and Anthropic, but xAI now offers the most expensive subscription among major AI providers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SuperGrok Heavy subscribers may get early access to some new products xAI plans to launch in the coming months. The company said Wednesday that an AI coding model is coming in August, a multi-modal agent in September, and a video generation model in October.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI is releasing Grok 4 through its API in an effort to get developers to build applications with the model. The company notes that xAI’s enterprise sector is only two months old, however, it plans to work with hyperscalers to make Grok available through their cloud platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite Grok’s frontier-level performance on benchmarks, it may prove difficult for xAI to move past its recent mishaps as it tries to pitch Grok to businesses as a real contender to ChatGPT, Claude, and Gemini. Whether businesses are ready to adopt Grok, flaws and all, remains to be seen.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/elon-musks-xai-launches-grok-4-alongside-a-300-monthly-subscription/</guid><pubDate>Thu, 10 Jul 2025 05:28:59 +0000</pubDate></item><item><title>[NEW] Google brings its AI-powered marketing tools to India after ‘Google tax’ repeal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/09/google-brings-its-ai-powered-marketing-tools-to-india-after-google-tax-repeal/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has launched a suite of its AI-powered advertising tools in India, which debuted in the U.S. in May, as the repeal of the so-called “Google tax” has made the South Asian market more attractive to global tech firms selling online ads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In March, the Indian government scrapped its 6% levy on digital advertisements, effective in April, as a move to address some of the trade concerns raised by the Trump administration. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The United States Trade Representative had criticized the levy by calling it “discriminatory and unreasonable,” as domestic companies were exempt. Its repeal would ease costs for tech giants, including Google, Meta, and Amazon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Google hosted the local version of its Marketing Live event to debut its AI-powered tools for Indian marketers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the tools is “Generated for You”, available within Product Studio, that identifies relevant content opportunities across shopping catalogs and pre-generates images and videos via AI that merchants can save or publish across Google platforms. Another tool is an opt-in feature called Smart Bidding Exploration in search campaigns, which is built on existing Smart Bidding and uses AI to find newer, qualified leads that merchants wouldn’t have captured or bid on typically. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus,  Google introduced new agentic capabilities in Google Ads and Analytics.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3026299" height="1280" src="https://techcrunch.com/wp-content/uploads/2025/07/agentic-google-analytics.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Agentic capabilities in Google Analytics&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“These agentic tools can learn from advertising inputs, including datasets, landing pages, assets, and real-time campaign performance, to take the guesswork out of achieving business goals,” Dan Taylor, Vice President for Global Ads at Google, said at a virtual media roundtable.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google brought AI Max for Search Campaigns, which aims to enhance search ad campaign performance by identifying more relevant and high-performing search queries by learning from brands’ landing pages, their existing ads, and existing keyword lists.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indian online marketplace for used electronics goods, Cashify, saw its conversions up by 15% and customer acquisition costs reduced by 12% after deploying AI Max during its early testing, Google said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also announced that ads will start appearing on AI Overviews in India later this year. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Additionally, the company has introduced its shoppable connected TV ads on YouTube in India. YouTube’s masthead on mobile will now also start serving ads in the country.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3026301" height="488" src="https://techcrunch.com/wp-content/uploads/2025/07/youtube-shoppable-masthead.jpg" width="1058" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;YouTube Shoppable Masthead now in India&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube on connected TVs has been the most-watched streaming service on television in India over the past year, said Roma Datta Chobey, managing director of Digital Native Industries at Google India.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similarly, the country has been a significant market for YouTube Shorts, with short videos on the platform viewed trillions of times since launch. As many as 87% of Indian consumers watch YouTube or Shorts as part of their shopping journey, Chobey said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India’s digital advertising presence is growing, as the world’s second-largest internet market continues to see more users come online. The country’s digital ad market is projected to grow over 20% year-over-year, reaching nearly $7 billion by the end of 2025, per a recent Dentsu Digital Advertising report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“India is such a thriving digital ecosystem. We have the largest number of users who are actively trying and testing our products. So, that’s really the reason behind us getting these innovations to India faster,” Chobey said, in response to TechCrunch’s question about the timing of the new AI ad tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India has long been a key market for Google, not just because it hosts the company’s largest user base but also due to consistent growth in ad revenues. In fiscal year 2024, Google’s gross ad revenue in India increased 11% year-over-year to ₹312.21 billion ($3.6 billion), while its net advertising revenue rose 18% to ₹27.43 billion ($320 million).&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has launched a suite of its AI-powered advertising tools in India, which debuted in the U.S. in May, as the repeal of the so-called “Google tax” has made the South Asian market more attractive to global tech firms selling online ads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In March, the Indian government scrapped its 6% levy on digital advertisements, effective in April, as a move to address some of the trade concerns raised by the Trump administration. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The United States Trade Representative had criticized the levy by calling it “discriminatory and unreasonable,” as domestic companies were exempt. Its repeal would ease costs for tech giants, including Google, Meta, and Amazon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Google hosted the local version of its Marketing Live event to debut its AI-powered tools for Indian marketers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the tools is “Generated for You”, available within Product Studio, that identifies relevant content opportunities across shopping catalogs and pre-generates images and videos via AI that merchants can save or publish across Google platforms. Another tool is an opt-in feature called Smart Bidding Exploration in search campaigns, which is built on existing Smart Bidding and uses AI to find newer, qualified leads that merchants wouldn’t have captured or bid on typically. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus,  Google introduced new agentic capabilities in Google Ads and Analytics.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3026299" height="1280" src="https://techcrunch.com/wp-content/uploads/2025/07/agentic-google-analytics.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Agentic capabilities in Google Analytics&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“These agentic tools can learn from advertising inputs, including datasets, landing pages, assets, and real-time campaign performance, to take the guesswork out of achieving business goals,” Dan Taylor, Vice President for Global Ads at Google, said at a virtual media roundtable.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Google brought AI Max for Search Campaigns, which aims to enhance search ad campaign performance by identifying more relevant and high-performing search queries by learning from brands’ landing pages, their existing ads, and existing keyword lists.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indian online marketplace for used electronics goods, Cashify, saw its conversions up by 15% and customer acquisition costs reduced by 12% after deploying AI Max during its early testing, Google said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google also announced that ads will start appearing on AI Overviews in India later this year. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Additionally, the company has introduced its shoppable connected TV ads on YouTube in India. YouTube’s masthead on mobile will now also start serving ads in the country.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3026301" height="488" src="https://techcrunch.com/wp-content/uploads/2025/07/youtube-shoppable-masthead.jpg" width="1058" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;YouTube Shoppable Masthead now in India&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube on connected TVs has been the most-watched streaming service on television in India over the past year, said Roma Datta Chobey, managing director of Digital Native Industries at Google India.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similarly, the country has been a significant market for YouTube Shorts, with short videos on the platform viewed trillions of times since launch. As many as 87% of Indian consumers watch YouTube or Shorts as part of their shopping journey, Chobey said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India’s digital advertising presence is growing, as the world’s second-largest internet market continues to see more users come online. The country’s digital ad market is projected to grow over 20% year-over-year, reaching nearly $7 billion by the end of 2025, per a recent Dentsu Digital Advertising report.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“India is such a thriving digital ecosystem. We have the largest number of users who are actively trying and testing our products. So, that’s really the reason behind us getting these innovations to India faster,” Chobey said, in response to TechCrunch’s question about the timing of the new AI ad tools.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India has long been a key market for Google, not just because it hosts the company’s largest user base but also due to consistent growth in ad revenues. In fiscal year 2024, Google’s gross ad revenue in India increased 11% year-over-year to ₹312.21 billion ($3.6 billion), while its net advertising revenue rose 18% to ₹27.43 billion ($320 million).&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/09/google-brings-its-ai-powered-marketing-tools-to-india-after-google-tax-repeal/</guid><pubDate>Thu, 10 Jul 2025 06:30:00 +0000</pubDate></item></channel></rss>