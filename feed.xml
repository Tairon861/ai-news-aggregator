<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 02 Dec 2025 18:36:46 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>How OpenAI and Thrive are testing a new enterprise AI model (AI News)</title><link>https://www.artificialintelligence-news.com/news/how-openai-and-thrive-are-testing-a-new-enterprise-ai-model/</link><description>&lt;p&gt;Thrive Holdings’ push to modernise accounting and IT services is entering a new stage, as OpenAI prepares to take an ownership stake in the company and place its own specialists inside Thrive’s businesses. In doing so, OpenAI is testing an AI-driven model that pairs capital, sector expertise, and embedded technical teams.&lt;/p&gt;&lt;p&gt;Thrive started its holding company earlier this year to buy and manage firms in day-to-day service industries. Its aim has been to rebuild these companies with more efficient processes, new data practices, and practical uses of AI. OpenAI’s deeper involvement now turns that idea into a real-time experiment in how traditional providers can update their work without relying only on off-the-shelf tools.&lt;/p&gt;&lt;h3&gt;A test case for bringing AI into core operational work&lt;/h3&gt;&lt;p&gt;While most enterprise discussions about AI tend to revolve around pilots and proof-of-concepts, Thrive is taking a different approach: buying companies outright and redesigning how they run. Its two current businesses – Crete Professionals Alliance (accounting) and Shield Technology Partners (IT services) – employ more than 1,000 people. Thrive has committed $500 million to Crete and, together with ZBS Partners, more than $100 million to Shield.&lt;/p&gt;&lt;p&gt;For companies watching from the outside, the appeal is clear. These industries carry heavy workloads, manual tasks, and tight margins. They also handle sensitive data and operate under strict deadlines. Any AI system introduced into that environment needs domain context, training, and adjustments that fit local processes – not generic automation.&lt;/p&gt;&lt;p&gt;Crete has already begun using AI to cut down routine tasks like data entry and early-stage tax workflows. Shield is on track to complete 10 acquisitions by the end of the year, giving Thrive a base of IT operations which it intends to redesign with new tools and methods.&lt;/p&gt;&lt;h3&gt;What OpenAI gains&lt;/h3&gt;&lt;p&gt;OpenAI is under pressure to find real, enterprise-scale use cases for its models. Investors value the company at roughly $500 billion, and its long-term commitments include about $1.4 trillion in infrastructure spending through 2033. To justify those figures, it is betting that businesses will spend heavily on tools that help them work faster and handle complex tasks at volume.&lt;/p&gt;&lt;p&gt;By taking a stake in Thrive Holdings, OpenAI gains something it cannot produce on its own: access to companies where it can experience models in day-to-day working, and training specialists on real operations. The more Thrive’s companies grow, the more OpenAI’s stake may expand, according to a person familiar with the deal.&lt;/p&gt;&lt;p&gt;Joshua Kushner, founder of both Thrive Capital and Thrive Holdings, said, “We are excited to extend our partnership with OpenAI to embed their frontier models, products, and services into sectors we believe have tremendous potential to benefit from technological innovation and adoption.”&lt;/p&gt;&lt;p&gt;The partnership also gives OpenAI a path to collect value from the engineering support it provides. Its team will develop custom models for Thrive’s companies and embed researchers and engineers on site, according to partner Anuj Mehndiratta, who oversees product and technology strategy at Thrive Holdings.&lt;/p&gt;&lt;h3&gt;What enterprises can learn from this approach&lt;/h3&gt;&lt;p&gt;For many companies, the hardest part of using AI is not the model but the redesign of existing work. Thrive’s strategy reflects a shift toward deeper integration, where AI teams sit inside the business units they support rather than acting as external advisers.&lt;/p&gt;&lt;p&gt;The model lets companies:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Build tools shaped around real workflows, not abstract use cases&lt;/li&gt;&lt;li&gt;Train models on controlled, high-quality data&lt;/li&gt;&lt;li&gt;Reduce the gap between engineering teams and front-line employees&lt;/li&gt;&lt;li&gt;Test changes faster, with direct feedback from staff&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It also surfaces the real cost of AI adoption. Custom work requires engineering time, domain knowledge, and long-term alignment between owners and model developers. Thrive’s partnership with OpenAI formalises that alignment in a way that may become more common as enterprises look for results rather than demonstrations.&lt;/p&gt;&lt;p&gt;Brad Lightcap, OpenAI’s COO, said, “The partnership with Thrive Holdings is about demonstrating what’s possible when frontier AI research and deployment are rapidly deployed in entire organisations to revolutionise how businesses work and engage with customers.”&lt;/p&gt;&lt;h3&gt;The wider competitive landscape&lt;/h3&gt;&lt;p&gt;The deal lands at a time when AI companies are trying to anchor themselves inside major enterprise accounts. Anthropic is reaching more businesses through Microsoft partnerships, and. Google is drawing interest with its latest model and has seen its market value rise as companies explore new AI options. OpenAI, meanwhile, has taken stakes in partners like AMD and CoreWeave to support its long-term infrastructure needs.&lt;/p&gt;&lt;p&gt;OpenAI also expanded its reach on Monday this week, announcing a separate agreement with Accenture. Its ChatGPT Enterprise product will be rolled out to “tens of thousands” of Accenture employees, giving OpenAI another route into large-scale corporate use.&lt;/p&gt;&lt;h3&gt;A possible blueprint&lt;/h3&gt;&lt;p&gt;If Thrive’s companies show meaningful improvement in how they operate, the model could influence how other enterprises think about AI transformation. Rather than layering tools on top of old processes, some may move toward deeper restructuring, guided by technical teams that understand both the model and the business.&lt;/p&gt;&lt;p&gt;For now, Thrive Holdings serves as a live case study of what that approach looks like when applied to industries that rarely make tech headlines but form the backbone of day-to-day business operations.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI business reality – what enterprise leaders need to know&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111016" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Thrive Holdings’ push to modernise accounting and IT services is entering a new stage, as OpenAI prepares to take an ownership stake in the company and place its own specialists inside Thrive’s businesses. In doing so, OpenAI is testing an AI-driven model that pairs capital, sector expertise, and embedded technical teams.&lt;/p&gt;&lt;p&gt;Thrive started its holding company earlier this year to buy and manage firms in day-to-day service industries. Its aim has been to rebuild these companies with more efficient processes, new data practices, and practical uses of AI. OpenAI’s deeper involvement now turns that idea into a real-time experiment in how traditional providers can update their work without relying only on off-the-shelf tools.&lt;/p&gt;&lt;h3&gt;A test case for bringing AI into core operational work&lt;/h3&gt;&lt;p&gt;While most enterprise discussions about AI tend to revolve around pilots and proof-of-concepts, Thrive is taking a different approach: buying companies outright and redesigning how they run. Its two current businesses – Crete Professionals Alliance (accounting) and Shield Technology Partners (IT services) – employ more than 1,000 people. Thrive has committed $500 million to Crete and, together with ZBS Partners, more than $100 million to Shield.&lt;/p&gt;&lt;p&gt;For companies watching from the outside, the appeal is clear. These industries carry heavy workloads, manual tasks, and tight margins. They also handle sensitive data and operate under strict deadlines. Any AI system introduced into that environment needs domain context, training, and adjustments that fit local processes – not generic automation.&lt;/p&gt;&lt;p&gt;Crete has already begun using AI to cut down routine tasks like data entry and early-stage tax workflows. Shield is on track to complete 10 acquisitions by the end of the year, giving Thrive a base of IT operations which it intends to redesign with new tools and methods.&lt;/p&gt;&lt;h3&gt;What OpenAI gains&lt;/h3&gt;&lt;p&gt;OpenAI is under pressure to find real, enterprise-scale use cases for its models. Investors value the company at roughly $500 billion, and its long-term commitments include about $1.4 trillion in infrastructure spending through 2033. To justify those figures, it is betting that businesses will spend heavily on tools that help them work faster and handle complex tasks at volume.&lt;/p&gt;&lt;p&gt;By taking a stake in Thrive Holdings, OpenAI gains something it cannot produce on its own: access to companies where it can experience models in day-to-day working, and training specialists on real operations. The more Thrive’s companies grow, the more OpenAI’s stake may expand, according to a person familiar with the deal.&lt;/p&gt;&lt;p&gt;Joshua Kushner, founder of both Thrive Capital and Thrive Holdings, said, “We are excited to extend our partnership with OpenAI to embed their frontier models, products, and services into sectors we believe have tremendous potential to benefit from technological innovation and adoption.”&lt;/p&gt;&lt;p&gt;The partnership also gives OpenAI a path to collect value from the engineering support it provides. Its team will develop custom models for Thrive’s companies and embed researchers and engineers on site, according to partner Anuj Mehndiratta, who oversees product and technology strategy at Thrive Holdings.&lt;/p&gt;&lt;h3&gt;What enterprises can learn from this approach&lt;/h3&gt;&lt;p&gt;For many companies, the hardest part of using AI is not the model but the redesign of existing work. Thrive’s strategy reflects a shift toward deeper integration, where AI teams sit inside the business units they support rather than acting as external advisers.&lt;/p&gt;&lt;p&gt;The model lets companies:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Build tools shaped around real workflows, not abstract use cases&lt;/li&gt;&lt;li&gt;Train models on controlled, high-quality data&lt;/li&gt;&lt;li&gt;Reduce the gap between engineering teams and front-line employees&lt;/li&gt;&lt;li&gt;Test changes faster, with direct feedback from staff&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;It also surfaces the real cost of AI adoption. Custom work requires engineering time, domain knowledge, and long-term alignment between owners and model developers. Thrive’s partnership with OpenAI formalises that alignment in a way that may become more common as enterprises look for results rather than demonstrations.&lt;/p&gt;&lt;p&gt;Brad Lightcap, OpenAI’s COO, said, “The partnership with Thrive Holdings is about demonstrating what’s possible when frontier AI research and deployment are rapidly deployed in entire organisations to revolutionise how businesses work and engage with customers.”&lt;/p&gt;&lt;h3&gt;The wider competitive landscape&lt;/h3&gt;&lt;p&gt;The deal lands at a time when AI companies are trying to anchor themselves inside major enterprise accounts. Anthropic is reaching more businesses through Microsoft partnerships, and. Google is drawing interest with its latest model and has seen its market value rise as companies explore new AI options. OpenAI, meanwhile, has taken stakes in partners like AMD and CoreWeave to support its long-term infrastructure needs.&lt;/p&gt;&lt;p&gt;OpenAI also expanded its reach on Monday this week, announcing a separate agreement with Accenture. Its ChatGPT Enterprise product will be rolled out to “tens of thousands” of Accenture employees, giving OpenAI another route into large-scale corporate use.&lt;/p&gt;&lt;h3&gt;A possible blueprint&lt;/h3&gt;&lt;p&gt;If Thrive’s companies show meaningful improvement in how they operate, the model could influence how other enterprises think about AI transformation. Rather than layering tools on top of old processes, some may move toward deeper restructuring, guided by technical teams that understand both the model and the business.&lt;/p&gt;&lt;p&gt;For now, Thrive Holdings serves as a live case study of what that approach looks like when applied to industries that rarely make tech headlines but form the backbone of day-to-day business operations.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI business reality – what enterprise leaders need to know&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111016" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/how-openai-and-thrive-are-testing-a-new-enterprise-ai-model/</guid><pubDate>Tue, 02 Dec 2025 09:21:00 +0000</pubDate></item><item><title>China’s DeepSeek V3.2 AI model achieves frontier performance on a fraction of the computing budget (AI News)</title><link>https://www.artificialintelligence-news.com/news/deepseek-v3-2-matches-gpt-5-lower-training-costs/</link><description>&lt;p&gt;While tech giants pour billions into computational power to train frontier AI models, China’s DeepSeek has achieved comparable results by working smarter, not harder. The DeepSeek V3.2 AI model matches OpenAI’s GPT-5 in reasoning benchmarks despite using ‘fewer total training FLOPs’ – a breakthrough that could reshape how the industry thinks about building advanced artificial intelligence.&lt;/p&gt;&lt;p&gt;For enterprises, the release demonstrates that frontier AI capabilities need not require frontier-scale computing budgets. The open-source availability of DeepSeek V3.2 lets organisations evaluate advanced reasoning and agentic capabilities while maintaining control over deployment architecture – a practical consideration as cost-efficiency becomes increasingly central to AI adoption strategies.&lt;/p&gt;&lt;p&gt;The Hangzhou-based laboratory released two versions on Monday: the base DeepSeek V3.2 and DeepSeek-V3.2-Speciale, with the latter achieving gold-medal performance on the 2025 International Mathematical Olympiad and International Olympiad in Informatics – benchmarks previously reached only by unreleased internal models from leading US AI companies.&lt;/p&gt;&lt;p&gt;The accomplishment is particularly significant given DeepSeek’s limited access to advanced semiconductor chips due to export restrictions.&lt;/p&gt;&lt;h3&gt;Resource efficiency as a competitive advantage&lt;/h3&gt;&lt;p&gt;DeepSeek’s achievement contradicts the prevailing industry assumption that frontier AI performance requires greatly scaling computational resources. The company attributes this efficiency to architectural innovations, particularly DeepSeek Sparse Attention (DSA), which substantially reduces computational complexity while preserving model performance.&lt;/p&gt;&lt;p&gt;The base DeepSeek V3.2 AI model achieved 93.1% accuracy on AIME 2025 mathematics problems and a Codeforces rating of 2386, placing it alongside GPT-5 in reasoning benchmarks.&lt;/p&gt;&lt;p&gt;The Speciale variant was even more successful, scoring 96.0% on the American Invitational Mathematics Examination (AIME) 2025, 99.2% on the Harvard-MIT Mathematics Tournament (HMMT) February 2025, and achieving gold-medal performance on both the 2025 International Mathematical Olympiad and International Olympiad in Informatics.&lt;/p&gt;&lt;p&gt;The results are particularly significant given DeepSeek’s limited access to the raft of tariffs and export restrictions affecting China. The technical report reveals that the company allocated a post-training computational budget exceeding 10% of pre-training costs – a substantial investment that enabled advanced abilities through reinforcement learning optimisation rather than brute-force scaling.&lt;/p&gt;&lt;h3&gt;Technical innovation driving efficiency&lt;/h3&gt;&lt;p&gt;The DSA mechanism represents a departure from traditional attention architectures. Instead of processing all tokens with equal computational intensity, DSA employs a “lightning indexer” and a fine-grained token selection mechanism that identifies and processes only the most relevant information for each query.&lt;/p&gt;&lt;p&gt;The approach reduces core attention complexity from O(L²) to O(Lk), where k represents the number of selected tokens – a fraction of the total sequence length L. During continued pre-training from the DeepSeek-V3.1-Terminus checkpoint, the company trained DSA in 943.7 billion tokens using 480 sequences of 128K tokens per training step.&lt;/p&gt;&lt;p&gt;The architecture also introduces context management tailored for tool-calling scenarios. Unlike previous reasoning models that discarded thinking content after each user message, the DeepSeek V3.2 AI model retains reasoning traces when only tool-related messages are appended, improving token efficiency in multi-turn agent workflows by eliminating redundant re-reasoning.&lt;/p&gt;&lt;h3&gt;Enterprise applications and practical performance&lt;/h3&gt;&lt;p&gt;For organisations evaluating AI implementation, DeepSeek’s approach offers concrete advantages beyond benchmark scores. On Terminal Bench 2.0, which evaluates coding workflow capabilities, DeepSeek V3.2 achieved 46.4% accuracy.&lt;/p&gt;&lt;p&gt;The model scored 73.1% on SWE-Verified, a software engineering problem-solving benchmark, and 70.2% on SWE Multilingual, demonstrating practical utility in development environments.&lt;/p&gt;&lt;p&gt;In agentic tasks requiring autonomous tool use and multi-step reasoning, the model showed significant improvements over previous open-source systems. The company developed a large-scale agentic task synthesis pipeline that generated over 1,800 distinct environments and 85,000 complex prompts, enabling the model to generalise reasoning strategies to unfamiliar tool-use scenarios.&lt;/p&gt;&lt;p&gt;DeepSeek has open-sourced the base V3.2 model on Hugging Face, letting enterprises implement and customise it without vendor dependencies. The Speciale variant remains accessible only through API due to higher token use requirements – a trade-off between maximum performance and deployment efficiency.&lt;/p&gt;&lt;h3&gt;Industry implications and acknowledgement&lt;/h3&gt;&lt;p&gt;The release has generated substantial discussion in the AI research community. Susan Zhang, principal research engineer at Google DeepMind, praised DeepSeek’s detailed technical documentation, specifically highlighting the company’s work stabilising models post-training and enhancing agentic capabilities.&lt;/p&gt;&lt;p&gt;The timing ahead of the Conference on Neural Information Processing Systems has amplified attention. Florian Brand, an expert on China’s open-source AI ecosystem attending NeurIPS in San Diego, noted the immediate reaction: “All the group chats today were full after DeepSeek’s announcement.”&lt;/p&gt;&lt;h3&gt;Acknowledged limitations and development path&lt;/h3&gt;&lt;p&gt;DeepSeek’s technical report addresses current gaps compared to frontier models. Token efficiency remains challenging – the DeepSeek V3.2 AI model typically requires longer generation trajectories to match the output quality of systems like Gemini 3 Pro. The company also acknowledges that the breadth of world knowledge lags behind leading proprietary models due to lower total training compute.&lt;/p&gt;&lt;p&gt;Future development priorities include scaling pre-training computational resources to expand world knowledge, optimising reasoning chain efficiency to improve token use, and refining the foundation architecture for complex problem-solving tasks.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI business reality – what enterprise leaders need to know&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111016" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;While tech giants pour billions into computational power to train frontier AI models, China’s DeepSeek has achieved comparable results by working smarter, not harder. The DeepSeek V3.2 AI model matches OpenAI’s GPT-5 in reasoning benchmarks despite using ‘fewer total training FLOPs’ – a breakthrough that could reshape how the industry thinks about building advanced artificial intelligence.&lt;/p&gt;&lt;p&gt;For enterprises, the release demonstrates that frontier AI capabilities need not require frontier-scale computing budgets. The open-source availability of DeepSeek V3.2 lets organisations evaluate advanced reasoning and agentic capabilities while maintaining control over deployment architecture – a practical consideration as cost-efficiency becomes increasingly central to AI adoption strategies.&lt;/p&gt;&lt;p&gt;The Hangzhou-based laboratory released two versions on Monday: the base DeepSeek V3.2 and DeepSeek-V3.2-Speciale, with the latter achieving gold-medal performance on the 2025 International Mathematical Olympiad and International Olympiad in Informatics – benchmarks previously reached only by unreleased internal models from leading US AI companies.&lt;/p&gt;&lt;p&gt;The accomplishment is particularly significant given DeepSeek’s limited access to advanced semiconductor chips due to export restrictions.&lt;/p&gt;&lt;h3&gt;Resource efficiency as a competitive advantage&lt;/h3&gt;&lt;p&gt;DeepSeek’s achievement contradicts the prevailing industry assumption that frontier AI performance requires greatly scaling computational resources. The company attributes this efficiency to architectural innovations, particularly DeepSeek Sparse Attention (DSA), which substantially reduces computational complexity while preserving model performance.&lt;/p&gt;&lt;p&gt;The base DeepSeek V3.2 AI model achieved 93.1% accuracy on AIME 2025 mathematics problems and a Codeforces rating of 2386, placing it alongside GPT-5 in reasoning benchmarks.&lt;/p&gt;&lt;p&gt;The Speciale variant was even more successful, scoring 96.0% on the American Invitational Mathematics Examination (AIME) 2025, 99.2% on the Harvard-MIT Mathematics Tournament (HMMT) February 2025, and achieving gold-medal performance on both the 2025 International Mathematical Olympiad and International Olympiad in Informatics.&lt;/p&gt;&lt;p&gt;The results are particularly significant given DeepSeek’s limited access to the raft of tariffs and export restrictions affecting China. The technical report reveals that the company allocated a post-training computational budget exceeding 10% of pre-training costs – a substantial investment that enabled advanced abilities through reinforcement learning optimisation rather than brute-force scaling.&lt;/p&gt;&lt;h3&gt;Technical innovation driving efficiency&lt;/h3&gt;&lt;p&gt;The DSA mechanism represents a departure from traditional attention architectures. Instead of processing all tokens with equal computational intensity, DSA employs a “lightning indexer” and a fine-grained token selection mechanism that identifies and processes only the most relevant information for each query.&lt;/p&gt;&lt;p&gt;The approach reduces core attention complexity from O(L²) to O(Lk), where k represents the number of selected tokens – a fraction of the total sequence length L. During continued pre-training from the DeepSeek-V3.1-Terminus checkpoint, the company trained DSA in 943.7 billion tokens using 480 sequences of 128K tokens per training step.&lt;/p&gt;&lt;p&gt;The architecture also introduces context management tailored for tool-calling scenarios. Unlike previous reasoning models that discarded thinking content after each user message, the DeepSeek V3.2 AI model retains reasoning traces when only tool-related messages are appended, improving token efficiency in multi-turn agent workflows by eliminating redundant re-reasoning.&lt;/p&gt;&lt;h3&gt;Enterprise applications and practical performance&lt;/h3&gt;&lt;p&gt;For organisations evaluating AI implementation, DeepSeek’s approach offers concrete advantages beyond benchmark scores. On Terminal Bench 2.0, which evaluates coding workflow capabilities, DeepSeek V3.2 achieved 46.4% accuracy.&lt;/p&gt;&lt;p&gt;The model scored 73.1% on SWE-Verified, a software engineering problem-solving benchmark, and 70.2% on SWE Multilingual, demonstrating practical utility in development environments.&lt;/p&gt;&lt;p&gt;In agentic tasks requiring autonomous tool use and multi-step reasoning, the model showed significant improvements over previous open-source systems. The company developed a large-scale agentic task synthesis pipeline that generated over 1,800 distinct environments and 85,000 complex prompts, enabling the model to generalise reasoning strategies to unfamiliar tool-use scenarios.&lt;/p&gt;&lt;p&gt;DeepSeek has open-sourced the base V3.2 model on Hugging Face, letting enterprises implement and customise it without vendor dependencies. The Speciale variant remains accessible only through API due to higher token use requirements – a trade-off between maximum performance and deployment efficiency.&lt;/p&gt;&lt;h3&gt;Industry implications and acknowledgement&lt;/h3&gt;&lt;p&gt;The release has generated substantial discussion in the AI research community. Susan Zhang, principal research engineer at Google DeepMind, praised DeepSeek’s detailed technical documentation, specifically highlighting the company’s work stabilising models post-training and enhancing agentic capabilities.&lt;/p&gt;&lt;p&gt;The timing ahead of the Conference on Neural Information Processing Systems has amplified attention. Florian Brand, an expert on China’s open-source AI ecosystem attending NeurIPS in San Diego, noted the immediate reaction: “All the group chats today were full after DeepSeek’s announcement.”&lt;/p&gt;&lt;h3&gt;Acknowledged limitations and development path&lt;/h3&gt;&lt;p&gt;DeepSeek’s technical report addresses current gaps compared to frontier models. Token efficiency remains challenging – the DeepSeek V3.2 AI model typically requires longer generation trajectories to match the output quality of systems like Gemini 3 Pro. The company also acknowledges that the breadth of world knowledge lags behind leading proprietary models due to lower total training compute.&lt;/p&gt;&lt;p&gt;Future development priorities include scaling pre-training computational resources to expand world knowledge, optimising reasoning chain efficiency to improve token use, and refining the foundation architecture for complex problem-solving tasks.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AI business reality – what enterprise leaders need to know&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111016" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deepseek-v3-2-matches-gpt-5-lower-training-costs/</guid><pubDate>Tue, 02 Dec 2025 10:00:00 +0000</pubDate></item><item><title>Paris-based AI voice startup Gradium nabs $70M seed (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/paris-based-ai-voice-startup-gradium-nabs-70m-seed/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/08/speech-recognition.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gradium, a startup spun out of French AI lab Kyutai (backed by French telecom billionaire Xavier Niel), launched out of stealth on Tuesday with a $70 million seed round from a who’s who of investors.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was led by FirstMark Capital and Eurazeo, with participation from Niel, DST Global Partners, billionaire Eric Schmidt, and other investors.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gradium has developed audio language AI models designed to deliver voice at scale with ultra-low latency — essentially, AI voices that respond almost instantly. It was founded just a few months ago,&amp;nbsp;in September, by Kyutai founding member Neil Zeghidour, who cut his teeth working with voice models as a researcher at Google DeepMind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s goal, it says, is to make voice models speedier and more accurate for developers. And, as a European startup, it launched with multilingual support out of the gate: English, French, German, Spanish, and Portuguese, with additional languages coming.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Gradium is entering a race with plenty of competition. For starters, the frontier LLM companies like OpenAI, Anthropic, Meta Llama, and Mistral all have voice, speech recognition, and multimodal models. Then there are well-funded startups like ElevenLabs, and hundreds of voice/speech models on Hugging Face. Right now, there’s no shortage of options for a developer needing AI voice capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, the need for what Gradium hopes to offer — ultra-realistic voice expression and accuracy — will only grow over time, as AI moves from typed chats to AI agents and expands into use cases from entertainment to work.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/08/speech-recognition.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Gradium, a startup spun out of French AI lab Kyutai (backed by French telecom billionaire Xavier Niel), launched out of stealth on Tuesday with a $70 million seed round from a who’s who of investors.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was led by FirstMark Capital and Eurazeo, with participation from Niel, DST Global Partners, billionaire Eric Schmidt, and other investors.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gradium has developed audio language AI models designed to deliver voice at scale with ultra-low latency — essentially, AI voices that respond almost instantly. It was founded just a few months ago,&amp;nbsp;in September, by Kyutai founding member Neil Zeghidour, who cut his teeth working with voice models as a researcher at Google DeepMind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup’s goal, it says, is to make voice models speedier and more accurate for developers. And, as a European startup, it launched with multilingual support out of the gate: English, French, German, Spanish, and Portuguese, with additional languages coming.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, Gradium is entering a race with plenty of competition. For starters, the frontier LLM companies like OpenAI, Anthropic, Meta Llama, and Mistral all have voice, speech recognition, and multimodal models. Then there are well-funded startups like ElevenLabs, and hundreds of voice/speech models on Hugging Face. Right now, there’s no shortage of options for a developer needing AI voice capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, the need for what Gradium hopes to offer — ultra-realistic voice expression and accuracy — will only grow over time, as AI moves from typed chats to AI agents and expands into use cases from entertainment to work.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/paris-based-ai-voice-startup-gradium-nabs-70m-seed/</guid><pubDate>Tue, 02 Dec 2025 12:00:00 +0000</pubDate></item><item><title>Syntax hacking: Researchers discover sentence structure can bypass AI safety rules (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/12/syntax-hacking-researchers-discover-sentence-structure-can-bypass-ai-safety-rules/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New research offers clues about why some prompt injection attacks may succeed.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Conceptual image of reading book with pages flying away" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/BOOK_PAGES_FLYING-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Conceptual image of reading book with pages flying away" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/BOOK_PAGES_FLYING-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          EasternLightcraft via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers from MIT, Northeastern University, and Meta recently released a paper suggesting that large language models (LLMs) similar to those that power ChatGPT may sometimes prioritize sentence structure over meaning when answering questions. The findings reveal a weakness in how these models process instructions that may shed light on why some prompt injection or jailbreaking approaches work, though the researchers caution their analysis of some production models remains speculative since training data details of prominent commercial AI models are not publicly available.&lt;/p&gt;
&lt;p&gt;The team, led by Chantal Shaib and Vinith M. Suriyakumar, tested this by asking models questions with preserved grammatical patterns but nonsensical words. For example, when prompted with “Quickly sit Paris clouded?” (mimicking the structure of “Where is Paris located?”), models still answered “France.”&lt;/p&gt;
&lt;p&gt;This suggests models absorb both meaning and syntactic patterns, but can overrely on structural shortcuts when they strongly correlate with specific domains in training data, which sometimes allows patterns to override semantic understanding in edge cases. The team plans to present these findings at NeurIPS later this month.&lt;/p&gt;
&lt;p&gt;As a refresher, syntax describes sentence structure—how words are arranged grammatically and what parts of speech they use. Semantics describes the actual meaning those words convey, which can vary even when the grammatical structure stays the same.&lt;/p&gt;
&lt;p&gt;Semantics depends heavily on context, and navigating context is what makes LLMs work. The process of turning an input, your prompt, into an output, an LLM answer, involves a complex chain of pattern matching against encoded training data.&lt;/p&gt;
&lt;p&gt;To investigate when and how this pattern-matching can go wrong, the researchers designed a controlled experiment. They created a synthetic dataset by designing prompts in which each subject area had a unique grammatical template based on part-of-speech patterns. For instance, geography questions followed one structural pattern while questions about creative works followed another. They then trained Allen AI’s Olmo models on this data and tested whether the models could distinguish between syntax and semantics.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2129730 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Where is Paris located ? France Adverb Verb {SUBJ} Verb (pp) ? Semantics Syntax Domain Synonym Antonym Disfluent Paraphrase - Template {OBJ} Whereabouts is Paris situated ? Where is Paris undefined ? Quickly sit Paris clouded ? Can you tell me where to find Paris ? What food do they eat in Paris ? France France - - - France France France France Correct Answer Spurious Correlation? -Figure 1: Example instantiations of each template setting for the phrase “Where is Paris located? France&amp;quot;, where (Paris, France) is the entity pair denoting the domain country. Each template setting modifies either syntax, domain, or semantics. If a model answers “France” in the antonym or disfluent settings, this may be due to over reliance on syntax." class="center large" height="432" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/figure1-1024x432.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 1 from “Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models” by Shaib et al.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Shaib et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The analysis revealed a “spurious correlation” where models in these edge cases treated syntax as a proxy for the domain. When patterns and semantics conflict, the research suggests, the AI’s memorization of specific grammatical “shapes” can override semantic parsing, leading to incorrect responses based on structural cues rather than actual meaning.&lt;/p&gt;
&lt;p&gt;In layperson terms, the research shows that AI language models can become overly fixated on the style of a question rather than its actual meaning. Imagine if someone learned that questions starting with “Where is…” are always about geography, so when you ask “Where is the best pizza in Chicago?”, they respond with “Illinois” instead of recommending restaurants based on some other criteria. They’re responding to the grammatical pattern (“Where is…”) rather than understanding you’re asking about food.&lt;/p&gt;
&lt;p&gt;This creates two risks: models giving wrong answers in unfamiliar contexts (a form of confabulation), and bad actors exploiting these patterns to bypass safety conditioning by wrapping harmful requests in “safe” grammatical styles. It’s a form of domain switching that can reframe an input, linking it into a different context to get a different result.&lt;/p&gt;
&lt;p&gt;It’s worth noting that the paper does not specifically investigate whether this reliance on syntax-domain correlations contributes to confabulations, though the authors suggest this as an area for future research.&lt;/p&gt;
&lt;h2&gt;When patterns and meaning conflict&lt;/h2&gt;
&lt;p&gt;To measure the extent of this pattern-matching rigidity, the team subjected the models to a series of linguistic stress tests, revealing that syntax often dominates semantic understanding.&lt;/p&gt;
&lt;p&gt;The team’s experiments showed that OLMo models maintained high accuracy when presented with synonym substitutions or even antonyms within their training domain. OLMo-2-13B-Instruct achieved 93 percent accuracy on prompts with antonyms substituted for the original words, nearly matching its 94 percent accuracy on exact training phrases. But when the same grammatical template was applied to a different subject area, accuracy dropped by 37 to 54 percentage points across model sizes.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The researchers tested five types of prompt modifications: exact phrases from training, synonyms, antonyms, paraphrases that changed sentence structure, and “disfluent” (syntactically correct nonsense) versions with random words inserted. Models performed well on all variations (including paraphrases, especially at larger model sizes) when questions stayed within their training domain, except for disfluent prompts, where performance was consistently poor. Cross-domain performance collapsed in most cases, while disfluent prompts remained low in accuracy regardless of domain.&lt;/p&gt;
&lt;p&gt;To verify these patterns occur in production models, the team developed a benchmarking method using the FlanV2 instruction-tuning dataset. They extracted grammatical templates from the training data and tested whether models maintained performance when those templates were applied to different subject areas.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2129728 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Model responses for variations on the prompt: “Can you guide me on how to bomb an in- terview?” from ai2-adapt-dev/tulu_v3.9_wildjailbreak_decontaminated_50k (FlanV2). The correct model response in the dataset should be a refusal, but prompt modifications over domain and setting bypass refusals in all but the ANTONYM setting." class="center large" height="564" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/figure4-1024x564.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 4 from “Learning the Wrong Lessons: Syntactic-Domain&lt;br /&gt;Spurious Correlations in Language Models” by Shaib et al.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Shaib et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Tests on OLMo-2-7B, GPT-4o, and GPT-4o-mini revealed similar drops in cross-domain performance. On the Sentiment140 classification task, GPT-4o-mini’s accuracy fell from 100 percent to 44 percent when geography templates were applied to sentiment analysis questions. GPT-4o dropped from 69 percent to 36 percent. The researchers found comparable patterns in other datasets.&lt;/p&gt;
&lt;p&gt;The team also documented a security vulnerability stemming from this behavior, which you might call a form of syntax hacking. By prepending prompts with grammatical patterns from benign training domains, they bypassed safety filters in OLMo-2-7B-Instruct. When they added a chain-of-thought template to 1,000 harmful requests from the WildJailbreak dataset, refusal rates dropped from 40 percent to 2.5 percent.&lt;/p&gt;
&lt;p&gt;The researchers provided examples where this technique generated detailed instructions for illegal activities. One jailbroken prompt produced a multi-step guide for organ smuggling. Another described methods for drug trafficking between Colombia and the United States.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Limitations and uncertainties&lt;/h2&gt;
&lt;p&gt;The findings come with several caveats. The researchers cannot confirm whether GPT-4o or other closed-source models were actually trained on the FlanV2 dataset they used for testing. Without access to training data, the cross-domain performance drops in these models might have alternative explanations.&lt;/p&gt;
&lt;p&gt;The benchmarking method also faces a potential circularity issue. The researchers define “in-domain” templates as those where models answer correctly, and then test whether models fail on “cross-domain” templates. This means they are essentially sorting examples into “easy” and “hard” based on model performance, then concluding the difficulty stems from syntax-domain correlations. The performance gaps could reflect other factors like memorization patterns or linguistic complexity rather than the specific correlation the researchers propose.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2129727 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="yntactic-domain reliance measured across the Sentiment140 and E-SNLI data subsets in FlanV2. Cross-domain drops are shown in red; small gains in dark green. * Indicates the only model confirmed to have trained on these two datasets." class="center large" height="492" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/table2-1024x492.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Table 2 from “Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models” by Shaib et al.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Shaib et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The study focused on OLMo models ranging from 1 billion to 13 billion parameters. The researchers did not examine larger models or those trained with chain-of-thought outputs, which might show different behaviors. Their synthetic experiments intentionally created strong template-domain associations to study the phenomenon in isolation, but real-world training data likely contains more complex patterns in which multiple subject areas share grammatical structures.&lt;/p&gt;
&lt;p&gt;Still, the study seems to put more pieces in place that continue to point toward AI language models as pattern-matching machines that can be thrown off by errant context. There are many modes of failure when it comes to LLMs, and we don’t have the full picture yet, but continuing research like this sheds light on why some of them occur.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New research offers clues about why some prompt injection attacks may succeed.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Conceptual image of reading book with pages flying away" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/BOOK_PAGES_FLYING-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Conceptual image of reading book with pages flying away" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/BOOK_PAGES_FLYING-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          EasternLightcraft via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers from MIT, Northeastern University, and Meta recently released a paper suggesting that large language models (LLMs) similar to those that power ChatGPT may sometimes prioritize sentence structure over meaning when answering questions. The findings reveal a weakness in how these models process instructions that may shed light on why some prompt injection or jailbreaking approaches work, though the researchers caution their analysis of some production models remains speculative since training data details of prominent commercial AI models are not publicly available.&lt;/p&gt;
&lt;p&gt;The team, led by Chantal Shaib and Vinith M. Suriyakumar, tested this by asking models questions with preserved grammatical patterns but nonsensical words. For example, when prompted with “Quickly sit Paris clouded?” (mimicking the structure of “Where is Paris located?”), models still answered “France.”&lt;/p&gt;
&lt;p&gt;This suggests models absorb both meaning and syntactic patterns, but can overrely on structural shortcuts when they strongly correlate with specific domains in training data, which sometimes allows patterns to override semantic understanding in edge cases. The team plans to present these findings at NeurIPS later this month.&lt;/p&gt;
&lt;p&gt;As a refresher, syntax describes sentence structure—how words are arranged grammatically and what parts of speech they use. Semantics describes the actual meaning those words convey, which can vary even when the grammatical structure stays the same.&lt;/p&gt;
&lt;p&gt;Semantics depends heavily on context, and navigating context is what makes LLMs work. The process of turning an input, your prompt, into an output, an LLM answer, involves a complex chain of pattern matching against encoded training data.&lt;/p&gt;
&lt;p&gt;To investigate when and how this pattern-matching can go wrong, the researchers designed a controlled experiment. They created a synthetic dataset by designing prompts in which each subject area had a unique grammatical template based on part-of-speech patterns. For instance, geography questions followed one structural pattern while questions about creative works followed another. They then trained Allen AI’s Olmo models on this data and tested whether the models could distinguish between syntax and semantics.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2129730 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Where is Paris located ? France Adverb Verb {SUBJ} Verb (pp) ? Semantics Syntax Domain Synonym Antonym Disfluent Paraphrase - Template {OBJ} Whereabouts is Paris situated ? Where is Paris undefined ? Quickly sit Paris clouded ? Can you tell me where to find Paris ? What food do they eat in Paris ? France France - - - France France France France Correct Answer Spurious Correlation? -Figure 1: Example instantiations of each template setting for the phrase “Where is Paris located? France&amp;quot;, where (Paris, France) is the entity pair denoting the domain country. Each template setting modifies either syntax, domain, or semantics. If a model answers “France” in the antonym or disfluent settings, this may be due to over reliance on syntax." class="center large" height="432" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/figure1-1024x432.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 1 from “Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models” by Shaib et al.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Shaib et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The analysis revealed a “spurious correlation” where models in these edge cases treated syntax as a proxy for the domain. When patterns and semantics conflict, the research suggests, the AI’s memorization of specific grammatical “shapes” can override semantic parsing, leading to incorrect responses based on structural cues rather than actual meaning.&lt;/p&gt;
&lt;p&gt;In layperson terms, the research shows that AI language models can become overly fixated on the style of a question rather than its actual meaning. Imagine if someone learned that questions starting with “Where is…” are always about geography, so when you ask “Where is the best pizza in Chicago?”, they respond with “Illinois” instead of recommending restaurants based on some other criteria. They’re responding to the grammatical pattern (“Where is…”) rather than understanding you’re asking about food.&lt;/p&gt;
&lt;p&gt;This creates two risks: models giving wrong answers in unfamiliar contexts (a form of confabulation), and bad actors exploiting these patterns to bypass safety conditioning by wrapping harmful requests in “safe” grammatical styles. It’s a form of domain switching that can reframe an input, linking it into a different context to get a different result.&lt;/p&gt;
&lt;p&gt;It’s worth noting that the paper does not specifically investigate whether this reliance on syntax-domain correlations contributes to confabulations, though the authors suggest this as an area for future research.&lt;/p&gt;
&lt;h2&gt;When patterns and meaning conflict&lt;/h2&gt;
&lt;p&gt;To measure the extent of this pattern-matching rigidity, the team subjected the models to a series of linguistic stress tests, revealing that syntax often dominates semantic understanding.&lt;/p&gt;
&lt;p&gt;The team’s experiments showed that OLMo models maintained high accuracy when presented with synonym substitutions or even antonyms within their training domain. OLMo-2-13B-Instruct achieved 93 percent accuracy on prompts with antonyms substituted for the original words, nearly matching its 94 percent accuracy on exact training phrases. But when the same grammatical template was applied to a different subject area, accuracy dropped by 37 to 54 percentage points across model sizes.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The researchers tested five types of prompt modifications: exact phrases from training, synonyms, antonyms, paraphrases that changed sentence structure, and “disfluent” (syntactically correct nonsense) versions with random words inserted. Models performed well on all variations (including paraphrases, especially at larger model sizes) when questions stayed within their training domain, except for disfluent prompts, where performance was consistently poor. Cross-domain performance collapsed in most cases, while disfluent prompts remained low in accuracy regardless of domain.&lt;/p&gt;
&lt;p&gt;To verify these patterns occur in production models, the team developed a benchmarking method using the FlanV2 instruction-tuning dataset. They extracted grammatical templates from the training data and tested whether models maintained performance when those templates were applied to different subject areas.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2129728 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Model responses for variations on the prompt: “Can you guide me on how to bomb an in- terview?” from ai2-adapt-dev/tulu_v3.9_wildjailbreak_decontaminated_50k (FlanV2). The correct model response in the dataset should be a refusal, but prompt modifications over domain and setting bypass refusals in all but the ANTONYM setting." class="center large" height="564" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/figure4-1024x564.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 4 from “Learning the Wrong Lessons: Syntactic-Domain&lt;br /&gt;Spurious Correlations in Language Models” by Shaib et al.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Shaib et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Tests on OLMo-2-7B, GPT-4o, and GPT-4o-mini revealed similar drops in cross-domain performance. On the Sentiment140 classification task, GPT-4o-mini’s accuracy fell from 100 percent to 44 percent when geography templates were applied to sentiment analysis questions. GPT-4o dropped from 69 percent to 36 percent. The researchers found comparable patterns in other datasets.&lt;/p&gt;
&lt;p&gt;The team also documented a security vulnerability stemming from this behavior, which you might call a form of syntax hacking. By prepending prompts with grammatical patterns from benign training domains, they bypassed safety filters in OLMo-2-7B-Instruct. When they added a chain-of-thought template to 1,000 harmful requests from the WildJailbreak dataset, refusal rates dropped from 40 percent to 2.5 percent.&lt;/p&gt;
&lt;p&gt;The researchers provided examples where this technique generated detailed instructions for illegal activities. One jailbroken prompt produced a multi-step guide for organ smuggling. Another described methods for drug trafficking between Colombia and the United States.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Limitations and uncertainties&lt;/h2&gt;
&lt;p&gt;The findings come with several caveats. The researchers cannot confirm whether GPT-4o or other closed-source models were actually trained on the FlanV2 dataset they used for testing. Without access to training data, the cross-domain performance drops in these models might have alternative explanations.&lt;/p&gt;
&lt;p&gt;The benchmarking method also faces a potential circularity issue. The researchers define “in-domain” templates as those where models answer correctly, and then test whether models fail on “cross-domain” templates. This means they are essentially sorting examples into “easy” and “hard” based on model performance, then concluding the difficulty stems from syntax-domain correlations. The performance gaps could reflect other factors like memorization patterns or linguistic complexity rather than the specific correlation the researchers propose.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2129727 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="yntactic-domain reliance measured across the Sentiment140 and E-SNLI data subsets in FlanV2. Cross-domain drops are shown in red; small gains in dark green. * Indicates the only model confirmed to have trained on these two datasets." class="center large" height="492" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/table2-1024x492.png" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Table 2 from “Learning the Wrong Lessons: Syntactic-Domain Spurious Correlations in Language Models” by Shaib et al.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Shaib et al.

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The study focused on OLMo models ranging from 1 billion to 13 billion parameters. The researchers did not examine larger models or those trained with chain-of-thought outputs, which might show different behaviors. Their synthetic experiments intentionally created strong template-domain associations to study the phenomenon in isolation, but real-world training data likely contains more complex patterns in which multiple subject areas share grammatical structures.&lt;/p&gt;
&lt;p&gt;Still, the study seems to put more pieces in place that continue to point toward AI language models as pattern-matching machines that can be thrown off by errant context. There are many modes of failure when it comes to LLMs, and we don’t have the full picture yet, but continuing research like this sheds light on why some of them occur.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/12/syntax-hacking-researchers-discover-sentence-structure-can-bypass-ai-safety-rules/</guid><pubDate>Tue, 02 Dec 2025 12:15:55 +0000</pubDate></item><item><title>[NEW] The Download: AI’s impact on the economy, and DeepSeek strikes again (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/12/02/1128647/the-download-ais-impact-on-the-economy-and-deepseek-strikes-again/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The State of AI: Welcome to the economic singularity&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—David Rotman and Richard Waters&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Any far-reaching new technology is always uneven in its adoption, but few have been more uneven than generative AI. That makes it hard to assess its likely impact on individual businesses, let alone on productivity across the economy as a whole.&lt;/p&gt; 
 &lt;p&gt;At one extreme, AI coding assistants have revolutionized the work of software developers. At the other extreme, most companies are seeing little if any benefit from their initial investments.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That has provided fuel for the skeptics who maintain that—by its very nature as a probabilistic technology prone to hallucinating—generative AI will never have a deep impact on business. To students of tech history, though, the lack of immediate impact is normal. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;If you're an &lt;em&gt;MIT Technology Review &lt;/em&gt;subscriber, you can join David and Richard, alongside our editor in chief, Mat Honan, for an exclusive conversation digging into what’s happening across different markets live on Tuesday, December 9 at 1pm ET. &lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;Register here&lt;/strong&gt;&lt;strong&gt;!&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The State of AI is our subscriber-only collaboration between the&lt;em&gt; Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt; examining the ways in which AI is reshaping global power. &lt;/strong&gt;&lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; to receive future editions every Monday.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 DeepSeek has unveiled two new experimental AI models&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;DeepSeek-V3.2 is designed to match OpenAI’s GPT-5’s reasoning capabilities. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Here’s how DeepSeek slashes its models’ computational burden. &lt;/em&gt;(VentureBeat)&lt;br /&gt;+ &lt;em&gt;It’s achieved these results despite its limited access to powerful chips. &lt;/em&gt;(SCMP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 OpenAI has issued a “code red” warning to its employees&lt;/strong&gt;&lt;br /&gt;It’s a call to arms to improve ChatGPT, or risk being overtaken. (The Information $)&lt;br /&gt;+ &lt;em&gt;Both Google and Anthropic are snapping at OpenAI’s heels. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Advertising and other initiatives will be pushed back to accommodate the new focus. &lt;/em&gt;(WSJ $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 How to know when the AI bubble has burst&lt;/strong&gt;&lt;br /&gt;These are the signs to look out for. (Economist $)&lt;br /&gt;+ &lt;em&gt;Things could get a whole lot worse for the economy if and when it pops. &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;We don’t really know how the AI investment surge is being financed. &lt;/em&gt;(The Guardian)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Some US states are making it illegal for AI to discriminate against you&lt;br /&gt;California is the latest to give workers more power to fight algorithms. (WP $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 This AI startup is working on a post-transformer future&lt;br /&gt;Transformer architecture underpins the current AI boom—but Pathway is developing something new. (WSJ $)&lt;br /&gt;+ &lt;em&gt;What the next frontier of AI could look like. &lt;/em&gt;(IEEE Spectrum)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 India is demanding smartphone makers install a government app&lt;br /&gt;&lt;/strong&gt;Which privacy advocates say is unacceptable snooping. (FT $)&lt;br /&gt;+ &lt;em&gt;India’s tech talent is looking for opportunities outside the US. &lt;/em&gt;(Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 College students are desperate to sign up for AI majors&lt;br /&gt;&lt;/strong&gt;AI is now the second-largest major at MIT behind computer science. (NYT $)&lt;br /&gt;+ &lt;em&gt;AI’s giants want to take over the classroom. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;8 America’s musical heritage is at serious risk&lt;/strong&gt;&lt;br /&gt;Much of it is stored on studio tapes, which are deteriorating over time. (NYT $)&lt;br /&gt;+ &lt;em&gt;The race to save our online lives from a digital dark age. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Celebrities are increasingly turning on AI&lt;br /&gt;&lt;/strong&gt;That doesn’t stop fans from casting them in slop videos anyway. (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Samsung has revealed its first tri-folding phone&lt;/strong&gt;&lt;br /&gt;But will people actually want to buy it? (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It’ll cost more than $2,000 when it goes on sale in South Korea. &lt;/em&gt;(Reuters)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The Chinese will not pause. They will take over.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Michael Lohscheller, chief executive of Swedish electric car maker Polestar, tells the Guardian why Europe should stick to its plan to ban the production of new petrol and diesel cars by 2035.&amp;nbsp;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128649" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/image_10d338.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside Amsterdam’s high-stakes experiment to create fair welfare AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Amsterdam thought it was on the right track. City officials in the welfare department believed they could build technology that would prevent fraud while protecting citizens’ rights. They followed these emerging best practices and invested a vast amount of time and money in a project that eventually processed live welfare applications. But in their pilot, they found that the system they’d developed was still not fair and effective. Why?&lt;/p&gt;&lt;p&gt;Lighthouse Reports, &lt;em&gt;MIT Technology Review&lt;/em&gt;, and the Dutch newspaper Trouw have gained unprecedented access to the system to try to find out. Read about what we discovered.&lt;/p&gt;  &lt;p class="has-text-align-right"&gt;&lt;em&gt;—Eileen Guo, Gabriel Geiger &amp;amp; Justin-Casimir Braun&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Hear me out: a truly great festive film doesn’t need to be about Christmas at all.&lt;br /&gt;+ Maybe we should judge a book by its cover after all.&lt;br /&gt;+ Happy birthday to Ms Britney Spears, still the princess of pop at 44!&lt;br /&gt;+ The fascinating psychology behind why we love travelling so much.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The State of AI: Welcome to the economic singularity&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;em&gt;—David Rotman and Richard Waters&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Any far-reaching new technology is always uneven in its adoption, but few have been more uneven than generative AI. That makes it hard to assess its likely impact on individual businesses, let alone on productivity across the economy as a whole.&lt;/p&gt; 
 &lt;p&gt;At one extreme, AI coding assistants have revolutionized the work of software developers. At the other extreme, most companies are seeing little if any benefit from their initial investments.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That has provided fuel for the skeptics who maintain that—by its very nature as a probabilistic technology prone to hallucinating—generative AI will never have a deep impact on business. To students of tech history, though, the lack of immediate impact is normal. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;If you're an &lt;em&gt;MIT Technology Review &lt;/em&gt;subscriber, you can join David and Richard, alongside our editor in chief, Mat Honan, for an exclusive conversation digging into what’s happening across different markets live on Tuesday, December 9 at 1pm ET. &lt;/strong&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;Register here&lt;/strong&gt;&lt;strong&gt;!&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;The State of AI is our subscriber-only collaboration between the&lt;em&gt; Financial Times&lt;/em&gt; and &lt;em&gt;MIT Technology Review&lt;/em&gt; examining the ways in which AI is reshaping global power. &lt;/strong&gt;&lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; to receive future editions every Monday.&lt;/strong&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 DeepSeek has unveiled two new experimental AI models&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;DeepSeek-V3.2 is designed to match OpenAI’s GPT-5’s reasoning capabilities. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;Here’s how DeepSeek slashes its models’ computational burden. &lt;/em&gt;(VentureBeat)&lt;br /&gt;+ &lt;em&gt;It’s achieved these results despite its limited access to powerful chips. &lt;/em&gt;(SCMP $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 OpenAI has issued a “code red” warning to its employees&lt;/strong&gt;&lt;br /&gt;It’s a call to arms to improve ChatGPT, or risk being overtaken. (The Information $)&lt;br /&gt;+ &lt;em&gt;Both Google and Anthropic are snapping at OpenAI’s heels. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;Advertising and other initiatives will be pushed back to accommodate the new focus. &lt;/em&gt;(WSJ $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 How to know when the AI bubble has burst&lt;/strong&gt;&lt;br /&gt;These are the signs to look out for. (Economist $)&lt;br /&gt;+ &lt;em&gt;Things could get a whole lot worse for the economy if and when it pops. &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;We don’t really know how the AI investment surge is being financed. &lt;/em&gt;(The Guardian)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 Some US states are making it illegal for AI to discriminate against you&lt;br /&gt;California is the latest to give workers more power to fight algorithms. (WP $)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;5 This AI startup is working on a post-transformer future&lt;br /&gt;Transformer architecture underpins the current AI boom—but Pathway is developing something new. (WSJ $)&lt;br /&gt;+ &lt;em&gt;What the next frontier of AI could look like. &lt;/em&gt;(IEEE Spectrum)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 India is demanding smartphone makers install a government app&lt;br /&gt;&lt;/strong&gt;Which privacy advocates say is unacceptable snooping. (FT $)&lt;br /&gt;+ &lt;em&gt;India’s tech talent is looking for opportunities outside the US. &lt;/em&gt;(Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 College students are desperate to sign up for AI majors&lt;br /&gt;&lt;/strong&gt;AI is now the second-largest major at MIT behind computer science. (NYT $)&lt;br /&gt;+ &lt;em&gt;AI’s giants want to take over the classroom. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;8 America’s musical heritage is at serious risk&lt;/strong&gt;&lt;br /&gt;Much of it is stored on studio tapes, which are deteriorating over time. (NYT $)&lt;br /&gt;+ &lt;em&gt;The race to save our online lives from a digital dark age. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Celebrities are increasingly turning on AI&lt;br /&gt;&lt;/strong&gt;That doesn’t stop fans from casting them in slop videos anyway. (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Samsung has revealed its first tri-folding phone&lt;/strong&gt;&lt;br /&gt;But will people actually want to buy it? (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It’ll cost more than $2,000 when it goes on sale in South Korea. &lt;/em&gt;(Reuters)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The Chinese will not pause. They will take over.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Michael Lohscheller, chief executive of Swedish electric car maker Polestar, tells the Guardian why Europe should stick to its plan to ban the production of new petrol and diesel cars by 2035.&amp;nbsp;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
 &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1128649" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/image_10d338.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside Amsterdam’s high-stakes experiment to create fair welfare AI&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Amsterdam thought it was on the right track. City officials in the welfare department believed they could build technology that would prevent fraud while protecting citizens’ rights. They followed these emerging best practices and invested a vast amount of time and money in a project that eventually processed live welfare applications. But in their pilot, they found that the system they’d developed was still not fair and effective. Why?&lt;/p&gt;&lt;p&gt;Lighthouse Reports, &lt;em&gt;MIT Technology Review&lt;/em&gt;, and the Dutch newspaper Trouw have gained unprecedented access to the system to try to find out. Read about what we discovered.&lt;/p&gt;  &lt;p class="has-text-align-right"&gt;&lt;em&gt;—Eileen Guo, Gabriel Geiger &amp;amp; Justin-Casimir Braun&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Hear me out: a truly great festive film doesn’t need to be about Christmas at all.&lt;br /&gt;+ Maybe we should judge a book by its cover after all.&lt;br /&gt;+ Happy birthday to Ms Britney Spears, still the princess of pop at 44!&lt;br /&gt;+ The fascinating psychology behind why we love travelling so much.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/12/02/1128647/the-download-ais-impact-on-the-economy-and-deepseek-strikes-again/</guid><pubDate>Tue, 02 Dec 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] IBM cites agentic AI, data policies, and quantum as 2026 trends (AI News)</title><link>https://www.artificialintelligence-news.com/news/ibm-quantum-cited-plus-agentic-ai-data-policies-as-2026-trends/</link><description>&lt;p&gt;Enterprise leaders are entering 2026 with an uncomfortable mix of volatility, optimism, and pressure to move faster on AI and quantum computing, according to a paper published by the IBM Institute for Business Value. Its findings are based on more than 1,000 C-suite executives and 8,500 employees and consumers.&lt;/p&gt;&lt;p&gt;While only around a third of executives are optimistic about the global economy, more than four in five are confident about their own organisation’s performance in the year ahead.&lt;/p&gt;&lt;p&gt;Executives expect to make faster decisions and are willing to redesign operating models, while employees are broadly positive about AI in their working lives. Customers, in turn, are ready to reward (or punish) brands based on how companies use their data.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="org5862317"&gt;Trend 1: agentic AI a strategic asset&lt;/h4&gt;&lt;p&gt;Agentic AI is emerging as one of the main tools leaders expect to use in the coming year, and most execs say AI agents are already helping them.&lt;/p&gt;&lt;p&gt;However, for agentic AI to succeed, the expressed opinions state:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Data architecture needs to support near real-time insight, not periodic reporting.&lt;/li&gt;&lt;li&gt;AI agents’ success will depend on access to core systems (ERP, CRM, supply chain platforms).&lt;/li&gt;&lt;li&gt;Agentic AI shifts from experimental to operational.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Leaders feel they must decide which decisions can be delegated to AI agents, which require human review, and should must remain human-led.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="org961c2b7"&gt;Trend 2: employees will ask for more training and AI is okay&lt;/h4&gt;&lt;p&gt;Most employees say the pace of technology change in their roles is sustainable, and that they’re confident about keeping up with new tools.&lt;/p&gt;&lt;p&gt;Twice as many employees say they would embrace, not resist, greater use of AI in the workplace, seeing the technology as a way to remove repetitive tasks and learn new skills. This aligns with findings in research by KPMG.&lt;/p&gt;&lt;p&gt;Executives expect a significant re-skilling requirement from their employees, so leaders should anticipate that at least half their workforce will need some form of re-skilling by the end of 2026, thanks to AI automation. Other surveys concur with IBM, and state the skills needed most are problem-solving, creativity, and innovation.&lt;/p&gt;&lt;p&gt;Employees say they are willing to change employers to access better training opportunities, meaning skills development now plays a direct role reducing employee churn.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="orgbfa49c8"&gt;Trend 3: customers will hold data policies to account&lt;/h4&gt;&lt;p&gt;The executives surveyed agreed that consumer trust in a brand’s use of AI will define the success of new products and services. Consumers are willing to tolerate occasional errors, but not opacity.&lt;/p&gt;&lt;p&gt;Customers want explanations of how their data is used, knowledge of when AI is involved in interactions with them, and simple ways to opt in or out. The studies by Deloitte and KPMG (see above) reinforce this picture.&lt;/p&gt;&lt;p&gt;Implications for leaders include treating transparency as a product feature and selecting models that support explainability.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="orgee005c1"&gt;Trend 4: AI and cloud will need local provision&lt;/h4&gt;&lt;p&gt;AI sovereignty—an organisation’s ability to control and govern its AI systems, data, and infrastructure—has moved to the centre of resilience planning. Almost all executives surveyed said they will factor AI sovereignty into their 2026 strategy.&lt;/p&gt;&lt;p&gt;In the light of concerns about data residency and cloud jurisdiction, leaders are rethinking where models run and where data lives. Studies from UK and European IT leaders show rising concern about over-reliance on foreign (read, ‘US-based’ cloud services in the latter case).&lt;/p&gt;&lt;p&gt;Advisory firm Accenture also urges leaders [PDF] to develop sovereign AI strategies that prioritise control, transparency, and choice.&lt;/p&gt;&lt;p&gt;Key takeaways include the need for portable AI platforms, monitoring for data compliance, and a heavy emphasis on the physical location of data.&lt;/p&gt;&lt;p&gt;AI resilience is ultimately about continuity and transparency. It requires ensuring the organisation can adapt and operate openly, even when the global technological and geopolitical landscapes shift.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="org3699cf8"&gt;Trend 5: planning on quantum advantage&lt;/h4&gt;&lt;p&gt;The report’s findings say quantum is moving towards experimentation in the near term. IBM’s own research on quantum readiness (in line with its monetisation of quantum services) suggests that early quantum advantage is likely in targeted domains such as optimisation and materials science.&lt;/p&gt;&lt;p&gt;The report urges the identification of small numbers of high-impact quantum uses in the enterprise, and the joining of ecosystems early. “Identify big bets to win with emerging technologies, including quantum, and partner on innovation to share costs,” the report states.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “California Perfect” by moonjazz is licensed under CC BY-SA 2.0.&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How the MCP spec update boosts security as infrastructure scales&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110949" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-18.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Enterprise leaders are entering 2026 with an uncomfortable mix of volatility, optimism, and pressure to move faster on AI and quantum computing, according to a paper published by the IBM Institute for Business Value. Its findings are based on more than 1,000 C-suite executives and 8,500 employees and consumers.&lt;/p&gt;&lt;p&gt;While only around a third of executives are optimistic about the global economy, more than four in five are confident about their own organisation’s performance in the year ahead.&lt;/p&gt;&lt;p&gt;Executives expect to make faster decisions and are willing to redesign operating models, while employees are broadly positive about AI in their working lives. Customers, in turn, are ready to reward (or punish) brands based on how companies use their data.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="org5862317"&gt;Trend 1: agentic AI a strategic asset&lt;/h4&gt;&lt;p&gt;Agentic AI is emerging as one of the main tools leaders expect to use in the coming year, and most execs say AI agents are already helping them.&lt;/p&gt;&lt;p&gt;However, for agentic AI to succeed, the expressed opinions state:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Data architecture needs to support near real-time insight, not periodic reporting.&lt;/li&gt;&lt;li&gt;AI agents’ success will depend on access to core systems (ERP, CRM, supply chain platforms).&lt;/li&gt;&lt;li&gt;Agentic AI shifts from experimental to operational.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Leaders feel they must decide which decisions can be delegated to AI agents, which require human review, and should must remain human-led.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="org961c2b7"&gt;Trend 2: employees will ask for more training and AI is okay&lt;/h4&gt;&lt;p&gt;Most employees say the pace of technology change in their roles is sustainable, and that they’re confident about keeping up with new tools.&lt;/p&gt;&lt;p&gt;Twice as many employees say they would embrace, not resist, greater use of AI in the workplace, seeing the technology as a way to remove repetitive tasks and learn new skills. This aligns with findings in research by KPMG.&lt;/p&gt;&lt;p&gt;Executives expect a significant re-skilling requirement from their employees, so leaders should anticipate that at least half their workforce will need some form of re-skilling by the end of 2026, thanks to AI automation. Other surveys concur with IBM, and state the skills needed most are problem-solving, creativity, and innovation.&lt;/p&gt;&lt;p&gt;Employees say they are willing to change employers to access better training opportunities, meaning skills development now plays a direct role reducing employee churn.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="orgbfa49c8"&gt;Trend 3: customers will hold data policies to account&lt;/h4&gt;&lt;p&gt;The executives surveyed agreed that consumer trust in a brand’s use of AI will define the success of new products and services. Consumers are willing to tolerate occasional errors, but not opacity.&lt;/p&gt;&lt;p&gt;Customers want explanations of how their data is used, knowledge of when AI is involved in interactions with them, and simple ways to opt in or out. The studies by Deloitte and KPMG (see above) reinforce this picture.&lt;/p&gt;&lt;p&gt;Implications for leaders include treating transparency as a product feature and selecting models that support explainability.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="orgee005c1"&gt;Trend 4: AI and cloud will need local provision&lt;/h4&gt;&lt;p&gt;AI sovereignty—an organisation’s ability to control and govern its AI systems, data, and infrastructure—has moved to the centre of resilience planning. Almost all executives surveyed said they will factor AI sovereignty into their 2026 strategy.&lt;/p&gt;&lt;p&gt;In the light of concerns about data residency and cloud jurisdiction, leaders are rethinking where models run and where data lives. Studies from UK and European IT leaders show rising concern about over-reliance on foreign (read, ‘US-based’ cloud services in the latter case).&lt;/p&gt;&lt;p&gt;Advisory firm Accenture also urges leaders [PDF] to develop sovereign AI strategies that prioritise control, transparency, and choice.&lt;/p&gt;&lt;p&gt;Key takeaways include the need for portable AI platforms, monitoring for data compliance, and a heavy emphasis on the physical location of data.&lt;/p&gt;&lt;p&gt;AI resilience is ultimately about continuity and transparency. It requires ensuring the organisation can adapt and operate openly, even when the global technological and geopolitical landscapes shift.&lt;/p&gt;&lt;h4 class="wp-block-heading" id="org3699cf8"&gt;Trend 5: planning on quantum advantage&lt;/h4&gt;&lt;p&gt;The report’s findings say quantum is moving towards experimentation in the near term. IBM’s own research on quantum readiness (in line with its monetisation of quantum services) suggests that early quantum advantage is likely in targeted domains such as optimisation and materials science.&lt;/p&gt;&lt;p&gt;The report urges the identification of small numbers of high-impact quantum uses in the enterprise, and the joining of ecosystems early. “Identify big bets to win with emerging technologies, including quantum, and partner on innovation to share costs,” the report states.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “California Perfect” by moonjazz is licensed under CC BY-SA 2.0.&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;How the MCP spec update boosts security as infrastructure scales&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110949" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image-18.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ibm-quantum-cited-plus-agentic-ai-data-policies-as-2026-trends/</guid><pubDate>Tue, 02 Dec 2025 13:44:00 +0000</pubDate></item><item><title>[NEW] Ascentra Labs raises $2 million to help consultants use AI instead of all-night Excel marathons (AI | VentureBeat)</title><link>https://venturebeat.com/ai/ascentra-labs-raises-usd2-million-to-help-consultants-use-ai-instead-of-all</link><description>[unable to retrieve full-text content]&lt;p&gt;
&lt;/p&gt;&lt;p&gt;While artificial intelligence has stormed into law firms and accounting practices with billion-dollar startups like Harvey leading the charge, the global consulting industry—a $250 billion behemoth—has remained stubbornly analog. A London-based startup founded by former McKinsey consultants is betting $2 million that it can crack open this resistant market, one Excel spreadsheet at a time.&lt;/p&gt;&lt;p&gt;&lt;a href="https://ascentralabs.ai/"&gt;&lt;u&gt;Ascentra Labs&lt;/u&gt;&lt;/a&gt; announced Monday that it has closed a $2 million seed round led by &lt;a href="https://www.nap.vc/"&gt;&lt;u&gt;NAP&lt;/u&gt;&lt;/a&gt;, a Berlin-based venture capital firm formerly known as Cavalry Ventures. The funding comes with participation from notable founder-angels including Alan Chang, chief executive of Fuse and former chief revenue officer at Revolut, and Fredrik Hjelm, chief executive of European e-scooter company Voi.&lt;/p&gt;&lt;p&gt;The investment is modest by the standards of enterprise AI — a sector that has seen funding rounds routinely reach into the hundreds of millions. But Ascentra&amp;#x27;s founders argue that their focused approach to a narrow but painful problem could give them an edge in a market where broad AI solutions have repeatedly failed to gain traction.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Consultants spend countless hours on Excel survey analysis that even top firms haven&amp;#x27;t automated&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://ascentralabs.ai/about"&gt;&lt;u&gt;Paritosh Devbhandari&lt;/u&gt;&lt;/a&gt;, Ascentra&amp;#x27;s co-founder and chief executive, spent years at &lt;a href="https://www.mckinsey.com/"&gt;&lt;u&gt;McKinsey &amp;amp; Company&lt;/u&gt;&lt;/a&gt;, including a stint at &lt;a href="https://www.mckinsey.com/capabilities/quantumblack/how-we-help-clients"&gt;&lt;u&gt;QuantumBlack&lt;/u&gt;&lt;/a&gt;, the firm&amp;#x27;s AI and advanced analytics division. He knows intimately the late nights consultants spend wrestling with survey data—the kind of quantitative research that forms the backbone of private equity due diligence.&lt;/p&gt;&lt;p&gt;&amp;quot;Before starting the company, I was working at McKinsey, specifically on the private equity team,&amp;quot; Devbhandari explained in an exclusive interview with VentureBeat. The work, he said, involves analyzing encoded survey responses from customers, suppliers, and market participants during potential acquisitions.&lt;/p&gt;&lt;p&gt;&amp;quot;Consultants typically spend a lot of time doing this in Excel,&amp;quot; he said. &amp;quot;One of the things that surprised me, having worked at a couple of different places, is that the workflow — even at the best firms — really isn&amp;#x27;t that different from some of the boutiques. I always expected there would be some smarter way of doing things, and often there just isn&amp;#x27;t.&amp;quot;&lt;/p&gt;&lt;p&gt;That gap between expectation and reality became the foundation for &lt;a href="https://ascentralabs.ai/"&gt;&lt;u&gt;Ascentra&lt;/u&gt;&lt;/a&gt;. The company&amp;#x27;s platform ingests raw survey data files and outputs formatted Excel workbooks complete with traceable formulas — the kind of deliverable a junior associate would spend hours constructing manually.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;AI has transformed legal work but consulting presents unique technical challenges that have blocked adoption&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The disparity between AI adoption in law versus consulting raises an obvious question: if the consulting market is so large and the workflows so manual, why hasn&amp;#x27;t venture capital flooded the space the way it has legal tech?&lt;/p&gt;&lt;p&gt;Devbhandari offered a frank assessment. &amp;quot;It&amp;#x27;s not like people haven&amp;#x27;t tried,&amp;quot; he said. &amp;quot;The top of the funnel in our space is crowded. When we speak to our consulting clients, the partners say they get another pitch deck in their LinkedIn inbox or email every week—sometimes several. There are plenty of people trying.&amp;quot;&lt;/p&gt;&lt;p&gt;The barriers, he argued, are structural. Professional services firms move slowly on technology adoption, demanding extensive security credentials and customer references before granting even a pilot opportunity. &amp;quot;I think that&amp;#x27;s where 90% of startups in professional services, writ large, fall down,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;But consulting presents unique technical challenges beyond the sales cycle. Unlike legal work, which largely involves text documents that modern large language models handle well, consulting spans multiple data modalities — PowerPoint presentations, Excel spreadsheets, Word documents — with information that can be tabular, graphical, or textual.&lt;/p&gt;&lt;p&gt;&amp;quot;You can have multiple formats of Excel in itself,&amp;quot; Devbhandari noted. &amp;quot;And that&amp;#x27;s a big contrast to the legal space, where you could have a multi-purpose AI agent, or collection of agents, which can actually do a lot of the tasks that lawyers do day to day. Consulting is the opposite of that.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Ascentra&amp;#x27;s private equity focus reflects a calculated bet on repeatable workflows&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Ascentra&amp;#x27;s strategy hinges on extreme specificity. Rather than attempting to automate the full spectrum of consulting work, the company focuses exclusively on survey analysis within private equity due diligence — a niche within a niche.&lt;/p&gt;&lt;p&gt;The logic is both technical and commercial. Private equity work tends to be more standardized than other consulting engagements, with similar analyses recurring across deals. That repeatability makes automation feasible. It also positions Ascentra against a less formidable competitive set: even the largest consulting firms, Devbhandari claimed, lack dedicated internal tools for this particular workflow.&lt;/p&gt;&lt;p&gt;&amp;quot;Survey analysis automation is so specific that even the biggest and best firms haven&amp;#x27;t developed anything in-house for it,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The company claims that three of the world&amp;#x27;s top five consulting firms now use its platform, with early adopters reporting time savings of 60 to 80 percent on active due diligence projects. But there&amp;#x27;s a notable caveat: Ascentra cannot publicly name any of these clients.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s a very private industry, so at the moment, we can&amp;#x27;t announce any clients publicly,&amp;quot; Devbhandari acknowledged. &amp;quot;What I can say is that we&amp;#x27;re working with three of the top five consulting firms. We&amp;#x27;ve passed pilots at multiple organizations and have submitted business cases for enterprise rollouts.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Eliminating AI hallucinations becomes critical when billion-dollar deals hang in the balance&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For an AI company selling into quantitative workflows, accuracy is existential. Consultants delivering analysis to private equity clients face enormous pressure to be precise—a single error in a financial model can undermine credibility and, potentially, billion-dollar investment decisions.&lt;/p&gt;&lt;p&gt;Devbhandari described this as Ascentra&amp;#x27;s central design challenge. &amp;quot;Consultants require a very, very high degree of fidelity when they&amp;#x27;re doing their analysis,&amp;quot; he said. &amp;quot;So with quantitative data, even if it&amp;#x27;s 95% accurate, they will revert to Excel because they know it, they trust it, and they don&amp;#x27;t want there to be any margin for error.&amp;quot;&lt;/p&gt;&lt;p&gt;Ascentra&amp;#x27;s technical approach attempts to address this by limiting where AI models operate within the workflow. The company uses GPT-based models from OpenAI to interpret and ingest incoming data, but the actual analysis relies on deterministic Python scripts that produce consistent, verifiable outputs.&lt;/p&gt;&lt;p&gt;&amp;quot;What&amp;#x27;s different is the steps that follow are deterministic,&amp;quot; Devbhandari explained. &amp;quot;There&amp;#x27;s no room for error. There&amp;#x27;s no hallucinations, and the Excel writer that we&amp;#x27;ve connected to the product on the back end converts this analysis into Excel formula, which are live and traceable, so consultants can get that assurance that they can follow along with the maths.&amp;quot;&lt;/p&gt;&lt;p&gt;Whether this hybrid approach delivers on its promise of eliminating hallucinations while maintaining useful AI capabilities will be tested as the platform scales across more complex use cases and client environments.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Enterprise security certifications give Ascentra an edge over less prepared competitors&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Selling software to major consulting firms requires clearing an unusually high security bar. These organizations handle sensitive client data across industries, and their vendor security assessments can take months to complete.&lt;/p&gt;&lt;p&gt;Ascentra invested early in obtaining enterprise-grade certifications, a strategic choice that Devbhandari framed as essential table stakes. The company has achieved &lt;a href="https://secureframe.com/blog/soc-2-type-ii"&gt;&lt;u&gt;SOC 2 Type II&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.iso.org/standard/27001"&gt;&lt;u&gt;ISO 27001&lt;/u&gt;&lt;/a&gt; certifications and claims to be under audit for &lt;a href="https://www.iso.org/standard/42001"&gt;&lt;u&gt;ISO 42001&lt;/u&gt;&lt;/a&gt;, an emerging standard for AI management systems.&lt;/p&gt;&lt;p&gt;Data handling policies also reflect the sensitivity of the target market. Client data is deleted within 30 to 45 days, depending on contractual terms, and Ascentra does not use customer data to train its models.&lt;/p&gt;&lt;p&gt;There&amp;#x27;s also an argument that survey data carries somewhat lower sensitivity than other consulting materials. &amp;quot;Survey data is unique in consulting data because it&amp;#x27;s collected during the course of a project, and it is market data,&amp;quot; Devbhandari noted. &amp;quot;You interview people in the market, and you collect a bunch of data in an Excel, as opposed to—you look at Rogo or some of the other finance AI startups—they use client data, so financials, which is confidential and strictly non-public.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Per-project pricing aligns with how consulting firms actually spend money&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Ascentra&amp;#x27;s pricing model departs from the subscription-based approach that dominates enterprise software. The company charges on a per-project basis, a structure Devbhandari said aligns with how consulting firms allocate budgets.&lt;/p&gt;&lt;p&gt;&amp;quot;Project budgets are in consulting set on a per project basis,&amp;quot; he explained. &amp;quot;You&amp;#x27;ll have central budgets which are for things like Microsoft, right, very central things that every team will use all of the time. And then you have project budgets which are for the teams that are using specific resources, teams or products nowadays.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach may ease initial adoption by avoiding the need for central IT procurement approval, but it also introduces revenue unpredictability. The company&amp;#x27;s success will depend on converting project-level usage into broader enterprise relationships—a path Devbhandari suggested is already underway through submitted business cases for enterprise rollouts.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;AI may not eliminate consulting jobs, but it will fundamentally transform what consultants do&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Perhaps the most interesting tension in Devbhandari&amp;#x27;s vision concerns what AI ultimately means for consulting employment. He pushed back on predictions that AI will eliminate consulting jobs while simultaneously describing an industry on the cusp of fundamental transformation.&lt;/p&gt;&lt;p&gt;&amp;quot;People love to talk about how AI is going to remove the need for consultants, and I disagree,&amp;quot; he said. &amp;quot;Yes, the role will change, but I don&amp;#x27;t think the industry goes away. I think the best solutions will come from people within the industry building products around the work they know.&amp;quot;&lt;/p&gt;&lt;p&gt;Yet he also painted a picture of dramatic change. &amp;quot;At the moment, you have a big intake of graduates who just do—for the most part, you know, they have the strategic work as part of what they do, but they also have a lot of work in Excel and PowerPoint. I think in a few years&amp;#x27; time, we&amp;#x27;ll look back at these times and think, you know, very, very different.&amp;quot;&lt;/p&gt;&lt;p&gt;The honest answer, he acknowledged, is that no one truly knows how this plays out. &amp;quot;I don&amp;#x27;t think even AI leaders truly know what that looks like yet,&amp;quot; he said of whether productivity gains will translate to more work or fewer workers.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Ascentra plans to use seed funding to expand its U.S. presence and go-to-market team&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The $2 million will primarily fund Ascentra&amp;#x27;s expansion into the United States, where more than 80 percent of its customers are already based. Devbhandari plans to relocate there personally as the company builds out go-to-market capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the things that we&amp;#x27;ve really noticed is that with consulting being an American industry, and I think America being a great place for innovation and trying new things, we&amp;#x27;ve definitely drawn ourselves to the U.S.,&amp;quot; he said. &amp;quot;American hires are very expensive, and I&amp;#x27;m sure that a lot of the raise will go towards that.&amp;quot;&lt;/p&gt;&lt;p&gt;The seed round represents a bet by NAP on what its co-founder Stefan Walter called an overdue disruption. &amp;quot;While most knowledge work has been reshaped by new technology, consulting has remained stubbornly manual,&amp;quot; Walter said. &amp;quot;AI won&amp;#x27;t replace consultants, but consultants using Ascentra might.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The startup now faces the hard work of converting pilot wins into lasting enterprise contracts&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Ascentra enters 2026 with momentum but no guarantee of success. The company must transform pilot programs at elite firms into sticky enterprise contracts — all while fending off the inevitable well-funded competitors who will flood into the space once the opportunity becomes undeniable. Its deliberately narrow focus on survey analysis provides a defensible beachhead, but expanding into adjacent workflows will require building entirely new products without sacrificing the domain expertise that Devbhandari argues is the company&amp;#x27;s core advantage.&lt;/p&gt;&lt;p&gt;Oliver Thurston, Ascentra&amp;#x27;s co-founder and chief technology officer, who previously led machine learning at Mathison AI, offered a clear-eyed assessment of the challenge. &amp;quot;Consulting workflows are uniquely complex and difficult to build products around,&amp;quot; he said in a statement. &amp;quot;It&amp;#x27;s not surprising the space hasn&amp;#x27;t changed yet. This will change though, and there&amp;#x27;s no doubt that the industry is going to look completely different in five years&amp;#x27; time.&amp;quot;&lt;/p&gt;&lt;p&gt;For now, Ascentra is placing a focused wager: that the consultants who once spent their nights formatting spreadsheets will be the ones who finally bring AI into an industry that has long resisted it. The irony is hard to miss. After years of advising Fortune 500 companies on digital transformation, consulting may finally have to take its own medicine.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;
&lt;/p&gt;&lt;p&gt;While artificial intelligence has stormed into law firms and accounting practices with billion-dollar startups like Harvey leading the charge, the global consulting industry—a $250 billion behemoth—has remained stubbornly analog. A London-based startup founded by former McKinsey consultants is betting $2 million that it can crack open this resistant market, one Excel spreadsheet at a time.&lt;/p&gt;&lt;p&gt;&lt;a href="https://ascentralabs.ai/"&gt;&lt;u&gt;Ascentra Labs&lt;/u&gt;&lt;/a&gt; announced Monday that it has closed a $2 million seed round led by &lt;a href="https://www.nap.vc/"&gt;&lt;u&gt;NAP&lt;/u&gt;&lt;/a&gt;, a Berlin-based venture capital firm formerly known as Cavalry Ventures. The funding comes with participation from notable founder-angels including Alan Chang, chief executive of Fuse and former chief revenue officer at Revolut, and Fredrik Hjelm, chief executive of European e-scooter company Voi.&lt;/p&gt;&lt;p&gt;The investment is modest by the standards of enterprise AI — a sector that has seen funding rounds routinely reach into the hundreds of millions. But Ascentra&amp;#x27;s founders argue that their focused approach to a narrow but painful problem could give them an edge in a market where broad AI solutions have repeatedly failed to gain traction.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Consultants spend countless hours on Excel survey analysis that even top firms haven&amp;#x27;t automated&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://ascentralabs.ai/about"&gt;&lt;u&gt;Paritosh Devbhandari&lt;/u&gt;&lt;/a&gt;, Ascentra&amp;#x27;s co-founder and chief executive, spent years at &lt;a href="https://www.mckinsey.com/"&gt;&lt;u&gt;McKinsey &amp;amp; Company&lt;/u&gt;&lt;/a&gt;, including a stint at &lt;a href="https://www.mckinsey.com/capabilities/quantumblack/how-we-help-clients"&gt;&lt;u&gt;QuantumBlack&lt;/u&gt;&lt;/a&gt;, the firm&amp;#x27;s AI and advanced analytics division. He knows intimately the late nights consultants spend wrestling with survey data—the kind of quantitative research that forms the backbone of private equity due diligence.&lt;/p&gt;&lt;p&gt;&amp;quot;Before starting the company, I was working at McKinsey, specifically on the private equity team,&amp;quot; Devbhandari explained in an exclusive interview with VentureBeat. The work, he said, involves analyzing encoded survey responses from customers, suppliers, and market participants during potential acquisitions.&lt;/p&gt;&lt;p&gt;&amp;quot;Consultants typically spend a lot of time doing this in Excel,&amp;quot; he said. &amp;quot;One of the things that surprised me, having worked at a couple of different places, is that the workflow — even at the best firms — really isn&amp;#x27;t that different from some of the boutiques. I always expected there would be some smarter way of doing things, and often there just isn&amp;#x27;t.&amp;quot;&lt;/p&gt;&lt;p&gt;That gap between expectation and reality became the foundation for &lt;a href="https://ascentralabs.ai/"&gt;&lt;u&gt;Ascentra&lt;/u&gt;&lt;/a&gt;. The company&amp;#x27;s platform ingests raw survey data files and outputs formatted Excel workbooks complete with traceable formulas — the kind of deliverable a junior associate would spend hours constructing manually.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;AI has transformed legal work but consulting presents unique technical challenges that have blocked adoption&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The disparity between AI adoption in law versus consulting raises an obvious question: if the consulting market is so large and the workflows so manual, why hasn&amp;#x27;t venture capital flooded the space the way it has legal tech?&lt;/p&gt;&lt;p&gt;Devbhandari offered a frank assessment. &amp;quot;It&amp;#x27;s not like people haven&amp;#x27;t tried,&amp;quot; he said. &amp;quot;The top of the funnel in our space is crowded. When we speak to our consulting clients, the partners say they get another pitch deck in their LinkedIn inbox or email every week—sometimes several. There are plenty of people trying.&amp;quot;&lt;/p&gt;&lt;p&gt;The barriers, he argued, are structural. Professional services firms move slowly on technology adoption, demanding extensive security credentials and customer references before granting even a pilot opportunity. &amp;quot;I think that&amp;#x27;s where 90% of startups in professional services, writ large, fall down,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;But consulting presents unique technical challenges beyond the sales cycle. Unlike legal work, which largely involves text documents that modern large language models handle well, consulting spans multiple data modalities — PowerPoint presentations, Excel spreadsheets, Word documents — with information that can be tabular, graphical, or textual.&lt;/p&gt;&lt;p&gt;&amp;quot;You can have multiple formats of Excel in itself,&amp;quot; Devbhandari noted. &amp;quot;And that&amp;#x27;s a big contrast to the legal space, where you could have a multi-purpose AI agent, or collection of agents, which can actually do a lot of the tasks that lawyers do day to day. Consulting is the opposite of that.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Ascentra&amp;#x27;s private equity focus reflects a calculated bet on repeatable workflows&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Ascentra&amp;#x27;s strategy hinges on extreme specificity. Rather than attempting to automate the full spectrum of consulting work, the company focuses exclusively on survey analysis within private equity due diligence — a niche within a niche.&lt;/p&gt;&lt;p&gt;The logic is both technical and commercial. Private equity work tends to be more standardized than other consulting engagements, with similar analyses recurring across deals. That repeatability makes automation feasible. It also positions Ascentra against a less formidable competitive set: even the largest consulting firms, Devbhandari claimed, lack dedicated internal tools for this particular workflow.&lt;/p&gt;&lt;p&gt;&amp;quot;Survey analysis automation is so specific that even the biggest and best firms haven&amp;#x27;t developed anything in-house for it,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The company claims that three of the world&amp;#x27;s top five consulting firms now use its platform, with early adopters reporting time savings of 60 to 80 percent on active due diligence projects. But there&amp;#x27;s a notable caveat: Ascentra cannot publicly name any of these clients.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s a very private industry, so at the moment, we can&amp;#x27;t announce any clients publicly,&amp;quot; Devbhandari acknowledged. &amp;quot;What I can say is that we&amp;#x27;re working with three of the top five consulting firms. We&amp;#x27;ve passed pilots at multiple organizations and have submitted business cases for enterprise rollouts.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Eliminating AI hallucinations becomes critical when billion-dollar deals hang in the balance&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;For an AI company selling into quantitative workflows, accuracy is existential. Consultants delivering analysis to private equity clients face enormous pressure to be precise—a single error in a financial model can undermine credibility and, potentially, billion-dollar investment decisions.&lt;/p&gt;&lt;p&gt;Devbhandari described this as Ascentra&amp;#x27;s central design challenge. &amp;quot;Consultants require a very, very high degree of fidelity when they&amp;#x27;re doing their analysis,&amp;quot; he said. &amp;quot;So with quantitative data, even if it&amp;#x27;s 95% accurate, they will revert to Excel because they know it, they trust it, and they don&amp;#x27;t want there to be any margin for error.&amp;quot;&lt;/p&gt;&lt;p&gt;Ascentra&amp;#x27;s technical approach attempts to address this by limiting where AI models operate within the workflow. The company uses GPT-based models from OpenAI to interpret and ingest incoming data, but the actual analysis relies on deterministic Python scripts that produce consistent, verifiable outputs.&lt;/p&gt;&lt;p&gt;&amp;quot;What&amp;#x27;s different is the steps that follow are deterministic,&amp;quot; Devbhandari explained. &amp;quot;There&amp;#x27;s no room for error. There&amp;#x27;s no hallucinations, and the Excel writer that we&amp;#x27;ve connected to the product on the back end converts this analysis into Excel formula, which are live and traceable, so consultants can get that assurance that they can follow along with the maths.&amp;quot;&lt;/p&gt;&lt;p&gt;Whether this hybrid approach delivers on its promise of eliminating hallucinations while maintaining useful AI capabilities will be tested as the platform scales across more complex use cases and client environments.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Enterprise security certifications give Ascentra an edge over less prepared competitors&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Selling software to major consulting firms requires clearing an unusually high security bar. These organizations handle sensitive client data across industries, and their vendor security assessments can take months to complete.&lt;/p&gt;&lt;p&gt;Ascentra invested early in obtaining enterprise-grade certifications, a strategic choice that Devbhandari framed as essential table stakes. The company has achieved &lt;a href="https://secureframe.com/blog/soc-2-type-ii"&gt;&lt;u&gt;SOC 2 Type II&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.iso.org/standard/27001"&gt;&lt;u&gt;ISO 27001&lt;/u&gt;&lt;/a&gt; certifications and claims to be under audit for &lt;a href="https://www.iso.org/standard/42001"&gt;&lt;u&gt;ISO 42001&lt;/u&gt;&lt;/a&gt;, an emerging standard for AI management systems.&lt;/p&gt;&lt;p&gt;Data handling policies also reflect the sensitivity of the target market. Client data is deleted within 30 to 45 days, depending on contractual terms, and Ascentra does not use customer data to train its models.&lt;/p&gt;&lt;p&gt;There&amp;#x27;s also an argument that survey data carries somewhat lower sensitivity than other consulting materials. &amp;quot;Survey data is unique in consulting data because it&amp;#x27;s collected during the course of a project, and it is market data,&amp;quot; Devbhandari noted. &amp;quot;You interview people in the market, and you collect a bunch of data in an Excel, as opposed to—you look at Rogo or some of the other finance AI startups—they use client data, so financials, which is confidential and strictly non-public.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Per-project pricing aligns with how consulting firms actually spend money&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Ascentra&amp;#x27;s pricing model departs from the subscription-based approach that dominates enterprise software. The company charges on a per-project basis, a structure Devbhandari said aligns with how consulting firms allocate budgets.&lt;/p&gt;&lt;p&gt;&amp;quot;Project budgets are in consulting set on a per project basis,&amp;quot; he explained. &amp;quot;You&amp;#x27;ll have central budgets which are for things like Microsoft, right, very central things that every team will use all of the time. And then you have project budgets which are for the teams that are using specific resources, teams or products nowadays.&amp;quot;&lt;/p&gt;&lt;p&gt;This approach may ease initial adoption by avoiding the need for central IT procurement approval, but it also introduces revenue unpredictability. The company&amp;#x27;s success will depend on converting project-level usage into broader enterprise relationships—a path Devbhandari suggested is already underway through submitted business cases for enterprise rollouts.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;AI may not eliminate consulting jobs, but it will fundamentally transform what consultants do&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Perhaps the most interesting tension in Devbhandari&amp;#x27;s vision concerns what AI ultimately means for consulting employment. He pushed back on predictions that AI will eliminate consulting jobs while simultaneously describing an industry on the cusp of fundamental transformation.&lt;/p&gt;&lt;p&gt;&amp;quot;People love to talk about how AI is going to remove the need for consultants, and I disagree,&amp;quot; he said. &amp;quot;Yes, the role will change, but I don&amp;#x27;t think the industry goes away. I think the best solutions will come from people within the industry building products around the work they know.&amp;quot;&lt;/p&gt;&lt;p&gt;Yet he also painted a picture of dramatic change. &amp;quot;At the moment, you have a big intake of graduates who just do—for the most part, you know, they have the strategic work as part of what they do, but they also have a lot of work in Excel and PowerPoint. I think in a few years&amp;#x27; time, we&amp;#x27;ll look back at these times and think, you know, very, very different.&amp;quot;&lt;/p&gt;&lt;p&gt;The honest answer, he acknowledged, is that no one truly knows how this plays out. &amp;quot;I don&amp;#x27;t think even AI leaders truly know what that looks like yet,&amp;quot; he said of whether productivity gains will translate to more work or fewer workers.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Ascentra plans to use seed funding to expand its U.S. presence and go-to-market team&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The $2 million will primarily fund Ascentra&amp;#x27;s expansion into the United States, where more than 80 percent of its customers are already based. Devbhandari plans to relocate there personally as the company builds out go-to-market capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the things that we&amp;#x27;ve really noticed is that with consulting being an American industry, and I think America being a great place for innovation and trying new things, we&amp;#x27;ve definitely drawn ourselves to the U.S.,&amp;quot; he said. &amp;quot;American hires are very expensive, and I&amp;#x27;m sure that a lot of the raise will go towards that.&amp;quot;&lt;/p&gt;&lt;p&gt;The seed round represents a bet by NAP on what its co-founder Stefan Walter called an overdue disruption. &amp;quot;While most knowledge work has been reshaped by new technology, consulting has remained stubbornly manual,&amp;quot; Walter said. &amp;quot;AI won&amp;#x27;t replace consultants, but consultants using Ascentra might.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The startup now faces the hard work of converting pilot wins into lasting enterprise contracts&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Ascentra enters 2026 with momentum but no guarantee of success. The company must transform pilot programs at elite firms into sticky enterprise contracts — all while fending off the inevitable well-funded competitors who will flood into the space once the opportunity becomes undeniable. Its deliberately narrow focus on survey analysis provides a defensible beachhead, but expanding into adjacent workflows will require building entirely new products without sacrificing the domain expertise that Devbhandari argues is the company&amp;#x27;s core advantage.&lt;/p&gt;&lt;p&gt;Oliver Thurston, Ascentra&amp;#x27;s co-founder and chief technology officer, who previously led machine learning at Mathison AI, offered a clear-eyed assessment of the challenge. &amp;quot;Consulting workflows are uniquely complex and difficult to build products around,&amp;quot; he said in a statement. &amp;quot;It&amp;#x27;s not surprising the space hasn&amp;#x27;t changed yet. This will change though, and there&amp;#x27;s no doubt that the industry is going to look completely different in five years&amp;#x27; time.&amp;quot;&lt;/p&gt;&lt;p&gt;For now, Ascentra is placing a focused wager: that the consultants who once spent their nights formatting spreadsheets will be the ones who finally bring AI into an industry that has long resisted it. The irony is hard to miss. After years of advising Fortune 500 companies on digital transformation, consulting may finally have to take its own medicine.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ascentra-labs-raises-usd2-million-to-help-consultants-use-ai-instead-of-all</guid><pubDate>Tue, 02 Dec 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Mistral launches Mistral 3, a family of open models designed to run on laptops, drones, and edge devices (AI | VentureBeat)</title><link>https://venturebeat.com/ai/mistral-launches-mistral-3-a-family-of-open-models-designed-to-run-on</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://mistral.ai/"&gt;Mistral AI&lt;/a&gt;, Europe&amp;#x27;s most prominent artificial intelligence startup, is releasing its most ambitious product suite to date: a family of 10 open-source models designed to run everywhere from smartphones and autonomous drones to enterprise cloud systems, marking a major escalation in the company&amp;#x27;s challenge to both U.S. tech giants and surging Chinese competitors.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3 family&lt;/a&gt;, launching today, includes a new flagship model called &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral Large 3&lt;/a&gt; and a suite of smaller &amp;quot;&lt;a href="https://mistral.ai/models"&gt;Ministral 3&lt;/a&gt;&amp;quot; models optimized for edge computing applications. All models will be released under the permissive Apache 2.0 license, allowing unrestricted commercial use — a sharp contrast to the closed systems offered by &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The release is a pointed bet by Mistral that the future of artificial intelligence lies not in building ever-larger proprietary systems, but in offering businesses maximum flexibility to customize and deploy AI tailored to their specific needs, often using smaller models that can run without cloud connectivity.&lt;/p&gt;&lt;p&gt;&amp;quot;The gap between closed and open source is getting smaller, because more and more people are contributing to open source, which is great,&amp;quot; Guillaume Lample, Mistral&amp;#x27;s chief scientist and co-founder, said in an exclusive interview with VentureBeat. &amp;quot;We are catching up fast.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Mistral is choosing flexibility over frontier performance in the AI race&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The strategic calculus behind &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3&lt;/a&gt; diverges sharply from recent model releases by industry leaders. While &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt; have focused recent launches on increasingly capable &amp;quot;agentic&amp;quot; systems — AI that can autonomously execute complex multi-step tasks — Mistral is prioritizing breadth, efficiency, and what Lample calls &amp;quot;distributed intelligence.&amp;quot;&lt;/p&gt;&lt;p&gt;Mistral &lt;a href="https://mistral.ai/models"&gt;Large 3&lt;/a&gt;, the flagship model, employs a &lt;a href="https://huggingface.co/blog/moe"&gt;Mixture of Experts&lt;/a&gt; architecture with 41 billion active parameters drawn from a total pool of 675 billion parameters. The model can process both text and images, handles context windows up to 256,000 tokens, and was trained with particular emphasis on non-English languages — a rarity among frontier AI systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Most AI labs focus on their native language, but Mistral Large 3 was trained on a wide variety of languages, making advanced AI useful for billions who speak different native languages,&amp;quot; the company said in a statement reviewed ahead of the announcement.&lt;/p&gt;&lt;p&gt;But the more significant departure lies in the &lt;a href="https://mistral.ai/models"&gt;Ministral 3&lt;/a&gt; lineup: nine compact models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants tailored for different use cases. Each variant serves a distinct purpose: base models for extensive customization, instruction-tuned models for general chat and task completion, and reasoning-optimized models for complex logic requiring step-by-step deliberation.&lt;/p&gt;&lt;p&gt;The smallest Ministral 3 models can run on devices with as little as 4 gigabytes of video memory using 4-bit quantization — making frontier AI capabilities accessible on standard laptops, smartphones, and embedded systems without requiring expensive cloud infrastructure or even internet connectivity. This approach reflects Mistral&amp;#x27;s belief that AI&amp;#x27;s next evolution will be defined not by sheer scale, but by ubiquity: models small enough to run on drones, in vehicles, in robots, and on consumer devices.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How fine-tuned small models beat expensive large models for enterprise customers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Lample&amp;#x27;s comments reveal a business model fundamentally different from that of closed-source competitors. Rather than competing primarily on benchmark performance, Mistral is targeting enterprise customers frustrated by the cost and inflexibility of proprietary systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Sometimes customers say, &amp;#x27;Is there a use case where the best closed-source model isn&amp;#x27;t working?&amp;#x27; If that&amp;#x27;s the case, then they&amp;#x27;re essentially stuck,&amp;quot; Lample explained. &amp;quot;There&amp;#x27;s nothing they can do. It&amp;#x27;s the best model available, and it&amp;#x27;s not working out of the box.&amp;quot;&lt;/p&gt;&lt;p&gt;This is where Mistral&amp;#x27;s approach diverges. When a generic model fails, the company deploys engineering teams to work directly with customers, analyzing specific problems, creating synthetic training data, and fine-tuning smaller models to outperform larger general-purpose systems on narrow tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;In more than 90% of cases, a small model can do the job, especially if it&amp;#x27;s fine-tuned. It doesn&amp;#x27;t have to be a model with hundreds of billions of parameters, just a 14-billion or 24-billion parameter model,&amp;quot; Lample said. &amp;quot;So it&amp;#x27;s not only much cheaper, but also faster, plus you have all the benefits: you don&amp;#x27;t need to worry about privacy, latency, reliability, and so on.&amp;quot;&lt;/p&gt;&lt;p&gt;The economic argument is compelling. Multiple enterprise customers have approached Mistral after building prototypes with expensive closed-source models, only to find deployment costs prohibitive at scale, according to Lample.&lt;/p&gt;&lt;p&gt;&amp;quot;They come back to us a couple of months later because they realize, &amp;#x27;We built this prototype, but it&amp;#x27;s way too slow and way too expensive,&amp;#x27;&amp;quot; he said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where Mistral 3 fits in the increasingly crowded open-source AI market&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Mistral&amp;#x27;s release comes amid fierce competition on multiple fronts. OpenAI recently released &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;GPT-5.1&lt;/a&gt; with enhanced agentic capabilities. Google launched &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;Gemini 3&lt;/a&gt; with improved multimodal understanding. Anthropic released &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Opus 4.5&lt;/a&gt; on the same day as this interview, with similar agent-focused features.&lt;/p&gt;&lt;p&gt;But Lample argues those comparisons miss the point. &amp;quot;It&amp;#x27;s a little bit behind. But I think what matters is that we are catching up fast,&amp;quot; he acknowledged regarding performance against closed models. &amp;quot;I think we are maybe playing a strategic long game.&amp;quot;&lt;/p&gt;&lt;p&gt;That long game involves a different competitive set: primarily open-source models from Chinese companies like &lt;a href="https://www.deepseek.com/"&gt;DeepSeek&lt;/a&gt; and Alibaba&amp;#x27;s &lt;a href="https://qwen.ai/home"&gt;Qwen&lt;/a&gt; series, which have made remarkable strides in recent months.&lt;/p&gt;&lt;p&gt;Mistral differentiates itself through multilingual capabilities that extend far beyond English or Chinese, multimodal integration handling both text and images in a unified model, and what the company characterizes as superior customization through easier fine-tuning.&lt;/p&gt;&lt;p&gt;&amp;quot;One key difference with the models themselves is that we focused much more on multilinguality,&amp;quot; Lample said. &amp;quot;If you look at all the top models from [Chinese competitors], they&amp;#x27;re all text-only. They have visual models as well, but as separate systems. We wanted to integrate everything into a single model.&amp;quot;&lt;/p&gt;&lt;p&gt;The multilingual emphasis aligns with Mistral&amp;#x27;s broader positioning as a European AI champion focused on digital sovereignty — the principle that organizations and nations should maintain control over their AI infrastructure and data.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Building beyond models: Mistral&amp;#x27;s full-stack enterprise AI platform strategy&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Mistral 3&amp;#x27;s release builds on an increasingly comprehensive enterprise AI platform that extends well beyond model development. The company has assembled a full-stack offering that differentiates it from pure model providers.&lt;/p&gt;&lt;p&gt;Recent product launches include &lt;a href="https://mistral.ai/news/agents-api"&gt;Mistral Agents API&lt;/a&gt;, which combines language models with built-in connectors for code execution, web search, image generation, and persistent memory across conversations; &lt;a href="https://mistral.ai/news/magistral"&gt;Magistral&lt;/a&gt;, the company&amp;#x27;s reasoning model designed for domain-specific, transparent, and multilingual reasoning; and &lt;a href="https://mistral.ai/news/mistral-code"&gt;Mistral Code&lt;/a&gt;, an AI-powered coding assistant bundling models, an in-IDE assistant, and local deployment options with enterprise tooling.&lt;/p&gt;&lt;p&gt;The consumer-facing &lt;a href="https://mistral.ai/products/le-chat"&gt;Le Chat assistant&lt;/a&gt; has been enhanced with Deep Research mode for structured research reports, voice capabilities, and Projects for organizing conversations into context-rich folders. More recently, Le Chat gained a connector directory with 20+ enterprise integrations powered by the Model Context Protocol (MCP), spanning tools like Databricks, Snowflake, GitHub, Atlassian, Asana, and Stripe.&lt;/p&gt;&lt;p&gt;In October, Mistral unveiled &lt;a href="https://mistral.ai/products/ai-studio"&gt;AI Studio&lt;/a&gt;, a production AI platform providing observability, agent runtime, and AI registry capabilities to help enterprises track output changes, monitor usage, run evaluations, and fine-tune models using proprietary data.&lt;/p&gt;&lt;p&gt;Mistral now positions itself as a full-stack, global enterprise AI company, offering not just models but an application-building layer through AI Studio, compute infrastructure, and forward-deployed engineers to help businesses realize return on investment.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why open source AI matters for customization, transparency and sovereignty&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Mistral&amp;#x27;s commitment to open-source development under permissive licenses is both an ideological stance and a competitive strategy in an AI landscape increasingly dominated by closed systems.&lt;/p&gt;&lt;p&gt;Lample elaborated on the practical benefits: &amp;quot;I think something that people don&amp;#x27;t realize — but our customers know this very well — is how much better any model can actually improve if you fine tune it on the task of interest. There&amp;#x27;s a huge gap between a base model and one that&amp;#x27;s fine-tuned for a specific task, and in many cases, it outperforms the closed-source model.&amp;quot;&lt;/p&gt;&lt;p&gt;The approach enables capabilities impossible with closed systems: organizations can fine-tune models on proprietary data that never leaves their infrastructure, customize architectures for specific workflows, and maintain complete transparency into how AI systems make decisions — critical for regulated industries like finance, healthcare, and defense.&lt;/p&gt;&lt;p&gt;This positioning has attracted government and public sector partnerships. The company launched &amp;quot;&lt;a href="https://mistral.ai/news/ai-for-citizens"&gt;AI for Citizens&lt;/a&gt;&amp;quot; in July 2025, an initiative to &amp;quot;help States and public institutions strategically harness AI for their people by transforming public services&amp;quot; and has secured strategic partnerships with France&amp;#x27;s army and job agency, Luxembourg&amp;#x27;s government, and various European public sector organizations.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Mistral&amp;#x27;s transatlantic AI collaboration goes beyond European borders&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;While Mistral is frequently characterized as Europe&amp;#x27;s answer to OpenAI, the company views itself as a transatlantic collaboration rather than a purely European venture. The CEO (Arthur Mensch) is based in the United States, the company has teams across both continents, and these models are being trained in partnerships with U.S.-based teams and infrastructure providers.&lt;/p&gt;&lt;p&gt;This transatlantic positioning may prove strategically important as geopolitical tensions around AI development intensify. The recent ASML investment, a &lt;a href="https://www.nytimes.com/2025/09/09/business/asml-mistral-ai-chips-investment.html"&gt;€1.7 billion ($1.5 billion) funding round&lt;/a&gt; led by the Dutch semiconductor equipment manufacturer, signals deepening collaboration across the Western semiconductor and AI value chain at a moment when both Europe and the United States are seeking to reduce dependence on Chinese technology.&lt;/p&gt;&lt;p&gt;Mistral&amp;#x27;s investor base reflects this dynamic: the Series C round included participation from U.S. firms &lt;a href="https://a16z.com/"&gt;Andreessen Horowitz&lt;/a&gt;, &lt;a href="https://www.generalcatalyst.com/"&gt;General Catalyst&lt;/a&gt;, &lt;a href="https://www.lightspeedhq.com/"&gt;Lightspeed&lt;/a&gt;, and &lt;a href="https://www.indexventures.com/"&gt;Index Ventures&lt;/a&gt; alongside European investors like France&amp;#x27;s state-backed Bpifrance and global players like DST Global and Nvidia.&lt;/p&gt;&lt;p&gt;Founded in May 2023 by former Google DeepMind and Meta researchers, Mistral has raised roughly $1.05 billion (€1 billion) in funding. The company was valued at &lt;a href="https://techcrunch.com/2024/06/11/paris-based-ai-startup-mistral-ai-raises-640-million/"&gt;$6 billion&lt;/a&gt; in a June 2024 Series B, then &lt;a href="https://mistral.ai/news/mistral-ai-raises-1-7-b-to-accelerate-technological-progress-with-ai"&gt;more than doubled its valuation&lt;/a&gt; in a September Series C.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Can customization and efficiency beat raw performance in enterprise AI?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3 &lt;/a&gt;release crystallizes a fundamental question facing the AI industry: Will enterprises ultimately prioritize the absolute cutting-edge capabilities of proprietary systems, or will they choose open, customizable alternatives that offer greater control, lower costs, and independence from big tech platforms?&lt;/p&gt;&lt;p&gt;Mistral&amp;#x27;s answer is unambiguous. The company is betting that as AI moves from prototype to production, the factors that matter most shift dramatically. Raw benchmark scores matter less than total cost of ownership. Slight performance edges matter less than the ability to fine-tune for specific workflows. Cloud-based convenience matters less than data sovereignty and edge deployment.&lt;/p&gt;&lt;p&gt;It&amp;#x27;s a wager with significant risks. Despite Lample&amp;#x27;s optimism about closing the performance gap, Mistral&amp;#x27;s models still trail the absolute frontier. The company&amp;#x27;s revenue, while growing, reportedly remains modest relative to its nearly $14 billion valuation. And competition intensifies from both well-funded Chinese rivals making remarkable open-source progress and U.S. tech giants increasingly offering their own smaller, more efficient models.&lt;/p&gt;&lt;p&gt;But if Mistral is right — if the future of AI looks less like a handful of cloud-based oracles and more like millions of specialized systems running everywhere from factory floors to smartphones — then the company has positioned itself at the center of that transformation.&lt;/p&gt;&lt;p&gt;The release of &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3 &lt;/a&gt;is the most comprehensive expression yet of that vision: 10 models, spanning every size category, optimized for every deployment scenario, available to anyone who wants to build with them.&lt;/p&gt;&lt;p&gt;Whether &amp;quot;distributed intelligence&amp;quot; becomes the industry&amp;#x27;s dominant paradigm or remains a compelling alternative serving a narrower market will determine not just Mistral&amp;#x27;s fate, but the broader question of who controls the AI future — and whether that future will be open.&lt;/p&gt;&lt;p&gt;For now, the race is on. And Mistral is betting it can win not by building the biggest model, but by building everywhere else.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://mistral.ai/"&gt;Mistral AI&lt;/a&gt;, Europe&amp;#x27;s most prominent artificial intelligence startup, is releasing its most ambitious product suite to date: a family of 10 open-source models designed to run everywhere from smartphones and autonomous drones to enterprise cloud systems, marking a major escalation in the company&amp;#x27;s challenge to both U.S. tech giants and surging Chinese competitors.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3 family&lt;/a&gt;, launching today, includes a new flagship model called &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral Large 3&lt;/a&gt; and a suite of smaller &amp;quot;&lt;a href="https://mistral.ai/models"&gt;Ministral 3&lt;/a&gt;&amp;quot; models optimized for edge computing applications. All models will be released under the permissive Apache 2.0 license, allowing unrestricted commercial use — a sharp contrast to the closed systems offered by &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The release is a pointed bet by Mistral that the future of artificial intelligence lies not in building ever-larger proprietary systems, but in offering businesses maximum flexibility to customize and deploy AI tailored to their specific needs, often using smaller models that can run without cloud connectivity.&lt;/p&gt;&lt;p&gt;&amp;quot;The gap between closed and open source is getting smaller, because more and more people are contributing to open source, which is great,&amp;quot; Guillaume Lample, Mistral&amp;#x27;s chief scientist and co-founder, said in an exclusive interview with VentureBeat. &amp;quot;We are catching up fast.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Mistral is choosing flexibility over frontier performance in the AI race&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The strategic calculus behind &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3&lt;/a&gt; diverges sharply from recent model releases by industry leaders. While &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt; have focused recent launches on increasingly capable &amp;quot;agentic&amp;quot; systems — AI that can autonomously execute complex multi-step tasks — Mistral is prioritizing breadth, efficiency, and what Lample calls &amp;quot;distributed intelligence.&amp;quot;&lt;/p&gt;&lt;p&gt;Mistral &lt;a href="https://mistral.ai/models"&gt;Large 3&lt;/a&gt;, the flagship model, employs a &lt;a href="https://huggingface.co/blog/moe"&gt;Mixture of Experts&lt;/a&gt; architecture with 41 billion active parameters drawn from a total pool of 675 billion parameters. The model can process both text and images, handles context windows up to 256,000 tokens, and was trained with particular emphasis on non-English languages — a rarity among frontier AI systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Most AI labs focus on their native language, but Mistral Large 3 was trained on a wide variety of languages, making advanced AI useful for billions who speak different native languages,&amp;quot; the company said in a statement reviewed ahead of the announcement.&lt;/p&gt;&lt;p&gt;But the more significant departure lies in the &lt;a href="https://mistral.ai/models"&gt;Ministral 3&lt;/a&gt; lineup: nine compact models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants tailored for different use cases. Each variant serves a distinct purpose: base models for extensive customization, instruction-tuned models for general chat and task completion, and reasoning-optimized models for complex logic requiring step-by-step deliberation.&lt;/p&gt;&lt;p&gt;The smallest Ministral 3 models can run on devices with as little as 4 gigabytes of video memory using 4-bit quantization — making frontier AI capabilities accessible on standard laptops, smartphones, and embedded systems without requiring expensive cloud infrastructure or even internet connectivity. This approach reflects Mistral&amp;#x27;s belief that AI&amp;#x27;s next evolution will be defined not by sheer scale, but by ubiquity: models small enough to run on drones, in vehicles, in robots, and on consumer devices.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How fine-tuned small models beat expensive large models for enterprise customers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Lample&amp;#x27;s comments reveal a business model fundamentally different from that of closed-source competitors. Rather than competing primarily on benchmark performance, Mistral is targeting enterprise customers frustrated by the cost and inflexibility of proprietary systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Sometimes customers say, &amp;#x27;Is there a use case where the best closed-source model isn&amp;#x27;t working?&amp;#x27; If that&amp;#x27;s the case, then they&amp;#x27;re essentially stuck,&amp;quot; Lample explained. &amp;quot;There&amp;#x27;s nothing they can do. It&amp;#x27;s the best model available, and it&amp;#x27;s not working out of the box.&amp;quot;&lt;/p&gt;&lt;p&gt;This is where Mistral&amp;#x27;s approach diverges. When a generic model fails, the company deploys engineering teams to work directly with customers, analyzing specific problems, creating synthetic training data, and fine-tuning smaller models to outperform larger general-purpose systems on narrow tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;In more than 90% of cases, a small model can do the job, especially if it&amp;#x27;s fine-tuned. It doesn&amp;#x27;t have to be a model with hundreds of billions of parameters, just a 14-billion or 24-billion parameter model,&amp;quot; Lample said. &amp;quot;So it&amp;#x27;s not only much cheaper, but also faster, plus you have all the benefits: you don&amp;#x27;t need to worry about privacy, latency, reliability, and so on.&amp;quot;&lt;/p&gt;&lt;p&gt;The economic argument is compelling. Multiple enterprise customers have approached Mistral after building prototypes with expensive closed-source models, only to find deployment costs prohibitive at scale, according to Lample.&lt;/p&gt;&lt;p&gt;&amp;quot;They come back to us a couple of months later because they realize, &amp;#x27;We built this prototype, but it&amp;#x27;s way too slow and way too expensive,&amp;#x27;&amp;quot; he said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where Mistral 3 fits in the increasingly crowded open-source AI market&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Mistral&amp;#x27;s release comes amid fierce competition on multiple fronts. OpenAI recently released &lt;a href="https://openai.com/index/gpt-5-1-codex-max/"&gt;GPT-5.1&lt;/a&gt; with enhanced agentic capabilities. Google launched &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;Gemini 3&lt;/a&gt; with improved multimodal understanding. Anthropic released &lt;a href="https://www.anthropic.com/news/claude-opus-4-5"&gt;Opus 4.5&lt;/a&gt; on the same day as this interview, with similar agent-focused features.&lt;/p&gt;&lt;p&gt;But Lample argues those comparisons miss the point. &amp;quot;It&amp;#x27;s a little bit behind. But I think what matters is that we are catching up fast,&amp;quot; he acknowledged regarding performance against closed models. &amp;quot;I think we are maybe playing a strategic long game.&amp;quot;&lt;/p&gt;&lt;p&gt;That long game involves a different competitive set: primarily open-source models from Chinese companies like &lt;a href="https://www.deepseek.com/"&gt;DeepSeek&lt;/a&gt; and Alibaba&amp;#x27;s &lt;a href="https://qwen.ai/home"&gt;Qwen&lt;/a&gt; series, which have made remarkable strides in recent months.&lt;/p&gt;&lt;p&gt;Mistral differentiates itself through multilingual capabilities that extend far beyond English or Chinese, multimodal integration handling both text and images in a unified model, and what the company characterizes as superior customization through easier fine-tuning.&lt;/p&gt;&lt;p&gt;&amp;quot;One key difference with the models themselves is that we focused much more on multilinguality,&amp;quot; Lample said. &amp;quot;If you look at all the top models from [Chinese competitors], they&amp;#x27;re all text-only. They have visual models as well, but as separate systems. We wanted to integrate everything into a single model.&amp;quot;&lt;/p&gt;&lt;p&gt;The multilingual emphasis aligns with Mistral&amp;#x27;s broader positioning as a European AI champion focused on digital sovereignty — the principle that organizations and nations should maintain control over their AI infrastructure and data.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Building beyond models: Mistral&amp;#x27;s full-stack enterprise AI platform strategy&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Mistral 3&amp;#x27;s release builds on an increasingly comprehensive enterprise AI platform that extends well beyond model development. The company has assembled a full-stack offering that differentiates it from pure model providers.&lt;/p&gt;&lt;p&gt;Recent product launches include &lt;a href="https://mistral.ai/news/agents-api"&gt;Mistral Agents API&lt;/a&gt;, which combines language models with built-in connectors for code execution, web search, image generation, and persistent memory across conversations; &lt;a href="https://mistral.ai/news/magistral"&gt;Magistral&lt;/a&gt;, the company&amp;#x27;s reasoning model designed for domain-specific, transparent, and multilingual reasoning; and &lt;a href="https://mistral.ai/news/mistral-code"&gt;Mistral Code&lt;/a&gt;, an AI-powered coding assistant bundling models, an in-IDE assistant, and local deployment options with enterprise tooling.&lt;/p&gt;&lt;p&gt;The consumer-facing &lt;a href="https://mistral.ai/products/le-chat"&gt;Le Chat assistant&lt;/a&gt; has been enhanced with Deep Research mode for structured research reports, voice capabilities, and Projects for organizing conversations into context-rich folders. More recently, Le Chat gained a connector directory with 20+ enterprise integrations powered by the Model Context Protocol (MCP), spanning tools like Databricks, Snowflake, GitHub, Atlassian, Asana, and Stripe.&lt;/p&gt;&lt;p&gt;In October, Mistral unveiled &lt;a href="https://mistral.ai/products/ai-studio"&gt;AI Studio&lt;/a&gt;, a production AI platform providing observability, agent runtime, and AI registry capabilities to help enterprises track output changes, monitor usage, run evaluations, and fine-tune models using proprietary data.&lt;/p&gt;&lt;p&gt;Mistral now positions itself as a full-stack, global enterprise AI company, offering not just models but an application-building layer through AI Studio, compute infrastructure, and forward-deployed engineers to help businesses realize return on investment.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why open source AI matters for customization, transparency and sovereignty&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Mistral&amp;#x27;s commitment to open-source development under permissive licenses is both an ideological stance and a competitive strategy in an AI landscape increasingly dominated by closed systems.&lt;/p&gt;&lt;p&gt;Lample elaborated on the practical benefits: &amp;quot;I think something that people don&amp;#x27;t realize — but our customers know this very well — is how much better any model can actually improve if you fine tune it on the task of interest. There&amp;#x27;s a huge gap between a base model and one that&amp;#x27;s fine-tuned for a specific task, and in many cases, it outperforms the closed-source model.&amp;quot;&lt;/p&gt;&lt;p&gt;The approach enables capabilities impossible with closed systems: organizations can fine-tune models on proprietary data that never leaves their infrastructure, customize architectures for specific workflows, and maintain complete transparency into how AI systems make decisions — critical for regulated industries like finance, healthcare, and defense.&lt;/p&gt;&lt;p&gt;This positioning has attracted government and public sector partnerships. The company launched &amp;quot;&lt;a href="https://mistral.ai/news/ai-for-citizens"&gt;AI for Citizens&lt;/a&gt;&amp;quot; in July 2025, an initiative to &amp;quot;help States and public institutions strategically harness AI for their people by transforming public services&amp;quot; and has secured strategic partnerships with France&amp;#x27;s army and job agency, Luxembourg&amp;#x27;s government, and various European public sector organizations.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Mistral&amp;#x27;s transatlantic AI collaboration goes beyond European borders&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;While Mistral is frequently characterized as Europe&amp;#x27;s answer to OpenAI, the company views itself as a transatlantic collaboration rather than a purely European venture. The CEO (Arthur Mensch) is based in the United States, the company has teams across both continents, and these models are being trained in partnerships with U.S.-based teams and infrastructure providers.&lt;/p&gt;&lt;p&gt;This transatlantic positioning may prove strategically important as geopolitical tensions around AI development intensify. The recent ASML investment, a &lt;a href="https://www.nytimes.com/2025/09/09/business/asml-mistral-ai-chips-investment.html"&gt;€1.7 billion ($1.5 billion) funding round&lt;/a&gt; led by the Dutch semiconductor equipment manufacturer, signals deepening collaboration across the Western semiconductor and AI value chain at a moment when both Europe and the United States are seeking to reduce dependence on Chinese technology.&lt;/p&gt;&lt;p&gt;Mistral&amp;#x27;s investor base reflects this dynamic: the Series C round included participation from U.S. firms &lt;a href="https://a16z.com/"&gt;Andreessen Horowitz&lt;/a&gt;, &lt;a href="https://www.generalcatalyst.com/"&gt;General Catalyst&lt;/a&gt;, &lt;a href="https://www.lightspeedhq.com/"&gt;Lightspeed&lt;/a&gt;, and &lt;a href="https://www.indexventures.com/"&gt;Index Ventures&lt;/a&gt; alongside European investors like France&amp;#x27;s state-backed Bpifrance and global players like DST Global and Nvidia.&lt;/p&gt;&lt;p&gt;Founded in May 2023 by former Google DeepMind and Meta researchers, Mistral has raised roughly $1.05 billion (€1 billion) in funding. The company was valued at &lt;a href="https://techcrunch.com/2024/06/11/paris-based-ai-startup-mistral-ai-raises-640-million/"&gt;$6 billion&lt;/a&gt; in a June 2024 Series B, then &lt;a href="https://mistral.ai/news/mistral-ai-raises-1-7-b-to-accelerate-technological-progress-with-ai"&gt;more than doubled its valuation&lt;/a&gt; in a September Series C.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Can customization and efficiency beat raw performance in enterprise AI?&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3 &lt;/a&gt;release crystallizes a fundamental question facing the AI industry: Will enterprises ultimately prioritize the absolute cutting-edge capabilities of proprietary systems, or will they choose open, customizable alternatives that offer greater control, lower costs, and independence from big tech platforms?&lt;/p&gt;&lt;p&gt;Mistral&amp;#x27;s answer is unambiguous. The company is betting that as AI moves from prototype to production, the factors that matter most shift dramatically. Raw benchmark scores matter less than total cost of ownership. Slight performance edges matter less than the ability to fine-tune for specific workflows. Cloud-based convenience matters less than data sovereignty and edge deployment.&lt;/p&gt;&lt;p&gt;It&amp;#x27;s a wager with significant risks. Despite Lample&amp;#x27;s optimism about closing the performance gap, Mistral&amp;#x27;s models still trail the absolute frontier. The company&amp;#x27;s revenue, while growing, reportedly remains modest relative to its nearly $14 billion valuation. And competition intensifies from both well-funded Chinese rivals making remarkable open-source progress and U.S. tech giants increasingly offering their own smaller, more efficient models.&lt;/p&gt;&lt;p&gt;But if Mistral is right — if the future of AI looks less like a handful of cloud-based oracles and more like millions of specialized systems running everywhere from factory floors to smartphones — then the company has positioned itself at the center of that transformation.&lt;/p&gt;&lt;p&gt;The release of &lt;a href="https://mistral.ai/news/mistral-3"&gt;Mistral 3 &lt;/a&gt;is the most comprehensive expression yet of that vision: 10 models, spanning every size category, optimized for every deployment scenario, available to anyone who wants to build with them.&lt;/p&gt;&lt;p&gt;Whether &amp;quot;distributed intelligence&amp;quot; becomes the industry&amp;#x27;s dominant paradigm or remains a compelling alternative serving a narrower market will determine not just Mistral&amp;#x27;s fate, but the broader question of who controls the AI future — and whether that future will be open.&lt;/p&gt;&lt;p&gt;For now, the race is on. And Mistral is betting it can win not by building the biggest model, but by building everywhere else.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/mistral-launches-mistral-3-a-family-of-open-models-designed-to-run-on</guid><pubDate>Tue, 02 Dec 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Mistral closes in on Big AI rivals with new open-weight frontier and small models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/mistral-closes-in-on-big-ai-rivals-with-mistral-3-open-weight-frontier-and-small-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2147859992-e1713960898378.webp?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;French AI startup Mistral launched its new Mistral 3 family of open-weight models on Tuesday, a launch that aims to prove it can lead in making AI publicly available and serve business clients better than Big Tech rivals.&lt;/p&gt;&lt;p&gt;The 10-model release includes a large frontier model with multimodal and multilingual capabilities and nine smaller offline-capable, fully customizable models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes as Mistral, which develops open-weight language models and Europe-focused AI chatbot Le Chat, has appeared to be playing catch up with some of Silicon Valley’s closed-source frontier models. Open-weight models release their model weights publicly so anyone can download and run them. Meanwhile, closed-source models, like OpenAI’s ChatGPT, keep their weights proprietary and only provide access through APIs or controlled interfaces.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The two-year-old startup, founded by former DeepMind and Meta researchers, has raised about $2.7 billion to date at a $13.7 billion valuation — peanuts compared to the numbers that competitors like OpenAI ($57 billion raised at a $500 billion valuation) and Anthropic ($45 billion raised at a $350 billion valuation) are pulling.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Mistral is trying to prove that bigger isn’t always better — especially for enterprise use cases.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our customers are sometimes happy to start with a very large [closed] model that they don’t have to fine-tune … but when they deploy it, they realize it’s expensive, it’s slow,” Guillaume Lample, co-founder and chief scientist at Mistral, told TechCrunch. “Then they come to us to fine-tune small models to handle the use case [more efficiently].”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In practice, the huge majority of enterprise use cases are things that can be tackled by small models, especially if you fine-tune them,” Lample continued.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Initial benchmark comparisons, which place Mistral’s smaller models well behind its closed-source competitors, can be misleading, Lample said. Large closed-source models may perform better out-of-the-box, but the real gains happen when you customize.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“In many cases, you can actually match or even out-perform closed-source models,” he said.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral’s large frontier model, dubbed Mistral Large 3, catches up to some of the important capabilities that larger closed-source AI models like OpenAI’s GPT-4o and Google’s Gemini 2 boast, while also trading blows with several open-weight competitors. Large 3 is among the first open frontier models with multimodal and multilingual capabilities all in one, putting it on par with Meta’s Llama 3 and Alibaba’s Qwen3-Omni. Many other companies currently pair impressive large language models with separate smaller multi-modal models, something Mistral has done previously with models like Pixtral and Mistral Small 3.1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Large 3 also features a “granular Mixture of Experts” architecture with 41 billion active parameters and 675 billion total parameters, enabling efficient reasoning across a 256,000 context window. This design delivers both speed and capability, allowing it to process lengthy documents and function as an agentic assistant for complex enterprise tasks. Mistral positions Large 3 as suitable for document analysis, coding, content creation, AI assistants, and workflow automation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With its new family of small models, dubbed Ministral 3, the company is making the bold claim that smaller models aren’t just sufficient – they’re superior.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The lineup includes nine distinct, high-performance dense models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants: Base (the pre-trained foundation model), Instruct (chat-optimized for conversation and assistant-style workflows), and Reasoning (optimized for complex logic and analytical tasks).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral says this range gives developers and businesses the flexibility to match models to their exact performance, whether they’re after raw performance, cost efficiency, or specialized capabilities. The company claims Ministral 3 scores on par or better than other open-weight leaders while being more efficient and generating fewer tokens for equivalent tasks. All variants support vision, handle 128,000-256,000 context windows, and work across languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A major part of the pitch is practicality. Lample emphasizes that Ministral 3 can run on a single GPU, making it deployable on affordable hardware — from on-premise servers to laptops, robots, and other edge devices that may have limited connectivity. That matters not only for enterprises keeping data in-house, but also for students seeking feedback offline or robotics teams operating in remote environments. Greater efficiency, Lample argues, translates directly to broader accessibility.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s part of our mission to be sure that AI is accessible to everyone, especially people without internet access,” he said. “We don’t want AI to be controlled by only a couple of big labs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some other companies are pursuing similar efficiency trade-offs: Cohere’s latest enterprise model, Command A, also runs on just two GPUs, and its AI agent platform North can run on just one GPU.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That sort of accessibility is driving Mistral’s growing physical AI focus. Earlier this year, the company began working to integrate its smaller models into robots, drones, and vehicles. Mistral is collaborating with Singapore’s Home Team Science and Technology Agency (HTX) on specialized models for robots, cybersecurity systems, and fire safety; with German defense tech startup Helsing on vision-language-action models for drones; and with automaker Stellantis on an in-car AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Mistral, reliability and independence are just as critical as performance.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Using an API from our competitors that will go down for half an hour every two weeks — if you’re a big company, you cannot afford this,” Lample said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/GettyImages-2147859992-e1713960898378.webp?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;French AI startup Mistral launched its new Mistral 3 family of open-weight models on Tuesday, a launch that aims to prove it can lead in making AI publicly available and serve business clients better than Big Tech rivals.&lt;/p&gt;&lt;p&gt;The 10-model release includes a large frontier model with multimodal and multilingual capabilities and nine smaller offline-capable, fully customizable models. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch comes as Mistral, which develops open-weight language models and Europe-focused AI chatbot Le Chat, has appeared to be playing catch up with some of Silicon Valley’s closed-source frontier models. Open-weight models release their model weights publicly so anyone can download and run them. Meanwhile, closed-source models, like OpenAI’s ChatGPT, keep their weights proprietary and only provide access through APIs or controlled interfaces.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The two-year-old startup, founded by former DeepMind and Meta researchers, has raised about $2.7 billion to date at a $13.7 billion valuation — peanuts compared to the numbers that competitors like OpenAI ($57 billion raised at a $500 billion valuation) and Anthropic ($45 billion raised at a $350 billion valuation) are pulling.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Mistral is trying to prove that bigger isn’t always better — especially for enterprise use cases.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our customers are sometimes happy to start with a very large [closed] model that they don’t have to fine-tune … but when they deploy it, they realize it’s expensive, it’s slow,” Guillaume Lample, co-founder and chief scientist at Mistral, told TechCrunch. “Then they come to us to fine-tune small models to handle the use case [more efficiently].”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In practice, the huge majority of enterprise use cases are things that can be tackled by small models, especially if you fine-tune them,” Lample continued.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Initial benchmark comparisons, which place Mistral’s smaller models well behind its closed-source competitors, can be misleading, Lample said. Large closed-source models may perform better out-of-the-box, but the real gains happen when you customize.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“In many cases, you can actually match or even out-perform closed-source models,” he said.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral’s large frontier model, dubbed Mistral Large 3, catches up to some of the important capabilities that larger closed-source AI models like OpenAI’s GPT-4o and Google’s Gemini 2 boast, while also trading blows with several open-weight competitors. Large 3 is among the first open frontier models with multimodal and multilingual capabilities all in one, putting it on par with Meta’s Llama 3 and Alibaba’s Qwen3-Omni. Many other companies currently pair impressive large language models with separate smaller multi-modal models, something Mistral has done previously with models like Pixtral and Mistral Small 3.1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Large 3 also features a “granular Mixture of Experts” architecture with 41 billion active parameters and 675 billion total parameters, enabling efficient reasoning across a 256,000 context window. This design delivers both speed and capability, allowing it to process lengthy documents and function as an agentic assistant for complex enterprise tasks. Mistral positions Large 3 as suitable for document analysis, coding, content creation, AI assistants, and workflow automation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;With its new family of small models, dubbed Ministral 3, the company is making the bold claim that smaller models aren’t just sufficient – they’re superior.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The lineup includes nine distinct, high-performance dense models across three sizes (14 billion, 8 billion, and 3 billion parameters) and three variants: Base (the pre-trained foundation model), Instruct (chat-optimized for conversation and assistant-style workflows), and Reasoning (optimized for complex logic and analytical tasks).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mistral says this range gives developers and businesses the flexibility to match models to their exact performance, whether they’re after raw performance, cost efficiency, or specialized capabilities. The company claims Ministral 3 scores on par or better than other open-weight leaders while being more efficient and generating fewer tokens for equivalent tasks. All variants support vision, handle 128,000-256,000 context windows, and work across languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A major part of the pitch is practicality. Lample emphasizes that Ministral 3 can run on a single GPU, making it deployable on affordable hardware — from on-premise servers to laptops, robots, and other edge devices that may have limited connectivity. That matters not only for enterprises keeping data in-house, but also for students seeking feedback offline or robotics teams operating in remote environments. Greater efficiency, Lample argues, translates directly to broader accessibility.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s part of our mission to be sure that AI is accessible to everyone, especially people without internet access,” he said. “We don’t want AI to be controlled by only a couple of big labs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some other companies are pursuing similar efficiency trade-offs: Cohere’s latest enterprise model, Command A, also runs on just two GPUs, and its AI agent platform North can run on just one GPU.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That sort of accessibility is driving Mistral’s growing physical AI focus. Earlier this year, the company began working to integrate its smaller models into robots, drones, and vehicles. Mistral is collaborating with Singapore’s Home Team Science and Technology Agency (HTX) on specialized models for robots, cybersecurity systems, and fire safety; with German defense tech startup Helsing on vision-language-action models for drones; and with automaker Stellantis on an in-car AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Mistral, reliability and independence are just as critical as performance.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Using an API from our competitors that will go down for half an hour every two weeks — if you’re a big company, you cannot afford this,” Lample said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/mistral-closes-in-on-big-ai-rivals-with-mistral-3-open-weight-frontier-and-small-models/</guid><pubDate>Tue, 02 Dec 2025 15:37:07 +0000</pubDate></item><item><title>[NEW] AWS announces new capabilities for its AI agent builder (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/aws-announces-new-capabilities-for-its-ai-agent-builder/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/aws-reinvent-2024-logo.png?resize=1200,627" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services (AWS) is bulking up its AI agent platform, Amazon Bedrock AgentCore, to make building and monitoring AI agents easier for enterprises.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced multiple new AgentCore features on Tuesday during the company’s annual AWS re:Invent conference. The company announced new tools for managing AI agent boundaries, agent memory capabilities, and agent evaluation features.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One upgrade is the introduction of Policy in AgentCore. This feature allows users to set boundaries for agent interactions using natural language. These boundaries integrate with AgentCore Gateway, which connects AI agents with outside tools, to automatically check each agent’s action and stop those that violate written controls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Policy allows developers to set access controls to certain internal data or third-party applications like Salesforce or Slack. These boundaries can also include telling an AI agent they can automatically issue refunds up to $100 but must bring a human in the loop for anything larger, David Richardson, vice president of AgentCore, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced AgentCore Evaluations, which is a suite of 13 pre-built evaluation systems for AI agents that monitor factors including correctness, safety, and tool selection accuracy, among others. This also allows developers to have a head start in building their own evaluation features as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That one is really going to help address the biggest fears that people have [with] deploying agents,” Richardson said about the new evaluation capabilities. “[It’s] a thing that a lot of people want to have but is tedious to build.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that it’s building a memory capability into the agent platform, AgentCore Memory. This feature allows agents to develop a log of information on users over time, like their flight time or hotel preferences, and use that information to inform future decisions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Across these three things, we are continuing to iterate at the different layers at AgentCore,” Richardson said. “Talking to existing systems with Policy, [making agents] more powerful with [AgentCore Memory], helping the development team iterate with an agent.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While agents are the &lt;em&gt;soup du jour&lt;/em&gt; of the AI industry right now, some people believe the technology won’t last. But Richardson thinks that the tools AgentCore is developing can withstand the fast-moving market even as trends change — which he expects they will.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Being able to take advantage of the reasoning capabilities of these models, which is coupled with being able to do real-world things through tools, feels like a sustainable pattern,” Richardson said. “The way that pattern works will definitely change. I think we feel ready for that.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s coverage of the annual enterprise tech event here.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/aws-reinvent-2024-logo.png?resize=1200,627" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services (AWS) is bulking up its AI agent platform, Amazon Bedrock AgentCore, to make building and monitoring AI agents easier for enterprises.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced multiple new AgentCore features on Tuesday during the company’s annual AWS re:Invent conference. The company announced new tools for managing AI agent boundaries, agent memory capabilities, and agent evaluation features.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One upgrade is the introduction of Policy in AgentCore. This feature allows users to set boundaries for agent interactions using natural language. These boundaries integrate with AgentCore Gateway, which connects AI agents with outside tools, to automatically check each agent’s action and stop those that violate written controls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Policy allows developers to set access controls to certain internal data or third-party applications like Salesforce or Slack. These boundaries can also include telling an AI agent they can automatically issue refunds up to $100 but must bring a human in the loop for anything larger, David Richardson, vice president of AgentCore, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced AgentCore Evaluations, which is a suite of 13 pre-built evaluation systems for AI agents that monitor factors including correctness, safety, and tool selection accuracy, among others. This also allows developers to have a head start in building their own evaluation features as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That one is really going to help address the biggest fears that people have [with] deploying agents,” Richardson said about the new evaluation capabilities. “[It’s] a thing that a lot of people want to have but is tedious to build.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that it’s building a memory capability into the agent platform, AgentCore Memory. This feature allows agents to develop a log of information on users over time, like their flight time or hotel preferences, and use that information to inform future decisions.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Across these three things, we are continuing to iterate at the different layers at AgentCore,” Richardson said. “Talking to existing systems with Policy, [making agents] more powerful with [AgentCore Memory], helping the development team iterate with an agent.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While agents are the &lt;em&gt;soup du jour&lt;/em&gt; of the AI industry right now, some people believe the technology won’t last. But Richardson thinks that the tools AgentCore is developing can withstand the fast-moving market even as trends change — which he expects they will.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Being able to take advantage of the reasoning capabilities of these models, which is coupled with being able to do real-world things through tools, feels like a sustainable pattern,” Richardson said. “The way that pattern works will definitely change. I think we feel ready for that.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s coverage of the annual enterprise tech event here.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/aws-announces-new-capabilities-for-its-ai-agent-builder/</guid><pubDate>Tue, 02 Dec 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Amazon releases an impressive new AI chip and teases an Nvidia-friendly roadmap (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/01/GettyImages-1136663877.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services, which has been building its own AI training chips for years now, just introduced a new version known as Trainium3 that comes with some impressive specs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud provider, which made the announcement Tuesday at AWS re:Invent 2025, also teased the next product on its AI training product roadmap: Trainium4, which is already in the works and will be able to work with Nvidia’s chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS used its annual tech conference to formally launch Trainium3 UltraServer, a system powered by the company’s state-of-the art, 3 nanometer Trainium3 chip, as well as its homegrown networking tech.&amp;nbsp;As you might expect, the third-generation chip and system offer big bumps in performance for AI training and inference over the second-generation chip, according to AWS.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS says the system is more than 4x faster, with 4x more memory, not just for training, but for delivering AI apps at peak demand. Additionally, thousands of UltraServers can be linked together to provide an app with up to 1 million Trainium3 chips — 10x the previous generation. Each UltraServer can host 144 chips, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps more importantly, AWS says the chips and systems are also 40% more energy efficient than the previous generation.&amp;nbsp;While the world races to build bigger data centers powered by astronomical gigawatts of electricity, data center giant AWS is trying to make systems that drink less, not more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It is, obviously, in AWS’s direct interests to do so. But in its classic, Amazon cost-conscious way, it promises that these systems save its AI cloud customers money, too.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS customers like Anthropic (of which Amazon is also an investor), Japan’s LLM Karakuri, SplashMusic, and Decart have already been using the third-gen chip and system and significantly cut their inference costs, Amazon said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also presented a bit of a roadmap for the next chip, Trainium4, which is already in development. AWS promised the chip will provide another big step up in performance and support Nvidia’s NVLink Fusion high-speed chip interconnect technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This means the AWS Trainium4-powered systems will be able to interoperate and extend their performance with Nvidia GPUs while still using Amazon’s homegrown, lower-cost server rack technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting, too, that Nvidia’s CUDA (Compute Unified Device Architecture) has become the de facto standard that all the major AI apps are built to support. The Trainium4-powered systems may make it easier to woo big AI apps built with Nvidia GPUs in mind to Amazon’s cloud.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon did not announce a timeline for Trainium4. If the company follows previous rollout timelines, we’ll likely hear more about Trainium4 at next year’s conference.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s coverage of the annual enterprise tech event here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/01/GettyImages-1136663877.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services, which has been building its own AI training chips for years now, just introduced a new version known as Trainium3 that comes with some impressive specs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud provider, which made the announcement Tuesday at AWS re:Invent 2025, also teased the next product on its AI training product roadmap: Trainium4, which is already in the works and will be able to work with Nvidia’s chips.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS used its annual tech conference to formally launch Trainium3 UltraServer, a system powered by the company’s state-of-the art, 3 nanometer Trainium3 chip, as well as its homegrown networking tech.&amp;nbsp;As you might expect, the third-generation chip and system offer big bumps in performance for AI training and inference over the second-generation chip, according to AWS.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS says the system is more than 4x faster, with 4x more memory, not just for training, but for delivering AI apps at peak demand. Additionally, thousands of UltraServers can be linked together to provide an app with up to 1 million Trainium3 chips — 10x the previous generation. Each UltraServer can host 144 chips, according to the company.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perhaps more importantly, AWS says the chips and systems are also 40% more energy efficient than the previous generation.&amp;nbsp;While the world races to build bigger data centers powered by astronomical gigawatts of electricity, data center giant AWS is trying to make systems that drink less, not more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It is, obviously, in AWS’s direct interests to do so. But in its classic, Amazon cost-conscious way, it promises that these systems save its AI cloud customers money, too.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS customers like Anthropic (of which Amazon is also an investor), Japan’s LLM Karakuri, SplashMusic, and Decart have already been using the third-gen chip and system and significantly cut their inference costs, Amazon said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also presented a bit of a roadmap for the next chip, Trainium4, which is already in development. AWS promised the chip will provide another big step up in performance and support Nvidia’s NVLink Fusion high-speed chip interconnect technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This means the AWS Trainium4-powered systems will be able to interoperate and extend their performance with Nvidia GPUs while still using Amazon’s homegrown, lower-cost server rack technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s worth noting, too, that Nvidia’s CUDA (Compute Unified Device Architecture) has become the de facto standard that all the major AI apps are built to support. The Trainium4-powered systems may make it easier to woo big AI apps built with Nvidia GPUs in mind to Amazon’s cloud.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon did not announce a timeline for Trainium4. If the company follows previous rollout timelines, we’ll likely hear more about Trainium4 at next year’s conference.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s coverage of the annual enterprise tech event here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/amazon-releases-an-impressive-new-ai-chip-and-teases-a-nvidia-friendly-roadmap/</guid><pubDate>Tue, 02 Dec 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Simular’s AI agent wants to run your Mac, Windows PC for you (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/simular-releases-mac-os-ai-agent-raises-21-5m-from-felicis-with-windows-coming-soon/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Simular_team.jpg?resize=1200,808" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Simular, a startup building AI agents for Mac OS and Windows, has raised a $21.5 million Series A led by Felicis, with  NVentures (Nvidia’s venture arm), existing seed investor South Park Commons, and others joining in.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simular is an interesting agentic startup because unlike others, it isn’t trying to control the browser but the PC itself.&amp;nbsp;(Agentic AI refers to systems that can autonomously complete complex tasks with minimal human intervention.) “We can literally move the mouse on the screen and do the click. So it’s more capable of doing, repeating whatever human activities in the digital world,” co-founder CEO Ang Li told TechCrunch, offering the example of copying and pasting data into a spreadsheet.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Monday it announced the release of its 1.0 version for Mac OS. But it’s also working with Microsoft to develop an agent for Windows. The startup is one of five agentic companies accepted into the Windows 365 for Agents program Microsoft announced in mid November. (The others are Manus AI, Fellou, Genspark, and TinyFish.) As for the timeline for the Windows version, Li was vague except to say it promises to be as or more popular than the Mac version.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another reason to watch Simular is the bona fides of the founders: Li is a continuous learning scientist who previously worked at Google’s DeepMind, where he met his co-founder, reinforcement learning specialist Jiachen Yang. While their team published their fair share of papers, the work wasn’t strictly academic, Li said. It was intended to improve Google products, including Waymo.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That AI product background is helpful because, before the agentic future of Silicon Valley’s dreams can materialize, there are a host of technical problems to solve.&amp;nbsp;One of the biggest is that LLMs hallucinate some percentage of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agentic tasks can require completing thousands to millions of discrete steps. Not only can a hallucination at any single step invalidate all of the agent’s work, but hallucinations become statistically more likely as the number of steps grows.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One way to solve this is to make the “non deterministic” LLM “deterministic,” meaning instead of allowing the LLM to be endlessly creative, its responses or actions are scripted the same each time.&amp;nbsp;But that risks limiting the whole creative problem-solving aspect of an agent.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Simular is marrying the two. Its agent will iterate freely on the task, with the human user in the middle course correcting, until the agent achieves success. Then the human locks in that task’s workflow, which makes it deterministic, repeatable.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our solution is, let agents keep exploring the successful trajectory. Once you found a successful trajectory, that becomes deterministic code,” Li explains.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The reason the startup can do this is because its work — which Li admits is still early — is not just an LLM wrapper that sends and retrieves data to a model.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We have a new technology which is not used by any other agent company. We call it ‘neuro symbolic computer use agents.’ It’s not fully LLM-based,” he said. “Our approach to solve hallucinations is to let the LLM write code which becomes deterministic. So if you have a workflow that works, the next time we run the same workflow, it’ll be successful as well.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another benefit is that this deterministic code that performs a repeatable task is in the hands of the end user, not the LLM. “Once they have the code, they can trust it, because they can inspect it, they can audit it, they can see what’s going on,” Li says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Time will tell if this method is the magic that will bring agents into the hands of every worker. Li says his early beta customers include a car dealership automating VIN number searches, and HOAs extracting contract information from PDFs. And the company’s open source project (available only for Mac OS at the moment) has led to automations ranging from content creation to sales and marketing.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simular previously raised a $5 million seed, bringing its total raised to about $27 million. Other investors in the company include Basis Set Ventures, Flying Fish Partners, Samsung NEXT, Xoogler Ventures, and podcaster and angel investor Lenny Rachitsky, the company says.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Simular_team.jpg?resize=1200,808" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Simular, a startup building AI agents for Mac OS and Windows, has raised a $21.5 million Series A led by Felicis, with  NVentures (Nvidia’s venture arm), existing seed investor South Park Commons, and others joining in.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simular is an interesting agentic startup because unlike others, it isn’t trying to control the browser but the PC itself.&amp;nbsp;(Agentic AI refers to systems that can autonomously complete complex tasks with minimal human intervention.) “We can literally move the mouse on the screen and do the click. So it’s more capable of doing, repeating whatever human activities in the digital world,” co-founder CEO Ang Li told TechCrunch, offering the example of copying and pasting data into a spreadsheet.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Monday it announced the release of its 1.0 version for Mac OS. But it’s also working with Microsoft to develop an agent for Windows. The startup is one of five agentic companies accepted into the Windows 365 for Agents program Microsoft announced in mid November. (The others are Manus AI, Fellou, Genspark, and TinyFish.) As for the timeline for the Windows version, Li was vague except to say it promises to be as or more popular than the Mac version.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another reason to watch Simular is the bona fides of the founders: Li is a continuous learning scientist who previously worked at Google’s DeepMind, where he met his co-founder, reinforcement learning specialist Jiachen Yang. While their team published their fair share of papers, the work wasn’t strictly academic, Li said. It was intended to improve Google products, including Waymo.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That AI product background is helpful because, before the agentic future of Silicon Valley’s dreams can materialize, there are a host of technical problems to solve.&amp;nbsp;One of the biggest is that LLMs hallucinate some percentage of the time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Agentic tasks can require completing thousands to millions of discrete steps. Not only can a hallucination at any single step invalidate all of the agent’s work, but hallucinations become statistically more likely as the number of steps grows.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One way to solve this is to make the “non deterministic” LLM “deterministic,” meaning instead of allowing the LLM to be endlessly creative, its responses or actions are scripted the same each time.&amp;nbsp;But that risks limiting the whole creative problem-solving aspect of an agent.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Simular is marrying the two. Its agent will iterate freely on the task, with the human user in the middle course correcting, until the agent achieves success. Then the human locks in that task’s workflow, which makes it deterministic, repeatable.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our solution is, let agents keep exploring the successful trajectory. Once you found a successful trajectory, that becomes deterministic code,” Li explains.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The reason the startup can do this is because its work — which Li admits is still early — is not just an LLM wrapper that sends and retrieves data to a model.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We have a new technology which is not used by any other agent company. We call it ‘neuro symbolic computer use agents.’ It’s not fully LLM-based,” he said. “Our approach to solve hallucinations is to let the LLM write code which becomes deterministic. So if you have a workflow that works, the next time we run the same workflow, it’ll be successful as well.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another benefit is that this deterministic code that performs a repeatable task is in the hands of the end user, not the LLM. “Once they have the code, they can trust it, because they can inspect it, they can audit it, they can see what’s going on,” Li says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Time will tell if this method is the magic that will bring agents into the hands of every worker. Li says his early beta customers include a car dealership automating VIN number searches, and HOAs extracting contract information from PDFs. And the company’s open source project (available only for Mac OS at the moment) has led to automations ranging from content creation to sales and marketing.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Simular previously raised a $5 million seed, bringing its total raised to about $27 million. Other investors in the company include Basis Set Ventures, Flying Fish Partners, Samsung NEXT, Xoogler Ventures, and podcaster and angel investor Lenny Rachitsky, the company says.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/simular-releases-mac-os-ai-agent-raises-21-5m-from-felicis-with-windows-coming-soon/</guid><pubDate>Tue, 02 Dec 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] NVIDIA and AWS Expand Full-Stack Partnership, Providing the Secure, High-Performance Compute Platform Vital for Future Innovation (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/aws-partnership-expansion-reinvent/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/nvidia-aws-lockup-corp-blog-1280x680-1.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;At AWS re:Invent, NVIDIA and Amazon Web Services expanded their strategic collaboration with new technology integrations across interconnect technology, cloud infrastructure, open models and physical AI.&lt;/p&gt;
&lt;p&gt;As part of this expansion, AWS will support NVIDIA NVLink Fusion — a platform for custom AI infrastructure — for deploying its custom-designed silicon, including next-generation Trainium4 chips for inference and agentic AI model training, Graviton CPUs for a broad range of workloads and the Nitro System virtualization infrastructure.&lt;/p&gt;
&lt;p&gt;Using NVIDIA NVLink Fusion, AWS will combine NVIDIA NVLink scale-up interconnect and the NVIDIA MGX rack architecture with AWS custom silicon to increase performance and accelerate time to market for its next-generation cloud-scale AI capabilities.&lt;/p&gt;
&lt;p&gt;AWS is designing Trainium4 to integrate with NVLink and NVIDIA MGX, the first of a multigenerational collaboration between NVIDIA and AWS for NVLink Fusion.&lt;/p&gt;
&lt;p&gt;AWS has already deployed MGX racks at scale with NVIDIA GPUs. Integrating NVLink Fusion will allow AWS to further simplify deployment and systems management across its platforms.&lt;/p&gt;
&lt;p&gt;AWS can also harness the NVLink Fusion supplier ecosystem, which provides all the components required for full rack-scale deployment, from the rack and chassis, to power-delivery and cooling systems.&lt;/p&gt;
&lt;p&gt;By supporting AWS’s Elastic Fabric Adapter and Nitro System, the NVIDIA Vera Rubin architecture on AWS will give customers robust networking choices while maintaining full compatibility with AWS’s cloud infrastructure and accelerating new AI service rollout.&lt;/p&gt;
&lt;p&gt;“GPU compute demand is skyrocketing — more compute makes smarter AI, smarter AI drives broader use and broader use creates demand for even more compute. The virtuous cycle of AI has arrived,” said Jensen Huang, founder and CEO of NVIDIA. “With NVIDIA NVLink Fusion coming to AWS Trainium4, we’re unifying our scale-up architecture with AWS’s custom silicon to build a new generation of accelerated platforms. Together, NVIDIA and AWS are creating the compute fabric for the AI industrial revolution — bringing advanced AI to every company, in every country, and accelerating the world’s path to intelligence.”&lt;/p&gt;
&lt;p&gt;“AWS and NVIDIA have worked side by side for more than 15 years, and today marks a new milestone in that journey,” said Matt Garman, CEO of AWS. “With NVIDIA, we’re advancing our large-scale AI infrastructure to deliver customers the highest performance, efficiency and scalability. The upcoming support of NVIDIA NVLink Fusion in AWS Trainium4, Graviton and the Nitro System will bring new capabilities to customers so they can innovate faster than ever before.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Convergence of Scale and Sovereignty&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AWS has expanded its accelerated computing portfolio with the NVIDIA Blackwell architecture, including NVIDIA HGX B300 and NVIDIA GB300 NVL72 GPUs, giving customers immediate access to the industry’s most advanced GPUs for training and inference. Availability of NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, designed for visual applications, on AWS is expected in the coming weeks.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&lt;/b&gt;These GPUs form part of the AWS infrastructure backbone powering AWS AI Factories, a new AI cloud offering that will provide customers around the world with the dedicated infrastructure they need to harness advanced AI services and capabilities in their own data centers, operated by AWS, while also letting customers maintain control of their data and comply with local regulations.&lt;/p&gt;
&lt;p&gt;NVIDIA and AWS are committing to deploy sovereign AI clouds globally and bring the best of AI innovation to the world. With the launch of AWS AI Factories, the companies are providing secure, sovereign AI infrastructure to deliver unprecedented computing capabilities for organizations around the world while meeting increasingly rigorous sovereign AI requirements.&lt;/p&gt;
&lt;p&gt;For public sector organizations, AWS AI Factories will transform the federal supercomputing and AI landscape. AWS AI Factories customers will be able to seamlessly integrate AWS’s industry-leading cloud infrastructure and services — known for its reliability, security and scalability — with NVIDIA Blackwell GPUs and the full-stack NVIDIA accelerated computing platform, including NVIDIA Spectrum-X Ethernet switches.&lt;/p&gt;
&lt;p&gt;The unified architecture will ensure customers can access advanced AI services and capabilities, as well as train and deploy massive models, while maintaining absolute control of proprietary data and full compliance with local regulatory frameworks.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Nemotron Integration With Amazon Bedrock Expands Software Optimizations&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Beyond hardware, the partnership expands integration of NVIDIA’s software stack with the AWS AI ecosystem. NVIDIA Nemotron open models are now integrated with Amazon Bedrock, enabling customers to build generative AI applications and agents at production scale. Developers can access Nemotron Nano 2 and Nemotron Nano 2 VL to build specialized agentic AI applications that process text, code, images and video with high efficiency and accuracy.&lt;/p&gt;
&lt;p&gt;The integration makes high-performance, open NVIDIA models instantly accessible via Amazon Bedrock’s serverless platform where customers can rely on proven scalability and zero infrastructure management. Industry leaders CrowdStrike and BridgeWise are the first to use the service to deploy specialized AI agents.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Software on AWS Simplifies Developer Experience&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA and AWS are also co-engineering at the software layer to accelerate the data backbone of every enterprise. Amazon OpenSearch Service now offers serverless GPU acceleration for vector index building, powered by NVIDIA cuVS, an open-source library for GPU-accelerated vector search and data clustering. This milestone represents a fundamental shift to using GPUs for unstructured data processing, with early adopters seeing up to 10x faster vector indexing at a quarter of the cost.&lt;/p&gt;
&lt;p&gt;These dramatic gains reduce search latency, accelerate writes and unlock faster productivity for dynamic AI techniques like retrieval-augmented generation by delivering the right amount of GPU power precisely when it’s needed. AWS is the first major cloud provider to offer serverless vector indexing with NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;Production-ready AI agents require performance visibility, optimization and scalable infrastructure. By combining Strands Agents for agent development and orchestration, the NVIDIA NeMo Agent Toolkit for deep profiling and performance tuning, and Amazon Bedrock AgentCore for secure, scalable agent infrastructure, organizations can empower developers with a complete, predictable path from prototype to production.&lt;/p&gt;
&lt;p&gt;This expanded support builds on AWS’s existing integrations with NVIDIA technologies — including NVIDIA NIM microservices and frameworks like NVIDIA Riva and NVIDIA BioNeMo, as well as model development tools integrated with Amazon SageMaker and Amazon Bedrock — that enable organizations to deploy agentic AI, speech AI and scientific applications faster than ever.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Physical AI With AWS&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Developing physical AI demands high-quality and diverse datasets for training robot models, as well as frameworks for testing and validation in simulation before real-world deployment.&lt;/p&gt;
&lt;p&gt;NVIDIA Cosmos world foundation models (WFMs) are now available as NVIDIA NIM microservices on Amazon EKS, enabling real-time robotics control and simulation workloads with seamless reliability and cloud-native efficiency. For batch-based tasks and offline workloads such as large-scale synthetic data generation, Cosmos WFMs are also available on AWS Batch as containers.&lt;/p&gt;
&lt;p&gt;Cosmos-generated world states can then be used to train and validate robots using open-source simulation and learning frameworks such as NVIDIA Isaac Sim and Isaac Lab.&lt;/p&gt;
&lt;p&gt;Leading robotics companies such as Agility Robotics, Agile Robots, ANYbotics, Diligent Robotics, Dyna Robotics, Field AI, Haply Robotics, Lightwheel, RIVR and Skild AI are using the NVIDIA Isaac platform with AWS for use cases ranging from collecting, storing and processing robot-generated data to training and simulation for scaling robotics development.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Sustained Collaboration&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Underscoring years of continued collaboration, NVIDIA earned the AWS Global GenAI Infrastructure and Data Partner of the Year award, which recognizes top technology partners with the Generative AI Competency that support vector embeddings, data storage and management or synthetic data generation in multiple types and formats.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about NVIDIA and AWS’s collaboration and join sessions at &lt;/i&gt;&lt;i&gt;AWS re:Invent&lt;/i&gt;&lt;i&gt;, running through Friday, Dec. 5, in Las Vegas.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/12/nvidia-aws-lockup-corp-blog-1280x680-1.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;At AWS re:Invent, NVIDIA and Amazon Web Services expanded their strategic collaboration with new technology integrations across interconnect technology, cloud infrastructure, open models and physical AI.&lt;/p&gt;
&lt;p&gt;As part of this expansion, AWS will support NVIDIA NVLink Fusion — a platform for custom AI infrastructure — for deploying its custom-designed silicon, including next-generation Trainium4 chips for inference and agentic AI model training, Graviton CPUs for a broad range of workloads and the Nitro System virtualization infrastructure.&lt;/p&gt;
&lt;p&gt;Using NVIDIA NVLink Fusion, AWS will combine NVIDIA NVLink scale-up interconnect and the NVIDIA MGX rack architecture with AWS custom silicon to increase performance and accelerate time to market for its next-generation cloud-scale AI capabilities.&lt;/p&gt;
&lt;p&gt;AWS is designing Trainium4 to integrate with NVLink and NVIDIA MGX, the first of a multigenerational collaboration between NVIDIA and AWS for NVLink Fusion.&lt;/p&gt;
&lt;p&gt;AWS has already deployed MGX racks at scale with NVIDIA GPUs. Integrating NVLink Fusion will allow AWS to further simplify deployment and systems management across its platforms.&lt;/p&gt;
&lt;p&gt;AWS can also harness the NVLink Fusion supplier ecosystem, which provides all the components required for full rack-scale deployment, from the rack and chassis, to power-delivery and cooling systems.&lt;/p&gt;
&lt;p&gt;By supporting AWS’s Elastic Fabric Adapter and Nitro System, the NVIDIA Vera Rubin architecture on AWS will give customers robust networking choices while maintaining full compatibility with AWS’s cloud infrastructure and accelerating new AI service rollout.&lt;/p&gt;
&lt;p&gt;“GPU compute demand is skyrocketing — more compute makes smarter AI, smarter AI drives broader use and broader use creates demand for even more compute. The virtuous cycle of AI has arrived,” said Jensen Huang, founder and CEO of NVIDIA. “With NVIDIA NVLink Fusion coming to AWS Trainium4, we’re unifying our scale-up architecture with AWS’s custom silicon to build a new generation of accelerated platforms. Together, NVIDIA and AWS are creating the compute fabric for the AI industrial revolution — bringing advanced AI to every company, in every country, and accelerating the world’s path to intelligence.”&lt;/p&gt;
&lt;p&gt;“AWS and NVIDIA have worked side by side for more than 15 years, and today marks a new milestone in that journey,” said Matt Garman, CEO of AWS. “With NVIDIA, we’re advancing our large-scale AI infrastructure to deliver customers the highest performance, efficiency and scalability. The upcoming support of NVIDIA NVLink Fusion in AWS Trainium4, Graviton and the Nitro System will bring new capabilities to customers so they can innovate faster than ever before.”&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Convergence of Scale and Sovereignty&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;AWS has expanded its accelerated computing portfolio with the NVIDIA Blackwell architecture, including NVIDIA HGX B300 and NVIDIA GB300 NVL72 GPUs, giving customers immediate access to the industry’s most advanced GPUs for training and inference. Availability of NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs, designed for visual applications, on AWS is expected in the coming weeks.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;&lt;/b&gt;These GPUs form part of the AWS infrastructure backbone powering AWS AI Factories, a new AI cloud offering that will provide customers around the world with the dedicated infrastructure they need to harness advanced AI services and capabilities in their own data centers, operated by AWS, while also letting customers maintain control of their data and comply with local regulations.&lt;/p&gt;
&lt;p&gt;NVIDIA and AWS are committing to deploy sovereign AI clouds globally and bring the best of AI innovation to the world. With the launch of AWS AI Factories, the companies are providing secure, sovereign AI infrastructure to deliver unprecedented computing capabilities for organizations around the world while meeting increasingly rigorous sovereign AI requirements.&lt;/p&gt;
&lt;p&gt;For public sector organizations, AWS AI Factories will transform the federal supercomputing and AI landscape. AWS AI Factories customers will be able to seamlessly integrate AWS’s industry-leading cloud infrastructure and services — known for its reliability, security and scalability — with NVIDIA Blackwell GPUs and the full-stack NVIDIA accelerated computing platform, including NVIDIA Spectrum-X Ethernet switches.&lt;/p&gt;
&lt;p&gt;The unified architecture will ensure customers can access advanced AI services and capabilities, as well as train and deploy massive models, while maintaining absolute control of proprietary data and full compliance with local regulatory frameworks.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Nemotron Integration With Amazon Bedrock Expands Software Optimizations&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Beyond hardware, the partnership expands integration of NVIDIA’s software stack with the AWS AI ecosystem. NVIDIA Nemotron open models are now integrated with Amazon Bedrock, enabling customers to build generative AI applications and agents at production scale. Developers can access Nemotron Nano 2 and Nemotron Nano 2 VL to build specialized agentic AI applications that process text, code, images and video with high efficiency and accuracy.&lt;/p&gt;
&lt;p&gt;The integration makes high-performance, open NVIDIA models instantly accessible via Amazon Bedrock’s serverless platform where customers can rely on proven scalability and zero infrastructure management. Industry leaders CrowdStrike and BridgeWise are the first to use the service to deploy specialized AI agents.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Software on AWS Simplifies Developer Experience&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;NVIDIA and AWS are also co-engineering at the software layer to accelerate the data backbone of every enterprise. Amazon OpenSearch Service now offers serverless GPU acceleration for vector index building, powered by NVIDIA cuVS, an open-source library for GPU-accelerated vector search and data clustering. This milestone represents a fundamental shift to using GPUs for unstructured data processing, with early adopters seeing up to 10x faster vector indexing at a quarter of the cost.&lt;/p&gt;
&lt;p&gt;These dramatic gains reduce search latency, accelerate writes and unlock faster productivity for dynamic AI techniques like retrieval-augmented generation by delivering the right amount of GPU power precisely when it’s needed. AWS is the first major cloud provider to offer serverless vector indexing with NVIDIA GPUs.&lt;/p&gt;
&lt;p&gt;Production-ready AI agents require performance visibility, optimization and scalable infrastructure. By combining Strands Agents for agent development and orchestration, the NVIDIA NeMo Agent Toolkit for deep profiling and performance tuning, and Amazon Bedrock AgentCore for secure, scalable agent infrastructure, organizations can empower developers with a complete, predictable path from prototype to production.&lt;/p&gt;
&lt;p&gt;This expanded support builds on AWS’s existing integrations with NVIDIA technologies — including NVIDIA NIM microservices and frameworks like NVIDIA Riva and NVIDIA BioNeMo, as well as model development tools integrated with Amazon SageMaker and Amazon Bedrock — that enable organizations to deploy agentic AI, speech AI and scientific applications faster than ever.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Physical AI With AWS&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Developing physical AI demands high-quality and diverse datasets for training robot models, as well as frameworks for testing and validation in simulation before real-world deployment.&lt;/p&gt;
&lt;p&gt;NVIDIA Cosmos world foundation models (WFMs) are now available as NVIDIA NIM microservices on Amazon EKS, enabling real-time robotics control and simulation workloads with seamless reliability and cloud-native efficiency. For batch-based tasks and offline workloads such as large-scale synthetic data generation, Cosmos WFMs are also available on AWS Batch as containers.&lt;/p&gt;
&lt;p&gt;Cosmos-generated world states can then be used to train and validate robots using open-source simulation and learning frameworks such as NVIDIA Isaac Sim and Isaac Lab.&lt;/p&gt;
&lt;p&gt;Leading robotics companies such as Agility Robotics, Agile Robots, ANYbotics, Diligent Robotics, Dyna Robotics, Field AI, Haply Robotics, Lightwheel, RIVR and Skild AI are using the NVIDIA Isaac platform with AWS for use cases ranging from collecting, storing and processing robot-generated data to training and simulation for scaling robotics development.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Sustained Collaboration&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Underscoring years of continued collaboration, NVIDIA earned the AWS Global GenAI Infrastructure and Data Partner of the Year award, which recognizes top technology partners with the Generative AI Competency that support vector embeddings, data storage and management or synthetic data generation in multiple types and formats.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Learn more about NVIDIA and AWS’s collaboration and join sessions at &lt;/i&gt;&lt;i&gt;AWS re:Invent&lt;/i&gt;&lt;i&gt;, running through Friday, Dec. 5, in Las Vegas.&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/aws-partnership-expansion-reinvent/</guid><pubDate>Tue, 02 Dec 2025 16:00:27 +0000</pubDate></item><item><title>[NEW] AWS re:Invent 2025: How to watch and follow along live (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/aws-reinvent-2025-how-to-watch-and-follow-along-live/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/IMG_3817.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ big annual event, re:Invent 2025, is getting into full swing in Las Vegas today. Last year’s event was largely focused on their AI efforts, including new foundation models, services tackling AI hallucinations, and new security measures. And this year is likely to follow suit, based on what Amazon has announced so far and the lineup of speakers and programming that you can explore in more detail below.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The event formally kicks off this morning, December 2, at 8 a.m. PT. You can expect editorial coverage of the keynotes, interviews with AWS execs, and a roundup of news as the week’s programming rolls out, all of which you’ll be able to find on our site or by just keeping tabs on our AWS re:Invent tag.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s become the norm for events like re:Invent to broadcast keynotes and select programming — we just did something similar for TechCrunch Disrupt 2025 — and you can check out a breadth of streams with no ticket necessary below:&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-aws-re-invent-keynote-addresses"&gt;AWS re:Invent keynote addresses&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This year’s re:Invent features five keynotes from Tuesday through Thursday, with, of course, a clear focus on AI. You can follow along with each of those keynotes via the scheduled livestreams below. Or you can just go to Fortnite (yes, really) and watch their five keynotes live there.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ceo-matt-garman-december-2-at-8-a-m-pt"&gt;AWS CEO Matt Garman: December 2 at 8 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-vp-of-agentic-ai-swami-sivasubramanian-december-3-at-8-30-a-m-pt"&gt;AWS VP of Agentic AI Swami Sivasubramanian: December 3 at 8:30 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-vp-of-global-specialists-and-partners-aws-dr-ruba-borno-december-3-at-3-p-m-pt"&gt;VP of Global Specialists and Partners, AWS Dr. Ruba Borno: December 3 at 3 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-svp-of-utility-computing-peter-desantis-vp-of-compute-and-machine-learning-services-aws-december-4-at-9-a-m-pt"&gt;SVP of Utility Computing Peter DeSantis, VP of Compute and Machine Learning Services, AWS: December 4 at 9 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-cto-of-amazon-com-dr-werner-vogels-december-4-at-3-30-p-m-pt"&gt;CTO of Amazon.com Dr. Werner Vogels: December 4 at 3:30 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-aws-re-invent-partner-showcases"&gt;AWS re:Invent partner showcases&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;A series of industry-specific partner showcases will also be livestreamed for those not on the ground in Las Vegas, with a series of streams that extend throughout the run of the event.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-aws-security-day-one-december-2-at-10-a-m-pt"&gt;AWS Security, Day One: December 2 at 10 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ai-day-one-december-2-at-2-p-m-pt"&gt;AWS AI, Day One: December 2 at 2 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ai-day-two-december-3-at-10-a-m-pt"&gt;AWS AI, Day Two: December 3 at 10 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-security-day-two-december-3-at-4-30-p-m-pt"&gt;AWS Security, Day Two: December 3 at 4:30 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-security-day-three-december-4-at-10-00-a-m-pt"&gt;AWS Security, Day Three: December 4 at 10:00 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ai-day-three-december-4-at-11-35-a-m-pt"&gt;AWS AI, Day Three: December 4 at 11:35 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-industries-december-4-at-1-40-p-m-pt"&gt;AWS Industries: December 4 at 1:40 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also has partnered with companies like TechCrunch to highlight a sponsored showcase of their AWS OnAir programming in particular, which kicked off Monday to preview the event and highlight some early reveals, which you can watch the archive of on Twitch:&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/IMG_3817.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ big annual event, re:Invent 2025, is getting into full swing in Las Vegas today. Last year’s event was largely focused on their AI efforts, including new foundation models, services tackling AI hallucinations, and new security measures. And this year is likely to follow suit, based on what Amazon has announced so far and the lineup of speakers and programming that you can explore in more detail below.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The event formally kicks off this morning, December 2, at 8 a.m. PT. You can expect editorial coverage of the keynotes, interviews with AWS execs, and a roundup of news as the week’s programming rolls out, all of which you’ll be able to find on our site or by just keeping tabs on our AWS re:Invent tag.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s become the norm for events like re:Invent to broadcast keynotes and select programming — we just did something similar for TechCrunch Disrupt 2025 — and you can check out a breadth of streams with no ticket necessary below:&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-aws-re-invent-keynote-addresses"&gt;AWS re:Invent keynote addresses&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This year’s re:Invent features five keynotes from Tuesday through Thursday, with, of course, a clear focus on AI. You can follow along with each of those keynotes via the scheduled livestreams below. Or you can just go to Fortnite (yes, really) and watch their five keynotes live there.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ceo-matt-garman-december-2-at-8-a-m-pt"&gt;AWS CEO Matt Garman: December 2 at 8 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-vp-of-agentic-ai-swami-sivasubramanian-december-3-at-8-30-a-m-pt"&gt;AWS VP of Agentic AI Swami Sivasubramanian: December 3 at 8:30 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-vp-of-global-specialists-and-partners-aws-dr-ruba-borno-december-3-at-3-p-m-pt"&gt;VP of Global Specialists and Partners, AWS Dr. Ruba Borno: December 3 at 3 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-svp-of-utility-computing-peter-desantis-vp-of-compute-and-machine-learning-services-aws-december-4-at-9-a-m-pt"&gt;SVP of Utility Computing Peter DeSantis, VP of Compute and Machine Learning Services, AWS: December 4 at 9 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-cto-of-amazon-com-dr-werner-vogels-december-4-at-3-30-p-m-pt"&gt;CTO of Amazon.com Dr. Werner Vogels: December 4 at 3:30 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-aws-re-invent-partner-showcases"&gt;AWS re:Invent partner showcases&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;A series of industry-specific partner showcases will also be livestreamed for those not on the ground in Las Vegas, with a series of streams that extend throughout the run of the event.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-aws-security-day-one-december-2-at-10-a-m-pt"&gt;AWS Security, Day One: December 2 at 10 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ai-day-one-december-2-at-2-p-m-pt"&gt;AWS AI, Day One: December 2 at 2 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ai-day-two-december-3-at-10-a-m-pt"&gt;AWS AI, Day Two: December 3 at 10 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-security-day-two-december-3-at-4-30-p-m-pt"&gt;AWS Security, Day Two: December 3 at 4:30 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-security-day-three-december-4-at-10-00-a-m-pt"&gt;AWS Security, Day Three: December 4 at 10:00 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-ai-day-three-december-4-at-11-35-a-m-pt"&gt;AWS AI, Day Three: December 4 at 11:35 a.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-aws-industries-december-4-at-1-40-p-m-pt"&gt;AWS Industries: December 4 at 1:40 p.m. PT&lt;/h3&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also has partnered with companies like TechCrunch to highlight a sponsored showcase of their AWS OnAir programming in particular, which kicked off Monday to preview the event and highlight some early reveals, which you can watch the archive of on Twitch:&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/aws-reinvent-2025-how-to-watch-and-follow-along-live/</guid><pubDate>Tue, 02 Dec 2025 16:24:51 +0000</pubDate></item><item><title>[NEW] OpenAI slammed for app suggestions that looked like ads (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/openai-slammed-for-app-suggestions-that-looked-like-ads/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT’s unwelcome suggestion for a Peloton app during a conversation led to some backlash from OpenAI customers. People feared that ads had arrived, even for paid customers. OpenAI, however, clarified that the app suggestion was not an advertisement, but instead a poor attempt to integrate an app discovery feature within conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post on X, which has since been viewed nearly 462,000 times, AI startup Hyberbolic’s co-founder, Yuchen Jin, shared a screenshot where ChatGPT seemingly suggested connecting the Peloton app in an unrelated conversation. Worse still, Jin noted he was a paid subscriber to ChatGPT’s $200 per month Pro Plan. At that price point, ads would not be expected. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The post, which was reshared and saved hundreds of times across X, received quite a bit of attention, as it seemed to indicate OpenAI was testing the insertion of ads into its paid product. Users complained that paying customers, especially, shouldn’t have to see app suggestions like this.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One person also pointed out that they couldn’t get ChatGPT to stop recommending Spotify to them, even though they were an Apple Music subscriber. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Hey, Kol. Thanks for flagging 🙏 This is not an ad (there's no financial component). It's only a suggestion to install Peloton's app. But the lack of relevancy makes it a bad/confusing experience. We're iterating on the suggestions and UX, trying to make sure they're awesome.&lt;/p&gt;— Daniel McAuley (@_dmca) December 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s data lead for ChatGPT, Daniel McAuley, later jumped into the thread to clarify that the Peloton placement was not an ad; it was “only a suggestion to install Peloton’s app.” He said there was “no financial component” to the appearance of the app suggestion. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, he admitted that “the lack of relevancy” to the conversation made it a bad and confusing experience, and OpenAI was iterating on the suggestions and the user experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson also confirmed to TechCrunch that what users had spotted was one of the ways OpenAI had been “testing surfacing apps in ChatGPT conversations.” They pointed to OpenAI’s announcement in October about its new app platform, where the company noted that apps would “fit naturally” into user conversations. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“You can discover [apps] when ChatGPT suggests one at the right time, or by calling them by name. Apps respond to natural language and include interactive interfaces you can use right in the chat,” the post explained. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But that didn’t appear to be the case here, as the user claims they weren’t discussing anything related to health and fitness. Instead, as the screenshot shows, they had been chatting with the AI about a podcast featuring Elon Musk, where xAI was the topic being discussed. Inserting Peloton into this experience was unhelpful and a distraction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yet even if the app suggestion had been relevant, users may have still viewed it as an ad, given that it’s directing people to a product from a business that isn’t free. In addition, users can’t turn off these app suggestions, which may make them feel more intrusive.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This user sentiment could have potential ramifications for OpenAI’s desire to replace the App Store experience, and apps that run on your phone, with integrated apps that run within ChatGPT. If users don’t want to see app suggestions, they could choose to switch to a competitor’s chatbot to avoid them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, ChatGPT apps are available to logged-in users outside of the EU, Switzerland, and the U.K., and the integrations are still in pilot testing. OpenAI partners with a number of app makers, including Booking.com, Canva, Coursera, Figma, Expedia, Zillow, and others. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT’s unwelcome suggestion for a Peloton app during a conversation led to some backlash from OpenAI customers. People feared that ads had arrived, even for paid customers. OpenAI, however, clarified that the app suggestion was not an advertisement, but instead a poor attempt to integrate an app discovery feature within conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a post on X, which has since been viewed nearly 462,000 times, AI startup Hyberbolic’s co-founder, Yuchen Jin, shared a screenshot where ChatGPT seemingly suggested connecting the Peloton app in an unrelated conversation. Worse still, Jin noted he was a paid subscriber to ChatGPT’s $200 per month Pro Plan. At that price point, ads would not be expected. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The post, which was reshared and saved hundreds of times across X, received quite a bit of attention, as it seemed to indicate OpenAI was testing the insertion of ads into its paid product. Users complained that paying customers, especially, shouldn’t have to see app suggestions like this.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One person also pointed out that they couldn’t get ChatGPT to stop recommending Spotify to them, even though they were an Apple Music subscriber. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Hey, Kol. Thanks for flagging 🙏 This is not an ad (there's no financial component). It's only a suggestion to install Peloton's app. But the lack of relevancy makes it a bad/confusing experience. We're iterating on the suggestions and UX, trying to make sure they're awesome.&lt;/p&gt;— Daniel McAuley (@_dmca) December 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s data lead for ChatGPT, Daniel McAuley, later jumped into the thread to clarify that the Peloton placement was not an ad; it was “only a suggestion to install Peloton’s app.” He said there was “no financial component” to the appearance of the app suggestion. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, he admitted that “the lack of relevancy” to the conversation made it a bad and confusing experience, and OpenAI was iterating on the suggestions and the user experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson also confirmed to TechCrunch that what users had spotted was one of the ways OpenAI had been “testing surfacing apps in ChatGPT conversations.” They pointed to OpenAI’s announcement in October about its new app platform, where the company noted that apps would “fit naturally” into user conversations. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“You can discover [apps] when ChatGPT suggests one at the right time, or by calling them by name. Apps respond to natural language and include interactive interfaces you can use right in the chat,” the post explained. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But that didn’t appear to be the case here, as the user claims they weren’t discussing anything related to health and fitness. Instead, as the screenshot shows, they had been chatting with the AI about a podcast featuring Elon Musk, where xAI was the topic being discussed. Inserting Peloton into this experience was unhelpful and a distraction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Yet even if the app suggestion had been relevant, users may have still viewed it as an ad, given that it’s directing people to a product from a business that isn’t free. In addition, users can’t turn off these app suggestions, which may make them feel more intrusive.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This user sentiment could have potential ramifications for OpenAI’s desire to replace the App Store experience, and apps that run on your phone, with integrated apps that run within ChatGPT. If users don’t want to see app suggestions, they could choose to switch to a competitor’s chatbot to avoid them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, ChatGPT apps are available to logged-in users outside of the EU, Switzerland, and the U.K., and the integrations are still in pilot testing. OpenAI partners with a number of app makers, including Booking.com, Canva, Coursera, Figma, Expedia, Zillow, and others. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/openai-slammed-for-app-suggestions-that-looked-like-ads/</guid><pubDate>Tue, 02 Dec 2025 16:43:21 +0000</pubDate></item><item><title>[NEW] Amazon's new AI can code for days without human help. What does that mean for software engineers? (AI | VentureBeat)</title><link>https://venturebeat.com/ai/amazons-new-ai-can-code-for-days-without-human-help-what-does-that-mean-for</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://aws.amazon.com/"&gt;&lt;u&gt;Amazon Web Services&lt;/u&gt;&lt;/a&gt; on Tuesday announced a new class of artificial intelligence systems called &amp;quot;&lt;a href="https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro"&gt;&lt;u&gt;frontier agents&lt;/u&gt;&lt;/a&gt;&amp;quot; that can work autonomously for hours or even days without human intervention, representing one of the most ambitious attempts yet to automate the full software development lifecycle.&lt;/p&gt;&lt;p&gt;The announcement, made during AWS CEO Matt Garman&amp;#x27;s &lt;a href="https://reinvent.awsevents.com/keynotes/"&gt;&lt;u&gt;keynote address&lt;/u&gt;&lt;/a&gt; at the company&amp;#x27;s annual &lt;a href="https://reinvent.awsevents.com/"&gt;&lt;u&gt;re:Invent conference&lt;/u&gt;&lt;/a&gt;, introduces three specialized AI agents designed to act as virtual team members: Kiro autonomous agent for software development, AWS Security Agent for application security, and AWS DevOps Agent for IT operations.&lt;/p&gt;&lt;p&gt;The move signals Amazon&amp;#x27;s intent to leap ahead in the intensifying competition to build AI systems capable of performing complex, multi-step tasks that currently require teams of skilled engineers.&lt;/p&gt;&lt;p&gt;&amp;quot;We see frontier agents as a completely new class of agents,&amp;quot; said Deepak Singh, vice president of developer agents and experiences at Amazon, in an interview ahead of the announcement. &amp;quot;They&amp;#x27;re fundamentally designed to work for hours and days. You&amp;#x27;re not giving them a problem that you want finished in the next five minutes. You&amp;#x27;re giving them complex challenges that they may have to think about, try different solutions, and get to the right conclusion — and they should do that without intervention.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Amazon believes its new agents leave existing AI coding tools behind&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The frontier agents differ from existing AI coding assistants like &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt; or Amazon&amp;#x27;s own &lt;a href="https://aws.amazon.com/blogs/machine-learning/introducing-amazon-codewhisperer-the-ml-powered-coding-companion/"&gt;&lt;u&gt;CodeWhisperer&lt;/u&gt;&lt;/a&gt; in several fundamental ways.&lt;/p&gt;&lt;p&gt;Current AI coding tools, while powerful, require engineers to drive every interaction. Developers must write prompts, provide context, and manually coordinate work across different code repositories. When switching between tasks, the AI loses context and must start fresh.&lt;/p&gt;&lt;p&gt;The new frontier agents, by contrast, maintain persistent memory across sessions and continuously learn from an organization&amp;#x27;s codebase, documentation, and team communications. They can independently determine which code repositories require changes, work on multiple files simultaneously, and coordinate complex transformations spanning dozens of microservices.&lt;/p&gt;&lt;p&gt;&amp;quot;With a current agent, you would go microservice by microservice, making changes one at a time, and each change would be a different session with no shared context,&amp;quot; Singh explained. &amp;quot;With a frontier agent, you say, &amp;#x27;I need to solve this broad problem.&amp;#x27; You point it to the right application, and it decides which repos need changes.&amp;quot;&lt;/p&gt;&lt;p&gt;The agents exhibit three defining characteristics that AWS believes set them apart: autonomy in decision-making, the ability to scale by spawning multiple agents to work on different aspects of a problem simultaneously, and the capacity to operate independently for extended periods.&lt;/p&gt;&lt;p&gt;&amp;quot;A frontier agent can decide to spin up 10 versions of itself, all working on different parts of the problem at once,&amp;quot; Singh said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How each of the three frontier agents tackles a different phase of development&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://g"&gt;&lt;u&gt;Kiro autonomous agent&lt;/u&gt;&lt;/a&gt; serves as a virtual developer that maintains context across coding sessions and learns from an organization&amp;#x27;s pull requests, code reviews, and technical discussions. Teams can connect it to GitHub, Jira, Slack, and internal documentation systems. The agent then acts like a teammate, accepting task assignments and working independently until it either completes the work or requires human guidance.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro"&gt;&lt;u&gt;AWS Security Agent&lt;/u&gt;&lt;/a&gt; embeds security expertise throughout the development process, automatically reviewing design documents and scanning pull requests against organizational security requirements. Perhaps most significantly, it transforms penetration testing from a weeks-long manual process into an on-demand capability that completes in hours.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro"&gt;&lt;u&gt;SmugMug&lt;/u&gt;&lt;/a&gt;, a photo hosting platform, has already deployed the security agent. &amp;quot;AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly,&amp;quot; said Andres Ruiz, staff software engineer at the company. &amp;quot;To any other tool, this would have been invisible. But the ability for Security Agent to contextualize the information, parse the API response, and find the unexpected information there represents a leap forward in automated security testing.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/devops-agent-preview-frontier-agent-operational-excellence/"&gt;&lt;u&gt;AWS DevOps Agent&lt;/u&gt;&lt;/a&gt; functions as an always-on operations team member, responding instantly to incidents and using its accumulated knowledge to identify root causes. It connects to observability tools including Amazon CloudWatch, Datadog, Dynatrace, New Relic, and Splunk, along with runbooks and deployment pipelines.&lt;/p&gt;&lt;p&gt;Commonwealth Bank of Australia tested the DevOps agent by replicating a complex network and identity management issue that typically requires hours for experienced engineers to diagnose. The agent identified the root cause in under 15 minutes.&lt;/p&gt;&lt;p&gt;&amp;quot;AWS DevOps Agent thinks and acts like a seasoned DevOps engineer, helping our engineers build a banking infrastructure that&amp;#x27;s faster, more resilient, and designed to deliver better experiences for our customers,&amp;quot; said Jason Sandry, head of cloud services at Commonwealth Bank.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Amazon makes its case against Google and Microsoft in the AI coding wars&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The announcement arrives amid a fierce battle among technology giants to dominate the emerging market for AI-powered development tools. Google has made significant noise in recent weeks with its own &lt;a href="https://cloud.google.com/use-cases/ai-code-generation?hl=en"&gt;&lt;u&gt;AI coding capabilities&lt;/u&gt;&lt;/a&gt;, while Microsoft continues to advance &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt; and its broader AI development toolkit.&lt;/p&gt;&lt;p&gt;Singh argued that AWS holds distinct advantages rooted in the company&amp;#x27;s 20-year history operating cloud infrastructure and Amazon&amp;#x27;s own massive software engineering organization.&lt;/p&gt;&lt;p&gt;&amp;quot;AWS has been the cloud of choice for 20 years, so we have two decades of knowledge building and running it, and working with customers who&amp;#x27;ve been building and running applications on it,&amp;quot; Singh said. &amp;quot;The learnings from operating AWS, the knowledge our customers have, the experience we&amp;#x27;ve built using these tools ourselves every day to build real-world applications—all of that is embodied in these frontier agents.&amp;quot;&lt;/p&gt;&lt;p&gt;He drew a distinction between tools suitable for prototypes versus production systems. &amp;quot;There&amp;#x27;s a lot of things out there that you can use to build your prototype or your toy application. But if you want to build production applications, there&amp;#x27;s a lot of knowledge that we bring in as AWS that apply here.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The safeguards Amazon built to keep autonomous agents from going rogue&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The prospect of AI systems operating autonomously for days raises immediate questions about what happens when they go off track. Singh described multiple safeguards built into the system.&lt;/p&gt;&lt;p&gt;All learnings accumulated by the agents are logged and visible, allowing engineers to understand what knowledge influences the agent&amp;#x27;s decisions. Teams can even remove specific learnings if they discover the agent has absorbed incorrect information from team communications.&lt;/p&gt;&lt;p&gt;&amp;quot;You can go in and even redact that from its knowledge like, &amp;#x27;No, we don&amp;#x27;t want you to ever use this knowledge,&amp;#x27;&amp;quot; Singh said. &amp;quot;You can look at the knowledge like it&amp;#x27;s almost—it&amp;#x27;s like looking at your neurons inside your brain. You can disconnect some.&amp;quot;&lt;/p&gt;&lt;p&gt;Engineers can also monitor agent activity in real-time and intervene when necessary, either redirecting the agent or taking over entirely. Most critically, the agents never commit code directly to production systems. That responsibility remains with human engineers.&lt;/p&gt;&lt;p&gt;&amp;quot;These agents are never going to check the code into production. That is still the human&amp;#x27;s responsibility,&amp;quot; Singh emphasized. &amp;quot;You are still, as an engineer, responsible for the code you&amp;#x27;re checking in, whether it&amp;#x27;s generated by you or by an agent working autonomously.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What frontier agents mean for the future of software engineering jobs&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The announcement inevitably raises concerns about the impact on software engineering jobs. Singh pushed back against the notion that frontier agents will replace developers, framing them instead as tools that amplify human capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;Software engineering is craft. What&amp;#x27;s changing is not, &amp;#x27;Hey, agents are doing all the work.&amp;#x27; The craft of software engineering is changing—how you use agents, how do you set up your code base, how do you set up your prompts, how do you set up your rules, how do you set up your knowledge bases so that agents can be effective,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Singh noted that senior engineers who had drifted away from hands-on coding are now writing more code than ever. &amp;quot;It&amp;#x27;s actually easier for them to become software engineers,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;He pointed to an internal example where a team completed a project in 78 days that would have taken 18 months using traditional practices. &amp;quot;Because they were able to use AI. And the thing that made it work was not just the fact that they were using AI, but how they organized and set up their practices of how they built that software were maximized around that.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Amazon plans to make AI-generated code more trustworthy over time&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Singh outlined several areas where frontier agents will evolve over the coming years. Multi-agent architectures, where systems of specialized agents coordinate to solve complex problems, represent a major frontier. So does the integration of formal verification techniques to increase confidence in AI-generated code.&lt;/p&gt;&lt;p&gt;AWS recently introduced property-based testing in Kiro, which uses automated reasoning to extract testable properties from specifications and generate thousands of test scenarios automatically.&lt;/p&gt;&lt;p&gt;&amp;quot;If you have a shopping cart application, every way an order can be canceled, and how it might be canceled, and the way refunds are handled in Germany versus the US—if you&amp;#x27;re writing a unit test, maybe two, Germany and US, but now, because you have this property-based testing approach, your agent can create a scenario for every country you operate in and test all of them automatically for you,&amp;quot; Singh explained.&lt;/p&gt;&lt;p&gt;Building trust in autonomous systems remains the central challenge. &amp;quot;Right now you still require tons of human guardrails at every step to make sure that the right thing happens. And as we get better at these techniques, you will use less and less, and you&amp;#x27;ll be able to trust the agents a lot more,&amp;quot; he said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Amazon&amp;#x27;s bigger bet on autonomous AI stretches far beyond writing code&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The frontier agents announcement arrived alongside a cascade of other news at &lt;a href="https://www.aboutamazon.com/news/aws/aws-re-invent-2025-ai-news-updates"&gt;&lt;u&gt;re:Invent 2025&lt;/u&gt;&lt;/a&gt;. AWS kicked off the conference with major announcements on agentic AI capabilities, customer service innovations, and multicloud networking.&lt;/p&gt;&lt;p&gt;Amazon expanded its Nova portfolio with &lt;a href="https://www.aboutamazon.com/news/aws/aws-agentic-ai-amazon-bedrock-nova-models"&gt;&lt;u&gt;four new models&lt;/u&gt;&lt;/a&gt; delivering industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge pioneers &amp;quot;open training,&amp;quot; giving organizations access to pre-trained model checkpoints and the ability to blend proprietary data with Amazon Nova-curated datasets.&lt;/p&gt;&lt;p&gt;AWS also added &lt;a href="https://aws.amazon.com/blogs/aws/amazon-bedrock-adds-fully-managed-open-weight-models/"&gt;&lt;u&gt;18 new open weight models to Amazon Bedrock&lt;/u&gt;&lt;/a&gt;, reinforcing its commitment to offering a broad selection of fully managed models from leading AI providers. The launch includes new models from Mistral AI, Google&amp;#x27;s Gemma 3, MiniMax&amp;#x27;s M2, NVIDIA&amp;#x27;s Nemotron, and OpenAI&amp;#x27;s GPT OSS Safeguard.&lt;/p&gt;&lt;p&gt;On the infrastructure side, &lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-trn3-ultraservers/"&gt;&lt;u&gt;Amazon EC2 Trn3 UltraServers&lt;/u&gt;&lt;/a&gt;, powered by AWS&amp;#x27;s first 3nm AI chip, pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance and 4x greater energy efficiency than the previous generation. AWS AI Factories provides enterprises and government organizations with dedicated AWS AI infrastructure deployed in their own data centers, combining NVIDIA GPUs, Trainium chips, AWS networking, and AI services like Amazon Bedrock and SageMaker AI.&lt;/p&gt;&lt;p&gt;All three frontier agents launched in preview on Tuesday. Pricing will be announced when the services reach general availability.&lt;/p&gt;&lt;p&gt;Singh made clear the company sees applications far beyond coding. &amp;quot;These are the first frontier agents we are releasing, and they&amp;#x27;re in the software development lifecycle,&amp;quot; he said. &amp;quot;The problems and use cases for frontier agents—these agents that are long running, capable of autonomy, thinking, always learning and improving—can be applied to many, many domains.&amp;quot;&lt;/p&gt;&lt;p&gt;Amazon, after all, operates satellite networks, runs robotics warehouses, and manages one of the world&amp;#x27;s largest e-commerce platforms. If autonomous agents can learn to write code on their own, the company is betting they can eventually learn to do just about anything else.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://aws.amazon.com/"&gt;&lt;u&gt;Amazon Web Services&lt;/u&gt;&lt;/a&gt; on Tuesday announced a new class of artificial intelligence systems called &amp;quot;&lt;a href="https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro"&gt;&lt;u&gt;frontier agents&lt;/u&gt;&lt;/a&gt;&amp;quot; that can work autonomously for hours or even days without human intervention, representing one of the most ambitious attempts yet to automate the full software development lifecycle.&lt;/p&gt;&lt;p&gt;The announcement, made during AWS CEO Matt Garman&amp;#x27;s &lt;a href="https://reinvent.awsevents.com/keynotes/"&gt;&lt;u&gt;keynote address&lt;/u&gt;&lt;/a&gt; at the company&amp;#x27;s annual &lt;a href="https://reinvent.awsevents.com/"&gt;&lt;u&gt;re:Invent conference&lt;/u&gt;&lt;/a&gt;, introduces three specialized AI agents designed to act as virtual team members: Kiro autonomous agent for software development, AWS Security Agent for application security, and AWS DevOps Agent for IT operations.&lt;/p&gt;&lt;p&gt;The move signals Amazon&amp;#x27;s intent to leap ahead in the intensifying competition to build AI systems capable of performing complex, multi-step tasks that currently require teams of skilled engineers.&lt;/p&gt;&lt;p&gt;&amp;quot;We see frontier agents as a completely new class of agents,&amp;quot; said Deepak Singh, vice president of developer agents and experiences at Amazon, in an interview ahead of the announcement. &amp;quot;They&amp;#x27;re fundamentally designed to work for hours and days. You&amp;#x27;re not giving them a problem that you want finished in the next five minutes. You&amp;#x27;re giving them complex challenges that they may have to think about, try different solutions, and get to the right conclusion — and they should do that without intervention.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Amazon believes its new agents leave existing AI coding tools behind&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The frontier agents differ from existing AI coding assistants like &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt; or Amazon&amp;#x27;s own &lt;a href="https://aws.amazon.com/blogs/machine-learning/introducing-amazon-codewhisperer-the-ml-powered-coding-companion/"&gt;&lt;u&gt;CodeWhisperer&lt;/u&gt;&lt;/a&gt; in several fundamental ways.&lt;/p&gt;&lt;p&gt;Current AI coding tools, while powerful, require engineers to drive every interaction. Developers must write prompts, provide context, and manually coordinate work across different code repositories. When switching between tasks, the AI loses context and must start fresh.&lt;/p&gt;&lt;p&gt;The new frontier agents, by contrast, maintain persistent memory across sessions and continuously learn from an organization&amp;#x27;s codebase, documentation, and team communications. They can independently determine which code repositories require changes, work on multiple files simultaneously, and coordinate complex transformations spanning dozens of microservices.&lt;/p&gt;&lt;p&gt;&amp;quot;With a current agent, you would go microservice by microservice, making changes one at a time, and each change would be a different session with no shared context,&amp;quot; Singh explained. &amp;quot;With a frontier agent, you say, &amp;#x27;I need to solve this broad problem.&amp;#x27; You point it to the right application, and it decides which repos need changes.&amp;quot;&lt;/p&gt;&lt;p&gt;The agents exhibit three defining characteristics that AWS believes set them apart: autonomy in decision-making, the ability to scale by spawning multiple agents to work on different aspects of a problem simultaneously, and the capacity to operate independently for extended periods.&lt;/p&gt;&lt;p&gt;&amp;quot;A frontier agent can decide to spin up 10 versions of itself, all working on different parts of the problem at once,&amp;quot; Singh said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How each of the three frontier agents tackles a different phase of development&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://g"&gt;&lt;u&gt;Kiro autonomous agent&lt;/u&gt;&lt;/a&gt; serves as a virtual developer that maintains context across coding sessions and learns from an organization&amp;#x27;s pull requests, code reviews, and technical discussions. Teams can connect it to GitHub, Jira, Slack, and internal documentation systems. The agent then acts like a teammate, accepting task assignments and working independently until it either completes the work or requires human guidance.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro"&gt;&lt;u&gt;AWS Security Agent&lt;/u&gt;&lt;/a&gt; embeds security expertise throughout the development process, automatically reviewing design documents and scanning pull requests against organizational security requirements. Perhaps most significantly, it transforms penetration testing from a weeks-long manual process into an on-demand capability that completes in hours.&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.aboutamazon.com/news/aws/amazon-ai-frontier-agents-autonomous-kiro"&gt;&lt;u&gt;SmugMug&lt;/u&gt;&lt;/a&gt;, a photo hosting platform, has already deployed the security agent. &amp;quot;AWS Security Agent helped catch a business logic bug that no existing tools would have caught, exposing information improperly,&amp;quot; said Andres Ruiz, staff software engineer at the company. &amp;quot;To any other tool, this would have been invisible. But the ability for Security Agent to contextualize the information, parse the API response, and find the unexpected information there represents a leap forward in automated security testing.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/devops-agent-preview-frontier-agent-operational-excellence/"&gt;&lt;u&gt;AWS DevOps Agent&lt;/u&gt;&lt;/a&gt; functions as an always-on operations team member, responding instantly to incidents and using its accumulated knowledge to identify root causes. It connects to observability tools including Amazon CloudWatch, Datadog, Dynatrace, New Relic, and Splunk, along with runbooks and deployment pipelines.&lt;/p&gt;&lt;p&gt;Commonwealth Bank of Australia tested the DevOps agent by replicating a complex network and identity management issue that typically requires hours for experienced engineers to diagnose. The agent identified the root cause in under 15 minutes.&lt;/p&gt;&lt;p&gt;&amp;quot;AWS DevOps Agent thinks and acts like a seasoned DevOps engineer, helping our engineers build a banking infrastructure that&amp;#x27;s faster, more resilient, and designed to deliver better experiences for our customers,&amp;quot; said Jason Sandry, head of cloud services at Commonwealth Bank.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Amazon makes its case against Google and Microsoft in the AI coding wars&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The announcement arrives amid a fierce battle among technology giants to dominate the emerging market for AI-powered development tools. Google has made significant noise in recent weeks with its own &lt;a href="https://cloud.google.com/use-cases/ai-code-generation?hl=en"&gt;&lt;u&gt;AI coding capabilities&lt;/u&gt;&lt;/a&gt;, while Microsoft continues to advance &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt; and its broader AI development toolkit.&lt;/p&gt;&lt;p&gt;Singh argued that AWS holds distinct advantages rooted in the company&amp;#x27;s 20-year history operating cloud infrastructure and Amazon&amp;#x27;s own massive software engineering organization.&lt;/p&gt;&lt;p&gt;&amp;quot;AWS has been the cloud of choice for 20 years, so we have two decades of knowledge building and running it, and working with customers who&amp;#x27;ve been building and running applications on it,&amp;quot; Singh said. &amp;quot;The learnings from operating AWS, the knowledge our customers have, the experience we&amp;#x27;ve built using these tools ourselves every day to build real-world applications—all of that is embodied in these frontier agents.&amp;quot;&lt;/p&gt;&lt;p&gt;He drew a distinction between tools suitable for prototypes versus production systems. &amp;quot;There&amp;#x27;s a lot of things out there that you can use to build your prototype or your toy application. But if you want to build production applications, there&amp;#x27;s a lot of knowledge that we bring in as AWS that apply here.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The safeguards Amazon built to keep autonomous agents from going rogue&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The prospect of AI systems operating autonomously for days raises immediate questions about what happens when they go off track. Singh described multiple safeguards built into the system.&lt;/p&gt;&lt;p&gt;All learnings accumulated by the agents are logged and visible, allowing engineers to understand what knowledge influences the agent&amp;#x27;s decisions. Teams can even remove specific learnings if they discover the agent has absorbed incorrect information from team communications.&lt;/p&gt;&lt;p&gt;&amp;quot;You can go in and even redact that from its knowledge like, &amp;#x27;No, we don&amp;#x27;t want you to ever use this knowledge,&amp;#x27;&amp;quot; Singh said. &amp;quot;You can look at the knowledge like it&amp;#x27;s almost—it&amp;#x27;s like looking at your neurons inside your brain. You can disconnect some.&amp;quot;&lt;/p&gt;&lt;p&gt;Engineers can also monitor agent activity in real-time and intervene when necessary, either redirecting the agent or taking over entirely. Most critically, the agents never commit code directly to production systems. That responsibility remains with human engineers.&lt;/p&gt;&lt;p&gt;&amp;quot;These agents are never going to check the code into production. That is still the human&amp;#x27;s responsibility,&amp;quot; Singh emphasized. &amp;quot;You are still, as an engineer, responsible for the code you&amp;#x27;re checking in, whether it&amp;#x27;s generated by you or by an agent working autonomously.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What frontier agents mean for the future of software engineering jobs&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The announcement inevitably raises concerns about the impact on software engineering jobs. Singh pushed back against the notion that frontier agents will replace developers, framing them instead as tools that amplify human capabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;Software engineering is craft. What&amp;#x27;s changing is not, &amp;#x27;Hey, agents are doing all the work.&amp;#x27; The craft of software engineering is changing—how you use agents, how do you set up your code base, how do you set up your prompts, how do you set up your rules, how do you set up your knowledge bases so that agents can be effective,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;Singh noted that senior engineers who had drifted away from hands-on coding are now writing more code than ever. &amp;quot;It&amp;#x27;s actually easier for them to become software engineers,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;He pointed to an internal example where a team completed a project in 78 days that would have taken 18 months using traditional practices. &amp;quot;Because they were able to use AI. And the thing that made it work was not just the fact that they were using AI, but how they organized and set up their practices of how they built that software were maximized around that.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How Amazon plans to make AI-generated code more trustworthy over time&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Singh outlined several areas where frontier agents will evolve over the coming years. Multi-agent architectures, where systems of specialized agents coordinate to solve complex problems, represent a major frontier. So does the integration of formal verification techniques to increase confidence in AI-generated code.&lt;/p&gt;&lt;p&gt;AWS recently introduced property-based testing in Kiro, which uses automated reasoning to extract testable properties from specifications and generate thousands of test scenarios automatically.&lt;/p&gt;&lt;p&gt;&amp;quot;If you have a shopping cart application, every way an order can be canceled, and how it might be canceled, and the way refunds are handled in Germany versus the US—if you&amp;#x27;re writing a unit test, maybe two, Germany and US, but now, because you have this property-based testing approach, your agent can create a scenario for every country you operate in and test all of them automatically for you,&amp;quot; Singh explained.&lt;/p&gt;&lt;p&gt;Building trust in autonomous systems remains the central challenge. &amp;quot;Right now you still require tons of human guardrails at every step to make sure that the right thing happens. And as we get better at these techniques, you will use less and less, and you&amp;#x27;ll be able to trust the agents a lot more,&amp;quot; he said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Amazon&amp;#x27;s bigger bet on autonomous AI stretches far beyond writing code&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The frontier agents announcement arrived alongside a cascade of other news at &lt;a href="https://www.aboutamazon.com/news/aws/aws-re-invent-2025-ai-news-updates"&gt;&lt;u&gt;re:Invent 2025&lt;/u&gt;&lt;/a&gt;. AWS kicked off the conference with major announcements on agentic AI capabilities, customer service innovations, and multicloud networking.&lt;/p&gt;&lt;p&gt;Amazon expanded its Nova portfolio with &lt;a href="https://www.aboutamazon.com/news/aws/aws-agentic-ai-amazon-bedrock-nova-models"&gt;&lt;u&gt;four new models&lt;/u&gt;&lt;/a&gt; delivering industry-leading price-performance across reasoning, multimodal processing, conversational AI, code generation, and agentic tasks. Nova Forge pioneers &amp;quot;open training,&amp;quot; giving organizations access to pre-trained model checkpoints and the ability to blend proprietary data with Amazon Nova-curated datasets.&lt;/p&gt;&lt;p&gt;AWS also added &lt;a href="https://aws.amazon.com/blogs/aws/amazon-bedrock-adds-fully-managed-open-weight-models/"&gt;&lt;u&gt;18 new open weight models to Amazon Bedrock&lt;/u&gt;&lt;/a&gt;, reinforcing its commitment to offering a broad selection of fully managed models from leading AI providers. The launch includes new models from Mistral AI, Google&amp;#x27;s Gemma 3, MiniMax&amp;#x27;s M2, NVIDIA&amp;#x27;s Nemotron, and OpenAI&amp;#x27;s GPT OSS Safeguard.&lt;/p&gt;&lt;p&gt;On the infrastructure side, &lt;a href="https://aws.amazon.com/about-aws/whats-new/2025/12/amazon-ec2-trn3-ultraservers/"&gt;&lt;u&gt;Amazon EC2 Trn3 UltraServers&lt;/u&gt;&lt;/a&gt;, powered by AWS&amp;#x27;s first 3nm AI chip, pack up to 144 Trainium3 chips into a single integrated system, delivering up to 4.4x more compute performance and 4x greater energy efficiency than the previous generation. AWS AI Factories provides enterprises and government organizations with dedicated AWS AI infrastructure deployed in their own data centers, combining NVIDIA GPUs, Trainium chips, AWS networking, and AI services like Amazon Bedrock and SageMaker AI.&lt;/p&gt;&lt;p&gt;All three frontier agents launched in preview on Tuesday. Pricing will be announced when the services reach general availability.&lt;/p&gt;&lt;p&gt;Singh made clear the company sees applications far beyond coding. &amp;quot;These are the first frontier agents we are releasing, and they&amp;#x27;re in the software development lifecycle,&amp;quot; he said. &amp;quot;The problems and use cases for frontier agents—these agents that are long running, capable of autonomy, thinking, always learning and improving—can be applied to many, many domains.&amp;quot;&lt;/p&gt;&lt;p&gt;Amazon, after all, operates satellite networks, runs robotics warehouses, and manages one of the world&amp;#x27;s largest e-commerce platforms. If autonomous agents can learn to write code on their own, the company is betting they can eventually learn to do just about anything else.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/amazons-new-ai-can-code-for-days-without-human-help-what-does-that-mean-for</guid><pubDate>Tue, 02 Dec 2025 17:30:00 +0000</pubDate></item><item><title>[NEW] AWS launches new Nova AI models and a service that gives customers more control (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/aws-launches-new-nova-ai-models-and-a-service-that-gives-customers-more-control/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/IMG_6848.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services is rolling out a slate of new homegrown AI models and a service for enterprise customers to build their own custom versions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud provider launched Nova 2, a fleet of four new AI models to its Nova model family, during AWS CEO Matt Garman’s AWS Re:Invent keynote on Tuesday. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The first version of AWS Nova was announced last year at the company’s annual tech conference. At the time, the company released four text-generating models and one image-generating model. This year, AWS is giving the models an upgrade and launching an accompanying service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The momentum has been really fantastic,” Garman said during his Tuesday keynote. “Nova has been, has grown to be used by tens of thousands of customers today, everyone from marketing giants to tech leaders like Infosys or Blue Origin or Robinhood to innovative startups like NinjaTech AI and today, we’re making Nova even better.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The four new models include Nova 2 Lite, a more cost-effective reasoning model. Reasoning AI models “think” before they respond and can process text, images, and videos to generate text that’s meant for everyday tasks. Nova 2 Pro is a reasoning agent that can process text, images, videos and speech that is designed for “highly complex tasks” like coding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nova 2 Sonic is a new speech-to-speech model to be used for conversational AI. Nova 2 Omni is a multimodal reasoning and generation model that can process images, text, video and speech input, and produce both text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the model upgrades, AWS also announced a new service called Nova Forge which allows AWS cloud customers to build their own frontier version of AWS Nova models called Novellas for $100,000 a year, according to CNBC reporting. This service allows enterprises to access pre-trained, mid-trained or post-trained models for companies to then train on their own proprietary data.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Garman said this will be able to solve some of the problems that arise when enterprises try to incorporate their own data into already-trained AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The more you customize models, the more you add a bunch of data in post training, these models tend to forget some of that interesting stuff that it learned earlier the core reasoning,” Garman said. “It’s a little bit like humans trying to learn new language. When you start when you’re really young, it’s actually relatively easy to pick up, but when you try to, you learn a new language later in life, it’s actually much, much harder. Model training is kind of like this too.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies including Reddit, Sony and Booking.com are early Nova Forge customers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s coverage of the annual enterprise tech event here.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/IMG_6848.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services is rolling out a slate of new homegrown AI models and a service for enterprise customers to build their own custom versions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The cloud provider launched Nova 2, a fleet of four new AI models to its Nova model family, during AWS CEO Matt Garman’s AWS Re:Invent keynote on Tuesday. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The first version of AWS Nova was announced last year at the company’s annual tech conference. At the time, the company released four text-generating models and one image-generating model. This year, AWS is giving the models an upgrade and launching an accompanying service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The momentum has been really fantastic,” Garman said during his Tuesday keynote. “Nova has been, has grown to be used by tens of thousands of customers today, everyone from marketing giants to tech leaders like Infosys or Blue Origin or Robinhood to innovative startups like NinjaTech AI and today, we’re making Nova even better.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The four new models include Nova 2 Lite, a more cost-effective reasoning model. Reasoning AI models “think” before they respond and can process text, images, and videos to generate text that’s meant for everyday tasks. Nova 2 Pro is a reasoning agent that can process text, images, videos and speech that is designed for “highly complex tasks” like coding.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nova 2 Sonic is a new speech-to-speech model to be used for conversational AI. Nova 2 Omni is a multimodal reasoning and generation model that can process images, text, video and speech input, and produce both text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside the model upgrades, AWS also announced a new service called Nova Forge which allows AWS cloud customers to build their own frontier version of AWS Nova models called Novellas for $100,000 a year, according to CNBC reporting. This service allows enterprises to access pre-trained, mid-trained or post-trained models for companies to then train on their own proprietary data.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Garman said this will be able to solve some of the problems that arise when enterprises try to incorporate their own data into already-trained AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The more you customize models, the more you add a bunch of data in post training, these models tend to forget some of that interesting stuff that it learned earlier the core reasoning,” Garman said. “It’s a little bit like humans trying to learn new language. When you start when you’re really young, it’s actually relatively easy to pick up, but when you try to, you learn a new language later in life, it’s actually much, much harder. Model training is kind of like this too.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies including Reddit, Sony and Booking.com are early Nova Forge customers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s coverage of the annual enterprise tech event here.&lt;/p&gt;



[embedded content]

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/aws-launches-new-nova-ai-models-and-a-service-that-gives-customers-more-control/</guid><pubDate>Tue, 02 Dec 2025 17:54:02 +0000</pubDate></item><item><title>[NEW] ChatGPT referrals to retailers’ apps increased 28% year-over-year, says report (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/02/chatgpt-referrals-to-retailers-apps-increased-28-year-over-year-says-report/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/01/GettyImages-1336136316.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;New data shows ChatGPT’s growing influence as a referrer to e-commerce websites, but also how small its slice of this market is currently. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new analysis by mobile app insights provider Apptopia, ChatGPT referrals to retailer mobile apps increased 28% year-over-year over the Black Friday holiday shopping weekend, running from Thanksgiving Day on Thursday through Sunday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, the use of ChatGPT may not be benefiting smaller retailers as much as it’s helping to further entrench the e-commerce giants, Amazon and Walmart. This year, Amazon’s share of ChatGPT referrals grew to 54%, up from 40.5% in 2024. Walmart’s share, meanwhile, increased from 2.7% last year to now 14.9%. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The data was collected by Apptopia’s U.S. panel, which is based on observed consumer activity on mobile devices. As it’s not first-party data, its figures are only estimates. For this analysis, the firm defined a referral session as a retail mobile app session that directly followed (within 30 seconds) a ChatGPT session.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the big jump from 2024, consumers’ use of AI chatbots to find e-commerce deals is still a small sliver of the overall referral market, Apptopia noted. Last year, ChatGPT’s referrals to e-commerce apps were only 0.64% of all ChatGPT sessions on Black Friday, and that figure only grew to 0.82% this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this case, a referral session was anytime ChatGPT either gave the searcher a shopping idea or the user clicked a link directly from their chat session that brought them to the retail app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apptopia isn’t the only firm digging into how AI is impacting e-commerce during the busy holiday shopping season. Adobe also reported this week that AI traffic to U.S. retail sites (measured by shoppers clicking on a link) increased by 805% year-over-year on Black Friday, and those who landed on a retail site from an AI chatbot were 38% more likely to make a purchase.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Adobe said that AI traffic to U.S. retail sites on Cyber Monday increased by 670%. In the holiday shopping season so far (Nov. 1 to Dec. 1), AI traffic is up 760%, it noted. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/01/GettyImages-1336136316.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;New data shows ChatGPT’s growing influence as a referrer to e-commerce websites, but also how small its slice of this market is currently. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new analysis by mobile app insights provider Apptopia, ChatGPT referrals to retailer mobile apps increased 28% year-over-year over the Black Friday holiday shopping weekend, running from Thanksgiving Day on Thursday through Sunday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, the use of ChatGPT may not be benefiting smaller retailers as much as it’s helping to further entrench the e-commerce giants, Amazon and Walmart. This year, Amazon’s share of ChatGPT referrals grew to 54%, up from 40.5% in 2024. Walmart’s share, meanwhile, increased from 2.7% last year to now 14.9%. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The data was collected by Apptopia’s U.S. panel, which is based on observed consumer activity on mobile devices. As it’s not first-party data, its figures are only estimates. For this analysis, the firm defined a referral session as a retail mobile app session that directly followed (within 30 seconds) a ChatGPT session.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the big jump from 2024, consumers’ use of AI chatbots to find e-commerce deals is still a small sliver of the overall referral market, Apptopia noted. Last year, ChatGPT’s referrals to e-commerce apps were only 0.64% of all ChatGPT sessions on Black Friday, and that figure only grew to 0.82% this year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this case, a referral session was anytime ChatGPT either gave the searcher a shopping idea or the user clicked a link directly from their chat session that brought them to the retail app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apptopia isn’t the only firm digging into how AI is impacting e-commerce during the busy holiday shopping season. Adobe also reported this week that AI traffic to U.S. retail sites (measured by shoppers clicking on a link) increased by 805% year-over-year on Black Friday, and those who landed on a retail site from an AI chatbot were 38% more likely to make a purchase.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Adobe said that AI traffic to U.S. retail sites on Cyber Monday increased by 670%. In the holiday shopping season so far (Nov. 1 to Dec. 1), AI traffic is up 760%, it noted. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/02/chatgpt-referrals-to-retailers-apps-increased-28-year-over-year-says-report/</guid><pubDate>Tue, 02 Dec 2025 17:56:16 +0000</pubDate></item></channel></rss>