<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 27 Jun 2025 01:50:54 +0000</lastBuildDate><item><title>Reddit CEO pledges site will remain “written by humans and voted on by humans” (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/06/reddit-ceo-pledges-site-will-remain-written-by-humans-and-voted-on-by-humans/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Reddit is in an “arms race” to protect its communities from AI-generated content.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An image of a woman holding a cell phone in front of the Reddit logo displayed on a computer screen, on April 29, 2024, in Edmonton, Canada." class="absolute inset-0 w-full h-full object-cover hidden" height="213" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-2150483549-300x213.jpg" width="300" /&gt;
                  &lt;img alt="An image of a woman holding a cell phone in front of the Reddit logo displayed on a computer screen, on April 29, 2024, in Edmonton, Canada." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-2150483549-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Reddit is in an “arms race” to protect its devoted online communities from a surge in artificial intelligence-generated content, with the authenticity of its vast repository of human interaction increasingly valuable in training new AI-powered search tools.&lt;/p&gt;
&lt;p&gt;Chief executive Steve Huffman told the Financial Times that Reddit had “20 years of conversation about everything,” leaving the company with a lucrative resource of personal interaction.&lt;/p&gt;
&lt;p&gt;This has allowed it to strike multimillion dollar partnerships with Google and OpenAI to train their large language models on its content, as tech companies look for real-world data that can improve their generative AI products.&lt;/p&gt;
&lt;p&gt;But Huffman said Reddit was now battling to ensure its users stay at the center of the social network. “Where the rest of the internet seems to be powered by or written by or summarized by AI, Reddit is distinctly human,” he said. “It’s the place you go when you want to hear from people, their lived experiences, their perspectives, their recommendations. Reddit is communities and human curation and conversation and authenticity.”&lt;/p&gt;
&lt;p&gt;As Reddit becomes an increasingly important source for LLMs, advertisers are responding with what one agency chief described as a “massive migration” to the platform.&lt;/p&gt;
&lt;p&gt;Multiple advertising and agency executives speaking during this month’s Cannes advertising festival told the FT that brands were increasingly exploring hosting a business account and posting content on Reddit to boost the likelihood of their ads appearing in the responses of generative AI chatbots.&lt;/p&gt;
&lt;p&gt;However, Huffman warned against any company seeking to game the site with fake or AI-generated content, with plans to bring in strict verification checks to ensure that only humans can post to its forums.&lt;/p&gt;
&lt;p&gt;“For 20 years, we’ve been fighting people who have wanted to be popular on Reddit,” he said. “We index very well into the search engines. If you want to show up in the search engines, you try to do well on Reddit, and now the LLMs, it’s the same thing. If you want to be in the LLMs, you can do it through Reddit.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For Huffman, success comes down to making sure that posts are “written by humans and voted on by humans”—referencing the process by which users can “upvote” posts in order to show their appreciation or “downvote” those they find unhelpful.&lt;/p&gt;
&lt;p&gt;“It’s an arms race, it’s a never ending battle,” he said. “The AI version of it, it’s a new frontier in the same battle that we’ve been fighting for a long time.”&lt;/p&gt;
&lt;p&gt;Huffman said Reddit would still not require users to post under their real names—one of the defining features of the site—but the group would seek to use services that will provide verification “you’re a human without knowing your name.”&lt;/p&gt;
&lt;p&gt;Reddit is exploring using World ID, the eyeball-scanning technology from Sam Altman’s Worldcoin venture, as a way to verify users while granting them anonymity, according to a person familiar with the talks and first reported by Semafor. Altman, OpenAI’s chief executive, used to sit on Reddit’s board.&lt;/p&gt;
&lt;p&gt;“Human verification is top of mind for us right now. Over the rest of this year, we’ll be evolving that—it’s a need on the Internet broadly,” Huffman said.&lt;/p&gt;
&lt;p&gt;Reddit is protecting the value of its content in other ways. Last month it sued AI start-up Anthropic in San Francisco, claiming it had scraped its platform more than 100,000 times since July 2024. “We disagree with Reddit’s claims and will defend ourselves vigorously,” Anthropic said.&lt;/p&gt;
&lt;p&gt;Huffman said there are “a few cases where people have taken advantage of Reddit content, and we’re working through those moments.”&lt;/p&gt;
&lt;p&gt;Huffman’s comments come as Reddit seeks to woo brands with new advertising tools and features. This month, it launched two AI-powered products to provide marketers with real-time data on trending conversations and showcase positive user-generated content underneath real adverts.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Reddit now has more than 100,000 communities based around topic and interest. Reddit’s commercial pitch is that many of these conversations—about 40 percent—are about a service or a product, and within this a quarter relate to some sort of recommendation.&lt;/p&gt;
&lt;p&gt;But several agency executives told the FT that Reddit’s advertising offering still needed fine-tuning, particularly around user targeting.&lt;/p&gt;
&lt;p&gt;Reddit is also improving its platform for users, with an AI-powered search that provides verbatim quotes from its communities and new translation tools to extend its site to 13 languages later this year, including Korean and Japanese.&lt;/p&gt;
&lt;p&gt;Huffman said the platform was now “much more than what we could have imagined 20 years ago” when he co-founded the site with a college friend. Huffman left Reddit in 2009 after it was acquired by Condé Nast, but returned in 2015 when the site faced potential collapse following widespread user dissent over toxic posts and harmful content.&lt;/p&gt;
&lt;p&gt;At the time, Reddit had 12 million daily users and revenue of $15 million. A decade later, it has reached more than 100 million daily average users and is turning over more than $1.3 billion.&lt;/p&gt;
&lt;p&gt;Reddit floated in March 2024 with a valuation of $6.4 billion, which has grown to $26 billion despite a fall in its stock in recent months over concerns that search traffic will be hit with the introduction of Google’s AI Overviews—answers to search queries that remove the need for users to click through to its webpages.&lt;/p&gt;
&lt;p&gt;Huffman said he was relaxed about the longer term impact of Google Overview removing the need for people to click through to Reddit links.&lt;/p&gt;
&lt;p&gt;The “majority of our traffic comes directly to Reddit” rather than through Google, he said, adding that “the search ecosystem is evolving, and it’s volatile right now, but that also opens the door for other players in search, including Reddit.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Reddit is in an “arms race” to protect its communities from AI-generated content.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An image of a woman holding a cell phone in front of the Reddit logo displayed on a computer screen, on April 29, 2024, in Edmonton, Canada." class="absolute inset-0 w-full h-full object-cover hidden" height="213" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-2150483549-300x213.jpg" width="300" /&gt;
                  &lt;img alt="An image of a woman holding a cell phone in front of the Reddit logo displayed on a computer screen, on April 29, 2024, in Edmonton, Canada." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-2150483549-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Reddit is in an “arms race” to protect its devoted online communities from a surge in artificial intelligence-generated content, with the authenticity of its vast repository of human interaction increasingly valuable in training new AI-powered search tools.&lt;/p&gt;
&lt;p&gt;Chief executive Steve Huffman told the Financial Times that Reddit had “20 years of conversation about everything,” leaving the company with a lucrative resource of personal interaction.&lt;/p&gt;
&lt;p&gt;This has allowed it to strike multimillion dollar partnerships with Google and OpenAI to train their large language models on its content, as tech companies look for real-world data that can improve their generative AI products.&lt;/p&gt;
&lt;p&gt;But Huffman said Reddit was now battling to ensure its users stay at the center of the social network. “Where the rest of the internet seems to be powered by or written by or summarized by AI, Reddit is distinctly human,” he said. “It’s the place you go when you want to hear from people, their lived experiences, their perspectives, their recommendations. Reddit is communities and human curation and conversation and authenticity.”&lt;/p&gt;
&lt;p&gt;As Reddit becomes an increasingly important source for LLMs, advertisers are responding with what one agency chief described as a “massive migration” to the platform.&lt;/p&gt;
&lt;p&gt;Multiple advertising and agency executives speaking during this month’s Cannes advertising festival told the FT that brands were increasingly exploring hosting a business account and posting content on Reddit to boost the likelihood of their ads appearing in the responses of generative AI chatbots.&lt;/p&gt;
&lt;p&gt;However, Huffman warned against any company seeking to game the site with fake or AI-generated content, with plans to bring in strict verification checks to ensure that only humans can post to its forums.&lt;/p&gt;
&lt;p&gt;“For 20 years, we’ve been fighting people who have wanted to be popular on Reddit,” he said. “We index very well into the search engines. If you want to show up in the search engines, you try to do well on Reddit, and now the LLMs, it’s the same thing. If you want to be in the LLMs, you can do it through Reddit.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For Huffman, success comes down to making sure that posts are “written by humans and voted on by humans”—referencing the process by which users can “upvote” posts in order to show their appreciation or “downvote” those they find unhelpful.&lt;/p&gt;
&lt;p&gt;“It’s an arms race, it’s a never ending battle,” he said. “The AI version of it, it’s a new frontier in the same battle that we’ve been fighting for a long time.”&lt;/p&gt;
&lt;p&gt;Huffman said Reddit would still not require users to post under their real names—one of the defining features of the site—but the group would seek to use services that will provide verification “you’re a human without knowing your name.”&lt;/p&gt;
&lt;p&gt;Reddit is exploring using World ID, the eyeball-scanning technology from Sam Altman’s Worldcoin venture, as a way to verify users while granting them anonymity, according to a person familiar with the talks and first reported by Semafor. Altman, OpenAI’s chief executive, used to sit on Reddit’s board.&lt;/p&gt;
&lt;p&gt;“Human verification is top of mind for us right now. Over the rest of this year, we’ll be evolving that—it’s a need on the Internet broadly,” Huffman said.&lt;/p&gt;
&lt;p&gt;Reddit is protecting the value of its content in other ways. Last month it sued AI start-up Anthropic in San Francisco, claiming it had scraped its platform more than 100,000 times since July 2024. “We disagree with Reddit’s claims and will defend ourselves vigorously,” Anthropic said.&lt;/p&gt;
&lt;p&gt;Huffman said there are “a few cases where people have taken advantage of Reddit content, and we’re working through those moments.”&lt;/p&gt;
&lt;p&gt;Huffman’s comments come as Reddit seeks to woo brands with new advertising tools and features. This month, it launched two AI-powered products to provide marketers with real-time data on trending conversations and showcase positive user-generated content underneath real adverts.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Reddit now has more than 100,000 communities based around topic and interest. Reddit’s commercial pitch is that many of these conversations—about 40 percent—are about a service or a product, and within this a quarter relate to some sort of recommendation.&lt;/p&gt;
&lt;p&gt;But several agency executives told the FT that Reddit’s advertising offering still needed fine-tuning, particularly around user targeting.&lt;/p&gt;
&lt;p&gt;Reddit is also improving its platform for users, with an AI-powered search that provides verbatim quotes from its communities and new translation tools to extend its site to 13 languages later this year, including Korean and Japanese.&lt;/p&gt;
&lt;p&gt;Huffman said the platform was now “much more than what we could have imagined 20 years ago” when he co-founded the site with a college friend. Huffman left Reddit in 2009 after it was acquired by Condé Nast, but returned in 2015 when the site faced potential collapse following widespread user dissent over toxic posts and harmful content.&lt;/p&gt;
&lt;p&gt;At the time, Reddit had 12 million daily users and revenue of $15 million. A decade later, it has reached more than 100 million daily average users and is turning over more than $1.3 billion.&lt;/p&gt;
&lt;p&gt;Reddit floated in March 2024 with a valuation of $6.4 billion, which has grown to $26 billion despite a fall in its stock in recent months over concerns that search traffic will be hit with the introduction of Google’s AI Overviews—answers to search queries that remove the need for users to click through to its webpages.&lt;/p&gt;
&lt;p&gt;Huffman said he was relaxed about the longer term impact of Google Overview removing the need for people to click through to Reddit links.&lt;/p&gt;
&lt;p&gt;The “majority of our traffic comes directly to Reddit” rather than through Google, he said, adding that “the search ecosystem is evolving, and it’s volatile right now, but that also opens the door for other players in search, including Reddit.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/06/reddit-ceo-pledges-site-will-remain-written-by-humans-and-voted-on-by-humans/</guid><pubDate>Thu, 26 Jun 2025 13:54:32 +0000</pubDate></item><item><title>YouTube adds an AI Overviews-like search results carousel (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/youtube-adds-an-ai-overviews-like-search-results-carousel/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube is rolling out new AI-powered features to help users find content and information more easily, the company announced on Thursday. The platform is launching an AI-powered search results carousel similar to Google’s AI Overviews and is also testing conversational AI with more users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI-powered search results carousel, available only to YouTube Premium users in the United States, will suggest videos and display brief AI-generated topic descriptions to help users find what they’re looking for faster. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube says the AI-powered search results carousel will appear in searches related to shopping, places, or things to do at a specific place. For example, if you search for something like “best beaches in Hawaii,” you’ll see an AI-generated carousel highlighting clips from videos showcasing the best snorkel spots and volcanic beaches, alongside descriptions and more videos to help you plan your vacation.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022395" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/youtube-ai-search.png?w=338" width="338" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new feature is pretty similar to Google’s AI Overviews, the tool that provides AI-generated summaries of search results at the top of the Google Search results page. While the AI-powered search results carousel will ease discovery for users, it could be an unwelcome change for creators, as they rely on engagement to earn revenue on the platform. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if a person is able to get the information they need directly from the AI-powered search results carousel, they may not click into the video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of the AI-powered search results carousel comes two weeks after a Wall Street Journal report revealed that Google’s AI Overviews and other AI-powered tools are devastating traffic for news publishers. YouTube creators may be concerned that the new carousel feature could reduce engagement with their videos, just like how AI Overviews on Google Search have led to fewer referrals to news sites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for YouTube’s conversational AI tool, the Google-owned platform announced that it’s making it available to some non-Premium users. First launched in late 2023, the conversational tool uses AI to help users get more information, content recommendations, and summaries of videos. It can also be used to quiz yourself on key concepts in academic videos.&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022396" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/Screenshot-2025-06-26-at-9.42.04AM.png?w=675" width="675" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, YouTube explained that the tool’s responses are generated by large language models that draw on information from YouTube and the web. The responses are designed to help viewers dive deeper into the content they’re watching.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, if you’re watching a roller skate dance tutorial, the conversational AI tool will ask if you want it to “summarize the video” or “recommend related content.” You can also ask your own questions, like “What’s the song in this video?” and the tool will provide details such as the song title, artist, genre, and more.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;YouTube is rolling out new AI-powered features to help users find content and information more easily, the company announced on Thursday. The platform is launching an AI-powered search results carousel similar to Google’s AI Overviews and is also testing conversational AI with more users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new AI-powered search results carousel, available only to YouTube Premium users in the United States, will suggest videos and display brief AI-generated topic descriptions to help users find what they’re looking for faster. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;YouTube says the AI-powered search results carousel will appear in searches related to shopping, places, or things to do at a specific place. For example, if you search for something like “best beaches in Hawaii,” you’ll see an AI-generated carousel highlighting clips from videos showcasing the best snorkel spots and volcanic beaches, alongside descriptions and more videos to help you plan your vacation.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022395" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/youtube-ai-search.png?w=338" width="338" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new feature is pretty similar to Google’s AI Overviews, the tool that provides AI-generated summaries of search results at the top of the Google Search results page. While the AI-powered search results carousel will ease discovery for users, it could be an unwelcome change for creators, as they rely on engagement to earn revenue on the platform. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if a person is able to get the information they need directly from the AI-powered search results carousel, they may not click into the video.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of the AI-powered search results carousel comes two weeks after a Wall Street Journal report revealed that Google’s AI Overviews and other AI-powered tools are devastating traffic for news publishers. YouTube creators may be concerned that the new carousel feature could reduce engagement with their videos, just like how AI Overviews on Google Search have led to fewer referrals to news sites.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As for YouTube’s conversational AI tool, the Google-owned platform announced that it’s making it available to some non-Premium users. First launched in late 2023, the conversational tool uses AI to help users get more information, content recommendations, and summaries of videos. It can also be used to quiz yourself on key concepts in academic videos.&lt;/p&gt;


&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022396" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/Screenshot-2025-06-26-at-9.42.04AM.png?w=675" width="675" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;YouTube&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;At launch, YouTube explained that the tool’s responses are generated by large language models that draw on information from YouTube and the web. The responses are designed to help viewers dive deeper into the content they’re watching.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, if you’re watching a roller skate dance tutorial, the conversational AI tool will ask if you want it to “summarize the video” or “recommend related content.” You can also ask your own questions, like “What’s the song in this video?” and the tool will provide details such as the song title, artist, genre, and more.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/youtube-adds-an-ai-overviews-like-search-results-carousel/</guid><pubDate>Thu, 26 Jun 2025 14:08:38 +0000</pubDate></item><item><title>Nvidia reclaims title of most valuable company on AI momentum (AI News)</title><link>https://www.artificialintelligence-news.com/news/nvidia-reclaims-title-of-most-valuable-company-on-ai-momentum/</link><description>&lt;p&gt;Nvidia briefly became the world’s most valuable company on Wednesday after its stock jumped over 4% in price to a new high of $154.10, pushing its market value to $3.76 trillion. &lt;em&gt;Reuters&lt;/em&gt; said the chipmaker overtook Microsoft, which stood at $3.65 trillion after a smaller gain.&lt;/p&gt;&lt;p&gt;The rise follows a note from Loop Capital, which raised its price target for Nvidia to $250 from $175. The firm kept its “buy” rating and said demand for generative AI could grow faster than expected.&lt;/p&gt;&lt;p&gt;“We are entering the next ‘Golden Wave’ of Gen AI adoption and Nvidia is at the front-end of another material leg of stronger than anticipated demand,” said Loop Capital analyst Ananda Baruah.&lt;/p&gt;&lt;p&gt;The renewed interest in AI has sent investors back into tech stocks, especially companies involved in chips and data infrastructure. Nvidia, which designs high-performance GPUs used in AI models, has been a key figure in that trend.&lt;/p&gt;&lt;p&gt;Even with the stock’s strong performance, its valuation doesn’t appear overly stretched. Nvidia trades at about 30 times projected earnings for the next year, below its five-year average of 40 times. This suggests analysts have been raising their forecasts as the company keeps delivering bigger profits.&lt;/p&gt;&lt;p&gt;Nvidia, Microsoft, and Apple have all rotated in and out of the top spot for market value over the past year. Microsoft had recently pulled ahead, but Nvidia regained the lead this week. Apple’s shares rose 0.4% on Wednesday, bringing its valuation to about $3 trillion.&lt;/p&gt;&lt;p&gt;Nvidia’s stock has climbed more than 60% in value since hitting a low in early April. That drop came during a broader sell-off triggered by tariff announcements from Donald Trump. Since then, markets have steadied, with hoping for trade deals that could reduce some of the pressure on the company.&lt;/p&gt;&lt;p&gt;The broader tech sector has also been moving to higher valuations. The S&amp;amp;P 500’s technology index was up 0.9% on Wednesday, reaching a new record. It has gained nearly 6% so far in 2025.&lt;/p&gt;&lt;h3&gt;Tesla’s AI push goes beyond self-driving cars&lt;/h3&gt;&lt;p&gt;Tesla is best known for electric vehicles, but the company is also working to build up its AI capabilities and robotaxi project, plus lesser-known work in robotics.&lt;/p&gt;&lt;p&gt;While many are focused on Tesla’s push to launch a self-driving ride-hailing service, CEO Elon Musk has also been talking about a broader AI future. As &lt;em&gt;The Motley Fool&lt;/em&gt; highlighted, one example is Optimus, a humanoid robot the company is developing for factory and, potentially, domestic use.&lt;/p&gt;&lt;p&gt;Nvidia CEO Jensen Huang recently highlighted the potential of this market, calling humanoid robotics a “multitrillion-dollar industry.” He mentioned Tesla’s Optimus project as one of the efforts that has caught his attention.&lt;/p&gt;&lt;p&gt;Tesla sees two main uses for Optimus. First, the robot could be trained with machine learning to help on the company’s own production lines. Over time, it could take over more tasks and operate without breaks, increasing factory output.&lt;/p&gt;&lt;p&gt;Secondly, Tesla could sell Optimus to other industries where labour is physically demanding. The robot could be adapted for more routine settings outside factories. Musk has said Optimus could eventually become more valuable than the company’s car business.&lt;/p&gt;&lt;p&gt;Other companies are also working in this space. Figure AI, a startup backed by Nvidia, is developing similar humanoid robots for use in factories. A demo video shows how its machines could work alongside people to boost output and reduce repetitive tasks.&lt;/p&gt;&lt;h3&gt;What’s next for Tesla’s stock?&lt;/h3&gt;&lt;p&gt;Tesla’s share price has jumped nearly 30%, driven in part by its robotaxi rollout. The company started testing the service in Texas this week, which has helped fuel investor optimism.&lt;/p&gt;&lt;p&gt;But some analysts say its stock may have already peaked due to the short-term excitement of the Optimus announcement. Tesla tends to move based on headlines, and the same pattern could apply to its robot and robotaxi projects.&lt;/p&gt;&lt;p&gt;While Optimus could become an important part of Tesla’s future, it’s still early. Key questions remain about how soon the robot can scale, how it will compare with other options, and whether the company can turn the project into a real business.&lt;/p&gt;&lt;p&gt;Investors watching Tesla’s AI plans may want to see more progress before making new bets.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Mariia Shalabaieva)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: NO FAKES Act: AI deepfakes protection or internet freedom threat?&lt;/strong&gt;&lt;/p&gt;&lt;img alt="alt" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Nvidia briefly became the world’s most valuable company on Wednesday after its stock jumped over 4% in price to a new high of $154.10, pushing its market value to $3.76 trillion. &lt;em&gt;Reuters&lt;/em&gt; said the chipmaker overtook Microsoft, which stood at $3.65 trillion after a smaller gain.&lt;/p&gt;&lt;p&gt;The rise follows a note from Loop Capital, which raised its price target for Nvidia to $250 from $175. The firm kept its “buy” rating and said demand for generative AI could grow faster than expected.&lt;/p&gt;&lt;p&gt;“We are entering the next ‘Golden Wave’ of Gen AI adoption and Nvidia is at the front-end of another material leg of stronger than anticipated demand,” said Loop Capital analyst Ananda Baruah.&lt;/p&gt;&lt;p&gt;The renewed interest in AI has sent investors back into tech stocks, especially companies involved in chips and data infrastructure. Nvidia, which designs high-performance GPUs used in AI models, has been a key figure in that trend.&lt;/p&gt;&lt;p&gt;Even with the stock’s strong performance, its valuation doesn’t appear overly stretched. Nvidia trades at about 30 times projected earnings for the next year, below its five-year average of 40 times. This suggests analysts have been raising their forecasts as the company keeps delivering bigger profits.&lt;/p&gt;&lt;p&gt;Nvidia, Microsoft, and Apple have all rotated in and out of the top spot for market value over the past year. Microsoft had recently pulled ahead, but Nvidia regained the lead this week. Apple’s shares rose 0.4% on Wednesday, bringing its valuation to about $3 trillion.&lt;/p&gt;&lt;p&gt;Nvidia’s stock has climbed more than 60% in value since hitting a low in early April. That drop came during a broader sell-off triggered by tariff announcements from Donald Trump. Since then, markets have steadied, with hoping for trade deals that could reduce some of the pressure on the company.&lt;/p&gt;&lt;p&gt;The broader tech sector has also been moving to higher valuations. The S&amp;amp;P 500’s technology index was up 0.9% on Wednesday, reaching a new record. It has gained nearly 6% so far in 2025.&lt;/p&gt;&lt;h3&gt;Tesla’s AI push goes beyond self-driving cars&lt;/h3&gt;&lt;p&gt;Tesla is best known for electric vehicles, but the company is also working to build up its AI capabilities and robotaxi project, plus lesser-known work in robotics.&lt;/p&gt;&lt;p&gt;While many are focused on Tesla’s push to launch a self-driving ride-hailing service, CEO Elon Musk has also been talking about a broader AI future. As &lt;em&gt;The Motley Fool&lt;/em&gt; highlighted, one example is Optimus, a humanoid robot the company is developing for factory and, potentially, domestic use.&lt;/p&gt;&lt;p&gt;Nvidia CEO Jensen Huang recently highlighted the potential of this market, calling humanoid robotics a “multitrillion-dollar industry.” He mentioned Tesla’s Optimus project as one of the efforts that has caught his attention.&lt;/p&gt;&lt;p&gt;Tesla sees two main uses for Optimus. First, the robot could be trained with machine learning to help on the company’s own production lines. Over time, it could take over more tasks and operate without breaks, increasing factory output.&lt;/p&gt;&lt;p&gt;Secondly, Tesla could sell Optimus to other industries where labour is physically demanding. The robot could be adapted for more routine settings outside factories. Musk has said Optimus could eventually become more valuable than the company’s car business.&lt;/p&gt;&lt;p&gt;Other companies are also working in this space. Figure AI, a startup backed by Nvidia, is developing similar humanoid robots for use in factories. A demo video shows how its machines could work alongside people to boost output and reduce repetitive tasks.&lt;/p&gt;&lt;h3&gt;What’s next for Tesla’s stock?&lt;/h3&gt;&lt;p&gt;Tesla’s share price has jumped nearly 30%, driven in part by its robotaxi rollout. The company started testing the service in Texas this week, which has helped fuel investor optimism.&lt;/p&gt;&lt;p&gt;But some analysts say its stock may have already peaked due to the short-term excitement of the Optimus announcement. Tesla tends to move based on headlines, and the same pattern could apply to its robot and robotaxi projects.&lt;/p&gt;&lt;p&gt;While Optimus could become an important part of Tesla’s future, it’s still early. Key questions remain about how soon the robot can scale, how it will compare with other options, and whether the company can turn the project into a real business.&lt;/p&gt;&lt;p&gt;Investors watching Tesla’s AI plans may want to see more progress before making new bets.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Mariia Shalabaieva)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: NO FAKES Act: AI deepfakes protection or internet freedom threat?&lt;/strong&gt;&lt;/p&gt;&lt;img alt="alt" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/nvidia-reclaims-title-of-most-valuable-company-on-ai-momentum/</guid><pubDate>Thu, 26 Jun 2025 14:08:38 +0000</pubDate></item><item><title>People use AI for companionship much less than we’re led to believe (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/people-use-ai-for-companionship-much-less-than-were-led-to-believe/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The overabundance of attention paid to how people are turning to AI chatbots for emotional support, sometimes even striking up relationships, often leads one to think such behavior is commonplace.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A new report by Anthropic, which makes the popular AI chatbot Claude, reveals a different reality: In fact, people rarely seek out companionship from Claude and turn to the bot for emotional support and personal advice only 2.9% of the time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Companionship and roleplay combined comprise less than 0.5% of conversations,” the company highlighted in its report. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says its study sought to unearth insights into the use of AI for “affective conversations,” which it defines as personal exchanges in which people talked to Claude for coaching, counseling, companionship, roleplay, or advice on relationships. Analyzing 4.5 million conversations that users had on the Claude Free and Pro tiers, the company said the vast majority of Claude usage is related to work or productivity, with people mostly using the chatbot for content creation. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022369" height="382" src="https://techcrunch.com/wp-content/uploads/2025/06/image_e977d3.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt; &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Anthropic&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Anthropic found that people do use Claude more often for interpersonal advice, coaching, and counseling, with users most often asking for advice on improving mental health, personal and professional development, and studying communication and interpersonal skills.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company notes that help-seeking conversations can sometimes turn into companionship-seeking in cases where the user is facing emotional or personal distress, such as existential dread or loneliness, or when they find it hard to make meaningful connections in their real life.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We also noticed that in longer conversations, counseling or coaching conversations occasionally morph into companionship — despite that not being the original reason someone reached out,” Anthropic wrote, noting that extensive conversations (with over 50+ human messages) were not the norm.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Anthropic also highlighted other insights, like how Claude itself rarely resists users’ requests, except when its programming prevents it from broaching safety boundaries, like providing dangerous advice or supporting self-harm. Conversations also tend to become more positive over time when people seek coaching or advice from the bot, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The report is certainly interesting — it does a good job of reminding us yet again of just how much and how often AI tools are being used for purposes beyond work. Still, it’s important to remember that AI chatbots, across the board, are still very much a work in progress: They hallucinate, are known to readily provide wrong information or dangerous advice, and as Anthropic itself has acknowledged, may even resort to blackmail.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The overabundance of attention paid to how people are turning to AI chatbots for emotional support, sometimes even striking up relationships, often leads one to think such behavior is commonplace.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A new report by Anthropic, which makes the popular AI chatbot Claude, reveals a different reality: In fact, people rarely seek out companionship from Claude and turn to the bot for emotional support and personal advice only 2.9% of the time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Companionship and roleplay combined comprise less than 0.5% of conversations,” the company highlighted in its report. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic says its study sought to unearth insights into the use of AI for “affective conversations,” which it defines as personal exchanges in which people talked to Claude for coaching, counseling, companionship, roleplay, or advice on relationships. Analyzing 4.5 million conversations that users had on the Claude Free and Pro tiers, the company said the vast majority of Claude usage is related to work or productivity, with people mostly using the chatbot for content creation. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022369" height="382" src="https://techcrunch.com/wp-content/uploads/2025/06/image_e977d3.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt; &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Anthropic&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Anthropic found that people do use Claude more often for interpersonal advice, coaching, and counseling, with users most often asking for advice on improving mental health, personal and professional development, and studying communication and interpersonal skills.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the company notes that help-seeking conversations can sometimes turn into companionship-seeking in cases where the user is facing emotional or personal distress, such as existential dread or loneliness, or when they find it hard to make meaningful connections in their real life.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We also noticed that in longer conversations, counseling or coaching conversations occasionally morph into companionship — despite that not being the original reason someone reached out,” Anthropic wrote, noting that extensive conversations (with over 50+ human messages) were not the norm.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Anthropic also highlighted other insights, like how Claude itself rarely resists users’ requests, except when its programming prevents it from broaching safety boundaries, like providing dangerous advice or supporting self-harm. Conversations also tend to become more positive over time when people seek coaching or advice from the bot, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The report is certainly interesting — it does a good job of reminding us yet again of just how much and how often AI tools are being used for purposes beyond work. Still, it’s important to remember that AI chatbots, across the board, are still very much a work in progress: They hallucinate, are known to readily provide wrong information or dangerous advice, and as Anthropic itself has acknowledged, may even resort to blackmail.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/people-use-ai-for-companionship-much-less-than-were-led-to-believe/</guid><pubDate>Thu, 26 Jun 2025 14:21:28 +0000</pubDate></item><item><title>Suno snaps up WavTool for its AI music editing tools amid ongoing dispute with music labels (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/suno-snaps-up-wavtool-for-its-ai-music-editing-tools-amid-ongoing-dispute-with-music-labels/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2159558534.jpg?resize=1200,837" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Suno, the AI music company currently in a legal battle with music labels, announced on Thursday the acquisition of WavTool, a browser-based AI digital audio workstation (DAW). This acquisition aims to improve Suno’s editing capabilities for songwriters and producers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WavTool, launched in 2023, offers several tools to musicians, such as stem separation, AI audio generation, and an AI music assistant. Suno will integrate WavTool’s technology into its new editing interface, which launched this month.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The terms of the deal have not been disclosed. A company spokesperson noted that “most” of the WavTool employees moved to Suno’s product and engineering teams, although the exact number of those who did not make the move wasn’t revealed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The acquisition comes on the heels of yet another lawsuit against the company. Country musician Tony Justice and his music label, 5th Wheel Records, filed a lawsuit against Suno earlier this month, alleging that Suno used&amp;nbsp;copyrighted sound recordings to train its AI music generator.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This allegation is similar to lawsuits filed last year by Universal Music Group, Warner Music Group, and Sony Music Entertainment against Suno for copyright infringement. According to Bloomberg, the major music labels are in licensing talks with Suno.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suno acquired WavTool a few months ago, with the browser-based DAW going offline in November. Timing the announcement for this week seems intentional, possibly aimed at diverting attention from the lawsuit. Legal disputes often shake investor confidence, so the announcement of this acquisition may serve as a way to reassure them that the company remains committed to growth.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI startup secured $125 million in funding this past May.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-2159558534.jpg?resize=1200,837" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Suno, the AI music company currently in a legal battle with music labels, announced on Thursday the acquisition of WavTool, a browser-based AI digital audio workstation (DAW). This acquisition aims to improve Suno’s editing capabilities for songwriters and producers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WavTool, launched in 2023, offers several tools to musicians, such as stem separation, AI audio generation, and an AI music assistant. Suno will integrate WavTool’s technology into its new editing interface, which launched this month.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The terms of the deal have not been disclosed. A company spokesperson noted that “most” of the WavTool employees moved to Suno’s product and engineering teams, although the exact number of those who did not make the move wasn’t revealed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The acquisition comes on the heels of yet another lawsuit against the company. Country musician Tony Justice and his music label, 5th Wheel Records, filed a lawsuit against Suno earlier this month, alleging that Suno used&amp;nbsp;copyrighted sound recordings to train its AI music generator.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This allegation is similar to lawsuits filed last year by Universal Music Group, Warner Music Group, and Sony Music Entertainment against Suno for copyright infringement. According to Bloomberg, the major music labels are in licensing talks with Suno.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suno acquired WavTool a few months ago, with the browser-based DAW going offline in November. Timing the announcement for this week seems intentional, possibly aimed at diverting attention from the lawsuit. Legal disputes often shake investor confidence, so the announcement of this acquisition may serve as a way to reassure them that the company remains committed to growth.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI startup secured $125 million in funding this past May.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/suno-snaps-up-wavtool-for-its-ai-music-editing-tools-amid-ongoing-dispute-with-music-labels/</guid><pubDate>Thu, 26 Jun 2025 15:30:00 +0000</pubDate></item><item><title>PadChest-GR: A bilingual grounded radiology reporting benchmark for chest X-rays (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Alt text: The image features three white icons on a gradient background transitioning from blue on the left to green on the right. The first icon, located on the left, resembles an X-ray of a ribcage enclosed in a square with rounded corners. The middle icon depicts a hierarchical structure with one circle at the top connected by lines to two smaller circles below it. The third icon, positioned on the right, shows the letters " class="wp-image-1142658" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;In our ever-evolving journey to enhance healthcare through technology, we’re announcing a unique new benchmark for grounded radiology report generation—&lt;strong&gt;PadChest-GR&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;/strong&gt;. The world’s first multimodal, bilingual sentence-level radiology report dataset, developed&amp;nbsp;by the University of Alicante with Microsoft Research, University Hospital Sant Joan d’Alacant and MedBravo, is set to redefine how AI and radiologists interpret radiological images. Our work demonstrates how collaboration between humans and AI can create powerful feedback loops—where new datasets drive better AI models, and those models, in turn, inspire richer datasets. We’re excited to share this progress in NEJM AI, highlighting both the clinical relevance and research excellence of this initiative.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="a-new-frontier-in-radiology-report-generation"&gt;A new frontier in radiology report generation&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;It is estimated that over half of people visiting hospitals have radiology scans that must be interpreted by a clinical professional. Traditional radiology reports often condense multiple findings into unstructured narratives. In contrast, grounded radiology reporting demands that each finding be described and localized individually.&lt;/p&gt;



&lt;p&gt;This can mitigate the risk of AI fabrications and enable new interactive capabilities that enhance clinical and patient interpretability. PadChest-GR is the first bilingual dataset to address this need with 4,555 chest X-ray studies complete with Spanish and English sentence-level descriptions and precise spatial (bounding box) annotations for both positive and negative findings. It is the first public benchmark that enables us to evaluate generation of fully grounded radiology reports in chest X-rays.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: A chest X-ray overlaid with numbered bounding boxes, next to a matching list of structured radiological findings in Spanish and English. " class="wp-image-1142582" height="781" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example.png" width="1516" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Example of a grounded report from PadChest-GR. The original free-text report in Spanish was &lt;em&gt;”Motivo de consulta: Preoperatorio. Rx PA tórax: Impresión diagnóstica: Ateromatosis aórtica calcificada. Engrosamiento pleural biapical. Atelectasia laminar basal izquierda. Elongación aórtica. Sin otros hallazgos radiológicos significativos.”&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Microsoft research podcast&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Collaborators: Silica in space with Richard Black and Dexter Greene&lt;/h2&gt;
				
								&lt;p class="large" id="collaborators-silica-in-space-with-richard-black-and-dexter-greene"&gt;College freshman Dexter Greene and Microsoft research manager Richard Black discuss how technology that stores data in glass is supporting students as they expand earlier efforts to communicate what it means to be human to extraterrestrials.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;This benchmark isn’t standing alone—it plays a critical role in powering our state-of-the-art multimodal report generation model, &lt;strong&gt;MAIRA-2&lt;/strong&gt;. Leveraging the detailed annotations of PadChest-GR, MAIRA-2 represents our commitment to building more interpretable and clinically useful AI systems. You can explore our work on MAIRA-2 on our project web page, including recent user research conducted with clinicians in healthcare settings.&lt;/p&gt;



&lt;p&gt;PadChest-GR is a testament to the power of collaboration. Aurelia Bustos at MedBravo and Antonio Pertusa at the University of Alicante published the original&amp;nbsp;PadChest dataset&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; in 2020,&amp;nbsp;with the help of Jose María Salinas from Hospital San Juan de Alicante and María de la Iglesia Vayá from the Center of Excellence in Biomedical Imaging at the Ministry of Health in Valencia, Spain. We started to look at PadChest and were deeply impressed by the scale, depth, and diversity of the data.&lt;/p&gt;



&lt;p&gt;As we worked more closely with the dataset, we realized the opportunity to develop this for grounded radiology reporting research and worked with the team at the University of Alicante to determine how to approach this together. Our complementary expertise was a nice fit. At Microsoft Research, our mission is to push the boundaries of medical AI through innovative, data-driven solutions. The University of Alicante, with its deep clinical expertise, provided critical insights that greatly enriched the dataset’s relevance and utility. The result of this collaboration is the PadChest-GR dataset.&lt;/p&gt;



&lt;p&gt;A significant enabler of our annotation process was &lt;strong&gt;Centaur Labs&lt;/strong&gt;. The team of senior and junior radiologists from the University Hospital Sant Joan d’Alacant, coordinated by Joaquin Galant,&amp;nbsp;used this HIPAA-compliant labeling platform to&amp;nbsp;perform rigorous study-level quality control and bounding box annotations. The annotation protocol implemented ensured that each annotation was accurate and consistent, forming the backbone of a dataset designed for the next generation of grounded radiology report generation models.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="accelerating-padchest-gr-dataset-annotation-with-ai"&gt;Accelerating PadChest-GR dataset annotation with AI&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Our approach integrates advanced large language models with comprehensive manual annotation:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Data Selection &amp;amp; Processing:&lt;/strong&gt; Leveraging Microsoft Azure OpenAI Service&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; with GPT-4, we extracted sentences describing individual positive and negative findings from raw radiology reports, translated them from Spanish to English, and linked each sentence to the existing expert labels from PadChest. This was done for a selected subset of the full PadChest dataset, carefully curated to reflect a realistic distribution of clinically relevant findings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Manual Quality Control &amp;amp; Annotation:&lt;/strong&gt; The processed studies underwent meticulous quality checks on the Centaur Labs platform by radiologist from Hospital San Juan de Alicante. Each positive finding was then annotated with bounding boxes to capture critical spatial information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Standardization &amp;amp; Integration:&lt;/strong&gt; All annotations were harmonized into coherent grounded reports, preserving the structure and context of the original findings while enhancing interpretability.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: A detailed block diagram illustrating the flow of data between various stages of AI processing and manual annotation. " class="wp-image-1142586" height="790" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow.png" width="1752" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Overview of the data curation pipeline.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="impact-and-future-directions"&gt;Impact and future directions&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;PadChest-GR not only sets a new benchmark for grounded radiology reporting, but also serves as the foundation for our MAIRA-2 model, which already showcases the potential of highly interpretable AI in clinical settings. While we developed PadChest-GR to help train and validate our own models, we believe the research community will greatly benefit from this dataset for many years to come. We look forward to seeing the broader research community build on this—improving grounded reporting AI models and using PadChest-GR as a standard for evaluation. We believe that by fostering open collaboration and sharing our resources, we can accelerate progress in medical imaging AI and ultimately improve patient care together with the community.&lt;/p&gt;



&lt;p&gt;The collaboration between Microsoft Research and the University of Alicante highlights the transformative power of working together across disciplines. With our publication in NEJM-AI and the integral role of PadChest-GR in the development of MAIRA-2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and RadFact&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, we are excited about the future of AI-empowered radiology. We invite researchers and industry experts to explore PadChest-GR and MAIRA-2, contribute innovative ideas, and join us in advancing the field of grounded radiology reporting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Papers already using PadChest-GR:&lt;/p&gt;







&lt;p&gt;For further details or to download PadChest-GR, please visit the BIMCV PadChest-GR Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models in the Azure Foundry that can do Grounded Reporting:&amp;nbsp;&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgement"&gt;Acknowledgement&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Authors: Daniel C. Castro&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Aurelia Bustos&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Shruthi Bannur&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Stephanie L. Hyland&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Kenza Bouzid&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Maria Teodora Wetscherek&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Maria Dolores Sánchez-Valverde&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Lara Jaques-Pérez&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Lourdes Pérez-Rodríguez&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Kenji Takeda&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, José María Salinas&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Javier Alvarez-Valle&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Joaquín Galant Herrero&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Antonio Pertusa&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;












&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Alt text: The image features three white icons on a gradient background transitioning from blue on the left to green on the right. The first icon, located on the left, resembles an X-ray of a ribcage enclosed in a square with rounded corners. The middle icon depicts a hierarchical structure with one circle at the top connected by lines to two smaller circles below it. The third icon, positioned on the right, shows the letters " class="wp-image-1142658" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/PadChest-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;In our ever-evolving journey to enhance healthcare through technology, we’re announcing a unique new benchmark for grounded radiology report generation—&lt;strong&gt;PadChest-GR&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;/strong&gt;. The world’s first multimodal, bilingual sentence-level radiology report dataset, developed&amp;nbsp;by the University of Alicante with Microsoft Research, University Hospital Sant Joan d’Alacant and MedBravo, is set to redefine how AI and radiologists interpret radiological images. Our work demonstrates how collaboration between humans and AI can create powerful feedback loops—where new datasets drive better AI models, and those models, in turn, inspire richer datasets. We’re excited to share this progress in NEJM AI, highlighting both the clinical relevance and research excellence of this initiative.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="a-new-frontier-in-radiology-report-generation"&gt;A new frontier in radiology report generation&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;It is estimated that over half of people visiting hospitals have radiology scans that must be interpreted by a clinical professional. Traditional radiology reports often condense multiple findings into unstructured narratives. In contrast, grounded radiology reporting demands that each finding be described and localized individually.&lt;/p&gt;



&lt;p&gt;This can mitigate the risk of AI fabrications and enable new interactive capabilities that enhance clinical and patient interpretability. PadChest-GR is the first bilingual dataset to address this need with 4,555 chest X-ray studies complete with Spanish and English sentence-level descriptions and precise spatial (bounding box) annotations for both positive and negative findings. It is the first public benchmark that enables us to evaluate generation of fully grounded radiology reports in chest X-rays.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 1: A chest X-ray overlaid with numbered bounding boxes, next to a matching list of structured radiological findings in Spanish and English. " class="wp-image-1142582" height="781" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/grounded_report_example.png" width="1516" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1. Example of a grounded report from PadChest-GR. The original free-text report in Spanish was &lt;em&gt;”Motivo de consulta: Preoperatorio. Rx PA tórax: Impresión diagnóstica: Ateromatosis aórtica calcificada. Engrosamiento pleural biapical. Atelectasia laminar basal izquierda. Elongación aórtica. Sin otros hallazgos radiológicos significativos.”&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;




	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Microsoft research podcast&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Collaborators: Silica in space with Richard Black and Dexter Greene&lt;/h2&gt;
				
								&lt;p class="large" id="collaborators-silica-in-space-with-richard-black-and-dexter-greene"&gt;College freshman Dexter Greene and Microsoft research manager Richard Black discuss how technology that stores data in glass is supporting students as they expand earlier efforts to communicate what it means to be human to extraterrestrials.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	&lt;p&gt;This benchmark isn’t standing alone—it plays a critical role in powering our state-of-the-art multimodal report generation model, &lt;strong&gt;MAIRA-2&lt;/strong&gt;. Leveraging the detailed annotations of PadChest-GR, MAIRA-2 represents our commitment to building more interpretable and clinically useful AI systems. You can explore our work on MAIRA-2 on our project web page, including recent user research conducted with clinicians in healthcare settings.&lt;/p&gt;



&lt;p&gt;PadChest-GR is a testament to the power of collaboration. Aurelia Bustos at MedBravo and Antonio Pertusa at the University of Alicante published the original&amp;nbsp;PadChest dataset&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; in 2020,&amp;nbsp;with the help of Jose María Salinas from Hospital San Juan de Alicante and María de la Iglesia Vayá from the Center of Excellence in Biomedical Imaging at the Ministry of Health in Valencia, Spain. We started to look at PadChest and were deeply impressed by the scale, depth, and diversity of the data.&lt;/p&gt;



&lt;p&gt;As we worked more closely with the dataset, we realized the opportunity to develop this for grounded radiology reporting research and worked with the team at the University of Alicante to determine how to approach this together. Our complementary expertise was a nice fit. At Microsoft Research, our mission is to push the boundaries of medical AI through innovative, data-driven solutions. The University of Alicante, with its deep clinical expertise, provided critical insights that greatly enriched the dataset’s relevance and utility. The result of this collaboration is the PadChest-GR dataset.&lt;/p&gt;



&lt;p&gt;A significant enabler of our annotation process was &lt;strong&gt;Centaur Labs&lt;/strong&gt;. The team of senior and junior radiologists from the University Hospital Sant Joan d’Alacant, coordinated by Joaquin Galant,&amp;nbsp;used this HIPAA-compliant labeling platform to&amp;nbsp;perform rigorous study-level quality control and bounding box annotations. The annotation protocol implemented ensured that each annotation was accurate and consistent, forming the backbone of a dataset designed for the next generation of grounded radiology report generation models.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="accelerating-padchest-gr-dataset-annotation-with-ai"&gt;Accelerating PadChest-GR dataset annotation with AI&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;Our approach integrates advanced large language models with comprehensive manual annotation:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Data Selection &amp;amp; Processing:&lt;/strong&gt; Leveraging Microsoft Azure OpenAI Service&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; with GPT-4, we extracted sentences describing individual positive and negative findings from raw radiology reports, translated them from Spanish to English, and linked each sentence to the existing expert labels from PadChest. This was done for a selected subset of the full PadChest dataset, carefully curated to reflect a realistic distribution of clinically relevant findings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Manual Quality Control &amp;amp; Annotation:&lt;/strong&gt; The processed studies underwent meticulous quality checks on the Centaur Labs platform by radiologist from Hospital San Juan de Alicante. Each positive finding was then annotated with bounding boxes to capture critical spatial information.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Standardization &amp;amp; Integration:&lt;/strong&gt; All annotations were harmonized into coherent grounded reports, preserving the structure and context of the original findings while enhancing interpretability.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Figure 2: A detailed block diagram illustrating the flow of data between various stages of AI processing and manual annotation. " class="wp-image-1142586" height="790" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/06/dataflow.png" width="1752" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Overview of the data curation pipeline.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="impact-and-future-directions"&gt;Impact and future directions&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;PadChest-GR not only sets a new benchmark for grounded radiology reporting, but also serves as the foundation for our MAIRA-2 model, which already showcases the potential of highly interpretable AI in clinical settings. While we developed PadChest-GR to help train and validate our own models, we believe the research community will greatly benefit from this dataset for many years to come. We look forward to seeing the broader research community build on this—improving grounded reporting AI models and using PadChest-GR as a standard for evaluation. We believe that by fostering open collaboration and sharing our resources, we can accelerate progress in medical imaging AI and ultimately improve patient care together with the community.&lt;/p&gt;



&lt;p&gt;The collaboration between Microsoft Research and the University of Alicante highlights the transformative power of working together across disciplines. With our publication in NEJM-AI and the integral role of PadChest-GR in the development of MAIRA-2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and RadFact&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, we are excited about the future of AI-empowered radiology. We invite researchers and industry experts to explore PadChest-GR and MAIRA-2, contribute innovative ideas, and join us in advancing the field of grounded radiology reporting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Papers already using PadChest-GR:&lt;/p&gt;







&lt;p&gt;For further details or to download PadChest-GR, please visit the BIMCV PadChest-GR Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models in the Azure Foundry that can do Grounded Reporting:&amp;nbsp;&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgement"&gt;Acknowledgement&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Authors: Daniel C. Castro&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Aurelia Bustos&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Shruthi Bannur&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Stephanie L. Hyland&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Kenza Bouzid&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Maria Teodora Wetscherek&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Maria Dolores Sánchez-Valverde&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Lara Jaques-Pérez&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Lourdes Pérez-Rodríguez&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Kenji Takeda&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, José María Salinas&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Javier Alvarez-Valle&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Joaquín Galant Herrero&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, Antonio Pertusa&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;












&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;&lt;!-- promos injected --&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/padchest-gr-a-bilingual-grounded-radiology-reporting-benchmark-for-chest-x-rays/</guid><pubDate>Thu, 26 Jun 2025 16:08:25 +0000</pubDate></item><item><title>Meta hires key OpenAI researcher to work on AI reasoning models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/meta-hires-key-openai-researcher-to-work-on-ai-reasoning-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta has hired a highly influential OpenAI researcher, Trapit Bansal, to work on its AI reasoning models under the company’s new AI superintelligence unit, a person familiar with the matter tells TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI spokesperson Kayla Wood confirmed to TechCrunch that Bansal had departed OpenAI. Bansal’s LinkedIn page says that he left OpenAI in June.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Bansal has worked at OpenAI since 2022 and was a key player in kickstarting the company’s work on reinforcement learning alongside co-founder Ilya Sutskever. He is listed as a foundational contributor on OpenAI’s first AI reasoning model, o1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bansal could offer a significant lift to Meta’s AI superintelligence lab, which also features leaders such as former Scale AI CEO Alexandr Wang and is looking to add former GitHub CEO Nat Friedman and Safe Superintelligence co-founder Daniel Gross. Bansal could help Meta develop a frontier AI reasoning model that’s competitive with industry-leading technology, such as OpenAI’s o3 or DeepSeek’s R1. Currently, Meta does not offer an AI reasoning model publicly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, Mark Zuckerberg has been on a hiring spree to build out Meta’s new AI team, offering $100 million compensation packages to top researchers who join his company. It’s unclear what Bansal was offered to join in this deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, it seems that Zuckerberg has been successful at nabbing top AI research talent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Three other former OpenAI researchers — Lucas Beyer, Alexander Kolesnikov, and Xiaohua Zhai — have also joined Meta’s AI superintelligence team in recent weeks, The Wall Street Journal reported on Wednesday. Bansal will join them, alongside former Google DeepMind researcher Jack Rae and former machine learning leader at the startup Sesame, Johan Schalkwyk, according to Bloomberg.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;To further fill out its new AI unit, Zuckerberg reportedly tried to acquire startups with heavy-hitting AI research labs, such as Sutskever’s Safe Superintelligence, Mira Murati’s Thinking Machines Labs, and Perplexity. However, those talks never progressed to a final stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On a recent podcast, OpenAI CEO Sam Altman said Meta has been trying to poach his startup’s top talent, but claimed that “none of our best people have decided to take him up on that.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Meta spokesperson declined to comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI reasoning models present a key area for Meta’s AI superintelligence team to get right. In the last year, OpenAI, Google, and DeepSeek have shipped highly performant AI reasoning models that have pushed the limits of what software can do. By training AI models to work through problems before giving an answer, using additional time and computing resources to do so, AI labs have found success in improving AI’s performance on benchmarks and real-world tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI superintelligence lab could become a key internal group that powers products throughout the company, much like Google’s DeepMind unit. Meta has an ambitious effort to build AI agents for business under the former Salesforce CEO of AI, Clara Shih. In order to build competitive agents, Meta needs to develop frontier AI reasoning models to power them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Bansal and other key AI researchers, Meta hopes to pull ahead in the AI race. That may be difficult given that OpenAI plans to release an open AI reasoning model in the coming weeks — an offering that could add even more pressure on Meta’s open AI offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was updated after publication with more details&lt;/em&gt;. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta has hired a highly influential OpenAI researcher, Trapit Bansal, to work on its AI reasoning models under the company’s new AI superintelligence unit, a person familiar with the matter tells TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI spokesperson Kayla Wood confirmed to TechCrunch that Bansal had departed OpenAI. Bansal’s LinkedIn page says that he left OpenAI in June.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Bansal has worked at OpenAI since 2022 and was a key player in kickstarting the company’s work on reinforcement learning alongside co-founder Ilya Sutskever. He is listed as a foundational contributor on OpenAI’s first AI reasoning model, o1.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bansal could offer a significant lift to Meta’s AI superintelligence lab, which also features leaders such as former Scale AI CEO Alexandr Wang and is looking to add former GitHub CEO Nat Friedman and Safe Superintelligence co-founder Daniel Gross. Bansal could help Meta develop a frontier AI reasoning model that’s competitive with industry-leading technology, such as OpenAI’s o3 or DeepSeek’s R1. Currently, Meta does not offer an AI reasoning model publicly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, Mark Zuckerberg has been on a hiring spree to build out Meta’s new AI team, offering $100 million compensation packages to top researchers who join his company. It’s unclear what Bansal was offered to join in this deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nevertheless, it seems that Zuckerberg has been successful at nabbing top AI research talent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Three other former OpenAI researchers — Lucas Beyer, Alexander Kolesnikov, and Xiaohua Zhai — have also joined Meta’s AI superintelligence team in recent weeks, The Wall Street Journal reported on Wednesday. Bansal will join them, alongside former Google DeepMind researcher Jack Rae and former machine learning leader at the startup Sesame, Johan Schalkwyk, according to Bloomberg.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;To further fill out its new AI unit, Zuckerberg reportedly tried to acquire startups with heavy-hitting AI research labs, such as Sutskever’s Safe Superintelligence, Mira Murati’s Thinking Machines Labs, and Perplexity. However, those talks never progressed to a final stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On a recent podcast, OpenAI CEO Sam Altman said Meta has been trying to poach his startup’s top talent, but claimed that “none of our best people have decided to take him up on that.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A Meta spokesperson declined to comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI reasoning models present a key area for Meta’s AI superintelligence team to get right. In the last year, OpenAI, Google, and DeepSeek have shipped highly performant AI reasoning models that have pushed the limits of what software can do. By training AI models to work through problems before giving an answer, using additional time and computing resources to do so, AI labs have found success in improving AI’s performance on benchmarks and real-world tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s AI superintelligence lab could become a key internal group that powers products throughout the company, much like Google’s DeepMind unit. Meta has an ambitious effort to build AI agents for business under the former Salesforce CEO of AI, Clara Shih. In order to build competitive agents, Meta needs to develop frontier AI reasoning models to power them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the addition of Bansal and other key AI researchers, Meta hopes to pull ahead in the AI race. That may be difficult given that OpenAI plans to release an open AI reasoning model in the coming weeks — an offering that could add even more pressure on Meta’s open AI offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was updated after publication with more details&lt;/em&gt;. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/meta-hires-key-openai-researcher-to-work-on-ai-reasoning-models/</guid><pubDate>Thu, 26 Jun 2025 16:13:59 +0000</pubDate></item><item><title>Google begins rolling out AI search in YouTube (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/06/google-begins-rolling-out-ai-search-in-youtube/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The feature is only available as a test for Premium members for now.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube AI simple" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YouTube-AI-640x360.jpg" width="640" /&gt;
                  &lt;img alt="YouTube AI simple" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YouTube-AI-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Over the past year, Google has transformed its web search experience with AI, driving toward a zero-click experience. Now, the same AI focus is coming to YouTube, and Premium subscribers can get a preview of the new search regime. Select searches on the video platform will now produce an AI-generated results carousel with a collection of relevant videos. Even if you don't pay for YouTube, AI is still coming for you with an expansion of Google's video chatbot.&lt;/p&gt;
&lt;p&gt;Google says the new AI search feature, which appears at the top of the results page, will include multiple videos, along with an AI summary of each. You can tap the video thumbnails to begin playing them right from the carousel. The summary is intended to extract the information most relevant to your search query, so you may not even have to watch the videos.&lt;/p&gt;
&lt;p&gt;The AI results carousel is only a test right now, and it's limited to YouTube Premium subscribers. If you're paying for Premium, you can enable the feature on YouTube's experimental page. While the feature is entirely opt-in, that probably won't last long. Like AI Overviews in search, this feature will take precedence over organic search results and get people interacting with Google's AI, and that's the driving force behind most of the company's decisions lately.&lt;/p&gt;
&lt;div class="yt-short-wrapper"&gt;

&lt;/div&gt;
&lt;p&gt;It's not hard to see where this feature could lead because we've seen the same thing play out in general web search. By putting AI-generated content at the top of search results, Google will reduce the number of videos people click to watch. The carousel gives you the relevant parts of the video along with a summary, but the video page is another tap away. Rather than opening videos, commenting, subscribing, and otherwise interacting with creators, some users will just peruse the AI carousel. That could make it harder for channels to grow and earn revenue from their content—the same content Google will feed into Gemini to generate the AI carousel.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, the AI-generated results carousel will only appear for shopping, places, and activities in specific areas. Google recommends searches like "best beaches in Hawaii" and "noise canceling headphones." However, AI Overviews launched with AI answers for a small subset of searches, and it has since expanded to almost all queries. The AI-generated results carousel could end up the same, but we're not there yet. In addition to being an opt-in test for subscribers, the AI results are also limited to the mobile app and English-language videos for now.&lt;/p&gt;
&lt;p&gt;Alongside the debut of AI search in YouTube, Google is expanding its conversational AI tool to more users. This feature was previously limited to Premium members, but it will now appear for everyone. This chatbot lets you ask questions about a video, get recommendations for similar content, and explore concepts.&lt;/p&gt;
&lt;p&gt;Google has also promised (threatened?) that it's working on more AI features to "help you get the most out of YouTube." Prepare yourself.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The feature is only available as a test for Premium members for now.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="YouTube AI simple" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YouTube-AI-640x360.jpg" width="640" /&gt;
                  &lt;img alt="YouTube AI simple" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/YouTube-AI-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Over the past year, Google has transformed its web search experience with AI, driving toward a zero-click experience. Now, the same AI focus is coming to YouTube, and Premium subscribers can get a preview of the new search regime. Select searches on the video platform will now produce an AI-generated results carousel with a collection of relevant videos. Even if you don't pay for YouTube, AI is still coming for you with an expansion of Google's video chatbot.&lt;/p&gt;
&lt;p&gt;Google says the new AI search feature, which appears at the top of the results page, will include multiple videos, along with an AI summary of each. You can tap the video thumbnails to begin playing them right from the carousel. The summary is intended to extract the information most relevant to your search query, so you may not even have to watch the videos.&lt;/p&gt;
&lt;p&gt;The AI results carousel is only a test right now, and it's limited to YouTube Premium subscribers. If you're paying for Premium, you can enable the feature on YouTube's experimental page. While the feature is entirely opt-in, that probably won't last long. Like AI Overviews in search, this feature will take precedence over organic search results and get people interacting with Google's AI, and that's the driving force behind most of the company's decisions lately.&lt;/p&gt;
&lt;div class="yt-short-wrapper"&gt;

&lt;/div&gt;
&lt;p&gt;It's not hard to see where this feature could lead because we've seen the same thing play out in general web search. By putting AI-generated content at the top of search results, Google will reduce the number of videos people click to watch. The carousel gives you the relevant parts of the video along with a summary, but the video page is another tap away. Rather than opening videos, commenting, subscribing, and otherwise interacting with creators, some users will just peruse the AI carousel. That could make it harder for channels to grow and earn revenue from their content—the same content Google will feed into Gemini to generate the AI carousel.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Currently, the AI-generated results carousel will only appear for shopping, places, and activities in specific areas. Google recommends searches like "best beaches in Hawaii" and "noise canceling headphones." However, AI Overviews launched with AI answers for a small subset of searches, and it has since expanded to almost all queries. The AI-generated results carousel could end up the same, but we're not there yet. In addition to being an opt-in test for subscribers, the AI results are also limited to the mobile app and English-language videos for now.&lt;/p&gt;
&lt;p&gt;Alongside the debut of AI search in YouTube, Google is expanding its conversational AI tool to more users. This feature was previously limited to Premium members, but it will now appear for everyone. This chatbot lets you ask questions about a video, get recommendations for similar content, and explore concepts.&lt;/p&gt;
&lt;p&gt;Google has also promised (threatened?) that it's working on more AI features to "help you get the most out of YouTube." Prepare yourself.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/06/google-begins-rolling-out-ai-search-in-youtube/</guid><pubDate>Thu, 26 Jun 2025 16:43:05 +0000</pubDate></item><item><title>Book authors made the wrong arguments in Meta AI training case, judge says (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/06/book-authors-made-the-wrong-arguments-in-meta-ai-training-case-judge-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Judges clash over "schoolchildren" analogy in key AI training rulings.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2207798306-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2207798306-1152x648-1750956527.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Book authors and publishing professionals staged a protest outside Meta UK offices in King's Cross over the Facebook owner's use of copyrighted books to train artificial intelligence. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SOPA Images / Contributor | LightRocket

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Soon after a landmark ruling deemed that when Anthropic copied books to train artificial intelligence models, it was a "transformative" fair use, another judge has arrived at the same conclusion in a case pitting book authors against Meta.&lt;/p&gt;
&lt;p&gt;But that doesn't necessarily mean the judges are completely in agreement, and that could soon become a problem for not just Meta, but other big AI companies celebrating the pair of wins this week.&lt;/p&gt;
&lt;p&gt;On Wednesday, Judge Vince Chhabria explained that he sided with Meta, despite his better judgment, mainly because the authors made all the wrong arguments in their case against Meta.&lt;/p&gt;
&lt;p&gt;"This ruling does not stand for the proposition that Meta’s use of copyrighted materials to train its language models is lawful," Chhabria wrote. "It stands only for the proposition that these plaintiffs made the wrong arguments and failed to develop a record in support of the right one."&lt;/p&gt;
&lt;p&gt;Rather than argue that Meta's Llama AI models risked rapidly flooding their markets with competing AI-generated books that could indirectly harm sales, authors fatally only argued "that users of Llama can reproduce text from their books, and that Meta’s copying harmed the market for licensing copyrighted materials to companies for AI training."&lt;/p&gt;
&lt;p&gt;Because Chhabria found both of these theories "flawed"—the former because Llama cannot produce long excerpts of works, even with adversarial prompting, and the latter because authors are not entitled to monopolize the market for licensing books for AI training—he said he had no choice but to grant Meta's request for summary judgment.&lt;/p&gt;
&lt;p&gt;Ultimately, because authors introduced no evidence that Meta's AI threatened to dilute their markets, Chhabria ruled that Meta did enough to overcome authors' other arguments regarding alleged harms by simply providing "its own expert testimony explaining that Llama 3’s release did not have any discernible effect on the plaintiffs’ sales."&lt;/p&gt;
&lt;p&gt;Chhabria seemed to criticize authors for raising a "half-hearted" defense of their works, noting that his opinion "may be in significant tension with reality," where it seems "possible, even likely, that Llama will harm the book sale market."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There is perhaps a silver lining for other book authors in this ruling, Chhabria suggested. Since Meta's request for summary judgment came before class certification in the lawsuit, his ruling only applies to the 13 authors who sued Meta in this particular case. That means that other authors who perhaps could make a stronger case alleging market harms could still have a strong chance at winning a future Meta lawsuit, Chhabria wrote.&lt;/p&gt;
&lt;p&gt;"In cases involving uses like Meta’s, it seems like the plaintiffs will often win, at least where those cases have better-developed records on the market effects of the defendant’s use," Chhabria wrote. "No matter how transformative [AI] training may be, it’s hard to imagine that it can be fair use to use copyrighted books to develop a tool to make billions or trillions of dollars while enabling the creation of a potentially endless stream of competing works that could significantly harm the market for those books."&lt;/p&gt;
&lt;p&gt;Further, Chhabria suggested that "some cases might present even stronger arguments against fair use"—such as news organizations suing OpenAI over allegedly infringing ChatGPT outputs that could indirectly compete with their websites. Celebrating the ruling, a lawyer representing The New York Times in that suit, Ian Crosby, told Ars that both Chhabria's and Alsup's rulings are viewed as strengthening the NYT's case.&lt;/p&gt;
&lt;p&gt;"These two decisions show what we have long argued: generative AI developers may not build products by copying stolen news content, particularly where that content is taken by wrongful means and their products output substitutive content that threatens the market for original, human-made journalism," Crosby said.&lt;/p&gt;
&lt;p&gt;On the other hand, Chhabria wrote that AI companies may have an easier time defeating copyright claims if the feared market dilution is a trade-off for a clear public benefit, like advancing non-commercial research into national security or medicine.&lt;/p&gt;
&lt;p&gt;Chhabria said that if the authors had introduced any evidence of market dilution, Meta would not have won at this stage of the case and would have likely faced broader discovery in a class-action suit weighed by a jury.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, the only surviving claim in this case concerns Meta's controversial torrenting of books to train Llama, which authors have so far successfully alleged may have violated copyright laws by distributing their works as part of the torrenting process.&lt;/p&gt;
&lt;h2&gt;Training AI is not akin to teaching “schoolchildren”&lt;/h2&gt;
&lt;p&gt;According to Chhabria, if rights holders provide evidence of market dilution, that may raise the strongest opposition most likely to win AI copyright fights. So, while Meta technically won this fight against these book authors, the ruling isn't necessarily a slam dunk for Meta, nor does it offer ample security for any AI company.&lt;/p&gt;
&lt;p&gt;Rather than suggest that AI companies can defeat copyright claims on the virtue that their products are "transformative" uses of authors' works, Chhabria said that cases will win or lose based on allegations of market harm.&lt;/p&gt;
&lt;p&gt;He claimed that the "upshot" of his ruling is that he did not create any bright-line rules carving out exceptions for AI companies. Instead, he believes that his ruling makes it clear "that in many circumstances it will be illegal to copy copyright-protected works to train generative AI models without permission. Which means that the companies, to avoid liability for copyright infringement, will generally need to pay copyright holders for the right to use their materials."&lt;/p&gt;
&lt;p&gt;In his order, Chhabria called out Judge William Alsup for focusing his ruling this week in the Anthropic case "heavily on the transformative nature of generative AI while brushing aside concerns about the harm it can inflict on the market for the works it gets trained on."&lt;/p&gt;
&lt;p&gt;Chhabria particularly did not approve that Alsup compared authors' complaints of the possible market harms that could result if Anthropic's Claude flooded&amp;nbsp;book markets to the outlandish idea that teaching "schoolchildren to write well" would "result in an explosion of competing works."&lt;/p&gt;
&lt;p&gt;"According to Judge Alsup, this 'is not the kind of competitive or creative displacement that concerns the Copyright Act,'" Chhabria wrote. "But when it comes to market effects, using books to teach children to write is not remotely like using books to create a product that a single individual could employ to generate countless competing works with a miniscule [sic] fraction of the time and creativity it would otherwise take.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"This inapt analogy is not a basis for blowing off the most important factor in the fair use analysis," Chhabria cautioned.&lt;/p&gt;
&lt;p&gt;Additionally, Meta's claim that granting authors a win would stop AI innovation "in its tracks" is "ridiculous," Chhabria wrote, noting that if rights holders win in any of the lawsuits against AI companies today, the only outcome would be that AI companies would have to pay authors—or else rely on materials in the public domain and prove that it's not necessary to use copyrighted works for AI training after all.&lt;/p&gt;
&lt;p&gt;"These products are expected to generate billions, even trillions, of dollars for the companies that are developing them," Chhabria wrote. "If using copyrighted works to train the models is as necessary as the companies say, they will figure out a way to compensate copyright holders for it."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Three ways authors can keep fighting AI training&lt;/h2&gt;
&lt;p&gt;This week's rulings suggest that the question of whether AI training is transformative has been largely settled.&lt;/p&gt;
&lt;p&gt;But as authors continue suing AI companies, with the latest lawsuit lobbed at Microsoft this week, Chhabria suggested that "generally the plaintiff’s only chance to defeat fair use will be to win decisively on" the fourth factor of a fair use analysis, where judges and juries weigh "the effect of the use upon the potential market for or value of the copyrighted work."&lt;/p&gt;
&lt;p&gt;Chhabria suggested that authors had at least three paths to fight AI training on the basis of market harms. First, they could claim that AI outputs "regurgitate their works." Second, they could "point to the market for licensing their works for AI training and contend that unauthorized copying for training harms that market (or precludes the development of that market)." And third, they could argue that AI outputs could "indirectly substitute" their works by generating "substantially similar" works.&lt;/p&gt;
&lt;p&gt;Because the first two arguments failed in the Meta case, Chhabria thinks "the third argument is far more promising" for authors intending to pick up the torch where the 13 authors in the current case have failed.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;An interesting wrinkle that may have stopped authors from invoking market dilution as a threat in the Meta case is that Chhabria noted that Meta had argued that "market dilution does not count under the fourth factor."&lt;/p&gt;
&lt;p&gt;But Chhabria clarified "that can’t be right."&lt;/p&gt;
&lt;p&gt;"Indirect substitution is still substitution," Chhabria wrote. "If someone bought a romance novel written by [a large language model (LLM)] instead of a romance novel written by a human author, the LLM-generated novel is substituting for the human-written one." Seemingly, the same would go for AI-generated non-fiction books, he suggested.&lt;/p&gt;
&lt;p&gt;So while "it’s true that, in many copyright cases, this concept of market dilution or indirect substitution is not particularly important," AI cases may change the copyright landscape because it "involves a technology that can generate literally millions of secondary works, with a miniscule [sic] fraction of the time and creativity used to create the original works it was trained on," Chhabria wrote.&lt;/p&gt;
&lt;p&gt;This is unprecedented, Chhabria suggested, as no other use "has anything near the potential to flood the market with competing works the way that LLM training does. And so the concept of market dilution becomes highly relevant... Courts can’t stick their heads in the sand to an obvious way that a new technology might severely harm the incentive to create, just because the issue has not come up before."&lt;/p&gt;
&lt;p&gt;In a way, Chhabria's ruling provides a roadmap for rights holders looking to advance lawsuits against AI companies in the midst of precedent-setting rulings.&lt;/p&gt;
&lt;p&gt;Unfortunately for book authors suing Meta who found a sympathetic judge in Chhabria—but only made a "fleeting reference" to indirect substitution in a single report in its filings ahead of yesterday's ruling—"courts can’t decide cases based on what they think will or should happen in other cases."&lt;/p&gt;
&lt;p&gt;If their allegations were just a little stronger, Chhabria suggested they could have even won on summary judgment, instead of Meta.&lt;/p&gt;
&lt;p&gt;"Indeed, it seems likely that market dilution will often cause plaintiffs to decisively win the fourth factor—and thus win the fair use question overall—in cases like this," Chhabria wrote.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Judges clash over "schoolchildren" analogy in key AI training rulings.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2207798306-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2207798306-1152x648-1750956527.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Book authors and publishing professionals staged a protest outside Meta UK offices in King's Cross over the Facebook owner's use of copyrighted books to train artificial intelligence. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          SOPA Images / Contributor | LightRocket

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Soon after a landmark ruling deemed that when Anthropic copied books to train artificial intelligence models, it was a "transformative" fair use, another judge has arrived at the same conclusion in a case pitting book authors against Meta.&lt;/p&gt;
&lt;p&gt;But that doesn't necessarily mean the judges are completely in agreement, and that could soon become a problem for not just Meta, but other big AI companies celebrating the pair of wins this week.&lt;/p&gt;
&lt;p&gt;On Wednesday, Judge Vince Chhabria explained that he sided with Meta, despite his better judgment, mainly because the authors made all the wrong arguments in their case against Meta.&lt;/p&gt;
&lt;p&gt;"This ruling does not stand for the proposition that Meta’s use of copyrighted materials to train its language models is lawful," Chhabria wrote. "It stands only for the proposition that these plaintiffs made the wrong arguments and failed to develop a record in support of the right one."&lt;/p&gt;
&lt;p&gt;Rather than argue that Meta's Llama AI models risked rapidly flooding their markets with competing AI-generated books that could indirectly harm sales, authors fatally only argued "that users of Llama can reproduce text from their books, and that Meta’s copying harmed the market for licensing copyrighted materials to companies for AI training."&lt;/p&gt;
&lt;p&gt;Because Chhabria found both of these theories "flawed"—the former because Llama cannot produce long excerpts of works, even with adversarial prompting, and the latter because authors are not entitled to monopolize the market for licensing books for AI training—he said he had no choice but to grant Meta's request for summary judgment.&lt;/p&gt;
&lt;p&gt;Ultimately, because authors introduced no evidence that Meta's AI threatened to dilute their markets, Chhabria ruled that Meta did enough to overcome authors' other arguments regarding alleged harms by simply providing "its own expert testimony explaining that Llama 3’s release did not have any discernible effect on the plaintiffs’ sales."&lt;/p&gt;
&lt;p&gt;Chhabria seemed to criticize authors for raising a "half-hearted" defense of their works, noting that his opinion "may be in significant tension with reality," where it seems "possible, even likely, that Llama will harm the book sale market."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There is perhaps a silver lining for other book authors in this ruling, Chhabria suggested. Since Meta's request for summary judgment came before class certification in the lawsuit, his ruling only applies to the 13 authors who sued Meta in this particular case. That means that other authors who perhaps could make a stronger case alleging market harms could still have a strong chance at winning a future Meta lawsuit, Chhabria wrote.&lt;/p&gt;
&lt;p&gt;"In cases involving uses like Meta’s, it seems like the plaintiffs will often win, at least where those cases have better-developed records on the market effects of the defendant’s use," Chhabria wrote. "No matter how transformative [AI] training may be, it’s hard to imagine that it can be fair use to use copyrighted books to develop a tool to make billions or trillions of dollars while enabling the creation of a potentially endless stream of competing works that could significantly harm the market for those books."&lt;/p&gt;
&lt;p&gt;Further, Chhabria suggested that "some cases might present even stronger arguments against fair use"—such as news organizations suing OpenAI over allegedly infringing ChatGPT outputs that could indirectly compete with their websites. Celebrating the ruling, a lawyer representing The New York Times in that suit, Ian Crosby, told Ars that both Chhabria's and Alsup's rulings are viewed as strengthening the NYT's case.&lt;/p&gt;
&lt;p&gt;"These two decisions show what we have long argued: generative AI developers may not build products by copying stolen news content, particularly where that content is taken by wrongful means and their products output substitutive content that threatens the market for original, human-made journalism," Crosby said.&lt;/p&gt;
&lt;p&gt;On the other hand, Chhabria wrote that AI companies may have an easier time defeating copyright claims if the feared market dilution is a trade-off for a clear public benefit, like advancing non-commercial research into national security or medicine.&lt;/p&gt;
&lt;p&gt;Chhabria said that if the authors had introduced any evidence of market dilution, Meta would not have won at this stage of the case and would have likely faced broader discovery in a class-action suit weighed by a jury.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, the only surviving claim in this case concerns Meta's controversial torrenting of books to train Llama, which authors have so far successfully alleged may have violated copyright laws by distributing their works as part of the torrenting process.&lt;/p&gt;
&lt;h2&gt;Training AI is not akin to teaching “schoolchildren”&lt;/h2&gt;
&lt;p&gt;According to Chhabria, if rights holders provide evidence of market dilution, that may raise the strongest opposition most likely to win AI copyright fights. So, while Meta technically won this fight against these book authors, the ruling isn't necessarily a slam dunk for Meta, nor does it offer ample security for any AI company.&lt;/p&gt;
&lt;p&gt;Rather than suggest that AI companies can defeat copyright claims on the virtue that their products are "transformative" uses of authors' works, Chhabria said that cases will win or lose based on allegations of market harm.&lt;/p&gt;
&lt;p&gt;He claimed that the "upshot" of his ruling is that he did not create any bright-line rules carving out exceptions for AI companies. Instead, he believes that his ruling makes it clear "that in many circumstances it will be illegal to copy copyright-protected works to train generative AI models without permission. Which means that the companies, to avoid liability for copyright infringement, will generally need to pay copyright holders for the right to use their materials."&lt;/p&gt;
&lt;p&gt;In his order, Chhabria called out Judge William Alsup for focusing his ruling this week in the Anthropic case "heavily on the transformative nature of generative AI while brushing aside concerns about the harm it can inflict on the market for the works it gets trained on."&lt;/p&gt;
&lt;p&gt;Chhabria particularly did not approve that Alsup compared authors' complaints of the possible market harms that could result if Anthropic's Claude flooded&amp;nbsp;book markets to the outlandish idea that teaching "schoolchildren to write well" would "result in an explosion of competing works."&lt;/p&gt;
&lt;p&gt;"According to Judge Alsup, this 'is not the kind of competitive or creative displacement that concerns the Copyright Act,'" Chhabria wrote. "But when it comes to market effects, using books to teach children to write is not remotely like using books to create a product that a single individual could employ to generate countless competing works with a miniscule [sic] fraction of the time and creativity it would otherwise take.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"This inapt analogy is not a basis for blowing off the most important factor in the fair use analysis," Chhabria cautioned.&lt;/p&gt;
&lt;p&gt;Additionally, Meta's claim that granting authors a win would stop AI innovation "in its tracks" is "ridiculous," Chhabria wrote, noting that if rights holders win in any of the lawsuits against AI companies today, the only outcome would be that AI companies would have to pay authors—or else rely on materials in the public domain and prove that it's not necessary to use copyrighted works for AI training after all.&lt;/p&gt;
&lt;p&gt;"These products are expected to generate billions, even trillions, of dollars for the companies that are developing them," Chhabria wrote. "If using copyrighted works to train the models is as necessary as the companies say, they will figure out a way to compensate copyright holders for it."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Three ways authors can keep fighting AI training&lt;/h2&gt;
&lt;p&gt;This week's rulings suggest that the question of whether AI training is transformative has been largely settled.&lt;/p&gt;
&lt;p&gt;But as authors continue suing AI companies, with the latest lawsuit lobbed at Microsoft this week, Chhabria suggested that "generally the plaintiff’s only chance to defeat fair use will be to win decisively on" the fourth factor of a fair use analysis, where judges and juries weigh "the effect of the use upon the potential market for or value of the copyrighted work."&lt;/p&gt;
&lt;p&gt;Chhabria suggested that authors had at least three paths to fight AI training on the basis of market harms. First, they could claim that AI outputs "regurgitate their works." Second, they could "point to the market for licensing their works for AI training and contend that unauthorized copying for training harms that market (or precludes the development of that market)." And third, they could argue that AI outputs could "indirectly substitute" their works by generating "substantially similar" works.&lt;/p&gt;
&lt;p&gt;Because the first two arguments failed in the Meta case, Chhabria thinks "the third argument is far more promising" for authors intending to pick up the torch where the 13 authors in the current case have failed.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;An interesting wrinkle that may have stopped authors from invoking market dilution as a threat in the Meta case is that Chhabria noted that Meta had argued that "market dilution does not count under the fourth factor."&lt;/p&gt;
&lt;p&gt;But Chhabria clarified "that can’t be right."&lt;/p&gt;
&lt;p&gt;"Indirect substitution is still substitution," Chhabria wrote. "If someone bought a romance novel written by [a large language model (LLM)] instead of a romance novel written by a human author, the LLM-generated novel is substituting for the human-written one." Seemingly, the same would go for AI-generated non-fiction books, he suggested.&lt;/p&gt;
&lt;p&gt;So while "it’s true that, in many copyright cases, this concept of market dilution or indirect substitution is not particularly important," AI cases may change the copyright landscape because it "involves a technology that can generate literally millions of secondary works, with a miniscule [sic] fraction of the time and creativity used to create the original works it was trained on," Chhabria wrote.&lt;/p&gt;
&lt;p&gt;This is unprecedented, Chhabria suggested, as no other use "has anything near the potential to flood the market with competing works the way that LLM training does. And so the concept of market dilution becomes highly relevant... Courts can’t stick their heads in the sand to an obvious way that a new technology might severely harm the incentive to create, just because the issue has not come up before."&lt;/p&gt;
&lt;p&gt;In a way, Chhabria's ruling provides a roadmap for rights holders looking to advance lawsuits against AI companies in the midst of precedent-setting rulings.&lt;/p&gt;
&lt;p&gt;Unfortunately for book authors suing Meta who found a sympathetic judge in Chhabria—but only made a "fleeting reference" to indirect substitution in a single report in its filings ahead of yesterday's ruling—"courts can’t decide cases based on what they think will or should happen in other cases."&lt;/p&gt;
&lt;p&gt;If their allegations were just a little stronger, Chhabria suggested they could have even won on summary judgment, instead of Meta.&lt;/p&gt;
&lt;p&gt;"Indeed, it seems likely that market dilution will often cause plaintiffs to decisively win the fourth factor—and thus win the fair use question overall—in cases like this," Chhabria wrote.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/06/book-authors-made-the-wrong-arguments-in-meta-ai-training-case-judge-says/</guid><pubDate>Thu, 26 Jun 2025 17:45:41 +0000</pubDate></item><item><title>Google Photos merges classic search with AI to speed up results (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/google-photos-merges-classic-search-with-ai-to-speed-up-results/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After Google temporarily paused the rollout of its buggy AI-powered “Ask Photos” feature in Google Photos, the company announced that it has improved the feature’s ability to quickly return search results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI feature, first introduced at Google’s I/O developer conference last year, allows users to search across their collection of digital photos using natural language queries. Leveraging Google’s Gemini, Ask Photos taps into the AI’s ability to understand a photo’s content and its other metadata when responding to input. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, users complained the AI feature wasn’t reliable and was often slow to respond while the AI was “thinking.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Addressing these concerns, Google Photos product manager Jamie Aspinall wrote on X earlier in June that “Ask Photos isn’t where it needs to be, in terms of latency, quality and ux,” and noted the rollout would be paused for a couple of weeks while Google worked to bring back the “speed and recall of the original search.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022535" height="391" src="https://techcrunch.com/wp-content/uploads/2025/06/ask-photos-june-2025.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In a short blog post published on Thursday, Google says it’s bringing the best of Photos’ classic search feature into Ask Photos, particularly for simple searches like “beach” or “dogs.” This allows the search results to display more quickly, as classic search did before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI, in the meantime, will work in the background to find the most relevant photos and work to answer more complex queries. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if you search for a photo of a “white dog,” a series of initial search results immediately appear. After the AI finishes its analysis, its results will appear below, along with some introductory text that may identify your dog by name, if you’ve added it, and tell you when photos of the animal first appeared.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The interface still allows you to switch to classic search if you prefer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result of these changes, Google has now resumed the rollout of Ask Photos to more people across the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be eligible to use Ask Photos, you must be 18 or older, and your account language must be set to English. You must also enable Face Groups, the feature that labels the people and pets found in the Google Photos library.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After Google temporarily paused the rollout of its buggy AI-powered “Ask Photos” feature in Google Photos, the company announced that it has improved the feature’s ability to quickly return search results.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI feature, first introduced at Google’s I/O developer conference last year, allows users to search across their collection of digital photos using natural language queries. Leveraging Google’s Gemini, Ask Photos taps into the AI’s ability to understand a photo’s content and its other metadata when responding to input. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, users complained the AI feature wasn’t reliable and was often slow to respond while the AI was “thinking.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Addressing these concerns, Google Photos product manager Jamie Aspinall wrote on X earlier in June that “Ask Photos isn’t where it needs to be, in terms of latency, quality and ux,” and noted the rollout would be paused for a couple of weeks while Google worked to bring back the “speed and recall of the original search.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022535" height="391" src="https://techcrunch.com/wp-content/uploads/2025/06/ask-photos-june-2025.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In a short blog post published on Thursday, Google says it’s bringing the best of Photos’ classic search feature into Ask Photos, particularly for simple searches like “beach” or “dogs.” This allows the search results to display more quickly, as classic search did before.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI, in the meantime, will work in the background to find the most relevant photos and work to answer more complex queries. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if you search for a photo of a “white dog,” a series of initial search results immediately appear. After the AI finishes its analysis, its results will appear below, along with some introductory text that may identify your dog by name, if you’ve added it, and tell you when photos of the animal first appeared.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The interface still allows you to switch to classic search if you prefer. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result of these changes, Google has now resumed the rollout of Ask Photos to more people across the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To be eligible to use Ask Photos, you must be 18 or older, and your account language must be set to English. You must also enable Face Groups, the feature that labels the people and pets found in the Google Photos library.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/google-photos-merges-classic-search-with-ai-to-speed-up-results/</guid><pubDate>Thu, 26 Jun 2025 17:55:05 +0000</pubDate></item><item><title>In just 3 months, CoreWeave CEO, once a crypto-mining bro, becomes a deca-billionaire (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/in-just-3-months-coreweave-ceo-once-a-crypto-mining-bro-becomes-a-deca-billionaire/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CoreWeave co-founder and CEO Michael Intrator’s net worth has skyrocketed to about $10 billion in the three months since the AI firm went public, Bloomberg reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His company’s debut was both the biggest tech IPO so far of 2025 — raising $1.5 billion — and somewhat of a clunker: Its founders had reportedly hoped to raise a lot more — up to $4 billion — and had to skinny their ambitions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CoreWeave still feels a bit like both a success and a house of cards. It offers AI training and inference cloud services built upon a growing stockpile of Nvidia GPUs. One of its investors is Nvidia, which helps it obtain the precious, short-in-supply chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CoreWeave has both Microsoft and OpenAI as customers — the latter signed a deal to buy $12 billion worth of services and still has about $11 billion worth to buy. And Nvidia increased its stake after the IPO, the company disclosed.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="CoreWeave CEO Mike Intrator" class="wp-image-3022529" height="454" src="https://techcrunch.com/wp-content/uploads/2025/06/Mike-Intrator-Headshot-e1750958788389.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;CoreWeave CEO Mike Intrator.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CoreWeave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But CoreWeave borrows money against the GPUs to pay for them, and its IPO wasn’t big enough to get it out of that cycle. It’s got about $8.8 billion worth of debt as of March, it disclosed, with interest rates as high as 15%. Even though it brought in almost $1 billion in revenue in Q1 alone ($985 million), it recorded a net loss of about $315 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That has not scared away investors, who remain eager for ways to make money on AI. CoreWeave’s stock has soared almost 300% since its March IPO, raising Intrator’s net worth to above $10 billion, Bloomberg calculates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the wildest part of Intrator’s history, as well as that of his co-founders Brian Venturo and Brannin McBee, is that the whole thing started out as a make-money-quick, crypto mining enterprise when their previous company, a hedge fund, failed. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The business partners went from a closet full of GPUs to thousands of them in a New Jersey warehouse, to an AI training experiment with an open source LLM group, EleutherAI, Venturo previously told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, the company is servicing the biggest LLM players on the planet, reportedly seeking to buy its competitor Core Scientific, and the founders are billionaires. And, as we previously reported, it’s not all paper money. All three founders pocketed over $150 million apiece by cashing out of shares ahead of the IPO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CoreWeave remains a symbol of the AI industry in 2025: Massive, fast-growing revenue and investor enthusiasm built on an insatiable need for more resources.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CoreWeave declined additional comment.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;CoreWeave co-founder and CEO Michael Intrator’s net worth has skyrocketed to about $10 billion in the three months since the AI firm went public, Bloomberg reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His company’s debut was both the biggest tech IPO so far of 2025 — raising $1.5 billion — and somewhat of a clunker: Its founders had reportedly hoped to raise a lot more — up to $4 billion — and had to skinny their ambitions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CoreWeave still feels a bit like both a success and a house of cards. It offers AI training and inference cloud services built upon a growing stockpile of Nvidia GPUs. One of its investors is Nvidia, which helps it obtain the precious, short-in-supply chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CoreWeave has both Microsoft and OpenAI as customers — the latter signed a deal to buy $12 billion worth of services and still has about $11 billion worth to buy. And Nvidia increased its stake after the IPO, the company disclosed.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="CoreWeave CEO Mike Intrator" class="wp-image-3022529" height="454" src="https://techcrunch.com/wp-content/uploads/2025/06/Mike-Intrator-Headshot-e1750958788389.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;CoreWeave CEO Mike Intrator.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CoreWeave&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But CoreWeave borrows money against the GPUs to pay for them, and its IPO wasn’t big enough to get it out of that cycle. It’s got about $8.8 billion worth of debt as of March, it disclosed, with interest rates as high as 15%. Even though it brought in almost $1 billion in revenue in Q1 alone ($985 million), it recorded a net loss of about $315 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That has not scared away investors, who remain eager for ways to make money on AI. CoreWeave’s stock has soared almost 300% since its March IPO, raising Intrator’s net worth to above $10 billion, Bloomberg calculates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the wildest part of Intrator’s history, as well as that of his co-founders Brian Venturo and Brannin McBee, is that the whole thing started out as a make-money-quick, crypto mining enterprise when their previous company, a hedge fund, failed. &lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;The business partners went from a closet full of GPUs to thousands of them in a New Jersey warehouse, to an AI training experiment with an open source LLM group, EleutherAI, Venturo previously told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, the company is servicing the biggest LLM players on the planet, reportedly seeking to buy its competitor Core Scientific, and the founders are billionaires. And, as we previously reported, it’s not all paper money. All three founders pocketed over $150 million apiece by cashing out of shares ahead of the IPO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CoreWeave remains a symbol of the AI industry in 2025: Massive, fast-growing revenue and investor enthusiasm built on an insatiable need for more resources.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CoreWeave declined additional comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/in-just-3-months-coreweave-ceo-once-a-crypto-mining-bro-becomes-a-deca-billionaire/</guid><pubDate>Thu, 26 Jun 2025 18:12:18 +0000</pubDate></item><item><title>[NEW] Get paid faster: How Intuit’s new AI agents help businesses get funds up to 5 days faster and save 12 hours a month with autonomous workflows (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/get-paid-faster-how-intuits-new-ai-agents-help-businesses-get-paid-up-to-5-days-faster-and-save-up-to-12-hours-a-month-with-autonomous-workflows/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Intuit has been on a journey over the last several years with generative AI, incorporating the technology as part of its services at QuickBooks, Credit Karma,Turbotax and Mailchimp.&lt;/p&gt;



&lt;p&gt;Today the company is taking the next step with a series of AI agents that go beyond that to transform how small and mid-market businesses operate. These new agents work as a virtual team that automates workflows and provides real-time business insights. They include capabilities for payments, accounts and finance that will directly impact business operations. According to Intuit, customers save up to 12 hours per month and, on average, will get paid up to five days faster thanks to the new agents.&lt;/p&gt;



&lt;p&gt;“If you look at the trajectory of our AI experiences at Intuit in the early years, AI was built into the background, and with Intuit Assist, you saw a shift to provide information back to the customer,” Ashok Srivastava, chief AI and data officer at Intuit, told VentureBeat. “Now what you’re seeing is a complete redesign. The agents are actually doing work on behalf of the customer, with their permission.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-technical-architecture-from-starter-kit-to-production-agents"&gt;Technical architecture: From starter kit to production agents&lt;/h2&gt;



&lt;p&gt;Intuit has been working on the path from assistants to agentic AI for some time.&lt;/p&gt;



&lt;p&gt;In September 2024, the company detailed its plans to use AI to automate complex tasks. It’s an approach  built firmly on the company’s generative AI operating system (GenOS) platform, the foundation of its AI efforts.&lt;/p&gt;



&lt;p&gt;Earlier this month, Intuit announced a series of efforts that further extend its capabilities. The company has developed its own prompt optimization service that will optimize queries for any large language model (LLM). It has also developed what it calls an intelligent data cognition layer for enterprise data that can understand different data sources required for enterprise workflows.&lt;/p&gt;



&lt;p&gt;Going a step further, Intuit developed an agent starter kit that builds on the company’s technical foundation to enable agentic AI development.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-agent-portfolio-from-cash-flow-to-customer-management"&gt;The agent portfolio: From cash flow to customer management&lt;/h2&gt;



&lt;p&gt;With the technical foundation in place, including agent starter kits, Intuit has built out a series of new agents that help business owners get things done.&lt;/p&gt;



&lt;p&gt;Intuit’s agent suite demonstrates the technical sophistication required to move from predictive AI to autonomous workflow execution. Each agent coordinates prediction, natural language processing (NLP) and autonomous decision-making within complete business processes. They include:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Payments agent&lt;/strong&gt;: Autonomously optimizes cash flow by predicting late payments, generating invoices and executing follow-up sequences.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Accounting agent&lt;/strong&gt;: Represents Intuit’s evolution from rules-based systems to autonomous bookkeeping. The agent now autonomously handles transaction categorization, reconciliation and workflow completion, delivering cleaner and more accurate books.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Finance agent&lt;/strong&gt;: Automates strategic analysis traditionally requiring dedicated business intelligence (BI) tools and human analysts. Provides key performance indicator (KPI) analysis, scenario planning and forecasting based on how the company is doing against peer benchmarks while autonomously generating growth recommendations.&lt;/p&gt;



&lt;p&gt;Intuit is also building out customer hub agents that will help with customer acquisition tasks. Payroll processing as well as project management efforts are also part of the future release plans.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-beyond-conversational-ui-task-oriented-agent-design"&gt;Beyond conversational UI: Task-oriented agent design&lt;/h2&gt;



&lt;p&gt;The new agents mark an evolution in how AI is presented to users.&lt;/p&gt;



&lt;p&gt;Intuit’s interface redesign reveals important user experience principles for enterprise agent deployment. Rather than bolting AI capabilities onto existing software, the company fundamentally restructured the QuickBooks user experience for AI.&lt;/p&gt;



&lt;p&gt;“The user interface now is really oriented around the business tasks that need to be done,” Srivastava explained. “It allows for real time insights and recommendations to come to the user directly.”&lt;/p&gt;



&lt;p&gt;This task-centric approach contrasts with the chat-based interfaces dominating current enterprise AI tools. Instead of requiring users to learn prompting strategies or navigate conversational flows, the agents operate within existing business workflows. The system includes what Intuit calls a “business feed” that contextually surfaces agent actions and recommendations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-trust-and-verification-the-closed-loop-challenge"&gt;Trust and verification: The closed-loop challenge&lt;/h2&gt;



&lt;p&gt;One of the most technically significant aspects of Intuit’s implementation addresses a critical challenge in autonomous agent deployment: Verification and trust. Enterprise AI teams often struggle with the black box problem — how do you ensure AI agents are performing correctly when they operate autonomously?&lt;/p&gt;



&lt;p&gt;“In order to build trust with artificial intelligence systems, we need to provide proof points back to the customer that what they think is happening is actually happening,” Srivastava emphasized. “That closed loop is very, very important.”&lt;/p&gt;



&lt;p&gt;Intuit’s solution involves building verification capabilities directly into GenOS, allowing the system to provide evidence of agent actions and outcomes. For the payments agent, this means showing users that invoices were sent, tracking delivery and demonstrating the improvement in payment cycles that results from the agent’s actions.&lt;/p&gt;



&lt;p&gt;This verification approach offers a template for enterprise teams deploying autonomous agents in high-stakes business processes. Rather than asking users to trust AI outputs, the system provides auditable trails and measurable outcomes.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-this-means-for-enterprises-looking-to-get-into-agentic-ai"&gt;What this means for enterprises looking to get into agentic AI&lt;/h2&gt;



&lt;p&gt;Intuit’s evolution offers a concrete roadmap for enterprise teams planning autonomous AI implementations: &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Focus on workflow completion, not conversation: &lt;/strong&gt;Target specific business processes for end-to-end automation rather than building general-purpose chat interfaces.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Build agent orchestration infrastructure:&lt;/strong&gt; Invest in platforms that coordinate prediction, language processing and autonomous execution within unified workflows, not isolated AI tools.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Design verification systems upfront:&lt;/strong&gt; Include comprehensive audit trails, outcome tracking and user notifications as core capabilities rather than afterthoughts.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Map workflows before building technology:&lt;/strong&gt; Use customer advisory programs to define agent capabilities based on actual operational challenges.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Plan for interface redesign: &lt;/strong&gt;Optimize UX for agent-driven workflows rather than traditional software navigation patterns.&lt;/p&gt;



&lt;p&gt;“As large language models become commoditized, the experiences that are built upon them become much more important,” Srivastava said.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Intuit has been on a journey over the last several years with generative AI, incorporating the technology as part of its services at QuickBooks, Credit Karma,Turbotax and Mailchimp.&lt;/p&gt;



&lt;p&gt;Today the company is taking the next step with a series of AI agents that go beyond that to transform how small and mid-market businesses operate. These new agents work as a virtual team that automates workflows and provides real-time business insights. They include capabilities for payments, accounts and finance that will directly impact business operations. According to Intuit, customers save up to 12 hours per month and, on average, will get paid up to five days faster thanks to the new agents.&lt;/p&gt;



&lt;p&gt;“If you look at the trajectory of our AI experiences at Intuit in the early years, AI was built into the background, and with Intuit Assist, you saw a shift to provide information back to the customer,” Ashok Srivastava, chief AI and data officer at Intuit, told VentureBeat. “Now what you’re seeing is a complete redesign. The agents are actually doing work on behalf of the customer, with their permission.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-technical-architecture-from-starter-kit-to-production-agents"&gt;Technical architecture: From starter kit to production agents&lt;/h2&gt;



&lt;p&gt;Intuit has been working on the path from assistants to agentic AI for some time.&lt;/p&gt;



&lt;p&gt;In September 2024, the company detailed its plans to use AI to automate complex tasks. It’s an approach  built firmly on the company’s generative AI operating system (GenOS) platform, the foundation of its AI efforts.&lt;/p&gt;



&lt;p&gt;Earlier this month, Intuit announced a series of efforts that further extend its capabilities. The company has developed its own prompt optimization service that will optimize queries for any large language model (LLM). It has also developed what it calls an intelligent data cognition layer for enterprise data that can understand different data sources required for enterprise workflows.&lt;/p&gt;



&lt;p&gt;Going a step further, Intuit developed an agent starter kit that builds on the company’s technical foundation to enable agentic AI development.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-agent-portfolio-from-cash-flow-to-customer-management"&gt;The agent portfolio: From cash flow to customer management&lt;/h2&gt;



&lt;p&gt;With the technical foundation in place, including agent starter kits, Intuit has built out a series of new agents that help business owners get things done.&lt;/p&gt;



&lt;p&gt;Intuit’s agent suite demonstrates the technical sophistication required to move from predictive AI to autonomous workflow execution. Each agent coordinates prediction, natural language processing (NLP) and autonomous decision-making within complete business processes. They include:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Payments agent&lt;/strong&gt;: Autonomously optimizes cash flow by predicting late payments, generating invoices and executing follow-up sequences.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Accounting agent&lt;/strong&gt;: Represents Intuit’s evolution from rules-based systems to autonomous bookkeeping. The agent now autonomously handles transaction categorization, reconciliation and workflow completion, delivering cleaner and more accurate books.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Finance agent&lt;/strong&gt;: Automates strategic analysis traditionally requiring dedicated business intelligence (BI) tools and human analysts. Provides key performance indicator (KPI) analysis, scenario planning and forecasting based on how the company is doing against peer benchmarks while autonomously generating growth recommendations.&lt;/p&gt;



&lt;p&gt;Intuit is also building out customer hub agents that will help with customer acquisition tasks. Payroll processing as well as project management efforts are also part of the future release plans.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-beyond-conversational-ui-task-oriented-agent-design"&gt;Beyond conversational UI: Task-oriented agent design&lt;/h2&gt;



&lt;p&gt;The new agents mark an evolution in how AI is presented to users.&lt;/p&gt;



&lt;p&gt;Intuit’s interface redesign reveals important user experience principles for enterprise agent deployment. Rather than bolting AI capabilities onto existing software, the company fundamentally restructured the QuickBooks user experience for AI.&lt;/p&gt;



&lt;p&gt;“The user interface now is really oriented around the business tasks that need to be done,” Srivastava explained. “It allows for real time insights and recommendations to come to the user directly.”&lt;/p&gt;



&lt;p&gt;This task-centric approach contrasts with the chat-based interfaces dominating current enterprise AI tools. Instead of requiring users to learn prompting strategies or navigate conversational flows, the agents operate within existing business workflows. The system includes what Intuit calls a “business feed” that contextually surfaces agent actions and recommendations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-trust-and-verification-the-closed-loop-challenge"&gt;Trust and verification: The closed-loop challenge&lt;/h2&gt;



&lt;p&gt;One of the most technically significant aspects of Intuit’s implementation addresses a critical challenge in autonomous agent deployment: Verification and trust. Enterprise AI teams often struggle with the black box problem — how do you ensure AI agents are performing correctly when they operate autonomously?&lt;/p&gt;



&lt;p&gt;“In order to build trust with artificial intelligence systems, we need to provide proof points back to the customer that what they think is happening is actually happening,” Srivastava emphasized. “That closed loop is very, very important.”&lt;/p&gt;



&lt;p&gt;Intuit’s solution involves building verification capabilities directly into GenOS, allowing the system to provide evidence of agent actions and outcomes. For the payments agent, this means showing users that invoices were sent, tracking delivery and demonstrating the improvement in payment cycles that results from the agent’s actions.&lt;/p&gt;



&lt;p&gt;This verification approach offers a template for enterprise teams deploying autonomous agents in high-stakes business processes. Rather than asking users to trust AI outputs, the system provides auditable trails and measurable outcomes.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-this-means-for-enterprises-looking-to-get-into-agentic-ai"&gt;What this means for enterprises looking to get into agentic AI&lt;/h2&gt;



&lt;p&gt;Intuit’s evolution offers a concrete roadmap for enterprise teams planning autonomous AI implementations: &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Focus on workflow completion, not conversation: &lt;/strong&gt;Target specific business processes for end-to-end automation rather than building general-purpose chat interfaces.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Build agent orchestration infrastructure:&lt;/strong&gt; Invest in platforms that coordinate prediction, language processing and autonomous execution within unified workflows, not isolated AI tools.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Design verification systems upfront:&lt;/strong&gt; Include comprehensive audit trails, outcome tracking and user notifications as core capabilities rather than afterthoughts.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Map workflows before building technology:&lt;/strong&gt; Use customer advisory programs to define agent capabilities based on actual operational challenges.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Plan for interface redesign: &lt;/strong&gt;Optimize UX for agent-driven workflows rather than traditional software navigation patterns.&lt;/p&gt;



&lt;p&gt;“As large language models become commoditized, the experiences that are built upon them become much more important,” Srivastava said.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/get-paid-faster-how-intuits-new-ai-agents-help-businesses-get-paid-up-to-5-days-faster-and-save-up-to-12-hours-a-month-with-autonomous-workflows/</guid><pubDate>Thu, 26 Jun 2025 20:00:00 +0000</pubDate></item><item><title>[NEW] Lessons learned from agentic AI leaders reveal critical deployment strategies for enterprises (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/lessons-learned-from-agentic-ai-leaders-reveal-critical-deployment-strategies-for-enterprises/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Companies are rushing AI agents into production — and many of them will fail. But the reason has nothing to do with their AI models.&lt;/p&gt;



&lt;p&gt;On day two of VB Transform 2025, industry leaders shared hard-won lessons from deploying AI agents at scale. A panel moderated by Joanne Chen, general partner at Foundation Capital, included Shawn Malhotra, CTO at Rocket Companies, which uses agents across the home ownership journey from mortgage underwriting to customer chat; Shailesh Nalawadi, head of product at Sendbird, which builds agentic customer service experiences for companies across multiple verticals; and Thys Waanders, SVP of AI transformation at Cognigy, whose platform automates customer experiences for large enterprise contact centers.&lt;/p&gt;



&lt;p&gt;Their shared discovery: Companies that build evaluation and orchestration infrastructure first are successful, while those rushing to production with powerful models fail at scale.&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-the-roi-reality-beyond-simple-cost-cutting"&gt;The ROI reality: Beyond simple cost cutting&lt;/h2&gt;



&lt;p&gt;A key part of engineering AI agent for success is understanding the return on investment (ROI). Early AI agent deployments focused on cost reduction. While that remains a key component, enterprise leaders now report more complex ROI patterns that demand different technical architectures.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-cost-reduction-wins"&gt;Cost reduction wins &lt;/h3&gt;



&lt;p&gt;Malhotra shared the most dramatic cost example from Rocket Companies. “We had an engineer [who] in about two days of work was able to build a simple agent to handle a very niche problem called ‘transfer tax calculations’ in the mortgage underwriting part of the process. And that two days of effort saved us a million dollars a year in expense,” he said.&lt;/p&gt;



&lt;p&gt;For Cognigy, Waanders noted that cost per call is a key metric. He said that if AI agents are used to automate parts of those calls, it’s possible to reduce the average handling time per call.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-revenue-generation-methods"&gt;Revenue generation methods&lt;/h3&gt;



&lt;p&gt;Saving is one thing; making more revenue is another. Malhotra reported that his team has seen conversion improvements: As clients get the answers to their questions faster and have a good experience, they are converting at higher rates.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-proactive-revenue-opportunities"&gt;Proactive revenue opportunities&lt;/h3&gt;



&lt;p&gt;Nalawadi highlighted entirely new revenue capabilities through proactive outreach. His team enables proactive customer service, reaching out before customers even realize they have a problem.&lt;/p&gt;



&lt;p&gt;A food delivery example illustrates this perfectly. “They already know when an order is going to be late, and rather than waiting for the customer to get upset and call them, they realize that there was an opportunity to get ahead of it,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-ai-agents-break-in-production"&gt;Why AI agents break in production&lt;/h2&gt;



&lt;p&gt;While there are solid ROI opportunities for enterprises that deploy agentic AI, there are also some challenges in production deployments.&lt;/p&gt;



&lt;p&gt;Nalawadi identified the core technical failure: Companies build AI agents without evaluation infrastructure.&lt;/p&gt;



&lt;p&gt;“Before you even start building it, you should have an eval infrastructure in place,” Nalawadi said. “All of us used to be software engineers. No one deploys to production without running unit tests. And I think a very simplistic way of thinking about eval is that it’s the unit test for your AI agent system.”&lt;/p&gt;



&lt;p&gt;Traditional software testing approaches don’t work for AI agents. He noted that it’s just not possible to&amp;nbsp; predict every possible input or write comprehensive test cases for natural language interactions. Nalawadi’s team learned this through customer service deployments across retail, food delivery and financial services. Standard quality assurance approaches missed edge cases that emerged in production.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-testing-ai-the-new-quality-assurance-paradigm"&gt;AI testing AI: The new quality assurance paradigm&lt;/h2&gt;



&lt;p&gt;Given the complexity of AI testing, what should organizations do? Waanders solved the testing problem through simulation.&lt;/p&gt;



&lt;p&gt;“We have a feature that we’re releasing soon that is about simulating potential conversations,” Waanders explained. “So it’s essentially AI agents testing AI agents.”&lt;/p&gt;



&lt;p&gt;The testing isn’t just conversation quality testing, it’s behavioral analysis at scale. Can it help to understand how an agent responds to angry customers? How does it handle multiple languages? What happens when customers use slang?&lt;/p&gt;



&lt;p&gt;“The biggest challenge is you don’t know what you don’t know,” Waanders said. “How does it react to anything that anyone could come up with? You only find it out by simulating conversations, by really pushing it under thousands of different scenarios.”&lt;/p&gt;



&lt;p&gt;The approach tests demographic variations, emotional states and edge cases that human QA teams can’t cover comprehensively.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-coming-complexity-explosion"&gt;The coming complexity explosion&lt;/h2&gt;



&lt;p&gt;Current AI agents handle single tasks independently. Enterprise leaders need to prepare for a different reality: Hundreds of agents per organization learning from each other.&lt;/p&gt;



&lt;p&gt;The infrastructure implications are massive. When agents share data and collaborate, failure modes multiply exponentially. Traditional monitoring systems can’t track these interactions.&lt;/p&gt;



&lt;p&gt;Companies must architect for this complexity now. Retrofitting infrastructure for multi-agent systems costs significantly more than building it correctly from the start.&lt;/p&gt;



&lt;p&gt;“If you fast forward in what’s theoretically possible, there could be hundreds of them in an organization, and perhaps they are learning from each other,”Chen said. “The number of things that could happen just explodes. The complexity explodes.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Companies are rushing AI agents into production — and many of them will fail. But the reason has nothing to do with their AI models.&lt;/p&gt;



&lt;p&gt;On day two of VB Transform 2025, industry leaders shared hard-won lessons from deploying AI agents at scale. A panel moderated by Joanne Chen, general partner at Foundation Capital, included Shawn Malhotra, CTO at Rocket Companies, which uses agents across the home ownership journey from mortgage underwriting to customer chat; Shailesh Nalawadi, head of product at Sendbird, which builds agentic customer service experiences for companies across multiple verticals; and Thys Waanders, SVP of AI transformation at Cognigy, whose platform automates customer experiences for large enterprise contact centers.&lt;/p&gt;



&lt;p&gt;Their shared discovery: Companies that build evaluation and orchestration infrastructure first are successful, while those rushing to production with powerful models fail at scale.&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-the-roi-reality-beyond-simple-cost-cutting"&gt;The ROI reality: Beyond simple cost cutting&lt;/h2&gt;



&lt;p&gt;A key part of engineering AI agent for success is understanding the return on investment (ROI). Early AI agent deployments focused on cost reduction. While that remains a key component, enterprise leaders now report more complex ROI patterns that demand different technical architectures.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-cost-reduction-wins"&gt;Cost reduction wins &lt;/h3&gt;



&lt;p&gt;Malhotra shared the most dramatic cost example from Rocket Companies. “We had an engineer [who] in about two days of work was able to build a simple agent to handle a very niche problem called ‘transfer tax calculations’ in the mortgage underwriting part of the process. And that two days of effort saved us a million dollars a year in expense,” he said.&lt;/p&gt;



&lt;p&gt;For Cognigy, Waanders noted that cost per call is a key metric. He said that if AI agents are used to automate parts of those calls, it’s possible to reduce the average handling time per call.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-revenue-generation-methods"&gt;Revenue generation methods&lt;/h3&gt;



&lt;p&gt;Saving is one thing; making more revenue is another. Malhotra reported that his team has seen conversion improvements: As clients get the answers to their questions faster and have a good experience, they are converting at higher rates.&lt;/p&gt;



&lt;h3 class="wp-block-heading" id="h-proactive-revenue-opportunities"&gt;Proactive revenue opportunities&lt;/h3&gt;



&lt;p&gt;Nalawadi highlighted entirely new revenue capabilities through proactive outreach. His team enables proactive customer service, reaching out before customers even realize they have a problem.&lt;/p&gt;



&lt;p&gt;A food delivery example illustrates this perfectly. “They already know when an order is going to be late, and rather than waiting for the customer to get upset and call them, they realize that there was an opportunity to get ahead of it,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-ai-agents-break-in-production"&gt;Why AI agents break in production&lt;/h2&gt;



&lt;p&gt;While there are solid ROI opportunities for enterprises that deploy agentic AI, there are also some challenges in production deployments.&lt;/p&gt;



&lt;p&gt;Nalawadi identified the core technical failure: Companies build AI agents without evaluation infrastructure.&lt;/p&gt;



&lt;p&gt;“Before you even start building it, you should have an eval infrastructure in place,” Nalawadi said. “All of us used to be software engineers. No one deploys to production without running unit tests. And I think a very simplistic way of thinking about eval is that it’s the unit test for your AI agent system.”&lt;/p&gt;



&lt;p&gt;Traditional software testing approaches don’t work for AI agents. He noted that it’s just not possible to&amp;nbsp; predict every possible input or write comprehensive test cases for natural language interactions. Nalawadi’s team learned this through customer service deployments across retail, food delivery and financial services. Standard quality assurance approaches missed edge cases that emerged in production.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-ai-testing-ai-the-new-quality-assurance-paradigm"&gt;AI testing AI: The new quality assurance paradigm&lt;/h2&gt;



&lt;p&gt;Given the complexity of AI testing, what should organizations do? Waanders solved the testing problem through simulation.&lt;/p&gt;



&lt;p&gt;“We have a feature that we’re releasing soon that is about simulating potential conversations,” Waanders explained. “So it’s essentially AI agents testing AI agents.”&lt;/p&gt;



&lt;p&gt;The testing isn’t just conversation quality testing, it’s behavioral analysis at scale. Can it help to understand how an agent responds to angry customers? How does it handle multiple languages? What happens when customers use slang?&lt;/p&gt;



&lt;p&gt;“The biggest challenge is you don’t know what you don’t know,” Waanders said. “How does it react to anything that anyone could come up with? You only find it out by simulating conversations, by really pushing it under thousands of different scenarios.”&lt;/p&gt;



&lt;p&gt;The approach tests demographic variations, emotional states and edge cases that human QA teams can’t cover comprehensively.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-coming-complexity-explosion"&gt;The coming complexity explosion&lt;/h2&gt;



&lt;p&gt;Current AI agents handle single tasks independently. Enterprise leaders need to prepare for a different reality: Hundreds of agents per organization learning from each other.&lt;/p&gt;



&lt;p&gt;The infrastructure implications are massive. When agents share data and collaborate, failure modes multiply exponentially. Traditional monitoring systems can’t track these interactions.&lt;/p&gt;



&lt;p&gt;Companies must architect for this complexity now. Retrofitting infrastructure for multi-agent systems costs significantly more than building it correctly from the start.&lt;/p&gt;



&lt;p&gt;“If you fast forward in what’s theoretically possible, there could be hundreds of them in an organization, and perhaps they are learning from each other,”Chen said. “The number of things that could happen just explodes. The complexity explodes.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/lessons-learned-from-agentic-ai-leaders-reveal-critical-deployment-strategies-for-enterprises/</guid><pubDate>Thu, 26 Jun 2025 20:07:32 +0000</pubDate></item><item><title>[NEW] What enterprise leaders can learn from LinkedIn’s success with AI agents (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/what-enterprise-leaders-can-learn-from-linkedins-success-with-ai-agents/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AI agents are one of the hottest topics in tech right now — but how many enterprises have actually deployed and are actively using them?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;LinkedIn says it has with its LinkedIn hiring assistant. Going beyond its popular recommender systems and AI-powered search, the company’s AI agent sources and recruits job candidates through a simple natural language interface.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This is not a demo product,” Deepak Agarwal, chief AI officer at LinkedIn, said onstage this week at VB Transform. “This is live. It’s saving a lot of time for recruiters so that they can spend their time doing what they really love to do, which is nurturing candidates and hiring the best talent for the job.”&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-relying-on-a-multi-agent-system"&gt;Relying on a multi-agent system&lt;/h2&gt;



&lt;p&gt;LinkedIn is taking a multi-agent approach, using what Agarwal described as a collection of agents collaborating to get the job done. A supervisor agent orchestrates all the tasks among other agents, including intake and sourcing agents that are “good at one and only one job.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All communication occurs through the supervisor agent, which receives input from human users regarding role qualifications and other details. That agent then provides context to a sourcing agent, which culls through recruiter search stacks and sources candidates along with descriptions on why they might be a good fit for the job. That information is then returned to the supervisor agent, which begins actively interacting with the human user.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Then you can collaborate with it, right?” said Agarwal. “You can modify it. No longer do you have to talk to the platform in keywords. You can talk to the platform in natural language, and it’s going to answer you back, it’s going to have a conversation with you.”&lt;/p&gt;



&lt;p&gt;The agent can then refine qualifications and begin sourcing candidates, working for the hiring manager “both synchronously and asynchronously.” “It knows when to delegate the task to what agent, how to collect feedback and display to the user,” said Agarwal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He emphasized the importance of “human first” agents that keeps users always in control. The goal is to “deeply personalize” experiences with AI that adapts to preferences, learns from behaviors and continues to evolve and improve the more that users interact with it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It is about helping you accomplish your job in a better and more efficient way,” said Agarwal.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-linkedin-trains-its-multi-agent-system"&gt;How LinkedIn trains its multi-agent system&lt;/h2&gt;



&lt;p&gt;A multi-agent system requires a nuanced approach to training. LinkedIn’s team spends a lot of time on fine-tuning and making each downstream agent efficient for its specific task to improve reliability, explained Tejas Dharamsi, LinkedIn senior staff software engineer.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We fine-tune domain-adapted models and make them smaller, smarter and better for our task,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Whereas the supervisor agent is a special agent that requires high intelligence and adaptability. LinkedIn’s orchestrating agent can reason by using the company’s frontier large language models (LLMs). It also incorporates reinforcement learning and continuous user feedback.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Further, the agent has “experiential memory,” Agarwal explained, so it can retain information from recent dialog. It can preserve long-term memory about user preferences, as well, and discussions that could be important to recall later in the process.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Experiential memory, along with global context and intelligent routing, is the heart of the supervisor agent, and it keeps getting better and better through reinforcement learning,” he said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-iterating-throughout-the-agent-development-cycle"&gt;Iterating throughout the agent development cycle&lt;/h2&gt;



&lt;p&gt;Dharamsi emphasized that with AI agents, latency has to be on point. Before deploying into production, LinkedIn model builders need to understand how many queries per second (QPS) models can support and how many GPUs are required to power those. To determine this and other factors, the company runs a lot of inference and does evaluations, along with ntensive red teaming and risk assessment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We want these models to be faster, and sub-agents to do their tasks better, and they’re really fast at doing that,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Once deployed, from a UI perspective, Dharamsi described LinkedIn’s AI agent platform as “Lego blocks that an AI developer can plug and play.” The abstractions are designed so that users can pick and choose based on their product and what they want to build.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The focus here is how we standardize the development of agents at LinkedIn, so that in a consistent fashion you can build these again and again, try different hypotheses,” he explained. Engineers can instead focus on data, optimization and loss and reward function, rather than the underlying recipe or  infrastructure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;LinkedIn provides engineers with different algorithms based on RL, supervised fine tuning, pruning, quantization and distillation to use out of the box without worrying about GPU optimization or FLOPS, so they can begin running algorithms and training, said Dharamsi.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In building out its models, LinkedIn focuses on several factors, including reliability, trust, privacy, personalization and price, he said. Models must provide consistent outputs without getting derailed. Users also want to know that they can rely on agents to be consistent; that their work is secure; that past interactions are being used to personalize; and that costs don’t skyrocket.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We want to provide more value to the user, to do their job back better and do things that bring them happiness, like hiring,” said Dharamsi. “Recruiters want to focus on sourcing the right candidate, not spending time on searches.”&amp;nbsp;&lt;br /&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;AI agents are one of the hottest topics in tech right now — but how many enterprises have actually deployed and are actively using them?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;LinkedIn says it has with its LinkedIn hiring assistant. Going beyond its popular recommender systems and AI-powered search, the company’s AI agent sources and recruits job candidates through a simple natural language interface.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“This is not a demo product,” Deepak Agarwal, chief AI officer at LinkedIn, said onstage this week at VB Transform. “This is live. It’s saving a lot of time for recruiters so that they can spend their time doing what they really love to do, which is nurturing candidates and hiring the best talent for the job.”&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-relying-on-a-multi-agent-system"&gt;Relying on a multi-agent system&lt;/h2&gt;



&lt;p&gt;LinkedIn is taking a multi-agent approach, using what Agarwal described as a collection of agents collaborating to get the job done. A supervisor agent orchestrates all the tasks among other agents, including intake and sourcing agents that are “good at one and only one job.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All communication occurs through the supervisor agent, which receives input from human users regarding role qualifications and other details. That agent then provides context to a sourcing agent, which culls through recruiter search stacks and sources candidates along with descriptions on why they might be a good fit for the job. That information is then returned to the supervisor agent, which begins actively interacting with the human user.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Then you can collaborate with it, right?” said Agarwal. “You can modify it. No longer do you have to talk to the platform in keywords. You can talk to the platform in natural language, and it’s going to answer you back, it’s going to have a conversation with you.”&lt;/p&gt;



&lt;p&gt;The agent can then refine qualifications and begin sourcing candidates, working for the hiring manager “both synchronously and asynchronously.” “It knows when to delegate the task to what agent, how to collect feedback and display to the user,” said Agarwal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He emphasized the importance of “human first” agents that keeps users always in control. The goal is to “deeply personalize” experiences with AI that adapts to preferences, learns from behaviors and continues to evolve and improve the more that users interact with it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It is about helping you accomplish your job in a better and more efficient way,” said Agarwal.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-linkedin-trains-its-multi-agent-system"&gt;How LinkedIn trains its multi-agent system&lt;/h2&gt;



&lt;p&gt;A multi-agent system requires a nuanced approach to training. LinkedIn’s team spends a lot of time on fine-tuning and making each downstream agent efficient for its specific task to improve reliability, explained Tejas Dharamsi, LinkedIn senior staff software engineer.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We fine-tune domain-adapted models and make them smaller, smarter and better for our task,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Whereas the supervisor agent is a special agent that requires high intelligence and adaptability. LinkedIn’s orchestrating agent can reason by using the company’s frontier large language models (LLMs). It also incorporates reinforcement learning and continuous user feedback.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Further, the agent has “experiential memory,” Agarwal explained, so it can retain information from recent dialog. It can preserve long-term memory about user preferences, as well, and discussions that could be important to recall later in the process.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Experiential memory, along with global context and intelligent routing, is the heart of the supervisor agent, and it keeps getting better and better through reinforcement learning,” he said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-iterating-throughout-the-agent-development-cycle"&gt;Iterating throughout the agent development cycle&lt;/h2&gt;



&lt;p&gt;Dharamsi emphasized that with AI agents, latency has to be on point. Before deploying into production, LinkedIn model builders need to understand how many queries per second (QPS) models can support and how many GPUs are required to power those. To determine this and other factors, the company runs a lot of inference and does evaluations, along with ntensive red teaming and risk assessment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We want these models to be faster, and sub-agents to do their tasks better, and they’re really fast at doing that,” he said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Once deployed, from a UI perspective, Dharamsi described LinkedIn’s AI agent platform as “Lego blocks that an AI developer can plug and play.” The abstractions are designed so that users can pick and choose based on their product and what they want to build.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The focus here is how we standardize the development of agents at LinkedIn, so that in a consistent fashion you can build these again and again, try different hypotheses,” he explained. Engineers can instead focus on data, optimization and loss and reward function, rather than the underlying recipe or  infrastructure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;LinkedIn provides engineers with different algorithms based on RL, supervised fine tuning, pruning, quantization and distillation to use out of the box without worrying about GPU optimization or FLOPS, so they can begin running algorithms and training, said Dharamsi.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In building out its models, LinkedIn focuses on several factors, including reliability, trust, privacy, personalization and price, he said. Models must provide consistent outputs without getting derailed. Users also want to know that they can rely on agents to be consistent; that their work is secure; that past interactions are being used to personalize; and that costs don’t skyrocket.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“We want to provide more value to the user, to do their job back better and do things that bring them happiness, like hiring,” said Dharamsi. “Recruiters want to focus on sourcing the right candidate, not spending time on searches.”&amp;nbsp;&lt;br /&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/what-enterprise-leaders-can-learn-from-linkedins-success-with-ai-agents/</guid><pubDate>Thu, 26 Jun 2025 20:15:00 +0000</pubDate></item><item><title>[NEW] Anthropic summons the spirit of Flash games for the AI age (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/06/anthropic-summons-the-spirit-of-flash-games-for-the-ai-age/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI chatbot codes browser-based apps from plain English with classic web vibes.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Arcade video gaming lo fi aesthetic wallpaper - stock illustration" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/digital_arcade_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Arcade video gaming lo fi aesthetic wallpaper - stock illustration" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/digital_arcade_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Nataliia Nesterenko via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Anthropic announced a new feature that expands its Artifacts document management system into the basis of a personal AI app gallery resembling something from the Flash game era of the early 2000s—though these apps run on modern web code rather than Adobe's defunct plugin.&lt;/p&gt;
&lt;p&gt;Using plain English dialogue, users can build and share interactive applications directly within Claude's chatbot interface using a new API capability that lets artifacts interact with Claude itself. Claude is an AI assistant similar to ChatGPT.&lt;/p&gt;
&lt;p&gt;Claude has been capable of building web apps for some time, but Anthropic has put renewed focus on the feature that many have overlooked. "I'm amused that Anthropic turned 'we added a window.claude.complete() function to Artifacts' into what looks like a major new product launch," wrote independent AI researcher Simon Willison in a blog post, "but I can't say it's bad marketing for them to do that!"&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="983" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/sakura_serenity-1024x983.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="1070" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/claude_3d_app-1024x1070.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="1066" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/claude_platformer_game-1024x1066.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="973" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/join_dots-1024x973.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
    
    
      &lt;/div&gt;

&lt;p&gt;On the Anthropic gallery site, example artifact apps come organized into categories like "Learn something," "Life hacks," and "Be creative." Featured artifacts at launch include an interactive writing editor, a bedtime story generator, a molecule visualizer, and a 3D first-person "Anthropic office simulator" where you can walk around and interact with simple representations of real Anthropic employees.&lt;/p&gt;
&lt;p&gt;Users can examine the prompts and the chats that made those examples possible and even modify them for their own purposes. The beta Artifacts gallery feature is currently available to users on Claude's Free, Pro, and Max plans, and it's accessible through the Claude app's sidebar.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;How it works: AI as the coder&lt;/h2&gt;
&lt;p&gt;When users ask Claude to create an artifact, the AI model writes the HTML, CSS, and JavaScript codef, typically using React (a JavaScript library for web interfaces) for interactive components. Anthropic provided a demo video that showcases the process.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Anthropic's "Build a Claude-powered app" video.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The key addition in the latest update is a "window.claude.complete()" function that AI-generated apps can use to make their own requests back to Claude, enabling in-app conversational chatbot features like dynamic NPCs or tutors that users can talk to. Inspired by a demo created by Anthropic, we created a simple 2D simulation where the users move around an office and chat with some members of Ars Technica staff as if they were chatbot characters themselves.&lt;/p&gt;
&lt;p&gt;It's worth noting that the experience is entirely sandboxed for now. Unlike traditional web development, where developers manually integrate APIs and services, Claude creates self-contained applications that can only communicate with Claude itself—no external API calls ("yet," as Anthropic notes), no database connections, and no local browser storage.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2103208 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of the interface for building apps within Claude. You see a live preview of the app on the right side of the window." class="center large" height="757" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/making_an_app_2-1024x757.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of the interface for building apps within Claude. You see a live preview of the app on the right side of the window.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;All state management happens in-memory through React components or JavaScript variables that Claude implements, creating a simplified environment where users describe their ideas and Claude handles both the interface code and the AI logic. In a way, it's a form of vibe coding&amp;nbsp;but self-contained entirely within its own web environment.&lt;/p&gt;
&lt;h2&gt;Web portal throwback&lt;/h2&gt;
&lt;p&gt;Perhaps unintentionally, Anthropic's artifact gallery interface reminds us of classic Flash gaming portals, with each tile in the gallery showing a snapshot of the interactive experience waiting inside—similar to how Flash portals teased players with game screenshots back in the early 2000s.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For those who missed the Flash era, these in-browser apps feel somewhat like the vintage apps that defined a generation of Internet culture from the late 1990s through the 2000s when it first became possible to create complex in-browser experiences. Adobe Flash (originally Macromedia Flash) began as animation software for designers but quickly became the backbone of interactive web content when it gained its own programming language, ActionScript, in 2000.&lt;/p&gt;
&lt;p&gt;But unlike Flash games, where hosting costs fell on portal operators, Anthropic has crafted a system where users pay for their own fun through their existing Claude subscriptions. "When someone uses your Claude-powered app, they authenticate with their existing Claude account," Anthropic explained in its announcement. "Their API usage counts against their subscription, not yours. You pay nothing for their usage."&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;Play a Game&amp;quot; section." class="ars-gallery-image" height="1134" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/claude_gallery_1.jpg" width="1238" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the "Play a Game" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;learn something&amp;quot; section." class="ars-gallery-image" height="928" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/learn_something-1024x928.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the "learn something" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the ironically-named &amp;quot;touch grass&amp;quot; section." class="ars-gallery-image" height="693" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/touch_grass-1024x693.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the ironically named "touch grass" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the "learn something" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the ironically named "touch grass" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
          &lt;div class="ars-gallery-thumbnails grid grid-cols-4 gap-3 sm:grid-cols-6"&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;be creative&amp;quot; section." class="ars-gallery-image" height="603" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/be_creative-640x603.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;life hacks&amp;quot; section." class="ars-gallery-image" height="595" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/life_hacks-640x595.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
              &lt;/div&gt;
      &lt;/div&gt;

&lt;p&gt;Like the Flash games of yesteryear, any Claude-powered apps you build run in the browser and can be shared with anyone who has a Claude account. They're interactive experiences shared with a simple link, no installation required, created by other people for the sake of creating, except now they're powered by JavaScript instead of ActionScript.&lt;/p&gt;
&lt;p&gt;While you can share these apps with others individually, right now Anthropic's Artifact gallery only shows examples made by Anthropic and your own personal Artifacts. (If Anthropic expanded it into the future, it might end up feeling a bit like Scratch meets Newgrounds, but with AI doing the coding.) Ultimately, humans are still behind the wheel, describing what kinds of apps they want the AI model to build and guiding the process when it inevitably makes mistakes.&lt;/p&gt;
&lt;p&gt;Speaking of mistakes, don't expect perfect results at first. Usually, building an app with Claude is an interactive experience that requires some guidance to achieve your desired results. But with a little patience and a lot of tokens, you'll be vibe coding in no time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI chatbot codes browser-based apps from plain English with classic web vibes.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Arcade video gaming lo fi aesthetic wallpaper - stock illustration" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/digital_arcade_1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Arcade video gaming lo fi aesthetic wallpaper - stock illustration" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/digital_arcade_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Nataliia Nesterenko via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, Anthropic announced a new feature that expands its Artifacts document management system into the basis of a personal AI app gallery resembling something from the Flash game era of the early 2000s—though these apps run on modern web code rather than Adobe's defunct plugin.&lt;/p&gt;
&lt;p&gt;Using plain English dialogue, users can build and share interactive applications directly within Claude's chatbot interface using a new API capability that lets artifacts interact with Claude itself. Claude is an AI assistant similar to ChatGPT.&lt;/p&gt;
&lt;p&gt;Claude has been capable of building web apps for some time, but Anthropic has put renewed focus on the feature that many have overlooked. "I'm amused that Anthropic turned 'we added a window.claude.complete() function to Artifacts' into what looks like a major new product launch," wrote independent AI researcher Simon Willison in a blog post, "but I can't say it's bad marketing for them to do that!"&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="983" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/sakura_serenity-1024x983.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="1070" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/claude_3d_app-1024x1070.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="1066" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/claude_platformer_game-1024x1066.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A screenshot of an example AI-coded game within Claude Artifacts." class="ars-gallery-image" height="973" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/join_dots-1024x973.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A screenshot of an example AI-coded game within Claude Artifacts.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
    
    
      &lt;/div&gt;

&lt;p&gt;On the Anthropic gallery site, example artifact apps come organized into categories like "Learn something," "Life hacks," and "Be creative." Featured artifacts at launch include an interactive writing editor, a bedtime story generator, a molecule visualizer, and a 3D first-person "Anthropic office simulator" where you can walk around and interact with simple representations of real Anthropic employees.&lt;/p&gt;
&lt;p&gt;Users can examine the prompts and the chats that made those examples possible and even modify them for their own purposes. The beta Artifacts gallery feature is currently available to users on Claude's Free, Pro, and Max plans, and it's accessible through the Claude app's sidebar.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;How it works: AI as the coder&lt;/h2&gt;
&lt;p&gt;When users ask Claude to create an artifact, the AI model writes the HTML, CSS, and JavaScript codef, typically using React (a JavaScript library for web interfaces) for interactive components. Anthropic provided a demo video that showcases the process.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Anthropic's "Build a Claude-powered app" video.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;The key addition in the latest update is a "window.claude.complete()" function that AI-generated apps can use to make their own requests back to Claude, enabling in-app conversational chatbot features like dynamic NPCs or tutors that users can talk to. Inspired by a demo created by Anthropic, we created a simple 2D simulation where the users move around an office and chat with some members of Ars Technica staff as if they were chatbot characters themselves.&lt;/p&gt;
&lt;p&gt;It's worth noting that the experience is entirely sandboxed for now. Unlike traditional web development, where developers manually integrate APIs and services, Claude creates self-contained applications that can only communicate with Claude itself—no external API calls ("yet," as Anthropic notes), no database connections, and no local browser storage.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2103208 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A screenshot of the interface for building apps within Claude. You see a live preview of the app on the right side of the window." class="center large" height="757" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/making_an_app_2-1024x757.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A screenshot of the interface for building apps within Claude. You see a live preview of the app on the right side of the window.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards / Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;All state management happens in-memory through React components or JavaScript variables that Claude implements, creating a simplified environment where users describe their ideas and Claude handles both the interface code and the AI logic. In a way, it's a form of vibe coding&amp;nbsp;but self-contained entirely within its own web environment.&lt;/p&gt;
&lt;h2&gt;Web portal throwback&lt;/h2&gt;
&lt;p&gt;Perhaps unintentionally, Anthropic's artifact gallery interface reminds us of classic Flash gaming portals, with each tile in the gallery showing a snapshot of the interactive experience waiting inside—similar to how Flash portals teased players with game screenshots back in the early 2000s.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For those who missed the Flash era, these in-browser apps feel somewhat like the vintage apps that defined a generation of Internet culture from the late 1990s through the 2000s when it first became possible to create complex in-browser experiences. Adobe Flash (originally Macromedia Flash) began as animation software for designers but quickly became the backbone of interactive web content when it gained its own programming language, ActionScript, in 2000.&lt;/p&gt;
&lt;p&gt;But unlike Flash games, where hosting costs fell on portal operators, Anthropic has crafted a system where users pay for their own fun through their existing Claude subscriptions. "When someone uses your Claude-powered app, they authenticate with their existing Claude account," Anthropic explained in its announcement. "Their API usage counts against their subscription, not yours. You pay nothing for their usage."&lt;/p&gt;
&lt;div class="ars-lightbox align-fullwidth my-5"&gt;
    
          &lt;div class="ars-gallery-1-up my-5"&gt;
  &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;Play a Game&amp;quot; section." class="ars-gallery-image" height="1134" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/claude_gallery_1.jpg" width="1238" /&gt;
  
      
  &lt;/div&gt;
  &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the "Play a Game" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
      &lt;div class="flex flex-col flex-nowrap gap-5 py-5 md:flex-row"&gt;
  &lt;div class="class"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;learn something&amp;quot; section." class="ars-gallery-image" height="928" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/learn_something-1024x928.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the "learn something" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
  &lt;div class="flex-1"&gt;
    &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the ironically-named &amp;quot;touch grass&amp;quot; section." class="ars-gallery-image" height="693" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/touch_grass-1024x693.jpg" width="1024" /&gt;
  
      
  &lt;/div&gt;
    &lt;div class="md:hidden"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content "&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the ironically named "touch grass" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;div class="hidden md:block"&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content left"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the "learn something" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;div class="ars-gallery-caption"&gt;
    

    &lt;div class="ars-gallery-caption-content right"&gt;
              &lt;span class="ars-gallery-caption-text"&gt;A view of the Anthropic Artifacts gallery in the ironically named "touch grass" section.&lt;/span&gt;
                    &lt;span class="ars-gallery-caption-credit"&gt;
                      Benj Edwards / Anthropic
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/div&gt;
      
    
    
          &lt;div class="ars-gallery-thumbnails grid grid-cols-4 gap-3 sm:grid-cols-6"&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;be creative&amp;quot; section." class="ars-gallery-image" height="603" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/be_creative-640x603.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
                  &lt;div class="aspect-square"&gt;
            &lt;div class="ars-lightbox-item relative block h-full w-full overflow-hidden rounded-sm"&gt;
  
    &lt;img alt="A view of the Anthropic Artifacts gallery in the &amp;quot;life hacks&amp;quot; section." class="ars-gallery-image" height="595" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/life_hacks-640x595.jpg" width="640" /&gt;
  
      
  &lt;/div&gt;
          &lt;/div&gt;
              &lt;/div&gt;
      &lt;/div&gt;

&lt;p&gt;Like the Flash games of yesteryear, any Claude-powered apps you build run in the browser and can be shared with anyone who has a Claude account. They're interactive experiences shared with a simple link, no installation required, created by other people for the sake of creating, except now they're powered by JavaScript instead of ActionScript.&lt;/p&gt;
&lt;p&gt;While you can share these apps with others individually, right now Anthropic's Artifact gallery only shows examples made by Anthropic and your own personal Artifacts. (If Anthropic expanded it into the future, it might end up feeling a bit like Scratch meets Newgrounds, but with AI doing the coding.) Ultimately, humans are still behind the wheel, describing what kinds of apps they want the AI model to build and guiding the process when it inevitably makes mistakes.&lt;/p&gt;
&lt;p&gt;Speaking of mistakes, don't expect perfect results at first. Usually, building an app with Claude is an interactive experience that requires some guidance to achieve your desired results. But with a little patience and a lot of tokens, you'll be vibe coding in no time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/06/anthropic-summons-the-spirit-of-flash-games-for-the-ai-age/</guid><pubDate>Thu, 26 Jun 2025 20:33:20 +0000</pubDate></item><item><title>[NEW] Judge: Pirate libraries may have profited from Meta torrenting 80TB of books (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/06/judge-rejects-metas-claim-that-torrenting-is-irrelevant-in-ai-copyright-case/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Meta may defeat authors’ torrenting claim due to lack of evidence.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="366" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1383559939-640x366.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1383559939-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          VectorUp | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Now that Meta has largely beaten an AI training copyright lawsuit raised by 13 book authors—including comedian Sarah Silverman and Pulitzer Prize-winning author Junot Diaz—the only matter left to settle in that case is whether Meta violated copyright laws by torrenting books used to train Llama models.&lt;/p&gt;
&lt;p&gt;In an order that partly grants Meta's motion for summary judgment, judge Vince Chhabria confirmed that Meta and the authors would meet on July 11 to "discuss how to proceed on the plaintiffs’ separate claim that Meta unlawfully distributed their protected works during the torrenting process."&lt;/p&gt;
&lt;p&gt;Chhabria's order suggested that authors may struggle to win this part of the fight, too, due to a lack of evidence, as there has not yet been much discovery on this issue that was raised so late in the case. But he also warned that Meta was wrong to argue its torrenting was completely "irrelevant" to whether its copying of books was fair use.&lt;/p&gt;
&lt;p&gt;Chhabria suggested the torrenting—which may have comprised more than 80.6 terabytes of data from one shadow library, LibGen—is "at least potentially relevant" in "a few different ways."&lt;/p&gt;
&lt;p&gt;First, Chhabria noted that Meta deciding to pirate books from shadow libraries was "relevant to the issue of bad faith." That’s connected to the first factor of a fair use analysis, which weighs the character of the use.&lt;/p&gt;
&lt;p&gt;Authors had argued that Meta had sparked conversations with some publishers about licensing authors' works, but "after failing to acquire licenses," CEO Mark Zuckerberg "escalated" the issue, Chhabria explained. That prompted a decision to acquire books from pirate libraries instead, Chhabria wrote, with Meta admittedly using BitTorrent to seize data after abandoning its pursuit of licensing deals for the same books.&lt;/p&gt;
&lt;p&gt;However, that aspect of the trial may not matter much, since Chhabria noted that "the law is in flux about whether bad faith is relevant to fair use."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;It could certainly look worse for Meta if authors manage to present evidence supporting the second way that torrenting could be relevant to the case, Chhabaria suggested.&lt;/p&gt;
&lt;p&gt;"Meta downloading copyrighted material from shadow libraries" would also be relevant to the character of the use, "if it benefitted those who created the libraries and thus supported and perpetuated their unauthorized copying and distribution of copyrighted works," Chhabria wrote.&lt;/p&gt;
&lt;p&gt;Counting potential strikes against Meta, Chhabria pointed out that the "vast majority of cases" involving "this sort of peer-to-peer file-sharing" are found to "constitute copyright infringement." And it likely doesn't help Meta's case that "some of the libraries Meta used have themselves been found liable for infringement."&lt;/p&gt;
&lt;p&gt;However, Meta may overcome this argument, too, since book authors "have not submitted any evidence" that potentially shows how Meta's downloading may perhaps be "propping up" or financially benefiting pirate libraries.&lt;/p&gt;
&lt;p&gt;Finally, Chhabria noted that the "last issue relating to the character of Meta’s use" of books in regards to its torrenting is "the relationship between Meta’s downloading of the plaintiffs’ books and Meta’s use of the books to train Llama."&lt;/p&gt;
&lt;p&gt;Authors had tried to argue that these elements were distinct. But Chhabria said there's no separating the fact that Meta downloaded the books to serve the "highly transformative" purpose of training Llama.&lt;/p&gt;
&lt;p&gt;"Because Meta’s ultimate use of the plaintiffs’ books was transformative, so too was Meta’s downloading of those books," Chhabria wrote.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;AI training rulings may get more authors paid&lt;/h2&gt;
&lt;p&gt;Authors only learned of Meta's torrenting through discovery in the lawsuit, and because of that, Chhabria noted that "the record on Meta’s alleged distribution is incomplete."&lt;/p&gt;
&lt;p&gt;It's possible that authors may be able to show evidence that Meta "contributed to the BitTorrent network" by providing significant computing power that could've meaningfully assisted shadow libraries, Chhabria said in a footnote.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But Chhabria dinged authors for citing only an outdated Ars Technica article from 2010 that suggested that people only rarely used torrents to pirate books. (E-book piracy has significantly spiked since then, as TorrentFreak has documented in more recent reports that also note research showing that taking pirated books offline can benefit book sales.)&lt;/p&gt;
&lt;p&gt;More will be revealed as the Meta case advances next month, but Chhabria noted that one potential outcome, win or lose for authors, could be that publishers become incentivized to make it easier to license authors' works for AI training.&lt;/p&gt;
&lt;p&gt;"Publishers may not currently hold the subsidiary rights necessary to make group licensing possible," Chhabria wrote. "But it’s hard to believe that they won’t soon start negotiating those rights with their authors so that they can engage in large-scale negotiation and licensing" with large language model (LLM) developers—"assuming they haven’t already started to do so."&lt;/p&gt;
&lt;p&gt;"It seems especially likely that these licensing markets will arise if LLM developers’ only choices are to get licenses or forgo the use of copyrighted books as training data," Chhabria noted.&lt;/p&gt;
&lt;p&gt;That could be the outcome if other authors suing AI companies secure victories that Chhabria views as inevitable. They would need to show evidence that AI products dilute markets for their works, which the authors suing Meta failed to do.&lt;/p&gt;
&lt;p&gt;In his ruling granting Meta the win against authors' copyright infringement claims, Chhabria suggested that Meta won only because authors raised the "wrong arguments," suggesting Meta may be more inclined to renew licensing talks in the future if a stronger copyright fight is raised, despite winning this landmark copyright battle against a handful of authors this week.&lt;/p&gt;
&lt;p&gt;And if AI companies facing that potential reality "instead choose to use only public domain works as training data (instead of licensing copyrighted works), that would indicate that they don’t actually need the copyrighted works as badly as they say they do," Chhabria wrote. And if that's true, there's likely little excuse for torrenting of pirated books that authors otherwise had long considered an obvious example of copyright infringement.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Meta may defeat authors’ torrenting claim due to lack of evidence.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="366" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1383559939-640x366.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1383559939-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          VectorUp | iStock / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Now that Meta has largely beaten an AI training copyright lawsuit raised by 13 book authors—including comedian Sarah Silverman and Pulitzer Prize-winning author Junot Diaz—the only matter left to settle in that case is whether Meta violated copyright laws by torrenting books used to train Llama models.&lt;/p&gt;
&lt;p&gt;In an order that partly grants Meta's motion for summary judgment, judge Vince Chhabria confirmed that Meta and the authors would meet on July 11 to "discuss how to proceed on the plaintiffs’ separate claim that Meta unlawfully distributed their protected works during the torrenting process."&lt;/p&gt;
&lt;p&gt;Chhabria's order suggested that authors may struggle to win this part of the fight, too, due to a lack of evidence, as there has not yet been much discovery on this issue that was raised so late in the case. But he also warned that Meta was wrong to argue its torrenting was completely "irrelevant" to whether its copying of books was fair use.&lt;/p&gt;
&lt;p&gt;Chhabria suggested the torrenting—which may have comprised more than 80.6 terabytes of data from one shadow library, LibGen—is "at least potentially relevant" in "a few different ways."&lt;/p&gt;
&lt;p&gt;First, Chhabria noted that Meta deciding to pirate books from shadow libraries was "relevant to the issue of bad faith." That’s connected to the first factor of a fair use analysis, which weighs the character of the use.&lt;/p&gt;
&lt;p&gt;Authors had argued that Meta had sparked conversations with some publishers about licensing authors' works, but "after failing to acquire licenses," CEO Mark Zuckerberg "escalated" the issue, Chhabria explained. That prompted a decision to acquire books from pirate libraries instead, Chhabria wrote, with Meta admittedly using BitTorrent to seize data after abandoning its pursuit of licensing deals for the same books.&lt;/p&gt;
&lt;p&gt;However, that aspect of the trial may not matter much, since Chhabria noted that "the law is in flux about whether bad faith is relevant to fair use."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;It could certainly look worse for Meta if authors manage to present evidence supporting the second way that torrenting could be relevant to the case, Chhabaria suggested.&lt;/p&gt;
&lt;p&gt;"Meta downloading copyrighted material from shadow libraries" would also be relevant to the character of the use, "if it benefitted those who created the libraries and thus supported and perpetuated their unauthorized copying and distribution of copyrighted works," Chhabria wrote.&lt;/p&gt;
&lt;p&gt;Counting potential strikes against Meta, Chhabria pointed out that the "vast majority of cases" involving "this sort of peer-to-peer file-sharing" are found to "constitute copyright infringement." And it likely doesn't help Meta's case that "some of the libraries Meta used have themselves been found liable for infringement."&lt;/p&gt;
&lt;p&gt;However, Meta may overcome this argument, too, since book authors "have not submitted any evidence" that potentially shows how Meta's downloading may perhaps be "propping up" or financially benefiting pirate libraries.&lt;/p&gt;
&lt;p&gt;Finally, Chhabria noted that the "last issue relating to the character of Meta’s use" of books in regards to its torrenting is "the relationship between Meta’s downloading of the plaintiffs’ books and Meta’s use of the books to train Llama."&lt;/p&gt;
&lt;p&gt;Authors had tried to argue that these elements were distinct. But Chhabria said there's no separating the fact that Meta downloaded the books to serve the "highly transformative" purpose of training Llama.&lt;/p&gt;
&lt;p&gt;"Because Meta’s ultimate use of the plaintiffs’ books was transformative, so too was Meta’s downloading of those books," Chhabria wrote.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;AI training rulings may get more authors paid&lt;/h2&gt;
&lt;p&gt;Authors only learned of Meta's torrenting through discovery in the lawsuit, and because of that, Chhabria noted that "the record on Meta’s alleged distribution is incomplete."&lt;/p&gt;
&lt;p&gt;It's possible that authors may be able to show evidence that Meta "contributed to the BitTorrent network" by providing significant computing power that could've meaningfully assisted shadow libraries, Chhabria said in a footnote.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But Chhabria dinged authors for citing only an outdated Ars Technica article from 2010 that suggested that people only rarely used torrents to pirate books. (E-book piracy has significantly spiked since then, as TorrentFreak has documented in more recent reports that also note research showing that taking pirated books offline can benefit book sales.)&lt;/p&gt;
&lt;p&gt;More will be revealed as the Meta case advances next month, but Chhabria noted that one potential outcome, win or lose for authors, could be that publishers become incentivized to make it easier to license authors' works for AI training.&lt;/p&gt;
&lt;p&gt;"Publishers may not currently hold the subsidiary rights necessary to make group licensing possible," Chhabria wrote. "But it’s hard to believe that they won’t soon start negotiating those rights with their authors so that they can engage in large-scale negotiation and licensing" with large language model (LLM) developers—"assuming they haven’t already started to do so."&lt;/p&gt;
&lt;p&gt;"It seems especially likely that these licensing markets will arise if LLM developers’ only choices are to get licenses or forgo the use of copyrighted books as training data," Chhabria noted.&lt;/p&gt;
&lt;p&gt;That could be the outcome if other authors suing AI companies secure victories that Chhabria views as inevitable. They would need to show evidence that AI products dilute markets for their works, which the authors suing Meta failed to do.&lt;/p&gt;
&lt;p&gt;In his ruling granting Meta the win against authors' copyright infringement claims, Chhabria suggested that Meta won only because authors raised the "wrong arguments," suggesting Meta may be more inclined to renew licensing talks in the future if a stronger copyright fight is raised, despite winning this landmark copyright battle against a handful of authors this week.&lt;/p&gt;
&lt;p&gt;And if AI companies facing that potential reality "instead choose to use only public domain works as training data (instead of licensing copyrighted works), that would indicate that they don’t actually need the copyrighted works as badly as they say they do," Chhabria wrote. And if that's true, there's likely little excuse for torrenting of pirated books that authors otherwise had long considered an obvious example of copyright infringement.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/06/judge-rejects-metas-claim-that-torrenting-is-irrelevant-in-ai-copyright-case/</guid><pubDate>Thu, 26 Jun 2025 20:46:52 +0000</pubDate></item><item><title>[NEW] Why a16z VC believes that Cluely, the ‘cheat on everything’ startup, is the new blueprint for AI startups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/why-a16z-vc-believes-that-cluely-the-cheat-on-everything-startup-is-the-new-blueprint-for-ai-startups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/IMG-0036-from-100CANON.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Cluely, a startup claiming to be building a product that helps people “cheat” on everything, announced that it raised a $15 million Series A financing round from Andreessen Horowitz, some people on X criticized the VC firm for backing the controversial company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After all, Cluely isn’t just offering a product that may have questionable uses; the startup has also become famous for using what many people call rage-bait marketing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Cluely’s ability to grab attention is precisely what attracted a16z to the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even before meeting Cluely’s founder Roy Lee, Andreessen Horowitz’s partner Bryan Kim thought that startups need new marketing tactics in the AI era.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kim, like many investors, previously thought that building a superb “artisan” product with highly desired features was the key to a startup’s lasting success, he explained on the latest a16z podcast episode.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But shortly after the emergence of generative AI, he noticed that offering an exceptional product might not be enough.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you craft this thing and OpenAI or someone builds a new model to include that part in their product, you’re done,” Kim said. “So, it couldn’t become this highly thoughtful, slow-build product. It needed to be something where founders moved extremely quickly.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;That realization has led Kim to believe that speed, whether in marketing or product building, is paramount to creating a successful startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, Kim published a post explaining his theory of why, for consumer-facing AI startups, “momentum is the moat.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When Kim met Lee and saw that Cluely had been able to convert awareness into paying customers, he instantly knew that he had discovered a founder he had theorized about.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It’s been so hard to pierce through the noise of everything AI, especially in consumer, and to do that consistently is actually near impossible,” Kim said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How does Lee explain why his polarizing marketing approach has generated so much buzz?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Most people don’t know how to make viral content,” Lee said on the podcast. “Everyone on X is trying to [sound] like the most intellectual, thoughtful person. But this just lacks viral sense.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee, instead, had studied why some posts on TikTok and Instagram blow up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Algorithms promote the most controversial things,” he said. “I’m just literally applying the same principles of controversy on X and LinkedIn.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What many people don’t know, Lee said, is that Cluely barely had a functioning product when the startup launched in April with its slickly produced video of Lee using its hidden AI to lie to a woman about his age and knowledge of art while on a date.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite having some semblance of a product, the startup has yet to unveil the solution it has been hyping.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The internet is up in storm saying, ‘Where’s the product?’” Lee said. “We’re earlier than the latest YC batch of companies. Yet, we’re generating more views than every single one of them.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Lee is convinced that once the product launches, it will generate even more excitement than if Cluely introduced it without “marketing” the company for the last two months. (The official launch is set for Friday, June 27, he posted on X.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kim sees Cluely’s approach as a perfect embodiment of his “momentum as a moat” theory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since time is of the essence in AI, the a16z partner is certain that Cluely can figure out its product on the fly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What’s important is to try to build a plane as it’s falling down the cliff,” Kim said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ll all see soon if that plane soars or crashes.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/IMG-0036-from-100CANON.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Cluely, a startup claiming to be building a product that helps people “cheat” on everything, announced that it raised a $15 million Series A financing round from Andreessen Horowitz, some people on X criticized the VC firm for backing the controversial company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After all, Cluely isn’t just offering a product that may have questionable uses; the startup has also become famous for using what many people call rage-bait marketing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Cluely’s ability to grab attention is precisely what attracted a16z to the startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even before meeting Cluely’s founder Roy Lee, Andreessen Horowitz’s partner Bryan Kim thought that startups need new marketing tactics in the AI era.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kim, like many investors, previously thought that building a superb “artisan” product with highly desired features was the key to a startup’s lasting success, he explained on the latest a16z podcast episode.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But shortly after the emergence of generative AI, he noticed that offering an exceptional product might not be enough.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you craft this thing and OpenAI or someone builds a new model to include that part in their product, you’re done,” Kim said. “So, it couldn’t become this highly thoughtful, slow-build product. It needed to be something where founders moved extremely quickly.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;That realization has led Kim to believe that speed, whether in marketing or product building, is paramount to creating a successful startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier this month, Kim published a post explaining his theory of why, for consumer-facing AI startups, “momentum is the moat.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When Kim met Lee and saw that Cluely had been able to convert awareness into paying customers, he instantly knew that he had discovered a founder he had theorized about.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It’s been so hard to pierce through the noise of everything AI, especially in consumer, and to do that consistently is actually near impossible,” Kim said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How does Lee explain why his polarizing marketing approach has generated so much buzz?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Most people don’t know how to make viral content,” Lee said on the podcast. “Everyone on X is trying to [sound] like the most intellectual, thoughtful person. But this just lacks viral sense.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lee, instead, had studied why some posts on TikTok and Instagram blow up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Algorithms promote the most controversial things,” he said. “I’m just literally applying the same principles of controversy on X and LinkedIn.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What many people don’t know, Lee said, is that Cluely barely had a functioning product when the startup launched in April with its slickly produced video of Lee using its hidden AI to lie to a woman about his age and knowledge of art while on a date.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite having some semblance of a product, the startup has yet to unveil the solution it has been hyping.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The internet is up in storm saying, ‘Where’s the product?’” Lee said. “We’re earlier than the latest YC batch of companies. Yet, we’re generating more views than every single one of them.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Lee is convinced that once the product launches, it will generate even more excitement than if Cluely introduced it without “marketing” the company for the last two months. (The official launch is set for Friday, June 27, he posted on X.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kim sees Cluely’s approach as a perfect embodiment of his “momentum as a moat” theory.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since time is of the essence in AI, the a16z partner is certain that Cluely can figure out its product on the fly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What’s important is to try to build a plane as it’s falling down the cliff,” Kim said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ll all see soon if that plane soars or crashes.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/why-a16z-vc-believes-that-cluely-the-cheat-on-everything-startup-is-the-new-blueprint-for-ai-startups/</guid><pubDate>Thu, 26 Jun 2025 21:06:44 +0000</pubDate></item><item><title>[NEW] Google launches Doppl, a new app that lets you visualize how an outfit might look on you (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/26/google-launches-doppl-a-new-app-that-lets-you-visualize-how-an-outfit-might-look-on-you/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is launching a new experimental app called Doppl that uses AI to visualize how different outfits might look on you, the company announced on Thursday. The app is available on iOS and Android in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Doppl is designed to let you virtually try on outfits on a digital version of yourself. The app works by first getting you to upload a full-body photo of yourself. From there, you can use photos or screenshots of different outfits to virtually try them on. These images could be a photo of an outfit you see at a thrift store or on a friend, or even a screenshot of an outfit you see while scrolling through social media. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Once you select an outfit that you want to visualize, Doppl will create an image of a virtual version of yourself wearing the outfit. Doppl can also take these static images and convert them into AI-generated videos so you can get a better sense of how the outfit would look on you in real life. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can save your favorite looks and browse through all of your other virtual try-ons. Plus, you can also share your look with others.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022615" height="364" src="https://techcrunch.com/wp-content/uploads/2025/06/doppl-google.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant says the new app builds on Google Shopping’s recently launched capabilities that allow you to try on clothes virtually. By launching the functionality in a stand-alone app, Google is making the feature easier to access while allowing people to explore their style in a fun and interactive way, the company believes. It may also help Google collect more data on how apps like this could work, to aid its future efforts in the space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google has offered virtual try-on technology before, the earlier features focused on showing items on a diverse range of models’ bodies. With Doppl, the company is letting you try clothes on an animated version of your own body.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We hope Doppl helps you explore your style in new and exciting ways,” Google said in a blog post. “As a Google Labs experiment, Doppl is in its early days and it might not always get things right. Fit, appearance and clothing details may not always be accurate.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Given that the Doppl is an experimental launch, it’s unknown when or if Google plans to bring the app to additional regions. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is launching a new experimental app called Doppl that uses AI to visualize how different outfits might look on you, the company announced on Thursday. The app is available on iOS and Android in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Doppl is designed to let you virtually try on outfits on a digital version of yourself. The app works by first getting you to upload a full-body photo of yourself. From there, you can use photos or screenshots of different outfits to virtually try them on. These images could be a photo of an outfit you see at a thrift store or on a friend, or even a screenshot of an outfit you see while scrolling through social media. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Once you select an outfit that you want to visualize, Doppl will create an image of a virtual version of yourself wearing the outfit. Doppl can also take these static images and convert them into AI-generated videos so you can get a better sense of how the outfit would look on you in real life. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can save your favorite looks and browse through all of your other virtual try-ons. Plus, you can also share your look with others.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3022615" height="364" src="https://techcrunch.com/wp-content/uploads/2025/06/doppl-google.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The tech giant says the new app builds on Google Shopping’s recently launched capabilities that allow you to try on clothes virtually. By launching the functionality in a stand-alone app, Google is making the feature easier to access while allowing people to explore their style in a fun and interactive way, the company believes. It may also help Google collect more data on how apps like this could work, to aid its future efforts in the space.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google has offered virtual try-on technology before, the earlier features focused on showing items on a diverse range of models’ bodies. With Doppl, the company is letting you try clothes on an animated version of your own body.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We hope Doppl helps you explore your style in new and exciting ways,” Google said in a blog post. “As a Google Labs experiment, Doppl is in its early days and it might not always get things right. Fit, appearance and clothing details may not always be accurate.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Given that the Doppl is an experimental launch, it’s unknown when or if Google plans to bring the app to additional regions. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/26/google-launches-doppl-a-new-app-that-lets-you-visualize-how-an-outfit-might-look-on-you/</guid><pubDate>Thu, 26 Jun 2025 21:19:11 +0000</pubDate></item><item><title>[NEW] Walmart cracks enterprise AI at scale: Thousands of use cases, one framework (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/walmarts-enterprise-ai-blueprint-trust-engineering-at-scale/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Walmart continues to make strides in cracking the code on deploying agentic AI at enterprise scale. Their secret? Treating trust as an engineering requirement, not some compliance checkbox you tick at the end.&lt;/p&gt;



&lt;p&gt;During the “Trust in the Algorithm: How Walmart’s Agentic AI Is Redefining Consumer Confidence and Retail Leadership” session at VB Transform 2025, &lt;span&gt;Walmart’s&amp;nbsp;VP of Emerging Technology Desirée Gosby, explained how the retail giant&lt;/span&gt;&amp;nbsp;operationalizes thousands of AI use cases. One of the retailer’s primary objectives is to consistently maintain and strengthen customer confidence among its 255 million weekly shoppers.&lt;/p&gt;



&lt;p&gt;“We see this as a pretty big inflection point, very similar to the internet,” Gosby told industry analyst Susan Etlinger during Tuesday’s morning session. “It’s as profound in terms of how we’re actually going to operate, how we actually do work.”&lt;/p&gt;



&lt;p&gt;The session delivered valuable lessons learned from Walmart’s AI deployment experiences. Implicit throughout the discussion is the retail giant’s continual search for new ways to apply distributed systems architecture principles, thereby avoiding the creation of technical debt. &lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-four-stakeholder-framework-structures-ai-deployment"&gt;&lt;strong&gt;Four-stakeholder framework structures AI deployment&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s AI architecture rejects horizontal platforms for targeted stakeholder solutions. Each group receives purpose-built tools that address specific operational frictions.&lt;/p&gt;



&lt;p&gt;Customers engage Sparky for natural language shopping. Field associates get inventory and workflow optimization tools. Merchants access decision-support systems for category management. Sellers receive business integration capabilities. “And then, of course, we’ve got developers, and really, you know, giving them the superpowers and charging them up with, you know, the new agent of tools,” Gosby explained.&lt;/p&gt;



&lt;p&gt;“We have hundreds, if not thousands, of different use cases across the company that we’re bringing to life,” Gosby revealed. The scale demands architectural discipline that most enterprises lack.&lt;/p&gt;



&lt;p&gt;The segmentation acknowledges the fundamental need of each team in Walmart to have purpose-built tools for their specific jobs. Store associates managing inventory need different tools from merchants analyzing regional trends. Generic platforms fail because they ignore operational reality. Walmart’s specificity drives adoption through relevance, not mandate.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-trust-economics-are-driving-ai-adoption-at-walmart"&gt;&lt;strong&gt;Trust economics are driving AI adoption at Walmart&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart discovered that trust is built through value delivery, not just mandatory training programs that associates, at times, question the value of.&lt;/p&gt;



&lt;p&gt;Gosby’s example resonated as she explained her mother’s shopping evolution from weekly store visits to COVID-era deliveries, illustrating exactly how natural adoption works. Each step provided an immediate, tangible benefit. No friction, no forced change management, yet the progression happened faster than anyone could have predicted.&lt;/p&gt;



&lt;p&gt;“She’s been interacting with AI through that whole time,” Gosby explained. “The fact that she was able to go to the store and get what she wanted, it was on the shelf. AI was used to do that.”&lt;/p&gt;



&lt;p&gt;The benefits customers are getting from Walmart’s predictive commerce vision are further reflected in Gosby’s mother’s experiences. “Instead of having to go weekly, figure out what groceries you need to have delivered, what if it just showed up for you automatically?” That’s the essence of predictive commerce and how it delivers value at scale to every Walmart customer. &lt;/p&gt;



&lt;p&gt;“If you’re adding value to their lives, helping them remove friction, helping them save money and live better, which is part of our mission, then the trust comes,” Gosby stated. Associates follow the same pattern. When AI actually improves their work, saves them time and helps them excel, adoption happens naturally and trust is earned.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fashion-cycles-compress-from-months-to-weeks"&gt;&lt;strong&gt;Fashion cycles compress from months to weeks&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s Trend to Product system quantifies the operational value of AI. The platform synthesizes social media signals, customer behavior and regional patterns to slash product development from months to weeks.&lt;/p&gt;



&lt;p&gt;“Trend to Product has gotten us down from months to weeks to getting the right products to our customers,” Gosby revealed. The system creates products in response to real-time demand rather than historical data.&lt;/p&gt;



&lt;p&gt;The months-to-weeks compression transforms Walmart’s retail economics. Inventory turns accelerate. Markdown exposure shrinks. Capital efficiency multiplies. The company maintains price leadership while matching any competitor’s speed-to-market capabilities. Every high-velocity category can benefit from using AI to shrink time-to-market and deliver quantifiable gains. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-walmart-uses-mcp-protocol-to-create-a-scalable-agent-architecture"&gt;&lt;strong&gt;How Walmart uses MCP Protocol  to create a scalable agent architecture&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s approach to agent orchestration draws directly from its hard-won experience with distributed systems. The company uses Model Context Protocol (MCP) to standardize how agents interact with existing services.&lt;/p&gt;



&lt;p&gt;“We break down our domains and really looking at how do we wrap those things as MCP protocol, and then exposing those things that we can then start to orchestrate different agents,” Gosby explained. The strategy transforms existing infrastructure rather than replacing it.&lt;/p&gt;



&lt;p&gt;The architectural philosophy runs deeper than protocols. “The change that we’re seeing today is very similar to what we’ve seen when we went from monoliths to distributed systems. We don’t want to repeat those mistakes,” Gosby stated.&lt;/p&gt;



&lt;p&gt;Gosby outlined the execution requirements: “How do you decompose your domains? What MCP servers should you have? What sort of agent orchestration should you have?” At Walmart, these represent daily operational decisions, not theoretical exercises.&lt;/p&gt;&lt;p&gt;“We’re looking to take our existing infrastructure, break it down, and then recompose it into the agents that we want to be able to build,” Gosby explained. This standardization-first approach enables flexibility. Services built years ago now power agentic experiences through proper abstraction layers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-merchant-expertise-becomes-enterprise-intelligence"&gt;&lt;strong&gt;Merchant expertise becomes enterprise intelligence&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart leverages decades of employee knowledge, making it a core component of its growing AI capabilities. The company systematically captures category expertise from thousands of merchants, creating a competitive advantage no digital-first retailer can match.&lt;/p&gt;



&lt;p&gt;“We have thousands of merchants who are excellent at what they do. They are experts in the categories that they support,” Gosby explained. “We have a cheese merchant who knows exactly what wine goes or what cheese pairing, but that data isn’t necessarily captured in a structured way.”&lt;/p&gt;



&lt;p&gt;AI operationalizes this knowledge. “With the tools that we have, we can capture that expertise that they have and really bring that to bear for our customers,” Gosby said. The application is specific: “When they’re trying to figure out, hey, I need to throw the party, what kind of appetizers should I have?”&lt;/p&gt;



&lt;p&gt;The strategic advantage compounds. Decades of merchant expertise become accessible through natural language queries. Digital-first retailers lack this human knowledge foundation. Walmart’s 2.2 million associates represent proprietary intelligence that algorithms cannot synthesize independently.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-metrics-measure-autonomous-success"&gt;&lt;strong&gt;New metrics measure autonomous success&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart pioneers measurement systems designed for autonomous AI rather than human-driven processes. Traditional funnel metrics fail when agents handle end-to-end workflows.&lt;/p&gt;



&lt;p&gt;“In an agentic world, we’re starting to work through this, and it’s going to change,” Gosby said. “The metrics around conversion and things like that, those are not going to change, but we’re going to be looking at goal completion.”&lt;/p&gt;



&lt;p&gt;The shift reflects operational reality. “Did we actually achieve what is the ultimate goal that our associate, that our customers, are actually solving?” Gosby asked. The question reframes success measurement.&lt;/p&gt;



&lt;p&gt;“At the end of the day, it’s a measure of, are we delivering the benefit? Are we delivering the value that we expect, and then working back from there to basically figure out the right metrics?” Gosby explained. Problem resolution matters more than process compliance. How AI is helping customers achieve their goals is prioritized over conversion funnels.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-lessons-from-walmart-s-ai-transformation"&gt;&lt;strong&gt;Enterprise lessons from Walmart’s AI transformation&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s Transform 2025 session delivers actionable intelligence for enterprise AI deployment. The company’s operational approach provides a framework that has been validated at scale.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Apply architectural discipline from day one.&lt;/strong&gt; The shift from monolithic to distributed systems provided Walmart with the lessons it needed to learn to succeed with AI deployments. The key lesson learned is to build proper foundations before scaling and define a systematic approach that prevents expensive rework.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Match solutions to specific user needs.&lt;/strong&gt; One-size-fits-all AI fails every time. Store associates need different tools than merchants. Suppliers require different capabilities than developers. Walmart’s targeted approach drives adoption.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Build trust through proven value.&lt;/strong&gt; Start with clear wins that deliver measurable results. Walmart moved from basic inventory management to predictive commerce step by step. Each success earns insights and knowledge for the next.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Turn employee knowledge into enterprise assets.&lt;/strong&gt; Decades of specialist expertise exists within your organization. Walmart systematically captures merchant intelligence and operationalizes it across 255 million weekly transactions. This institutional knowledge creates competitive advantage no algorithm can replicate from scratch.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Measure what matters in autonomous systems.&lt;/strong&gt; Conversion rates miss the point when AI handles entire workflows. Focus on problem resolution and value delivery. Walmart’s metrics evolved to match operational reality.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Standardize before complexity hits.&lt;/strong&gt; Integration failures killed more projects than bad code ever did. Walmart’s protocol decisions prevent the chaos that derails most AI initiatives. Structure enables speed.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;“It always comes back to basics,” Gosby advised. “Take a step back and first understand what problems do you really need to solve for your customers, for our associates. Where is there friction? Where is there manual work that you can now start to think differently about?”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-walmart-s-blueprint-scales-beyond-retail"&gt;&lt;strong&gt;Walmart’s blueprint scales beyond retail&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart demonstrates how enterprise AI succeeds through engineering discipline and systematic deployment. The company processes millions of daily transactions across 4,700 stores by treating each stakeholder group as a distinct challenge requiring tailored, real-time solutions.&lt;/p&gt;



&lt;p&gt;“It’s permeating everything it is that we do,” Gosby explained. “But at the end of the day, the way that we look at it is we always start with our customers and our members and really understanding how it’s going to impact them.”&lt;/p&gt;



&lt;p&gt;Their framework applies across industries. Financial services organizations balancing customer needs with regulatory requirements, healthcare systems coordinating patient care across providers, manufacturers managing complex supply chains are all facing similar multi-stakeholder challenges. Walmart’s approach provides a tested methodology for addressing this complexity.&lt;/p&gt;



&lt;p&gt;“Our customers are trying to solve a problem for themselves. Same thing for our associates,” Gosby stated. “Did we actually solve that problem with these new tools?” This focus on problem resolution rather than technology deployment drives measurable outcomes. Walmart’s scale validates the approach for any enterprise ready to move beyond pilot programs.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Walmart continues to make strides in cracking the code on deploying agentic AI at enterprise scale. Their secret? Treating trust as an engineering requirement, not some compliance checkbox you tick at the end.&lt;/p&gt;



&lt;p&gt;During the “Trust in the Algorithm: How Walmart’s Agentic AI Is Redefining Consumer Confidence and Retail Leadership” session at VB Transform 2025, &lt;span&gt;Walmart’s&amp;nbsp;VP of Emerging Technology Desirée Gosby, explained how the retail giant&lt;/span&gt;&amp;nbsp;operationalizes thousands of AI use cases. One of the retailer’s primary objectives is to consistently maintain and strengthen customer confidence among its 255 million weekly shoppers.&lt;/p&gt;



&lt;p&gt;“We see this as a pretty big inflection point, very similar to the internet,” Gosby told industry analyst Susan Etlinger during Tuesday’s morning session. “It’s as profound in terms of how we’re actually going to operate, how we actually do work.”&lt;/p&gt;



&lt;p&gt;The session delivered valuable lessons learned from Walmart’s AI deployment experiences. Implicit throughout the discussion is the retail giant’s continual search for new ways to apply distributed systems architecture principles, thereby avoiding the creation of technical debt. &lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-four-stakeholder-framework-structures-ai-deployment"&gt;&lt;strong&gt;Four-stakeholder framework structures AI deployment&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s AI architecture rejects horizontal platforms for targeted stakeholder solutions. Each group receives purpose-built tools that address specific operational frictions.&lt;/p&gt;



&lt;p&gt;Customers engage Sparky for natural language shopping. Field associates get inventory and workflow optimization tools. Merchants access decision-support systems for category management. Sellers receive business integration capabilities. “And then, of course, we’ve got developers, and really, you know, giving them the superpowers and charging them up with, you know, the new agent of tools,” Gosby explained.&lt;/p&gt;



&lt;p&gt;“We have hundreds, if not thousands, of different use cases across the company that we’re bringing to life,” Gosby revealed. The scale demands architectural discipline that most enterprises lack.&lt;/p&gt;



&lt;p&gt;The segmentation acknowledges the fundamental need of each team in Walmart to have purpose-built tools for their specific jobs. Store associates managing inventory need different tools from merchants analyzing regional trends. Generic platforms fail because they ignore operational reality. Walmart’s specificity drives adoption through relevance, not mandate.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-trust-economics-are-driving-ai-adoption-at-walmart"&gt;&lt;strong&gt;Trust economics are driving AI adoption at Walmart&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart discovered that trust is built through value delivery, not just mandatory training programs that associates, at times, question the value of.&lt;/p&gt;



&lt;p&gt;Gosby’s example resonated as she explained her mother’s shopping evolution from weekly store visits to COVID-era deliveries, illustrating exactly how natural adoption works. Each step provided an immediate, tangible benefit. No friction, no forced change management, yet the progression happened faster than anyone could have predicted.&lt;/p&gt;



&lt;p&gt;“She’s been interacting with AI through that whole time,” Gosby explained. “The fact that she was able to go to the store and get what she wanted, it was on the shelf. AI was used to do that.”&lt;/p&gt;



&lt;p&gt;The benefits customers are getting from Walmart’s predictive commerce vision are further reflected in Gosby’s mother’s experiences. “Instead of having to go weekly, figure out what groceries you need to have delivered, what if it just showed up for you automatically?” That’s the essence of predictive commerce and how it delivers value at scale to every Walmart customer. &lt;/p&gt;



&lt;p&gt;“If you’re adding value to their lives, helping them remove friction, helping them save money and live better, which is part of our mission, then the trust comes,” Gosby stated. Associates follow the same pattern. When AI actually improves their work, saves them time and helps them excel, adoption happens naturally and trust is earned.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-fashion-cycles-compress-from-months-to-weeks"&gt;&lt;strong&gt;Fashion cycles compress from months to weeks&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s Trend to Product system quantifies the operational value of AI. The platform synthesizes social media signals, customer behavior and regional patterns to slash product development from months to weeks.&lt;/p&gt;



&lt;p&gt;“Trend to Product has gotten us down from months to weeks to getting the right products to our customers,” Gosby revealed. The system creates products in response to real-time demand rather than historical data.&lt;/p&gt;



&lt;p&gt;The months-to-weeks compression transforms Walmart’s retail economics. Inventory turns accelerate. Markdown exposure shrinks. Capital efficiency multiplies. The company maintains price leadership while matching any competitor’s speed-to-market capabilities. Every high-velocity category can benefit from using AI to shrink time-to-market and deliver quantifiable gains. &lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-walmart-uses-mcp-protocol-to-create-a-scalable-agent-architecture"&gt;&lt;strong&gt;How Walmart uses MCP Protocol  to create a scalable agent architecture&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s approach to agent orchestration draws directly from its hard-won experience with distributed systems. The company uses Model Context Protocol (MCP) to standardize how agents interact with existing services.&lt;/p&gt;



&lt;p&gt;“We break down our domains and really looking at how do we wrap those things as MCP protocol, and then exposing those things that we can then start to orchestrate different agents,” Gosby explained. The strategy transforms existing infrastructure rather than replacing it.&lt;/p&gt;



&lt;p&gt;The architectural philosophy runs deeper than protocols. “The change that we’re seeing today is very similar to what we’ve seen when we went from monoliths to distributed systems. We don’t want to repeat those mistakes,” Gosby stated.&lt;/p&gt;



&lt;p&gt;Gosby outlined the execution requirements: “How do you decompose your domains? What MCP servers should you have? What sort of agent orchestration should you have?” At Walmart, these represent daily operational decisions, not theoretical exercises.&lt;/p&gt;&lt;p&gt;“We’re looking to take our existing infrastructure, break it down, and then recompose it into the agents that we want to be able to build,” Gosby explained. This standardization-first approach enables flexibility. Services built years ago now power agentic experiences through proper abstraction layers.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-merchant-expertise-becomes-enterprise-intelligence"&gt;&lt;strong&gt;Merchant expertise becomes enterprise intelligence&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart leverages decades of employee knowledge, making it a core component of its growing AI capabilities. The company systematically captures category expertise from thousands of merchants, creating a competitive advantage no digital-first retailer can match.&lt;/p&gt;



&lt;p&gt;“We have thousands of merchants who are excellent at what they do. They are experts in the categories that they support,” Gosby explained. “We have a cheese merchant who knows exactly what wine goes or what cheese pairing, but that data isn’t necessarily captured in a structured way.”&lt;/p&gt;



&lt;p&gt;AI operationalizes this knowledge. “With the tools that we have, we can capture that expertise that they have and really bring that to bear for our customers,” Gosby said. The application is specific: “When they’re trying to figure out, hey, I need to throw the party, what kind of appetizers should I have?”&lt;/p&gt;



&lt;p&gt;The strategic advantage compounds. Decades of merchant expertise become accessible through natural language queries. Digital-first retailers lack this human knowledge foundation. Walmart’s 2.2 million associates represent proprietary intelligence that algorithms cannot synthesize independently.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-metrics-measure-autonomous-success"&gt;&lt;strong&gt;New metrics measure autonomous success&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart pioneers measurement systems designed for autonomous AI rather than human-driven processes. Traditional funnel metrics fail when agents handle end-to-end workflows.&lt;/p&gt;



&lt;p&gt;“In an agentic world, we’re starting to work through this, and it’s going to change,” Gosby said. “The metrics around conversion and things like that, those are not going to change, but we’re going to be looking at goal completion.”&lt;/p&gt;



&lt;p&gt;The shift reflects operational reality. “Did we actually achieve what is the ultimate goal that our associate, that our customers, are actually solving?” Gosby asked. The question reframes success measurement.&lt;/p&gt;



&lt;p&gt;“At the end of the day, it’s a measure of, are we delivering the benefit? Are we delivering the value that we expect, and then working back from there to basically figure out the right metrics?” Gosby explained. Problem resolution matters more than process compliance. How AI is helping customers achieve their goals is prioritized over conversion funnels.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-lessons-from-walmart-s-ai-transformation"&gt;&lt;strong&gt;Enterprise lessons from Walmart’s AI transformation&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart’s Transform 2025 session delivers actionable intelligence for enterprise AI deployment. The company’s operational approach provides a framework that has been validated at scale.&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Apply architectural discipline from day one.&lt;/strong&gt; The shift from monolithic to distributed systems provided Walmart with the lessons it needed to learn to succeed with AI deployments. The key lesson learned is to build proper foundations before scaling and define a systematic approach that prevents expensive rework.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Match solutions to specific user needs.&lt;/strong&gt; One-size-fits-all AI fails every time. Store associates need different tools than merchants. Suppliers require different capabilities than developers. Walmart’s targeted approach drives adoption.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Build trust through proven value.&lt;/strong&gt; Start with clear wins that deliver measurable results. Walmart moved from basic inventory management to predictive commerce step by step. Each success earns insights and knowledge for the next.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Turn employee knowledge into enterprise assets.&lt;/strong&gt; Decades of specialist expertise exists within your organization. Walmart systematically captures merchant intelligence and operationalizes it across 255 million weekly transactions. This institutional knowledge creates competitive advantage no algorithm can replicate from scratch.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Measure what matters in autonomous systems.&lt;/strong&gt; Conversion rates miss the point when AI handles entire workflows. Focus on problem resolution and value delivery. Walmart’s metrics evolved to match operational reality.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Standardize before complexity hits.&lt;/strong&gt; Integration failures killed more projects than bad code ever did. Walmart’s protocol decisions prevent the chaos that derails most AI initiatives. Structure enables speed.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;“It always comes back to basics,” Gosby advised. “Take a step back and first understand what problems do you really need to solve for your customers, for our associates. Where is there friction? Where is there manual work that you can now start to think differently about?”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-walmart-s-blueprint-scales-beyond-retail"&gt;&lt;strong&gt;Walmart’s blueprint scales beyond retail&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Walmart demonstrates how enterprise AI succeeds through engineering discipline and systematic deployment. The company processes millions of daily transactions across 4,700 stores by treating each stakeholder group as a distinct challenge requiring tailored, real-time solutions.&lt;/p&gt;



&lt;p&gt;“It’s permeating everything it is that we do,” Gosby explained. “But at the end of the day, the way that we look at it is we always start with our customers and our members and really understanding how it’s going to impact them.”&lt;/p&gt;



&lt;p&gt;Their framework applies across industries. Financial services organizations balancing customer needs with regulatory requirements, healthcare systems coordinating patient care across providers, manufacturers managing complex supply chains are all facing similar multi-stakeholder challenges. Walmart’s approach provides a tested methodology for addressing this complexity.&lt;/p&gt;



&lt;p&gt;“Our customers are trying to solve a problem for themselves. Same thing for our associates,” Gosby stated. “Did we actually solve that problem with these new tools?” This focus on problem resolution rather than technology deployment drives measurable outcomes. Walmart’s scale validates the approach for any enterprise ready to move beyond pilot programs.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/walmarts-enterprise-ai-blueprint-trust-engineering-at-scale/</guid><pubDate>Thu, 26 Jun 2025 21:54:19 +0000</pubDate></item><item><title>[NEW] The hidden scaling cliff that’s about to break your agent rollouts (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/the-hidden-scaling-cliff-thats-about-to-break-your-agent-rollouts/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Enterprises that want to build and scale agents also need to embrace another reality: agents aren’t built like other software.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;Agents are “categorically different” in how they’re built, how they operate, and how they’re improved, according to&amp;nbsp;Writer&amp;nbsp;CEO and co-founder May Habib.&lt;/span&gt; This means ditching the traditional software development life cycle when dealing with adaptive systems.&lt;/p&gt;



&lt;p&gt;“Agents don’t reliably follow rules,” Habib said on Wednesday while on stage at VB Transform. “They are outcome-driven. They interpret. They adapt. And the behavior really only emerges in real-world environments.”&lt;/p&gt;



&lt;p&gt;Knowing what works —&amp;nbsp;and what doesn’t work — comes from Habib’s experience helping hundreds of enterprise clients build and scale enterprise-grade agents. According to Habib, more than 350 of the Fortune 1000 are Writer customers, and more than half of the Fortune 500 will be scaling agents with Writer by the end of 2025.&lt;/p&gt;



&lt;p&gt;Using non-deterministic tech to produce powerful outputs can even be “really nightmarish,” Habib said — especially when trying to scale agents systemically. Even if enterprise teams can spin up agents without product managers and designers, Habib thinks a “PM mindset” is still needed for collaborating, building, iterating and maintaining agents.&lt;/p&gt;



&lt;p&gt;“Unfortunately or fortunately, depending on your perspective, IT is going to be left holding the bag if they don’t lead their business counterparts into that new way of building.”&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-why-goal-based-agents-is-the-right-approach-nbsp"&gt;&lt;strong&gt;Why goal-based agents is the right approach&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One of the shifts in thinking includes understanding the outcome-based nature of agents. For example, she said that many customers request agents to assist their legal teams in reviewing or redlining contracts. But that’s too open-ended. Instead, a goal-oriented approach means designing an agent to reduce the time spent reviewing and redlining contracts.&lt;/p&gt;



&lt;p&gt;“In the traditional software development life cycle, you are designing for a deterministic set of very predictable steps,” Habib said. “It’s input in, input out in a more deterministic way. But with agents, you’re seeking to shape agentic behavior. So you are seeking less of a controlled flow and much more to give context and guide decision-making by the agent.”&lt;/p&gt;



&lt;p&gt;Another difference is building a blueprint for agents that instructs them with business logic, rather than providing them with workflows to follow. This includes designing reasoning loops and collaborating with subject experts to map processes that promote desired behaviors.&lt;/p&gt;



&lt;p&gt;While there’s a lot of talk about scaling agents, Writer is still helping most clients with building them one at a time. That’s because it’s important first to answer questions about who owns and audits the agent, who makes sure it stays relevant and still checks if it’s still producing desired outcomes.&lt;/p&gt;



&lt;p&gt;“There is a scaling cliff that folks get to very, very quickly without a new approach to building and scaling agents,” Habib said. “There is a cliff that folks are going to get to when their organization’s ability to manage agents responsibly really outstrips the pace of development happening department by department.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-qa-for-agents-vs-software"&gt;&lt;strong&gt;QA for agents vs software&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Quality assurance is also different for agents. Instead of an objective checklist, agentic evaluation includes accounting for non-binary behavior and assessing how agents act in real-world situations. That’s because failure isn’t always obvious — and not as black and white as checking if something broke. Instead, Habib said it’s better to check if an agent behaved well, asking if fail-safes worked, evaluating outcomes and intent: “The goal here isn’t perfection It is behavioral confidence, because there is a lot of subjectivity in this here.”&lt;/p&gt;



&lt;p&gt;Businesses that don’t understand the importance of iteration end up playing “a constant game of tennis that just wears down each side until they don’t want to play anymore,” Habib said. It’s also important for teams to be okay with agents being less than perfect and more about “launching them safely and running fast and iterating over and over and over.”&lt;/p&gt;



&lt;p&gt;Despite the challenges, there are examples of AI agents already helping bring in new revenue for enterprise businesses. For example, Habib mentioned a major bank that collaborated with Writer to develop an agent-based system, resulting in a new upsell pipeline worth $600 million by onboarding new customers into multiple product lines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-version-controls-for-ai-agents"&gt;&lt;strong&gt;New version controls for AI agents&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Agentic maintenance is also different. Traditional software maintenance involves checking the code when something breaks, but Habib said AI agents require a new kind of version control for everything that can shape behavior. It also requires proper governance and ensuring that agents remain useful over time, rather than incurring unnecessary costs.&lt;/p&gt;



&lt;p&gt;Because models don’t map cleanly to AI agents, Habib said maintenance includes checking prompts, model settings, tool schemas and memory configuration. It also means fully tracing executions across inputs, outputs, reasoning steps, tool calls and human interactions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You can update a [large language model] LLM prompt and watch the agent behave completely differently even though nothing in the git history actually changed,” Habib said. “The model links shift, retrieval indexes get updated, tool APIs evolve and suddenly the same prompt does not behave as expected…It can feel like we are debugging ghosts.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Enterprises that want to build and scale agents also need to embrace another reality: agents aren’t built like other software.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;span&gt;Agents are “categorically different” in how they’re built, how they operate, and how they’re improved, according to&amp;nbsp;Writer&amp;nbsp;CEO and co-founder May Habib.&lt;/span&gt; This means ditching the traditional software development life cycle when dealing with adaptive systems.&lt;/p&gt;



&lt;p&gt;“Agents don’t reliably follow rules,” Habib said on Wednesday while on stage at VB Transform. “They are outcome-driven. They interpret. They adapt. And the behavior really only emerges in real-world environments.”&lt;/p&gt;



&lt;p&gt;Knowing what works —&amp;nbsp;and what doesn’t work — comes from Habib’s experience helping hundreds of enterprise clients build and scale enterprise-grade agents. According to Habib, more than 350 of the Fortune 1000 are Writer customers, and more than half of the Fortune 500 will be scaling agents with Writer by the end of 2025.&lt;/p&gt;



&lt;p&gt;Using non-deterministic tech to produce powerful outputs can even be “really nightmarish,” Habib said — especially when trying to scale agents systemically. Even if enterprise teams can spin up agents without product managers and designers, Habib thinks a “PM mindset” is still needed for collaborating, building, iterating and maintaining agents.&lt;/p&gt;



&lt;p&gt;“Unfortunately or fortunately, depending on your perspective, IT is going to be left holding the bag if they don’t lead their business counterparts into that new way of building.”&lt;/p&gt;


&lt;strong&gt;&amp;gt;&amp;gt;See all our Transform 2025 coverage here&amp;lt;&amp;lt;&lt;/strong&gt;


&lt;h2 class="wp-block-heading" id="h-why-goal-based-agents-is-the-right-approach-nbsp"&gt;&lt;strong&gt;Why goal-based agents is the right approach&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One of the shifts in thinking includes understanding the outcome-based nature of agents. For example, she said that many customers request agents to assist their legal teams in reviewing or redlining contracts. But that’s too open-ended. Instead, a goal-oriented approach means designing an agent to reduce the time spent reviewing and redlining contracts.&lt;/p&gt;



&lt;p&gt;“In the traditional software development life cycle, you are designing for a deterministic set of very predictable steps,” Habib said. “It’s input in, input out in a more deterministic way. But with agents, you’re seeking to shape agentic behavior. So you are seeking less of a controlled flow and much more to give context and guide decision-making by the agent.”&lt;/p&gt;



&lt;p&gt;Another difference is building a blueprint for agents that instructs them with business logic, rather than providing them with workflows to follow. This includes designing reasoning loops and collaborating with subject experts to map processes that promote desired behaviors.&lt;/p&gt;



&lt;p&gt;While there’s a lot of talk about scaling agents, Writer is still helping most clients with building them one at a time. That’s because it’s important first to answer questions about who owns and audits the agent, who makes sure it stays relevant and still checks if it’s still producing desired outcomes.&lt;/p&gt;



&lt;p&gt;“There is a scaling cliff that folks get to very, very quickly without a new approach to building and scaling agents,” Habib said. “There is a cliff that folks are going to get to when their organization’s ability to manage agents responsibly really outstrips the pace of development happening department by department.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-qa-for-agents-vs-software"&gt;&lt;strong&gt;QA for agents vs software&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Quality assurance is also different for agents. Instead of an objective checklist, agentic evaluation includes accounting for non-binary behavior and assessing how agents act in real-world situations. That’s because failure isn’t always obvious — and not as black and white as checking if something broke. Instead, Habib said it’s better to check if an agent behaved well, asking if fail-safes worked, evaluating outcomes and intent: “The goal here isn’t perfection It is behavioral confidence, because there is a lot of subjectivity in this here.”&lt;/p&gt;



&lt;p&gt;Businesses that don’t understand the importance of iteration end up playing “a constant game of tennis that just wears down each side until they don’t want to play anymore,” Habib said. It’s also important for teams to be okay with agents being less than perfect and more about “launching them safely and running fast and iterating over and over and over.”&lt;/p&gt;



&lt;p&gt;Despite the challenges, there are examples of AI agents already helping bring in new revenue for enterprise businesses. For example, Habib mentioned a major bank that collaborated with Writer to develop an agent-based system, resulting in a new upsell pipeline worth $600 million by onboarding new customers into multiple product lines.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-new-version-controls-for-ai-agents"&gt;&lt;strong&gt;New version controls for AI agents&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Agentic maintenance is also different. Traditional software maintenance involves checking the code when something breaks, but Habib said AI agents require a new kind of version control for everything that can shape behavior. It also requires proper governance and ensuring that agents remain useful over time, rather than incurring unnecessary costs.&lt;/p&gt;



&lt;p&gt;Because models don’t map cleanly to AI agents, Habib said maintenance includes checking prompts, model settings, tool schemas and memory configuration. It also means fully tracing executions across inputs, outputs, reasoning steps, tool calls and human interactions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“You can update a [large language model] LLM prompt and watch the agent behave completely differently even though nothing in the git history actually changed,” Habib said. “The model links shift, retrieval indexes get updated, tool APIs evolve and suddenly the same prompt does not behave as expected…It can feel like we are debugging ghosts.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-hidden-scaling-cliff-thats-about-to-break-your-agent-rollouts/</guid><pubDate>Thu, 26 Jun 2025 23:33:40 +0000</pubDate></item></channel></rss>