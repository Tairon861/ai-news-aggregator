<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 14 Oct 2025 06:31:41 +0000</lastBuildDate><item><title>To shield kids, California hikes fake nude fines to $250K max (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/10/to-shield-kids-california-hikes-fake-nude-fines-to-250k-max/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        California cracks down on AI as child safety concerns grow.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kilito Chan | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;California is cracking down on AI technology deemed too harmful for kids, attacking two increasingly notorious child safety fronts: companion bots and deepfake pornography.&lt;/p&gt;
&lt;p&gt;On Monday, Governor Gavin Newsom signed the first-ever US law regulating companion bots after several teen suicides sparked lawsuits.&lt;/p&gt;
&lt;p&gt;Moving forward, California will require any companion bot platforms—including ChatGPT, Grok, Character.AI, and the like—to create and make public "protocols to identify and address users’ suicidal ideation or expressions of self-harm."&lt;/p&gt;
&lt;p&gt;They must also share "statistics regarding how often they provided users with crisis center prevention notifications to the Department of Public Health," the governor's office said. Those stats will also be posted on the platforms' websites, potentially helping lawmakers and parents track any disturbing trends.&lt;/p&gt;
&lt;p&gt;Further, companion bots will be banned from claiming that they're therapists, and platforms must take extra steps to ensure child safety, including providing kids with break reminders and preventing kids from viewing sexually explicit images.&lt;/p&gt;
&lt;p&gt;Additionally, Newsom strengthened the state's penalties for those who create deepfake pornography, which could help shield young people, who are increasingly targeted with fake nudes, from cyber bullying.&lt;/p&gt;
&lt;p&gt;Now any victims, including minors, can seek up to $250,000 in damages per deepfake from any third parties who knowingly distribute nonconsensual sexually explicit material created using AI tools. Previously, the state allowed victims to recover "statutory damages of not less than $1,500 but not more than $30,000, or $150,000 for a malicious violation."&lt;/p&gt;
&lt;p&gt;Both laws take effect January 1, 2026.&lt;/p&gt;
&lt;h2&gt;American families “are in a battle” with AI&lt;/h2&gt;
&lt;p&gt;The companion bot law's sponsor, Democratic Senator Steve Padilla, said in a press release celebrating the signing that the California law demonstrates how to "put real protections into place" and said it "will become the bedrock for further regulation as this technology develops."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Padilla's law was introduced back in January, but Techcrunch noted that it gained momentum following the death of 16-year-old Adam Raine, who died after ChatGPT allegedly became his "suicide coach," his parents have alleged. California lawmakers were also disturbed by a lax Meta policy that had to be reversed after previously allowing chatbots to be creepy to kids, Padilla noted.&lt;/p&gt;
&lt;p&gt;In lawsuits, parents have alleged that companion bots engage young users in sexualized chats in attempts to groom kids, as well as encourage isolation, self-harm, and violence.&lt;/p&gt;
&lt;p&gt;Megan Garcia, the first mother to publicly link her son's suicide to a companion bot, set off alarm bells across the US last year. She echoed Padilla's praise in his press release, saying, "finally, there is a law that requires companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;"American families, like mine, are in a battle for the online safety of our children," Garcia said.&lt;/p&gt;
&lt;p&gt;Meanwhile, the deepfake pornography law, which protects all victims of all ages, was introduced after the federal government proposed a 10-year moratorium on state AI laws. Opposing the moratorium, a bipartisan coalition of California lawmakers defended the state's AI initiatives, expressing particular concerns about both "AI-generated deepfake nude images of minors circulating in schools" and "companion chatbots developing inappropriate relationships with children."&lt;/p&gt;
&lt;p&gt;On Monday, Newsom promised that California would continue pushing back on AI products that could endanger kids.&lt;/p&gt;
&lt;p&gt;"We’ve seen some truly horrific and tragic examples of young people harmed by unregulated tech, and we won’t stand by while companies continue without necessary limits and accountability," Newsom said. "Without real guardrails," AI can "exploit, mislead, and endanger our kids," Newsom added, while confirming that California's safety initiatives would not stop tech companies based there from leading in AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        California cracks down on AI as child safety concerns grow.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/GettyImages-1262115351-2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Kilito Chan | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;California is cracking down on AI technology deemed too harmful for kids, attacking two increasingly notorious child safety fronts: companion bots and deepfake pornography.&lt;/p&gt;
&lt;p&gt;On Monday, Governor Gavin Newsom signed the first-ever US law regulating companion bots after several teen suicides sparked lawsuits.&lt;/p&gt;
&lt;p&gt;Moving forward, California will require any companion bot platforms—including ChatGPT, Grok, Character.AI, and the like—to create and make public "protocols to identify and address users’ suicidal ideation or expressions of self-harm."&lt;/p&gt;
&lt;p&gt;They must also share "statistics regarding how often they provided users with crisis center prevention notifications to the Department of Public Health," the governor's office said. Those stats will also be posted on the platforms' websites, potentially helping lawmakers and parents track any disturbing trends.&lt;/p&gt;
&lt;p&gt;Further, companion bots will be banned from claiming that they're therapists, and platforms must take extra steps to ensure child safety, including providing kids with break reminders and preventing kids from viewing sexually explicit images.&lt;/p&gt;
&lt;p&gt;Additionally, Newsom strengthened the state's penalties for those who create deepfake pornography, which could help shield young people, who are increasingly targeted with fake nudes, from cyber bullying.&lt;/p&gt;
&lt;p&gt;Now any victims, including minors, can seek up to $250,000 in damages per deepfake from any third parties who knowingly distribute nonconsensual sexually explicit material created using AI tools. Previously, the state allowed victims to recover "statutory damages of not less than $1,500 but not more than $30,000, or $150,000 for a malicious violation."&lt;/p&gt;
&lt;p&gt;Both laws take effect January 1, 2026.&lt;/p&gt;
&lt;h2&gt;American families “are in a battle” with AI&lt;/h2&gt;
&lt;p&gt;The companion bot law's sponsor, Democratic Senator Steve Padilla, said in a press release celebrating the signing that the California law demonstrates how to "put real protections into place" and said it "will become the bedrock for further regulation as this technology develops."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Padilla's law was introduced back in January, but Techcrunch noted that it gained momentum following the death of 16-year-old Adam Raine, who died after ChatGPT allegedly became his "suicide coach," his parents have alleged. California lawmakers were also disturbed by a lax Meta policy that had to be reversed after previously allowing chatbots to be creepy to kids, Padilla noted.&lt;/p&gt;
&lt;p&gt;In lawsuits, parents have alleged that companion bots engage young users in sexualized chats in attempts to groom kids, as well as encourage isolation, self-harm, and violence.&lt;/p&gt;
&lt;p&gt;Megan Garcia, the first mother to publicly link her son's suicide to a companion bot, set off alarm bells across the US last year. She echoed Padilla's praise in his press release, saying, "finally, there is a law that requires companies to protect their users who express suicidal ideations to chatbots.&lt;/p&gt;
&lt;p&gt;"American families, like mine, are in a battle for the online safety of our children," Garcia said.&lt;/p&gt;
&lt;p&gt;Meanwhile, the deepfake pornography law, which protects all victims of all ages, was introduced after the federal government proposed a 10-year moratorium on state AI laws. Opposing the moratorium, a bipartisan coalition of California lawmakers defended the state's AI initiatives, expressing particular concerns about both "AI-generated deepfake nude images of minors circulating in schools" and "companion chatbots developing inappropriate relationships with children."&lt;/p&gt;
&lt;p&gt;On Monday, Newsom promised that California would continue pushing back on AI products that could endanger kids.&lt;/p&gt;
&lt;p&gt;"We’ve seen some truly horrific and tragic examples of young people harmed by unregulated tech, and we won’t stand by while companies continue without necessary limits and accountability," Newsom said. "Without real guardrails," AI can "exploit, mislead, and endanger our kids," Newsom added, while confirming that California's safety initiatives would not stop tech companies based there from leading in AI.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/10/to-shield-kids-california-hikes-fake-nude-fines-to-250k-max/</guid><pubDate>Mon, 13 Oct 2025 18:52:06 +0000</pubDate></item><item><title>Google’s Photoshop-killer AI model is coming to search, Photos, and NotebookLM (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/10/googles-nano-banana-ai-image-editor-is-coming-to-search-photos-and-notebooklm/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        After more than 5 billion AI image edits, Nano Banana is expanding.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana banana" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-640x361.jpg" width="640" /&gt;
                  &lt;img alt="Nano Banana banana" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google began experimenting with conversational image editing earlier this year in the dev-focused AI studio, but the feature didn't remain experimental for long. Over the summer, Google rolled out the "Nano Banana" image-editing model in Gemini 2.5 Flash. You can use this feature to modify images with just a prompt, and now you don't even need to go to Gemini to use it. Google says Nano Banana is now coming to search, Google Photos, and NotebookLM.&lt;/p&gt;
&lt;p&gt;The AI image editor is coming to search via Lens and AI Mode. For Lens, you can simply open the app (iOS and Android) and snap a photo to get started. When the rollout is complete, you'll see a "Create" button at the bottom, with a banana icon. Tap that to enter a prompt, telling the AI how you'd like the photo changed.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122178-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Nano_Banana_in_Lens_-_Photo_Booth.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;When you begin an edit in Lens, the Google app will display the results and offer the chance for follow-up edits in the AI Mode interface. Google is always looking for more ways to get people plugged into its conversational search bot, so there's also a separate way to access Nano Banana there. Simply select the "Create image" tool and enter your prompt to create an image. You can then continue the conversation to have Nano Banana change the image.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;NotebookLM added a video overview feature several months back, which uses AI to generate a video summary of the content you've added to the notebook. The addition of Nano Banana to NotebookLM is much less open-ended. Instead of entering prompts to edit images, NotebookLM has a new set of video styles powered by Nano Banana, including whiteboard, anime, retro print, and more. The original style is still available as "Classic."&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      My favorite video.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;NotebookLM's videos are still somewhat limited, but this update adds a second general format. You can now choose "Brief" in addition to "Explainer," with the option to add prompts that steer the video in the right direction. Although, that's not a guarantee, as this is still generative AI. At least the style should be more consistent with the addition of Nano Banana.&lt;/p&gt;
&lt;p&gt;The updated image editor is also coming to Google Photos, but Google doesn't have a firm timeline. Google claims that its Nano Banana model is a "major upgrade" over its previous image-editing model. Conversational editing was added to Photos last month, but it's not the Nano Banana model that has impressed testers over the summer. Google says that Nano Banana will arrive in the Photos app in the next few weeks, which should make those conversational edits much less frustrating.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        After more than 5 billion AI image edits, Nano Banana is expanding.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Nano Banana banana" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-640x361.jpg" width="640" /&gt;
                  &lt;img alt="Nano Banana banana" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/BananaLens-2096x1182.width-2200.format-webp-copy-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google began experimenting with conversational image editing earlier this year in the dev-focused AI studio, but the feature didn't remain experimental for long. Over the summer, Google rolled out the "Nano Banana" image-editing model in Gemini 2.5 Flash. You can use this feature to modify images with just a prompt, and now you don't even need to go to Gemini to use it. Google says Nano Banana is now coming to search, Google Photos, and NotebookLM.&lt;/p&gt;
&lt;p&gt;The AI image editor is coming to search via Lens and AI Mode. For Lens, you can simply open the app (iOS and Android) and snap a photo to get started. When the rollout is complete, you'll see a "Create" button at the bottom, with a banana icon. Tap that to enter a prompt, telling the AI how you'd like the photo changed.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122178-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Nano_Banana_in_Lens_-_Photo_Booth.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;When you begin an edit in Lens, the Google app will display the results and offer the chance for follow-up edits in the AI Mode interface. Google is always looking for more ways to get people plugged into its conversational search bot, so there's also a separate way to access Nano Banana there. Simply select the "Create image" tool and enter your prompt to create an image. You can then continue the conversation to have Nano Banana change the image.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;NotebookLM added a video overview feature several months back, which uses AI to generate a video summary of the content you've added to the notebook. The addition of Nano Banana to NotebookLM is much less open-ended. Instead of entering prompts to edit images, NotebookLM has a new set of video styles powered by Nano Banana, including whiteboard, anime, retro print, and more. The original style is still available as "Classic."&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      My favorite video.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;NotebookLM's videos are still somewhat limited, but this update adds a second general format. You can now choose "Brief" in addition to "Explainer," with the option to add prompts that steer the video in the right direction. Although, that's not a guarantee, as this is still generative AI. At least the style should be more consistent with the addition of Nano Banana.&lt;/p&gt;
&lt;p&gt;The updated image editor is also coming to Google Photos, but Google doesn't have a firm timeline. Google claims that its Nano Banana model is a "major upgrade" over its previous image-editing model. Conversational editing was added to Photos last month, but it's not the Nano Banana model that has impressed testers over the summer. Google says that Nano Banana will arrive in the Photos app in the next few weeks, which should make those conversational edits much less frustrating.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/10/googles-nano-banana-ai-image-editor-is-coming-to-search-photos-and-notebooklm/</guid><pubDate>Mon, 13 Oct 2025 19:52:23 +0000</pubDate></item><item><title>Researchers find that retraining only small parts of AI models can cut costs and prevent forgetting (AI | VentureBeat)</title><link>https://venturebeat.com/ai/researchers-find-that-retraining-only-small-parts-of-ai-models-can-cut-costs</link><description>[unable to retrieve full-text content]&lt;p&gt;Enterprises often find that when &lt;a href="https://venturebeat.com/ai/fine-tuning-vs-in-context-learning-new-research-guides-better-llm-customization-for-real-world-tasks"&gt;&lt;u&gt;they fine-tune models&lt;/u&gt;&lt;/a&gt;, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. &lt;/p&gt;&lt;p&gt;Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.&lt;/p&gt;&lt;p&gt;The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. &lt;/p&gt;&lt;p&gt;“Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the &lt;a href="https://arxiv.org/pdf/2510.08564"&gt;&lt;u&gt;paper&lt;/u&gt;&lt;/a&gt;. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”&lt;/p&gt;&lt;p&gt;The researchers focused on a multi-layer perceptron (MLP), the model&amp;#x27;s internal decision-making component. 
&lt;/p&gt;&lt;h2&gt;Catastrophic forgetting &lt;/h2&gt;&lt;p&gt;The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. &lt;/p&gt;&lt;p&gt;To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. &lt;/p&gt;&lt;p&gt;“We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”&lt;/p&gt;&lt;p&gt;The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”&lt;/p&gt;&lt;h2&gt;Narrow retraining&lt;/h2&gt;&lt;p&gt;That finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. &lt;/p&gt;&lt;p&gt;“To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. &lt;/p&gt;&lt;p&gt;This allows for a more straightforward and more reproducible method for fine-tuning a model. &lt;/p&gt;&lt;p&gt;By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. &lt;/p&gt;&lt;p&gt;However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.&lt;/p&gt;&lt;p&gt;Their findings, however, can be extended to other LLMs, especially for different modalities. &lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Enterprises often find that when &lt;a href="https://venturebeat.com/ai/fine-tuning-vs-in-context-learning-new-research-guides-better-llm-customization-for-real-world-tasks"&gt;&lt;u&gt;they fine-tune models&lt;/u&gt;&lt;/a&gt;, one effective approach to making a large language model (LLM) fit for purpose and grounded in data is to have the model lose some of its abilities. After fine-tuning, some models “forget” how to perform certain tasks or other tasks they already learned. &lt;/p&gt;&lt;p&gt;Research from the University of Illinois Urbana-Champaign proposes a new method for retraining models that avoids “catastrophic forgetting,” in which the model loses some of its prior knowledge. The paper focuses on two specific LLMs that generate responses from images: LLaVA and Qwen 2.5-VL.&lt;/p&gt;&lt;p&gt;The approach encourages enterprises to retrain only narrow parts of an LLM to avoid retraining the entire model and incurring a significant increase in compute costs. The team claims that catastrophic forgetting isn’t true memory loss, but rather a side effect of bias drift. &lt;/p&gt;&lt;p&gt;“Training a new LMM can cost millions of dollars, weeks of time, and emit hundreds of tons of CO2, so finding ways to more efficiently and effectively update existing models is a pressing concern,” the team wrote in the &lt;a href="https://arxiv.org/pdf/2510.08564"&gt;&lt;u&gt;paper&lt;/u&gt;&lt;/a&gt;. “Guided by this result, we explore tuning recipes that preserve learning while limiting output shift.”&lt;/p&gt;&lt;p&gt;The researchers focused on a multi-layer perceptron (MLP), the model&amp;#x27;s internal decision-making component. 
&lt;/p&gt;&lt;h2&gt;Catastrophic forgetting &lt;/h2&gt;&lt;p&gt;The researchers wanted first to verify the existence and the cause of catastrophic forgetting in models. &lt;/p&gt;&lt;p&gt;To do this, they created a set of target tasks for the models to complete. The models were then fine-tuned and evaluated to determine whether they led to substantial forgetting. But as the process went on, the researchers found that the models were recovering some of their abilities. &lt;/p&gt;&lt;p&gt;“We also noticed a surprising result, that the model performance would drop significantly in held out benchmarks after training on the counting task, it would mostly recover on PathVQA, another specialized task that is not well represented in the benchmarks,” they said. “Meanwhile, while performing the forgetting mitigation experiments, we also tried separately tuning only the self-attention projection (SA Proj) or MLP layers, motivated by the finding that tuning only the LLM was generally better than tuning the full model. This led to another very surprising result – that tuning only self-attention projection layers led to very good learning of the target tasks with no drop in performance in held out tasks, even after training all five target tasks in a sequence.”&lt;/p&gt;&lt;p&gt;The researchers said they believe that “what looks like forgetting or interference after fine-tuning on a narrow target task is actually bias in the output distribution due to the task distribution shift.”&lt;/p&gt;&lt;h2&gt;Narrow retraining&lt;/h2&gt;&lt;p&gt;That finding turned out to be the key to the experiment. The researchers noted that tuning the MLP increases the likelihood of “outputting numeric tokens and a highly correlated drop in held out task accuracy.” What it showed is that a model forgetting some of its knowledge is only temporary and not a long-term matter. &lt;/p&gt;&lt;p&gt;“To avoid biasing the output distribution, we tune the MLP up/gating projections while keeping the down projection frozen, and find that it achieves similar learning to full MLP tuning with little forgetting,” the researchers said. &lt;/p&gt;&lt;p&gt;This allows for a more straightforward and more reproducible method for fine-tuning a model. &lt;/p&gt;&lt;p&gt;By focusing on a narrow segment of the model, rather than a wholesale retraining, enterprises can cut compute costs. It also allows better control of output drift. &lt;/p&gt;&lt;p&gt;However, the research focuses only on two models, specifically those dealing with vision and language. The researchers noted that due to limited resources, they are unable to try the experiment with other models.&lt;/p&gt;&lt;p&gt;Their findings, however, can be extended to other LLMs, especially for different modalities. &lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/researchers-find-that-retraining-only-small-parts-of-ai-models-can-cut-costs</guid><pubDate>Mon, 13 Oct 2025 22:39:00 +0000</pubDate></item><item><title>Self-improving language models are becoming reality with MIT's updated SEAL technique (AI | VentureBeat)</title><link>https://venturebeat.com/ai/self-improving-language-models-are-becoming-reality-with-mits-updated-seal</link><description>[unable to retrieve full-text content]&lt;p&gt;Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and &lt;a href="https://github.com/Continual-Intelligence/SEAL/blob/main/LICENSE"&gt;open sourcing&lt;/a&gt; a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. &lt;/p&gt;&lt;p&gt;The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and &lt;a href="https://venturebeat.com/ai/beyond-static-ai-mits-new-framework-lets-models-teach-themselves"&gt;covered by VentureBeat at the time.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A significantly expanded and &lt;a href="https://arxiv.org/pdf/2506.10943"&gt;updated version of the paper was released last month&lt;/a&gt;, as well as &lt;a href="https://github.com/Continual-Intelligence/SEAL"&gt;open source code posted on Github&lt;/a&gt; (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.&lt;/p&gt;&lt;p&gt;SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.&lt;/p&gt;&lt;p&gt;The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Background: From “Beyond Static AI” to Self-Adaptive Systems&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Earlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. &lt;/p&gt;&lt;p&gt;At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.&lt;/p&gt;&lt;p&gt;Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. &lt;/p&gt;&lt;p&gt;The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Addressing the Limitations of Static Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. &lt;/p&gt;&lt;p&gt;SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.&lt;/p&gt;&lt;p&gt;These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.&lt;/p&gt;&lt;p&gt;The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Across Tasks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL has been tested across two main domains: knowledge incorporation and few-shot learning.&lt;/p&gt;&lt;p&gt;In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). &lt;/p&gt;&lt;p&gt;Rather than fine-tuning directly on passage text, &lt;b&gt;the model generated synthetic implications of the passage&lt;/b&gt; and then fine-tuned on them. &lt;/p&gt;&lt;p&gt;After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.&lt;/p&gt;&lt;p&gt;In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. &lt;/p&gt;&lt;p&gt;After reinforcement learning,&lt;b&gt; the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. &lt;/b&gt;Models that relied solely on in-context learning without any adaptation scored 0%.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Framework&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.&lt;/p&gt;&lt;p&gt;The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.&lt;/p&gt;&lt;p&gt;For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Strengths and Limitations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. &lt;/p&gt;&lt;p&gt;They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.&lt;/p&gt;&lt;p&gt;However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. &lt;/p&gt;&lt;p&gt;In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.&lt;/p&gt;&lt;p&gt;Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. &lt;/p&gt;&lt;p&gt;As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.&lt;/p&gt;&lt;p&gt;Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;AI Community Reactions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.&lt;/p&gt;&lt;p&gt;User &lt;a href="https://x.com/VraserX/status/1977270686285459482"&gt;@VraserX&lt;/a&gt;, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&amp;#x27;s GPT-6 could adopt similar architecture. &lt;/p&gt;&lt;p&gt;In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. &lt;/p&gt;&lt;p&gt;They highlighted SEAL&amp;#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;a href="https://x.com/alex_prompter/status/1977633849879527877"&gt;@alex_prompter&lt;/a&gt;, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. &lt;b&gt;Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data &lt;/b&gt;— he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”&lt;/p&gt;&lt;p&gt;The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Future Directions and Open Questions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.&lt;/p&gt;&lt;p&gt;When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. &lt;/p&gt;&lt;p&gt;“SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.&lt;/p&gt;&lt;p&gt;Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Toward More Adaptive and Agentic Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.&lt;/p&gt;&lt;p&gt;In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.&lt;/p&gt;&lt;p&gt;As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.&lt;/p&gt;&lt;p&gt;You can access the SEAL project, including code and further documentation, at: &lt;a href="https://jyopari.github.io/posts/seal"&gt;https://jyopari.github.io/posts/seal&lt;/a&gt;&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Researchers at the Massachusetts Institute of Technology (MIT) are gaining renewed attention for developing and &lt;a href="https://github.com/Continual-Intelligence/SEAL/blob/main/LICENSE"&gt;open sourcing&lt;/a&gt; a technique that allows large language models (LLMs) — like those underpinning ChatGPT and most modern AI chatbots — to improve themselves by generating synthetic data to fine-tune upon. &lt;/p&gt;&lt;p&gt;The technique, known as SEAL (Self-Adapting LLMs), was first described in a paper published back in June and &lt;a href="https://venturebeat.com/ai/beyond-static-ai-mits-new-framework-lets-models-teach-themselves"&gt;covered by VentureBeat at the time.&lt;/a&gt;&lt;/p&gt;&lt;p&gt;A significantly expanded and &lt;a href="https://arxiv.org/pdf/2506.10943"&gt;updated version of the paper was released last month&lt;/a&gt;, as well as &lt;a href="https://github.com/Continual-Intelligence/SEAL"&gt;open source code posted on Github&lt;/a&gt; (under an MIT License, allowing for commercial and enterprise usage), and is making new waves among AI power users on the social network X this week.&lt;/p&gt;&lt;p&gt;SEAL allows LLMs to autonomously generate and apply their own fine-tuning strategies. Unlike conventional models that rely on fixed external data and human-crafted optimization pipelines, SEAL enables models to evolve by producing their own synthetic training data and corresponding optimization directives.&lt;/p&gt;&lt;p&gt;The development comes from a team affiliated with MIT’s Improbable AI Lab, including Adam Zweiger, Jyothish Pari, Han Guo, Ekin Akyürek, Yoon Kim, and Pulkit Agrawal. Their research was recently presented at the 39th Conference on Neural Information Processing Systems (NeurIPS 2025).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Background: From “Beyond Static AI” to Self-Adaptive Systems&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Earlier this year, VentureBeat first reported on SEAL as an early-stage framework that allowed language models to generate and train on their own synthetic data — a potential remedy for the stagnation of pretrained models once deployed. &lt;/p&gt;&lt;p&gt;At that stage, SEAL was framed as a proof-of-concept that could let enterprise AI agents continuously learn in dynamic environments without manual retraining.&lt;/p&gt;&lt;p&gt;Since then, the research has advanced considerably. The new version expands on the prior framework by demonstrating that SEAL’s self-adaptation ability scales with model size, integrates reinforcement learning more effectively to reduce catastrophic forgetting, and formalizes SEAL’s dual-loop structure (inner supervised fine-tuning and outer reinforcement optimization) for reproducibility. &lt;/p&gt;&lt;p&gt;The updated paper also introduces evaluations across different prompting formats, improved stability during learning cycles, and a discussion of practical deployment challenges at inference time.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Addressing the Limitations of Static Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While LLMs have demonstrated remarkable capabilities in text generation and understanding, their adaptation to new tasks or knowledge is often manual, brittle, or dependent on context. &lt;/p&gt;&lt;p&gt;SEAL challenges this status quo by equipping models with the ability to generate what the authors call “self-edits” — natural language outputs that specify how the model should update its weights.&lt;/p&gt;&lt;p&gt;These self-edits may take the form of reformulated information, logical implications, or tool configurations for augmentation and training. Once generated, the model fine-tunes itself based on these edits. The process is guided by reinforcement learning, where the reward signal comes from improved performance on a downstream task.&lt;/p&gt;&lt;p&gt;The design mimics how human learners might rephrase or reorganize study materials to better internalize information. This restructuring of knowledge before assimilation serves as a key advantage over models that passively consume new data “as-is.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Performance Across Tasks&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL has been tested across two main domains: knowledge incorporation and few-shot learning.&lt;/p&gt;&lt;p&gt;In the knowledge incorporation setting, the researchers evaluated how well a model could internalize new factual content from passages similar to those in the SQuAD dataset, a benchmark reading comprehension dataset introduced by Stanford University in 2016, consisting of over 100,000 crowd-sourced question–answer pairs based on Wikipedia articles (Rajpurkar et al., 2016). &lt;/p&gt;&lt;p&gt;Rather than fine-tuning directly on passage text, &lt;b&gt;the model generated synthetic implications of the passage&lt;/b&gt; and then fine-tuned on them. &lt;/p&gt;&lt;p&gt;After two rounds of reinforcement learning, the model improved question-answering accuracy from 33.5% to 47.0% on a no-context version of SQuAD — surpassing results obtained using synthetic data generated by GPT-4.1.&lt;/p&gt;&lt;p&gt;In the few-shot learning setting, SEAL was evaluated using a subset of the ARC benchmark, where tasks require reasoning from only a few examples. Here, SEAL generated self-edits specifying data augmentations and hyperparameters. &lt;/p&gt;&lt;p&gt;After reinforcement learning,&lt;b&gt; the success rate in correctly solving held-out tasks jumped to 72.5%, up from 20% using self-edits generated without reinforcement learning. &lt;/b&gt;Models that relied solely on in-context learning without any adaptation scored 0%.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Technical Framework&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL operates using a two-loop structure: an inner loop performs supervised fine-tuning based on the self-edit, while an outer loop uses reinforcement learning to refine the policy that generates those self-edits.&lt;/p&gt;&lt;p&gt;The reinforcement learning algorithm used is based on ReSTEM, which combines sampling with filtered behavior cloning. During training, only self-edits that lead to performance improvements are reinforced. This approach effectively teaches the model which kinds of edits are most beneficial for learning.&lt;/p&gt;&lt;p&gt;For efficiency, SEAL applies LoRA-based fine-tuning rather than full parameter updates, enabling rapid experimentation and low-cost adaptation.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Strengths and Limitations&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The researchers report that SEAL can produce high-utility training data with minimal supervision, outperforming even large external models like GPT-4.1 in specific tasks. &lt;/p&gt;&lt;p&gt;They also demonstrate that SEAL generalizes beyond its original setup: it continues to perform well when scaling from single-pass updates to multi-document continued pretraining scenarios.&lt;/p&gt;&lt;p&gt;However, the framework is not without limitations. One issue is catastrophic forgetting, where updates to incorporate new information can degrade performance on previously learned tasks. &lt;/p&gt;&lt;p&gt;In response to this concern, co-author Jyo Pari told VentureBeat via email that reinforcement learning (RL) appears to mitigate forgetting more effectively than standard supervised fine-tuning (SFT), citing a recent paper on the topic. He added that combining this insight with SEAL could lead to new variants where SEAL learns not just training data, but reward functions.&lt;/p&gt;&lt;p&gt;Another challenge is computational overhead: evaluating each self-edit requires fine-tuning and performance testing, which can take 30–45 seconds per edit — significantly more than standard reinforcement learning tasks. &lt;/p&gt;&lt;p&gt;As Jyo explained, “Training SEAL is non-trivial because it requires 2 loops of optimization, an outer RL one and an inner SFT one. At inference time, updating model weights will also require new systems infrastructure.” He emphasized the need for future research into deployment systems as a critical path to making SEAL practical.&lt;/p&gt;&lt;p&gt;Additionally, SEAL’s current design assumes the presence of paired tasks and reference answers for every context, limiting its direct applicability to unlabeled corpora. However, Jyo clarified that as long as there is a downstream task with a computable reward, SEAL can be trained to adapt accordingly—even in safety-critical domains. In principle, a SEAL-trained model could learn to avoid training on harmful or malicious inputs if guided by the appropriate reward signal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;AI Community Reactions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The AI research and builder community has reacted with a mix of excitement and speculation to the SEAL paper. On X, formerly Twitter, several prominent AI-focused accounts weighed in on the potential impact.&lt;/p&gt;&lt;p&gt;User &lt;a href="https://x.com/VraserX/status/1977270686285459482"&gt;@VraserX&lt;/a&gt;, a self-described educator and AI enthusiast, called SEAL “the birth of continuous self-learning AI” and predicted that models like OpenAI&amp;#x27;s GPT-6 could adopt similar architecture. &lt;/p&gt;&lt;p&gt;In their words, SEAL represents “the end of the frozen-weights era,” ushering in systems that evolve as the world around them changes. &lt;/p&gt;&lt;p&gt;They highlighted SEAL&amp;#x27;s ability to form persistent memories, repair knowledge, and learn from real-time data, comparing it to a foundational step toward models that don’t just use information but absorb it.&lt;/p&gt;&lt;p&gt;Meanwhile, &lt;a href="https://x.com/alex_prompter/status/1977633849879527877"&gt;@alex_prompter&lt;/a&gt;, co-founder of an AI-powered marketing venture, framed SEAL as a leap toward models that literally rewrite themselves. “MIT just built an AI that can rewrite its own code to get smarter,” he wrote. &lt;b&gt;Citing the paper’s key results — a 40% boost in factual recall and outperforming GPT-4.1 using self-generated data &lt;/b&gt;— he described the findings as confirmation that “LLMs that finetune themselves are no longer sci-fi.”&lt;/p&gt;&lt;p&gt;The enthusiasm reflects a broader appetite in the AI space for models that can evolve without constant retraining or human oversight — particularly in rapidly changing domains or personalized use cases.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Future Directions and Open Questions&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In response to questions about scaling SEAL to larger models and tasks, Jyo pointed to experiments (Appendix B.7) showing that as model size increases, so does their self-adaptation ability. He compared this to students improving their study techniques over time — larger models are simply better at generating useful self-edits.&lt;/p&gt;&lt;p&gt;When asked whether SEAL generalizes to new prompting styles, he confirmed it does, citing Table 10 in the paper. However, he also acknowledged that the team has not yet tested SEAL’s ability to transfer across entirely new domains or model architectures. &lt;/p&gt;&lt;p&gt;“SEAL is an initial work showcasing the possibilities,” he said. “But it requires much more testing.” He added that generalization may improve as SEAL is trained on a broader distribution of tasks.&lt;/p&gt;&lt;p&gt;Interestingly, the team found that only a few reinforcement learning steps already led to measurable performance gains. “This is exciting,” Jyo noted, “because it means that with more compute, we could hopefully get even more improvements.” He suggested future experiments could explore more advanced reinforcement learning methods beyond ReSTEM, such as Group Relative Policy Optimization (GRPO).&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Toward More Adaptive and Agentic Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;SEAL represents a step toward models that can autonomously improve over time, both by integrating new knowledge and by reconfiguring how they learn. The authors envision future extensions where SEAL could assist in self-pretraining, continual learning, and the development of agentic systems — models that interact with evolving environments and adapt incrementally.&lt;/p&gt;&lt;p&gt;In such settings, a model could use SEAL to synthesize weight updates after each interaction, gradually internalizing behaviors or insights. This could reduce the need for repeated supervision and manual intervention, particularly in data-constrained or specialized domains.&lt;/p&gt;&lt;p&gt;As public web text becomes saturated and further scaling of LLMs becomes bottlenecked by data availability, self-directed approaches like SEAL could play a critical role in pushing the boundaries of what LLMs can achieve.&lt;/p&gt;&lt;p&gt;You can access the SEAL project, including code and further documentation, at: &lt;a href="https://jyopari.github.io/posts/seal"&gt;https://jyopari.github.io/posts/seal&lt;/a&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/self-improving-language-models-are-becoming-reality-with-mits-updated-seal</guid><pubDate>Mon, 13 Oct 2025 22:51:00 +0000</pubDate></item><item><title>Elon Musk Gets Just-Launched NVIDIA DGX Spark: Petaflop AI Supercomputer Lands at SpaceX (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/live-dgx-spark-delivery/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The next AI revolution starts where rockets launch. NVIDIA DGX Spark’s first stop: Starbase, Texas.&lt;/p&gt;
&lt;p&gt;NVIDIA founder and CEO Jensen Huang arrived at the SpaceX facility — amid towering engines and gleaming steel — to hand-deliver the company’s just-launched DGX Spark to Elon Musk.&lt;/p&gt;
&lt;p&gt;Huang arrived walking past rows of engineers who waved and grinned. Moments later, Musk appeared in the cafeteria, greeting staff and opening donuts and chips for kids before grabbing a slice of pizza.&lt;/p&gt;
&lt;p&gt;Huang joined him, recounting the story of delivering the first DGX system to OpenAI and explaining how Spark takes that mission further.&lt;/p&gt;
&lt;p&gt;“Imagine delivering the smallest supercomputer next to the biggest rocket,” Huang said with a laugh.&lt;/p&gt;
&lt;p&gt;The handoff came as SpaceX prepared for the 11th test of Starship, the world’s most powerful launch vehicle.&lt;/p&gt;
&lt;p&gt;DGX Spark packs 128GB of unified memory and delivers a petaflop of AI performance, enough to run models with 200 billion parameters locally.&lt;/p&gt;
&lt;p&gt;Built for developers, researchers and creators, DGX Spark brings supercomputer-class performance beyond the data center — ready to grab and go.&lt;/p&gt;
&lt;p&gt;Nine years ago, NVIDIA bet on the future of AI with NVIDIA DGX-1. Today, that bet goes beyond the data center with the handoff to Musk coming amid the 11th test of SpaceX’s Starship, the world’s most powerful launch vehicle.&lt;/p&gt;
&lt;p&gt;DGX Spark packs 128GB of unified memory and is powerful enough to run models with 200 billion parameters locally.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85778" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/L1031489-retouch.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Built for developers, researchers and creators who want supercomputer-class performance that’s ready to grab and go.&lt;/p&gt;
&lt;p&gt;From robotics labs to creative studios, DGX Sparks are landing where ideas happen… putting petaflop AI within arm’s reach of everyone.&lt;/p&gt;
&lt;p&gt;This blog will be updated as DGX Spark systems land from Ollama in Palo Alto to Arizona State’s robotics lab, from Refik Anadol’s studio to the hands of Jo Mardall at Zipline. Each delivery is a new chapter in the story of AI.&lt;/p&gt;
&lt;h2&gt;What’s Inside DGX Spark? A Supercomputer in the Palm of Your Hand&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85758" height="1126" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/image4.jpg" width="1999" /&gt;&lt;/p&gt;
&lt;p&gt;It’s the size of a piece of origami paper, and the thickness of a hardcover book. It acts like a rocket engine for AI.&lt;/p&gt;
&lt;p&gt;DGX Spark isn’t just compact — it’s dense with possibility. Inside its 1.2 kg chassis is a full-blown AI supercomputer built to take AI beyond the data center and into the hands of those who create.&lt;/p&gt;
&lt;p&gt;At its core:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;NVIDIA GB10 Grace Blackwell Superchip &lt;/b&gt;— delivering up to 1 petaflop of AI performance at FP4 precision.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;128GB of unified CPU-GPU memory &lt;/b&gt;— so developers can prototype, fine-tune and run inference locally without bouncing between machines or cloud instances.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;NVIDIA ConnectX networking&lt;/b&gt; for clustering and NVIDIA NVLink-C2C for 5x PCIe bandwidth.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;NVMe storage&lt;/b&gt; for speed and &lt;b&gt;HDMI out&lt;/b&gt; for visuals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And it’s not just hardware. DGX Spark comes with the full NVIDIA AI software stack — frameworks, libraries, pretrained models and NVIDIA NIM microservices, ready to power workflows like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Customizing image-generation models such as FLUX.1&lt;/li&gt;
&lt;li&gt;Building vision search and summarization agents with NVIDIA Cosmos&lt;/li&gt;
&lt;li&gt;Deploying optimized chatbots using Qwen3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This isn’t a dev box. It’s a launchpad… A petaflop of AI performance within arm’s reach for developers, researchers and creators everywhere.&lt;/p&gt;
&lt;h2&gt;Partners Power Up: DGX Spark Lands Beyond the Data Center
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85752" height="1125" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/image2.jpg" width="1999" /&gt;&lt;/p&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;From PC giants to AI pioneers, the diminutive DGX Spark is sure to start something big.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;DGX Spark is already in the hands of innovators — from ISVs optimizing their tools to researchers pushing the boundaries of robotics, art and edge AI.&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;DGX Spark isn’t just a breakthrough in size and performance… it’s a platform built on collaboration. Acer, ASUS, Dell Technologies, GIGABYTE, HP, Lenovo and MSI are rolling out systems that put petaflop AI on your desk, transforming the desktop into an AI launchpad. &lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;These partners deliver more than hardware. They deliver possibility — NVIDIA’s full AI stack in a compact form factor that accelerates agentic and physical AI development everywhere ideas happen.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;And the rollout doesn’t stop at OEMs. DGX Sparks are already lighting up the AI ecosystem. Some highlights:&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Ollama&lt;/b&gt;&lt;span&gt; in Palo Alto, rewriting how developers run large language models locally.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;NYU Global Frontier Lab&lt;/b&gt;&lt;span&gt;, where researchers prototype algorithms for privacy-sensitive applications.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Zipline&lt;/b&gt;&lt;span&gt;, pushing the boundaries of autonomous delivery.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Arizona State University&lt;/b&gt;&lt;span&gt;, running robotics simulations and vision models at the edge.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Refik Anadol’s studio&lt;/b&gt;&lt;span&gt;, blending art and AI with petaflop performance.&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;From creative studios to robotics labs, DGX Sparks are landing where imagination meets engineering — taking AI beyond the data center and into the hands of those building what’s next.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;DGX Spark will be generally available starting Wednesday, Oct. 15, on NVIDIA.com and through partners worldwide.&lt;/span&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;The next AI revolution starts where rockets launch. NVIDIA DGX Spark’s first stop: Starbase, Texas.&lt;/p&gt;
&lt;p&gt;NVIDIA founder and CEO Jensen Huang arrived at the SpaceX facility — amid towering engines and gleaming steel — to hand-deliver the company’s just-launched DGX Spark to Elon Musk.&lt;/p&gt;
&lt;p&gt;Huang arrived walking past rows of engineers who waved and grinned. Moments later, Musk appeared in the cafeteria, greeting staff and opening donuts and chips for kids before grabbing a slice of pizza.&lt;/p&gt;
&lt;p&gt;Huang joined him, recounting the story of delivering the first DGX system to OpenAI and explaining how Spark takes that mission further.&lt;/p&gt;
&lt;p&gt;“Imagine delivering the smallest supercomputer next to the biggest rocket,” Huang said with a laugh.&lt;/p&gt;
&lt;p&gt;The handoff came as SpaceX prepared for the 11th test of Starship, the world’s most powerful launch vehicle.&lt;/p&gt;
&lt;p&gt;DGX Spark packs 128GB of unified memory and delivers a petaflop of AI performance, enough to run models with 200 billion parameters locally.&lt;/p&gt;
&lt;p&gt;Built for developers, researchers and creators, DGX Spark brings supercomputer-class performance beyond the data center — ready to grab and go.&lt;/p&gt;
&lt;p&gt;Nine years ago, NVIDIA bet on the future of AI with NVIDIA DGX-1. Today, that bet goes beyond the data center with the handoff to Musk coming amid the 11th test of SpaceX’s Starship, the world’s most powerful launch vehicle.&lt;/p&gt;
&lt;p&gt;DGX Spark packs 128GB of unified memory and is powerful enough to run models with 200 billion parameters locally.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85778" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/L1031489-retouch.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Built for developers, researchers and creators who want supercomputer-class performance that’s ready to grab and go.&lt;/p&gt;
&lt;p&gt;From robotics labs to creative studios, DGX Sparks are landing where ideas happen… putting petaflop AI within arm’s reach of everyone.&lt;/p&gt;
&lt;p&gt;This blog will be updated as DGX Spark systems land from Ollama in Palo Alto to Arizona State’s robotics lab, from Refik Anadol’s studio to the hands of Jo Mardall at Zipline. Each delivery is a new chapter in the story of AI.&lt;/p&gt;
&lt;h2&gt;What’s Inside DGX Spark? A Supercomputer in the Palm of Your Hand&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85758" height="1126" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/image4.jpg" width="1999" /&gt;&lt;/p&gt;
&lt;p&gt;It’s the size of a piece of origami paper, and the thickness of a hardcover book. It acts like a rocket engine for AI.&lt;/p&gt;
&lt;p&gt;DGX Spark isn’t just compact — it’s dense with possibility. Inside its 1.2 kg chassis is a full-blown AI supercomputer built to take AI beyond the data center and into the hands of those who create.&lt;/p&gt;
&lt;p&gt;At its core:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;NVIDIA GB10 Grace Blackwell Superchip &lt;/b&gt;— delivering up to 1 petaflop of AI performance at FP4 precision.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;128GB of unified CPU-GPU memory &lt;/b&gt;— so developers can prototype, fine-tune and run inference locally without bouncing between machines or cloud instances.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;NVIDIA ConnectX networking&lt;/b&gt; for clustering and NVIDIA NVLink-C2C for 5x PCIe bandwidth.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;NVMe storage&lt;/b&gt; for speed and &lt;b&gt;HDMI out&lt;/b&gt; for visuals.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And it’s not just hardware. DGX Spark comes with the full NVIDIA AI software stack — frameworks, libraries, pretrained models and NVIDIA NIM microservices, ready to power workflows like:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Customizing image-generation models such as FLUX.1&lt;/li&gt;
&lt;li&gt;Building vision search and summarization agents with NVIDIA Cosmos&lt;/li&gt;
&lt;li&gt;Deploying optimized chatbots using Qwen3&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This isn’t a dev box. It’s a launchpad… A petaflop of AI performance within arm’s reach for developers, researchers and creators everywhere.&lt;/p&gt;
&lt;h2&gt;Partners Power Up: DGX Spark Lands Beyond the Data Center
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-85752" height="1125" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/image2.jpg" width="1999" /&gt;&lt;/p&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;From PC giants to AI pioneers, the diminutive DGX Spark is sure to start something big.&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;DGX Spark is already in the hands of innovators — from ISVs optimizing their tools to researchers pushing the boundaries of robotics, art and edge AI.&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;DGX Spark isn’t just a breakthrough in size and performance… it’s a platform built on collaboration. Acer, ASUS, Dell Technologies, GIGABYTE, HP, Lenovo and MSI are rolling out systems that put petaflop AI on your desk, transforming the desktop into an AI launchpad. &lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;&lt;br /&gt;&lt;/span&gt;&lt;span&gt;These partners deliver more than hardware. They deliver possibility — NVIDIA’s full AI stack in a compact form factor that accelerates agentic and physical AI development everywhere ideas happen.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;And the rollout doesn’t stop at OEMs. DGX Sparks are already lighting up the AI ecosystem. Some highlights:&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Ollama&lt;/b&gt;&lt;span&gt; in Palo Alto, rewriting how developers run large language models locally.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;NYU Global Frontier Lab&lt;/b&gt;&lt;span&gt;, where researchers prototype algorithms for privacy-sensitive applications.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Zipline&lt;/b&gt;&lt;span&gt;, pushing the boundaries of autonomous delivery.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Arizona State University&lt;/b&gt;&lt;span&gt;, running robotics simulations and vision models at the edge.&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Refik Anadol’s studio&lt;/b&gt;&lt;span&gt;, blending art and AI with petaflop performance.&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;From creative studios to robotics labs, DGX Sparks are landing where imagination meets engineering — taking AI beyond the data center and into the hands of those building what’s next.&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;DGX Spark will be generally available starting Wednesday, Oct. 15, on NVIDIA.com and through partners worldwide.&lt;/span&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/live-dgx-spark-delivery/</guid><pubDate>Tue, 14 Oct 2025 00:31:39 +0000</pubDate></item></channel></rss>