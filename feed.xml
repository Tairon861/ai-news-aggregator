<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 20 Sep 2025 06:28:15 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Cracking product-market fit: Lessons from founders and investors at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/19/crack-the-code-to-startup-traction-with-insights-from-chef-robotics-nea-and-iconiq-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Finding product-market fit isn’t a milestone — it’s a messy, make-or-break journey. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — taking place October 27–29 at Moscone West in San Francisco — Rajat Bhageria (Chef Robotics), Ann Bordetsky (NEA), and Murali Joshi (ICONIQ) break down how to navigate this critical phase. &lt;strong&gt;Register now.&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Rajat Bhageria, Ann Bordetsky, Murali Joshi" class="wp-image-3034069" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Bhageria-Bordetsky-Joshi-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-no-more-guessing-just-growth"&gt;No more guessing — just growth&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Rajat Bhageria&lt;/strong&gt;: Founder and CEO of Chef Robotics, scaling AI-powered automation that’s transforming food production.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Ann Bordetsky&lt;/strong&gt;: Partner at NEA, previously at Uber and Twitter, spotting scrappy ingenuity that drives breakout success.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Murali Joshi&lt;/strong&gt;: Partner at ICONIQ, Forbes Midas Brink List honoree, with over $2.5 billion invested in companies like Drata, 1Password, and Fivetran.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;They’ll cover smart testing strategies, real-time iteration, and how to listen to users without getting lost in the noise — offering a rare inside look at what product-market fit really looks like.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-build-something-customers-can-t-live-without"&gt;Build something customers can’t live without&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re in prototype mode or scaling a growing product, this session will give founders actionable insight to cut the guesswork and focus on what actually moves the needle. Catch it on the &lt;strong&gt;Builders Stage&lt;/strong&gt; at TechCrunch Disrupt 2025. &lt;strong&gt;Grab your pass&lt;/strong&gt; before tomorrow ends to save up to $668.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Finding product-market fit isn’t a milestone — it’s a messy, make-or-break journey. At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; — taking place October 27–29 at Moscone West in San Francisco — Rajat Bhageria (Chef Robotics), Ann Bordetsky (NEA), and Murali Joshi (ICONIQ) break down how to navigate this critical phase. &lt;strong&gt;Register now.&lt;/strong&gt;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Rajat Bhageria, Ann Bordetsky, Murali Joshi" class="wp-image-3034069" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Bhageria-Bordetsky-Joshi-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-no-more-guessing-just-growth"&gt;No more guessing — just growth&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Rajat Bhageria&lt;/strong&gt;: Founder and CEO of Chef Robotics, scaling AI-powered automation that’s transforming food production.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Ann Bordetsky&lt;/strong&gt;: Partner at NEA, previously at Uber and Twitter, spotting scrappy ingenuity that drives breakout success.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Murali Joshi&lt;/strong&gt;: Partner at ICONIQ, Forbes Midas Brink List honoree, with over $2.5 billion invested in companies like Drata, 1Password, and Fivetran.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;They’ll cover smart testing strategies, real-time iteration, and how to listen to users without getting lost in the noise — offering a rare inside look at what product-market fit really looks like.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-build-something-customers-can-t-live-without"&gt;Build something customers can’t live without&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re in prototype mode or scaling a growing product, this session will give founders actionable insight to cut the guesswork and focus on what actually moves the needle. Catch it on the &lt;strong&gt;Builders Stage&lt;/strong&gt; at TechCrunch Disrupt 2025. &lt;strong&gt;Grab your pass&lt;/strong&gt; before tomorrow ends to save up to $668.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/19/crack-the-code-to-startup-traction-with-insights-from-chef-robotics-nea-and-iconiq-at-techcrunch-disrupt-2025/</guid><pubDate>Fri, 19 Sep 2025 20:30:00 +0000</pubDate></item><item><title>Deep researcher with test-time diffusion (The latest research from Google)</title><link>https://research.google/blog/deep-researcher-with-test-time-diffusion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The recent advances in large language models (LLMs) have fueled the emergence of deep research (DR) agents. These agents demonstrate remarkable capabilities, including the generation of novel ideas, efficient information retrieval, experimental execution, and the subsequent drafting of comprehensive reports and academic papers.&lt;/p&gt;&lt;p&gt;Currently, most public DR agents use a variety of clever techniques to improve their results, like performing reasoning via chain-of-thought or generating multiple answers and selecting the best one. While they've made impressive progress, they often bolt different tools together without considering the iterative nature of human research. They're missing the key process (i.e., planning, drafting, researching, and iterating based on feedback) on which people rely when writing a paper about a complex topic. A key part of that revision process is to do more research to find missing information or strengthen your arguments. This human pattern is surprisingly similar to the mechanism of &lt;i&gt;retrieval&lt;/i&gt;-augmented diffusion models that start with a “noisy” or messy output and gradually refine it into a high-quality result. What if an AI agent's rough draft is the noisy version, and a search tool acts as the denoising step that cleans it up with new facts?&lt;/p&gt;&lt;p&gt;Today we introduce Test-Time Diffusion Deep Researcher (TTD-DR), a DR agent that imitates the way humans do research. To our knowledge, TTD-DR is the first research agent that models research report writing as a diffusion process, where a messy first draft is gradually polished into a high-quality final version. We introduce two new algorithms that work together to enable TTD-DR. First, component-wise optimization via self-evolution enhances the quality of each step in the research workflow. Then, report-level refinement via denoising with retrieval applies newly retrieved information to revise and improve the report draft. We demonstrate that TTD-DR achieves state-of-the-art results on long-form report writing and multi-hop reasoning tasks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The recent advances in large language models (LLMs) have fueled the emergence of deep research (DR) agents. These agents demonstrate remarkable capabilities, including the generation of novel ideas, efficient information retrieval, experimental execution, and the subsequent drafting of comprehensive reports and academic papers.&lt;/p&gt;&lt;p&gt;Currently, most public DR agents use a variety of clever techniques to improve their results, like performing reasoning via chain-of-thought or generating multiple answers and selecting the best one. While they've made impressive progress, they often bolt different tools together without considering the iterative nature of human research. They're missing the key process (i.e., planning, drafting, researching, and iterating based on feedback) on which people rely when writing a paper about a complex topic. A key part of that revision process is to do more research to find missing information or strengthen your arguments. This human pattern is surprisingly similar to the mechanism of &lt;i&gt;retrieval&lt;/i&gt;-augmented diffusion models that start with a “noisy” or messy output and gradually refine it into a high-quality result. What if an AI agent's rough draft is the noisy version, and a search tool acts as the denoising step that cleans it up with new facts?&lt;/p&gt;&lt;p&gt;Today we introduce Test-Time Diffusion Deep Researcher (TTD-DR), a DR agent that imitates the way humans do research. To our knowledge, TTD-DR is the first research agent that models research report writing as a diffusion process, where a messy first draft is gradually polished into a high-quality final version. We introduce two new algorithms that work together to enable TTD-DR. First, component-wise optimization via self-evolution enhances the quality of each step in the research workflow. Then, report-level refinement via denoising with retrieval applies newly retrieved information to revise and improve the report draft. We demonstrate that TTD-DR achieves state-of-the-art results on long-form report writing and multi-hop reasoning tasks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/deep-researcher-with-test-time-diffusion/</guid><pubDate>Fri, 19 Sep 2025 20:43:00 +0000</pubDate></item><item><title>Why California’s SB 53 might provide a meaningful check on big AI companies (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/19/why-californias-sb-53-might-provide-a-meaningful-check-on-big-ai-companies/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-950173010.jpg?resize=1200,861" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California’s state senate recently gave final approval to a new AI safety bill, SB 53, sending it to Governor Gavin Newsom to either sign or veto.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If this all sounds familiar, that’s because Newsom vetoed another AI safety bill, also written by state senator Scott Wiener, last year. But SB 53 is narrower than Wiener’s previous SB 1047, with a focus on big AI companies making more than $500 million in annual revenue.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I got the chance to discuss SB 53 with my colleagues Max Zeff and Kirsten Korosec on the latest episode of TechCrunch’s flagship podcast Equity. Max believes that Wiener’s new bill has a better shot of becoming law, partly because of that big company focus, and because it’s been endorsed by AI company Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read a preview of our conversation about AI safety and state-level legislation below. (I’ve edited the transcript for length and clarity, and to make us sound slightly smarter.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Max:&lt;/strong&gt; Why should you care about AI safety legislation that’s passing a chamber in California? We’re entering this era where AI companies are becoming the most powerful companies in the world, and this is going to be potentially one of the few checks on their power.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is much narrower than SB 1047, which got a lot of pushback last year. But I think SB 53 still puts some meaningful regulations on the AI labs. It makes them publish safety reports for their models. If they have an incident, it basically forces them to report that to the government. And it also, for employees at these labs, if they have concerns, gives them a channel to report that to the government and not face pushback from the companies, even though a lot of them have signed NDAs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To me, this feels like a potentially meaningful check on tech companies’ power, something we haven’t really had for the last couple of decades.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Kirsten: &lt;/strong&gt;To your point about why it matters at the state level, it’s important to think about the fact that it’s California. Every major AI company is pretty much, if not based here, it has a major footprint in this state. Not that other states don’t matter — I do not want to be getting emails from the folks in Colorado or whatever —&amp;nbsp; but it does matter that it’s specifically California because it’s really a hub of AI activity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;My question for you, though, Max, is it just seems like there’s a lot of exceptions and carve-outs. It’s narrower, but is it more complicated than the previous [bill]?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Max:&lt;/strong&gt; In some ways, yes. I would say the main carve-out of this bill is that it really tries to not apply to small startups. And basically, one of the main controversies around the last legislative effort from Senator Scott Weiner, who represents San Francisco, who authored this bill, a lot of people said it could harm the startup ecosystem, which a lot of people take issue with because that’s such a booming part of California’s economy right now.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This bill specifically applies to AI developers that are [generating] more than $500 million [from] their AI models. This really tries to target OpenAI, Google DeepMind, these big companies and not your run-of-the-mill startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Anthony:&lt;/strong&gt; As I understand it, if you’re a smaller startup, you do have to share some safety information, but not nearly as much.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s [also] worth talking about the broader landscape around AI regulation and the fact that one of the big changes between last year and this year is now we have a new president. The federal administration has taken much more of a stance of no regulation and companies should be able to do what they want, to the extent that they’ve actually included [language] in funding bills saying states cannot have their own AI regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I don’t think any of that has passed so far, but potentially they could try to get that through in the future. So this could be another front in which the Trump administration and blue states are fighting.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&lt;/em&gt;&lt;/p&gt;

&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt;, and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and &lt;/em&gt;&lt;em&gt;Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-950173010.jpg?resize=1200,861" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;California’s state senate recently gave final approval to a new AI safety bill, SB 53, sending it to Governor Gavin Newsom to either sign or veto.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If this all sounds familiar, that’s because Newsom vetoed another AI safety bill, also written by state senator Scott Wiener, last year. But SB 53 is narrower than Wiener’s previous SB 1047, with a focus on big AI companies making more than $500 million in annual revenue.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I got the chance to discuss SB 53 with my colleagues Max Zeff and Kirsten Korosec on the latest episode of TechCrunch’s flagship podcast Equity. Max believes that Wiener’s new bill has a better shot of becoming law, partly because of that big company focus, and because it’s been endorsed by AI company Anthropic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read a preview of our conversation about AI safety and state-level legislation below. (I’ve edited the transcript for length and clarity, and to make us sound slightly smarter.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Max:&lt;/strong&gt; Why should you care about AI safety legislation that’s passing a chamber in California? We’re entering this era where AI companies are becoming the most powerful companies in the world, and this is going to be potentially one of the few checks on their power.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is much narrower than SB 1047, which got a lot of pushback last year. But I think SB 53 still puts some meaningful regulations on the AI labs. It makes them publish safety reports for their models. If they have an incident, it basically forces them to report that to the government. And it also, for employees at these labs, if they have concerns, gives them a channel to report that to the government and not face pushback from the companies, even though a lot of them have signed NDAs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To me, this feels like a potentially meaningful check on tech companies’ power, something we haven’t really had for the last couple of decades.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Kirsten: &lt;/strong&gt;To your point about why it matters at the state level, it’s important to think about the fact that it’s California. Every major AI company is pretty much, if not based here, it has a major footprint in this state. Not that other states don’t matter — I do not want to be getting emails from the folks in Colorado or whatever —&amp;nbsp; but it does matter that it’s specifically California because it’s really a hub of AI activity.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;My question for you, though, Max, is it just seems like there’s a lot of exceptions and carve-outs. It’s narrower, but is it more complicated than the previous [bill]?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Max:&lt;/strong&gt; In some ways, yes. I would say the main carve-out of this bill is that it really tries to not apply to small startups. And basically, one of the main controversies around the last legislative effort from Senator Scott Weiner, who represents San Francisco, who authored this bill, a lot of people said it could harm the startup ecosystem, which a lot of people take issue with because that’s such a booming part of California’s economy right now.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This bill specifically applies to AI developers that are [generating] more than $500 million [from] their AI models. This really tries to target OpenAI, Google DeepMind, these big companies and not your run-of-the-mill startup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Anthony:&lt;/strong&gt; As I understand it, if you’re a smaller startup, you do have to share some safety information, but not nearly as much.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s [also] worth talking about the broader landscape around AI regulation and the fact that one of the big changes between last year and this year is now we have a new president. The federal administration has taken much more of a stance of no regulation and companies should be able to do what they want, to the extent that they’ve actually included [language] in funding bills saying states cannot have their own AI regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;I don’t think any of that has passed so far, but potentially they could try to get that through in the future. So this could be another front in which the Trump administration and blue states are fighting.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&lt;/em&gt;&lt;/p&gt;

&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt;, and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and &lt;/em&gt;&lt;em&gt;Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/19/why-californias-sb-53-might-provide-a-meaningful-check-on-big-ai-companies/</guid><pubDate>Fri, 19 Sep 2025 21:00:37 +0000</pubDate></item></channel></rss>