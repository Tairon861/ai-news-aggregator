<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 15 Oct 2025 18:31:49 +0000</lastBuildDate><item><title>Big Tech’s big bet on a controversial carbon removal tactic (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/15/1125715/big-techs-big-bet-on-a-controversial-carbon-removal-tactic/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AP24203458670422.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Over the last century, much of the US pulp and paper industry crowded into the southeastern corner of the nation, setting up mills amid sprawling timber forests to strip the fibers from juvenile loblolly, long leaf, and slash pine trees.&lt;/p&gt;  &lt;p&gt;Today, after the factories chip the softwood and digest it into pulp, the leftover lignin, spent chemicals, and remaining organic matter form a dark, syrupy by-product known as black liquor. It’s then concentrated into a biofuel and burned, which heats the towering boilers that power the facility—and releases carbon dioxide into the air.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Microsoft, JP MorganChase, and a tech company consortium that includes Alphabet, Meta, Shopify, and Stripe have all recently struck multimillion-dollar deals to pay paper mill owners to capture at least hundreds of thousands of tons of this greenhouse gas by installing carbon scrubbing equipment in their facilities.&lt;/p&gt;  &lt;p&gt;The captured carbon dioxide will then be piped down into saline aquifers more than a mile underground, where it should be sequestered permanently.&lt;/p&gt; 
 &lt;p&gt;Big Tech is suddenly betting big on this form of carbon removal, known as bioenergy with carbon capture and storage, or BECCS. The sector also includes biomass-fueled power plants, waste incinerators, and biofuel refineries that add carbon capturing equipment to their facilities.&lt;/p&gt;&lt;p&gt;Since trees and other plants absorb carbon dioxide through photosynthesis and these factories will trap emissions that would have gone into the air, together they can theoretically remove more greenhouse gas from the atmosphere than was released, achieving what’s known as “negative emissions.”&lt;/p&gt;  &lt;p&gt;The companies that pay for this removal can apply that reduction in carbon dioxide to cancel out a share of their own corporate pollution. BECCS now accounts for nearly 70% of the announced contracts in carbon removal, a popularity due largely to the fact that it can be tacked onto industrial facilities already operating on large scales.&lt;/p&gt; 
 &lt;p&gt;“If we’re balancing cost, time to market, and ultimate scale potential, BECCS offers a really attractive value proposition across all three of those,” says Brian Marrs, senior director of energy and carbon removal at Microsoft, which has become by far the largest buyer of carbon removal credits as it races to balance out its ongoing emissions by the end of the decade.&lt;/p&gt;  &lt;p&gt;But experts have raised a number of concerns about various approaches to BECCS, stressing they may inflate the climate benefits of the projects, conflate prevented emissions with carbon removal, and extend the life of facilities that pollute in other ways. It could also create greater financial incentives to log forests or convert them to agricultural land.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When greenhouse-gas sources and sinks are properly tallied across all the fields, forests, and factories involved, it’s highly difficult to achieve negative emissions with many approaches to BECCS, says Tim Searchinger, a senior research scholar at Princeton University. That undermines the logic of dedicating more of the world’s limited land, crops, and woods to such projects, he argues.&lt;/p&gt;  &lt;p&gt;“I call it a ‘BECCS and switch,’” he says, adding later: “It’s folly at some level.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;The logic of BECCS&lt;/h3&gt;  &lt;p&gt;For a biomass-fueled power plant, BECCS works like this:&lt;/p&gt;&lt;p&gt;A tree captures carbon dioxide from the atmosphere as it grows, sequestering the carbon in its bark, trunk, branches, and roots while releasing the oxygen. Someone then cuts it down, converts it into wood pellets, and delivers it to a power plant that, in turn, burns the wood to produce heat or electricity.&lt;/p&gt;  &lt;p&gt;Usually, that facility will produce carbon dioxide as the wood incinerates. But under both European Union and US rules, the burning of the wood is generally treated as carbon neutral, so long as the timber forests are managed in sustainable ways and the various operations abide by other regulations. The argument is that the tree pulled CO&lt;sub&gt;2&lt;/sub&gt; out of the air in the first place, and new plant growth will bring that emissions debt back into balance over time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If that same power plant now captures a significant share of the greenhouse gas produced in the process and pumps it underground, the process can potentially go from carbon neutral to carbon negative.&lt;/p&gt;  &lt;p&gt;But the starting assumption that biomass is carbon neutral is fundamentally flawed, because it doesn’t fully take into account other ways that emissions are released throughout the process, according to Searchinger.&lt;/p&gt; 

 &lt;p&gt;Among other things, a proper analysis must also ask: How much carbon is left behind in roots or branches on the forest floor that will begin to decompose and release greenhouse gases after the plant is removed? How much fossil fuel was burned in the process of cutting, collecting, and distributing the biomass? How much greenhouse gas was produced while converting timber into wood pellets and shipping them elsewhere? And how long will it take to grow back the trees or plants that would have otherwise continued capturing and storing carbon?&lt;/p&gt;  &lt;p&gt;“If you’re harvesting wood, it’s essentially impossible to get negative emissions,” Searchinger says.&lt;/p&gt;  &lt;p&gt;Burning biomass, or the biofuels created from it, can also produce other forms of pollution that can harm human health, including particulate matter, volatile organic compounds, sulfur dioxide, and carbon monoxide.&lt;/p&gt;  &lt;p&gt;Preventing carbon dioxide emissions at a given factory may necessitate capturing certain other pollutants as well, notably sulfur dioxide. But it doesn’t necessarily filter out all the other pollution floating out of the flue stack, notes Emily Grubert, an associate professor of sustainable energy policy at the University of Notre Dame who focuses on carbon management issues and the transition away from fossil fuels.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;Driving demand&lt;/h3&gt;  &lt;p&gt;The idea that we might be able to use biomass to generate energy and suck down carbon dates back decades. But as global temperatures and emissions both continued to rise, climate modelers found that more and more BECCS or other types of carbon removal would be needed to prevent the planet from tipping past increasingly dangerous warming thresholds.&lt;/p&gt;  &lt;p&gt;In addition to dramatic cuts in emissions, the world may need to suck down 11 billion tons of carbon dioxide per year by 2050 and 20 billion by 2100 to limit warming to 2 °C over preindustrial levels, according to a 2022 UN climate panel report. That’s a threshold we’re increasingly likely to blow past.&lt;/p&gt;  &lt;p&gt;These grave climate warnings sparked growing interest and investments in ways to draw carbon dioxide out of the atmosphere. Companies sprang up offering to sink seaweed, bury biomass, develop carbon-sucking direct air capture factories, and add alkaline substances to agricultural fields or the oceans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But BECCS purchases have dwarfed those other approaches.&lt;/p&gt; 
   &lt;p&gt;For companies with fast-approaching climate deadlines, BECCS is one of the few options for removing hundreds of thousands of tons over the next few years, says Robert Höglund, who cofounded CDR.fyi, ​​a public-benefit corporation that analyzes the carbon removal sector.&lt;/p&gt;  &lt;p&gt;“If you have a target you want to meet in 2030 and you want durable carbon removal, that’s the thing you can buy,” he says.&lt;/p&gt; 
 &lt;p&gt;That’s chiefly because these projects can harness the infrastructure of existing industries. At least for now, you don’t have to finance, permit, and develop new facilities.&lt;/p&gt;  &lt;p&gt;“They’re not that hard to build, because it’s often a retrofitting of an existing plant,” Höglund says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;BECCS is also substantially less expensive for buyers than, say, direct air capture, with weighted average prices of $210 a ton compared with $490 among the deals to date, according to CDR.fyi. That’s in part because capturing the carbon dioxide from, say, a pulp and paper mill, where it makes up around 15% of flue gas, takes far less energy than plucking CO&lt;sub&gt;2&lt;/sub&gt; molecules out of the open air, where they account for just 0.04%.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Microsoft’s big BECCS bet&lt;/h3&gt;  &lt;p&gt;In 2020, Microsoft announced plans to become carbon negative by the end of this decade and, by midcentury, to remove all the emissions the company generated directly and from electricity use throughout its corporate history.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s leaning particularly heavily on BECCS to meet those climate commitments, with the category accounting for 76% of its known carbon removal purchases to date.&lt;/p&gt;  &lt;p&gt;In April, the company announced it would purchase 3.7 million tons of carbon dioxide that a paper and pulp mill, located at some unspecified site in the southern US, will eventually capture and store over a 12-year period. It reached the deal through CO280, a startup based in Vancouver, British Columbia, that is forming joint ventures with paper and pulp mill companies in the US and Canada, to finance, develop, and operate the projects.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It was the biggest carbon removal purchase on record—until four days later, when Microsoft revealed it had agreed to buy 6.75 million tons of carbon removal from AtmosClear, CDR.fyi noted. That company is building a biomass power plant at the Port of Greater Baton Rouge in Louisiana, which will run largely on sugarcane bagasse (a by-product of sugar production) and forest trimmings. AtmosClear says the facility will be able to capture 680,000 tons of carbon dioxide per year.&lt;/p&gt;  &lt;p&gt;“What we’ve seen is a lot of these BECCS projects have been very helpful, if not transformational, for providing investment in rural economies,” Marrs says. “We look at our BECCS deals, in Louisiana with AtmosClear and some other Gulf State providers, like CO280, as a real means of helping support these economies, while at the same time promoting sustainable forestry practices.”&lt;/p&gt;  &lt;p&gt;In earlier quarters, Microsoft also made substantial purchases from Orsted, which operates power plants that burn wood pellets; Gaia, which runs facilities that convert municipal waste into energy; and Arbor, whose plants are fueled by “overgrown brush, crop residues, and food waste.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Don’t let waste go to waste&lt;/h3&gt;  &lt;p&gt;Notably, at least three of these projects rely on some form of waste, a category distinct from fresh-cut timber or crops grown for the purpose of fueling BECCS projects. Solid waste, agricultural residues, logging leftovers, and plant material removed from forests to prevent fires present some of the ripest opportunities for BECCS—as well as some difficult questions of carbon accounting.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;A 2019 report from the National Academy of Sciences estimated that the US could achieve more than 500 million tons of carbon removal a year through BECCS by 2040, while the world could exceed 3.5 billion tons, by relying just on agricultural by-products, logging residues, and organic waste—without needing to grow crops dedicated to energy.&lt;/p&gt;  &lt;p&gt;Roger Aines, chief scientist of the energy program at Lawrence Livermore National Laboratory, argues we should at least be putting these sources to use rather than burning them or leaving them to decompose in fields. (Aines coauthored a similar analysis focused on California’s waste biomass and contributed to a 2022 lab report prepared for Microsoft to evaluate costs and options for carbon removal purchases.)&lt;/p&gt;  &lt;p&gt;He stresses that the BECCS sector can learn a lot from using that waste material. For example, it should help to provide a sharper sense of whether the carbon math will work if more land, forests, and crops are dedicated to these sorts of purposes.&lt;/p&gt;  &lt;p&gt;“The point is you won’t grow new material to do this in most cases, and won’t have to for a very long time, because there’s so much waste available,” Aines says. “If we get to that point, long into the future, we can address that then.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Wonky accounting&lt;/h3&gt;  &lt;p&gt;But the critical question that emerges with waste is: Would it otherwise have been burned or allowed to decompose, or might some of it have been used in some other way that kept the carbon out of the atmosphere?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Sugarcane bagasse, for instance, is or could also be used to produce recyclable packaging and paper, biodegradable food packaging and cutlery, building materials, or soil amendments that add nutrients back to agricultural fields.&lt;/p&gt;  &lt;p&gt;“A lot of the time those materials are being used for something else already, so the accounting gets wonky really quickly,” Grubert says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some fear that the financial incentives to pursue BECCS could also compel companies to trim away more trees and plants than is truly necessary to, say, manage forests or prevent fires—particularly as more and more BECCS plants create greater and greater demand for the limited supplies of such materials.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;“Once you start capturing waste, you create an incentive to produce waste, so you have to be very careful about the perverse incentives,” says Danny Cullenward, a researcher and senior fellow at the Kleinman Center for Energy Policy at the University of Pennsylvania who studies carbon markets.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Due diligence&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Like other big tech companies, Microsoft has lost some momentum when it comes to its climate goals, in large part because of the surging energy demands of its AI data centers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the company has generally earned a reputation for striving to clean up its direct emissions where possible and for seeking out high-quality approaches to carbon removal. It has consulted extensively with critically minded researchers at advisory firms like Carbon Direct and demonstrated a willingness to pay higher prices to support more credible projects.&lt;/p&gt;  &lt;p&gt;Marrs says the company has extended that scrutiny to its BECCS deals.&lt;/p&gt;  &lt;p&gt;“We want as much positive environmental impact as possible from every project,” he says.&lt;/p&gt;  &lt;p&gt;“We’re doing months and months of technical due diligence with teams that visit the site, that interview stakeholders, that produce a report for us that we go through in depth with a third-party engineering provider or technical perspective provider,” he adds.&lt;/p&gt;  &lt;p&gt;In a follow-up statement, Microsoft stressed that it strives to validate that every BECCS project it supports will achieve negative emissions, whatever the fuel source.&lt;/p&gt;  &lt;p&gt;“Across all of these projects, we conducted substantial due diligence to ensure that BECCS feedstocks would otherwise return carbon to the atmosphere in a few years,” the company said.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;Likewise, Jonathan Rhone, the cofounder and chief executive of CO280, stresses that they’ve worked with consultants, carbon market registries, and pulp and paper mills “to make sure we’re adopting the best standards.” He says they strive to conservatively assess the release and uptake of greenhouse gases across the supply chain of the mills they work with, taking into account the type of biomass used by a given plant, the growth rate of the forests it’s harvested from, the distance trucks drive to ship the timber or sawmill residues, the total emissions of the facility, and more.&lt;/p&gt;  &lt;p&gt;Rhone says its typical projects will capture and store away on the order of 850,000 to 900,000 tons of carbon dioxide per year. How much that would make up of the plant’s total emissions would vary, based in part on how much of the facility’s energy comes from by-product biomatter and how much comes from fossil fuels. For its first projects, the company will aim to capture 50% to 65% of the CO&lt;sub&gt;2&lt;/sub&gt; emissions at the pulp and paper mills, but it eventually hopes to exceed 90%.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a follow-up email, Rhone said the carbon capture equipment at the mills it works with will also prevent “substantial levels” of particulate matter and sulfur dioxide emissions and might reduce emissions of other pollutants as well.&lt;/p&gt;  &lt;p&gt;The company is in active discussions with 10 pulp and paper mills in the Gulf Coast and Canada. Each carbon capture and storage project could cost hundreds of millions of dollars.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“What we’re trying to do at CO280 is show and demonstrate that we can create a stable, repeatable playbook for developing projects that are low risk and provide the market with what it wants, with what it needs,” Rhone says.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Proponents of BECCS say we could leverage biomass to deliver substantial volumes of carbon removal, so long as appropriate industry standards are put in place to prevent, or at least minimize, bad behavior.&lt;/p&gt;  &lt;p&gt;The question is whether that will be the case—or whether, as the BECCS sector matures, it will veer closer to the pattern of carbon offset markets.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Studies and investigations have consistently shown that loosely regulated or poorly designed carbon credit and offset programs have allowed, if not invited, companies to significantly exaggerate the climate benefits of tree planting, forest preservation, and similar projects.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;“It appears to me to be something that will be manageable but that we’ll always have to keep an eye on,” Aines says.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Magic&lt;/h3&gt;  &lt;p&gt;Even with all these carbon accounting complexities, BECCS projects can often deliver climate benefits, particularly for existing plants.&lt;/p&gt;  &lt;p&gt;Adding carbon capture to an operating paper and pulp mill, power plant, or refinery is at least an improvement over the status quo from a climate perspective, insofar as it prevents emissions that would otherwise have continued.&lt;/p&gt;  &lt;p&gt;But ambitions for BECCS are already growing beyond existing plants: Last year Drax, the controversial UK power giant, announced plans to launch a Houston-based division tasked with developing enough new BECCS projects to deliver 6 million tons of carbon removal per year, in the US or elsewhere.&lt;/p&gt;  &lt;p&gt;Numerous other companies have also built or proposed biomass power plants in recent years, with or without carbon capture systems—decisions driven in part by policies that classify them as carbon neutral.&lt;/p&gt;&lt;p&gt;But if biomass &lt;em&gt;isn’t &lt;/em&gt;carbon neutral, as Searchinger and others argue it can’t be in many applications, then these new unfiltered power plants are just adding more emissions to the atmosphere—and BECCS projects aren’t drawing any out of the air. And if that’s the case, it raises tough questions about corporate climate claims that depend on its doing so and the societal trade-offs involved in building lots of new plants dedicated to these purposes.&lt;/p&gt;  &lt;p&gt;That’s because crops grown for energy require land, fertilizer, insecticides, and human labor that might otherwise go toward producing food for an expanding global population. And greater demand for wood invites the timber industry to chop down more and more of the world’s forests, which are already sucking up and storing away vast amounts of carbon dioxide and providing homes for immense varieties of plants and animals.&lt;/p&gt;  &lt;p&gt;If these projects are merely preventing greenhouse gas from floating into the atmosphere but not drawing any down, we’re better off adding carbon capture and storage (CCS) equipment to an existing natural-gas plant instead, Searchinger argues.&lt;/p&gt;  &lt;p&gt;Companies may think that harnessing nature to draw carbon dioxide out of the sky sounds better than cutting the emissions of a fossil-fuel turbine. But the electricity from the latter plant would cost dramatically less, the carbon capture system would reduce emissions more for the amount of same energy generated, and it would avoid the added pressures to cut down trees, he says.&lt;/p&gt;  &lt;p&gt;“People think some magic happens—this magic combination of using biomass and CCS creates something bigger than its parts,” Searchinger says. “But it’s not magic; it’s simply the sum of the two.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/AP24203458670422.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Over the last century, much of the US pulp and paper industry crowded into the southeastern corner of the nation, setting up mills amid sprawling timber forests to strip the fibers from juvenile loblolly, long leaf, and slash pine trees.&lt;/p&gt;  &lt;p&gt;Today, after the factories chip the softwood and digest it into pulp, the leftover lignin, spent chemicals, and remaining organic matter form a dark, syrupy by-product known as black liquor. It’s then concentrated into a biofuel and burned, which heats the towering boilers that power the facility—and releases carbon dioxide into the air.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Microsoft, JP MorganChase, and a tech company consortium that includes Alphabet, Meta, Shopify, and Stripe have all recently struck multimillion-dollar deals to pay paper mill owners to capture at least hundreds of thousands of tons of this greenhouse gas by installing carbon scrubbing equipment in their facilities.&lt;/p&gt;  &lt;p&gt;The captured carbon dioxide will then be piped down into saline aquifers more than a mile underground, where it should be sequestered permanently.&lt;/p&gt; 
 &lt;p&gt;Big Tech is suddenly betting big on this form of carbon removal, known as bioenergy with carbon capture and storage, or BECCS. The sector also includes biomass-fueled power plants, waste incinerators, and biofuel refineries that add carbon capturing equipment to their facilities.&lt;/p&gt;&lt;p&gt;Since trees and other plants absorb carbon dioxide through photosynthesis and these factories will trap emissions that would have gone into the air, together they can theoretically remove more greenhouse gas from the atmosphere than was released, achieving what’s known as “negative emissions.”&lt;/p&gt;  &lt;p&gt;The companies that pay for this removal can apply that reduction in carbon dioxide to cancel out a share of their own corporate pollution. BECCS now accounts for nearly 70% of the announced contracts in carbon removal, a popularity due largely to the fact that it can be tacked onto industrial facilities already operating on large scales.&lt;/p&gt; 
 &lt;p&gt;“If we’re balancing cost, time to market, and ultimate scale potential, BECCS offers a really attractive value proposition across all three of those,” says Brian Marrs, senior director of energy and carbon removal at Microsoft, which has become by far the largest buyer of carbon removal credits as it races to balance out its ongoing emissions by the end of the decade.&lt;/p&gt;  &lt;p&gt;But experts have raised a number of concerns about various approaches to BECCS, stressing they may inflate the climate benefits of the projects, conflate prevented emissions with carbon removal, and extend the life of facilities that pollute in other ways. It could also create greater financial incentives to log forests or convert them to agricultural land.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;When greenhouse-gas sources and sinks are properly tallied across all the fields, forests, and factories involved, it’s highly difficult to achieve negative emissions with many approaches to BECCS, says Tim Searchinger, a senior research scholar at Princeton University. That undermines the logic of dedicating more of the world’s limited land, crops, and woods to such projects, he argues.&lt;/p&gt;  &lt;p&gt;“I call it a ‘BECCS and switch,’” he says, adding later: “It’s folly at some level.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;The logic of BECCS&lt;/h3&gt;  &lt;p&gt;For a biomass-fueled power plant, BECCS works like this:&lt;/p&gt;&lt;p&gt;A tree captures carbon dioxide from the atmosphere as it grows, sequestering the carbon in its bark, trunk, branches, and roots while releasing the oxygen. Someone then cuts it down, converts it into wood pellets, and delivers it to a power plant that, in turn, burns the wood to produce heat or electricity.&lt;/p&gt;  &lt;p&gt;Usually, that facility will produce carbon dioxide as the wood incinerates. But under both European Union and US rules, the burning of the wood is generally treated as carbon neutral, so long as the timber forests are managed in sustainable ways and the various operations abide by other regulations. The argument is that the tree pulled CO&lt;sub&gt;2&lt;/sub&gt; out of the air in the first place, and new plant growth will bring that emissions debt back into balance over time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If that same power plant now captures a significant share of the greenhouse gas produced in the process and pumps it underground, the process can potentially go from carbon neutral to carbon negative.&lt;/p&gt;  &lt;p&gt;But the starting assumption that biomass is carbon neutral is fundamentally flawed, because it doesn’t fully take into account other ways that emissions are released throughout the process, according to Searchinger.&lt;/p&gt; 

 &lt;p&gt;Among other things, a proper analysis must also ask: How much carbon is left behind in roots or branches on the forest floor that will begin to decompose and release greenhouse gases after the plant is removed? How much fossil fuel was burned in the process of cutting, collecting, and distributing the biomass? How much greenhouse gas was produced while converting timber into wood pellets and shipping them elsewhere? And how long will it take to grow back the trees or plants that would have otherwise continued capturing and storing carbon?&lt;/p&gt;  &lt;p&gt;“If you’re harvesting wood, it’s essentially impossible to get negative emissions,” Searchinger says.&lt;/p&gt;  &lt;p&gt;Burning biomass, or the biofuels created from it, can also produce other forms of pollution that can harm human health, including particulate matter, volatile organic compounds, sulfur dioxide, and carbon monoxide.&lt;/p&gt;  &lt;p&gt;Preventing carbon dioxide emissions at a given factory may necessitate capturing certain other pollutants as well, notably sulfur dioxide. But it doesn’t necessarily filter out all the other pollution floating out of the flue stack, notes Emily Grubert, an associate professor of sustainable energy policy at the University of Notre Dame who focuses on carbon management issues and the transition away from fossil fuels.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;Driving demand&lt;/h3&gt;  &lt;p&gt;The idea that we might be able to use biomass to generate energy and suck down carbon dates back decades. But as global temperatures and emissions both continued to rise, climate modelers found that more and more BECCS or other types of carbon removal would be needed to prevent the planet from tipping past increasingly dangerous warming thresholds.&lt;/p&gt;  &lt;p&gt;In addition to dramatic cuts in emissions, the world may need to suck down 11 billion tons of carbon dioxide per year by 2050 and 20 billion by 2100 to limit warming to 2 °C over preindustrial levels, according to a 2022 UN climate panel report. That’s a threshold we’re increasingly likely to blow past.&lt;/p&gt;  &lt;p&gt;These grave climate warnings sparked growing interest and investments in ways to draw carbon dioxide out of the atmosphere. Companies sprang up offering to sink seaweed, bury biomass, develop carbon-sucking direct air capture factories, and add alkaline substances to agricultural fields or the oceans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But BECCS purchases have dwarfed those other approaches.&lt;/p&gt; 
   &lt;p&gt;For companies with fast-approaching climate deadlines, BECCS is one of the few options for removing hundreds of thousands of tons over the next few years, says Robert Höglund, who cofounded CDR.fyi, ​​a public-benefit corporation that analyzes the carbon removal sector.&lt;/p&gt;  &lt;p&gt;“If you have a target you want to meet in 2030 and you want durable carbon removal, that’s the thing you can buy,” he says.&lt;/p&gt; 
 &lt;p&gt;That’s chiefly because these projects can harness the infrastructure of existing industries. At least for now, you don’t have to finance, permit, and develop new facilities.&lt;/p&gt;  &lt;p&gt;“They’re not that hard to build, because it’s often a retrofitting of an existing plant,” Höglund says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;BECCS is also substantially less expensive for buyers than, say, direct air capture, with weighted average prices of $210 a ton compared with $490 among the deals to date, according to CDR.fyi. That’s in part because capturing the carbon dioxide from, say, a pulp and paper mill, where it makes up around 15% of flue gas, takes far less energy than plucking CO&lt;sub&gt;2&lt;/sub&gt; molecules out of the open air, where they account for just 0.04%.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Microsoft’s big BECCS bet&lt;/h3&gt;  &lt;p&gt;In 2020, Microsoft announced plans to become carbon negative by the end of this decade and, by midcentury, to remove all the emissions the company generated directly and from electricity use throughout its corporate history.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s leaning particularly heavily on BECCS to meet those climate commitments, with the category accounting for 76% of its known carbon removal purchases to date.&lt;/p&gt;  &lt;p&gt;In April, the company announced it would purchase 3.7 million tons of carbon dioxide that a paper and pulp mill, located at some unspecified site in the southern US, will eventually capture and store over a 12-year period. It reached the deal through CO280, a startup based in Vancouver, British Columbia, that is forming joint ventures with paper and pulp mill companies in the US and Canada, to finance, develop, and operate the projects.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It was the biggest carbon removal purchase on record—until four days later, when Microsoft revealed it had agreed to buy 6.75 million tons of carbon removal from AtmosClear, CDR.fyi noted. That company is building a biomass power plant at the Port of Greater Baton Rouge in Louisiana, which will run largely on sugarcane bagasse (a by-product of sugar production) and forest trimmings. AtmosClear says the facility will be able to capture 680,000 tons of carbon dioxide per year.&lt;/p&gt;  &lt;p&gt;“What we’ve seen is a lot of these BECCS projects have been very helpful, if not transformational, for providing investment in rural economies,” Marrs says. “We look at our BECCS deals, in Louisiana with AtmosClear and some other Gulf State providers, like CO280, as a real means of helping support these economies, while at the same time promoting sustainable forestry practices.”&lt;/p&gt;  &lt;p&gt;In earlier quarters, Microsoft also made substantial purchases from Orsted, which operates power plants that burn wood pellets; Gaia, which runs facilities that convert municipal waste into energy; and Arbor, whose plants are fueled by “overgrown brush, crop residues, and food waste.”&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Don’t let waste go to waste&lt;/h3&gt;  &lt;p&gt;Notably, at least three of these projects rely on some form of waste, a category distinct from fresh-cut timber or crops grown for the purpose of fueling BECCS projects. Solid waste, agricultural residues, logging leftovers, and plant material removed from forests to prevent fires present some of the ripest opportunities for BECCS—as well as some difficult questions of carbon accounting.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;A 2019 report from the National Academy of Sciences estimated that the US could achieve more than 500 million tons of carbon removal a year through BECCS by 2040, while the world could exceed 3.5 billion tons, by relying just on agricultural by-products, logging residues, and organic waste—without needing to grow crops dedicated to energy.&lt;/p&gt;  &lt;p&gt;Roger Aines, chief scientist of the energy program at Lawrence Livermore National Laboratory, argues we should at least be putting these sources to use rather than burning them or leaving them to decompose in fields. (Aines coauthored a similar analysis focused on California’s waste biomass and contributed to a 2022 lab report prepared for Microsoft to evaluate costs and options for carbon removal purchases.)&lt;/p&gt;  &lt;p&gt;He stresses that the BECCS sector can learn a lot from using that waste material. For example, it should help to provide a sharper sense of whether the carbon math will work if more land, forests, and crops are dedicated to these sorts of purposes.&lt;/p&gt;  &lt;p&gt;“The point is you won’t grow new material to do this in most cases, and won’t have to for a very long time, because there’s so much waste available,” Aines says. “If we get to that point, long into the future, we can address that then.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Wonky accounting&lt;/h3&gt;  &lt;p&gt;But the critical question that emerges with waste is: Would it otherwise have been burned or allowed to decompose, or might some of it have been used in some other way that kept the carbon out of the atmosphere?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Sugarcane bagasse, for instance, is or could also be used to produce recyclable packaging and paper, biodegradable food packaging and cutlery, building materials, or soil amendments that add nutrients back to agricultural fields.&lt;/p&gt;  &lt;p&gt;“A lot of the time those materials are being used for something else already, so the accounting gets wonky really quickly,” Grubert says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some fear that the financial incentives to pursue BECCS could also compel companies to trim away more trees and plants than is truly necessary to, say, manage forests or prevent fires—particularly as more and more BECCS plants create greater and greater demand for the limited supplies of such materials.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;“Once you start capturing waste, you create an incentive to produce waste, so you have to be very careful about the perverse incentives,” says Danny Cullenward, a researcher and senior fellow at the Kleinman Center for Energy Policy at the University of Pennsylvania who studies carbon markets.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Due diligence&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Like other big tech companies, Microsoft has lost some momentum when it comes to its climate goals, in large part because of the surging energy demands of its AI data centers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the company has generally earned a reputation for striving to clean up its direct emissions where possible and for seeking out high-quality approaches to carbon removal. It has consulted extensively with critically minded researchers at advisory firms like Carbon Direct and demonstrated a willingness to pay higher prices to support more credible projects.&lt;/p&gt;  &lt;p&gt;Marrs says the company has extended that scrutiny to its BECCS deals.&lt;/p&gt;  &lt;p&gt;“We want as much positive environmental impact as possible from every project,” he says.&lt;/p&gt;  &lt;p&gt;“We’re doing months and months of technical due diligence with teams that visit the site, that interview stakeholders, that produce a report for us that we go through in depth with a third-party engineering provider or technical perspective provider,” he adds.&lt;/p&gt;  &lt;p&gt;In a follow-up statement, Microsoft stressed that it strives to validate that every BECCS project it supports will achieve negative emissions, whatever the fuel source.&lt;/p&gt;  &lt;p&gt;“Across all of these projects, we conducted substantial due diligence to ensure that BECCS feedstocks would otherwise return carbon to the atmosphere in a few years,” the company said.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;Likewise, Jonathan Rhone, the cofounder and chief executive of CO280, stresses that they’ve worked with consultants, carbon market registries, and pulp and paper mills “to make sure we’re adopting the best standards.” He says they strive to conservatively assess the release and uptake of greenhouse gases across the supply chain of the mills they work with, taking into account the type of biomass used by a given plant, the growth rate of the forests it’s harvested from, the distance trucks drive to ship the timber or sawmill residues, the total emissions of the facility, and more.&lt;/p&gt;  &lt;p&gt;Rhone says its typical projects will capture and store away on the order of 850,000 to 900,000 tons of carbon dioxide per year. How much that would make up of the plant’s total emissions would vary, based in part on how much of the facility’s energy comes from by-product biomatter and how much comes from fossil fuels. For its first projects, the company will aim to capture 50% to 65% of the CO&lt;sub&gt;2&lt;/sub&gt; emissions at the pulp and paper mills, but it eventually hopes to exceed 90%.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In a follow-up email, Rhone said the carbon capture equipment at the mills it works with will also prevent “substantial levels” of particulate matter and sulfur dioxide emissions and might reduce emissions of other pollutants as well.&lt;/p&gt;  &lt;p&gt;The company is in active discussions with 10 pulp and paper mills in the Gulf Coast and Canada. Each carbon capture and storage project could cost hundreds of millions of dollars.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“What we’re trying to do at CO280 is show and demonstrate that we can create a stable, repeatable playbook for developing projects that are low risk and provide the market with what it wants, with what it needs,” Rhone says.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Proponents of BECCS say we could leverage biomass to deliver substantial volumes of carbon removal, so long as appropriate industry standards are put in place to prevent, or at least minimize, bad behavior.&lt;/p&gt;  &lt;p&gt;The question is whether that will be the case—or whether, as the BECCS sector matures, it will veer closer to the pattern of carbon offset markets.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Studies and investigations have consistently shown that loosely regulated or poorly designed carbon credit and offset programs have allowed, if not invited, companies to significantly exaggerate the climate benefits of tree planting, forest preservation, and similar projects.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt;&lt;p&gt;“It appears to me to be something that will be manageable but that we’ll always have to keep an eye on,” Aines says.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Magic&lt;/h3&gt;  &lt;p&gt;Even with all these carbon accounting complexities, BECCS projects can often deliver climate benefits, particularly for existing plants.&lt;/p&gt;  &lt;p&gt;Adding carbon capture to an operating paper and pulp mill, power plant, or refinery is at least an improvement over the status quo from a climate perspective, insofar as it prevents emissions that would otherwise have continued.&lt;/p&gt;  &lt;p&gt;But ambitions for BECCS are already growing beyond existing plants: Last year Drax, the controversial UK power giant, announced plans to launch a Houston-based division tasked with developing enough new BECCS projects to deliver 6 million tons of carbon removal per year, in the US or elsewhere.&lt;/p&gt;  &lt;p&gt;Numerous other companies have also built or proposed biomass power plants in recent years, with or without carbon capture systems—decisions driven in part by policies that classify them as carbon neutral.&lt;/p&gt;&lt;p&gt;But if biomass &lt;em&gt;isn’t &lt;/em&gt;carbon neutral, as Searchinger and others argue it can’t be in many applications, then these new unfiltered power plants are just adding more emissions to the atmosphere—and BECCS projects aren’t drawing any out of the air. And if that’s the case, it raises tough questions about corporate climate claims that depend on its doing so and the societal trade-offs involved in building lots of new plants dedicated to these purposes.&lt;/p&gt;  &lt;p&gt;That’s because crops grown for energy require land, fertilizer, insecticides, and human labor that might otherwise go toward producing food for an expanding global population. And greater demand for wood invites the timber industry to chop down more and more of the world’s forests, which are already sucking up and storing away vast amounts of carbon dioxide and providing homes for immense varieties of plants and animals.&lt;/p&gt;  &lt;p&gt;If these projects are merely preventing greenhouse gas from floating into the atmosphere but not drawing any down, we’re better off adding carbon capture and storage (CCS) equipment to an existing natural-gas plant instead, Searchinger argues.&lt;/p&gt;  &lt;p&gt;Companies may think that harnessing nature to draw carbon dioxide out of the sky sounds better than cutting the emissions of a fossil-fuel turbine. But the electricity from the latter plant would cost dramatically less, the carbon capture system would reduce emissions more for the amount of same energy generated, and it would avoid the added pressures to cut down trees, he says.&lt;/p&gt;  &lt;p&gt;“People think some magic happens—this magic combination of using biomass and CCS creates something bigger than its parts,” Searchinger says. “But it’s not magic; it’s simply the sum of the two.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/15/1125715/big-techs-big-bet-on-a-controversial-carbon-removal-tactic/</guid><pubDate>Wed, 15 Oct 2025 09:00:00 +0000</pubDate></item><item><title>Dfinity launches Caffeine, an AI platform that builds production apps from natural language prompts (AI | VentureBeat)</title><link>https://venturebeat.com/ai/dfinity-launches-caffeine-an-ai-platform-that-builds-production-apps-from</link><description>[unable to retrieve full-text content]&lt;p&gt;The &lt;a href="https://dfinity.org/"&gt;&lt;u&gt;Dfinity Foundation&lt;/u&gt;&lt;/a&gt; on Wednesday released &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt;, an artificial intelligence platform that allows users to build and deploy web applications through natural language conversation alone, bypassing traditional coding entirely. The system, which became publicly available today, represents a fundamental departure from existing AI coding assistants by building applications on a specialized decentralized infrastructure designed specifically for autonomous AI development.&lt;/p&gt;&lt;p&gt;Unlike &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://cursor.com/"&gt;&lt;u&gt;Cursor&lt;/u&gt;&lt;/a&gt;, or other &amp;quot;vibe coding&amp;quot; tools that help human developers write code faster, Caffeine positions itself as a complete replacement for technical teams. Users describe what they want in plain language, and an ensemble of AI models writes, deploys, and continually updates production-grade applications — with no human intervention in the codebase itself.&lt;/p&gt;&lt;p&gt;&amp;quot;In the future, you as a prospective app owner or service owner… will talk to AI. AI will give you what you want on a URL,&amp;quot; said Dominic Williams, founder and chief scientist at the Dfinity Foundation, in an exclusive interview with VentureBeat. &amp;quot;You will use that, completely interact productively, and you&amp;#x27;ll just keep talking to AI to evolve what that does. The AI, or an ensemble of AIs, will be your tech team.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform has attracted significant early interest: more than 15,000 alpha users tested Caffeine before its public release, with daily active users representing 26% of those who received access codes — &amp;quot;early Facebook kind of levels,&amp;quot; according to Williams. The foundation reports some users spending entire days building applications on the platform, forcing Dfinity to consider usage limits due to underlying AI infrastructure costs.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Caffeine&amp;#x27;s custom programming language guarantees your data won&amp;#x27;t disappear&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Caffeine&amp;#x27;s most significant technical claim addresses a problem that has plagued AI-generated code: data loss during application updates. The platform builds applications using &lt;a href="https://internetcomputer.org/docs/motoko/home"&gt;&lt;u&gt;Motoko&lt;/u&gt;&lt;/a&gt;, a programming language developed by Dfinity specifically for AI use, which provides mathematical guarantees that upgrades cannot accidentally delete user data.&lt;/p&gt;&lt;p&gt;&amp;quot;When AI is updating apps and services in production, a mistake cannot lose data. That&amp;#x27;s a guarantee,&amp;quot; Williams said. &amp;quot;It&amp;#x27;s not like there are some safeguards to try and stop it losing data. This language framework gives it rails that guarantee if an upgrade, an update to its app&amp;#x27;s underlying logic, would cause data loss, the upgrade fails and the AI just tries again.&amp;quot;&lt;/p&gt;&lt;p&gt;This addresses what Williams characterizes as critical failures in competing platforms. User forums for tools like &lt;a href="https://lovable.dev/"&gt;&lt;u&gt;Lovable&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://replit.com/"&gt;&lt;u&gt;Replit&lt;/u&gt;&lt;/a&gt;, he notes, frequently report three major problems: applications that become irreparably broken as complexity increases, security vulnerabilities that allow unauthorized access, and mysterious data loss during updates.&lt;/p&gt;&lt;p&gt;Traditional tech stacks evolved to meet human developer needs — familiarity with SQL databases, preference for known programming languages, existing skill investments. &amp;quot;That&amp;#x27;s how the traditional tech stacks evolved. It&amp;#x27;s really evolved to meet human needs,&amp;quot; Williams explained. &amp;quot;But in the future, it&amp;#x27;s going to be different. You&amp;#x27;re not going to care how the AI did it. Instead, for you, AI is the tech stack.&amp;quot;&lt;/p&gt;&lt;p&gt;Caffeine&amp;#x27;s architecture reflects this philosophy. Applications run entirely on the &lt;a href="https://internetcomputer.org/"&gt;&lt;u&gt;Internet Computer Protocol (ICP)&lt;/u&gt;&lt;/a&gt;, a blockchain-based network that Dfinity launched in May 2021 after raising over $100 million from investors including &lt;a href="https://a16z.com/dfinity/"&gt;&lt;u&gt;Andreessen Horowitz&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://techcrunch.com/2018/08/29/dfinity/"&gt;&lt;u&gt;Polychain Capital&lt;/u&gt;&lt;/a&gt;. The ICP uses what Dfinity calls &amp;quot;chain-key cryptography&amp;quot; to create what Williams describes as &amp;quot;tamper-proof&amp;quot; code — applications that are mathematically guaranteed to execute their written logic without interference from traditional cyberattacks.&lt;/p&gt;&lt;p&gt;&amp;quot;The code can&amp;#x27;t be affected by ransomware, so you don&amp;#x27;t have to worry about malware in the same way you do,&amp;quot; Williams said. &amp;quot;Configuration errors don&amp;#x27;t result in traditional cyber attacks. That passive traditional cyber attacks isn&amp;#x27;t something you need to worry about.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How &amp;#x27;orthogonal persistence&amp;#x27; lets AI build apps without managing databases&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;At the heart of Caffeine&amp;#x27;s technical approach is a concept called &amp;quot;&lt;a href="https://internetcomputer.org/docs/motoko/fundamentals/actors/orthogonal-persistence/"&gt;&lt;u&gt;orthogonal persistence&lt;/u&gt;&lt;/a&gt;,&amp;quot; which fundamentally reimagines how applications store and manage data. In traditional development, programmers must write extensive code to move data between application logic and separate database systems — marshaling data in and out of SQL servers, managing connections, handling synchronization.&lt;/p&gt;&lt;p&gt;&lt;a href="https://internetcomputer.org/docs/motoko/home"&gt;&lt;u&gt;Motoko&lt;/u&gt;&lt;/a&gt; eliminates this entirely. Williams demonstrated with a simple example: defining a blog post data type and declaring a variable to store an array of posts requires just two lines of code. &amp;quot;This declaration is all that&amp;#x27;s necessary to have the blog maintain its list of posts,&amp;quot; he explained during a presentation on the technology. &amp;quot;Compare that to traditional IT where in order to persist the blog posts, you&amp;#x27;d have to marshal them in and out of a database server. This is quite literally orders of magnitude more simple.&amp;quot;&lt;/p&gt;&lt;p&gt;This abstraction allows AI to work at a higher conceptual level, focusing on application logic rather than infrastructure plumbing. &amp;quot;Logic and data are kind of the same,&amp;quot; Williams said. &amp;quot;This is one of the things that enables AI to build far more complicated functionality than it could otherwise do.&amp;quot;&lt;/p&gt;&lt;p&gt;The system also employs what Dfinity calls &amp;quot;loss-safe data migration.&amp;quot; When AI needs to modify an application&amp;#x27;s data structure — adding a &amp;quot;likes&amp;quot; field to blog posts, for example — it must write migration logic in two passes. The framework automatically verifies that the transformation won&amp;#x27;t result in data loss, refusing to compile or deploy code that could delete information unless explicitly instructed.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From million-dollar SaaS contracts to conversational app building in minutes&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Williams positions &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; as particularly transformative for enterprise IT, where he claims costs could fall to &amp;quot;1% of what they were before&amp;quot; while time-to-market shrinks to similar fractions. The platform targets a spectrum from individual creators to large corporations, all of whom currently face either expensive development teams or constraining low-code templates.&lt;/p&gt;&lt;p&gt;&amp;quot;A corporation or government department might want to create a corporate portal or CRM, ERP functionality,&amp;quot; Williams said, referring to customer relationship management and enterprise resource planning systems. &amp;quot;They will otherwise have to obtain this by signing up for some incredibly expensive SaaS service where they become locked in, their data gets stuck, and they still have to spend a lot of money on consultants customizing the functionality.&amp;quot;&lt;/p&gt;&lt;p&gt;Applications built through &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; are owned entirely by their creators and cannot be shut down by centralized parties — a consequence of running on the decentralized &lt;a href="https://internetcomputer.org/"&gt;&lt;u&gt;Internet Computer&lt;/u&gt;&lt;/a&gt; network rather than traditional cloud providers like &lt;a href="https://aws.amazon.com/free/?trk=48ebaf74-0ade-44c7-b8c2-12a0e7718d21&amp;amp;sc_channel=ps&amp;amp;ef_id=Cj0KCQjwjL3HBhCgARIsAPUg7a5jTV7r4lhg4v2_akcje7Hv2RgfrbNK3YJRonxmzg3lQnhP5Dtop_waAscnEALw_wcB:G:s&amp;amp;s_kwcid=AL!4422!3!651751059777!e!!g!!amazon%20web%20services!19852662197!145019195737&amp;amp;gad_campaignid=19852662197&amp;amp;gbraid=0AAAAADjHtp-sA3cSfcBU924i9KU_I-qMh&amp;amp;gclid=Cj0KCQjwjL3HBhCgARIsAPUg7a5jTV7r4lhg4v2_akcje7Hv2RgfrbNK3YJRonxmzg3lQnhP5Dtop_waAscnEALw_wcB"&gt;&lt;u&gt;Amazon Web Services&lt;/u&gt;&lt;/a&gt;. &amp;quot;When someone says built on the internet computer, it actually means built on the internet computer,&amp;quot; Williams emphasized, contrasting this with blockchain projects that merely host tokens while running actual applications on centralized infrastructure.&lt;/p&gt;&lt;p&gt;The platform demonstrated this versatility during a July 2025 hackathon in San Francisco, where participants created applications ranging from a &amp;quot;Will Maker&amp;quot; tool for generating legal documents, to &amp;quot;Blue Lens,&amp;quot; a voice-AI water quality monitoring system, to &amp;quot;Road Patrol,&amp;quot; a gamified community reporting app for infrastructure problems. Critically, many of these came from non-technical participants with no coding background.&lt;/p&gt;&lt;p&gt;&amp;quot;I&amp;#x27;m from a non-technical background, I&amp;#x27;m actually a quality assurance professional,&amp;quot; said the creator of Blue Lens in a video testimonial. &amp;quot;Through Caffeine I can build something really intuitive and next-gen to the public.&amp;quot; The application integrated multiple external services — Eleven Labs for voice AI, real-time government water data through retrieval-augmented generation, and Midjourney-generated visual assets — all coordinated through conversational prompts.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What separates Caffeine from GitHub Copilot, Cursor, and the &amp;#x27;vibe coding&amp;#x27; wave&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://caffeine.ai"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; enters a crowded market of AI-assisted development tools, but Williams argues the competition isn&amp;#x27;t truly comparable. &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://cursor.com/"&gt;&lt;u&gt;Cursor&lt;/u&gt;&lt;/a&gt;, and similar tools serve human developers working with traditional technology stacks. Platforms like &lt;a href="https://replit.com/"&gt;&lt;u&gt;Replit&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://lovable.dev/"&gt;&lt;u&gt;Lovable&lt;/u&gt;&lt;/a&gt; occupy a middle ground, offering &amp;quot;vibe coding&amp;quot; that mixes AI generation with human editing.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re a Node.js developer, you know you&amp;#x27;re working with the traditional stack, and you might want to do your coding with Copilot or using Claude or using Cursor,&amp;quot; Williams said. &amp;quot;That&amp;#x27;s a very different thing to what Caffeine is offering. There&amp;#x27;ll always be cases where you probably wouldn&amp;#x27;t want to hand over the logic of the control system for a new nuclear missile silo to AI. But there&amp;#x27;s going to be these holdout areas, right? And there&amp;#x27;s all the legacy stuff that has to be maintained.&amp;quot;&lt;/p&gt;&lt;p&gt;The key distinction, according to Williams, lies in production readiness. Existing AI coding tools excel at rapid prototyping but stumble when applications grow complex or require guaranteed reliability. Reddit forums for these platforms document users hitting insurmountable walls where applications break irreparably, or where AI-generated code introduces security vulnerabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;As the demands and the requirements become more complicated, eventually you can hit a limit, and when you hit that limit, not only can you not go any further, but sometimes your app will get broken and there&amp;#x27;s no way of going back to where you were before,&amp;quot; Williams said. &amp;quot;That can&amp;#x27;t happen with productive apps, and it also can&amp;#x27;t be the case that you&amp;#x27;re getting hacked and losing data, because once you go hands-free, if you like, and there&amp;#x27;s no tech team, there&amp;#x27;s no technical people involved, who&amp;#x27;s going to run the backups and restore your app?&amp;quot;&lt;/p&gt;&lt;p&gt;The Internet Computer&amp;#x27;s architecture addresses this through Byzantine fault tolerance — even if attackers gain physical control over some network hardware, they cannot corrupt applications or their data. &amp;quot;This is the beginning of a compute revolution and it&amp;#x27;s also the perfect platform for AI to build on,&amp;quot; Williams said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the vision: A web that programs itself through natural language&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Dfinity frames &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; within a broader vision it calls the &amp;quot;&lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;self-writing internet&lt;/u&gt;&lt;/a&gt;,&amp;quot; where the web literally programs itself through natural language interaction. This represents what Williams describes as a &amp;quot;seismic shift coming to tech&amp;quot; — from human developers selecting technology stacks based on their existing skills, to AI selecting optimal implementations invisible to users.&lt;/p&gt;&lt;p&gt;&amp;quot;You don&amp;#x27;t care about whether some human being has learned all of the different platforms and Amazon Web Services or something like that. You don&amp;#x27;t care about that. You just care: Is it secure? Do you get security guarantees? Is it resilient? What&amp;#x27;s the level of resilience?&amp;quot; Williams said. &amp;quot;Those are the new parameters.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform demonstrated this during live demonstrations, including at the &lt;a href="https://worldcomputer.com/"&gt;&lt;u&gt;World Computer Summit 2025&lt;/u&gt;&lt;/a&gt; in Zurich. Williams created a talent recruitment application from scratch in under two minutes, then modified it in real-time while the application ran with users already interacting with it. &amp;quot;You will continue talking to the AI and just keep on refreshing the URL to see the changes,&amp;quot; he explained.&lt;/p&gt;&lt;p&gt;This capability extends to complex scenarios. During demonstrations, Williams showed building a tennis lesson booking system, an e-commerce platform, and an event registration system — all simultaneously, working on multiple applications in parallel. &amp;quot;We predict that as people get very proficient with &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt;, they could be working on even 10 apps in parallel,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The system writes substantial code: a simple personal blog generated 700 lines of code in a couple of minutes. More complex applications can involve thousands of lines across frontend and backend components, all abstracted away from the user who only describes desired functionality.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The economics of cloning: How Caffeine&amp;#x27;s app market challenges traditional stores&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Caffeine&amp;#x27;s economic model differs fundamentally from traditional software-as-a-service platforms. Applications run on the &lt;a href="https://internetcomputer.org/"&gt;&lt;u&gt;Internet Computer Protocol&lt;/u&gt;&lt;/a&gt;, which uses a &amp;quot;reverse gas model&amp;quot; where developers pay for computation rather than users paying transaction fees. The platform includes an integrated App Market where creators can publish applications for others to clone and adapt — creating what Dfinity envisions as a new economic ecosystem.&lt;/p&gt;&lt;p&gt;&amp;quot;App stores today obviously operate on gatekeeping,&amp;quot; said Pierre Samaties, chief business officer at Dfinity, during the World Computer Summit. &amp;quot;That&amp;#x27;s going to erode.&amp;quot; Rather than purchasing applications, users can clone them and modify them for their own purposes — fundamentally different from Apple&amp;#x27;s &lt;a href="https://www.apple.com/app-store/"&gt;&lt;u&gt;App Store&lt;/u&gt;&lt;/a&gt; or &lt;a href="https://play.google.com/store/games?hl=en_US"&gt;&lt;u&gt;Google Play&lt;/u&gt;&lt;/a&gt; models.&lt;/p&gt;&lt;p&gt;Williams acknowledges that &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; itself currently runs on centralized infrastructure, despite building applications on the decentralized Internet Computer. &amp;quot;Caffeine itself actually is centralized. It uses aspects of the Internet Computer. We want Caffeine itself to run on the Internet Computer in the future, but it&amp;#x27;s not there now,&amp;quot; he said. The platform leverages commercially available foundation models from companies like Anthropic, whose &lt;a href="https://www.anthropic.com/claude/sonnet"&gt;&lt;u&gt;Claude Sonnet&lt;/u&gt;&lt;/a&gt; model powers much of Caffeine&amp;#x27;s backend logic.&lt;/p&gt;&lt;p&gt;This pragmatic approach reflects Dfinity&amp;#x27;s strategy of using best-in-class AI models while focusing its own development on the specialized infrastructure and programming language designed for AI use. &amp;quot;These content models have been developed by companies with enormous budgets, absolutely enormous budgets,&amp;quot; Williams said. &amp;quot;I don&amp;#x27;t think in the near future we&amp;#x27;ll run AI on the Internet Computer for that reason, unless there&amp;#x27;s a special case.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A decade in the making: From Ethereum roots to the self-writing internet&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The &lt;a href="https://dfinity.org/"&gt;&lt;u&gt;Dfinity Foundation&lt;/u&gt;&lt;/a&gt; has pursued this vision since Williams began researching decentralized networks in late 2013. After involvement with Ethereum before its 2015 launch, Williams became fascinated with the concept of a &amp;quot;world computer&amp;quot;—a public blockchain network that could host not just tokens but entire applications and services.&lt;/p&gt;&lt;p&gt;&amp;quot;By 2015 I was talking about network-focused drivers, Dfinity back then, and that could really operate as an alternative tech stack, and eventually host even things like social networks and massive enterprise systems,&amp;quot; Williams said. The foundation launched the Internet Computer Protocol in May 2021, initially focusing on Web3 developers. Despite not being among the highest-valued blockchain projects, ICP consistently ranks in the top 10 for developer numbers.&lt;/p&gt;&lt;p&gt;The pivot to AI-driven development came from recognizing that &amp;quot;in the future, the tech stack will be AI,&amp;quot; according to Williams. This realization led to Caffeine&amp;#x27;s development, announced on Dfinity&amp;#x27;s public roadmap in March 2025 and demonstrated at the &lt;a href="https://worldcomputer.com/"&gt;&lt;u&gt;World Computer Summit&lt;/u&gt;&lt;/a&gt; in June 2025.&lt;/p&gt;&lt;p&gt;One successful example of the Dfinity vision running in production is &lt;a href="https://oc.app/"&gt;&lt;u&gt;OpenChat&lt;/u&gt;&lt;/a&gt;, a messaging application that runs entirely on the Internet Computer and is governed by a decentralized autonomous organization (DAO) with tens of thousands of participants voting on source code updates through algorithmic governance. &amp;quot;The community is actually controlling the source code updates,&amp;quot; Williams explained. &amp;quot;Developers propose updates, community reads the updates, and if the community is happy, OpenChat updates itself.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The skeptics weigh in: Crypto baggage and real-world testing ahead&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform faces several challenges. Dfinity&amp;#x27;s crypto industry roots may create perception problems in enterprise markets, Williams acknowledges. &amp;quot;The Web3 industry&amp;#x27;s reputation is a bit tarnished and probably rightfully so,&amp;quot; he said during the World Computer Summit. &amp;quot;Now people can, for themselves, experience what a decentralized network is. We&amp;#x27;re going to see self-writing take over the enterprise space because the speed and efficiency are just incredible.&amp;quot;&lt;/p&gt;&lt;p&gt;The foundation&amp;#x27;s history includes controversy: ICP&amp;#x27;s token launched in 2021 at over $100 per token with an all-time high around $700, then &lt;a href="https://www.nytimes.com/2021/06/28/business/dealbook/dfinity-icp-ico.html"&gt;&lt;u&gt;crashed below $3 in 2023&lt;/u&gt;&lt;/a&gt; before recovering. The project has faced legal challenges, including class action lawsuits &lt;a href="https://www.nytimes.com/2021/06/28/business/dealbook/icp-cryptocurrency-crash.html"&gt;&lt;u&gt;alleging misleading investors&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.reuters.com/legal/transactional/column-new-york-times-crypto-analyst-beat-dfinity-defamation-claims-2023-11-14/"&gt;&lt;u&gt;Dfinity filed defamation claims&lt;/u&gt;&lt;/a&gt; against industry critics.&lt;/p&gt;&lt;p&gt;Technical limitations also remain. Caffeine cannot yet compile React front-ends on the Internet Computer itself, requiring some off-chain processing. Complex integrations with traditional systems — payment processing through Stripe, for example — still require centralized components. &amp;quot;Your app is running end-to-end on the Internet Computer, then when it needs to actually accept payment, it&amp;#x27;s going to hand over to your Stripe account,&amp;quot; Williams explained.&lt;/p&gt;&lt;p&gt;The platform&amp;#x27;s claims about data loss prevention and security guarantees, while technically grounded in the Motoko language design and Internet Computer architecture, remain to be tested at scale with diverse real-world applications. The 26% daily active user rate from alpha testing is impressive but comes from a self-selected group of early adopters.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;When five billion smartphone users become developers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Williams rejects concerns that AI-driven development will eliminate software engineering jobs, arguing instead for market expansion. &amp;quot;The self-writing internet empowers eight billion non-technical people,&amp;quot; he said. &amp;quot;Some of these people will enter roles in tech, becoming prompt engineers, tech entrepreneurs, or helping run online communities. Humanity will create millions of new custom apps and services, and a subset of those will require professional human assistance.&amp;quot;&lt;/p&gt;&lt;p&gt;During his &lt;a href="https://www.youtube.com/watch?v=GN_JleruySc"&gt;&lt;u&gt;World Computer Summit demonstration&lt;/u&gt;&lt;/a&gt;, Williams was explicit about the scale of transformation Dfinity envisions. &amp;quot;Today there are about 35,000 Web3 engineers in the world. Worldwide there are about 15 million full-stack engineers,&amp;quot; he said. &amp;quot;But tomorrow with the self-writing internet, everyone will be a builder. Today there are already about five billion people with internet-connected smartphones and they&amp;#x27;ll all be able to use Caffeine.&amp;quot;&lt;/p&gt;&lt;p&gt;The hackathon results suggest this isn&amp;#x27;t pure hyperbole. A dentist built &amp;quot;Dental Tracks&amp;quot; to help patients manage their dental records. A transportation industry professional created &amp;quot;Road Patrol&amp;quot; for gamified infrastructure reporting. A frustrated knitting student built &amp;quot;Skill Sprout,&amp;quot; a garden-themed app for learning new hobbies, complete with material checklists and step-by-step skill breakdowns—all without writing a single line of code.&lt;/p&gt;&lt;p&gt;&amp;quot;I was learning to knit. I got irritated because I had the wrong materials,&amp;quot; the creator explained in a video interview. &amp;quot;I don&amp;#x27;t know how to do the stitches, so I have to individually search, and it&amp;#x27;s really intimidating when you&amp;#x27;re trying to learn something you don&amp;#x27;t—you don&amp;#x27;t even know what you don&amp;#x27;t know.&amp;quot;&lt;/p&gt;&lt;p&gt;Whether &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; succeeds depends on factors still unknown: how production applications perform under real-world stress, whether the Internet Computer scales to millions of applications, whether enterprises can overcome their skepticism of blockchain-adjacent technology. But if Williams is right about the fundamental shift — that AI will be the tech stack, not just a tool for human developers — then someone will build what Caffeine promises.&lt;/p&gt;&lt;p&gt;The question isn&amp;#x27;t whether the future looks like this. It&amp;#x27;s who gets there first, and whether they can do it without losing everyone&amp;#x27;s data along the way.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;The &lt;a href="https://dfinity.org/"&gt;&lt;u&gt;Dfinity Foundation&lt;/u&gt;&lt;/a&gt; on Wednesday released &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt;, an artificial intelligence platform that allows users to build and deploy web applications through natural language conversation alone, bypassing traditional coding entirely. The system, which became publicly available today, represents a fundamental departure from existing AI coding assistants by building applications on a specialized decentralized infrastructure designed specifically for autonomous AI development.&lt;/p&gt;&lt;p&gt;Unlike &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://cursor.com/"&gt;&lt;u&gt;Cursor&lt;/u&gt;&lt;/a&gt;, or other &amp;quot;vibe coding&amp;quot; tools that help human developers write code faster, Caffeine positions itself as a complete replacement for technical teams. Users describe what they want in plain language, and an ensemble of AI models writes, deploys, and continually updates production-grade applications — with no human intervention in the codebase itself.&lt;/p&gt;&lt;p&gt;&amp;quot;In the future, you as a prospective app owner or service owner… will talk to AI. AI will give you what you want on a URL,&amp;quot; said Dominic Williams, founder and chief scientist at the Dfinity Foundation, in an exclusive interview with VentureBeat. &amp;quot;You will use that, completely interact productively, and you&amp;#x27;ll just keep talking to AI to evolve what that does. The AI, or an ensemble of AIs, will be your tech team.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform has attracted significant early interest: more than 15,000 alpha users tested Caffeine before its public release, with daily active users representing 26% of those who received access codes — &amp;quot;early Facebook kind of levels,&amp;quot; according to Williams. The foundation reports some users spending entire days building applications on the platform, forcing Dfinity to consider usage limits due to underlying AI infrastructure costs.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Caffeine&amp;#x27;s custom programming language guarantees your data won&amp;#x27;t disappear&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Caffeine&amp;#x27;s most significant technical claim addresses a problem that has plagued AI-generated code: data loss during application updates. The platform builds applications using &lt;a href="https://internetcomputer.org/docs/motoko/home"&gt;&lt;u&gt;Motoko&lt;/u&gt;&lt;/a&gt;, a programming language developed by Dfinity specifically for AI use, which provides mathematical guarantees that upgrades cannot accidentally delete user data.&lt;/p&gt;&lt;p&gt;&amp;quot;When AI is updating apps and services in production, a mistake cannot lose data. That&amp;#x27;s a guarantee,&amp;quot; Williams said. &amp;quot;It&amp;#x27;s not like there are some safeguards to try and stop it losing data. This language framework gives it rails that guarantee if an upgrade, an update to its app&amp;#x27;s underlying logic, would cause data loss, the upgrade fails and the AI just tries again.&amp;quot;&lt;/p&gt;&lt;p&gt;This addresses what Williams characterizes as critical failures in competing platforms. User forums for tools like &lt;a href="https://lovable.dev/"&gt;&lt;u&gt;Lovable&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://replit.com/"&gt;&lt;u&gt;Replit&lt;/u&gt;&lt;/a&gt;, he notes, frequently report three major problems: applications that become irreparably broken as complexity increases, security vulnerabilities that allow unauthorized access, and mysterious data loss during updates.&lt;/p&gt;&lt;p&gt;Traditional tech stacks evolved to meet human developer needs — familiarity with SQL databases, preference for known programming languages, existing skill investments. &amp;quot;That&amp;#x27;s how the traditional tech stacks evolved. It&amp;#x27;s really evolved to meet human needs,&amp;quot; Williams explained. &amp;quot;But in the future, it&amp;#x27;s going to be different. You&amp;#x27;re not going to care how the AI did it. Instead, for you, AI is the tech stack.&amp;quot;&lt;/p&gt;&lt;p&gt;Caffeine&amp;#x27;s architecture reflects this philosophy. Applications run entirely on the &lt;a href="https://internetcomputer.org/"&gt;&lt;u&gt;Internet Computer Protocol (ICP)&lt;/u&gt;&lt;/a&gt;, a blockchain-based network that Dfinity launched in May 2021 after raising over $100 million from investors including &lt;a href="https://a16z.com/dfinity/"&gt;&lt;u&gt;Andreessen Horowitz&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://techcrunch.com/2018/08/29/dfinity/"&gt;&lt;u&gt;Polychain Capital&lt;/u&gt;&lt;/a&gt;. The ICP uses what Dfinity calls &amp;quot;chain-key cryptography&amp;quot; to create what Williams describes as &amp;quot;tamper-proof&amp;quot; code — applications that are mathematically guaranteed to execute their written logic without interference from traditional cyberattacks.&lt;/p&gt;&lt;p&gt;&amp;quot;The code can&amp;#x27;t be affected by ransomware, so you don&amp;#x27;t have to worry about malware in the same way you do,&amp;quot; Williams said. &amp;quot;Configuration errors don&amp;#x27;t result in traditional cyber attacks. That passive traditional cyber attacks isn&amp;#x27;t something you need to worry about.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How &amp;#x27;orthogonal persistence&amp;#x27; lets AI build apps without managing databases&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;At the heart of Caffeine&amp;#x27;s technical approach is a concept called &amp;quot;&lt;a href="https://internetcomputer.org/docs/motoko/fundamentals/actors/orthogonal-persistence/"&gt;&lt;u&gt;orthogonal persistence&lt;/u&gt;&lt;/a&gt;,&amp;quot; which fundamentally reimagines how applications store and manage data. In traditional development, programmers must write extensive code to move data between application logic and separate database systems — marshaling data in and out of SQL servers, managing connections, handling synchronization.&lt;/p&gt;&lt;p&gt;&lt;a href="https://internetcomputer.org/docs/motoko/home"&gt;&lt;u&gt;Motoko&lt;/u&gt;&lt;/a&gt; eliminates this entirely. Williams demonstrated with a simple example: defining a blog post data type and declaring a variable to store an array of posts requires just two lines of code. &amp;quot;This declaration is all that&amp;#x27;s necessary to have the blog maintain its list of posts,&amp;quot; he explained during a presentation on the technology. &amp;quot;Compare that to traditional IT where in order to persist the blog posts, you&amp;#x27;d have to marshal them in and out of a database server. This is quite literally orders of magnitude more simple.&amp;quot;&lt;/p&gt;&lt;p&gt;This abstraction allows AI to work at a higher conceptual level, focusing on application logic rather than infrastructure plumbing. &amp;quot;Logic and data are kind of the same,&amp;quot; Williams said. &amp;quot;This is one of the things that enables AI to build far more complicated functionality than it could otherwise do.&amp;quot;&lt;/p&gt;&lt;p&gt;The system also employs what Dfinity calls &amp;quot;loss-safe data migration.&amp;quot; When AI needs to modify an application&amp;#x27;s data structure — adding a &amp;quot;likes&amp;quot; field to blog posts, for example — it must write migration logic in two passes. The framework automatically verifies that the transformation won&amp;#x27;t result in data loss, refusing to compile or deploy code that could delete information unless explicitly instructed.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;From million-dollar SaaS contracts to conversational app building in minutes&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Williams positions &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; as particularly transformative for enterprise IT, where he claims costs could fall to &amp;quot;1% of what they were before&amp;quot; while time-to-market shrinks to similar fractions. The platform targets a spectrum from individual creators to large corporations, all of whom currently face either expensive development teams or constraining low-code templates.&lt;/p&gt;&lt;p&gt;&amp;quot;A corporation or government department might want to create a corporate portal or CRM, ERP functionality,&amp;quot; Williams said, referring to customer relationship management and enterprise resource planning systems. &amp;quot;They will otherwise have to obtain this by signing up for some incredibly expensive SaaS service where they become locked in, their data gets stuck, and they still have to spend a lot of money on consultants customizing the functionality.&amp;quot;&lt;/p&gt;&lt;p&gt;Applications built through &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; are owned entirely by their creators and cannot be shut down by centralized parties — a consequence of running on the decentralized &lt;a href="https://internetcomputer.org/"&gt;&lt;u&gt;Internet Computer&lt;/u&gt;&lt;/a&gt; network rather than traditional cloud providers like &lt;a href="https://aws.amazon.com/free/?trk=48ebaf74-0ade-44c7-b8c2-12a0e7718d21&amp;amp;sc_channel=ps&amp;amp;ef_id=Cj0KCQjwjL3HBhCgARIsAPUg7a5jTV7r4lhg4v2_akcje7Hv2RgfrbNK3YJRonxmzg3lQnhP5Dtop_waAscnEALw_wcB:G:s&amp;amp;s_kwcid=AL!4422!3!651751059777!e!!g!!amazon%20web%20services!19852662197!145019195737&amp;amp;gad_campaignid=19852662197&amp;amp;gbraid=0AAAAADjHtp-sA3cSfcBU924i9KU_I-qMh&amp;amp;gclid=Cj0KCQjwjL3HBhCgARIsAPUg7a5jTV7r4lhg4v2_akcje7Hv2RgfrbNK3YJRonxmzg3lQnhP5Dtop_waAscnEALw_wcB"&gt;&lt;u&gt;Amazon Web Services&lt;/u&gt;&lt;/a&gt;. &amp;quot;When someone says built on the internet computer, it actually means built on the internet computer,&amp;quot; Williams emphasized, contrasting this with blockchain projects that merely host tokens while running actual applications on centralized infrastructure.&lt;/p&gt;&lt;p&gt;The platform demonstrated this versatility during a July 2025 hackathon in San Francisco, where participants created applications ranging from a &amp;quot;Will Maker&amp;quot; tool for generating legal documents, to &amp;quot;Blue Lens,&amp;quot; a voice-AI water quality monitoring system, to &amp;quot;Road Patrol,&amp;quot; a gamified community reporting app for infrastructure problems. Critically, many of these came from non-technical participants with no coding background.&lt;/p&gt;&lt;p&gt;&amp;quot;I&amp;#x27;m from a non-technical background, I&amp;#x27;m actually a quality assurance professional,&amp;quot; said the creator of Blue Lens in a video testimonial. &amp;quot;Through Caffeine I can build something really intuitive and next-gen to the public.&amp;quot; The application integrated multiple external services — Eleven Labs for voice AI, real-time government water data through retrieval-augmented generation, and Midjourney-generated visual assets — all coordinated through conversational prompts.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What separates Caffeine from GitHub Copilot, Cursor, and the &amp;#x27;vibe coding&amp;#x27; wave&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="http://caffeine.ai"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; enters a crowded market of AI-assisted development tools, but Williams argues the competition isn&amp;#x27;t truly comparable. &lt;a href="https://github.com/features/copilot"&gt;&lt;u&gt;GitHub Copilot&lt;/u&gt;&lt;/a&gt;, &lt;a href="https://cursor.com/"&gt;&lt;u&gt;Cursor&lt;/u&gt;&lt;/a&gt;, and similar tools serve human developers working with traditional technology stacks. Platforms like &lt;a href="https://replit.com/"&gt;&lt;u&gt;Replit&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://lovable.dev/"&gt;&lt;u&gt;Lovable&lt;/u&gt;&lt;/a&gt; occupy a middle ground, offering &amp;quot;vibe coding&amp;quot; that mixes AI generation with human editing.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re a Node.js developer, you know you&amp;#x27;re working with the traditional stack, and you might want to do your coding with Copilot or using Claude or using Cursor,&amp;quot; Williams said. &amp;quot;That&amp;#x27;s a very different thing to what Caffeine is offering. There&amp;#x27;ll always be cases where you probably wouldn&amp;#x27;t want to hand over the logic of the control system for a new nuclear missile silo to AI. But there&amp;#x27;s going to be these holdout areas, right? And there&amp;#x27;s all the legacy stuff that has to be maintained.&amp;quot;&lt;/p&gt;&lt;p&gt;The key distinction, according to Williams, lies in production readiness. Existing AI coding tools excel at rapid prototyping but stumble when applications grow complex or require guaranteed reliability. Reddit forums for these platforms document users hitting insurmountable walls where applications break irreparably, or where AI-generated code introduces security vulnerabilities.&lt;/p&gt;&lt;p&gt;&amp;quot;As the demands and the requirements become more complicated, eventually you can hit a limit, and when you hit that limit, not only can you not go any further, but sometimes your app will get broken and there&amp;#x27;s no way of going back to where you were before,&amp;quot; Williams said. &amp;quot;That can&amp;#x27;t happen with productive apps, and it also can&amp;#x27;t be the case that you&amp;#x27;re getting hacked and losing data, because once you go hands-free, if you like, and there&amp;#x27;s no tech team, there&amp;#x27;s no technical people involved, who&amp;#x27;s going to run the backups and restore your app?&amp;quot;&lt;/p&gt;&lt;p&gt;The Internet Computer&amp;#x27;s architecture addresses this through Byzantine fault tolerance — even if attackers gain physical control over some network hardware, they cannot corrupt applications or their data. &amp;quot;This is the beginning of a compute revolution and it&amp;#x27;s also the perfect platform for AI to build on,&amp;quot; Williams said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the vision: A web that programs itself through natural language&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Dfinity frames &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; within a broader vision it calls the &amp;quot;&lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;self-writing internet&lt;/u&gt;&lt;/a&gt;,&amp;quot; where the web literally programs itself through natural language interaction. This represents what Williams describes as a &amp;quot;seismic shift coming to tech&amp;quot; — from human developers selecting technology stacks based on their existing skills, to AI selecting optimal implementations invisible to users.&lt;/p&gt;&lt;p&gt;&amp;quot;You don&amp;#x27;t care about whether some human being has learned all of the different platforms and Amazon Web Services or something like that. You don&amp;#x27;t care about that. You just care: Is it secure? Do you get security guarantees? Is it resilient? What&amp;#x27;s the level of resilience?&amp;quot; Williams said. &amp;quot;Those are the new parameters.&amp;quot;&lt;/p&gt;&lt;p&gt;The platform demonstrated this during live demonstrations, including at the &lt;a href="https://worldcomputer.com/"&gt;&lt;u&gt;World Computer Summit 2025&lt;/u&gt;&lt;/a&gt; in Zurich. Williams created a talent recruitment application from scratch in under two minutes, then modified it in real-time while the application ran with users already interacting with it. &amp;quot;You will continue talking to the AI and just keep on refreshing the URL to see the changes,&amp;quot; he explained.&lt;/p&gt;&lt;p&gt;This capability extends to complex scenarios. During demonstrations, Williams showed building a tennis lesson booking system, an e-commerce platform, and an event registration system — all simultaneously, working on multiple applications in parallel. &amp;quot;We predict that as people get very proficient with &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt;, they could be working on even 10 apps in parallel,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The system writes substantial code: a simple personal blog generated 700 lines of code in a couple of minutes. More complex applications can involve thousands of lines across frontend and backend components, all abstracted away from the user who only describes desired functionality.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The economics of cloning: How Caffeine&amp;#x27;s app market challenges traditional stores&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Caffeine&amp;#x27;s economic model differs fundamentally from traditional software-as-a-service platforms. Applications run on the &lt;a href="https://internetcomputer.org/"&gt;&lt;u&gt;Internet Computer Protocol&lt;/u&gt;&lt;/a&gt;, which uses a &amp;quot;reverse gas model&amp;quot; where developers pay for computation rather than users paying transaction fees. The platform includes an integrated App Market where creators can publish applications for others to clone and adapt — creating what Dfinity envisions as a new economic ecosystem.&lt;/p&gt;&lt;p&gt;&amp;quot;App stores today obviously operate on gatekeeping,&amp;quot; said Pierre Samaties, chief business officer at Dfinity, during the World Computer Summit. &amp;quot;That&amp;#x27;s going to erode.&amp;quot; Rather than purchasing applications, users can clone them and modify them for their own purposes — fundamentally different from Apple&amp;#x27;s &lt;a href="https://www.apple.com/app-store/"&gt;&lt;u&gt;App Store&lt;/u&gt;&lt;/a&gt; or &lt;a href="https://play.google.com/store/games?hl=en_US"&gt;&lt;u&gt;Google Play&lt;/u&gt;&lt;/a&gt; models.&lt;/p&gt;&lt;p&gt;Williams acknowledges that &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; itself currently runs on centralized infrastructure, despite building applications on the decentralized Internet Computer. &amp;quot;Caffeine itself actually is centralized. It uses aspects of the Internet Computer. We want Caffeine itself to run on the Internet Computer in the future, but it&amp;#x27;s not there now,&amp;quot; he said. The platform leverages commercially available foundation models from companies like Anthropic, whose &lt;a href="https://www.anthropic.com/claude/sonnet"&gt;&lt;u&gt;Claude Sonnet&lt;/u&gt;&lt;/a&gt; model powers much of Caffeine&amp;#x27;s backend logic.&lt;/p&gt;&lt;p&gt;This pragmatic approach reflects Dfinity&amp;#x27;s strategy of using best-in-class AI models while focusing its own development on the specialized infrastructure and programming language designed for AI use. &amp;quot;These content models have been developed by companies with enormous budgets, absolutely enormous budgets,&amp;quot; Williams said. &amp;quot;I don&amp;#x27;t think in the near future we&amp;#x27;ll run AI on the Internet Computer for that reason, unless there&amp;#x27;s a special case.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;A decade in the making: From Ethereum roots to the self-writing internet&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The &lt;a href="https://dfinity.org/"&gt;&lt;u&gt;Dfinity Foundation&lt;/u&gt;&lt;/a&gt; has pursued this vision since Williams began researching decentralized networks in late 2013. After involvement with Ethereum before its 2015 launch, Williams became fascinated with the concept of a &amp;quot;world computer&amp;quot;—a public blockchain network that could host not just tokens but entire applications and services.&lt;/p&gt;&lt;p&gt;&amp;quot;By 2015 I was talking about network-focused drivers, Dfinity back then, and that could really operate as an alternative tech stack, and eventually host even things like social networks and massive enterprise systems,&amp;quot; Williams said. The foundation launched the Internet Computer Protocol in May 2021, initially focusing on Web3 developers. Despite not being among the highest-valued blockchain projects, ICP consistently ranks in the top 10 for developer numbers.&lt;/p&gt;&lt;p&gt;The pivot to AI-driven development came from recognizing that &amp;quot;in the future, the tech stack will be AI,&amp;quot; according to Williams. This realization led to Caffeine&amp;#x27;s development, announced on Dfinity&amp;#x27;s public roadmap in March 2025 and demonstrated at the &lt;a href="https://worldcomputer.com/"&gt;&lt;u&gt;World Computer Summit&lt;/u&gt;&lt;/a&gt; in June 2025.&lt;/p&gt;&lt;p&gt;One successful example of the Dfinity vision running in production is &lt;a href="https://oc.app/"&gt;&lt;u&gt;OpenChat&lt;/u&gt;&lt;/a&gt;, a messaging application that runs entirely on the Internet Computer and is governed by a decentralized autonomous organization (DAO) with tens of thousands of participants voting on source code updates through algorithmic governance. &amp;quot;The community is actually controlling the source code updates,&amp;quot; Williams explained. &amp;quot;Developers propose updates, community reads the updates, and if the community is happy, OpenChat updates itself.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The skeptics weigh in: Crypto baggage and real-world testing ahead&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The platform faces several challenges. Dfinity&amp;#x27;s crypto industry roots may create perception problems in enterprise markets, Williams acknowledges. &amp;quot;The Web3 industry&amp;#x27;s reputation is a bit tarnished and probably rightfully so,&amp;quot; he said during the World Computer Summit. &amp;quot;Now people can, for themselves, experience what a decentralized network is. We&amp;#x27;re going to see self-writing take over the enterprise space because the speed and efficiency are just incredible.&amp;quot;&lt;/p&gt;&lt;p&gt;The foundation&amp;#x27;s history includes controversy: ICP&amp;#x27;s token launched in 2021 at over $100 per token with an all-time high around $700, then &lt;a href="https://www.nytimes.com/2021/06/28/business/dealbook/dfinity-icp-ico.html"&gt;&lt;u&gt;crashed below $3 in 2023&lt;/u&gt;&lt;/a&gt; before recovering. The project has faced legal challenges, including class action lawsuits &lt;a href="https://www.nytimes.com/2021/06/28/business/dealbook/icp-cryptocurrency-crash.html"&gt;&lt;u&gt;alleging misleading investors&lt;/u&gt;&lt;/a&gt;, and &lt;a href="https://www.reuters.com/legal/transactional/column-new-york-times-crypto-analyst-beat-dfinity-defamation-claims-2023-11-14/"&gt;&lt;u&gt;Dfinity filed defamation claims&lt;/u&gt;&lt;/a&gt; against industry critics.&lt;/p&gt;&lt;p&gt;Technical limitations also remain. Caffeine cannot yet compile React front-ends on the Internet Computer itself, requiring some off-chain processing. Complex integrations with traditional systems — payment processing through Stripe, for example — still require centralized components. &amp;quot;Your app is running end-to-end on the Internet Computer, then when it needs to actually accept payment, it&amp;#x27;s going to hand over to your Stripe account,&amp;quot; Williams explained.&lt;/p&gt;&lt;p&gt;The platform&amp;#x27;s claims about data loss prevention and security guarantees, while technically grounded in the Motoko language design and Internet Computer architecture, remain to be tested at scale with diverse real-world applications. The 26% daily active user rate from alpha testing is impressive but comes from a self-selected group of early adopters.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;When five billion smartphone users become developers&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Williams rejects concerns that AI-driven development will eliminate software engineering jobs, arguing instead for market expansion. &amp;quot;The self-writing internet empowers eight billion non-technical people,&amp;quot; he said. &amp;quot;Some of these people will enter roles in tech, becoming prompt engineers, tech entrepreneurs, or helping run online communities. Humanity will create millions of new custom apps and services, and a subset of those will require professional human assistance.&amp;quot;&lt;/p&gt;&lt;p&gt;During his &lt;a href="https://www.youtube.com/watch?v=GN_JleruySc"&gt;&lt;u&gt;World Computer Summit demonstration&lt;/u&gt;&lt;/a&gt;, Williams was explicit about the scale of transformation Dfinity envisions. &amp;quot;Today there are about 35,000 Web3 engineers in the world. Worldwide there are about 15 million full-stack engineers,&amp;quot; he said. &amp;quot;But tomorrow with the self-writing internet, everyone will be a builder. Today there are already about five billion people with internet-connected smartphones and they&amp;#x27;ll all be able to use Caffeine.&amp;quot;&lt;/p&gt;&lt;p&gt;The hackathon results suggest this isn&amp;#x27;t pure hyperbole. A dentist built &amp;quot;Dental Tracks&amp;quot; to help patients manage their dental records. A transportation industry professional created &amp;quot;Road Patrol&amp;quot; for gamified infrastructure reporting. A frustrated knitting student built &amp;quot;Skill Sprout,&amp;quot; a garden-themed app for learning new hobbies, complete with material checklists and step-by-step skill breakdowns—all without writing a single line of code.&lt;/p&gt;&lt;p&gt;&amp;quot;I was learning to knit. I got irritated because I had the wrong materials,&amp;quot; the creator explained in a video interview. &amp;quot;I don&amp;#x27;t know how to do the stitches, so I have to individually search, and it&amp;#x27;s really intimidating when you&amp;#x27;re trying to learn something you don&amp;#x27;t—you don&amp;#x27;t even know what you don&amp;#x27;t know.&amp;quot;&lt;/p&gt;&lt;p&gt;Whether &lt;a href="https://caffeine.ai/"&gt;&lt;u&gt;Caffeine&lt;/u&gt;&lt;/a&gt; succeeds depends on factors still unknown: how production applications perform under real-world stress, whether the Internet Computer scales to millions of applications, whether enterprises can overcome their skepticism of blockchain-adjacent technology. But if Williams is right about the fundamental shift — that AI will be the tech stack, not just a tool for human developers — then someone will build what Caffeine promises.&lt;/p&gt;&lt;p&gt;The question isn&amp;#x27;t whether the future looks like this. It&amp;#x27;s who gets there first, and whether they can do it without losing everyone&amp;#x27;s data along the way.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/dfinity-launches-caffeine-an-ai-platform-that-builds-production-apps-from</guid><pubDate>Wed, 15 Oct 2025 09:00:00 +0000</pubDate></item><item><title>AI is changing how we quantify pain (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/15/1125116/ai-is-changing-how-we-quantify-pain/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;For years at Orchard Care Homes, a 23‑facility dementia-care chain in northern England, Cheryl Baird watched nurses fill out the Abbey Pain Scale, an observational methodology used to evaluate pain in those who can’t communicate verbally. Baird, a former nurse who was then the facility’s director of quality, describes it as “a tick‑box exercise where people weren’t truly considering pain indicators.”&lt;/p&gt;  &lt;p&gt;As a result, agitated residents were assumed to have behavioral issues, since the scale does not always differentiate well between pain and other forms of suffering or distress. They were often prescribed psychotropic sedatives, while the pain itself went untreated.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Then, in January 2021, Orchard Care Homes began a trial of PainChek, a smartphone app that scans a resident’s face for microscopic muscle movements and uses artificial intelligence to output an expected pain score. Within weeks, the pilot unit saw fewer prescriptions and had calmer corridors. “We immediately saw the benefits: ease of use, accuracy, and identifying pain that wouldn’t have been spotted using the old scale,” Baird recalls.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In nursing homes, neonatal units, and ICU wards, researchers are racing to turn pain into something a camera or sensor can score as reliably as blood pressure.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;This kind of technology-assisted diagnosis hints at a bigger trend. In nursing homes, neonatal units, and ICU wards, researchers are racing to turn pain—medicine’s most subjective vital sign—into something a camera or sensor can score as reliably as blood pressure. The push has already produced PainChek, which has been cleared by regulators on three continents and has logged more than 10 million pain assessments. Other startups are beginning to make similar inroads in care settings.&lt;/p&gt; 
 &lt;p&gt;The way we assess pain may finally be shifting, but when algorithms measure our suffering, does that change the way we understand and treat it?&lt;/p&gt;  &lt;p&gt;Science already understands certain aspects of pain. We know that when you stub your toe, for example, microscopic alarm bells called nociceptors send electrical impulses toward your spinal cord on “express” wires, delivering the first stab of pain, while a slower convoy follows with the dull throb that lingers. At the spinal cord, the signal meets a microscopic switchboard scientists call the gate. Flood that gate with friendly touches—say, by rubbing the bruise—or let the brain return an instruction born of panic or calm, and the gate might muffle or magnify the message before you even become aware of it.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The gate can either let pain signals pass through or block them, depending on other nerve activity and instructions from your brain. Only the signals that succeed in getting past this gate travel up to your brain’s sensory map to help locate the damage, while others branch out to emotion centers that decide how bad it feels. Within milliseconds, those same hubs in the brain shoot fresh orders back down the line, releasing built-in painkillers or stoking the alarm. In other words, pain isn’t a straightforward translation of damage or sensation but a live negotiation between the body and the brain.&lt;/p&gt;  &lt;p&gt;But much of how that negotiation plays out is still a mystery. For instance, scientists cannot predict what causes someone to slip from a routine injury into years-long hypersensitivity; the molecular shift from acute to chronic pain is still largely unknown. Phantom-limb pain remains equally puzzling: About two-thirds of amputees feel agony in a part of their body that no longer exists, yet competing theories—cortical remapping, peripheral neuromas, body-schema mismatch—do not explain why they suffer while the other third feel nothing.&lt;/p&gt;  &lt;p&gt;The first serious attempt at a system for quantifying pain was introduced in 1921. Patients marked their degree of pain as a point on a blank 10‑centimeter line and clinicians scored the distance in millimeters, converting lived experience into a 0–100 ladder. By 1975, psychologist Ronald Melzack’s McGill Pain Questionnaire offered 78 adjectives like “burning,” “stabbing,” and “throbbing,” so that pain’s texture could join intensity in the chart. Over the past few decades, hospitals have ultimately settled on the 0–10 Numeric Rating Scale.&lt;/p&gt;  &lt;p&gt;Yet pain is stubbornly subjective. Feedback from the brain in the form of your reaction can send instructions back down the spinal cord, meaning that expectation and emotion can change how much the same injury hurts. In one trial, volunteers who believed they had received a pain relief cream reported a stimulus as 22% less painful than those who knew the cream was inactive—and a functional magnetic resonance image of their brains showed that the drop corresponded with decreased activity in the parts of the brain that report pain, meaning they really did feel less hurt.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;What’s more, pain can also be affected by a slew of external factors. In one study, experimenters applied the same calibrated electrical stimulus to volunteers from Italy, Sweden, and Saudi Arabia, and the ratings varied dramatically. Italian women recorded the highest scores on the 0–10 scale, while Swedish and Saudi participants judged the identical burn several points lower, implying that culture can amplify or dampen the felt intensity of the same experience.&lt;/p&gt;  &lt;p&gt;Bias inside the clinic can drive different responses even to the same pain score. A 2024 analysis of discharge notes found that women’s scores were recorded 10% less often than men’s. At a large pediatric emergency department, Black children presenting with limb fractures were roughly 39% less likely to receive an opioid analgesic than their white non-Hispanic peers, even after the researchers controlled for pain score and other clinical factors. Together these studies make clear that an “8 out of 10” does not always result in the same reaction or treatment. And many patients cannot self-report their pain at all—for example, a review of bedside studies concludes that about 70% of intensive-care patients have pain that goes unrecognized or undertreated, a problem the authors link to their impaired communication due to sedation or intubation.&lt;/p&gt;  &lt;p&gt;These issues have prompted a search for a better, more objective way to understand and assess pain. Progress in artificial intelligence has brought a new dimension to that hunt.&lt;/p&gt;  &lt;p&gt;Research groups are pursuing two broad routes. The first listens underneath the skin. Electrophysiologists strap electrode nets to volunteers and look for neural signatures that rise and fall with administered stimuli. A 2024 machine-learning study reported that one such algorithm could tell with over 80% accuracy, using a few minutes of resting-state EEG, which subjects experienced chronic pain and which were pain-free control participants. Other researchers combine EEG with galvanic skin response and heart-rate variability, hoping a multisignal “pain fingerprint” will provide more robust measurements.&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;One example of this method is the PMD-200 patient monitor from Medasense, which uses AI-based tools to output pain scores. The device uses physiological patterns like heart rate, sweating, or peripheral temperature changes as the input and focuses on surgical patients, with the goal of helping anesthesiologists adjust doses during operations. In a 2022 study of 75 patients undergoing major abdominal surgery, use of the monitor resulted in lower self-reported pain scores after the operation—a median score of 3 out of 10, versus 5 out of 10 in controls—without an increase in opioid use. The device is authorized by the US Food and Drug Administration and is in use in the United States, the European Union, Canada, and elsewhere.&lt;/p&gt;  &lt;p&gt;The second path is behavioral. A grimace, a guarded posture, or a sharp intake of breath correlates with various levels of pain. Computer-vision teams have fed high-speed video of patients’ changing expressions into neural networks trained on the Face Action Coding System (FACS), which was introduced in the late 1970s with the goal of creating an objective and universal system to analyze such expressions—it’s the Rosetta stone of 44 facial micro-movements. In lab tests, those models can flag frames indicating pain from the data set with over 90% accuracy, edging close to the consistency of expert human assessors. Similar approaches mine posture and even sentence fragments in clinical notes, using natural-language processing, to spot phrases like “curling knees to chest” that often correlate with high pain.&lt;/p&gt;  &lt;p&gt;PainChek is one of these behavioral models, and it acts like a camera‑based thermometer, but for pain: A care worker opens the app and holds a phone 30 centimeters from a person’s face. For three seconds, a neural network looks for nine particular microscopic movements—upper‑lip raise, brow pinch, cheek tension, and so on—that research has linked most strongly to pain. Then the screen flashes a score of 0 to 42. “There’s a catalogue of ‘action‑unit codes’—facial expressions common to all humans. Nine of those are associated with pain,” explains Kreshnik Hoti, a senior research scientist with PainChek and a co-inventor of the device. This system is built directly on the foundation of FACS. After the scan, the app walks the user through a yes‑or‑no checklist of other signs, like groaning, “guarding,” and sleep disruption, and stores the result on a cloud dashboard that can show trends.&lt;/p&gt;  &lt;p&gt;Linking the scan to a human‑filled checklist was, Hoti admits, a late design choice. “Initially, we thought AI should automate everything, but now we see [that] hybrid use—AI plus human input—is our major strength,” he says. Care aides, not nurses, complete most assessments, freeing clinicians to act on the data rather than gather it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;PainChek was cleared by Australia’s Therapeutic Goods Administration in 2017, and national rollout funding from Canberra helped embed it in hundreds of nursing homes in the country. The system has also won authorization in the UK—where expansion began just before covid-19 started spreading and resumed as lockdowns eased—and in Canada and New Zealand, which are running pilot programs. In the US, it’s currently awaiting an FDA decision. Company‑wide data show “about a 25% drop in anti­psychotic use and, in Scotland, a 42% reduction in falls,” Hoti says.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a person holding a phone up in front of an elderly person, whose face is visible on the screen" class="wp-image-1125454" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/PainChek-Montage-3.jpg?w=618" /&gt;&lt;figcaption class="wp-element-caption"&gt;PainChek is a mobile app that estimates pain scores by applying artificial intelligence to facial scans.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF PAINCHEK&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Orchard Care Homes is one of its early adopters. Baird, then the facility’s director of quality, remembers the pre‑AI routine that was largely done “to prove compliance,” she says.&lt;/p&gt;  &lt;p&gt;PainChek added an algorithm to that workflow, and the hybrid approach has paid off. Orchard’s internal study of four care homes tracked monthly pain scores, behavioral incidents, and prescriptions. Within weeks, psychotropic scripts fell and residents’ behavior calmed. The ripple effects went beyond pharmacy tallies. Residents who had skipped meals because of undetected dental pain “began eating again,” Baird notes, and “those who were isolated due to pain began socializing.”&lt;/p&gt;  &lt;p&gt;Inside Orchard facilities, a cultural shift is underway. When Baird trained new staff, she likened pain “to measuring blood pressure or oxygen,” she says. “We wouldn’t guess those, so why guess pain?” The analogy lands, but getting people fully on board is still a slog. Some nurses insist their clinical judgment is enough; others balk at another login and audit trail. “The sector has been slow to adopt technology, but it’s changing,” Baird says. That’s helped by the fact that administering a full Abbey Pain Scale takes 20 minutes, while a PainChek scan and checklist take less than five.&lt;/p&gt; 
 &lt;p&gt;Engineers at PainChek are now adapting the code for the very youngest patients. PainChek Infant targets babies under one year, whose grimaces flicker faster than adults’. The algorithm, retrained on neonatal faces, detects six validated facial action units based on the well-established Baby Facial Action Coding System. PainChek Infant is starting limited testing in Australia while the company pursues a separate regulatory pathway.&lt;/p&gt;  &lt;p&gt;Skeptics raise familiar red flags about these devices. Facial‑analysis AI has a history of skin‑tone bias, for example. Facial analysis may also misread grimaces stemming from nausea or fear. The tool is only as good as the yes‑or‑no answers that follow the scan; sloppy data entry can skew results in either direction. Results lack the broader clinical and interpersonal context a caregiver is likely to have from interacting with individual patients regularly and understanding their medical history. It’s also possible that clinicians might defer too strongly to the algorithm, over-relying on outside judgment and eroding their own.&lt;/p&gt; 
 &lt;p&gt;If PainChek is approved by the FDA this fall, it will be part of a broader effort to create a system of new pain measurement technology. Other startups are pitching EEG headbands for neuropathic pain, galvanic skin sensors that flag breakthrough cancer pain, and even language models that comb nursing notes for evidence of hidden distress. Still, quantifying pain with an external device could be rife with hidden issues, like bias or inaccuracies, that we will uncover only after significant use.&lt;/p&gt;  &lt;p&gt;For Baird, the issue is fairly straightforward nonetheless. “I’ve lived with chronic pain and had a hard time getting people to believe me. [PainChek] would have made a huge difference,” she says. If artificial intelligence can give silent sufferers a numerical voice—and make clinicians listen—then adding one more line to the vital‑sign chart might be worth the screen time.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Deena Mousa is a researcher, grantmaker, and journalist focused on global health, economic development, and scientific and technological progress.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Mousa is employed as lead researcher by Open Philanthropy, a funder and adviser focused on high-impact causes, including global health and the potential risks posed by AI. The research team investigates new causes of focus and is not involved in work related to pain management. Mousa has not been involved with any grants related to pain management, although Open Philanthropy has funded research in this area in the past.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;For years at Orchard Care Homes, a 23‑facility dementia-care chain in northern England, Cheryl Baird watched nurses fill out the Abbey Pain Scale, an observational methodology used to evaluate pain in those who can’t communicate verbally. Baird, a former nurse who was then the facility’s director of quality, describes it as “a tick‑box exercise where people weren’t truly considering pain indicators.”&lt;/p&gt;  &lt;p&gt;As a result, agitated residents were assumed to have behavioral issues, since the scale does not always differentiate well between pain and other forms of suffering or distress. They were often prescribed psychotropic sedatives, while the pain itself went untreated.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Then, in January 2021, Orchard Care Homes began a trial of PainChek, a smartphone app that scans a resident’s face for microscopic muscle movements and uses artificial intelligence to output an expected pain score. Within weeks, the pilot unit saw fewer prescriptions and had calmer corridors. “We immediately saw the benefits: ease of use, accuracy, and identifying pain that wouldn’t have been spotted using the old scale,” Baird recalls.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In nursing homes, neonatal units, and ICU wards, researchers are racing to turn pain into something a camera or sensor can score as reliably as blood pressure.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;This kind of technology-assisted diagnosis hints at a bigger trend. In nursing homes, neonatal units, and ICU wards, researchers are racing to turn pain—medicine’s most subjective vital sign—into something a camera or sensor can score as reliably as blood pressure. The push has already produced PainChek, which has been cleared by regulators on three continents and has logged more than 10 million pain assessments. Other startups are beginning to make similar inroads in care settings.&lt;/p&gt; 
 &lt;p&gt;The way we assess pain may finally be shifting, but when algorithms measure our suffering, does that change the way we understand and treat it?&lt;/p&gt;  &lt;p&gt;Science already understands certain aspects of pain. We know that when you stub your toe, for example, microscopic alarm bells called nociceptors send electrical impulses toward your spinal cord on “express” wires, delivering the first stab of pain, while a slower convoy follows with the dull throb that lingers. At the spinal cord, the signal meets a microscopic switchboard scientists call the gate. Flood that gate with friendly touches—say, by rubbing the bruise—or let the brain return an instruction born of panic or calm, and the gate might muffle or magnify the message before you even become aware of it.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;The gate can either let pain signals pass through or block them, depending on other nerve activity and instructions from your brain. Only the signals that succeed in getting past this gate travel up to your brain’s sensory map to help locate the damage, while others branch out to emotion centers that decide how bad it feels. Within milliseconds, those same hubs in the brain shoot fresh orders back down the line, releasing built-in painkillers or stoking the alarm. In other words, pain isn’t a straightforward translation of damage or sensation but a live negotiation between the body and the brain.&lt;/p&gt;  &lt;p&gt;But much of how that negotiation plays out is still a mystery. For instance, scientists cannot predict what causes someone to slip from a routine injury into years-long hypersensitivity; the molecular shift from acute to chronic pain is still largely unknown. Phantom-limb pain remains equally puzzling: About two-thirds of amputees feel agony in a part of their body that no longer exists, yet competing theories—cortical remapping, peripheral neuromas, body-schema mismatch—do not explain why they suffer while the other third feel nothing.&lt;/p&gt;  &lt;p&gt;The first serious attempt at a system for quantifying pain was introduced in 1921. Patients marked their degree of pain as a point on a blank 10‑centimeter line and clinicians scored the distance in millimeters, converting lived experience into a 0–100 ladder. By 1975, psychologist Ronald Melzack’s McGill Pain Questionnaire offered 78 adjectives like “burning,” “stabbing,” and “throbbing,” so that pain’s texture could join intensity in the chart. Over the past few decades, hospitals have ultimately settled on the 0–10 Numeric Rating Scale.&lt;/p&gt;  &lt;p&gt;Yet pain is stubbornly subjective. Feedback from the brain in the form of your reaction can send instructions back down the spinal cord, meaning that expectation and emotion can change how much the same injury hurts. In one trial, volunteers who believed they had received a pain relief cream reported a stimulus as 22% less painful than those who knew the cream was inactive—and a functional magnetic resonance image of their brains showed that the drop corresponded with decreased activity in the parts of the brain that report pain, meaning they really did feel less hurt.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;What’s more, pain can also be affected by a slew of external factors. In one study, experimenters applied the same calibrated electrical stimulus to volunteers from Italy, Sweden, and Saudi Arabia, and the ratings varied dramatically. Italian women recorded the highest scores on the 0–10 scale, while Swedish and Saudi participants judged the identical burn several points lower, implying that culture can amplify or dampen the felt intensity of the same experience.&lt;/p&gt;  &lt;p&gt;Bias inside the clinic can drive different responses even to the same pain score. A 2024 analysis of discharge notes found that women’s scores were recorded 10% less often than men’s. At a large pediatric emergency department, Black children presenting with limb fractures were roughly 39% less likely to receive an opioid analgesic than their white non-Hispanic peers, even after the researchers controlled for pain score and other clinical factors. Together these studies make clear that an “8 out of 10” does not always result in the same reaction or treatment. And many patients cannot self-report their pain at all—for example, a review of bedside studies concludes that about 70% of intensive-care patients have pain that goes unrecognized or undertreated, a problem the authors link to their impaired communication due to sedation or intubation.&lt;/p&gt;  &lt;p&gt;These issues have prompted a search for a better, more objective way to understand and assess pain. Progress in artificial intelligence has brought a new dimension to that hunt.&lt;/p&gt;  &lt;p&gt;Research groups are pursuing two broad routes. The first listens underneath the skin. Electrophysiologists strap electrode nets to volunteers and look for neural signatures that rise and fall with administered stimuli. A 2024 machine-learning study reported that one such algorithm could tell with over 80% accuracy, using a few minutes of resting-state EEG, which subjects experienced chronic pain and which were pain-free control participants. Other researchers combine EEG with galvanic skin response and heart-rate variability, hoping a multisignal “pain fingerprint” will provide more robust measurements.&lt;/p&gt; 

&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;One example of this method is the PMD-200 patient monitor from Medasense, which uses AI-based tools to output pain scores. The device uses physiological patterns like heart rate, sweating, or peripheral temperature changes as the input and focuses on surgical patients, with the goal of helping anesthesiologists adjust doses during operations. In a 2022 study of 75 patients undergoing major abdominal surgery, use of the monitor resulted in lower self-reported pain scores after the operation—a median score of 3 out of 10, versus 5 out of 10 in controls—without an increase in opioid use. The device is authorized by the US Food and Drug Administration and is in use in the United States, the European Union, Canada, and elsewhere.&lt;/p&gt;  &lt;p&gt;The second path is behavioral. A grimace, a guarded posture, or a sharp intake of breath correlates with various levels of pain. Computer-vision teams have fed high-speed video of patients’ changing expressions into neural networks trained on the Face Action Coding System (FACS), which was introduced in the late 1970s with the goal of creating an objective and universal system to analyze such expressions—it’s the Rosetta stone of 44 facial micro-movements. In lab tests, those models can flag frames indicating pain from the data set with over 90% accuracy, edging close to the consistency of expert human assessors. Similar approaches mine posture and even sentence fragments in clinical notes, using natural-language processing, to spot phrases like “curling knees to chest” that often correlate with high pain.&lt;/p&gt;  &lt;p&gt;PainChek is one of these behavioral models, and it acts like a camera‑based thermometer, but for pain: A care worker opens the app and holds a phone 30 centimeters from a person’s face. For three seconds, a neural network looks for nine particular microscopic movements—upper‑lip raise, brow pinch, cheek tension, and so on—that research has linked most strongly to pain. Then the screen flashes a score of 0 to 42. “There’s a catalogue of ‘action‑unit codes’—facial expressions common to all humans. Nine of those are associated with pain,” explains Kreshnik Hoti, a senior research scientist with PainChek and a co-inventor of the device. This system is built directly on the foundation of FACS. After the scan, the app walks the user through a yes‑or‑no checklist of other signs, like groaning, “guarding,” and sleep disruption, and stores the result on a cloud dashboard that can show trends.&lt;/p&gt;  &lt;p&gt;Linking the scan to a human‑filled checklist was, Hoti admits, a late design choice. “Initially, we thought AI should automate everything, but now we see [that] hybrid use—AI plus human input—is our major strength,” he says. Care aides, not nurses, complete most assessments, freeing clinicians to act on the data rather than gather it.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;PainChek was cleared by Australia’s Therapeutic Goods Administration in 2017, and national rollout funding from Canberra helped embed it in hundreds of nursing homes in the country. The system has also won authorization in the UK—where expansion began just before covid-19 started spreading and resumed as lockdowns eased—and in Canada and New Zealand, which are running pilot programs. In the US, it’s currently awaiting an FDA decision. Company‑wide data show “about a 25% drop in anti­psychotic use and, in Scotland, a 42% reduction in falls,” Hoti says.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a person holding a phone up in front of an elderly person, whose face is visible on the screen" class="wp-image-1125454" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/PainChek-Montage-3.jpg?w=618" /&gt;&lt;figcaption class="wp-element-caption"&gt;PainChek is a mobile app that estimates pain scores by applying artificial intelligence to facial scans.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF PAINCHEK&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Orchard Care Homes is one of its early adopters. Baird, then the facility’s director of quality, remembers the pre‑AI routine that was largely done “to prove compliance,” she says.&lt;/p&gt;  &lt;p&gt;PainChek added an algorithm to that workflow, and the hybrid approach has paid off. Orchard’s internal study of four care homes tracked monthly pain scores, behavioral incidents, and prescriptions. Within weeks, psychotropic scripts fell and residents’ behavior calmed. The ripple effects went beyond pharmacy tallies. Residents who had skipped meals because of undetected dental pain “began eating again,” Baird notes, and “those who were isolated due to pain began socializing.”&lt;/p&gt;  &lt;p&gt;Inside Orchard facilities, a cultural shift is underway. When Baird trained new staff, she likened pain “to measuring blood pressure or oxygen,” she says. “We wouldn’t guess those, so why guess pain?” The analogy lands, but getting people fully on board is still a slog. Some nurses insist their clinical judgment is enough; others balk at another login and audit trail. “The sector has been slow to adopt technology, but it’s changing,” Baird says. That’s helped by the fact that administering a full Abbey Pain Scale takes 20 minutes, while a PainChek scan and checklist take less than five.&lt;/p&gt; 
 &lt;p&gt;Engineers at PainChek are now adapting the code for the very youngest patients. PainChek Infant targets babies under one year, whose grimaces flicker faster than adults’. The algorithm, retrained on neonatal faces, detects six validated facial action units based on the well-established Baby Facial Action Coding System. PainChek Infant is starting limited testing in Australia while the company pursues a separate regulatory pathway.&lt;/p&gt;  &lt;p&gt;Skeptics raise familiar red flags about these devices. Facial‑analysis AI has a history of skin‑tone bias, for example. Facial analysis may also misread grimaces stemming from nausea or fear. The tool is only as good as the yes‑or‑no answers that follow the scan; sloppy data entry can skew results in either direction. Results lack the broader clinical and interpersonal context a caregiver is likely to have from interacting with individual patients regularly and understanding their medical history. It’s also possible that clinicians might defer too strongly to the algorithm, over-relying on outside judgment and eroding their own.&lt;/p&gt; 
 &lt;p&gt;If PainChek is approved by the FDA this fall, it will be part of a broader effort to create a system of new pain measurement technology. Other startups are pitching EEG headbands for neuropathic pain, galvanic skin sensors that flag breakthrough cancer pain, and even language models that comb nursing notes for evidence of hidden distress. Still, quantifying pain with an external device could be rife with hidden issues, like bias or inaccuracies, that we will uncover only after significant use.&lt;/p&gt;  &lt;p&gt;For Baird, the issue is fairly straightforward nonetheless. “I’ve lived with chronic pain and had a hard time getting people to believe me. [PainChek] would have made a huge difference,” she says. If artificial intelligence can give silent sufferers a numerical voice—and make clinicians listen—then adding one more line to the vital‑sign chart might be worth the screen time.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Deena Mousa is a researcher, grantmaker, and journalist focused on global health, economic development, and scientific and technological progress.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Mousa is employed as lead researcher by Open Philanthropy, a funder and adviser focused on high-impact causes, including global health and the potential risks posed by AI. The research team investigates new causes of focus and is not involved in work related to pain management. Mousa has not been involved with any grants related to pain management, although Open Philanthropy has funded research in this area in the past.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/15/1125116/ai-is-changing-how-we-quantify-pain/</guid><pubDate>Wed, 15 Oct 2025 10:00:00 +0000</pubDate></item><item><title>The quest to find out how our bodies react to extreme temperatures (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/15/1124949/bodies-heat-climate-change-extreme-temperatures/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;It’s the 25th of June and I’m shivering in my lab-issued underwear in Fort Worth, Texas. Libby Cowgill, an anthropologist in a furry parka, has wheeled me and my cot into a metal-walled room set to 40 °F. A loud fan pummels me from above and siphons the dregs of my body heat through the cot’s mesh from below. A large respirator fits snug over my nose and mouth. The device tracks carbon dioxide in my exhales—a proxy for how my metabolism speeds up or slows down throughout the experiment. Eventually Cowgill will remove my respirator to slip a wire-thin metal temperature probe several pointy inches into my nose.&lt;/p&gt;  &lt;p&gt;Cowgill and a graduate student quietly observe me from the corner of their so-called “climate chamber.&lt;sup&gt;”&lt;/sup&gt; Just a few hours earlier I’d sat beside them to observe as another volunteer, a 24-year-old personal trainer, endured the cold. Every few minutes, they measured his skin temperature with a thermal camera, his core temperature with a wireless pill, and his blood pressure and other metrics that hinted at how his body handles extreme cold. He lasted almost an hour without shivering; when my turn comes, I shiver aggressively on the cot for nearly an hour straight.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;I’m visiting Texas to learn about this experiment on how different bodies respond to extreme climates. “What’s the record for fastest to shiver so far?” I jokingly ask Cowgill as she tapes biosensing devices to my chest and legs. After I exit the cold, she surprises me: “You, believe it or not, were not the worst person we’ve ever seen.”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Climate change forces us to reckon with the knotty science of how our bodies interact with the environment.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Cowgill is a 40-something anthropologist at the University of Missouri who powerlifts and teaches CrossFit in her spare time. She’s small and strong, with dark bangs and geometric tattoos. Since 2022, she’s spent the summers at the University of North Texas Health Science Center tending to these uncomfortable experiments. Her team hopes to revamp the science of thermoregulation.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While we know in broad strokes how people thermoregulate, the science of keeping warm or cool is mottled with blind spots. “We have the general picture. We don’t have a lot of the specifics for vulnerable groups,” says Kristie Ebi, an epidemiologist with the University of Washington who has studied heat and health for over 30 years. “How does thermoregulation work if you’ve got heart disease?”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“Epidemiologists have particular tools that they’re applying for this question,” Ebi continues. “But we do need more answers from other disciplines.”&lt;/p&gt; 
 &lt;p&gt;Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed to have occurred in Europe. Researchers estimate that climate change could add an extra 2.3 million European heat deaths this century. That’s heightened the stakes for solving the mystery of just what happens to bodies in extreme conditions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Extreme temperatures already threaten large stretches of the world. Populations across the Middle East, Asia, and sub-­Saharan Africa regularly face highs beyond widely accepted levels of human heat tolerance. Swaths of the southern US, northern Europe, and Asia now also endure unprecedented lows: The 2021 Texas freeze killed at least 246 people, and a 2023 polar vortex sank temperatures in China’s northernmost city to a hypothermic record of –63.4 °F.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This change is here, and more is coming. Climate scientists predict that limiting emissions can prevent lethal extremes from encroaching elsewhere. But if emissions keep course, fierce heat and even cold will reach deeper into every continent. About 2.5 billion people in the world’s hottest places don’t have air-­conditioning. When people do, it can make outdoor temperatures even worse, intensifying the heat island effect in dense cities. And neither AC nor radiators are much help when heat waves and cold snaps capsize the power grid.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignwide size-large"&gt;&lt;img alt="A thermal image shows a human male holding up peace signs during a test of extreme temperatures." class="wp-image-1125153" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Max.jpg?w=640" /&gt;&lt;div class="image-credit"&gt;COURTESY OF MAX G. LEVY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A thermal image shows a human hand during a test of extreme temperatures." class="wp-image-1125152" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/IR_14499.jpg" /&gt;&lt;div class="image-credit"&gt;COURTESY OF MAX G. LEVY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A thermal image shows a human foot during a test of extreme temperatures." class="wp-image-1125154" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/IR_14511.jpg" /&gt;&lt;div class="image-credit"&gt;COURTESY OF MAX G. LEVY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;“You, believe it or not, were not the worst person we’ve ever seen,” the author was told after enduring Cowgill’s “climate chamber.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Through experiments like Cowgill’s, researchers around the world are revising rules about when extremes veer from uncomfortable to deadly. Their findings change how we should think about the limits of hot and cold—and how to survive in a new world.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;Embodied change&lt;/h3&gt;  &lt;p&gt;Archaeologists have known for some time that we once braved colder temperatures than anyone previously imagined. Humans pushed into Eurasia and North America well before the last glacial period ended about 11,700 years ago. We were the only hominins to make it out of this era. Neanderthals, Denisovans, and &lt;em&gt;Homo floresiensis&lt;/em&gt; all went extinct. We don’t know for certain what killed those species. But we do know that humans survived thanks to protection from clothing, large social networks, and physiological flexibility. Human resilience to extreme temperature is baked into our bodies, behavior, and genetic code. We wouldn’t be here without it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Our bodies are constantly in communication with the environment,” says Cara Ocobock, an anthropologist at the University of Notre Dame who studies how we expend energy in extreme conditions. She has worked closely with Finnish reindeer herders and Wyoming mountaineers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the relationship between bodies and temperature is surprisingly still a mystery to scientists. In 1847, the anatomist Carl Bergmann observed that animal species grow larger in cold climates. The zoologist Joel Asaph Allen noted in 1877 that cold-dwellers had shorter appendages. Then there’s the nose thing: In the 1920s, the British anthropologist Arthur Thomson theorized that people in cold places have relatively long, narrow noses, the better to heat and humidify the air they take in. These theories stemmed from observations of animals like bears and foxes, and others that followed stemmed from studies comparing the bodies of cold-accustomed Indigenous populations with white male control groups. Some, like those having to do with optimization of surface area, do make sense: It seems reasonable that a tall, thin body increases the amount of skin available to dump excess heat. The problem is, scientists have never actually tested this stuff in humans.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“Our bodies are constantly in communication with the environment.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Cara Ocobock, anthropologist, University of Notre Dame&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;Some of what we know about temperature tolerance thus far comes from century-old race science or assumptions that anatomy controls everything. But science has evolved. Biology has matured. Childhood experiences, lifestyles, fat cells, and wonky biochemical feedback loops can contribute to a picture of the body as more malleable than anything imagined before. And that’s prompting researchers to change how they study it.&lt;/p&gt; 

 &lt;p&gt;“If you take someone who’s super long and lanky and lean and put them in a cold climate, are they gonna burn more calories to stay warm than somebody who’s short and broad?” Ocobock says. “No one’s looked at that.”&lt;/p&gt;  &lt;p&gt;Ocobock and Cowgill teamed up with Scott Maddux and Elizabeth Cho at the Center for Anatomical Sciences at the University of North Texas Health Fort Worth. All four are biological anthropologists who have also puzzled over whether the rules Bergmann, Allen, and Thomson proposed are actually true.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For the past four years, the team has been studying how factors like metabolism, fat, sweat, blood flow, and personal history control thermoregulation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Your native climate, for example, may influence how you handle temperature extremes. In a unique study of mortality statistics from 1980s Milan, Italians raised in warm southern Italy were more likely to survive heat waves in the northern part of the country.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Similar trends have appeared in cold climes. Researchers often measure cold tolerance by a person’s “brown adipose,” a type of fat that is specialized for generating heat (unlike white fat, which primarily stores energy). Brown fat is a cold adaptation because it delivers heat without the mechanism of shivering. Studies have linked it to living in cold climates, particularly at young ages. Wouter van Marken Lichtenbelt, the physiologist at Maastricht University who with colleagues discovered brown fat in adults, has shown that this tissue can further activate with cold exposure and even help regulate blood sugar and influence how the body burns other fat.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That adaptability served as an early clue for the Texas team. They want to know how a person’s response to hot and cold correlates with height, weight, and body shape. What is the difference, Maddux asks, between “a male who’s 6 foot 6 and weighs 240 pounds” and someone else in the same environment “who’s 4 foot 10 and weighs 89 pounds”? But the team also wondered if shape was only part of the story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Their multi-year experiment uses tools that anthropologists couldn’t have imagined a century ago—devices that track metabolism in real time and analyze genetics. Each participant gets a CT scan (measuring body shape), a DEXA scan (estimating percentages of fat and muscle), high-resolution 3D scans, and DNA analysis from saliva to examine ancestry genetically.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Volunteers lie on a cot in underwear, as I did, for about 45 minutes in each climate condition, all on separate days. There’s dry cold, around 40 °F, akin to braving a walk-in refrigerator. Then dry heat and humid heat: 112 °F with 15% humidity and 98&amp;nbsp;°F with 85% humidity. They call it “going to Vegas” and “going to Houston,” says Cowgill. The chamber session is long enough to measure an effect, but short enough to be safe.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Before I traveled to Texas, Cowgill told me she suspected the old rules would fall. Studies linking temperature tolerance to race and ethnicity, for example, seemed tenuous because biological anthropologists today reject the concept of distinct races. It’s a false premise, she told me: “No one in biological anthropology would argue that human beings do not vary across the globe—that’s obvious to anyone with eyes. [But] you can’t draw sharp borders around populations.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;She added, “I think there’s a substantial possibility that we spend four years testing this and find out that really, limb length, body mass, surface area […] are not the primary things that are predicting how well you do in cold and heat.”&amp;nbsp;&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Adaptable to a degree&lt;/h3&gt;  &lt;p&gt;In July 1995, a week-long heat wave pushed Chicago above 100 °F, killing roughly 500 people. Thirty years later, Ollie Jay, a physiologist at the University of Sydney, can duplicate the conditions of that exceptionally humid heat wave in a climate chamber at his laboratory.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We can simulate the Chicago heat wave of ’95. The Paris heat wave of 2003. The heat wave [in early July of this year]&amp;nbsp; in Europe,” Jay says. “As long as we’ve got the temperature and humidity information, we can re-create those conditions.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;“Everybody has quite an intimate experience of feeling hot, so we’ve got 8 billion experts on how to keep cool,” he says. Yet our internal sense of when heat turns deadly is unreliable. Even professional athletes overseen by experienced medics have died after missing dangerous warning signs. And little research has been done to explore how vulnerable populations such as elderly people, those with heart disease, and low-income communities with limited access to cooling respond to extreme heat.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Jay’s team researches the most effective strategies for surviving it. He lambastes air-conditioning, saying it demands so much energy that it can aggravate climate change in “a vicious cycle.” Instead, he has monitored people’s vital signs while they use fans and skin mists to endure three hours in humid and dry heat. In results published last year, his research found that fans reduced cardiovascular strain by 86% for people with heart disease in the type of humid heat familiar in Chicago.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;Dry heat was a different story. In that simulation, fans not only didn’t help but actually doubled the rate at which core temperatures rose in healthy older people.&lt;/p&gt;  &lt;p&gt;Heat kills. But not without a fight. Your body must keep its internal temperature in a narrow window flanking 98 °F by less than two degrees. The simple fact that you’re alive means you are &lt;em&gt;producing&lt;/em&gt; heat. Your body needs to export that heat without amassing much more. The nervous system relaxes narrow blood vessels along your skin. Your heart rate increases, propelling more warm blood to your extremities and away from your organs. You sweat. And when that sweat evaporates, it carries a torrent of body heat away with it.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This thermoregulatory response can be trained. Studies by van Marken Lichtenbelt have shown that exposure to mild heat increases sweat capacity, decreases blood pressure, and drops resting heart rate. Long-term studies based on Finnish saunas suggest similar correlations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The body may adapt protectively to cold, too. In this case, body heat is your lifeline. Shivering and exercise help keep bodies warm. So can clothing. Cardiovascular deaths are thought to spike in cold weather. But people more adapted to cold seem better able to reroute their blood flow in ways that keep their organs warm without dropping their temperature too many degrees in their extremities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Earlier this year, the biological anthropologist Stephanie B. Levy (no relation) reported that New Yorkers who experienced lower average temperatures had more productive brown fat, adding evidence for the idea that the inner workings of our bodies adjust to the climate throughout the year and perhaps even throughout our lives. “Do our bodies hold a biological memory of past seasons?” Levy wonders. “That’s still an open question. There’s some work in rodent models to suggest that that’s the case.”&lt;/p&gt;  &lt;p&gt;Although people clearly acclimatize with enough strenuous exposures to either cold or heat, Jay says, “you reach a ceiling.” Consider sweat: Heat exposure can increase the amount you sweat only until your skin is completely saturated. It’s a non­negotiable physical limit. Any additional sweat just means leaking water without carrying away any more heat. “I’ve heard people say we’ll just find a way of evolving out of this—we’ll biologically adapt,” Jay says. “Unless we’re completely changing our body shape, then that’s not going to happen.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;And body shape may not even sway thermoregulation as much as previously believed. The subject I observed, a personal trainer, appeared outwardly adapted for cold: his broad shoulders didn’t even fit in a single CT scan image. Cowgill supposed that this muscle mass insulated him. When he emerged from his session in the 40 °F environment, though, he had finally started shivering—intensely. The researchers covered him in a heated blanket. He continued shivering. Driving to lunch over an hour later in a hot car, he still mentioned feeling cold. An hour after that, a finger prick drew no blood, a sign that blood vessels in his extremities remained constricted. His body temperature fell about half a degree C in the cold session—a significant drop—and his wider build did not appear to shield him from the cold as well as my involuntary shivering protected me.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I asked Cowgill if perhaps there is no such thing as being uniquely predisposed to hot or cold. “Absolutely,” she said.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A hot mess&lt;/h3&gt;  &lt;p&gt;So if body shape doesn’t tell us much about how a person maintains body temperature, and acclimation also runs into limits, then how do we determine how hot is too hot?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In 2010 two climate change researchers, Steven Sherwood and Matthew Huber, argued that regions around the world become uninhabitable at wet-bulb temperatures of 35 °C, or 95 °F. (Wet-bulb measurements are a way to combine air temperature and relative humidity.) Above 35 °C, a person simply wouldn’t be able to dissipate heat quickly enough. But it turns out that their estimate was too optimistic.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Researchers “ran with” that number for a decade, says Daniel Vecellio, a bioclimatologist at the University of Nebraska, Omaha. “But the number had never been actually empirically tested.” In 2021 a Pennsylvania State University physiologist, W. Larry Kenney, worked with Vecellio and others to test wet-bulb limits in a climate chamber. Kenney’s lab investigates which combinations of temperature, humidity, and time push a person’s body over the edge.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Not long after, the researchers came up with their own wet-bulb limit of human tolerance: below 31 °C in warm, humid conditions for the youngest cohort, people in their thermoregulatory prime. Their research suggests that a day reaching 98 °F and 65% humidity, for example, poses danger in a matter of hours, even for healthy people.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignwide size-large"&gt;&lt;img alt="alt" class="wp-image-1125253" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Clemons-MIT-8-25-307.jpg?w=2001" width="2001" /&gt;&lt;div class="image-credit"&gt;JUSTIN CLEMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125256" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Clemons-MIT-8-25-433_f18271.jpg" /&gt;&lt;div class="image-credit"&gt;JUSTIN CLEMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="three medical team members make preparations around a person on a gurney" class="wp-image-1125258" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Clemons-MIT-8-25-359-edited.jpg" /&gt;&lt;div class="image-credit"&gt;JUSTIN CLEMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Cowgill and her colleagues Elizabeth Cho (top) and Scott Maddux prepare graduate student Joanna Bui for a “room-temperature test.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;In 2023, Vecellio and Huber teamed up, combining the growing arsenal of lab data with state-of-the-art climate simulations to predict where heat and humidity most threatened global populations: first the Middle East and South Asia, then sub-Saharan Africa and eastern China. And assuming that warming reaches 3 to 4 °C over preindustrial levels this century, as predicted, parts of North America, South America, and northern and central Australia will be next.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last June, Vecellio, Huber, and Kenney co-published an article revising the limits that Huber had proposed in 2010. “Why not 35 °C?” explained why the human limits have turned out to be lower than expected. Those initial estimates overlooked the fact that our skin temperature can quickly jump above 101 °F in hot weather, for example, making it harder to dump internal heat.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;The Penn State team has published deep dives on how heat tolerance changes with sex and age. Older participants’ wet-bulb limits wound up being even lower—between 27 and 28 °C in warm, humid conditions—and varied more from person to person than they did in young people. “The conditions that we experience now—especially here in North America and Europe, places like that—are well below the limits that we found in our research,” Vecellio says. “We know that heat kills now.” &amp;nbsp;&lt;/p&gt;  &lt;p&gt;What this fast-growing body of research suggests, Vecellio stresses, is that you can’t define heat risk by just one or two numbers. Last year, he and researchers at Arizona State University pulled up the hottest 10% of hours between 2005 and 2020 for each of 96 US cities. They wanted to compare recent heat-health research with historical weather data for a new perspective: How frequently is it so hot that people’s bodies can’t compensate for it? Over 88% of those “hot hours” met that criterion for people in full sun. In the shade, most of those heat waves became meaningfully less dangerous.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There’s really almost no one who ‘needs’ to die in a heat wave,” says Ebi, the epidemiologist. “We have the tools. We have the understanding. Essentially all [those] deaths are preventable.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;More than a number&lt;/h3&gt;  &lt;p&gt;A year after visiting Texas, I called Cowgill to hear what she was thinking after four summers of chamber experiments. She told me that the only rule about hot and cold she currently stands behind is … well, none.&lt;/p&gt;  &lt;p&gt;She recalled a recent participant—the smallest man in the study, weighing 114 pounds. “He shivered like a leaf on a tree,” Cowgill says. Normally, a strong shiverer warms up quickly. Core temperature may even climb a little. “This [guy] was just shivering and shivering and shivering and not getting any warmer,” she says. She doesn’t know why this happened. “Every time I think I get a picture of what’s going on in there, we’ll have one person come in and just kind of be a complete exception to the rule,” she says, adding that you can’t just gloss over how much human bodies vary inside and out.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt;&lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;The same messiness complicates physiology studies.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Jay looks to embrace bodily complexities by improving physiological simulations of heat and the human strain it causes. He’s piloted studies that input a person’s activity level and type of clothing to predict core temperature, dehydration, and cardiovascular strain based on the particular level of heat. One can then estimate the person’s risk on the basis of factors like age and health. He’s also working on physiological models to identify vulnerable groups, inform early-warning systems ahead of heat waves, and possibly advise cities on whether interventions like fans and mists can help protect residents. “Heat is an all-of-­society issue,” Ebi says. Officials could better prepare the public for cold snaps this way too.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;“Death is not the only thing we’re concerned about,” Jay adds.&amp;nbsp; Extreme temperatures bring morbidity and sickness and strain hospital systems: “There’s all these community-level impacts that we’re just completely missing.”&lt;/p&gt;  &lt;p&gt;Climate change forces us to reckon with the knotty science of how our bodies interact with the environment. Predicting the health effects is a big and messy matter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The first wave of answers from Fort Worth will materialize next year. The researchers will analyze thermal images to crunch data on brown fat. They’ll resolve whether, as Cowgill suspects, your body shape may not sway temperature tolerance as much as previously assumed. “Human variation is the rule,” she says, “not the exception.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Max G. Levy is an independent journalist who writes about chemistry, public health, and the environment.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;It’s the 25th of June and I’m shivering in my lab-issued underwear in Fort Worth, Texas. Libby Cowgill, an anthropologist in a furry parka, has wheeled me and my cot into a metal-walled room set to 40 °F. A loud fan pummels me from above and siphons the dregs of my body heat through the cot’s mesh from below. A large respirator fits snug over my nose and mouth. The device tracks carbon dioxide in my exhales—a proxy for how my metabolism speeds up or slows down throughout the experiment. Eventually Cowgill will remove my respirator to slip a wire-thin metal temperature probe several pointy inches into my nose.&lt;/p&gt;  &lt;p&gt;Cowgill and a graduate student quietly observe me from the corner of their so-called “climate chamber.&lt;sup&gt;”&lt;/sup&gt; Just a few hours earlier I’d sat beside them to observe as another volunteer, a 24-year-old personal trainer, endured the cold. Every few minutes, they measured his skin temperature with a thermal camera, his core temperature with a wireless pill, and his blood pressure and other metrics that hinted at how his body handles extreme cold. He lasted almost an hour without shivering; when my turn comes, I shiver aggressively on the cot for nearly an hour straight.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;I’m visiting Texas to learn about this experiment on how different bodies respond to extreme climates. “What’s the record for fastest to shiver so far?” I jokingly ask Cowgill as she tapes biosensing devices to my chest and legs. After I exit the cold, she surprises me: “You, believe it or not, were not the worst person we’ve ever seen.”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Climate change forces us to reckon with the knotty science of how our bodies interact with the environment.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;Cowgill is a 40-something anthropologist at the University of Missouri who powerlifts and teaches CrossFit in her spare time. She’s small and strong, with dark bangs and geometric tattoos. Since 2022, she’s spent the summers at the University of North Texas Health Science Center tending to these uncomfortable experiments. Her team hopes to revamp the science of thermoregulation.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;While we know in broad strokes how people thermoregulate, the science of keeping warm or cool is mottled with blind spots. “We have the general picture. We don’t have a lot of the specifics for vulnerable groups,” says Kristie Ebi, an epidemiologist with the University of Washington who has studied heat and health for over 30 years. “How does thermoregulation work if you’ve got heart disease?”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“Epidemiologists have particular tools that they’re applying for this question,” Ebi continues. “But we do need more answers from other disciplines.”&lt;/p&gt; 
 &lt;p&gt;Climate change is subjecting vulnerable people to temperatures that push their limits. In 2023, about 47,000 heat-related deaths are believed to have occurred in Europe. Researchers estimate that climate change could add an extra 2.3 million European heat deaths this century. That’s heightened the stakes for solving the mystery of just what happens to bodies in extreme conditions.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Extreme temperatures already threaten large stretches of the world. Populations across the Middle East, Asia, and sub-­Saharan Africa regularly face highs beyond widely accepted levels of human heat tolerance. Swaths of the southern US, northern Europe, and Asia now also endure unprecedented lows: The 2021 Texas freeze killed at least 246 people, and a 2023 polar vortex sank temperatures in China’s northernmost city to a hypothermic record of –63.4 °F.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This change is here, and more is coming. Climate scientists predict that limiting emissions can prevent lethal extremes from encroaching elsewhere. But if emissions keep course, fierce heat and even cold will reach deeper into every continent. About 2.5 billion people in the world’s hottest places don’t have air-­conditioning. When people do, it can make outdoor temperatures even worse, intensifying the heat island effect in dense cities. And neither AC nor radiators are much help when heat waves and cold snaps capsize the power grid.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignwide size-large"&gt;&lt;img alt="A thermal image shows a human male holding up peace signs during a test of extreme temperatures." class="wp-image-1125153" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Max.jpg?w=640" /&gt;&lt;div class="image-credit"&gt;COURTESY OF MAX G. LEVY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A thermal image shows a human hand during a test of extreme temperatures." class="wp-image-1125152" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/IR_14499.jpg" /&gt;&lt;div class="image-credit"&gt;COURTESY OF MAX G. LEVY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A thermal image shows a human foot during a test of extreme temperatures." class="wp-image-1125154" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/IR_14511.jpg" /&gt;&lt;div class="image-credit"&gt;COURTESY OF MAX G. LEVY&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;“You, believe it or not, were not the worst person we’ve ever seen,” the author was told after enduring Cowgill’s “climate chamber.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Through experiments like Cowgill’s, researchers around the world are revising rules about when extremes veer from uncomfortable to deadly. Their findings change how we should think about the limits of hot and cold—and how to survive in a new world.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;Embodied change&lt;/h3&gt;  &lt;p&gt;Archaeologists have known for some time that we once braved colder temperatures than anyone previously imagined. Humans pushed into Eurasia and North America well before the last glacial period ended about 11,700 years ago. We were the only hominins to make it out of this era. Neanderthals, Denisovans, and &lt;em&gt;Homo floresiensis&lt;/em&gt; all went extinct. We don’t know for certain what killed those species. But we do know that humans survived thanks to protection from clothing, large social networks, and physiological flexibility. Human resilience to extreme temperature is baked into our bodies, behavior, and genetic code. We wouldn’t be here without it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Our bodies are constantly in communication with the environment,” says Cara Ocobock, an anthropologist at the University of Notre Dame who studies how we expend energy in extreme conditions. She has worked closely with Finnish reindeer herders and Wyoming mountaineers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But the relationship between bodies and temperature is surprisingly still a mystery to scientists. In 1847, the anatomist Carl Bergmann observed that animal species grow larger in cold climates. The zoologist Joel Asaph Allen noted in 1877 that cold-dwellers had shorter appendages. Then there’s the nose thing: In the 1920s, the British anthropologist Arthur Thomson theorized that people in cold places have relatively long, narrow noses, the better to heat and humidify the air they take in. These theories stemmed from observations of animals like bears and foxes, and others that followed stemmed from studies comparing the bodies of cold-accustomed Indigenous populations with white male control groups. Some, like those having to do with optimization of surface area, do make sense: It seems reasonable that a tall, thin body increases the amount of skin available to dump excess heat. The problem is, scientists have never actually tested this stuff in humans.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“Our bodies are constantly in communication with the environment.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Cara Ocobock, anthropologist, University of Notre Dame&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;Some of what we know about temperature tolerance thus far comes from century-old race science or assumptions that anatomy controls everything. But science has evolved. Biology has matured. Childhood experiences, lifestyles, fat cells, and wonky biochemical feedback loops can contribute to a picture of the body as more malleable than anything imagined before. And that’s prompting researchers to change how they study it.&lt;/p&gt; 

 &lt;p&gt;“If you take someone who’s super long and lanky and lean and put them in a cold climate, are they gonna burn more calories to stay warm than somebody who’s short and broad?” Ocobock says. “No one’s looked at that.”&lt;/p&gt;  &lt;p&gt;Ocobock and Cowgill teamed up with Scott Maddux and Elizabeth Cho at the Center for Anatomical Sciences at the University of North Texas Health Fort Worth. All four are biological anthropologists who have also puzzled over whether the rules Bergmann, Allen, and Thomson proposed are actually true.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For the past four years, the team has been studying how factors like metabolism, fat, sweat, blood flow, and personal history control thermoregulation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Your native climate, for example, may influence how you handle temperature extremes. In a unique study of mortality statistics from 1980s Milan, Italians raised in warm southern Italy were more likely to survive heat waves in the northern part of the country.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Similar trends have appeared in cold climes. Researchers often measure cold tolerance by a person’s “brown adipose,” a type of fat that is specialized for generating heat (unlike white fat, which primarily stores energy). Brown fat is a cold adaptation because it delivers heat without the mechanism of shivering. Studies have linked it to living in cold climates, particularly at young ages. Wouter van Marken Lichtenbelt, the physiologist at Maastricht University who with colleagues discovered brown fat in adults, has shown that this tissue can further activate with cold exposure and even help regulate blood sugar and influence how the body burns other fat.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That adaptability served as an early clue for the Texas team. They want to know how a person’s response to hot and cold correlates with height, weight, and body shape. What is the difference, Maddux asks, between “a male who’s 6 foot 6 and weighs 240 pounds” and someone else in the same environment “who’s 4 foot 10 and weighs 89 pounds”? But the team also wondered if shape was only part of the story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Their multi-year experiment uses tools that anthropologists couldn’t have imagined a century ago—devices that track metabolism in real time and analyze genetics. Each participant gets a CT scan (measuring body shape), a DEXA scan (estimating percentages of fat and muscle), high-resolution 3D scans, and DNA analysis from saliva to examine ancestry genetically.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Volunteers lie on a cot in underwear, as I did, for about 45 minutes in each climate condition, all on separate days. There’s dry cold, around 40 °F, akin to braving a walk-in refrigerator. Then dry heat and humid heat: 112 °F with 15% humidity and 98&amp;nbsp;°F with 85% humidity. They call it “going to Vegas” and “going to Houston,” says Cowgill. The chamber session is long enough to measure an effect, but short enough to be safe.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Before I traveled to Texas, Cowgill told me she suspected the old rules would fall. Studies linking temperature tolerance to race and ethnicity, for example, seemed tenuous because biological anthropologists today reject the concept of distinct races. It’s a false premise, she told me: “No one in biological anthropology would argue that human beings do not vary across the globe—that’s obvious to anyone with eyes. [But] you can’t draw sharp borders around populations.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;She added, “I think there’s a substantial possibility that we spend four years testing this and find out that really, limb length, body mass, surface area […] are not the primary things that are predicting how well you do in cold and heat.”&amp;nbsp;&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Adaptable to a degree&lt;/h3&gt;  &lt;p&gt;In July 1995, a week-long heat wave pushed Chicago above 100 °F, killing roughly 500 people. Thirty years later, Ollie Jay, a physiologist at the University of Sydney, can duplicate the conditions of that exceptionally humid heat wave in a climate chamber at his laboratory.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“We can simulate the Chicago heat wave of ’95. The Paris heat wave of 2003. The heat wave [in early July of this year]&amp;nbsp; in Europe,” Jay says. “As long as we’ve got the temperature and humidity information, we can re-create those conditions.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt; &lt;p&gt;“Everybody has quite an intimate experience of feeling hot, so we’ve got 8 billion experts on how to keep cool,” he says. Yet our internal sense of when heat turns deadly is unreliable. Even professional athletes overseen by experienced medics have died after missing dangerous warning signs. And little research has been done to explore how vulnerable populations such as elderly people, those with heart disease, and low-income communities with limited access to cooling respond to extreme heat.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Jay’s team researches the most effective strategies for surviving it. He lambastes air-conditioning, saying it demands so much energy that it can aggravate climate change in “a vicious cycle.” Instead, he has monitored people’s vital signs while they use fans and skin mists to endure three hours in humid and dry heat. In results published last year, his research found that fans reduced cardiovascular strain by 86% for people with heart disease in the type of humid heat familiar in Chicago.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_16"&gt; &lt;p&gt;Dry heat was a different story. In that simulation, fans not only didn’t help but actually doubled the rate at which core temperatures rose in healthy older people.&lt;/p&gt;  &lt;p&gt;Heat kills. But not without a fight. Your body must keep its internal temperature in a narrow window flanking 98 °F by less than two degrees. The simple fact that you’re alive means you are &lt;em&gt;producing&lt;/em&gt; heat. Your body needs to export that heat without amassing much more. The nervous system relaxes narrow blood vessels along your skin. Your heart rate increases, propelling more warm blood to your extremities and away from your organs. You sweat. And when that sweat evaporates, it carries a torrent of body heat away with it.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;This thermoregulatory response can be trained. Studies by van Marken Lichtenbelt have shown that exposure to mild heat increases sweat capacity, decreases blood pressure, and drops resting heart rate. Long-term studies based on Finnish saunas suggest similar correlations.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The body may adapt protectively to cold, too. In this case, body heat is your lifeline. Shivering and exercise help keep bodies warm. So can clothing. Cardiovascular deaths are thought to spike in cold weather. But people more adapted to cold seem better able to reroute their blood flow in ways that keep their organs warm without dropping their temperature too many degrees in their extremities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Earlier this year, the biological anthropologist Stephanie B. Levy (no relation) reported that New Yorkers who experienced lower average temperatures had more productive brown fat, adding evidence for the idea that the inner workings of our bodies adjust to the climate throughout the year and perhaps even throughout our lives. “Do our bodies hold a biological memory of past seasons?” Levy wonders. “That’s still an open question. There’s some work in rodent models to suggest that that’s the case.”&lt;/p&gt;  &lt;p&gt;Although people clearly acclimatize with enough strenuous exposures to either cold or heat, Jay says, “you reach a ceiling.” Consider sweat: Heat exposure can increase the amount you sweat only until your skin is completely saturated. It’s a non­negotiable physical limit. Any additional sweat just means leaking water without carrying away any more heat. “I’ve heard people say we’ll just find a way of evolving out of this—we’ll biologically adapt,” Jay says. “Unless we’re completely changing our body shape, then that’s not going to happen.”&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_18"&gt; &lt;p&gt;And body shape may not even sway thermoregulation as much as previously believed. The subject I observed, a personal trainer, appeared outwardly adapted for cold: his broad shoulders didn’t even fit in a single CT scan image. Cowgill supposed that this muscle mass insulated him. When he emerged from his session in the 40 °F environment, though, he had finally started shivering—intensely. The researchers covered him in a heated blanket. He continued shivering. Driving to lunch over an hour later in a hot car, he still mentioned feeling cold. An hour after that, a finger prick drew no blood, a sign that blood vessels in his extremities remained constricted. His body temperature fell about half a degree C in the cold session—a significant drop—and his wider build did not appear to shield him from the cold as well as my involuntary shivering protected me.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I asked Cowgill if perhaps there is no such thing as being uniquely predisposed to hot or cold. “Absolutely,” she said.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A hot mess&lt;/h3&gt;  &lt;p&gt;So if body shape doesn’t tell us much about how a person maintains body temperature, and acclimation also runs into limits, then how do we determine how hot is too hot?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In 2010 two climate change researchers, Steven Sherwood and Matthew Huber, argued that regions around the world become uninhabitable at wet-bulb temperatures of 35 °C, or 95 °F. (Wet-bulb measurements are a way to combine air temperature and relative humidity.) Above 35 °C, a person simply wouldn’t be able to dissipate heat quickly enough. But it turns out that their estimate was too optimistic.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Researchers “ran with” that number for a decade, says Daniel Vecellio, a bioclimatologist at the University of Nebraska, Omaha. “But the number had never been actually empirically tested.” In 2021 a Pennsylvania State University physiologist, W. Larry Kenney, worked with Vecellio and others to test wet-bulb limits in a climate chamber. Kenney’s lab investigates which combinations of temperature, humidity, and time push a person’s body over the edge.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Not long after, the researchers came up with their own wet-bulb limit of human tolerance: below 31 °C in warm, humid conditions for the youngest cohort, people in their thermoregulatory prime. Their research suggests that a day reaching 98 °F and 65% humidity, for example, poses danger in a matter of hours, even for healthy people.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignwide size-large"&gt;&lt;img alt="alt" class="wp-image-1125253" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Clemons-MIT-8-25-307.jpg?w=2001" width="2001" /&gt;&lt;div class="image-credit"&gt;JUSTIN CLEMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125256" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Clemons-MIT-8-25-433_f18271.jpg" /&gt;&lt;div class="image-credit"&gt;JUSTIN CLEMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="three medical team members make preparations around a person on a gurney" class="wp-image-1125258" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Clemons-MIT-8-25-359-edited.jpg" /&gt;&lt;div class="image-credit"&gt;JUSTIN CLEMONS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="class"&gt; &lt;p class="imageSet__caption"&gt;Cowgill and her colleagues Elizabeth Cho (top) and Scott Maddux prepare graduate student Joanna Bui for a “room-temperature test.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;In 2023, Vecellio and Huber teamed up, combining the growing arsenal of lab data with state-of-the-art climate simulations to predict where heat and humidity most threatened global populations: first the Middle East and South Asia, then sub-Saharan Africa and eastern China. And assuming that warming reaches 3 to 4 °C over preindustrial levels this century, as predicted, parts of North America, South America, and northern and central Australia will be next.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Last June, Vecellio, Huber, and Kenney co-published an article revising the limits that Huber had proposed in 2010. “Why not 35 °C?” explained why the human limits have turned out to be lower than expected. Those initial estimates overlooked the fact that our skin temperature can quickly jump above 101 °F in hot weather, for example, making it harder to dump internal heat.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;The Penn State team has published deep dives on how heat tolerance changes with sex and age. Older participants’ wet-bulb limits wound up being even lower—between 27 and 28 °C in warm, humid conditions—and varied more from person to person than they did in young people. “The conditions that we experience now—especially here in North America and Europe, places like that—are well below the limits that we found in our research,” Vecellio says. “We know that heat kills now.” &amp;nbsp;&lt;/p&gt;  &lt;p&gt;What this fast-growing body of research suggests, Vecellio stresses, is that you can’t define heat risk by just one or two numbers. Last year, he and researchers at Arizona State University pulled up the hottest 10% of hours between 2005 and 2020 for each of 96 US cities. They wanted to compare recent heat-health research with historical weather data for a new perspective: How frequently is it so hot that people’s bodies can’t compensate for it? Over 88% of those “hot hours” met that criterion for people in full sun. In the shade, most of those heat waves became meaningfully less dangerous.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“There’s really almost no one who ‘needs’ to die in a heat wave,” says Ebi, the epidemiologist. “We have the tools. We have the understanding. Essentially all [those] deaths are preventable.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;More than a number&lt;/h3&gt;  &lt;p&gt;A year after visiting Texas, I called Cowgill to hear what she was thinking after four summers of chamber experiments. She told me that the only rule about hot and cold she currently stands behind is … well, none.&lt;/p&gt;  &lt;p&gt;She recalled a recent participant—the smallest man in the study, weighing 114 pounds. “He shivered like a leaf on a tree,” Cowgill says. Normally, a strong shiverer warms up quickly. Core temperature may even climb a little. “This [guy] was just shivering and shivering and shivering and not getting any warmer,” she says. She doesn’t know why this happened. “Every time I think I get a picture of what’s going on in there, we’ll have one person come in and just kind of be a complete exception to the rule,” she says, adding that you can’t just gloss over how much human bodies vary inside and out.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt;&lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;The same messiness complicates physiology studies.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;Jay looks to embrace bodily complexities by improving physiological simulations of heat and the human strain it causes. He’s piloted studies that input a person’s activity level and type of clothing to predict core temperature, dehydration, and cardiovascular strain based on the particular level of heat. One can then estimate the person’s risk on the basis of factors like age and health. He’s also working on physiological models to identify vulnerable groups, inform early-warning systems ahead of heat waves, and possibly advise cities on whether interventions like fans and mists can help protect residents. “Heat is an all-of-­society issue,” Ebi says. Officials could better prepare the public for cold snaps this way too.&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;“Death is not the only thing we’re concerned about,” Jay adds.&amp;nbsp; Extreme temperatures bring morbidity and sickness and strain hospital systems: “There’s all these community-level impacts that we’re just completely missing.”&lt;/p&gt;  &lt;p&gt;Climate change forces us to reckon with the knotty science of how our bodies interact with the environment. Predicting the health effects is a big and messy matter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The first wave of answers from Fort Worth will materialize next year. The researchers will analyze thermal images to crunch data on brown fat. They’ll resolve whether, as Cowgill suspects, your body shape may not sway temperature tolerance as much as previously assumed. “Human variation is the rule,” she says, “not the exception.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Max G. Levy is an independent journalist who writes about chemistry, public health, and the environment.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/15/1124949/bodies-heat-climate-change-extreme-temperatures/</guid><pubDate>Wed, 15 Oct 2025 10:00:00 +0000</pubDate></item><item><title>Future-proofing business capabilities with AI technologies (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/15/1124329/future-proofing-business-capabilities-with-ai-technologies/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In collaboration with&lt;/span&gt;Cloudera and AWS&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Artificial intelligence has always promised speed, efficiency, and new ways of solving problems. But what’s changed in the past few years is how quickly those promises are becoming reality. From oil and gas to retail, logistics to law, AI is no longer confined to pilot projects or speculative labs. It is being deployed in critical workflows, reducing processes that once took hours to just minutes, and freeing up employees to focus on higher-value work.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125555" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MITTRICloudera-1200px-social-card.png" /&gt;&lt;/figure&gt;    &lt;p&gt;“Business process automation has been around a long while. What GenAI and AI agents are allowing us to do is really give superpowers, so to speak, to business process automation.” says chief AI architect at Cloudera, Manasi Vartak.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;Much of the momentum is being driven by two related forces: the rise of AI agents and the rapid democratization of AI tools. AI agents, whether designed for automation or assistance, are proving especially powerful at speeding up response times and removing friction from complex workflows. Instead of waiting on humans to interpret a claim form, read a contract, or process a delivery driver’s query, AI agents can now do it in seconds, and at scale.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At the same time, advances in usability are putting AI into the hands of nontechnical staff, making it easier for employees across various functions to experiment, adopt and adapt these tools for their own needs.&lt;/p&gt; 
 &lt;p&gt;That doesn’t mean the road is without obstacles. Concerns about privacy, security, and the accuracy of LLMs remain pressing. Enterprises are also grappling with the realities of cost management, data quality, and how to build AI systems that are sustainable over the long term. And as companies explore what comes next—including autonomous agents, domain-specific models, and even steps toward artificial general intelligence—questions about trust, governance, and responsible deployment loom large.&lt;/p&gt;  &lt;p&gt;“Your leadership is especially critical in making sure that your business has an AI strategy that addresses both the opportunity and the risk while giving the workforce some ability to upskill such that there's a path to become fluent with these AI tools,” says principal advisor of AI and modern data strategy at Amazon Web Services, Eddie Kim.&lt;/p&gt; 
 &lt;p&gt;Still, the case studies are compelling. A global energy company cutting threat detection times from over an hour to just seven minutes. A Fortune 100 legal team saving millions by automating contract reviews. A humanitarian aid group harnessing AI to respond faster to crises. Long gone are the days of incremental steps forward. These examples illustrate that when data, infrastructure, and AI expertise come together, the impact is transformative.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The future of enterprise AI will be defined by how effectively organizations can marry innovation with scale, security, and strategy. That’s where the real race is happening.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the webcast now.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In collaboration with&lt;/span&gt;Cloudera and AWS&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Artificial intelligence has always promised speed, efficiency, and new ways of solving problems. But what’s changed in the past few years is how quickly those promises are becoming reality. From oil and gas to retail, logistics to law, AI is no longer confined to pilot projects or speculative labs. It is being deployed in critical workflows, reducing processes that once took hours to just minutes, and freeing up employees to focus on higher-value work.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125555" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/MITTRICloudera-1200px-social-card.png" /&gt;&lt;/figure&gt;    &lt;p&gt;“Business process automation has been around a long while. What GenAI and AI agents are allowing us to do is really give superpowers, so to speak, to business process automation.” says chief AI architect at Cloudera, Manasi Vartak.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;Much of the momentum is being driven by two related forces: the rise of AI agents and the rapid democratization of AI tools. AI agents, whether designed for automation or assistance, are proving especially powerful at speeding up response times and removing friction from complex workflows. Instead of waiting on humans to interpret a claim form, read a contract, or process a delivery driver’s query, AI agents can now do it in seconds, and at scale.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;At the same time, advances in usability are putting AI into the hands of nontechnical staff, making it easier for employees across various functions to experiment, adopt and adapt these tools for their own needs.&lt;/p&gt; 
 &lt;p&gt;That doesn’t mean the road is without obstacles. Concerns about privacy, security, and the accuracy of LLMs remain pressing. Enterprises are also grappling with the realities of cost management, data quality, and how to build AI systems that are sustainable over the long term. And as companies explore what comes next—including autonomous agents, domain-specific models, and even steps toward artificial general intelligence—questions about trust, governance, and responsible deployment loom large.&lt;/p&gt;  &lt;p&gt;“Your leadership is especially critical in making sure that your business has an AI strategy that addresses both the opportunity and the risk while giving the workforce some ability to upskill such that there's a path to become fluent with these AI tools,” says principal advisor of AI and modern data strategy at Amazon Web Services, Eddie Kim.&lt;/p&gt; 
 &lt;p&gt;Still, the case studies are compelling. A global energy company cutting threat detection times from over an hour to just seven minutes. A Fortune 100 legal team saving millions by automating contract reviews. A humanitarian aid group harnessing AI to respond faster to crises. Long gone are the days of incremental steps forward. These examples illustrate that when data, infrastructure, and AI expertise come together, the impact is transformative.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The future of enterprise AI will be defined by how effectively organizations can marry innovation with scale, security, and strategy. That’s where the real race is happening.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the webcast now.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/15/1124329/future-proofing-business-capabilities-with-ai-technologies/</guid><pubDate>Wed, 15 Oct 2025 11:07:35 +0000</pubDate></item><item><title>The Download: Big Tech’s carbon removals plans, and the next wave of nuclear reactors (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/10/15/1125770/the-download-big-techs-carbon-removals-plans-and-the-next-wave-of-nuclear-reactors/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Big Tech’s big bet on a controversial carbon removal tactic&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Microsoft, JP MorganChase, and a tech company consortium that includes Alphabet, Meta, Shopify, and Stripe have all recently struck multimillion-dollar deals to pay paper mill owners to capture at least hundreds of thousands of tons of this greenhouse gas by installing carbon scrubbing equipment in their facilities.&lt;/p&gt;&lt;p&gt;The captured carbon dioxide will then be piped down into saline aquifers more than a mile underground, where it should be sequestered permanently.&lt;/p&gt;&lt;p&gt;Big Tech is suddenly betting big on this form of carbon removal, known as bioenergy with carbon capture and storage, or BECCS. But experts have raised a number of concerns.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;2025 climate tech companies to watch: Kairos Power and its next-generation nuclear reactors&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Like many new nuclear startups, Kairos promises a path to reliable, 24/7 decarbonized power. Unlike most, it already has prototypes under construction and permits for several reactors.&lt;/p&gt;&lt;p&gt;The company uses molten salt to cool its reactions and transfer heat, rather than the high-pressure water that’s used in existing fission reactors. It hopes its technology will enable commercial reactors that are cost-competitive with natural gas plants and boast safer operation than conventional reactors, even in the event of complete power loss. Read the full story.&lt;/p&gt;  &lt;p&gt;—&lt;em&gt;Mark Harris&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Kairos Power is one of our 10 climate tech companies to watch—our annual list of some of the most promising climate tech firms on the planet. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Inside the strange limbo facing millions of IVF embryos&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Millions of embryos created through IVF sit frozen in time, stored in tanks around the world. The number is only growing thanks to advances in technology, the rising popularity of IVF, and improvements in its success rates.&lt;/p&gt;&lt;p&gt;At a basic level, an embryo is simply a tiny ball of a hundred or so cells. But unlike other types of body tissue, it holds the potential for life. Many argue that this endows embryos with a special moral status, one that requires special protections.&lt;/p&gt;&lt;p&gt;The problem is that no one can really agree on what that status is. While these embryos persist in suspended animation, patients, clinicians, embryologists, and legislators must grapple with the essential question of what we should do with them. What do these embryos mean to us? Who should be responsible for them?&lt;/p&gt;  &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 ChatGPT will start talking dirty to verified adults&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The chatbot is getting a new erotica function as part of OpenAI’s bid to “safely relax” its restrictions. (The Verge)&lt;br /&gt;+ &lt;em&gt;The company has created its own wellness council to inform its decisions. &lt;/em&gt;(Ars Technica)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 A secret surveillance empire tracked thousands of people across the world&lt;/strong&gt;&lt;br /&gt;The European-led First Wap has operated covertly for more than two decades. (Mother Jones)&lt;br /&gt;+ &lt;em&gt;The group ran at least 10 scam compounds across the country. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Inside a romance scam compound—and how people get tricked into being there. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;3 YouTube ran Israel-funded ads claiming there was food in famine-struck Gaza&lt;br /&gt;&lt;/strong&gt;And allowed them to remain online even after complaints from multiple government authorities. (WP $)&lt;br /&gt;+ &lt;em&gt;Companies have denied they’re involved in rebuilding Gaza. &lt;/em&gt;(Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Instagram wants to become a more teen-friendly space&lt;br /&gt;&lt;/strong&gt;It’s bringing in new age-gating measures inspired by the PG-13 movie rating. (NBC News)&lt;br /&gt;+ &lt;em&gt;The policy will also extend to its chatbots. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 A massive Cambodia-based pig butchering scheme has been foiled&lt;/strong&gt;&lt;br /&gt;It’s the biggest forfeiture action the US Department of Justice has ever pursued. (CNBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Waymo’s driverless taxis are coming to London&lt;/strong&gt;&lt;br /&gt;From next year, it says pedestrians will be able to hail its robotaxis. (WSJ $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 Black patients were failed by a race-based medical calculation&lt;/strong&gt;&lt;br /&gt;It delayed their access to life-saving kidney transplants. (The Markup)&lt;br /&gt;+ &lt;em&gt;A woman in the US is the third person to receive a gene-edited pig kidney. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;8 AI flood forecasting is helping farmers across the world&lt;br /&gt;Nonprofits are using it to deliver early aid. (Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 A man with paralysis can feel objects through another person's hand&lt;/strong&gt;&lt;br /&gt;Thanks to a new brain implant. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Meet the other companies developing brain-computer interfaces. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Tech internships are alive and well&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Despite all the AI angst. (Insider $)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“You made ChatGPT “pretty restrictive”? Really. Is that why it has been recommending kids harm and kill themselves?”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Josh Hawley, US Senator for Missouri, reacts to the news OpenAI is planning to loosen its restrictions in a post on X.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125772" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_73ddb9.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why we should thank pigeons for our AI breakthroughs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;People looking for precursors to artificial intelligence often point to science fiction by authors like Isaac Asimov or thought experiments like the Turing test. But an equally important, if surprising and less appreciated, forerunner is American psychologist B.F. Skinner’s research with pigeons in the middle of the 20th century.&lt;/p&gt;&lt;p&gt;Skinner believed that association—learning, through trial and error, to link an action with a punishment or reward—was the building block of every behavior, not just in pigeons but in all living organisms, including human beings.&lt;/p&gt;&lt;p&gt;His “behaviorist” theories fell out of favor with psychologists and animal researchers in the 1960s but were taken up by computer scientists who eventually provided the foundation for many of the artificial-intelligence tools from leading firms like Google and OpenAI. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ben Crair&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ I love the sound of Grateful Fishing TV—starring two fishermen who just love hanging out and frying some fish. Truly wholesome stuff (thanks to Chino Moreno via Perfectly Imperfect for the recommendation!)&lt;br /&gt;+ Rest in power D’Angelo, your timeless tunes will live on.&lt;br /&gt;+ If you’re into stress-watches, this list is full of anxiety-inducing classics.&lt;br /&gt;+ One of the world’s longest dinosaur superhighways has been uncovered in a sleepy part of England.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Big Tech’s big bet on a controversial carbon removal tactic&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Microsoft, JP MorganChase, and a tech company consortium that includes Alphabet, Meta, Shopify, and Stripe have all recently struck multimillion-dollar deals to pay paper mill owners to capture at least hundreds of thousands of tons of this greenhouse gas by installing carbon scrubbing equipment in their facilities.&lt;/p&gt;&lt;p&gt;The captured carbon dioxide will then be piped down into saline aquifers more than a mile underground, where it should be sequestered permanently.&lt;/p&gt;&lt;p&gt;Big Tech is suddenly betting big on this form of carbon removal, known as bioenergy with carbon capture and storage, or BECCS. But experts have raised a number of concerns.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—James Temple&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;2025 climate tech companies to watch: Kairos Power and its next-generation nuclear reactors&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Like many new nuclear startups, Kairos promises a path to reliable, 24/7 decarbonized power. Unlike most, it already has prototypes under construction and permits for several reactors.&lt;/p&gt;&lt;p&gt;The company uses molten salt to cool its reactions and transfer heat, rather than the high-pressure water that’s used in existing fission reactors. It hopes its technology will enable commercial reactors that are cost-competitive with natural gas plants and boast safer operation than conventional reactors, even in the event of complete power loss. Read the full story.&lt;/p&gt;  &lt;p&gt;—&lt;em&gt;Mark Harris&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Kairos Power is one of our 10 climate tech companies to watch—our annual list of some of the most promising climate tech firms on the planet. &lt;/strong&gt;&lt;strong&gt;Check out the rest of the list here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: Inside the strange limbo facing millions of IVF embryos&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Millions of embryos created through IVF sit frozen in time, stored in tanks around the world. The number is only growing thanks to advances in technology, the rising popularity of IVF, and improvements in its success rates.&lt;/p&gt;&lt;p&gt;At a basic level, an embryo is simply a tiny ball of a hundred or so cells. But unlike other types of body tissue, it holds the potential for life. Many argue that this endows embryos with a special moral status, one that requires special protections.&lt;/p&gt;&lt;p&gt;The problem is that no one can really agree on what that status is. While these embryos persist in suspended animation, patients, clinicians, embryologists, and legislators must grapple with the essential question of what we should do with them. What do these embryos mean to us? Who should be responsible for them?&lt;/p&gt;  &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 ChatGPT will start talking dirty to verified adults&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The chatbot is getting a new erotica function as part of OpenAI’s bid to “safely relax” its restrictions. (The Verge)&lt;br /&gt;+ &lt;em&gt;The company has created its own wellness council to inform its decisions. &lt;/em&gt;(Ars Technica)&lt;br /&gt;+ &lt;em&gt;It’s surprisingly easy to stumble into a relationship with an AI chatbot. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 A secret surveillance empire tracked thousands of people across the world&lt;/strong&gt;&lt;br /&gt;The European-led First Wap has operated covertly for more than two decades. (Mother Jones)&lt;br /&gt;+ &lt;em&gt;The group ran at least 10 scam compounds across the country. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;Inside a romance scam compound—and how people get tricked into being there. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;3 YouTube ran Israel-funded ads claiming there was food in famine-struck Gaza&lt;br /&gt;&lt;/strong&gt;And allowed them to remain online even after complaints from multiple government authorities. (WP $)&lt;br /&gt;+ &lt;em&gt;Companies have denied they’re involved in rebuilding Gaza. &lt;/em&gt;(Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Instagram wants to become a more teen-friendly space&lt;br /&gt;&lt;/strong&gt;It’s bringing in new age-gating measures inspired by the PG-13 movie rating. (NBC News)&lt;br /&gt;+ &lt;em&gt;The policy will also extend to its chatbots. &lt;/em&gt;(NYT $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 A massive Cambodia-based pig butchering scheme has been foiled&lt;/strong&gt;&lt;br /&gt;It’s the biggest forfeiture action the US Department of Justice has ever pursued. (CNBC)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Waymo’s driverless taxis are coming to London&lt;/strong&gt;&lt;br /&gt;From next year, it says pedestrians will be able to hail its robotaxis. (WSJ $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;7 Black patients were failed by a race-based medical calculation&lt;/strong&gt;&lt;br /&gt;It delayed their access to life-saving kidney transplants. (The Markup)&lt;br /&gt;+ &lt;em&gt;A woman in the US is the third person to receive a gene-edited pig kidney. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;8 AI flood forecasting is helping farmers across the world&lt;br /&gt;Nonprofits are using it to deliver early aid. (Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 A man with paralysis can feel objects through another person's hand&lt;/strong&gt;&lt;br /&gt;Thanks to a new brain implant. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Meet the other companies developing brain-computer interfaces. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;10 Tech internships are alive and well&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Despite all the AI angst. (Insider $)&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“You made ChatGPT “pretty restrictive”? Really. Is that why it has been recommending kids harm and kill themselves?”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Josh Hawley, US Senator for Missouri, reacts to the news OpenAI is planning to loosen its restrictions in a post on X.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1125772" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/image_73ddb9.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Why we should thank pigeons for our AI breakthroughs&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;People looking for precursors to artificial intelligence often point to science fiction by authors like Isaac Asimov or thought experiments like the Turing test. But an equally important, if surprising and less appreciated, forerunner is American psychologist B.F. Skinner’s research with pigeons in the middle of the 20th century.&lt;/p&gt;&lt;p&gt;Skinner believed that association—learning, through trial and error, to link an action with a punishment or reward—was the building block of every behavior, not just in pigeons but in all living organisms, including human beings.&lt;/p&gt;&lt;p&gt;His “behaviorist” theories fell out of favor with psychologists and animal researchers in the 1960s but were taken up by computer scientists who eventually provided the foundation for many of the artificial-intelligence tools from leading firms like Google and OpenAI. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ben Crair&lt;/em&gt;&lt;/p&gt;   
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ I love the sound of Grateful Fishing TV—starring two fishermen who just love hanging out and frying some fish. Truly wholesome stuff (thanks to Chino Moreno via Perfectly Imperfect for the recommendation!)&lt;br /&gt;+ Rest in power D’Angelo, your timeless tunes will live on.&lt;br /&gt;+ If you’re into stress-watches, this list is full of anxiety-inducing classics.&lt;br /&gt;+ One of the world’s longest dinosaur superhighways has been uncovered in a sleepy part of England.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/10/15/1125770/the-download-big-techs-carbon-removals-plans-and-the-next-wave-of-nuclear-reactors/</guid><pubDate>Wed, 15 Oct 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] How Starcloud Is Bringing Data Centers to Outer Space (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/starcloud/</link><description>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
	
	


	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.1 (Yoast SEO v26.1.1) - https://yoast.com/wordpress/plugins/seo/ --&gt;
	How Starcloud Is Bringing Data Centers to Outer Space | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;






































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					The NVIDIA Inception startup projects that space-based data centers will offer 10x lower energy costs and reduce the need for energy consumption on Earth.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	&lt;p&gt;
		&lt;video class="full-width-layout__hero-video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;	&lt;/p&gt;

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Extraterrestrial data centers are just on the horizon. Soon, an AI-equipped satellite from Starcloud, a member of the NVIDIA Inception program for startups, will orbit the Earth.&lt;/p&gt;
&lt;p&gt;It’s a large step toward the startup’s ultimate goal to bring state-of-the-art data centers to outer space. This can be a part of the solution to address challenges faced by rising AI demands, including energy consumption and cooling requirements for data centers on Earth.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-5gw-data-center.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Starcloud plans to build a 5-gigawatt orbital data center with super-large solar and cooling panels approximately 4 kilometers in width and length. Video courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“In space, you get almost unlimited, low-cost renewable energy,” said Philip Johnston, cofounder and CEO of the startup, which is based in Redmond, Washington. “The only cost on the environment will be on the launch, then there will be 10x carbon-dioxide savings over the life of the data center compared with powering the data center terrestrially on Earth.”&lt;/p&gt;
&lt;p&gt;Starcloud’s upcoming satellite launch, planned for November, will mark the NVIDIA H100 GPU’s cosmic debut — and the first time a state-of-the-art, data center-class GPU is in outer space.&lt;/p&gt;
&lt;p&gt;The 60-kilogram Starcloud-1 satellite, about the size of a small fridge, is expected to offer 100x more powerful GPU compute than any previous space-based operation.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			An engineer inspects the Starcloud-1 satellite planned for launch in November. The silver module inside the satellite houses the NVIDIA H100 GPU. Video courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;How Data Centers in Space Can Increase Sustainability&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Instead of relying on fresh water for cooling through evaporation towers, as many Earth-based data centers do, Starcloud’s space-based data centers can use the vacuum of deep space as an infinite heat sink.&lt;/p&gt;
&lt;p&gt;Emitting waste heat from infrared radiation into space can conserve significant water resources on Earth, since water isn’t needed for cooling. Constant exposure to the sun in orbit also means nearly infinite solar power — aka no need for the data centers to rely on batteries or backup power.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__narrow-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-solar-panel.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			One of the solar panels on the Starcloud-1 satellite launching in November. Video courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Starcloud projects the energy costs in space to be 10x cheaper than land-based options, even including launch expenses. “In 10 years, nearly all new data centers will be being built in outer space,” Johnston predicts.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“In 10 years, nearly all new data centers will be being built in outer space,” said Philip Johnston, cofounder and CEO of Starcloud." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-johnston-quote-pulled-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Applications for Space-Based Data Centers&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;An early use case for extraterrestrial data centers is the analysis of Earth observation data, which could inform applications for detecting crop types and predicting local weather.&lt;/p&gt;
&lt;p&gt;Plus, real-time data processing in space offers immense benefits for critical applications such as wildfire detection and distress-signal response. Running inference in space, right where the data’s collected, allows insights to be delivered nearly instantaneously, reducing response times from hours to minutes.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="A rendering of Starcloud’s satellite orbiting the terminator line — the line between night and day." class="full-width-layout__image" height="900" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-orbital-line.jpeg" width="1600" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A rendering of Starcloud’s satellite orbiting the terminator line — the line between night and day. Image courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Earth observation methods include optical imaging with cameras, hyperspectral imaging using light wavelengths beyond human vision and synthetic-aperture radar (SAR) imaging to build high-resolution, 3D maps of Earth.&lt;/p&gt;
&lt;p&gt;SAR, in particular, generates lots of data — about 10 gigabytes per second, according to Johnston — so in-space inference would be especially beneficial when creating these maps.&lt;/p&gt;
&lt;p&gt;“Starcloud needs to be competitive with the type of workload you can run on an Earth-based data center, and NVIDIA GPUs are the most performant in terms of training, fine-tuning and inference,” Johnston said, explaining why the company chose to use NVIDIA accelerated computing on its upcoming satellite launch.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__narrow-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-star-tracker.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Starcloud cofounder and CEO Philip Johnston examines the star tracker, used for orienting the satellite. Video courtesy of Starcloud. 		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Being a part of NVIDIA Inception has been critical, as it provided us with technical support, access to NVIDIA experts and NVIDIA GPUs,” Johnston added.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1048" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-team.jpg" width="1243" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Starcloud team including engineers as well as cofounders Ezra Feilden, Philip Johnston and Adi Oltean. Image courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;


&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</description><content:encoded>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	
	
	


	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.1 (Yoast SEO v26.1.1) - https://yoast.com/wordpress/plugins/seo/ --&gt;
	How Starcloud Is Bringing Data Centers to Outer Space | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;






































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		
&lt;div class="full-width-layout__hero light"&gt;
	&lt;div class="full-width-layout__hero-content light"&gt;
		&lt;div class="full-width-layout__hero-content__inner light"&gt;
			

							&lt;p&gt;
					The NVIDIA Inception startup projects that space-based data centers will offer 10x lower energy costs and reduce the need for energy consumption on Earth.				&lt;/p&gt;
			
			
		&lt;/div&gt;
	&lt;/div&gt;

	&lt;p&gt;
		&lt;video class="full-width-layout__hero-video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;	&lt;/p&gt;

	&lt;/div&gt;

	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Extraterrestrial data centers are just on the horizon. Soon, an AI-equipped satellite from Starcloud, a member of the NVIDIA Inception program for startups, will orbit the Earth.&lt;/p&gt;
&lt;p&gt;It’s a large step toward the startup’s ultimate goal to bring state-of-the-art data centers to outer space. This can be a part of the solution to address challenges faced by rising AI demands, including energy consumption and cooling requirements for data centers on Earth.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-5gw-data-center.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Starcloud plans to build a 5-gigawatt orbital data center with super-large solar and cooling panels approximately 4 kilometers in width and length. Video courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“In space, you get almost unlimited, low-cost renewable energy,” said Philip Johnston, cofounder and CEO of the startup, which is based in Redmond, Washington. “The only cost on the environment will be on the launch, then there will be 10x carbon-dioxide savings over the life of the data center compared with powering the data center terrestrially on Earth.”&lt;/p&gt;
&lt;p&gt;Starcloud’s upcoming satellite launch, planned for November, will mark the NVIDIA H100 GPU’s cosmic debut — and the first time a state-of-the-art, data center-class GPU is in outer space.&lt;/p&gt;
&lt;p&gt;The 60-kilogram Starcloud-1 satellite, about the size of a small fridge, is expected to offer 100x more powerful GPU compute than any previous space-based operation.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-video-section"&gt;
	&lt;video class="full-width-layout__video js-responsive-video" loop="loop"&gt;Your browser does not support the video tag.&lt;/video&gt;
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			An engineer inspects the Starcloud-1 satellite planned for launch in November. The silver module inside the satellite houses the NVIDIA H100 GPU. Video courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;How Data Centers in Space Can Increase Sustainability&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Instead of relying on fresh water for cooling through evaporation towers, as many Earth-based data centers do, Starcloud’s space-based data centers can use the vacuum of deep space as an infinite heat sink.&lt;/p&gt;
&lt;p&gt;Emitting waste heat from infrared radiation into space can conserve significant water resources on Earth, since water isn’t needed for cooling. Constant exposure to the sun in orbit also means nearly infinite solar power — aka no need for the data centers to rely on batteries or backup power.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__narrow-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-solar-panel.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			One of the solar panels on the Starcloud-1 satellite launching in November. Video courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Starcloud projects the energy costs in space to be 10x cheaper than land-based options, even including launch expenses. “In 10 years, nearly all new data centers will be being built in outer space,” Johnston predicts.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="“In 10 years, nearly all new data centers will be being built in outer space,” said Philip Johnston, cofounder and CEO of Starcloud." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-johnston-quote-pulled-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Applications for Space-Based Data Centers&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;An early use case for extraterrestrial data centers is the analysis of Earth observation data, which could inform applications for detecting crop types and predicting local weather.&lt;/p&gt;
&lt;p&gt;Plus, real-time data processing in space offers immense benefits for critical applications such as wildfire detection and distress-signal response. Running inference in space, right where the data’s collected, allows insights to be delivered nearly instantaneously, reducing response times from hours to minutes.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="A rendering of Starcloud’s satellite orbiting the terminator line — the line between night and day." class="full-width-layout__image" height="900" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-orbital-line.jpeg" width="1600" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			A rendering of Starcloud’s satellite orbiting the terminator line — the line between night and day. Image courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Earth observation methods include optical imaging with cameras, hyperspectral imaging using light wavelengths beyond human vision and synthetic-aperture radar (SAR) imaging to build high-resolution, 3D maps of Earth.&lt;/p&gt;
&lt;p&gt;SAR, in particular, generates lots of data — about 10 gigabytes per second, according to Johnston — so in-space inference would be especially beneficial when creating these maps.&lt;/p&gt;
&lt;p&gt;“Starcloud needs to be competitive with the type of workload you can run on an Earth-based data center, and NVIDIA GPUs are the most performant in terms of training, fine-tuning and inference,” Johnston said, explaining why the company chose to use NVIDIA accelerated computing on its upcoming satellite launch.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__narrow-video-section"&gt;
			&lt;video class="full-width-layout__video" loop="loop"&gt;
							&lt;source src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-star-tracker.mp4" type="video/mp4" /&gt;
						&lt;p&gt;Your browser does not support HTML5 video.&lt;/p&gt;
		&lt;/video&gt;
	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Starcloud cofounder and CEO Philip Johnston examines the star tracker, used for orienting the satellite. Video courtesy of Starcloud. 		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;“Being a part of NVIDIA Inception has been critical, as it provided us with technical support, access to NVIDIA experts and NVIDIA GPUs,” Johnston added.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1048" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/starcloud-team.jpg" width="1243" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Starcloud team including engineers as well as cofounders Ezra Feilden, Philip Johnston and Adi Oltean. Image courtesy of Starcloud.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;


&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/starcloud/</guid><pubDate>Wed, 15 Oct 2025 13:00:55 +0000</pubDate></item><item><title>[NEW] Coral NPU: A full-stack platform for Edge AI (The latest research from Google)</title><link>https://research.google/blog/coral-npu-a-full-stack-platform-for-edge-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Acknowledgements&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;&lt;i&gt;We would like to thank the core contributors and leadership team for this work, particularly Billy Rutledge, Ben Laurie, Derek Chow, Michael Hoang, Naveen Dodda, Murali Vijayaraghavan, Gregory Kielian, Matthew Wilson, Bill Luan, Divya Pandya, Preeti Singh, Akib Uddin, Stefan Hall, Alex Van Damme, David Gao, Lun Dong, Julian Mullings-Black, Roman Lewkow, Shaked Flur, Yenkai Wang, Reid Tatge, Tim Harvey, Tor Jeremiassen, Isha Mishra, Kai Yick, Cindy Liu, Bangfei Pan, Ian Field, Srikanth Muroor, Jay Yagnik, Avinatan Hassidim, and Yossi Matias.&lt;/i&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Acknowledgements&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;&lt;i&gt;We would like to thank the core contributors and leadership team for this work, particularly Billy Rutledge, Ben Laurie, Derek Chow, Michael Hoang, Naveen Dodda, Murali Vijayaraghavan, Gregory Kielian, Matthew Wilson, Bill Luan, Divya Pandya, Preeti Singh, Akib Uddin, Stefan Hall, Alex Van Damme, David Gao, Lun Dong, Julian Mullings-Black, Roman Lewkow, Shaked Flur, Yenkai Wang, Reid Tatge, Tim Harvey, Tor Jeremiassen, Isha Mishra, Kai Yick, Cindy Liu, Bangfei Pan, Ian Field, Srikanth Muroor, Jay Yagnik, Avinatan Hassidim, and Yossi Matias.&lt;/i&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/coral-npu-a-full-stack-platform-for-edge-ai/</guid><pubDate>Wed, 15 Oct 2025 13:07:00 +0000</pubDate></item><item><title>[NEW] 3 days left: Save up to $624 on your TechCrunch Disrupt 2025 Pass before prices rise (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/3-days-left-save-up-to-624-on-your-techcrunch-disrupt-2025-pass-before-prices-rise/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The final countdown of the final flash sale is here. Only three days remain to save up to $624 on your &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; pass before prices increase on Friday, October 17 at 11:59 p.m. PT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From October 27–29 at San Francisco’s Moscone West, Disrupt 2025 will bring together 10,000+ founders, investors, and operators for three days of ideas, dealmaking, and discovery across more than 200 sessions, 250+ speakers, and 300+ exhibiting startups building what’s next.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now to save up to $624&lt;/strong&gt; on your pass before this week ends. Got a group? Save up to 30% on &lt;strong&gt;group passes&lt;/strong&gt;. Bringing a plus-one? Get 50% off the second pass.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 3 days left" class="wp-image-3011291" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_3Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-where-innovation-and-opportunity-collide"&gt;Where innovation and opportunity collide&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is where the global startup ecosystem comes to connect, learn, and move faster. Discover the trends shaping AI, fintech, climate tech, mobility, and frontier industries, and meet the people leading those transformations.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 Breakout Session" class="wp-image-2985187" height="454" src="https://techcrunch.com/wp-content/uploads/2025/03/Disrupt-2024-Breakout.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; returns with the top 20 early-stage startups pitching live for $100,000 equity-free funding on the main stage.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Unparalleled networking&lt;/strong&gt; opportunities through curated meetups and impromptu run-ins.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Expert-led programming&lt;/strong&gt; designed to deliver actionable insights for founders, investors, and operators alike.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-featured-speakers"&gt;Featured speakers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Sarah Guo and Elad Gil" class="wp-image-2660351" height="453" src="https://techcrunch.com/wp-content/uploads/2024/02/53486897769_be737acd80_k.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Join the industry’s most influential voices, including:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Chris Barman&lt;/strong&gt;, CEO,&amp;nbsp;Slate Auto&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Baiju Bhatt&lt;/strong&gt;, founder, Aetherflux&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roelof Botha&lt;/strong&gt;, managing partner,&amp;nbsp;Sequoia Capital&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Phoebe Gates&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Sophia Kianni&lt;/strong&gt;, co-founders,&amp;nbsp;Phia&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elad Gil&lt;/strong&gt;, CEO, Gil &amp;amp; Co.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Vinod Khosla&lt;/strong&gt;, founder,&amp;nbsp;Khosla Ventures&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tekedra Mawakana&lt;/strong&gt;, co-CEO,&amp;nbsp;Waymo&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Bridgit Mendler&lt;/strong&gt;, co-founder, Northwood Space&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Kevin Scott&lt;/strong&gt;, CTO,&amp;nbsp;Microsoft&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elizabeth Stone&lt;/strong&gt;, CTO,&amp;nbsp;Netflix&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Anatoly Yakovenko&lt;/strong&gt;, co-founder, Solana, and CEO,&amp;nbsp;Solana Labs&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Check out the &lt;strong&gt;250+ top voices&lt;/strong&gt; joining the Disrupt lineup&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-1707092" height="453" src="https://techcrunch.com/wp-content/uploads/2018/09/disruptsf18_brynn_putnam_mirror-1618.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steve Jennings / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-passes-for-everyone-in-tech"&gt;Passes for everyone in tech&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is &lt;em&gt;the&lt;/em&gt; tech epicenter of the year. Anybody and everybody who is building, investing, operating, or simply has a passion for tech, there’s&amp;nbsp;&lt;strong&gt;a pass designed for you&lt;/strong&gt;, your plus-one,&amp;nbsp;or&amp;nbsp;&lt;strong&gt;your team&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-founder-pass-build-smarter-scale-faster"&gt;Founder Pass: Build smarter, scale faster&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Founder Pass&lt;/strong&gt; is built for entrepreneurs ready to grow.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Access the &lt;strong&gt;Deal Flow Cafe&lt;/strong&gt; for networking and investor meetups.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Learn from &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; finalists and alumni who’ve gone on to raise millions.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Attend tactical sessions on &lt;strong&gt;fundraising, product strategy, and scaling&lt;/strong&gt;.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Connect directly with mentors, partners, and journalists who can amplify your story.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re pre-seed or scaling globally, the &lt;strong&gt;Founder Pass&lt;/strong&gt; is your ticket to meaningful progress.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-investor-pass-source-smarter-connect-faster"&gt;Investor Pass: Source smarter, connect faster&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Investor Pass&lt;/strong&gt; is designed for dealmakers and venture leaders.&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Gain &lt;strong&gt;exclusive access to Startup Battlefield 200&lt;/strong&gt; and the founders behind tomorrow’s category leaders.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Attend &lt;strong&gt;private investor-only receptions&lt;/strong&gt; and networking events.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Get &lt;strong&gt;market insights&lt;/strong&gt; from VCs, LPs, and strategics across emerging tech sectors in an investor-exclusive StrictlyVC session.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Build relationships with the operators and innovators defining the next generation of startups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;For angels, venture firms, and CVCs, the &lt;strong&gt;Investor Pass&lt;/strong&gt; delivers high-value connections and actionable insight in one place.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-clock-is-ticking-3-days-until-the-final-flash-sale-disappears"&gt;The clock is ticking: 3 days until the final flash sale disappears&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This is your final chance to get into one of the biggest tech conferences of the year at a discount. &lt;strong&gt;Register now and save up to $624&lt;/strong&gt; before prices rise on Friday, October 17 at 11:59 p.m. PT. Bringing your team? Save 15% to 30% on &lt;strong&gt;group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt" class="wp-image-1301789" height="453" src="https://techcrunch.com/wp-content/uploads/2016/04/17205300128_99b3d607eb_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Noam Galai&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The final countdown of the final flash sale is here. Only three days remain to save up to $624 on your &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; pass before prices increase on Friday, October 17 at 11:59 p.m. PT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;From October 27–29 at San Francisco’s Moscone West, Disrupt 2025 will bring together 10,000+ founders, investors, and operators for three days of ideas, dealmaking, and discovery across more than 200 sessions, 250+ speakers, and 300+ exhibiting startups building what’s next.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now to save up to $624&lt;/strong&gt; on your pass before this week ends. Got a group? Save up to 30% on &lt;strong&gt;group passes&lt;/strong&gt;. Bringing a plus-one? Get 50% off the second pass.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 3 days left" class="wp-image-3011291" height="383" src="https://techcrunch.com/wp-content/uploads/2025/05/TC25_3Days-16X9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-where-innovation-and-opportunity-collide"&gt;Where innovation and opportunity collide&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is where the global startup ecosystem comes to connect, learn, and move faster. Discover the trends shaping AI, fintech, climate tech, mobility, and frontier industries, and meet the people leading those transformations.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2024 Breakout Session" class="wp-image-2985187" height="454" src="https://techcrunch.com/wp-content/uploads/2025/03/Disrupt-2024-Breakout.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; returns with the top 20 early-stage startups pitching live for $100,000 equity-free funding on the main stage.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Unparalleled networking&lt;/strong&gt; opportunities through curated meetups and impromptu run-ins.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Expert-led programming&lt;/strong&gt; designed to deliver actionable insights for founders, investors, and operators alike.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-featured-speakers"&gt;Featured speakers&lt;/h2&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Sarah Guo and Elad Gil" class="wp-image-2660351" height="453" src="https://techcrunch.com/wp-content/uploads/2024/02/53486897769_be737acd80_k.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Slava Blazer Photography&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Join the industry’s most influential voices, including:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Chris Barman&lt;/strong&gt;, CEO,&amp;nbsp;Slate Auto&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Baiju Bhatt&lt;/strong&gt;, founder, Aetherflux&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Roelof Botha&lt;/strong&gt;, managing partner,&amp;nbsp;Sequoia Capital&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Phoebe Gates&lt;/strong&gt;&amp;nbsp;and&amp;nbsp;&lt;strong&gt;Sophia Kianni&lt;/strong&gt;, co-founders,&amp;nbsp;Phia&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elad Gil&lt;/strong&gt;, CEO, Gil &amp;amp; Co.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Vinod Khosla&lt;/strong&gt;, founder,&amp;nbsp;Khosla Ventures&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Tekedra Mawakana&lt;/strong&gt;, co-CEO,&amp;nbsp;Waymo&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Bridgit Mendler&lt;/strong&gt;, co-founder, Northwood Space&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Kevin Scott&lt;/strong&gt;, CTO,&amp;nbsp;Microsoft&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Elizabeth Stone&lt;/strong&gt;, CTO,&amp;nbsp;Netflix&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Anatoly Yakovenko&lt;/strong&gt;, co-founder, Solana, and CEO,&amp;nbsp;Solana Labs&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Check out the &lt;strong&gt;250+ top voices&lt;/strong&gt; joining the Disrupt lineup&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-1707092" height="453" src="https://techcrunch.com/wp-content/uploads/2018/09/disruptsf18_brynn_putnam_mirror-1618.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Steve Jennings / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-passes-for-everyone-in-tech"&gt;Passes for everyone in tech&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Disrupt is &lt;em&gt;the&lt;/em&gt; tech epicenter of the year. Anybody and everybody who is building, investing, operating, or simply has a passion for tech, there’s&amp;nbsp;&lt;strong&gt;a pass designed for you&lt;/strong&gt;, your plus-one,&amp;nbsp;or&amp;nbsp;&lt;strong&gt;your team&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-founder-pass-build-smarter-scale-faster"&gt;Founder Pass: Build smarter, scale faster&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Founder Pass&lt;/strong&gt; is built for entrepreneurs ready to grow.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Access the &lt;strong&gt;Deal Flow Cafe&lt;/strong&gt; for networking and investor meetups.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Learn from &lt;strong&gt;Startup Battlefield 200&lt;/strong&gt; finalists and alumni who’ve gone on to raise millions.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Attend tactical sessions on &lt;strong&gt;fundraising, product strategy, and scaling&lt;/strong&gt;.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Connect directly with mentors, partners, and journalists who can amplify your story.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re pre-seed or scaling globally, the &lt;strong&gt;Founder Pass&lt;/strong&gt; is your ticket to meaningful progress.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-investor-pass-source-smarter-connect-faster"&gt;Investor Pass: Source smarter, connect faster&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;The &lt;strong&gt;Investor Pass&lt;/strong&gt; is designed for dealmakers and venture leaders.&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Gain &lt;strong&gt;exclusive access to Startup Battlefield 200&lt;/strong&gt; and the founders behind tomorrow’s category leaders.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Attend &lt;strong&gt;private investor-only receptions&lt;/strong&gt; and networking events.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Get &lt;strong&gt;market insights&lt;/strong&gt; from VCs, LPs, and strategics across emerging tech sectors in an investor-exclusive StrictlyVC session.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Build relationships with the operators and innovators defining the next generation of startups.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;For angels, venture firms, and CVCs, the &lt;strong&gt;Investor Pass&lt;/strong&gt; delivers high-value connections and actionable insight in one place.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-the-clock-is-ticking-3-days-until-the-final-flash-sale-disappears"&gt;The clock is ticking: 3 days until the final flash sale disappears&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;This is your final chance to get into one of the biggest tech conferences of the year at a discount. &lt;strong&gt;Register now and save up to $624&lt;/strong&gt; before prices rise on Friday, October 17 at 11:59 p.m. PT. Bringing your team? Save 15% to 30% on &lt;strong&gt;group passes&lt;/strong&gt;.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt" class="wp-image-1301789" height="453" src="https://techcrunch.com/wp-content/uploads/2016/04/17205300128_99b3d607eb_o.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Noam Galai&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/3-days-left-save-up-to-624-on-your-techcrunch-disrupt-2025-pass-before-prices-rise/</guid><pubDate>Wed, 15 Oct 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] You can now text Spotify’s AI DJ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/you-can-now-text-spotifys-ai-dj/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/DJ-Header-2-2048x782-1.png?resize=1200,458" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spotify on Wednesday upgraded its AI DJ feature — available to Premium subscribers — with a handful of new features, including the ability to send in your requests by typing, not just using voice commands.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature works with both English and Spanish requests, as Spotify’s Spanish-language DJ, called DJ Livi, now accepts music requests.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The AI DJ feature was updated earlier this year to accept voice requests, instead of only playing tunes Spotify thinks that you’ll like. However, that feature was only available to the English-language AI DJ until today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Texting with an AI assistant is now a common behavior, thanks to the rising popularity of AI chatbots like ChatGPT and Gemini. These services allow for multi-modal inputs, meaning you can either talk, text, or upload images and files as part of your request. As more people have gotten used to shifting back and forth between input methods, Apple rolled out a version of its Siri assistant that can also be reached by text.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a natural next step for Spotify’s AI feature to accept text input, as well, given that users are often engaged with the streaming service when out and about, commuting, or in a quiet space where they don’t want to disturb others by issuing voice commands.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the new texting feature, Spotify says that the AI DJ will also now offer personalized prompt suggestions to help inspire you if you’re not sure what you want to listen to next.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To access the DJ, you simply search for the term “DJ” on Spotify and then press play to start your curated selection of music. If you want to change the music, you can tap the DJ button in the bottom-right of the screen, then offer your suggestion via voice or text.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spotify notes the DJ can handle requests that combine genre, mood, artist, or activity. The feature is currently live in English and Spanish in over 60 markets worldwide.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/DJ-Header-2-2048x782-1.png?resize=1200,458" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Spotify on Wednesday upgraded its AI DJ feature — available to Premium subscribers — with a handful of new features, including the ability to send in your requests by typing, not just using voice commands.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature works with both English and Spanish requests, as Spotify’s Spanish-language DJ, called DJ Livi, now accepts music requests.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The AI DJ feature was updated earlier this year to accept voice requests, instead of only playing tunes Spotify thinks that you’ll like. However, that feature was only available to the English-language AI DJ until today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Texting with an AI assistant is now a common behavior, thanks to the rising popularity of AI chatbots like ChatGPT and Gemini. These services allow for multi-modal inputs, meaning you can either talk, text, or upload images and files as part of your request. As more people have gotten used to shifting back and forth between input methods, Apple rolled out a version of its Siri assistant that can also be reached by text.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a natural next step for Spotify’s AI feature to accept text input, as well, given that users are often engaged with the streaming service when out and about, commuting, or in a quiet space where they don’t want to disturb others by issuing voice commands.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the new texting feature, Spotify says that the AI DJ will also now offer personalized prompt suggestions to help inspire you if you’re not sure what you want to listen to next.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To access the DJ, you simply search for the term “DJ” on Spotify and then press play to start your curated selection of music. If you want to change the music, you can tap the DJ button in the bottom-right of the screen, then offer your suggestion via voice or text.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Spotify notes the DJ can handle requests that combine genre, mood, artist, or activity. The feature is currently live in English and Spanish in over 60 markets worldwide.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/you-can-now-text-spotifys-ai-dj/</guid><pubDate>Wed, 15 Oct 2025 14:17:28 +0000</pubDate></item><item><title>[NEW] Less than 3 days remain to secure your exhibit table at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/less-than-3-days-remain-to-secure-your-exhibit-table-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; runs October 27-29 in San Francisco’s Moscone West, and the Expo Hall is filling up fast. With just three days left to book, &lt;em&gt;now&lt;/em&gt; is the moment to &lt;strong&gt;reserve your exhibit table&lt;/strong&gt; before a competitor takes it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is your opportunity to showcase your innovation to investors, founders, media, and tech leaders who are actively seeking the next big idea, investment, or solution. The bustling Expo Hall is where all of Disrupt’s foot traffic converges — and that’s exactly where you’ll be.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now&lt;/strong&gt; before October 17, 11:59 p.m. PT, and learn more about how an exhibit table boosts your brand.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-exclusive-perks-for-exhibitors"&gt;Exclusive perks for exhibitors&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Lead generation&lt;/strong&gt; through the Disrupt mobile app to connect with qualified attendees instantly&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Complimentary&lt;/strong&gt; partner Wi-Fi network to keep your team connected&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Silver Tier sponsor recognition for &lt;strong&gt;maximum visibility&lt;/strong&gt;&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Access to the &lt;strong&gt;TechCrunch Disrupt press list&lt;/strong&gt; to amplify your story&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;10 comped passes&lt;/strong&gt; for your team to network, attend sessions, and meet key players&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Branding&lt;/strong&gt; on the website, app, on-site signage, and more to elevate your presence&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-your-brand-spotlight"&gt;Don’t miss your brand spotlight&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch Disrupt&lt;/strong&gt; is where startups launch, deals are made, and industry-defining conversations happen. Tables are going fast, and the spot you want might not be available for long. &lt;strong&gt;Reserve your table now&lt;/strong&gt; before the October 17th booking deadline.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 Fidelity exhibit" class="wp-image-2987335" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-Fidelity-exhibit.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt; runs October 27-29 in San Francisco’s Moscone West, and the Expo Hall is filling up fast. With just three days left to book, &lt;em&gt;now&lt;/em&gt; is the moment to &lt;strong&gt;reserve your exhibit table&lt;/strong&gt; before a competitor takes it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is your opportunity to showcase your innovation to investors, founders, media, and tech leaders who are actively seeking the next big idea, investment, or solution. The bustling Expo Hall is where all of Disrupt’s foot traffic converges — and that’s exactly where you’ll be.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Register now&lt;/strong&gt; before October 17, 11:59 p.m. PT, and learn more about how an exhibit table boosts your brand.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt Expo Hall" class="wp-image-2571166" height="383" src="https://techcrunch.com/wp-content/uploads/2023/07/expo_hall.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Eric Slomonson, The Photo Group&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-exclusive-perks-for-exhibitors"&gt;Exclusive perks for exhibitors&lt;/h2&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Lead generation&lt;/strong&gt; through the Disrupt mobile app to connect with qualified attendees instantly&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Complimentary&lt;/strong&gt; partner Wi-Fi network to keep your team connected&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Silver Tier sponsor recognition for &lt;strong&gt;maximum visibility&lt;/strong&gt;&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Access to the &lt;strong&gt;TechCrunch Disrupt press list&lt;/strong&gt; to amplify your story&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;10 comped passes&lt;/strong&gt; for your team to network, attend sessions, and meet key players&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Branding&lt;/strong&gt; on the website, app, on-site signage, and more to elevate your presence&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 class="wp-block-heading" id="h-don-t-miss-your-brand-spotlight"&gt;Don’t miss your brand spotlight&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch Disrupt&lt;/strong&gt; is where startups launch, deals are made, and industry-defining conversations happen. Tables are going fast, and the spot you want might not be available for long. &lt;strong&gt;Reserve your table now&lt;/strong&gt; before the October 17th booking deadline.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Early Stage 2024 Fidelity exhibit" class="wp-image-2987335" height="453" src="https://techcrunch.com/wp-content/uploads/2025/03/Early-Stage-2024-Fidelity-exhibit.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Halo Creative&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/less-than-3-days-remain-to-secure-your-exhibit-table-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 15 Oct 2025 14:30:00 +0000</pubDate></item><item><title>[NEW] ChatGPT erotica coming soon with age verification, CEO says (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/10/chatgpt-will-soon-allow-erotic-chats-for-verified-adults-only/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sam Altman claims new tools can detect mental distress while relaxing limits for adults.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/openai-math-apples-300x169.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/openai-math-apples-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, OpenAI CEO Sam Altman announced that the company will allow verified adult users to have erotic conversations with ChatGPT starting in December. The change represents a shift in how OpenAI approaches content restrictions, which the company had loosened in February but then dramatically tightened&amp;nbsp;after an August lawsuit from parents of a teen who died by suicide after allegedly receiving encouragement from ChatGPT.&lt;/p&gt;
&lt;p&gt;"In December, as we roll out age-gating more fully and as part of our 'treat adult users like adults' principle, we will allow even more, like erotica for verified adults," Altman wrote in his post on X (formerly Twitter). The announcement follows OpenAI's recent hint that it would allow developers to create "mature" ChatGPT applications once the company implements appropriate age verification and controls.&lt;/p&gt;
&lt;p&gt;Altman explained that OpenAI had made ChatGPT "pretty restrictive to make sure we were being careful with mental health issues" but acknowledged this approach made the chatbot "less useful/enjoyable to many users who had no mental health problems." The CEO said the company now has new tools to better detect when users are experiencing mental distress, allowing OpenAI to relax restrictions in most cases.&lt;/p&gt;
&lt;p&gt;Striking the right balance between freedom for adults and safety for users has been a difficult balancing act for OpenAI, which has vacillated between permissive and restrictive chat content controls over the past year.&lt;/p&gt;
&lt;p&gt;In February, the company updated its Model Spec to allow erotica in "appropriate contexts." But a March update made GPT-4o so agreeable that users complained about its "relentlessly positive tone." By August, Ars reported on cases where ChatGPT's sycophantic behavior had validated users' false beliefs to the point of causing mental health crises, and news of the aforementioned suicide lawsuit hit not long after.&lt;/p&gt;
&lt;p&gt;Aside from adjusting the behavioral outputs for its previous GPT-40 AI language model, new model changes have also created some turmoil among users. Since the launch of GPT-5 in early August, some users have been complaining that the new model feels less engaging than its predecessor, prompting OpenAI to bring back the older model as an option. Altman said the upcoming release will allow users to choose whether they want ChatGPT to "respond in a very human-like way, or use a ton of emoji, or act like a friend."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The December rollout will implement age verification for adult content, which OpenAI has not yet detailed technically. This represents a more explicit approach than the February policy change, which allowed erotica in certain contexts but lacked age-gating infrastructure.&lt;/p&gt;
&lt;h2&gt;Mental health concerns remain&lt;/h2&gt;
&lt;p&gt;Over time, as OpenAI allowed ChatGPT to express more humanlike simulated personality through revised system instructions and fine-tuning as a response to user feedback, ChatGPT has become more like a companion to some people than a work assistant. But dealing with the unexpected impacts of a reported 700 million users relying emotionally on largely unregulated and untested technology has been difficult for OpenAI, and the company has been forced to rapidly develop new safety initiatives and oversight bodies.&lt;/p&gt;
&lt;p&gt;OpenAI recently formed a council on "wellbeing and AI" to help guide the company's response to sensitive scenarios involving users in distress. The council includes eight researchers and experts who study how technology and AI affect mental health. However, as we previously reported, the council does not include any suicide prevention experts, despite recent calls from that community for OpenAI to implement stronger safeguards for users with suicidal thoughts.&lt;/p&gt;
&lt;p&gt;Altman maintains that the new detection tools will allow the company to "safely relax the restrictions" while still protecting vulnerable users. OpenAI has not yet specified what technical measures it will use for age verification or how the system will distinguish between allowed adult content and requests that might indicate mental health concerns, although the company typically uses moderation AI models that read the ongoing chat within ChatGPT and can interrupt it if it sees content that goes against OpenAI's policy instructions.&lt;/p&gt;
&lt;p&gt;OpenAI is not the first company to venture into AI companionship with mature content. Elon Musk's xAI previously launched an adult voice mode in its Grok app and flirty AI companions that appear as 3D anime models in the Grok app.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Sam Altman claims new tools can detect mental distress while relaxing limits for adults.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/openai-math-apples-300x169.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/openai-math-apples-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Tuesday, OpenAI CEO Sam Altman announced that the company will allow verified adult users to have erotic conversations with ChatGPT starting in December. The change represents a shift in how OpenAI approaches content restrictions, which the company had loosened in February but then dramatically tightened&amp;nbsp;after an August lawsuit from parents of a teen who died by suicide after allegedly receiving encouragement from ChatGPT.&lt;/p&gt;
&lt;p&gt;"In December, as we roll out age-gating more fully and as part of our 'treat adult users like adults' principle, we will allow even more, like erotica for verified adults," Altman wrote in his post on X (formerly Twitter). The announcement follows OpenAI's recent hint that it would allow developers to create "mature" ChatGPT applications once the company implements appropriate age verification and controls.&lt;/p&gt;
&lt;p&gt;Altman explained that OpenAI had made ChatGPT "pretty restrictive to make sure we were being careful with mental health issues" but acknowledged this approach made the chatbot "less useful/enjoyable to many users who had no mental health problems." The CEO said the company now has new tools to better detect when users are experiencing mental distress, allowing OpenAI to relax restrictions in most cases.&lt;/p&gt;
&lt;p&gt;Striking the right balance between freedom for adults and safety for users has been a difficult balancing act for OpenAI, which has vacillated between permissive and restrictive chat content controls over the past year.&lt;/p&gt;
&lt;p&gt;In February, the company updated its Model Spec to allow erotica in "appropriate contexts." But a March update made GPT-4o so agreeable that users complained about its "relentlessly positive tone." By August, Ars reported on cases where ChatGPT's sycophantic behavior had validated users' false beliefs to the point of causing mental health crises, and news of the aforementioned suicide lawsuit hit not long after.&lt;/p&gt;
&lt;p&gt;Aside from adjusting the behavioral outputs for its previous GPT-40 AI language model, new model changes have also created some turmoil among users. Since the launch of GPT-5 in early August, some users have been complaining that the new model feels less engaging than its predecessor, prompting OpenAI to bring back the older model as an option. Altman said the upcoming release will allow users to choose whether they want ChatGPT to "respond in a very human-like way, or use a ton of emoji, or act like a friend."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The December rollout will implement age verification for adult content, which OpenAI has not yet detailed technically. This represents a more explicit approach than the February policy change, which allowed erotica in certain contexts but lacked age-gating infrastructure.&lt;/p&gt;
&lt;h2&gt;Mental health concerns remain&lt;/h2&gt;
&lt;p&gt;Over time, as OpenAI allowed ChatGPT to express more humanlike simulated personality through revised system instructions and fine-tuning as a response to user feedback, ChatGPT has become more like a companion to some people than a work assistant. But dealing with the unexpected impacts of a reported 700 million users relying emotionally on largely unregulated and untested technology has been difficult for OpenAI, and the company has been forced to rapidly develop new safety initiatives and oversight bodies.&lt;/p&gt;
&lt;p&gt;OpenAI recently formed a council on "wellbeing and AI" to help guide the company's response to sensitive scenarios involving users in distress. The council includes eight researchers and experts who study how technology and AI affect mental health. However, as we previously reported, the council does not include any suicide prevention experts, despite recent calls from that community for OpenAI to implement stronger safeguards for users with suicidal thoughts.&lt;/p&gt;
&lt;p&gt;Altman maintains that the new detection tools will allow the company to "safely relax the restrictions" while still protecting vulnerable users. OpenAI has not yet specified what technical measures it will use for age verification or how the system will distinguish between allowed adult content and requests that might indicate mental health concerns, although the company typically uses moderation AI models that read the ongoing chat within ChatGPT and can interrupt it if it sees content that goes against OpenAI's policy instructions.&lt;/p&gt;
&lt;p&gt;OpenAI is not the first company to venture into AI companionship with mature content. Elon Musk's xAI previously launched an adult voice mode in its Grok app and flirty AI companions that appear as 3D anime models in the Grok app.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/10/chatgpt-will-soon-allow-erotic-chats-for-verified-adults-only/</guid><pubDate>Wed, 15 Oct 2025 15:14:52 +0000</pubDate></item><item><title>[NEW] Google releases Veo 3.1, adds it to Flow video editor (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/google-releases-veo-3-1-adds-it-to-flow-video-editor/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-15-at-8.03.20PM.jpg?resize=1200,578" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google launched its new video model Veo 3.1 with improved audio output, granular editing controls, and better output for image to video. It said that Veo 3.1 builds on May’s Veo 3 release and generates more realistic clips and adheres to prompts better.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The model allows users to add an object to the video and have it blend into the clip’s style, Google said. Soon, users will be able to remove an existing object from the video in Flow, too.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Veo 3 already has edit features such as adding reference images to drive a character, providing the first and last frame to generate a clip using AI, and the ability to extend an existing video based on the last few frames. With Veo 3.1, Google is adding audio to all these features to make the clips more lively. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is rolling out the model to its video editor Flow, the  Gemini App, along with Vertex and Gemini APIs. It said that since Flow’s launch in May, users have created more than 275 million videos on the app. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-15-at-8.03.20PM.jpg?resize=1200,578" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google launched its new video model Veo 3.1 with improved audio output, granular editing controls, and better output for image to video. It said that Veo 3.1 builds on May’s Veo 3 release and generates more realistic clips and adheres to prompts better.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The model allows users to add an object to the video and have it blend into the clip’s style, Google said. Soon, users will be able to remove an existing object from the video in Flow, too.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Veo 3 already has edit features such as adding reference images to drive a character, providing the first and last frame to generate a clip using AI, and the ability to extend an existing video based on the last few frames. With Veo 3.1, Google is adding audio to all these features to make the clips more lively. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is rolling out the model to its video editor Flow, the  Gemini App, along with Vertex and Gemini APIs. It said that since Flow’s launch in May, users have created more than 275 million videos on the app. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/google-releases-veo-3-1-adds-it-to-flow-video-editor/</guid><pubDate>Wed, 15 Oct 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] Google’s AI videos get a big upgrade with Veo 3.1 (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/10/googles-ai-videos-get-a-big-upgrade-with-veo-3-1/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Veo 3.1 is coming to the Gemini app and the Flow filmmaking tool.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Veo 3.1" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-640x360.png" width="640" /&gt;
                  &lt;img alt="Veo 3.1" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;It's getting harder to know what's real on the Internet, and Google is not helping one bit with the announcement of Veo 3.1. The company's new video model supposedly offers better audio and realism, along with greater prompt accuracy. The updated video AI will be available throughout the Google ecosystem, including the Flow filmmaking tool, where the new model will unlock additional features. And if you're worried about the cost of conjuring all these AI videos, Google is also adding a "Fast" variant of Veo.&lt;/p&gt;
&lt;p&gt;Veo made waves when it debuted earlier this year, demonstrating a staggering improvement in AI video quality just a few months after Veo 2's release. It turns out that having all that video on YouTube is very useful for training AI models, so Google is already moving on to Veo 3.1 with a raft of new features.&lt;/p&gt;
&lt;p&gt;Google says Veo 3.1 offers stronger prompt adherence, which results in better video outputs and fewer wasted compute cycles. Audio, which was a hallmark feature of the Veo 3 release, has reportedly improved, too. Veo 3's text-to-video was limited to 720p landscape output, but there's an ever-increasing volume of vertical video on the Internet. So Veo 3.1 can produce both landscape and portrait 16:9 video.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122592-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-opt.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Google previously said it would bring Veo video tools to YouTube Shorts, which use a vertical video format like TikTok. The release of Veo 3.1 probably opens the door to fulfilling that promise. You can bet Veo videos will show up more frequently on TikTok as well now that it fits the format. This release also keeps Google in its race with OpenAI, which recently released a Sora iPhone app with an impressive new version of its video-generating AI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A focus on filmmakers&lt;/h2&gt;
&lt;p&gt;The Veo 3.1 model will be available across Google's AI ecosystem. You'll be able to create content with Veo 3.1 and Veo 3.1 Fast via the Gemini app, and developers will have access in Vertex AI and through the Gemini API. Using the Fast variant will help keep costs down when paying per token. Presumably, users of the Gemini app will get more Fast video generations—we've asked Google about limits and will report if we hear back.&lt;/p&gt;
&lt;p&gt;Veo is the underlying model in Google's Flow filmmaking tool, and it's getting a few new capabilities thanks to the updated model. The Ingredients to Video, Frames to Video, and Extend features are now all compatible with generated audio. So you can upload multiple images as a reference or use images as a starting or end point while also adding custom audio to the clip. These same capabilities are offered in the API, and the Gemini app continues to accept reference images for Veo outputs. The app doesn't get all the Flow features, though.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122592-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Add-or-remove-object-opt.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;There are a couple of entirely new video features coming with Veo 3.1, too. Google says Veo 3.1 is better able to replicate the look of a video while making "precision" edits. So you'll be able to add an object to a clip while keeping the rest of it unchanged (more or less). Likewise, you can remove an element without changing the rest of the scene. Adding objects will be available in Flow and the API immediately. Removing objects won't be available in Flow just yet, but Google says that feature will be coming soon.&lt;/p&gt;
&lt;p&gt;The new video model begins rolling out today, so make sure you use a skeptical eye when scrolling through vertical videos.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google Veo 3.1

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Veo 3.1 is coming to the Gemini app and the Flow filmmaking tool.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Veo 3.1" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-640x360.png" width="640" /&gt;
                  &lt;img alt="Veo 3.1" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;It's getting harder to know what's real on the Internet, and Google is not helping one bit with the announcement of Veo 3.1. The company's new video model supposedly offers better audio and realism, along with greater prompt accuracy. The updated video AI will be available throughout the Google ecosystem, including the Flow filmmaking tool, where the new model will unlock additional features. And if you're worried about the cost of conjuring all these AI videos, Google is also adding a "Fast" variant of Veo.&lt;/p&gt;
&lt;p&gt;Veo made waves when it debuted earlier this year, demonstrating a staggering improvement in AI video quality just a few months after Veo 2's release. It turns out that having all that video on YouTube is very useful for training AI models, so Google is already moving on to Veo 3.1 with a raft of new features.&lt;/p&gt;
&lt;p&gt;Google says Veo 3.1 offers stronger prompt adherence, which results in better video outputs and fewer wasted compute cycles. Audio, which was a hallmark feature of the Veo 3 release, has reportedly improved, too. Veo 3's text-to-video was limited to 720p landscape output, but there's an ever-increasing volume of vertical video on the Internet. So Veo 3.1 can produce both landscape and portrait 16:9 video.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122592-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Veo-3.1-opt.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Google previously said it would bring Veo video tools to YouTube Shorts, which use a vertical video format like TikTok. The release of Veo 3.1 probably opens the door to fulfilling that promise. You can bet Veo videos will show up more frequently on TikTok as well now that it fits the format. This release also keeps Google in its race with OpenAI, which recently released a Sora iPhone app with an impressive new version of its video-generating AI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;A focus on filmmakers&lt;/h2&gt;
&lt;p&gt;The Veo 3.1 model will be available across Google's AI ecosystem. You'll be able to create content with Veo 3.1 and Veo 3.1 Fast via the Gemini app, and developers will have access in Vertex AI and through the Gemini API. Using the Fast variant will help keep costs down when paying per token. Presumably, users of the Gemini app will get more Fast video generations—we've asked Google about limits and will report if we hear back.&lt;/p&gt;
&lt;p&gt;Veo is the underlying model in Google's Flow filmmaking tool, and it's getting a few new capabilities thanks to the updated model. The Ingredients to Video, Frames to Video, and Extend features are now all compatible with generated audio. So you can upload multiple images as a reference or use images as a starting or end point while also adding custom audio to the clip. These same capabilities are offered in the API, and the Gemini app continues to accept reference images for Veo outputs. The app doesn't get all the Flow features, though.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2122592-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/Add-or-remove-object-opt.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;There are a couple of entirely new video features coming with Veo 3.1, too. Google says Veo 3.1 is better able to replicate the look of a video while making "precision" edits. So you'll be able to add an object to a clip while keeping the rest of it unchanged (more or less). Likewise, you can remove an element without changing the rest of the scene. Adding objects will be available in Flow and the API immediately. Removing objects won't be available in Flow just yet, but Google says that feature will be coming soon.&lt;/p&gt;
&lt;p&gt;The new video model begins rolling out today, so make sure you use a skeptical eye when scrolling through vertical videos.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Google Veo 3.1

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/10/googles-ai-videos-get-a-big-upgrade-with-veo-3-1/</guid><pubDate>Wed, 15 Oct 2025 16:00:51 +0000</pubDate></item><item><title>[NEW] Introducing Veo 3.1 and advanced creative capabilities (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/introducing-veo-3-1-and-advanced-creative-capabilities/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Veo3.1_Social_v3.width-1300.png" /&gt;&lt;/div&gt;

            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Five months ago, we introduced Flow, our AI filmmaking tool powered by Veo, and have been inspired by the creativity it has sparked with over 275 million videos generated in Flow



  &lt;sup&gt;1&lt;/sup&gt;

. We're always listening to your feedback, and we've heard that you want more artistic control within Flow, with increased support for audio across all features.&lt;/p&gt;&lt;p&gt;Today, we’re introducing new and enhanced creative capabilities to edit your clips, giving you more granular control over your final scene. For the first time, we’re also bringing audio to existing capabilities like “Ingredients to Video,” “Frames to Video” and “Extend.”&lt;/p&gt;&lt;p&gt;We’re also introducing Veo 3.1, which brings richer audio, more narrative control, and enhanced realism that captures true-to-life textures. Veo 3.1 is state-of-the-art and builds on Veo 3, with stronger prompt adherence and improved audiovisual quality when turning images into videos.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Refine your narrative with audio and more control&lt;/h2&gt;&lt;p&gt;With Veo 3.1, we’re bringing audio to existing capabilities to help you craft the perfect scene. These features are experimental and actively improving, and we’re excited to see what you create as we iterate based on your feedback.&lt;/p&gt;&lt;p&gt;Now, with rich, generated audio, you can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Craft the look of your scene.&lt;/b&gt; With "Ingredients to Video," you can use multiple reference images to control the characters, objects and style. Flow uses your ingredients to create a final scene that looks just as you envisioned.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Control the shot from start to finish.&lt;/b&gt; Provide a starting and ending image with “Frames to Video,” and Flow will generate a seamless video that bridges the two, perfect for artful and epic transitions.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Create longer, seamless shots.&lt;/b&gt; With "Extend," you can create longer videos, even lasting for a minute or more, that connect to and continue the action from your original clip. Each video is generated based on the final second of your previous clip, making it most useful for creating a longer establishing shot.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Edit your ingredients and videos with more precision&lt;/h2&gt;&lt;p&gt;Great ideas can strike at any point in the creative process. For moments when the first take isn't the final one, we're introducing new editing capabilities directly within Flow to help you reimagine and perfect your scenes.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Add new elements to any scene.&lt;/b&gt; With “Insert,” introduce anything you can imagine, from realistic details to fantastical creatures. Flow now handles complex details like shadows and scene lighting, making the addition look natural.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Remove unwanted objects or characters seamlessly.&lt;/b&gt; Soon, you’ll be able to take anything out of a scene, and Flow will reconstruct the background and surroundings, making it look as though the object was never there.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Start creating in Flow today&lt;/h2&gt;&lt;p&gt;With more precise editing capabilities, audio across all existing features and higher-quality outputs powered by Veo 3.1, we're opening up new possibilities for richer, more powerful video storytelling right inside Flow.&lt;/p&gt;&lt;p&gt;The Veo 3.1 model is also available via the Gemini API for developers, Vertex AI for enterprise customers, and the Gemini app. New capabilities are available in both Gemini API



  &lt;sup&gt;2&lt;/sup&gt;

and Vertex AI



  &lt;sup&gt;3&lt;/sup&gt;

.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    
      &lt;li&gt;
        
        
        


  


Google Labs


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Veo3.1_Social_v3.width-1300.png" /&gt;&lt;/div&gt;

            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Five months ago, we introduced Flow, our AI filmmaking tool powered by Veo, and have been inspired by the creativity it has sparked with over 275 million videos generated in Flow



  &lt;sup&gt;1&lt;/sup&gt;

. We're always listening to your feedback, and we've heard that you want more artistic control within Flow, with increased support for audio across all features.&lt;/p&gt;&lt;p&gt;Today, we’re introducing new and enhanced creative capabilities to edit your clips, giving you more granular control over your final scene. For the first time, we’re also bringing audio to existing capabilities like “Ingredients to Video,” “Frames to Video” and “Extend.”&lt;/p&gt;&lt;p&gt;We’re also introducing Veo 3.1, which brings richer audio, more narrative control, and enhanced realism that captures true-to-life textures. Veo 3.1 is state-of-the-art and builds on Veo 3, with stronger prompt adherence and improved audiovisual quality when turning images into videos.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Refine your narrative with audio and more control&lt;/h2&gt;&lt;p&gt;With Veo 3.1, we’re bringing audio to existing capabilities to help you craft the perfect scene. These features are experimental and actively improving, and we’re excited to see what you create as we iterate based on your feedback.&lt;/p&gt;&lt;p&gt;Now, with rich, generated audio, you can:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Craft the look of your scene.&lt;/b&gt; With "Ingredients to Video," you can use multiple reference images to control the characters, objects and style. Flow uses your ingredients to create a final scene that looks just as you envisioned.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Control the shot from start to finish.&lt;/b&gt; Provide a starting and ending image with “Frames to Video,” and Flow will generate a seamless video that bridges the two, perfect for artful and epic transitions.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Create longer, seamless shots.&lt;/b&gt; With "Extend," you can create longer videos, even lasting for a minute or more, that connect to and continue the action from your original clip. Each video is generated based on the final second of your previous clip, making it most useful for creating a longer establishing shot.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Edit your ingredients and videos with more precision&lt;/h2&gt;&lt;p&gt;Great ideas can strike at any point in the creative process. For moments when the first take isn't the final one, we're introducing new editing capabilities directly within Flow to help you reimagine and perfect your scenes.&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;b&gt;Add new elements to any scene.&lt;/b&gt; With “Insert,” introduce anything you can imagine, from realistic details to fantastical creatures. Flow now handles complex details like shadows and scene lighting, making the addition look natural.&lt;/li&gt;&lt;li&gt;&lt;b&gt;Remove unwanted objects or characters seamlessly.&lt;/b&gt; Soon, you’ll be able to take anything out of a scene, and Flow will reconstruct the background and surroundings, making it look as though the object was never there.&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Start creating in Flow today&lt;/h2&gt;&lt;p&gt;With more precise editing capabilities, audio across all existing features and higher-quality outputs powered by Veo 3.1, we're opening up new possibilities for richer, more powerful video storytelling right inside Flow.&lt;/p&gt;&lt;p&gt;The Veo 3.1 model is also available via the Gemini API for developers, Vertex AI for enterprise customers, and the Gemini app. New capabilities are available in both Gemini API



  &lt;sup&gt;2&lt;/sup&gt;

and Vertex AI



  &lt;sup&gt;3&lt;/sup&gt;

.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    
      &lt;li&gt;
        
        
        


  


Google Labs


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/introducing-veo-3-1-and-advanced-creative-capabilities/</guid><pubDate>Wed, 15 Oct 2025 16:01:08 +0000</pubDate></item><item><title>[NEW] Nscale inks massive AI infrastructure deal with Microsoft (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/nscale-inks-massive-ai-infrastructure-deal-with-microsoft/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2201260651.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI hyperscaler startup Nscale has signed a sizable deal with Microsoft to bring Nvidia AI hardware to multiple data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI cloud provider announced that it signed a deal with Microsoft to bring approximately 200,000 Nvidia GB300 GPUs to three data centers in Europe and one in the U.S. on Wednesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These GPUs will be delivered through Nscale-owned operations and through a joint venture with investment company Aker, one of Nscale’s investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;About half of these GPUs, 104,000, will head to a data center in Texas leased by Ionic Digital, over the next 12 to 18 months. Nscale plans to increase its footprint at this location to 1.2 gigawatts, the company stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nscale will also deploy 12,600 GPUs to the Start Campus data center in Sines, Portugal, starting in the first quarter of 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal builds on previous plans with both Microsoft and Aker regarding data centers in Norway and the United Kingdom. Nscale will send 23,000 GPUS to its Loughton, England campus starting in 2027, and send the remaining 52,000 GPUs to Microsoft’s AI campus in Narvik, Norway.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This agreement confirms Nscale’s place as a partner of choice for the world’s most important technology leaders,” Josh Payne, founder and CEO of Nscale, said in a company press release. “Few companies are equipped to deliver GPU deployments at this scale, but we have the experience and have built the global pipeline to do so.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a bold claim by Payne, considering that Nscale was founded in 2024. Since its launch, the company has raised more than $1.7 billion from strategic partners including Aker, Nokia and Nvidia. Nscale has also raised from investors like Sandton Capital Partners, G Squared and Point72, among others. Payne told the Financial Times that the company is looking at an IPO as early as the end of next year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The pace with which we have expanded our capacity demonstrates both our readiness and our commitment to efficiency, sustainability and providing our customers with the most advanced technology available. It’s a clear signal that Nscale is setting a new standard for how the next wave of AI infrastructure will be delivered,” Payne said in the release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPU deals have picked up in recent weeks. OpenAI announced it was purchasing six gigawatts worth of chips from AMD last week. OpenAI also recently inked a deal with Nvidia in which Nvidia will invest up to $100 billion in the company in exchange for 10 gigawatts worth of chips in September. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2201260651.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI hyperscaler startup Nscale has signed a sizable deal with Microsoft to bring Nvidia AI hardware to multiple data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI cloud provider announced that it signed a deal with Microsoft to bring approximately 200,000 Nvidia GB300 GPUs to three data centers in Europe and one in the U.S. on Wednesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These GPUs will be delivered through Nscale-owned operations and through a joint venture with investment company Aker, one of Nscale’s investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;About half of these GPUs, 104,000, will head to a data center in Texas leased by Ionic Digital, over the next 12 to 18 months. Nscale plans to increase its footprint at this location to 1.2 gigawatts, the company stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nscale will also deploy 12,600 GPUs to the Start Campus data center in Sines, Portugal, starting in the first quarter of 2026.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal builds on previous plans with both Microsoft and Aker regarding data centers in Norway and the United Kingdom. Nscale will send 23,000 GPUS to its Loughton, England campus starting in 2027, and send the remaining 52,000 GPUs to Microsoft’s AI campus in Narvik, Norway.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This agreement confirms Nscale’s place as a partner of choice for the world’s most important technology leaders,” Josh Payne, founder and CEO of Nscale, said in a company press release. “Few companies are equipped to deliver GPU deployments at this scale, but we have the experience and have built the global pipeline to do so.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a bold claim by Payne, considering that Nscale was founded in 2024. Since its launch, the company has raised more than $1.7 billion from strategic partners including Aker, Nokia and Nvidia. Nscale has also raised from investors like Sandton Capital Partners, G Squared and Point72, among others. Payne told the Financial Times that the company is looking at an IPO as early as the end of next year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The pace with which we have expanded our capacity demonstrates both our readiness and our commitment to efficiency, sustainability and providing our customers with the most advanced technology available. It’s a clear signal that Nscale is setting a new standard for how the next wave of AI infrastructure will be delivered,” Payne said in the release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPU deals have picked up in recent weeks. OpenAI announced it was purchasing six gigawatts worth of chips from AMD last week. OpenAI also recently inked a deal with Nvidia in which Nvidia will invest up to $100 billion in the company in exchange for 10 gigawatts worth of chips in September. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/nscale-inks-massive-ai-infrastructure-deal-with-microsoft/</guid><pubDate>Wed, 15 Oct 2025 16:01:11 +0000</pubDate></item><item><title>[NEW] Meta partners up with Arm to scale AI efforts (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/arm-partners-with-meta-to-scale-ai-efforts/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Semiconductor design company Arm is partnering up with Meta to enhance the social media giant’s AI systems amid an unprecedented infrastructure buildout. Under the partnership, Meta’s ranking and recommendation systems will move to Arm’s Neoverse platform, which was recently optimized for AI systems in the cloud, among other implementations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is transforming how people connect and create,” Santosh Janardhan, Meta’s head of infrastructure, said in a statement. “Partnering with Arm enables us to efficiently scale that innovation to the more than 3 billion people who use Meta’s apps and technologies.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Best known for its mobile CPU architecture, Arm’s GPU offerings have often been overshadowed by competitors like Nvidia. But Arm is now emphasizing its advantage in low-power deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI’s next era will be defined by delivering efficiency at scale,” Rene Haas, Arm’s CEO, said in a statement. “Partnering with Meta, we’re uniting Arm’s performance-per-watt leadership with Meta’s AI innovation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The multi-year partnership comes as Meta invests in vastly expanding its data center network to keep pace with anticipated demand for AI services. One project, code-named “Prometheus,” is expected to come online with multiple gigawatts of power in 2027. Construction is currently underway in New Albany, Ohio, and a 200-megawatt natural gas project is being constructed to directly serve the project’s power needs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta is also building a data center campus, code-named “Hyperion,” across 2,250 acres in northwest Louisiana that’s meant to deliver 5 gigawatts of computational power when complete. Construction is expected to continue through 2030, although some portions may come online before then.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, Arm and Meta are&amp;nbsp;not exchanging ownership stakes or significant physical infrastructure, setting this partnership apart from a number of recent AI infrastructure deals. Nvidia has been particularly aggressive with its investments — it recently committed to a $100 billion phased investment into OpenAI, as well as billion-dollar investments into Elon Musk’s xAI, Mira Murati’s Thinking Machines Lab, and French AI lab Mistral.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;A rival to both Nvidia and Arm, AMD recently committed to supplying OpenAI with 6 gigawatts worth of compute capacity. As part of the deal, OpenAI will receive AMD stock options worth as much as 10% of the company.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Semiconductor design company Arm is partnering up with Meta to enhance the social media giant’s AI systems amid an unprecedented infrastructure buildout. Under the partnership, Meta’s ranking and recommendation systems will move to Arm’s Neoverse platform, which was recently optimized for AI systems in the cloud, among other implementations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is transforming how people connect and create,” Santosh Janardhan, Meta’s head of infrastructure, said in a statement. “Partnering with Arm enables us to efficiently scale that innovation to the more than 3 billion people who use Meta’s apps and technologies.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Best known for its mobile CPU architecture, Arm’s GPU offerings have often been overshadowed by competitors like Nvidia. But Arm is now emphasizing its advantage in low-power deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI’s next era will be defined by delivering efficiency at scale,” Rene Haas, Arm’s CEO, said in a statement. “Partnering with Meta, we’re uniting Arm’s performance-per-watt leadership with Meta’s AI innovation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The multi-year partnership comes as Meta invests in vastly expanding its data center network to keep pace with anticipated demand for AI services. One project, code-named “Prometheus,” is expected to come online with multiple gigawatts of power in 2027. Construction is currently underway in New Albany, Ohio, and a 200-megawatt natural gas project is being constructed to directly serve the project’s power needs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta is also building a data center campus, code-named “Hyperion,” across 2,250 acres in northwest Louisiana that’s meant to deliver 5 gigawatts of computational power when complete. Construction is expected to continue through 2030, although some portions may come online before then.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, Arm and Meta are&amp;nbsp;not exchanging ownership stakes or significant physical infrastructure, setting this partnership apart from a number of recent AI infrastructure deals. Nvidia has been particularly aggressive with its investments — it recently committed to a $100 billion phased investment into OpenAI, as well as billion-dollar investments into Elon Musk’s xAI, Mira Murati’s Thinking Machines Lab, and French AI lab Mistral.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;A rival to both Nvidia and Arm, AMD recently committed to supplying OpenAI with 6 gigawatts worth of compute capacity. As part of the deal, OpenAI will receive AMD stock options worth as much as 10% of the company.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/arm-partners-with-meta-to-scale-ai-efforts/</guid><pubDate>Wed, 15 Oct 2025 16:05:00 +0000</pubDate></item><item><title>[NEW] Liberate bags $50M at $300M valuation to bring AI deeper into insurance back offices (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/liberate-bags-50m-at-300m-valuation-to-bring-ai-deeper-into-insurance-back-offices/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Liberate, an AI startup automating insurance operations, has raised $50 million in a round led by Battery Ventures as it looks to scale its agentic deployments across carriers and agencies globally.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The all-equity round values the three-year-old startup at $300 million post-money, with participation from new investor Canapi Ventures and returning backers Redpoint Ventures, Eclipse, and Commerce Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The insurance industry has been navigating a difficult stretch, with rising operational costs, legacy system constraints, and increasing customer expectations. Specifically in the non-life segment, global premium growth is projected to slow through 2026, driven by heightened competition, weaker rate momentum, and new cost pressures, including tariffs, per a recent report by Deloitte. While some carriers experimented with AI, many early efforts stalled due to fragmented data and inflexible workflows. That is now changing, as insurers shift toward full-scale AI adoption — embedding it into the core of their operations rather than layering it on top. Liberate is stepping in to meet this shift head-on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2022, the San Francisco-based startup builds AI systems for property and casualty insurers, focusing on sales, service, and claims. At the front end, its voice AI assistant, Nicole, handles inbound and outbound calls to help sell policies or respond to service requests. Behind the scenes, a network of reasoning-based AI agents connects to insurers’ existing systems, gathering context and generating responses that Nicole delivers — all without human intervention.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liberate’s AI agents are built to complete end-to-end tasks — not just respond to queries or escalate tickets. These include quoting policies, processing claims, and updating endorsements, among other routine functions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agents can also operate over SMS and email, allowing insurers to interact with customers across different channels while automating more of their day-to-day workflows.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Insurance companies want to grow, but they’re not able to do so,” Liberate co-founder and CEO Amrish Singh (pictured above, center) said in an interview. “It’s the status quo where the opportunity is.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Singh co-founded Liberate after nearly four years at Metromile, the car insurance firm owned by Lemonade, where he worked across both back-office operations and technology. He teamed up with Ryan Eldridge, Liberate’s VP of engineering and also a former Metromile executive, and Jason St. Pierre, the company’s CPO, who previously held roles at Twitter, Google, and Verily, Alphabet’s life sciences arm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liberate’s AI systems have helped increase sales by an average of 15% and cut costs by 23%, Singh told TechCrunch, adding that the startup now has over 60 customers and focuses on the top 100 carriers and agencies, which together represent 70% to 80% of the U.S. property and casualty insurance market.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3057757" height="1200" src="https://techcrunch.com/wp-content/uploads/2025/10/liberate-agent-orchestration-screenshot.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Liberate’s agent orchestration&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The technology uses reinforcement learning tailored for long, regulated insurance conversations. Each interaction is auditable and includes human-in-the-loop safeguards to meet compliance requirements, the startup said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Over the past year, Liberate has scaled from 10,000 monthly automations to 1.3 million automated resolutions, Singh stated. These include direct customer interactions via its voice AI, as well as back-office tasks handled by AI agents integrated into carriers’ core systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since AI systems can still make mistakes and are not foolproof &lt;em&gt;yet&lt;/em&gt;, Liberate uses an internal tool called Supervisor to monitor all interactions between its agents and customers. The software flags issues or anomalies and escalates to a human when the AI’s response may be off-track, Singh said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The advantage of servicing only one industry, and within that servicing only three specific use cases, is that you can put a lot more guardrails in place,” the executive noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Without disclosing the names of its clients, Liberate said that using its agents, hurricane claim response time dropped from 30 hours to 30 seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI agents enable 24/7 sales operations, allowing customers to buy insurance even at midnight or early in the morning — times when human agents typically are not available, Singh said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before this round, Liberate raised $15 million in Series A last year. Its voice AI–powered omnichannel experience and ability to fully automate tasks by integrating into existing systems were key factors that drew investors to back the company at a larger scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Mapping the process, modeling it, and making sure that all the systems connections are in place, well tested, and appropriately designed so that you can complete the task, not just communicate, is what Liberate is doing,” Marcus Ryu, a general partner at Battery Ventures, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ryu, who previously worked with property and casualty insurers at Guidewire Software, focuses on enterprise software, fintech, and insurtech investments at Battery Ventures. He is joining Liberate’s board.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Series B funding will be used to expand Liberate’s reasoning capabilities and support broader deployment across insurers. The startup has raised $72 million to date and currently employs around 50 people.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Liberate, an AI startup automating insurance operations, has raised $50 million in a round led by Battery Ventures as it looks to scale its agentic deployments across carriers and agencies globally.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The all-equity round values the three-year-old startup at $300 million post-money, with participation from new investor Canapi Ventures and returning backers Redpoint Ventures, Eclipse, and Commerce Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The insurance industry has been navigating a difficult stretch, with rising operational costs, legacy system constraints, and increasing customer expectations. Specifically in the non-life segment, global premium growth is projected to slow through 2026, driven by heightened competition, weaker rate momentum, and new cost pressures, including tariffs, per a recent report by Deloitte. While some carriers experimented with AI, many early efforts stalled due to fragmented data and inflexible workflows. That is now changing, as insurers shift toward full-scale AI adoption — embedding it into the core of their operations rather than layering it on top. Liberate is stepping in to meet this shift head-on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2022, the San Francisco-based startup builds AI systems for property and casualty insurers, focusing on sales, service, and claims. At the front end, its voice AI assistant, Nicole, handles inbound and outbound calls to help sell policies or respond to service requests. Behind the scenes, a network of reasoning-based AI agents connects to insurers’ existing systems, gathering context and generating responses that Nicole delivers — all without human intervention.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liberate’s AI agents are built to complete end-to-end tasks — not just respond to queries or escalate tickets. These include quoting policies, processing claims, and updating endorsements, among other routine functions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agents can also operate over SMS and email, allowing insurers to interact with customers across different channels while automating more of their day-to-day workflows.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Insurance companies want to grow, but they’re not able to do so,” Liberate co-founder and CEO Amrish Singh (pictured above, center) said in an interview. “It’s the status quo where the opportunity is.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Singh co-founded Liberate after nearly four years at Metromile, the car insurance firm owned by Lemonade, where he worked across both back-office operations and technology. He teamed up with Ryan Eldridge, Liberate’s VP of engineering and also a former Metromile executive, and Jason St. Pierre, the company’s CPO, who previously held roles at Twitter, Google, and Verily, Alphabet’s life sciences arm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liberate’s AI systems have helped increase sales by an average of 15% and cut costs by 23%, Singh told TechCrunch, adding that the startup now has over 60 customers and focuses on the top 100 carriers and agencies, which together represent 70% to 80% of the U.S. property and casualty insurance market.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3057757" height="1200" src="https://techcrunch.com/wp-content/uploads/2025/10/liberate-agent-orchestration-screenshot.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Liberate’s agent orchestration&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The technology uses reinforcement learning tailored for long, regulated insurance conversations. Each interaction is auditable and includes human-in-the-loop safeguards to meet compliance requirements, the startup said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Over the past year, Liberate has scaled from 10,000 monthly automations to 1.3 million automated resolutions, Singh stated. These include direct customer interactions via its voice AI, as well as back-office tasks handled by AI agents integrated into carriers’ core systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since AI systems can still make mistakes and are not foolproof &lt;em&gt;yet&lt;/em&gt;, Liberate uses an internal tool called Supervisor to monitor all interactions between its agents and customers. The software flags issues or anomalies and escalates to a human when the AI’s response may be off-track, Singh said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The advantage of servicing only one industry, and within that servicing only three specific use cases, is that you can put a lot more guardrails in place,” the executive noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Without disclosing the names of its clients, Liberate said that using its agents, hurricane claim response time dropped from 30 hours to 30 seconds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI agents enable 24/7 sales operations, allowing customers to buy insurance even at midnight or early in the morning — times when human agents typically are not available, Singh said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before this round, Liberate raised $15 million in Series A last year. Its voice AI–powered omnichannel experience and ability to fully automate tasks by integrating into existing systems were key factors that drew investors to back the company at a larger scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Mapping the process, modeling it, and making sure that all the systems connections are in place, well tested, and appropriately designed so that you can complete the task, not just communicate, is what Liberate is doing,” Marcus Ryu, a general partner at Battery Ventures, told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ryu, who previously worked with property and casualty insurers at Guidewire Software, focuses on enterprise software, fintech, and insurtech investments at Battery Ventures. He is joining Liberate’s board.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Series B funding will be used to expand Liberate’s reasoning capabilities and support broader deployment across insurers. The startup has raised $72 million to date and currently employs around 50 people.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/liberate-bags-50m-at-300m-valuation-to-bring-ai-deeper-into-insurance-back-offices/</guid><pubDate>Wed, 15 Oct 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Anthropic launches new version of scaled-down ‘Haiku’ model (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/anthropic-launches-new-version-of-scaled-down-haiku-model/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screen-Shot-2025-10-15-at-10.38.58-AM.jpg?w=800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Wednesday, Anthropic released Claude Haiku 4.5, the newest version of its smallest model, billed as offering similar performance to Sonnet 4 “at one-third the cost and more than twice the speed,” per a company blog post. While the &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic sites a range of new benchmark results to back up those performance claims. In the company’s testing, Haiku scored 73% on SWE-Bench verified and 41% on the command-line-focused Terminal-Bench — below Sonnet 4.5, but on par with Sonnet 4, GPT-5 and Gemini 2.5 in each case. Tests show similar results on benchmarks for tool use, computer use, and visual reasoning.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new version of Haiku will be immediately available under all free Anthropic plans and the company believes it will be particularly appealing for free versions of AI products, where it can provide significant capabilities while minimizing server loads. The lightweight nature of the model also means it’s easier to deploy multiple Haiku agents in parallel or in combination with a more sophisticated model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement to press, Anthropic CPO Mike Krieger said the Haiku would make new styles of deployment possible in production for the first time. “It’s is opening up entirely new categories of what’s possible with AI in production environments – with Sonnet handling complex planning while Haiku-powered sub-agents execute at speed,” Krieger said. “We’re giving people a complete agent toolbox where each model has the right combination of intelligence, speed, and cost for different parts of the job.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most immediate applications are likely to come in software development tools, where Claude Code is already commonly used and latency is often a critical factor. In statements provided by Anthropic, Zencoder CEO Andrew Filev described the new version of Haiku as “unlocking an entirely new set of use cases.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Haiku 4.5 comes after a string of high-profile launches for Anthropic: just two weeks after the launch of Sonnet 4.5 and two months after the launch of Opus 4.1, both of which were hailed as state-of-the-art on release. The previous version of Haiku was released in October 2024.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screen-Shot-2025-10-15-at-10.38.58-AM.jpg?w=800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Wednesday, Anthropic released Claude Haiku 4.5, the newest version of its smallest model, billed as offering similar performance to Sonnet 4 “at one-third the cost and more than twice the speed,” per a company blog post. While the &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic sites a range of new benchmark results to back up those performance claims. In the company’s testing, Haiku scored 73% on SWE-Bench verified and 41% on the command-line-focused Terminal-Bench — below Sonnet 4.5, but on par with Sonnet 4, GPT-5 and Gemini 2.5 in each case. Tests show similar results on benchmarks for tool use, computer use, and visual reasoning.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new version of Haiku will be immediately available under all free Anthropic plans and the company believes it will be particularly appealing for free versions of AI products, where it can provide significant capabilities while minimizing server loads. The lightweight nature of the model also means it’s easier to deploy multiple Haiku agents in parallel or in combination with a more sophisticated model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement to press, Anthropic CPO Mike Krieger said the Haiku would make new styles of deployment possible in production for the first time. “It’s is opening up entirely new categories of what’s possible with AI in production environments – with Sonnet handling complex planning while Haiku-powered sub-agents execute at speed,” Krieger said. “We’re giving people a complete agent toolbox where each model has the right combination of intelligence, speed, and cost for different parts of the job.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The most immediate applications are likely to come in software development tools, where Claude Code is already commonly used and latency is often a critical factor. In statements provided by Anthropic, Zencoder CEO Andrew Filev described the new version of Haiku as “unlocking an entirely new set of use cases.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Haiku 4.5 comes after a string of high-profile launches for Anthropic: just two weeks after the launch of Sonnet 4.5 and two months after the launch of Opus 4.1, both of which were hailed as state-of-the-art on release. The previous version of Haiku was released in October 2024.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/anthropic-launches-new-version-of-scaled-down-haiku-model/</guid><pubDate>Wed, 15 Oct 2025 17:00:00 +0000</pubDate></item><item><title>[NEW] Eightfold co-founders raise $35M for Viven, an AI digital twin startup for querying unavailable coworkers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/15/eightfold-co-founders-raise-35m-for-viven-an-ai-digital-twin-startup-for-querying-unavailable-coworkers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Viven.jpg.jpeg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While employees spend much of their day communicating and coordinating amongst themselves on projects, this effort is often undermined by the availability of specific individuals. When a colleague with vital information is away — whether on vacation or in a different time zone — the rest of the team must delay progress until that person responds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ashutosh Garg and Varun Kacholia, the co-founders of Eightfold — an AI recruiting startup last valued at $2.1 billion — believe that advances in LLMs and data privacy technologies can help solve some aspects of this costly problem. Earlier this year, they launched Viven, a digital twins startup with a mission to grant employees access to crucial information from teammates even when those colleagues are unavailable.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Wednesday, Viven emerged out of stealth mode with $35 million in seed funding from Khosla Ventures, Foundation Capital, FPV Ventures, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Viven develops a specialized LLM for each employee, effectively creating a digital twin by accessing their internal electronic documents such as email, Slack, and Google Docs. Other employees in the organization can then query that person’s digital twin to get immediate answers related to common projects and shared knowledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When each and every person has a digital twin, you can just talk to their twin as if you’re talking to that person and get the response,” Ashutosh Garg told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One major hurdle is that people just can’t share everything with anyone who asks. Employees often handle sensitive  information or have personal files they want to keep private from the rest of the team.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Garg, Viven’s technology solves that complex problem through a concept known as pairwise context and privacy. This enables the startup’s LLMs to precisely determine what information can be shared and with whom across the organization.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Viven’s LLMs are smart enough to recognize personal context and know what information needs to stay private — like questions related to an employee’s personal life. But perhaps the most important safeguard is that everyone can see the query history of their digital twin, which acts as a deterrent against people asking inappropriate questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a very hard problem to solve, and until recently, it was unsolvable,” Ashu Garg, a general partner at Foundation Capital told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Viven is already in use by several enterprise clients, including Genpact and Eightfold. (Co-founders Ashutosh Garg and Varun Kacholia continue to lead Eightfold, splitting their time between that company and running Viven.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As for competition, Ashutosh Garg claims that no other company is tackling digital twins for the enterprise yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He wasn’t sure that there were no competitors when he first started thinking about the idea. So he called Vinod Khosla to ask about it. The legendary investor assured Ashutosh Garg that nobody is doing this and agreed to invest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ashu Garg of Foundation Capital was equally excited about Viven.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When Ashutosh came to me and described the product, the big aha for me was: there’s this horizontal problem across all jobs of coordination and communication, which no one is automating,” Ashu Garg told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But just because there are no direct competitors now, it doesn’t mean that other companies won’t build digital twins for companies in the future. Ashu Garg said that Anthropic, Google’s Gemina, Microsoft Copilot, and OpenAI’s enterprise search products have a personalization component. But, if they do enter this market, Viven hopes its “pairwise” context technology will be its moat.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Viven.jpg.jpeg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While employees spend much of their day communicating and coordinating amongst themselves on projects, this effort is often undermined by the availability of specific individuals. When a colleague with vital information is away — whether on vacation or in a different time zone — the rest of the team must delay progress until that person responds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ashutosh Garg and Varun Kacholia, the co-founders of Eightfold — an AI recruiting startup last valued at $2.1 billion — believe that advances in LLMs and data privacy technologies can help solve some aspects of this costly problem. Earlier this year, they launched Viven, a digital twins startup with a mission to grant employees access to crucial information from teammates even when those colleagues are unavailable.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Wednesday, Viven emerged out of stealth mode with $35 million in seed funding from Khosla Ventures, Foundation Capital, FPV Ventures, and others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Viven develops a specialized LLM for each employee, effectively creating a digital twin by accessing their internal electronic documents such as email, Slack, and Google Docs. Other employees in the organization can then query that person’s digital twin to get immediate answers related to common projects and shared knowledge.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When each and every person has a digital twin, you can just talk to their twin as if you’re talking to that person and get the response,” Ashutosh Garg told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One major hurdle is that people just can’t share everything with anyone who asks. Employees often handle sensitive  information or have personal files they want to keep private from the rest of the team.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Garg, Viven’s technology solves that complex problem through a concept known as pairwise context and privacy. This enables the startup’s LLMs to precisely determine what information can be shared and with whom across the organization.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Viven’s LLMs are smart enough to recognize personal context and know what information needs to stay private — like questions related to an employee’s personal life. But perhaps the most important safeguard is that everyone can see the query history of their digital twin, which acts as a deterrent against people asking inappropriate questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a very hard problem to solve, and until recently, it was unsolvable,” Ashu Garg, a general partner at Foundation Capital told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Viven is already in use by several enterprise clients, including Genpact and Eightfold. (Co-founders Ashutosh Garg and Varun Kacholia continue to lead Eightfold, splitting their time between that company and running Viven.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As for competition, Ashutosh Garg claims that no other company is tackling digital twins for the enterprise yet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He wasn’t sure that there were no competitors when he first started thinking about the idea. So he called Vinod Khosla to ask about it. The legendary investor assured Ashutosh Garg that nobody is doing this and agreed to invest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ashu Garg of Foundation Capital was equally excited about Viven.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When Ashutosh came to me and described the product, the big aha for me was: there’s this horizontal problem across all jobs of coordination and communication, which no one is automating,” Ashu Garg told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But just because there are no direct competitors now, it doesn’t mean that other companies won’t build digital twins for companies in the future. Ashu Garg said that Anthropic, Google’s Gemina, Microsoft Copilot, and OpenAI’s enterprise search products have a personalization component. But, if they do enter this market, Viven hopes its “pairwise” context technology will be its moat.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/15/eightfold-co-founders-raise-35m-for-viven-an-ai-digital-twin-startup-for-querying-unavailable-coworkers/</guid><pubDate>Wed, 15 Oct 2025 17:15:00 +0000</pubDate></item><item><title>[NEW] Blending neuroscience, AI, and music to create mental health innovations (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/kimaya-lecamwasam-blending-neuroscience-ai-music-to-create-mental-health-innovations-1015</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-Kimaya-Lecamwasam.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Computational neuroscientist and singer/songwriter Kimaya (Kimy) Lecamwasam, who also plays electric bass and guitar, says music has been a core part of her life for as long as she can remember. She grew up in a musical family and played in bands all through high school.&lt;/p&gt;&lt;p&gt;“For most of my life, writing and playing music was the clearest way I had to express myself,” says Lecamwasam. “I was a really shy and anxious kid, and I struggled with speaking up for myself. Over time, composing and performing music became central to both how I communicated and to how I managed my own mental health.”&lt;/p&gt;&lt;p&gt;Along with equipping her with valuable skills and experiences, she credits her passion for music as the catalyst for her interest in neuroscience.&lt;/p&gt;&lt;p&gt;“I got to see firsthand not only the ways that audiences reacted to music, but also how much value music had for musicians,” she says. “That close connection between making music and feeling well is what first pushed me to ask why music has such a powerful hold on us, and eventually led me to study the science behind it.”&lt;/p&gt;&lt;p&gt;Lecamwasam earned a bachelor’s degree in 2021 from Wellesley College, where she studied neuroscience — specifically in the Systems and Computational Neuroscience track — and also music. During her first semester, she took a class in songwriting that she says made her more aware of the connections between music and emotions. While studying at Wellesley, she participated in the MIT Undergraduate Research Opportunities Program for three years. Working in the Department of Brain and Cognitive Sciences lab of Emery Brown, the Edward Hood Taplin Professor of Medical Engineering and Computational Neuroscience, she focused primarily on classifying consciousness in anesthetized patients and training brain-computer interface-enabled prosthetics using reinforcement learning.&lt;/p&gt;&lt;p&gt;“I still had a really deep love for music, which I was pursuing in parallel to all of my neuroscience work, but I really wanted to try to find a way to combine both of those things in grad school,” says Lecamwasam. Brown recommended that she look into the graduate programs at the MIT Media Lab within the Program in Media Arts and Sciences (MAS), which turned out to be an ideal fit.&lt;/p&gt;&lt;p&gt;“One thing I really love about where I am is that I get to be both an artist and a scientist,” says Lecamwasam. “That was something that was important to me when I was picking a graduate program. I wanted to make sure that I was going to be able to do work that was really rigorous, validated, and important, but also get to do cool, creative explorations and actually put the research that I was doing into practice in different ways.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exploring the physical, mental, and emotional impacts of music&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Informed by her years of neuroscience research as an undergraduate and her passion for music, Lecamwasam focused her graduate research on harnessing the emotional potency of music into scalable, non-pharmacological mental health tools. Her master’s thesis focused on “pharmamusicology,” looking at how music might positively affect the physiology and psychology of those with anxiety.&lt;/p&gt;&lt;p&gt;The overarching theme of Lecamwasam’s research is exploring the various impacts of&amp;nbsp;music and affective computing — physically, mentally, and emotionally.&amp;nbsp;Now in the third year of her doctoral program in the&amp;nbsp;Opera of the Future group, she is currently investigating the impact of large-scale live music and concert experiences on the mental health and well-being of both audience members and performers. She is also working to clinically validate music listening, composition, and performance as health interventions, in combination with psychotherapy and pharmaceutical interventions.&lt;/p&gt;&lt;p&gt;Her recent work, in collaboration with Professor Anna Huang’s Human-AI Resonance Lab, assesses the emotional resonance of AI-generated music compared to human-composed music;&amp;nbsp;the aim is to identify more ethical applications of emotion-sensitive music generation and recommendation that preserve human creativity and agency, and can also be used as health interventions. She has co-led a wellness and music workshop at the Wellbeing Summit in Bilbao, Spain, and has presented her work at the 2023 CHI conference on Human Factors in Computing Systems in Hamburg, Germany and the 2024 Audio Mostly conference in Milan, Italy.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lecamwasam&amp;nbsp;has collaborated with organizations near and far to implement real-world applications of her research. She worked with Carnegie Hall's Weill Music Institute on its Well-Being Concerts and is currently partnering on a study assessing the impact of lullaby writing on perinatal health with the North Shore Lullaby Project in Massachusetts, an offshoot of Carnegie Hall’s Lullaby Project. Her main international collaboration is with a company called Myndstream, working on projects comparing the emotional resonance of AI-generated music to human-composed music and thinking of clinical and real-world applications. She is also working on a project with the companies PixMob and Empatica (an MIT Media Lab spinoff), centered on assessing the impact of interactive lighting and large-scale live music experiences on emotional resonance in stadium and arena settings.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building community&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“Kimy combines a deep love for — and sophisticated knowledge of — music with scientific curiosity and rigor in ways that represent the Media Lab/MAS spirit at its best,” says Professor Tod Machover, Lecamwasam’s research advisor, Media Lab faculty director, and director of the Opera of the Future group. “She has long believed that music is one of the most powerful and effective ways to create personalized interventions to help stabilize emotional distress and promote empathy and connection. It is this same desire to establish sane, safe, and sustaining environments for work and play that has led Kimy to become one of the most effective and devoted community-builders at the lab.”&lt;/p&gt;&lt;p&gt;Lecamwasam has participated in the SOS (Students Offering Support) program in MAS for a few years, which assists students from a variety of life experiences and backgrounds during the process of applying to the Program in Media Arts and Sciences. She will soon be the first MAS peer mentor as part of a new initiative through which she will establish and coordinate programs including a “buddy system,” pairing incoming master’s students with PhD students as a way to help them transition into graduate student life at MIT. She is also part of the Media Lab’s Studcom, a student-run organization that promotes, facilitates, and creates experiences meant to bring the community together.&lt;/p&gt;&lt;p&gt;“I think everything that I have gotten to do has been so supported by the friends I’ve made in my lab and department, as well as across departments,” says Lecamwasam. “I think everyone is just really excited about the work that they do and so supportive of one another. It makes it so that even when things are challenging or difficult, I’m motivated to do this work and be a part of this community.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-Kimaya-Lecamwasam.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Computational neuroscientist and singer/songwriter Kimaya (Kimy) Lecamwasam, who also plays electric bass and guitar, says music has been a core part of her life for as long as she can remember. She grew up in a musical family and played in bands all through high school.&lt;/p&gt;&lt;p&gt;“For most of my life, writing and playing music was the clearest way I had to express myself,” says Lecamwasam. “I was a really shy and anxious kid, and I struggled with speaking up for myself. Over time, composing and performing music became central to both how I communicated and to how I managed my own mental health.”&lt;/p&gt;&lt;p&gt;Along with equipping her with valuable skills and experiences, she credits her passion for music as the catalyst for her interest in neuroscience.&lt;/p&gt;&lt;p&gt;“I got to see firsthand not only the ways that audiences reacted to music, but also how much value music had for musicians,” she says. “That close connection between making music and feeling well is what first pushed me to ask why music has such a powerful hold on us, and eventually led me to study the science behind it.”&lt;/p&gt;&lt;p&gt;Lecamwasam earned a bachelor’s degree in 2021 from Wellesley College, where she studied neuroscience — specifically in the Systems and Computational Neuroscience track — and also music. During her first semester, she took a class in songwriting that she says made her more aware of the connections between music and emotions. While studying at Wellesley, she participated in the MIT Undergraduate Research Opportunities Program for three years. Working in the Department of Brain and Cognitive Sciences lab of Emery Brown, the Edward Hood Taplin Professor of Medical Engineering and Computational Neuroscience, she focused primarily on classifying consciousness in anesthetized patients and training brain-computer interface-enabled prosthetics using reinforcement learning.&lt;/p&gt;&lt;p&gt;“I still had a really deep love for music, which I was pursuing in parallel to all of my neuroscience work, but I really wanted to try to find a way to combine both of those things in grad school,” says Lecamwasam. Brown recommended that she look into the graduate programs at the MIT Media Lab within the Program in Media Arts and Sciences (MAS), which turned out to be an ideal fit.&lt;/p&gt;&lt;p&gt;“One thing I really love about where I am is that I get to be both an artist and a scientist,” says Lecamwasam. “That was something that was important to me when I was picking a graduate program. I wanted to make sure that I was going to be able to do work that was really rigorous, validated, and important, but also get to do cool, creative explorations and actually put the research that I was doing into practice in different ways.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Exploring the physical, mental, and emotional impacts of music&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Informed by her years of neuroscience research as an undergraduate and her passion for music, Lecamwasam focused her graduate research on harnessing the emotional potency of music into scalable, non-pharmacological mental health tools. Her master’s thesis focused on “pharmamusicology,” looking at how music might positively affect the physiology and psychology of those with anxiety.&lt;/p&gt;&lt;p&gt;The overarching theme of Lecamwasam’s research is exploring the various impacts of&amp;nbsp;music and affective computing — physically, mentally, and emotionally.&amp;nbsp;Now in the third year of her doctoral program in the&amp;nbsp;Opera of the Future group, she is currently investigating the impact of large-scale live music and concert experiences on the mental health and well-being of both audience members and performers. She is also working to clinically validate music listening, composition, and performance as health interventions, in combination with psychotherapy and pharmaceutical interventions.&lt;/p&gt;&lt;p&gt;Her recent work, in collaboration with Professor Anna Huang’s Human-AI Resonance Lab, assesses the emotional resonance of AI-generated music compared to human-composed music;&amp;nbsp;the aim is to identify more ethical applications of emotion-sensitive music generation and recommendation that preserve human creativity and agency, and can also be used as health interventions. She has co-led a wellness and music workshop at the Wellbeing Summit in Bilbao, Spain, and has presented her work at the 2023 CHI conference on Human Factors in Computing Systems in Hamburg, Germany and the 2024 Audio Mostly conference in Milan, Italy.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Lecamwasam&amp;nbsp;has collaborated with organizations near and far to implement real-world applications of her research. She worked with Carnegie Hall's Weill Music Institute on its Well-Being Concerts and is currently partnering on a study assessing the impact of lullaby writing on perinatal health with the North Shore Lullaby Project in Massachusetts, an offshoot of Carnegie Hall’s Lullaby Project. Her main international collaboration is with a company called Myndstream, working on projects comparing the emotional resonance of AI-generated music to human-composed music and thinking of clinical and real-world applications. She is also working on a project with the companies PixMob and Empatica (an MIT Media Lab spinoff), centered on assessing the impact of interactive lighting and large-scale live music experiences on emotional resonance in stadium and arena settings.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Building community&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“Kimy combines a deep love for — and sophisticated knowledge of — music with scientific curiosity and rigor in ways that represent the Media Lab/MAS spirit at its best,” says Professor Tod Machover, Lecamwasam’s research advisor, Media Lab faculty director, and director of the Opera of the Future group. “She has long believed that music is one of the most powerful and effective ways to create personalized interventions to help stabilize emotional distress and promote empathy and connection. It is this same desire to establish sane, safe, and sustaining environments for work and play that has led Kimy to become one of the most effective and devoted community-builders at the lab.”&lt;/p&gt;&lt;p&gt;Lecamwasam has participated in the SOS (Students Offering Support) program in MAS for a few years, which assists students from a variety of life experiences and backgrounds during the process of applying to the Program in Media Arts and Sciences. She will soon be the first MAS peer mentor as part of a new initiative through which she will establish and coordinate programs including a “buddy system,” pairing incoming master’s students with PhD students as a way to help them transition into graduate student life at MIT. She is also part of the Media Lab’s Studcom, a student-run organization that promotes, facilitates, and creates experiences meant to bring the community together.&lt;/p&gt;&lt;p&gt;“I think everything that I have gotten to do has been so supported by the friends I’ve made in my lab and department, as well as across departments,” says Lecamwasam. “I think everyone is just really excited about the work that they do and so supportive of one another. It makes it so that even when things are challenging or difficult, I’m motivated to do this work and be a part of this community.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/kimaya-lecamwasam-blending-neuroscience-ai-music-to-create-mental-health-innovations-1015</guid><pubDate>Wed, 15 Oct 2025 17:20:00 +0000</pubDate></item><item><title>[NEW] Remembering Professor Emerita Jeanne Shapiro  Bamberger, a pioneer in music education (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/remembering-professor-emerita-jeanne-shapiro-bamberger-1015</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-jeanne-shapiro-bamberger-obit.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;MIT Music and Theater Arts fondly remembers the legacy of Professor Emerita Jeanne Shapiro&amp;nbsp;Bamberger, who passed away peacefully at home in Berkeley, California, of natural causes on Dec. 12, 2024 at the age of 100.&amp;nbsp;&lt;/p&gt;&lt;p&gt;For three decades at the Institute, Bamberger found ways to use computers to engage students and help them learn music. A trained pianist who became fascinated with the idea of using technology to gain insights into music education, Bamberger ultimately helped to change how music was taught at MIT and elsewhere.&lt;/p&gt;&lt;p&gt;Bamberger was born on Feb. 11, 1924 in Minneapolis, Minnesota. Her mother, Gertrude Shapiro (nee Kulberg), from a Romanian Jewish family, studied child psychology and was active in the League of Women Voters. Her father, Morse Shapiro, of Lithuanian and Polish Jewish heritage, was a groundbreaking pediatric cardiologist.&lt;/p&gt;&lt;p&gt;In 1969, Bamberger began her 32-year career at MIT, initially in the former MIT Education Department. While at MIT, Bamberger became the first woman to earn tenure in the Music and Theater Arts Section. She was know for pioneering the use of computer languages to teach children to learn music. She also used her computer innovations to study how children — and by extension, all humans — learn music, and this vector in particular became her life's work.&lt;/p&gt;&lt;p&gt;Ahead of her time, Bamberger worked in the MIT Artificial Intelligence Lab in the 1980s and developed computer languages (MusicLogo and Impromptu) while at the MIT Division for Study and Research in Education from 1975 to 1995. She became associate professor in music and theater arts in 1981, earned tenure soon thereafter, and chaired the department in 1989-90. During this period, she continued to perform as a concert pianist, taking part in concerts with the MIT Symphony Orchestra, and actively playing chamber music both at MIT and in the community. She also taught at the Harvard University Department of Education.&lt;/p&gt;&lt;p&gt;Institute Professor Marcus Thompson recollects, “During her time with us as a senior professor she was clearly a jewel in the crown. For someone who had studied piano with an historic legend in Artur Schnabel, who had studied with and known at least one of the French Six, Darius Milhaud, and worked with French composer and conductor Pierre Boulez, she was among that group of our professors who continually advocated for a new music building, considered the possibility of a graduate program in music at a time when we were being pushed to grow, at a time when she was our only senior woman when the need to do better was finally seen.” Both the dedicated music building and the graduate music program are now a reality.&lt;/p&gt;&lt;p&gt;Bamberger loved her work and was beloved and admired by her students and colleagues. Kenan Sahin Distinguished Professor Evan Ziporyn shares that she “was very much a shaping presence for our section — MIT Music and Theater Arts wouldn't be what we are today without her contributions. She’s also just a very cool person — I mean, how many 90-year-old academics end up working with Herbie Hancock and taking their research to the White House?”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ziporyn adds that “among 7 million other singular accomplishments,” Bamberger published numerous articles and books&amp;nbsp;including&amp;nbsp;“The Art of Listening”&lt;em&gt;&amp;nbsp;&lt;/em&gt;with Howard Brofsky,&amp;nbsp;“The Mind Behind the Musical Ear,”&amp;nbsp;“Developing&amp;nbsp;Musical Intuitions,” and&amp;nbsp;“Discovering the Musical&amp;nbsp;Mind.”&lt;/p&gt;&lt;p&gt;While at MIT, Bamberger took many students under her wing and assisted many more with their academic careers. Elaine Chew SM ’98, PhD ’00, an operations researcher, pianist, current professor of engineering at King’s College London, and mentee of Bamberger, says, “I would not be doing what I am today if not for Jeanne. A child prodigy turned music philosopher, Jeanne was a pioneer in music and AI long before it was fashionable. She was deeply interested in people and passionate about how we learn. I will not forget the day when I came to her with complaints about things not working. Rather than telling me what to do, Jeanne said, ‘What are you going to do about it?’ prompting me to reflect on and develop my own sense of agency.” (Chew speaks more on Bamberger’s inspirational role in a 2016 interview.)&lt;/p&gt;&lt;p&gt;All told, Bamberger had a creative, fertile mind and loved to ask probing questions, a quality she passed to her progeny and community — it was her excitement and her passion.&lt;/p&gt;&lt;p&gt;While a professor at MIT, Bamberger was a force to be reckoned with. In addition to her long and productive academic career — in which she published four books and nearly 20 book chapters — she was politically active and supported the anti-Vietnam war and the civil rights movements. She continued teaching and publishing&amp;nbsp;her work well into her 90s and had a strong community of companions and colleagues to the end.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In 2002, Bamberger became professor emerita at MIT and moved to Berkeley, California, continuing to teach in the Music Department at the University of California at Berkeley.&lt;/p&gt;&lt;p&gt;At 100, she was predeceased by her former husband, Frank K. Bamberger. She is survived by her two sons, Joshua and Paul (Chip); four grandchildren — Jerehme, Kaela, Eli, and Noah; and many caring relatives and friends.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/mit-jeanne-shapiro-bamberger-obit.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;MIT Music and Theater Arts fondly remembers the legacy of Professor Emerita Jeanne Shapiro&amp;nbsp;Bamberger, who passed away peacefully at home in Berkeley, California, of natural causes on Dec. 12, 2024 at the age of 100.&amp;nbsp;&lt;/p&gt;&lt;p&gt;For three decades at the Institute, Bamberger found ways to use computers to engage students and help them learn music. A trained pianist who became fascinated with the idea of using technology to gain insights into music education, Bamberger ultimately helped to change how music was taught at MIT and elsewhere.&lt;/p&gt;&lt;p&gt;Bamberger was born on Feb. 11, 1924 in Minneapolis, Minnesota. Her mother, Gertrude Shapiro (nee Kulberg), from a Romanian Jewish family, studied child psychology and was active in the League of Women Voters. Her father, Morse Shapiro, of Lithuanian and Polish Jewish heritage, was a groundbreaking pediatric cardiologist.&lt;/p&gt;&lt;p&gt;In 1969, Bamberger began her 32-year career at MIT, initially in the former MIT Education Department. While at MIT, Bamberger became the first woman to earn tenure in the Music and Theater Arts Section. She was know for pioneering the use of computer languages to teach children to learn music. She also used her computer innovations to study how children — and by extension, all humans — learn music, and this vector in particular became her life's work.&lt;/p&gt;&lt;p&gt;Ahead of her time, Bamberger worked in the MIT Artificial Intelligence Lab in the 1980s and developed computer languages (MusicLogo and Impromptu) while at the MIT Division for Study and Research in Education from 1975 to 1995. She became associate professor in music and theater arts in 1981, earned tenure soon thereafter, and chaired the department in 1989-90. During this period, she continued to perform as a concert pianist, taking part in concerts with the MIT Symphony Orchestra, and actively playing chamber music both at MIT and in the community. She also taught at the Harvard University Department of Education.&lt;/p&gt;&lt;p&gt;Institute Professor Marcus Thompson recollects, “During her time with us as a senior professor she was clearly a jewel in the crown. For someone who had studied piano with an historic legend in Artur Schnabel, who had studied with and known at least one of the French Six, Darius Milhaud, and worked with French composer and conductor Pierre Boulez, she was among that group of our professors who continually advocated for a new music building, considered the possibility of a graduate program in music at a time when we were being pushed to grow, at a time when she was our only senior woman when the need to do better was finally seen.” Both the dedicated music building and the graduate music program are now a reality.&lt;/p&gt;&lt;p&gt;Bamberger loved her work and was beloved and admired by her students and colleagues. Kenan Sahin Distinguished Professor Evan Ziporyn shares that she “was very much a shaping presence for our section — MIT Music and Theater Arts wouldn't be what we are today without her contributions. She’s also just a very cool person — I mean, how many 90-year-old academics end up working with Herbie Hancock and taking their research to the White House?”&amp;nbsp;&lt;/p&gt;&lt;p&gt;Ziporyn adds that “among 7 million other singular accomplishments,” Bamberger published numerous articles and books&amp;nbsp;including&amp;nbsp;“The Art of Listening”&lt;em&gt;&amp;nbsp;&lt;/em&gt;with Howard Brofsky,&amp;nbsp;“The Mind Behind the Musical Ear,”&amp;nbsp;“Developing&amp;nbsp;Musical Intuitions,” and&amp;nbsp;“Discovering the Musical&amp;nbsp;Mind.”&lt;/p&gt;&lt;p&gt;While at MIT, Bamberger took many students under her wing and assisted many more with their academic careers. Elaine Chew SM ’98, PhD ’00, an operations researcher, pianist, current professor of engineering at King’s College London, and mentee of Bamberger, says, “I would not be doing what I am today if not for Jeanne. A child prodigy turned music philosopher, Jeanne was a pioneer in music and AI long before it was fashionable. She was deeply interested in people and passionate about how we learn. I will not forget the day when I came to her with complaints about things not working. Rather than telling me what to do, Jeanne said, ‘What are you going to do about it?’ prompting me to reflect on and develop my own sense of agency.” (Chew speaks more on Bamberger’s inspirational role in a 2016 interview.)&lt;/p&gt;&lt;p&gt;All told, Bamberger had a creative, fertile mind and loved to ask probing questions, a quality she passed to her progeny and community — it was her excitement and her passion.&lt;/p&gt;&lt;p&gt;While a professor at MIT, Bamberger was a force to be reckoned with. In addition to her long and productive academic career — in which she published four books and nearly 20 book chapters — she was politically active and supported the anti-Vietnam war and the civil rights movements. She continued teaching and publishing&amp;nbsp;her work well into her 90s and had a strong community of companions and colleagues to the end.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In 2002, Bamberger became professor emerita at MIT and moved to Berkeley, California, continuing to teach in the Music Department at the University of California at Berkeley.&lt;/p&gt;&lt;p&gt;At 100, she was predeceased by her former husband, Frank K. Bamberger. She is survived by her two sons, Joshua and Paul (Chip); four grandchildren — Jerehme, Kaela, Eli, and Noah; and many caring relatives and friends.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/remembering-professor-emerita-jeanne-shapiro-bamberger-1015</guid><pubDate>Wed, 15 Oct 2025 17:25:00 +0000</pubDate></item></channel></rss>