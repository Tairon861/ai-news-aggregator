<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 03 Nov 2025 18:30:34 +0000</lastBuildDate><item><title>[NEW]  ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Qualcomm unveils AI data centre chips to crack the Inference market (AI News)</title><link>https://www.artificialintelligence-news.com/news/qualcomm-ai-data-centre-chips-ai200-ai250/</link><description>&lt;p&gt;The AI chip wars just got a new heavyweight contender. Qualcomm, the company that powers billions of smartphones worldwide, has made an audacious leap into AI data centre chips – a market where Nvidia has been minting money at an almost unfathomable rate and where fortunes rise and fall on promises of computational supremacy.&lt;/p&gt;&lt;p&gt;On October 28, 2025, Qualcomm threw down the gauntlet with its AI200 and AI250 solutions, rack-scale systems designed specifically for AI inference workloads. Wall Street’s reaction was immediate: Qualcomm’s stock price jumped approximately 11% as investors bet that even a modest slice of the exploding AI infrastructure market could transform the company’s trajectory.&lt;/p&gt;&lt;p&gt;The product launch could redefine Qualcomm’s identity. The San Diego chip giant has been synonymous with mobile technology, riding the smartphone wave to dominance. But with that market stagnating, CEO Cristiano Amon is placing a calculated wager on AI data centre chips, backed by a multi-billion-dollar partnership with a Saudi AI powerhouse that signals serious intent.&lt;/p&gt;&lt;h3&gt;Two chips, two different bets on the future&lt;/h3&gt;&lt;p&gt;Here’s where Qualcomm’s strategy gets interesting. Rather than releasing a single product and hoping for the best, the company is hedging its bets with two distinct AI data centre chip architectures, each targeting different market needs and timelines.&lt;/p&gt;&lt;p&gt;The AI200, arriving in 2026, takes the pragmatic approach. Think of it as Qualcomm’s foot in the door – a rack-scale system packing 768 GB of LPDDR memory per card.&lt;/p&gt;&lt;p&gt;That massive memory capacity is crucial for running today’s memory-hungry large language models and multimodal AI applications, and Qualcomm is betting that its lower-cost memory approach can undercut competitors on total cost of ownership while still delivering the performance enterprises demand.&lt;/p&gt;&lt;p&gt;But the AI250, slated for 2027, is where Qualcomm’s engineers have really been dreaming big. The solution introduces a near-memory computing architecture that promises to shatter conventional limitations with more than 10x higher effective memory bandwidth.&lt;/p&gt;&lt;p&gt;For AI data centre chips, memory bandwidth is often the bottleneck that determines whether your chatbot responds instantly or leaves users waiting. Qualcomm’s innovation here could be a genuine game-changer – assuming it can deliver on the promise.&lt;/p&gt;&lt;p&gt;“With Qualcomm AI200 and AI250, we’re redefining what’s possible for rack-scale AI inference,” said Durga Malladi, SVP and GM of technology planning, edge solutions &amp;amp; data centre at Qualcomm Technologies. “The innovative new AI infrastructure solutions empower customers to deploy AI at unprecedented TCO, while maintaining the flexibility and security modern data centres demand.”&lt;/p&gt;&lt;h3&gt;The real battle: Economics, not just performance&lt;/h3&gt;&lt;p&gt;In the AI infrastructure arms race, raw performance specs only tell half the story. The real war is fought on spreadsheets, where data centre operators calculate power bills, cooling costs, and hardware depreciation. Qualcomm knows this, and that’s why both AI data centre chip solutions obsess over total cost of ownership.&lt;/p&gt;&lt;p&gt;Each rack consumes 160 kW of power and employs direct liquid cooling – a necessity when you’re pushing this much computational power through silicon. The systems use PCIe for internal scaling and Ethernet for connecting multiple racks, providing deployment flexibility whether you’re running a modest AI service or building the next ChatGPT competitor.&lt;/p&gt;&lt;p&gt;Security hasn’t been an afterthought either; confidential computing capabilities are baked in, addressing the growing enterprise demand for protecting proprietary AI models and sensitive data.&lt;/p&gt;&lt;h3&gt;The Saudi connection: A billion-dollar validation&lt;/h3&gt;&lt;p&gt;Partnership announcements in tech can be vapour-thin, but Qualcomm’s deal with Humain carries some weight. The Saudi state-backed AI company has committed to deploying 200 megawatts of Qualcomm AI data centre chips – a figure that analyst Stacy Rasgon of Sanford C. Bernstein estimates translates to roughly $2 billion in revenue for Qualcomm.&lt;/p&gt;&lt;p&gt;Is $2 billion transformative? In the context of AMD’s $10 billion Humain deal announced the same year, it might seem modest. But for a company trying to prove it belongs in the AI infrastructure conversation, securing a major deployment commitment before your first product even ships is validation that money can’t buy.&lt;/p&gt;&lt;p&gt;“Together with Humain, we are laying the groundwork for transformative AI-driven innovation that will empower enterprises, government organisations and communities in the region and globally,” Amon declared in a statement that positions Qualcomm not just as a chip supplier, but as a strategic technology partner for emerging AI economies.&lt;/p&gt;&lt;p&gt;The collaboration, first announced in May 2025, transforms Qualcomm into a key infrastructure provider for Humain’s ambitious AI inferencing services – a role that could establish crucial reference designs and deployment patterns for future customers.&lt;/p&gt;&lt;h3&gt;Software stack and developer experience&lt;/h3&gt;&lt;p&gt;Beyond hardware specifications, Qualcomm is betting on developer-friendly software to accelerate adoption. The company’s AI software stack supports leading machine learning frameworks and promises “one-click deployment” of models from Hugging Face, a popular AI model repository.&lt;/p&gt;&lt;p&gt;The Qualcomm AI Inference Suite and Efficient Transformers Library aim to remove integration friction that has historically slowed enterprise AI deployments.&lt;/p&gt;&lt;h2&gt;David vs. Goliath (and another Goliath?)&lt;/h2&gt;&lt;p&gt;Let’s be honest about what Qualcomm is up against. Nvidia’s market capitalisation has soared past $4.5 trillion, a valuation that reflects years of AI dominance and an ecosystem so entrenched that many developers can’t imagine building on anything else.&lt;/p&gt;&lt;p&gt;AMD, once the scrappy challenger, has seen its shares more than double in value in 2025 as it successfully carved out its own piece of the AI pie.&lt;/p&gt;&lt;p&gt;Qualcomm’s late arrival to the AI data centre chips party means fighting an uphill battle against competitors who have battle-tested products, mature software stacks, and customers already running production workloads at scale.&lt;/p&gt;&lt;p&gt;The company’s smartphone focus, once its greatest strength, now looks like strategic tunnel vision that caused it to miss the initial AI infrastructure boom. Yet market analysts aren’t writing Qualcomm’s obituary. Timothy Arcuri of UBS captured the prevailing sentiment on a conference call: “The tide is rising so fast, and it will continue to rise so fast, it will lift all boats.” Translation: the AI market is expanding so rapidly that there’s room for multiple winners – even latecomers with compelling technology and competitive pricing.&lt;/p&gt;&lt;p&gt;Qualcomm is playing the long game, betting that sustained innovation in AI data centre chips can gradually win over customers looking for alternatives to the Nvidia-AMD duopoly. For enterprises evaluating AI infrastructure options, Qualcomm’s emphasis on inference optimisation, energy efficiency, and TCO presents an alternative worth watching – particularly as the AI200 approaches its 2026 launch date.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Qualcomm)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Migrating AI from Nvidia to Huawei: Opportunities and trade-offs&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110157" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here&lt;/p&gt;</description><content:encoded>&lt;p&gt;The AI chip wars just got a new heavyweight contender. Qualcomm, the company that powers billions of smartphones worldwide, has made an audacious leap into AI data centre chips – a market where Nvidia has been minting money at an almost unfathomable rate and where fortunes rise and fall on promises of computational supremacy.&lt;/p&gt;&lt;p&gt;On October 28, 2025, Qualcomm threw down the gauntlet with its AI200 and AI250 solutions, rack-scale systems designed specifically for AI inference workloads. Wall Street’s reaction was immediate: Qualcomm’s stock price jumped approximately 11% as investors bet that even a modest slice of the exploding AI infrastructure market could transform the company’s trajectory.&lt;/p&gt;&lt;p&gt;The product launch could redefine Qualcomm’s identity. The San Diego chip giant has been synonymous with mobile technology, riding the smartphone wave to dominance. But with that market stagnating, CEO Cristiano Amon is placing a calculated wager on AI data centre chips, backed by a multi-billion-dollar partnership with a Saudi AI powerhouse that signals serious intent.&lt;/p&gt;&lt;h3&gt;Two chips, two different bets on the future&lt;/h3&gt;&lt;p&gt;Here’s where Qualcomm’s strategy gets interesting. Rather than releasing a single product and hoping for the best, the company is hedging its bets with two distinct AI data centre chip architectures, each targeting different market needs and timelines.&lt;/p&gt;&lt;p&gt;The AI200, arriving in 2026, takes the pragmatic approach. Think of it as Qualcomm’s foot in the door – a rack-scale system packing 768 GB of LPDDR memory per card.&lt;/p&gt;&lt;p&gt;That massive memory capacity is crucial for running today’s memory-hungry large language models and multimodal AI applications, and Qualcomm is betting that its lower-cost memory approach can undercut competitors on total cost of ownership while still delivering the performance enterprises demand.&lt;/p&gt;&lt;p&gt;But the AI250, slated for 2027, is where Qualcomm’s engineers have really been dreaming big. The solution introduces a near-memory computing architecture that promises to shatter conventional limitations with more than 10x higher effective memory bandwidth.&lt;/p&gt;&lt;p&gt;For AI data centre chips, memory bandwidth is often the bottleneck that determines whether your chatbot responds instantly or leaves users waiting. Qualcomm’s innovation here could be a genuine game-changer – assuming it can deliver on the promise.&lt;/p&gt;&lt;p&gt;“With Qualcomm AI200 and AI250, we’re redefining what’s possible for rack-scale AI inference,” said Durga Malladi, SVP and GM of technology planning, edge solutions &amp;amp; data centre at Qualcomm Technologies. “The innovative new AI infrastructure solutions empower customers to deploy AI at unprecedented TCO, while maintaining the flexibility and security modern data centres demand.”&lt;/p&gt;&lt;h3&gt;The real battle: Economics, not just performance&lt;/h3&gt;&lt;p&gt;In the AI infrastructure arms race, raw performance specs only tell half the story. The real war is fought on spreadsheets, where data centre operators calculate power bills, cooling costs, and hardware depreciation. Qualcomm knows this, and that’s why both AI data centre chip solutions obsess over total cost of ownership.&lt;/p&gt;&lt;p&gt;Each rack consumes 160 kW of power and employs direct liquid cooling – a necessity when you’re pushing this much computational power through silicon. The systems use PCIe for internal scaling and Ethernet for connecting multiple racks, providing deployment flexibility whether you’re running a modest AI service or building the next ChatGPT competitor.&lt;/p&gt;&lt;p&gt;Security hasn’t been an afterthought either; confidential computing capabilities are baked in, addressing the growing enterprise demand for protecting proprietary AI models and sensitive data.&lt;/p&gt;&lt;h3&gt;The Saudi connection: A billion-dollar validation&lt;/h3&gt;&lt;p&gt;Partnership announcements in tech can be vapour-thin, but Qualcomm’s deal with Humain carries some weight. The Saudi state-backed AI company has committed to deploying 200 megawatts of Qualcomm AI data centre chips – a figure that analyst Stacy Rasgon of Sanford C. Bernstein estimates translates to roughly $2 billion in revenue for Qualcomm.&lt;/p&gt;&lt;p&gt;Is $2 billion transformative? In the context of AMD’s $10 billion Humain deal announced the same year, it might seem modest. But for a company trying to prove it belongs in the AI infrastructure conversation, securing a major deployment commitment before your first product even ships is validation that money can’t buy.&lt;/p&gt;&lt;p&gt;“Together with Humain, we are laying the groundwork for transformative AI-driven innovation that will empower enterprises, government organisations and communities in the region and globally,” Amon declared in a statement that positions Qualcomm not just as a chip supplier, but as a strategic technology partner for emerging AI economies.&lt;/p&gt;&lt;p&gt;The collaboration, first announced in May 2025, transforms Qualcomm into a key infrastructure provider for Humain’s ambitious AI inferencing services – a role that could establish crucial reference designs and deployment patterns for future customers.&lt;/p&gt;&lt;h3&gt;Software stack and developer experience&lt;/h3&gt;&lt;p&gt;Beyond hardware specifications, Qualcomm is betting on developer-friendly software to accelerate adoption. The company’s AI software stack supports leading machine learning frameworks and promises “one-click deployment” of models from Hugging Face, a popular AI model repository.&lt;/p&gt;&lt;p&gt;The Qualcomm AI Inference Suite and Efficient Transformers Library aim to remove integration friction that has historically slowed enterprise AI deployments.&lt;/p&gt;&lt;h2&gt;David vs. Goliath (and another Goliath?)&lt;/h2&gt;&lt;p&gt;Let’s be honest about what Qualcomm is up against. Nvidia’s market capitalisation has soared past $4.5 trillion, a valuation that reflects years of AI dominance and an ecosystem so entrenched that many developers can’t imagine building on anything else.&lt;/p&gt;&lt;p&gt;AMD, once the scrappy challenger, has seen its shares more than double in value in 2025 as it successfully carved out its own piece of the AI pie.&lt;/p&gt;&lt;p&gt;Qualcomm’s late arrival to the AI data centre chips party means fighting an uphill battle against competitors who have battle-tested products, mature software stacks, and customers already running production workloads at scale.&lt;/p&gt;&lt;p&gt;The company’s smartphone focus, once its greatest strength, now looks like strategic tunnel vision that caused it to miss the initial AI infrastructure boom. Yet market analysts aren’t writing Qualcomm’s obituary. Timothy Arcuri of UBS captured the prevailing sentiment on a conference call: “The tide is rising so fast, and it will continue to rise so fast, it will lift all boats.” Translation: the AI market is expanding so rapidly that there’s room for multiple winners – even latecomers with compelling technology and competitive pricing.&lt;/p&gt;&lt;p&gt;Qualcomm is playing the long game, betting that sustained innovation in AI data centre chips can gradually win over customers looking for alternatives to the Nvidia-AMD duopoly. For enterprises evaluating AI infrastructure options, Qualcomm’s emphasis on inference optimisation, energy efficiency, and TCO presents an alternative worth watching – particularly as the AI200 approaches its 2026 launch date.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Qualcomm)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Migrating AI from Nvidia to Huawei: Opportunities and trade-offs&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110157" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/qualcomm-ai-data-centre-chips-ai200-ai250/</guid><pubDate>Mon, 03 Nov 2025 09:00:00 +0000</pubDate></item><item><title>NVIDIA and South Korea align on sovereign AI at APEC CEO Summit (AI News)</title><link>https://www.artificialintelligence-news.com/news/nvidia-and-south-korea-align-on-sovereign-ai-at-apec-summit/</link><description>&lt;p&gt;At the APEC CEO Summit, NVIDIA said it is working with public agencies and private companies to build sovereign AI infrastructure across South Korea. The plan includes hundreds of thousands of NVIDIA GPUs across sovereign clouds and AI factories for areas like automotive, manufacturing and telecommunications.&lt;/p&gt;&lt;p&gt;“Korea’s leadership in technology and manufacturing positions it at the heart of the AI industrial revolution — where accelerated computing infrastructure becomes as vital as power grids and broadband,” said Jensen Huang, founder and CEO of NVIDIA. “Just as Korea’s physical factories have inspired the world with sophisticated ships, cars, chips and electronics, the nation can now produce intelligence as a new export that will drive global transformation.”&lt;/p&gt;&lt;p&gt;“Now that AI has gone beyond mere innovation and become the foundation of future industries, South Korea stands at the threshold of transformation,” said Bae Kyung-hoon, Korea Deputy Prime Minister, and Minister of Science and Information and Communication Technologies.&lt;/p&gt;&lt;p&gt;The government plans to deploy up to 50,000 new NVIDIA GPUs to support sovereign AI programs for businesses and research groups. The first phase includes 13,000 NVIDIA Blackwell and other GPUs through providers such as NAVER Cloud, NHN Cloud and Kakao. The expansion includes efforts to build a National AI Computing Center. Startups, researchers and other organisations will be able to use this sovereign infrastructure to train models and build new applications.&lt;/p&gt;&lt;p&gt;NVIDIA is also working with Samsung, SK Telecom, ETRI, KT, LGU+ and Yonsei University on AI-RAN and 6G network research. The work focuses on shifting some computing tasks from devices to network base stations, which may reduce battery drain and lower computing costs across sovereign AI services.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-major-companies-build-sovereign-ai-factories"&gt;Major companies build sovereign AI factories&lt;/h3&gt;&lt;p&gt;Large corporations in Korea are investing in advanced AI infrastructure for chip production, network operations and digital manufacturing tools that support the country’s sovereign computing goals.&lt;/p&gt;&lt;p&gt;NVIDIA and Samsung plan to build a new AI factory that connects chip manufacturing with accelerated computing. The system will run more than 50,000 NVIDIA GPUs and support data-driven production methods, including predictive maintenance and process improvements across chip fabs.&lt;/p&gt;&lt;p&gt;“We are at the dawn of the AI industrial revolution — a new era that will redefine how the world designs, builds and manufactures,” said Jensen Huang. Jay Y. Lee, executive chairman of Samsung Electronics, added, “From Samsung’s DRAM for NVIDIA’s game-changing graphics card in 1995 to our new AI factory, we are thrilled to continue our longstanding journey with NVIDIA in leading this transformation.”&lt;/p&gt;&lt;p&gt;Samsung plans to use NVIDIA CUDA-X libraries, along with software from Synopsys, Cadence and Siemens, to speed circuit design and manufacturing workflows. It will also use NVIDIA Omniverse to create digital twins of factories and equipment for real-time simulation, testing and logistics planning — all supporting wider sovereign AI adoption.&lt;/p&gt;&lt;p&gt;NVIDIA’s cuLitho library is being integrated into Samsung’s computational lithography tools. The collaboration has led to major gains in performance, supporting faster scaling in chip production.&lt;/p&gt;&lt;p&gt;Samsung is also developing large language models that run across hundreds of millions of Samsung devices, supporting translation and other reasoning tasks. The company plans to expand into robotics using NVIDIA Isaac Sim, NVIDIA Cosmos and the Jetson Thor edge platform, which may strengthen its position in sovereign AI systems.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-sk-group-expands-ai-capacity"&gt;SK Group expands AI capacity&lt;/h3&gt;&lt;p&gt;SK Group is building an AI factory that will include more than 50,000 NVIDIA GPUs, with completion expected by late 2027. The facility will support SK subsidiaries and outside clients through GPU-as-a-service offerings that align with South Korea’s sovereign AI strategy. NVIDIA and SK are also working together on next-generation high-bandwidth memory for GPUs.&lt;/p&gt;&lt;p&gt;“SK Group is working with NVIDIA to make AI the engine of a profound transformation that will enable industries across Korea to transcend traditional limits of scale, speed and precision,” said Chey Tae-Won, chairman of SK Group.&lt;/p&gt;&lt;p&gt;SK Telecom plans to build an industrial AI cloud using NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs. The platform will support semiconductor manufacturing, digital twins and internal AI agents.&lt;/p&gt;&lt;p&gt;SK hynix is using NVIDIA PhysicsNeMo tools to support chip design simulations, aiming to improve accuracy and speed. It is also testing NVIDIA Blackwell GPUs with Synopsys software and building autonomous fab digital twins.&lt;/p&gt;&lt;p&gt;To support workers, SKT is developing a foundation model called A.X., built with NVIDIA NIM microservices and NVIDIA AI Enterprise. The model will power internal agents to assist thousands of employees across chip development and operations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-hyundai-motor-group-plans-new-ai-factory"&gt;Hyundai Motor Group plans new AI factory&lt;/h3&gt;&lt;p&gt;NVIDIA and Hyundai Motor Group are expanding their partnership to support autonomous driving, factory automation and robotics. Hyundai plans to build an AI factory using NVIDIA Blackwell GPUs for integrated training, simulation and deployment.&lt;/p&gt;&lt;p&gt;“AI is revolutionising every facet of every industry, and in transportation alone — from vehicle design and manufacturing to robotics and autonomous driving — NVIDIA’s AI and computing platforms are transforming how the world moves,” said Jensen Huang.&lt;/p&gt;&lt;p&gt;The companies expect joint investment of about $3 billion to grow national physical AI capabilities. The plan includes an NVIDIA AI Technology Center, Hyundai’s Physical AI Application Center and new data centres. These programs aim to help train a new generation of AI talent.&lt;/p&gt;&lt;p&gt;Hyundai will use NVIDIA Omniverse Enterprise to build digital twins of factories, supporting virtual testing, robot integration and predictive maintenance. It will also use NVIDIA DRIVE AGX Thor for in-vehicle AI systems, including driver assistance and infotainment features.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-growth-of-sovereign-ai-models"&gt;Growth of sovereign AI models&lt;/h3&gt;&lt;p&gt;NAVER Cloud plans to deploy more than 60,000 GPUs for sovereign and physical AI work. The company will build industry-targeted models for areas such as shipbuilding and public safety.&lt;/p&gt;&lt;p&gt;The Ministry of Science and ICT is also leading a Sovereign AI Foundation Models project using NVIDIA NeMo and open Nemotron datasets. Partners include LG AI Research, NC AI, SK Telecom and Upstage. These models will support language and reasoning tasks.&lt;/p&gt;&lt;p&gt;LG is working with NVIDIA on physical AI research and will support startups and researchers using its EXAONE models, including healthcare applications.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-quantum-and-scientific-research"&gt;Quantum and scientific research&lt;/h3&gt;&lt;p&gt;KISTI plans to use NVIDIA accelerated computing in its sixth national supercomputer, HANGANG. The institute will support NVQLink, an open architecture for connecting quantum processors with GPU clusters. It will also develop scientific foundation models and explore physics-informed AI tools using NVIDIA PhysicsNeMo.&lt;/p&gt;&lt;p&gt;NVIDIA and local partners are forming a startup alliance through the NVIDIA Inception program. Members will gain access to accelerated computing resources from cloud partners like SK Telecom, along with support from venture firms. NVIDIA also plans to take part in the N-Up AI startup incubation program from the Ministry of SMEs and Startups.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Nvidia)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Migrating AI from Nvidia to Huawei: Opportunities and trade-offs&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110157" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;At the APEC CEO Summit, NVIDIA said it is working with public agencies and private companies to build sovereign AI infrastructure across South Korea. The plan includes hundreds of thousands of NVIDIA GPUs across sovereign clouds and AI factories for areas like automotive, manufacturing and telecommunications.&lt;/p&gt;&lt;p&gt;“Korea’s leadership in technology and manufacturing positions it at the heart of the AI industrial revolution — where accelerated computing infrastructure becomes as vital as power grids and broadband,” said Jensen Huang, founder and CEO of NVIDIA. “Just as Korea’s physical factories have inspired the world with sophisticated ships, cars, chips and electronics, the nation can now produce intelligence as a new export that will drive global transformation.”&lt;/p&gt;&lt;p&gt;“Now that AI has gone beyond mere innovation and become the foundation of future industries, South Korea stands at the threshold of transformation,” said Bae Kyung-hoon, Korea Deputy Prime Minister, and Minister of Science and Information and Communication Technologies.&lt;/p&gt;&lt;p&gt;The government plans to deploy up to 50,000 new NVIDIA GPUs to support sovereign AI programs for businesses and research groups. The first phase includes 13,000 NVIDIA Blackwell and other GPUs through providers such as NAVER Cloud, NHN Cloud and Kakao. The expansion includes efforts to build a National AI Computing Center. Startups, researchers and other organisations will be able to use this sovereign infrastructure to train models and build new applications.&lt;/p&gt;&lt;p&gt;NVIDIA is also working with Samsung, SK Telecom, ETRI, KT, LGU+ and Yonsei University on AI-RAN and 6G network research. The work focuses on shifting some computing tasks from devices to network base stations, which may reduce battery drain and lower computing costs across sovereign AI services.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-major-companies-build-sovereign-ai-factories"&gt;Major companies build sovereign AI factories&lt;/h3&gt;&lt;p&gt;Large corporations in Korea are investing in advanced AI infrastructure for chip production, network operations and digital manufacturing tools that support the country’s sovereign computing goals.&lt;/p&gt;&lt;p&gt;NVIDIA and Samsung plan to build a new AI factory that connects chip manufacturing with accelerated computing. The system will run more than 50,000 NVIDIA GPUs and support data-driven production methods, including predictive maintenance and process improvements across chip fabs.&lt;/p&gt;&lt;p&gt;“We are at the dawn of the AI industrial revolution — a new era that will redefine how the world designs, builds and manufactures,” said Jensen Huang. Jay Y. Lee, executive chairman of Samsung Electronics, added, “From Samsung’s DRAM for NVIDIA’s game-changing graphics card in 1995 to our new AI factory, we are thrilled to continue our longstanding journey with NVIDIA in leading this transformation.”&lt;/p&gt;&lt;p&gt;Samsung plans to use NVIDIA CUDA-X libraries, along with software from Synopsys, Cadence and Siemens, to speed circuit design and manufacturing workflows. It will also use NVIDIA Omniverse to create digital twins of factories and equipment for real-time simulation, testing and logistics planning — all supporting wider sovereign AI adoption.&lt;/p&gt;&lt;p&gt;NVIDIA’s cuLitho library is being integrated into Samsung’s computational lithography tools. The collaboration has led to major gains in performance, supporting faster scaling in chip production.&lt;/p&gt;&lt;p&gt;Samsung is also developing large language models that run across hundreds of millions of Samsung devices, supporting translation and other reasoning tasks. The company plans to expand into robotics using NVIDIA Isaac Sim, NVIDIA Cosmos and the Jetson Thor edge platform, which may strengthen its position in sovereign AI systems.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-sk-group-expands-ai-capacity"&gt;SK Group expands AI capacity&lt;/h3&gt;&lt;p&gt;SK Group is building an AI factory that will include more than 50,000 NVIDIA GPUs, with completion expected by late 2027. The facility will support SK subsidiaries and outside clients through GPU-as-a-service offerings that align with South Korea’s sovereign AI strategy. NVIDIA and SK are also working together on next-generation high-bandwidth memory for GPUs.&lt;/p&gt;&lt;p&gt;“SK Group is working with NVIDIA to make AI the engine of a profound transformation that will enable industries across Korea to transcend traditional limits of scale, speed and precision,” said Chey Tae-Won, chairman of SK Group.&lt;/p&gt;&lt;p&gt;SK Telecom plans to build an industrial AI cloud using NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs. The platform will support semiconductor manufacturing, digital twins and internal AI agents.&lt;/p&gt;&lt;p&gt;SK hynix is using NVIDIA PhysicsNeMo tools to support chip design simulations, aiming to improve accuracy and speed. It is also testing NVIDIA Blackwell GPUs with Synopsys software and building autonomous fab digital twins.&lt;/p&gt;&lt;p&gt;To support workers, SKT is developing a foundation model called A.X., built with NVIDIA NIM microservices and NVIDIA AI Enterprise. The model will power internal agents to assist thousands of employees across chip development and operations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-hyundai-motor-group-plans-new-ai-factory"&gt;Hyundai Motor Group plans new AI factory&lt;/h3&gt;&lt;p&gt;NVIDIA and Hyundai Motor Group are expanding their partnership to support autonomous driving, factory automation and robotics. Hyundai plans to build an AI factory using NVIDIA Blackwell GPUs for integrated training, simulation and deployment.&lt;/p&gt;&lt;p&gt;“AI is revolutionising every facet of every industry, and in transportation alone — from vehicle design and manufacturing to robotics and autonomous driving — NVIDIA’s AI and computing platforms are transforming how the world moves,” said Jensen Huang.&lt;/p&gt;&lt;p&gt;The companies expect joint investment of about $3 billion to grow national physical AI capabilities. The plan includes an NVIDIA AI Technology Center, Hyundai’s Physical AI Application Center and new data centres. These programs aim to help train a new generation of AI talent.&lt;/p&gt;&lt;p&gt;Hyundai will use NVIDIA Omniverse Enterprise to build digital twins of factories, supporting virtual testing, robot integration and predictive maintenance. It will also use NVIDIA DRIVE AGX Thor for in-vehicle AI systems, including driver assistance and infotainment features.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-growth-of-sovereign-ai-models"&gt;Growth of sovereign AI models&lt;/h3&gt;&lt;p&gt;NAVER Cloud plans to deploy more than 60,000 GPUs for sovereign and physical AI work. The company will build industry-targeted models for areas such as shipbuilding and public safety.&lt;/p&gt;&lt;p&gt;The Ministry of Science and ICT is also leading a Sovereign AI Foundation Models project using NVIDIA NeMo and open Nemotron datasets. Partners include LG AI Research, NC AI, SK Telecom and Upstage. These models will support language and reasoning tasks.&lt;/p&gt;&lt;p&gt;LG is working with NVIDIA on physical AI research and will support startups and researchers using its EXAONE models, including healthcare applications.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-quantum-and-scientific-research"&gt;Quantum and scientific research&lt;/h3&gt;&lt;p&gt;KISTI plans to use NVIDIA accelerated computing in its sixth national supercomputer, HANGANG. The institute will support NVQLink, an open architecture for connecting quantum processors with GPU clusters. It will also develop scientific foundation models and explore physics-informed AI tools using NVIDIA PhysicsNeMo.&lt;/p&gt;&lt;p&gt;NVIDIA and local partners are forming a startup alliance through the NVIDIA Inception program. Members will gain access to accelerated computing resources from cloud partners like SK Telecom, along with support from venture firms. NVIDIA also plans to take part in the N-Up AI startup incubation program from the Ministry of SMEs and Startups.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Nvidia)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Migrating AI from Nvidia to Huawei: Opportunities and trade-offs&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110157" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/image.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/nvidia-and-south-korea-align-on-sovereign-ai-at-apec-summit/</guid><pubDate>Mon, 03 Nov 2025 10:00:00 +0000</pubDate></item><item><title>DevOps for AI: Continuous deployment pipelines for machine learning systems (AI News)</title><link>https://www.artificialintelligence-news.com/news/devops-for-ai-continuous-deployment-pipelines-for-machine-learning-systems/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Picture1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;AI’s effects on continuous development and deployment pipelines are becoming difficult to ignore. However, decision-makers in software development functions need to consider a broad range of elements when considering the uses of the technology.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-challenges-of-deploying-ai-at-scale"&gt;The challenges of deploying AI at scale&lt;/h3&gt;&lt;p&gt;Deploying artificial intelligence isn’t the same as deploying, for example, a web app. Traditional software updates are usually deterministic: once code passes tests, everything works as it’s meant to. With AI and machine learning, outputs can vary because models depend on ever-changing data and complex statistical behaviour.&lt;/p&gt;&lt;p&gt;Some unique challenges you’ll face include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Data drift: Your training data may not match real-world use, causing performance to decline.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Model versioning: Unlike simple code updates, you need to track both the model and the data it was trained on.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Long training times: Iterating on a new model can take hours or even days, slowing down releases.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Hardware needs: Training and inference often require GPUs or specialised infrastructure.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Monitoring complexity: Tracking performance in production means watching not just uptime but also accuracy, bias, and fairness.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The challenges mean you can’t treat AI like traditional software. You need machine learning pipelines built with automation and monitoring.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-applying-devops-principles-to-ai-systems"&gt;Applying DevOps principles to AI systems&lt;/h3&gt;&lt;p&gt;DevOps was designed to bring developers and operations closer by promoting automation, collaboration, and fast feedback loops. When you bring these principles to AI, so AI and DevOps, you create a foundation for scalable machine learning deployment pipelines.&lt;/p&gt;&lt;p&gt;Some DevOps best practices translate directly:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Automation: Automating training, testing, and deployment reduces manual errors and saves time.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Continuous integration: Code, data, and model updates should all be integrated and tested regularly.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Monitoring and observability: Just like server uptime, models need monitoring for drift and accuracy.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Collaboration: Data scientists, engineers, and operations teams need to work together in the same cycle.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The main difference between DevOps and MLOps lies in the focus. While DevOps centres on code, MLOps is about managing models and datasets alongside code. MLOps extends DevOps to address challenges specific to machine learning pipelines, like data validation, experiment tracking, and retraining strategies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-designing-a-continuous-deployment-pipeline-for-machine-learning"&gt;Designing a continuous deployment pipeline for machine learning&lt;/h3&gt;&lt;p&gt;When building a continuous deployment system for ML, you need to think beyond just code. Gone are the days of just needing to know how to programme and code; now it’s about much more. Having an artificial intelligence development company that can implement these stages for you is crucial. A step-by-step framework could look like this:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Data ingestion and validation: Collect data from multiple sources, validate it for quality, and ensure privacy compliance. For example, a healthcare company might verify that patient data is anonymised before use.&lt;/li&gt;&lt;li&gt;Model training and versioning: Train models in controlled environments and store them with a clear version history. Fintech companies often keep a strict record of which datasets and algorithms power models that impact credit scoring.&lt;/li&gt;&lt;li&gt;Automated testing: Validate accuracy, bias, and performance before models move forward. This prevents unreliable models from reaching production.&lt;/li&gt;&lt;li&gt;Deployment to staging: Push models to a staging environment first to test integration with real services.&lt;/li&gt;&lt;li&gt;Production deployment: Deploy with automation, often using containers and orchestration systems like Kubernetes.&lt;/li&gt;&lt;li&gt;Monitoring and feedback loops: Track performance in production, watch for drift, and trigger retraining when thresholds are met.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;By designing an ML pipeline this way, you minimise risks, comply with regulations, and ensure reliable performance in high-stakes industries like healthcare and finance.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-role-of-a-dedicated-development-team-in-mlops"&gt;The Role of a dedicated development team in MLOps&lt;/h3&gt;&lt;p&gt;You may wonder whether you need a dedicated software development team for MLOps or if hiring consultants is enough. The reality is that one-off consultants often provide short-term fixes, but machine learning pipelines require ongoing attention. Models degrade over time, new data becomes available, and deployment environments evolve.&lt;/p&gt;&lt;p&gt;A dedicated team provides long-term ownership, cross-functional expertise, faster iteration, and risk management. Having a dedicated software development team that knows what it’s doing, how it’s doing it, and can keep doing it for you in the long run is ideal and works a lot better than having one-off consultants.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-best-practices-for-successful-devops-in-ai"&gt;Best practices for successful DevOps in AI&lt;/h3&gt;&lt;p&gt;Even with the right tools and teams, success in DevOps for AI depends on following solid best practices.&lt;/p&gt;&lt;p&gt;These include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Version everything: Code, data, and models should all have clear version control.&lt;/li&gt;&lt;li&gt;Test for more than accuracy: Include checks for fairness, bias, and explainability.&lt;/li&gt;&lt;li&gt;Use containers for consistency: Containerising ML pipelines ensures models run the same in every environment.&lt;/li&gt;&lt;li&gt;Automate retraining triggers: Set thresholds for data drift or performance declines that trigger retraining jobs automatically.&lt;/li&gt;&lt;li&gt;Integrate monitoring into pipelines: Collect metrics on latency, accuracy, and use in real time.&lt;/li&gt;&lt;li&gt;Collaborate in roles: Encourage shared responsibility between data scientists, engineers, and operations teams.&lt;/li&gt;&lt;li&gt;Plan for scalability: Build pipelines that can handle growing datasets and user demand without major rework.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These practices transform a machine learning pipeline from experimental systems into production-ready infrastructure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-conclusion"&gt;Conclusion&lt;/h3&gt;&lt;p&gt;The future of artificial intelligence depends on a reliable and scalable machine learning deployment pipeline. As a business, it’s paramount to implement AI in highly-specific ways to create digital services and products.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/Picture1.jpg" /&gt;&lt;/div&gt;&lt;p&gt;AI’s effects on continuous development and deployment pipelines are becoming difficult to ignore. However, decision-makers in software development functions need to consider a broad range of elements when considering the uses of the technology.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-challenges-of-deploying-ai-at-scale"&gt;The challenges of deploying AI at scale&lt;/h3&gt;&lt;p&gt;Deploying artificial intelligence isn’t the same as deploying, for example, a web app. Traditional software updates are usually deterministic: once code passes tests, everything works as it’s meant to. With AI and machine learning, outputs can vary because models depend on ever-changing data and complex statistical behaviour.&lt;/p&gt;&lt;p&gt;Some unique challenges you’ll face include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Data drift: Your training data may not match real-world use, causing performance to decline.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Model versioning: Unlike simple code updates, you need to track both the model and the data it was trained on.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Long training times: Iterating on a new model can take hours or even days, slowing down releases.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Hardware needs: Training and inference often require GPUs or specialised infrastructure.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Monitoring complexity: Tracking performance in production means watching not just uptime but also accuracy, bias, and fairness.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The challenges mean you can’t treat AI like traditional software. You need machine learning pipelines built with automation and monitoring.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-applying-devops-principles-to-ai-systems"&gt;Applying DevOps principles to AI systems&lt;/h3&gt;&lt;p&gt;DevOps was designed to bring developers and operations closer by promoting automation, collaboration, and fast feedback loops. When you bring these principles to AI, so AI and DevOps, you create a foundation for scalable machine learning deployment pipelines.&lt;/p&gt;&lt;p&gt;Some DevOps best practices translate directly:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Automation: Automating training, testing, and deployment reduces manual errors and saves time.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Continuous integration: Code, data, and model updates should all be integrated and tested regularly.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Monitoring and observability: Just like server uptime, models need monitoring for drift and accuracy.&lt;br /&gt;&lt;/li&gt;&lt;li&gt;Collaboration: Data scientists, engineers, and operations teams need to work together in the same cycle.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The main difference between DevOps and MLOps lies in the focus. While DevOps centres on code, MLOps is about managing models and datasets alongside code. MLOps extends DevOps to address challenges specific to machine learning pipelines, like data validation, experiment tracking, and retraining strategies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-designing-a-continuous-deployment-pipeline-for-machine-learning"&gt;Designing a continuous deployment pipeline for machine learning&lt;/h3&gt;&lt;p&gt;When building a continuous deployment system for ML, you need to think beyond just code. Gone are the days of just needing to know how to programme and code; now it’s about much more. Having an artificial intelligence development company that can implement these stages for you is crucial. A step-by-step framework could look like this:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Data ingestion and validation: Collect data from multiple sources, validate it for quality, and ensure privacy compliance. For example, a healthcare company might verify that patient data is anonymised before use.&lt;/li&gt;&lt;li&gt;Model training and versioning: Train models in controlled environments and store them with a clear version history. Fintech companies often keep a strict record of which datasets and algorithms power models that impact credit scoring.&lt;/li&gt;&lt;li&gt;Automated testing: Validate accuracy, bias, and performance before models move forward. This prevents unreliable models from reaching production.&lt;/li&gt;&lt;li&gt;Deployment to staging: Push models to a staging environment first to test integration with real services.&lt;/li&gt;&lt;li&gt;Production deployment: Deploy with automation, often using containers and orchestration systems like Kubernetes.&lt;/li&gt;&lt;li&gt;Monitoring and feedback loops: Track performance in production, watch for drift, and trigger retraining when thresholds are met.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;By designing an ML pipeline this way, you minimise risks, comply with regulations, and ensure reliable performance in high-stakes industries like healthcare and finance.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-role-of-a-dedicated-development-team-in-mlops"&gt;The Role of a dedicated development team in MLOps&lt;/h3&gt;&lt;p&gt;You may wonder whether you need a dedicated software development team for MLOps or if hiring consultants is enough. The reality is that one-off consultants often provide short-term fixes, but machine learning pipelines require ongoing attention. Models degrade over time, new data becomes available, and deployment environments evolve.&lt;/p&gt;&lt;p&gt;A dedicated team provides long-term ownership, cross-functional expertise, faster iteration, and risk management. Having a dedicated software development team that knows what it’s doing, how it’s doing it, and can keep doing it for you in the long run is ideal and works a lot better than having one-off consultants.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-best-practices-for-successful-devops-in-ai"&gt;Best practices for successful DevOps in AI&lt;/h3&gt;&lt;p&gt;Even with the right tools and teams, success in DevOps for AI depends on following solid best practices.&lt;/p&gt;&lt;p&gt;These include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Version everything: Code, data, and models should all have clear version control.&lt;/li&gt;&lt;li&gt;Test for more than accuracy: Include checks for fairness, bias, and explainability.&lt;/li&gt;&lt;li&gt;Use containers for consistency: Containerising ML pipelines ensures models run the same in every environment.&lt;/li&gt;&lt;li&gt;Automate retraining triggers: Set thresholds for data drift or performance declines that trigger retraining jobs automatically.&lt;/li&gt;&lt;li&gt;Integrate monitoring into pipelines: Collect metrics on latency, accuracy, and use in real time.&lt;/li&gt;&lt;li&gt;Collaborate in roles: Encourage shared responsibility between data scientists, engineers, and operations teams.&lt;/li&gt;&lt;li&gt;Plan for scalability: Build pipelines that can handle growing datasets and user demand without major rework.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;These practices transform a machine learning pipeline from experimental systems into production-ready infrastructure.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-conclusion"&gt;Conclusion&lt;/h3&gt;&lt;p&gt;The future of artificial intelligence depends on a reliable and scalable machine learning deployment pipeline. As a business, it’s paramount to implement AI in highly-specific ways to create digital services and products.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/devops-for-ai-continuous-deployment-pipelines-for-machine-learning-systems/</guid><pubDate>Mon, 03 Nov 2025 10:31:40 +0000</pubDate></item><item><title>This startup wants to clean up the copper industry (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/03/1127474/copper-smelting-chemistry-clean/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Demand for copper is surging, as is pollution from its dirty production processes. The founders of one startup, Still Bright, think they have a better, cleaner way to generate the copper the world needs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company uses water-based reactions, based on battery chemistry technology, to purify copper in a process that could be less polluting than traditional smelting. The hope is that this alternative will also help ease growing strain on the copper supply chain.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;“We’re really focused on addressing the copper supply crisis that’s looming ahead of us,” says Randy Allen, Still Bright’s cofounder and CEO.&lt;/p&gt;  &lt;p&gt;Copper is a crucial ingredient in everything from electrical wiring to cookware today. And clean energy technologies like solar panels and electric vehicles are introducing even more demand for the metal. Global copper demand is expected to grow by 40% between now and 2040.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;As demand swells, so do the climate and environmental impacts of copper extraction, the process of refining ore into a pure metal. There’s also growing concern about the geographic concentration of the copper supply chain. Copper is mined all over the world, and historically, many of those mines had smelters on-site to process what they extracted. (Smelters form pure copper metal by essentially burning concentrated copper ore at high temperatures.) But today, the smelting industry has consolidated, with many mines shipping copper concentrates to smelters in Asia, particularly China.&lt;/p&gt;  &lt;p&gt;That’s partly because smelting uses a lot of energy and chemicals, and it can produce sulfur-containing emissions that can harm air quality. “They shipped the environmental and social problems elsewhere,” says Simon Jowitt, a professor at the University of Nevada, Reno, and director of the Nevada Bureau of Mines and Geology.&lt;/p&gt; 
 &lt;p&gt;It’s possible to scrub pollution out of a smelter’s emissions, and smelters are much cleaner than they used to be, Jowitt says. But overall, smelting centers aren’t exactly known for environmental responsibility.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So even countries like the US, which have plenty of copper reserves and operational mines, largely ship copper concentrates, which contain up to around 30% copper, to China or other countries for smelting. (There are just two operational ore smelters in the US today.)&lt;/p&gt;  &lt;p&gt;Still Bright avoids the pyrometallurgic process that smelters use in favor of a chemical approach, partially inspired by devices called vanadium flow batteries.&lt;/p&gt;  &lt;p&gt;In the startup’s reactor, vanadium reacts with the copper compounds in copper concentrates. The copper metal remains a solid, leaving many of the impurities behind in the liquid phase. The whole thing takes between 30 and 90 minutes. The solid, which contains roughly 70% copper after this reaction, can then be fed into another, established process in the mining industry, called solvent extraction and electrowinning, to make copper that’s over 99% pure.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;This is far from the first attempt to use a water-based, chemical approach to processing copper. Today, some copper ore is processed with acid, for example, and Ceibo, a startup based in Chile, is trying to use a version of that process on the type of copper that’s traditionally smelted. The difference here is the particular chemistry, particularly the choice to use vanadium.&lt;/p&gt;  &lt;p&gt;One of Still Bright’s founders, Jon Vardner, was researching copper reactions and vanadium flow batteries when he came up with the idea to marry a copper extraction reaction with an electrical charging step that could recycle the vanadium.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="worker in the lab" class="wp-image-1127471" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Copy-of-HAX_MeasuringConcentrate_Max.jpg?w=734" /&gt;&lt;div class="image-credit"&gt;COURTESY OF STILL BRIGHT&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;After the vanadium reacts with the copper, the liquid soup can be fed into an electrolyzer, which uses electricity to turn the vanadium back into a form that can react with copper again. It’s basically the same process that vanadium flow batteries use to charge up.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While other chemical processes for copper refining require high temperatures or extremely acidic conditions to get the copper into solution and force the reaction to proceed quickly and ensure all the copper gets reacted, Still Bright’s process can run at ambient temperatures.&lt;/p&gt; 

 &lt;p&gt;One of the major benefits to this approach is cutting the pollution from copper refining.&amp;nbsp; Traditional smelting heats the target material to over 1,200 °C (2,000 °F), forming sulfur-containing gases that are released into the atmosphere.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still Bright’s process produces hydrogen sulfide gas as a by-product instead. It’s still a dangerous material, but one that can be effectively captured and converted into useful side products, Allen says.&lt;/p&gt;  &lt;p&gt;Another source of potential pollution is the sulfide minerals left over after the refining process, which can form sulfuric acid when exposed to air and water (this is called acid mine drainage, common in mining waste). Still Bright’s process will also produce that material, and the company plans to carefully track it, ensuring that it doesn’t leak into groundwater.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company is currently testing its process in the lab in New Jersey and designing a pilot facility in Colorado, which will have the capacity to make about two tons of copper per year. Next will be a demonstration-scale reactor, which will have a 500-ton annual capacity and should come online in 2027 or 2028 at a mine site, Allen says. Still Bright recently raised an $18.7 million seed round to help with the scale-up process.&lt;/p&gt;  &lt;p&gt;How scale up goes will be a crucial test of the technology and whether the typically conservative mining industry will jump on board, UNR’s Jowitt says: “You want to see what happens on an industrial scale. And I think until that happens, people might be a little reluctant to get into this.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Demand for copper is surging, as is pollution from its dirty production processes. The founders of one startup, Still Bright, think they have a better, cleaner way to generate the copper the world needs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company uses water-based reactions, based on battery chemistry technology, to purify copper in a process that could be less polluting than traditional smelting. The hope is that this alternative will also help ease growing strain on the copper supply chain.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;“We’re really focused on addressing the copper supply crisis that’s looming ahead of us,” says Randy Allen, Still Bright’s cofounder and CEO.&lt;/p&gt;  &lt;p&gt;Copper is a crucial ingredient in everything from electrical wiring to cookware today. And clean energy technologies like solar panels and electric vehicles are introducing even more demand for the metal. Global copper demand is expected to grow by 40% between now and 2040.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;As demand swells, so do the climate and environmental impacts of copper extraction, the process of refining ore into a pure metal. There’s also growing concern about the geographic concentration of the copper supply chain. Copper is mined all over the world, and historically, many of those mines had smelters on-site to process what they extracted. (Smelters form pure copper metal by essentially burning concentrated copper ore at high temperatures.) But today, the smelting industry has consolidated, with many mines shipping copper concentrates to smelters in Asia, particularly China.&lt;/p&gt;  &lt;p&gt;That’s partly because smelting uses a lot of energy and chemicals, and it can produce sulfur-containing emissions that can harm air quality. “They shipped the environmental and social problems elsewhere,” says Simon Jowitt, a professor at the University of Nevada, Reno, and director of the Nevada Bureau of Mines and Geology.&lt;/p&gt; 
 &lt;p&gt;It’s possible to scrub pollution out of a smelter’s emissions, and smelters are much cleaner than they used to be, Jowitt says. But overall, smelting centers aren’t exactly known for environmental responsibility.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;So even countries like the US, which have plenty of copper reserves and operational mines, largely ship copper concentrates, which contain up to around 30% copper, to China or other countries for smelting. (There are just two operational ore smelters in the US today.)&lt;/p&gt;  &lt;p&gt;Still Bright avoids the pyrometallurgic process that smelters use in favor of a chemical approach, partially inspired by devices called vanadium flow batteries.&lt;/p&gt;  &lt;p&gt;In the startup’s reactor, vanadium reacts with the copper compounds in copper concentrates. The copper metal remains a solid, leaving many of the impurities behind in the liquid phase. The whole thing takes between 30 and 90 minutes. The solid, which contains roughly 70% copper after this reaction, can then be fed into another, established process in the mining industry, called solvent extraction and electrowinning, to make copper that’s over 99% pure.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt;&lt;p&gt;This is far from the first attempt to use a water-based, chemical approach to processing copper. Today, some copper ore is processed with acid, for example, and Ceibo, a startup based in Chile, is trying to use a version of that process on the type of copper that’s traditionally smelted. The difference here is the particular chemistry, particularly the choice to use vanadium.&lt;/p&gt;  &lt;p&gt;One of Still Bright’s founders, Jon Vardner, was researching copper reactions and vanadium flow batteries when he came up with the idea to marry a copper extraction reaction with an electrical charging step that could recycle the vanadium.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="worker in the lab" class="wp-image-1127471" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Copy-of-HAX_MeasuringConcentrate_Max.jpg?w=734" /&gt;&lt;div class="image-credit"&gt;COURTESY OF STILL BRIGHT&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;After the vanadium reacts with the copper, the liquid soup can be fed into an electrolyzer, which uses electricity to turn the vanadium back into a form that can react with copper again. It’s basically the same process that vanadium flow batteries use to charge up.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While other chemical processes for copper refining require high temperatures or extremely acidic conditions to get the copper into solution and force the reaction to proceed quickly and ensure all the copper gets reacted, Still Bright’s process can run at ambient temperatures.&lt;/p&gt; 

 &lt;p&gt;One of the major benefits to this approach is cutting the pollution from copper refining.&amp;nbsp; Traditional smelting heats the target material to over 1,200 °C (2,000 °F), forming sulfur-containing gases that are released into the atmosphere.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Still Bright’s process produces hydrogen sulfide gas as a by-product instead. It’s still a dangerous material, but one that can be effectively captured and converted into useful side products, Allen says.&lt;/p&gt;  &lt;p&gt;Another source of potential pollution is the sulfide minerals left over after the refining process, which can form sulfuric acid when exposed to air and water (this is called acid mine drainage, common in mining waste). Still Bright’s process will also produce that material, and the company plans to carefully track it, ensuring that it doesn’t leak into groundwater.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company is currently testing its process in the lab in New Jersey and designing a pilot facility in Colorado, which will have the capacity to make about two tons of copper per year. Next will be a demonstration-scale reactor, which will have a 500-ton annual capacity and should come online in 2027 or 2028 at a mine site, Allen says. Still Bright recently raised an $18.7 million seed round to help with the scale-up process.&lt;/p&gt;  &lt;p&gt;How scale up goes will be a crucial test of the technology and whether the typically conservative mining industry will jump on board, UNR’s Jowitt says: “You want to see what happens on an industrial scale. And I think until that happens, people might be a little reluctant to get into this.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/03/1127474/copper-smelting-chemistry-clean/</guid><pubDate>Mon, 03 Nov 2025 11:00:00 +0000</pubDate></item><item><title>From ambition to accountability: Quantifying AI ROI in strategy (AI News)</title><link>https://www.artificialintelligence-news.com/news/quantifying-ai-roi-leading-resolutions/</link><description>&lt;p&gt;For many UK executives, AI investment has become a necessity, not an experiment in innovation. Boards now demand evidence of measurable impact – whether through efficiency gains, revenue growth, or reduced operational risk. Yet, as Pete Smyth, CEO of Leading Resolutions notes, many SMEs treat AI as an exploratory exercise, not a structured business strategy. The result is wasted investment and a lack of demonstrable return.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-business-impact"&gt;Business impact&lt;/h3&gt;&lt;p&gt;Enterprises implementing AI effectively are doing so with a focus on business outcomes. Instead of isolated pilots, they align initiatives with strategic goals – optimising operations and enhancing customer experience, for example. Leaders of organisations of any size can transform AI from a speculative technology into performance improvement by translating their ambitions into quantifiable metrics.&lt;/p&gt;&lt;p&gt;Smyth gives examples that include automating routine analysis to reduce manual workflows, applying predictive analytics for inventory optimisation, or using natural language models to streamline customer service. The impact is measurable, he says: improved margins, faster decisions, and business resilience.&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110164" height="306" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/pete-smyth.webp" width="360" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Pete Smyth, Leading Resolutions&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-implementation-amp-challenges"&gt;Implementation &amp;amp; challenges&lt;/h3&gt;&lt;p&gt;According to Smyth’s Leading Resolutions, implementation success depends on priorities. The process begins with stakeholder engagement that identifies potential uses for AI in different departments. Each idea is evaluated for business value and readiness to implement; these processes produce a shortlist for potential pilot schemes.&lt;/p&gt;&lt;p&gt;Next comes structured value assessment, combining cost-benefit analysis with execution feasibility and risk tolerance. Leaders should agree on the metrics that would define success before any pilot begins. These might include tracking KPIs (cost reduction, customer retention, productivity gains, etc.). Once validated, AI’s use can be scaled carefully in discrete business units.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-strategic-takeaway"&gt;Strategic takeaway&lt;/h3&gt;&lt;p&gt;For data leaders and business decision-makers, measurable ROI requires a practically-based shift from experimentation to operational accountability. Focus should be on three principles, Smyth posits:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Tie AI projects directly to business outcomes with pre-agreed KPIs.&lt;/li&gt;&lt;li&gt;Embed governance, risk controls, and explainability early.&lt;/li&gt;&lt;li&gt;Build an AI culture grounded in data quality, collaboration, and evidence-based decision-making.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;As enterprises navigate tighter regulation and rising AI expectations, success depends not on how much they invest, but how effectively they quantify and scale positive results. Moving from speculative ambition to measurable performance is the hallmark of credible AI implementation.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Main image source: “M4 AT Night” by Paulio Geordio is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;For many UK executives, AI investment has become a necessity, not an experiment in innovation. Boards now demand evidence of measurable impact – whether through efficiency gains, revenue growth, or reduced operational risk. Yet, as Pete Smyth, CEO of Leading Resolutions notes, many SMEs treat AI as an exploratory exercise, not a structured business strategy. The result is wasted investment and a lack of demonstrable return.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-business-impact"&gt;Business impact&lt;/h3&gt;&lt;p&gt;Enterprises implementing AI effectively are doing so with a focus on business outcomes. Instead of isolated pilots, they align initiatives with strategic goals – optimising operations and enhancing customer experience, for example. Leaders of organisations of any size can transform AI from a speculative technology into performance improvement by translating their ambitions into quantifiable metrics.&lt;/p&gt;&lt;p&gt;Smyth gives examples that include automating routine analysis to reduce manual workflows, applying predictive analytics for inventory optimisation, or using natural language models to streamline customer service. The impact is measurable, he says: improved margins, faster decisions, and business resilience.&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-110164" height="306" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/11/pete-smyth.webp" width="360" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;Pete Smyth, Leading Resolutions&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-implementation-amp-challenges"&gt;Implementation &amp;amp; challenges&lt;/h3&gt;&lt;p&gt;According to Smyth’s Leading Resolutions, implementation success depends on priorities. The process begins with stakeholder engagement that identifies potential uses for AI in different departments. Each idea is evaluated for business value and readiness to implement; these processes produce a shortlist for potential pilot schemes.&lt;/p&gt;&lt;p&gt;Next comes structured value assessment, combining cost-benefit analysis with execution feasibility and risk tolerance. Leaders should agree on the metrics that would define success before any pilot begins. These might include tracking KPIs (cost reduction, customer retention, productivity gains, etc.). Once validated, AI’s use can be scaled carefully in discrete business units.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-strategic-takeaway"&gt;Strategic takeaway&lt;/h3&gt;&lt;p&gt;For data leaders and business decision-makers, measurable ROI requires a practically-based shift from experimentation to operational accountability. Focus should be on three principles, Smyth posits:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Tie AI projects directly to business outcomes with pre-agreed KPIs.&lt;/li&gt;&lt;li&gt;Embed governance, risk controls, and explainability early.&lt;/li&gt;&lt;li&gt;Build an AI culture grounded in data quality, collaboration, and evidence-based decision-making.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;As enterprises navigate tighter regulation and rising AI expectations, success depends not on how much they invest, but how effectively they quantify and scale positive results. Moving from speculative ambition to measurable performance is the hallmark of credible AI implementation.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Main image source: “M4 AT Night” by Paulio Geordio is licensed under CC BY 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/quantifying-ai-roi-leading-resolutions/</guid><pubDate>Mon, 03 Nov 2025 11:45:00 +0000</pubDate></item><item><title>[NEW] The Download: gene-edited babies, and cleaning up copper (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/03/1127483/the-download-gene-edited-babies-and-cleaning-up-copper/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Here’s the latest company planning for gene-edited babies&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;A West Coast biotech entrepreneur says he’s secured $30 million to form a public-benefit company to study how to safely create genetically edited babies, marking the largest known investment into the taboo technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How they’re doing it: &lt;/strong&gt;The new company, called Preventive, is being formed to research so-called “heritable genome editing,” in which the DNA of embryos would be modified by correcting harmful mutations or installing beneficial genes. The goal would be to prevent disease.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Why it’s contentious: &lt;/strong&gt;Creating genetically edited humans remains controversial. The first scientist to do it, in China, was imprisoned for three years. The procedure remains illegal in many countries, including the US, and doubts surround its usefulness as a form of medicine. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Antonio Regalado&lt;br /&gt;&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This startup wants to clean up the copper industry&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Demand for copper is surging, as is pollution from its dirty production processes. The founders of one startup, Still Bright, think they have a better, cleaner way to generate the copper the world needs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company uses water-based reactions, based on battery chemistry technology, to purify copper in a process that could be less polluting than traditional smelting. And the hope is that this alternative will also help ease growing strain on the copper supply chain. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;1 The FDA’s top drug regulator has resigned&lt;/strong&gt;&lt;br /&gt;George Tidmarsh allegedly abused his position to inflict financial harm on a former associate. (STAT)&lt;br /&gt;+ &lt;em&gt;He’s only been in the post since July. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;It’s just the latest in a long line of slapdash leadership changes at the agency. &lt;/em&gt;(AP News)&lt;br /&gt;+ &lt;em&gt;Here’s what food and drug regulation might look like under the Trump administration. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;America’s nuclear weapons testing won’t involve explosions&lt;/strong&gt;&lt;br /&gt;So don’t expect to see mushroom clouds any time soon. (BBC)&lt;br /&gt;+ &lt;em&gt;The tests will involve “the other parts of a nuclear weapon,” apparently. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;The US is working to modernize its nuclear stockpile too. &lt;/em&gt;(The Hill)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Mustafa Suleyman wants researchers to stop pursuing conscious AI&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The Microsoft AI boss believes consciousness is reserved for biological beings only. (CNBC)&lt;br /&gt;+ &lt;em&gt;Here’s what the man who coined the term AGI has to say. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;“We will never build a sex robot,” says Mustafa Suleyman. &lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 Elon Musk may relinquish control of Tesla&lt;/strong&gt;&lt;br /&gt;If the company’s shareholders decide against awarding him close to $1 trillion in stock. (NYT $)&lt;br /&gt;+ &lt;em&gt;One major investor has already said it won’t be supporting the pay package. &lt;/em&gt;(Gizmodo)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The hottest job in AI right now? Forward-deployed engineers&lt;br /&gt;&lt;/strong&gt;They’re specialists who help AI companies’ customers adopt their models. (FT $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 Hackers are stealing cargo shipments from transportation firms&lt;br /&gt;&lt;/strong&gt;They’re successfully infecting networks with remote access tools. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 OpenAI’s o1 model can analyze languages like a human expert&lt;br /&gt;&lt;/strong&gt;Experts suggest linguistic analysis is a key testbed for assessing the extent to which these models can reason like we can. (Quanta Magazine)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 US obesity rates have started to drop&lt;br /&gt;&lt;/strong&gt;And weight-loss drugs are highly likely to be the reason why. (Vox)&lt;br /&gt;+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Why it’s so tricky to make a good grocery list app&lt;/strong&gt;&lt;br /&gt;Notes just won’t cut it. (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Many robots make light work&lt;/strong&gt;&lt;br /&gt;Lots of machines working in tandem can achieve what they’d struggle to do alone. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Tiny robots inspired by spiders could help deliver diagnoses. &lt;/em&gt;(IEEE Spectrum)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“You can check if there’s a backdoor.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—&lt;/em&gt;China’s leader Xi Jinping jokes about the security of two Chinese-made cellphones he gifted to South Korea’s President Lee Jae Myung, the New York Times reports.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127491" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_95dc35.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Digital twins of human organs are here. They’re set to transform medical treatment.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“Digital twins” are the same size and shape as the human organs they’re designed to mimic. They work in the same way. But they exist only virtually. Scientists can do virtual surgery on virtual hearts, figuring out the best course of action for a patient’s condition.&lt;/p&gt;&lt;p&gt;After decades of research, models like these are now entering clinical trials and starting to be used for patient care. The eventual goal is to create digital versions of our bodies—computer copies that could help researchers and doctors figure out our risk of developing various diseases and determine which treatments might work best.&lt;/p&gt;&lt;p&gt;But the budding technology will need to be developed very carefully. Read the full story to learn why.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The Empire State Building Run-Up race sounds amazing, if completely gruelling.&lt;br /&gt;+ Very cool: each year, the scientific staff of the Amundsen–Scott South Pole Station screen horror classic &lt;em&gt;The Thing&lt;/em&gt;&lt;em&gt; &lt;/em&gt;to prepare themselves for the long, isolated winter ahead.&lt;br /&gt;+ How caterpillars spin their protective little cocoons.&lt;br /&gt;+ One-pot chicken sounds like a great winter warmer of a recipe.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Here’s the latest company planning for gene-edited babies&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;&lt;strong&gt;The news: &lt;/strong&gt;A West Coast biotech entrepreneur says he’s secured $30 million to form a public-benefit company to study how to safely create genetically edited babies, marking the largest known investment into the taboo technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;How they’re doing it: &lt;/strong&gt;The new company, called Preventive, is being formed to research so-called “heritable genome editing,” in which the DNA of embryos would be modified by correcting harmful mutations or installing beneficial genes. The goal would be to prevent disease.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Why it’s contentious: &lt;/strong&gt;Creating genetically edited humans remains controversial. The first scientist to do it, in China, was imprisoned for three years. The procedure remains illegal in many countries, including the US, and doubts surround its usefulness as a form of medicine. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Antonio Regalado&lt;br /&gt;&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;This startup wants to clean up the copper industry&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Demand for copper is surging, as is pollution from its dirty production processes. The founders of one startup, Still Bright, think they have a better, cleaner way to generate the copper the world needs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The company uses water-based reactions, based on battery chemistry technology, to purify copper in a process that could be less polluting than traditional smelting. And the hope is that this alternative will also help ease growing strain on the copper supply chain. Read the full story.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;em&gt;—Casey Crownhart&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;1 The FDA’s top drug regulator has resigned&lt;/strong&gt;&lt;br /&gt;George Tidmarsh allegedly abused his position to inflict financial harm on a former associate. (STAT)&lt;br /&gt;+ &lt;em&gt;He’s only been in the post since July. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;It’s just the latest in a long line of slapdash leadership changes at the agency. &lt;/em&gt;(AP News)&lt;br /&gt;+ &lt;em&gt;Here’s what food and drug regulation might look like under the Trump administration. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2&lt;/strong&gt; &lt;strong&gt;America’s nuclear weapons testing won’t involve explosions&lt;/strong&gt;&lt;br /&gt;So don’t expect to see mushroom clouds any time soon. (BBC)&lt;br /&gt;+ &lt;em&gt;The tests will involve “the other parts of a nuclear weapon,” apparently. &lt;/em&gt;(NYT $)&lt;br /&gt;+ &lt;em&gt;The US is working to modernize its nuclear stockpile too. &lt;/em&gt;(The Hill)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Mustafa Suleyman wants researchers to stop pursuing conscious AI&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;The Microsoft AI boss believes consciousness is reserved for biological beings only. (CNBC)&lt;br /&gt;+ &lt;em&gt;Here’s what the man who coined the term AGI has to say. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;“We will never build a sex robot,” says Mustafa Suleyman. &lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 Elon Musk may relinquish control of Tesla&lt;/strong&gt;&lt;br /&gt;If the company’s shareholders decide against awarding him close to $1 trillion in stock. (NYT $)&lt;br /&gt;+ &lt;em&gt;One major investor has already said it won’t be supporting the pay package. &lt;/em&gt;(Gizmodo)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 The hottest job in AI right now? Forward-deployed engineers&lt;br /&gt;&lt;/strong&gt;They’re specialists who help AI companies’ customers adopt their models. (FT $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;6 Hackers are stealing cargo shipments from transportation firms&lt;br /&gt;&lt;/strong&gt;They’re successfully infecting networks with remote access tools. (Bloomberg $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 OpenAI’s o1 model can analyze languages like a human expert&lt;br /&gt;&lt;/strong&gt;Experts suggest linguistic analysis is a key testbed for assessing the extent to which these models can reason like we can. (Quanta Magazine)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 US obesity rates have started to drop&lt;br /&gt;&lt;/strong&gt;And weight-loss drugs are highly likely to be the reason why. (Vox)&lt;br /&gt;+ &lt;em&gt;We’re learning more about what weight-loss drugs do to the body. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 Why it’s so tricky to make a good grocery list app&lt;/strong&gt;&lt;br /&gt;Notes just won’t cut it. (The Verge)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Many robots make light work&lt;/strong&gt;&lt;br /&gt;Lots of machines working in tandem can achieve what they’d struggle to do alone. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Tiny robots inspired by spiders could help deliver diagnoses. &lt;/em&gt;(IEEE Spectrum)&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“You can check if there’s a backdoor.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—&lt;/em&gt;China’s leader Xi Jinping jokes about the security of two Chinese-made cellphones he gifted to South Korea’s President Lee Jae Myung, the New York Times reports.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127491" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/image_95dc35.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Digital twins of human organs are here. They’re set to transform medical treatment.&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“Digital twins” are the same size and shape as the human organs they’re designed to mimic. They work in the same way. But they exist only virtually. Scientists can do virtual surgery on virtual hearts, figuring out the best course of action for a patient’s condition.&lt;/p&gt;&lt;p&gt;After decades of research, models like these are now entering clinical trials and starting to be used for patient care. The eventual goal is to create digital versions of our bodies—computer copies that could help researchers and doctors figure out our risk of developing various diseases and determine which treatments might work best.&lt;/p&gt;&lt;p&gt;But the budding technology will need to be developed very carefully. Read the full story to learn why.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The Empire State Building Run-Up race sounds amazing, if completely gruelling.&lt;br /&gt;+ Very cool: each year, the scientific staff of the Amundsen–Scott South Pole Station screen horror classic &lt;em&gt;The Thing&lt;/em&gt;&lt;em&gt; &lt;/em&gt;to prepare themselves for the long, isolated winter ahead.&lt;br /&gt;+ How caterpillars spin their protective little cocoons.&lt;br /&gt;+ One-pot chicken sounds like a great winter warmer of a recipe.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/03/1127483/the-download-gene-edited-babies-and-cleaning-up-copper/</guid><pubDate>Mon, 03 Nov 2025 13:10:00 +0000</pubDate></item><item><title>[NEW] The beginning of the end of the transformer era? Neuro-symbolic AI startup AUI announces new funding at $750M valuation (AI | VentureBeat)</title><link>https://venturebeat.com/ai/the-beginning-of-the-end-of-the-transformer-era-neuro-symbolic-ai-startup</link><description>[unable to retrieve full-text content]&lt;p&gt;The buzzed-about but still stealthy New York City startup &lt;a href="https://www.aui.io/"&gt;Augmented Intelligence Inc (AUI)&lt;/a&gt;, which seeks to go beyond the popular &amp;quot;transformer&amp;quot; architecture used by most of today&amp;#x27;s LLMs such as ChatGPT and Gemini, has&lt;b&gt; raised $20 million in a bridge SAFE round at a $750 million valuation cap, bringing its total funding to nearly $60 million&lt;/b&gt;, VentureBeat can exclusively reveal.&lt;/p&gt;&lt;p&gt;The round, completed in under a week, comes amid heightened interest in deterministic conversational AI and precedes a larger raise now in advanced stages.&lt;/p&gt;&lt;p&gt;AUI relies on a fusion of the transformer tech and a newer technology called &amp;quot;neuro-symbolic AI,&amp;quot; described in greater detail below. &lt;/p&gt;&lt;p&gt;&amp;quot;We realize that you can combine the brilliance of LLMs in linguistic capabilities with the guarantees of symbolic AI,&amp;quot; said &lt;b&gt;Ohad Elhelo&lt;/b&gt;, &lt;b&gt;AUI co-founder and CEO&lt;/b&gt; in a recent interview with VentureBeat. Elhelo launched the company in 2017 alongside &lt;b&gt;co-founder and Chief Product Officer Ori Cohen.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;The new financing includes participation from eGateway Ventures, New Era Capital Partners, existing shareholders, and other strategic investors. It follows a $10 million raise in September 2024 at a $350 million valuation cap, coinciding with the &lt;a href="https://cloud.google.com/blog/topics/partners/google-cloud-partners-with-aui/"&gt;company’s announced go-to-market partnership with Google&lt;/a&gt; in October 2024. Early investors include Vertex Pharmaceuticals founder Joshua Boger, UKG Chairman Aron Ain, and former IBM President Jim Whitehurst.&lt;/p&gt;&lt;p&gt;According to the company, the bridge round is a precursor to a significantly larger raise already in advanced stages.&lt;/p&gt;&lt;p&gt;AUI is the &lt;a href="https://venturebeat.com/ai/has-this-stealth-startup-finally-cracked-the-code-on-enterprise-ai-agent"&gt;company behind Apollo-1&lt;/a&gt;, a new foundation model built for task-oriented dialog, which it describes as the &amp;quot;economic half&amp;quot; of conversational AI — distinct from the open-ended dialog handled by LLMs like ChatGPT and Gemini. &lt;/p&gt;&lt;p&gt;The firm argues that existing LLMs lack the determinism, policy enforcement, and operational certainty required by enterprises, especially in regulated sectors.&lt;/p&gt;&lt;p&gt;Chris Varelas, co-founder of Redwood Capital and an advisor to AUI, said in a press release provided to VentureBeat: “I’ve seen some of today’s top AI leaders walk away with their heads spinning after interacting with Apollo-1.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Distinctive Neuro-Symbolic Architecture&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Apollo-1’s core innovation is its neuro-symbolic architecture, which separates linguistic fluency from task reasoning. Instead of using the most common technology underpinning most LLMs and conversational AI systems today — the vaunted transformer architecture described in the seminal 2017 Google paper &amp;quot;Attention Is All You Need&amp;quot; — AUI&amp;#x27;s system integrates two layers:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Neural modules, powered by LLMs, handle perception: encoding user inputs and generating natural language responses.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A symbolic reasoning engine, developed over several years, interprets structured task elements such as intents, entities, and parameters. This symbolic state engine determines the appropriate next actions using deterministic logic.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This hybrid architecture allows Apollo-1 to maintain state continuity, enforce organizational policies, and reliably trigger tool or API calls — capabilities that transformer-only agents lack.&lt;/p&gt;&lt;p&gt;Elhelo said this design emerged from a multi-year data collection effort: “We built a consumer service and recorded millions of human-agent interactions across 60,000 live agents. From that, we abstracted a symbolic language that defines the structure of task-based dialogs, separate from their domain-specific content.”&lt;/p&gt;&lt;p&gt;However, enterprises that have already built systems built around transformer LLMs needn&amp;#x27;t worry. AUI wants to make adopting its new technology just as easy. &lt;/p&gt;&lt;p&gt;&amp;quot;Apollo-1 deploys like any modern foundation model,&amp;quot; Elhelo told VentureBeat in a text last night. &amp;quot;It doesn’t require dedicated or proprietary clusters to run. It operates across standard cloud and hybrid environments, leveraging both GPUs and CPUs, and is significantly more cost-efficient to deploy than frontier reasoning models. Apollo-1 can also be deployed across all major clouds in a separated environment for increased security.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Generalization and Domain Flexibility&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Apollo-1 is described as a foundation model for task-oriented dialog, meaning it is domain-agnostic and generalizable across verticals like healthcare, travel, insurance, and retail.&lt;/p&gt;&lt;p&gt;Unlike consulting-heavy AI platforms that require building bespoke logic per client, Apollo-1 allows enterprises to define behaviors and tools within a shared symbolic language. This approach supports faster onboarding and reduces long-term maintenance. According to the team, an enterprise can launch a working agent in under a day.&lt;/p&gt;&lt;p&gt;Crucially, procedural rules are encoded at the symbolic layer — not learned from examples. This enables deterministic execution for sensitive or regulated tasks. &lt;/p&gt;&lt;p&gt;For instance, a system can block cancellation of a Basic Economy flight not by guessing intent but by applying hard-coded logic to a symbolic representation of the booking class.&lt;/p&gt;&lt;p&gt;As Elhelo explained to VentureBeat, LLMs are &amp;quot;not a good mechanism when you’re looking for certainty. It’s better if you know what you’re going to send [to an AI model] and always send it, and you know, always, what’s going to come back [to the user] and how to handle that.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Availability and Developer Access&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Apollo-1 is already in active use within Fortune 500 enterprises in a closed beta, and a broader general availability release is expected before the end of 2025, according to a &lt;a href="https://www.theinformation.com/articles/startup-teaching-ai-agents-shop"&gt;previous report by &lt;i&gt;The Information&lt;/i&gt;&lt;/a&gt;&lt;i&gt;, &lt;/i&gt;which broke the initial news on the startup.&lt;/p&gt;&lt;p&gt;Enterprises can integrate with Apollo-1 either via:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A developer playground, where business users and technical teams jointly configure policies, rules, and behaviors; or&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A standard API, using OpenAI-compatible formats.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The model supports policy enforcement, rule-based customization, and steering via guardrails. Symbolic rules allow businesses to dictate fixed behaviors, while LLM modules handle open-text interpretation and user interaction.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise Fit: When Reliability Beats Fluency&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While LLMs have advanced general-purpose dialog and creativity, they remain probabilistic — a barrier to enterprise deployment in finance, healthcare, and customer service. &lt;/p&gt;&lt;p&gt;Apollo-1 targets this gap by offering a system where policy adherence and deterministic task completion are first-class design goals.&lt;/p&gt;&lt;p&gt;Elhelo puts it plainly: “If your use case is task-oriented dialog, you have to use us, even if you are ChatGPT.”&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;The buzzed-about but still stealthy New York City startup &lt;a href="https://www.aui.io/"&gt;Augmented Intelligence Inc (AUI)&lt;/a&gt;, which seeks to go beyond the popular &amp;quot;transformer&amp;quot; architecture used by most of today&amp;#x27;s LLMs such as ChatGPT and Gemini, has&lt;b&gt; raised $20 million in a bridge SAFE round at a $750 million valuation cap, bringing its total funding to nearly $60 million&lt;/b&gt;, VentureBeat can exclusively reveal.&lt;/p&gt;&lt;p&gt;The round, completed in under a week, comes amid heightened interest in deterministic conversational AI and precedes a larger raise now in advanced stages.&lt;/p&gt;&lt;p&gt;AUI relies on a fusion of the transformer tech and a newer technology called &amp;quot;neuro-symbolic AI,&amp;quot; described in greater detail below. &lt;/p&gt;&lt;p&gt;&amp;quot;We realize that you can combine the brilliance of LLMs in linguistic capabilities with the guarantees of symbolic AI,&amp;quot; said &lt;b&gt;Ohad Elhelo&lt;/b&gt;, &lt;b&gt;AUI co-founder and CEO&lt;/b&gt; in a recent interview with VentureBeat. Elhelo launched the company in 2017 alongside &lt;b&gt;co-founder and Chief Product Officer Ori Cohen.&lt;/b&gt;&lt;/p&gt;&lt;p&gt;The new financing includes participation from eGateway Ventures, New Era Capital Partners, existing shareholders, and other strategic investors. It follows a $10 million raise in September 2024 at a $350 million valuation cap, coinciding with the &lt;a href="https://cloud.google.com/blog/topics/partners/google-cloud-partners-with-aui/"&gt;company’s announced go-to-market partnership with Google&lt;/a&gt; in October 2024. Early investors include Vertex Pharmaceuticals founder Joshua Boger, UKG Chairman Aron Ain, and former IBM President Jim Whitehurst.&lt;/p&gt;&lt;p&gt;According to the company, the bridge round is a precursor to a significantly larger raise already in advanced stages.&lt;/p&gt;&lt;p&gt;AUI is the &lt;a href="https://venturebeat.com/ai/has-this-stealth-startup-finally-cracked-the-code-on-enterprise-ai-agent"&gt;company behind Apollo-1&lt;/a&gt;, a new foundation model built for task-oriented dialog, which it describes as the &amp;quot;economic half&amp;quot; of conversational AI — distinct from the open-ended dialog handled by LLMs like ChatGPT and Gemini. &lt;/p&gt;&lt;p&gt;The firm argues that existing LLMs lack the determinism, policy enforcement, and operational certainty required by enterprises, especially in regulated sectors.&lt;/p&gt;&lt;p&gt;Chris Varelas, co-founder of Redwood Capital and an advisor to AUI, said in a press release provided to VentureBeat: “I’ve seen some of today’s top AI leaders walk away with their heads spinning after interacting with Apollo-1.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Distinctive Neuro-Symbolic Architecture&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Apollo-1’s core innovation is its neuro-symbolic architecture, which separates linguistic fluency from task reasoning. Instead of using the most common technology underpinning most LLMs and conversational AI systems today — the vaunted transformer architecture described in the seminal 2017 Google paper &amp;quot;Attention Is All You Need&amp;quot; — AUI&amp;#x27;s system integrates two layers:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;Neural modules, powered by LLMs, handle perception: encoding user inputs and generating natural language responses.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A symbolic reasoning engine, developed over several years, interprets structured task elements such as intents, entities, and parameters. This symbolic state engine determines the appropriate next actions using deterministic logic.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;This hybrid architecture allows Apollo-1 to maintain state continuity, enforce organizational policies, and reliably trigger tool or API calls — capabilities that transformer-only agents lack.&lt;/p&gt;&lt;p&gt;Elhelo said this design emerged from a multi-year data collection effort: “We built a consumer service and recorded millions of human-agent interactions across 60,000 live agents. From that, we abstracted a symbolic language that defines the structure of task-based dialogs, separate from their domain-specific content.”&lt;/p&gt;&lt;p&gt;However, enterprises that have already built systems built around transformer LLMs needn&amp;#x27;t worry. AUI wants to make adopting its new technology just as easy. &lt;/p&gt;&lt;p&gt;&amp;quot;Apollo-1 deploys like any modern foundation model,&amp;quot; Elhelo told VentureBeat in a text last night. &amp;quot;It doesn’t require dedicated or proprietary clusters to run. It operates across standard cloud and hybrid environments, leveraging both GPUs and CPUs, and is significantly more cost-efficient to deploy than frontier reasoning models. Apollo-1 can also be deployed across all major clouds in a separated environment for increased security.&amp;quot;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Generalization and Domain Flexibility&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Apollo-1 is described as a foundation model for task-oriented dialog, meaning it is domain-agnostic and generalizable across verticals like healthcare, travel, insurance, and retail.&lt;/p&gt;&lt;p&gt;Unlike consulting-heavy AI platforms that require building bespoke logic per client, Apollo-1 allows enterprises to define behaviors and tools within a shared symbolic language. This approach supports faster onboarding and reduces long-term maintenance. According to the team, an enterprise can launch a working agent in under a day.&lt;/p&gt;&lt;p&gt;Crucially, procedural rules are encoded at the symbolic layer — not learned from examples. This enables deterministic execution for sensitive or regulated tasks. &lt;/p&gt;&lt;p&gt;For instance, a system can block cancellation of a Basic Economy flight not by guessing intent but by applying hard-coded logic to a symbolic representation of the booking class.&lt;/p&gt;&lt;p&gt;As Elhelo explained to VentureBeat, LLMs are &amp;quot;not a good mechanism when you’re looking for certainty. It’s better if you know what you’re going to send [to an AI model] and always send it, and you know, always, what’s going to come back [to the user] and how to handle that.”&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Availability and Developer Access&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Apollo-1 is already in active use within Fortune 500 enterprises in a closed beta, and a broader general availability release is expected before the end of 2025, according to a &lt;a href="https://www.theinformation.com/articles/startup-teaching-ai-agents-shop"&gt;previous report by &lt;i&gt;The Information&lt;/i&gt;&lt;/a&gt;&lt;i&gt;, &lt;/i&gt;which broke the initial news on the startup.&lt;/p&gt;&lt;p&gt;Enterprises can integrate with Apollo-1 either via:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A developer playground, where business users and technical teams jointly configure policies, rules, and behaviors; or&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A standard API, using OpenAI-compatible formats.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The model supports policy enforcement, rule-based customization, and steering via guardrails. Symbolic rules allow businesses to dictate fixed behaviors, while LLM modules handle open-text interpretation and user interaction.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Enterprise Fit: When Reliability Beats Fluency&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;While LLMs have advanced general-purpose dialog and creativity, they remain probabilistic — a barrier to enterprise deployment in finance, healthcare, and customer service. &lt;/p&gt;&lt;p&gt;Apollo-1 targets this gap by offering a system where policy adherence and deterministic task completion are first-class design goals.&lt;/p&gt;&lt;p&gt;Elhelo puts it plainly: “If your use case is task-oriented dialog, you have to use us, even if you are ChatGPT.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/the-beginning-of-the-end-of-the-transformer-era-neuro-symbolic-ai-startup</guid><pubDate>Mon, 03 Nov 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] LG founder’s grandson, production firm partner up to bring AI to filmmaking (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/03/lg-scions-stock-farm-road-utopai-launch-ai-driven-filmmaking/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Since AI tools went mainstream, filmmakers, writers, and actors have been scrambling to figure out whether these technologies can truly assist their creativity or if they might end up replacing humans. But there’s a larger concern to address before we get swept away by debate: AI can’t run without enormous data centers and energy infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A new joint venture, dubbed Utopai East, aims to address that need by developing infrastructure specifically for producing movies and TV shows using AI. The joint venture is held 50-50 by investment firm Stock Farm Road (SFR) and AI film and television production company Utopai Studios. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SFR, co-founded by Brian Koo (the grandson of LG Group’s founder Koo In-hwoi) and Amin Badr-El-Din, the founder and chief executive of BADR Investments, is contributing capital to the joint venture, along with creative expertise and industry contacts. Utopai, meanwhile, is providing the technology, workflow and infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The project will also involve co-producing film and television projects, and expanding access to Korean intellectual property for international audiences. Production will begin using existing infrastructure, and the company expects the first piece of content from this collaboration to be released next year, according to Cecilia Shen, co-founder and CEO of Utopai Studios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the short term, using AI is going to be primarily about lowering costs and increasing efficiency, Koo told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But beyond that, we’re very excited about the new possibilities AI opens up. As we engage with creators, we’re exploring what entirely new things can become possible. Right now, some of our early focus is on creators in Korea,” Koo said. “Just as short-form content was a novelty when it first emerged, we see opportunities for fresh approaches. We’re working not only with established directors in cinema but also with young, innovative creators who aren’t limited to traditional movies.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3063430" height="387" src="https://techcrunch.com/wp-content/uploads/2025/11/Cecilia-Shen-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Cecilia Shen, co-founder and CEO of Utopai Studios&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But novelty alone won’t allay the concerns of the people working in the entertainment industry, or the ones consuming the content. AI could one day replace people in creative roles like acting, performance, and writing, yet it often lacks the depth, nuance and emotional resonance of human storytelling. This has sparked a broader debate about the value of human creativity in an era when machines can mimic, but not fully replicate, the human touch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But Shen and Koo maintain that their use of AI is only aimed at improving existing processes. “These questions have been at the center of everything we build at Utopai Studios,” Shen said. “From the beginning, our focus was never on automation. Our workflow is designed to work alongside filmmakers, not in place of them. We still need writers to write, directors to direct, and actors to perform,” Shen said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Every model and every dataset used is fully licensed and contractually approved, ensuring the technology respects the creators whose work makes filmmaking possible, Shen added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want creators to understand that AI can expand their creative potential rather than compete with them. It can help bring their dreams to life, giving them the freedom to fully explore their creativity without worrying that AI will replace them. This, we believe, is going to be one of the most exciting outcomes for us,” Koo said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Typically, content and IP grow incrementally — one IP develops after another — but with the right technology, especially AI, there’s potential for exponential growth. This isn’t about AI replacing people; it’s about the massive value it can create for audiences, creators, and engineers alike,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal follows SFR’s recent agreement with the Jeollanam-do Province government to build a 3-gigawatt AI data center in South Korea.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The data center is part of our larger mission at Stock Farm Road to build the backbone for the next generation of intelligence-driven industries. Beyond Utopai Studios and entertainment, we are also focused on areas such as manufacturing, energy-to-information, AI, and quantum computing. These are all interconnected fields that require the same kind of infrastructure,” said Koo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The data center will serve as the foundation for everything Utopai East is developing, and will include complete AI infrastructure for entertainment content, spanning data management, creative intelligence, production and distribution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the joint venture’s financial details were not disclosed, the capital is coming from multiple channels, including SFR’s investment vehicles, global sovereign and institutional investors, and industry partners in film and entertainment, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The JV will start off making Korean content, but aims to expand to other parts of Asia eventually. “Japan is always also a great market,” making it a natural starting point for expansion, Shen noted, adding that she also sees significant potential in China and Thailand.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Since AI tools went mainstream, filmmakers, writers, and actors have been scrambling to figure out whether these technologies can truly assist their creativity or if they might end up replacing humans. But there’s a larger concern to address before we get swept away by debate: AI can’t run without enormous data centers and energy infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A new joint venture, dubbed Utopai East, aims to address that need by developing infrastructure specifically for producing movies and TV shows using AI. The joint venture is held 50-50 by investment firm Stock Farm Road (SFR) and AI film and television production company Utopai Studios. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SFR, co-founded by Brian Koo (the grandson of LG Group’s founder Koo In-hwoi) and Amin Badr-El-Din, the founder and chief executive of BADR Investments, is contributing capital to the joint venture, along with creative expertise and industry contacts. Utopai, meanwhile, is providing the technology, workflow and infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The project will also involve co-producing film and television projects, and expanding access to Korean intellectual property for international audiences. Production will begin using existing infrastructure, and the company expects the first piece of content from this collaboration to be released next year, according to Cecilia Shen, co-founder and CEO of Utopai Studios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the short term, using AI is going to be primarily about lowering costs and increasing efficiency, Koo told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But beyond that, we’re very excited about the new possibilities AI opens up. As we engage with creators, we’re exploring what entirely new things can become possible. Right now, some of our early focus is on creators in Korea,” Koo said. “Just as short-form content was a novelty when it first emerged, we see opportunities for fresh approaches. We’re working not only with established directors in cinema but also with young, innovative creators who aren’t limited to traditional movies.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3063430" height="387" src="https://techcrunch.com/wp-content/uploads/2025/11/Cecilia-Shen-1.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Cecilia Shen, co-founder and CEO of Utopai Studios&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;But novelty alone won’t allay the concerns of the people working in the entertainment industry, or the ones consuming the content. AI could one day replace people in creative roles like acting, performance, and writing, yet it often lacks the depth, nuance and emotional resonance of human storytelling. This has sparked a broader debate about the value of human creativity in an era when machines can mimic, but not fully replicate, the human touch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;But Shen and Koo maintain that their use of AI is only aimed at improving existing processes. “These questions have been at the center of everything we build at Utopai Studios,” Shen said. “From the beginning, our focus was never on automation. Our workflow is designed to work alongside filmmakers, not in place of them. We still need writers to write, directors to direct, and actors to perform,” Shen said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Every model and every dataset used is fully licensed and contractually approved, ensuring the technology respects the creators whose work makes filmmaking possible, Shen added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We want creators to understand that AI can expand their creative potential rather than compete with them. It can help bring their dreams to life, giving them the freedom to fully explore their creativity without worrying that AI will replace them. This, we believe, is going to be one of the most exciting outcomes for us,” Koo said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Typically, content and IP grow incrementally — one IP develops after another — but with the right technology, especially AI, there’s potential for exponential growth. This isn’t about AI replacing people; it’s about the massive value it can create for audiences, creators, and engineers alike,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal follows SFR’s recent agreement with the Jeollanam-do Province government to build a 3-gigawatt AI data center in South Korea.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The data center is part of our larger mission at Stock Farm Road to build the backbone for the next generation of intelligence-driven industries. Beyond Utopai Studios and entertainment, we are also focused on areas such as manufacturing, energy-to-information, AI, and quantum computing. These are all interconnected fields that require the same kind of infrastructure,” said Koo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The data center will serve as the foundation for everything Utopai East is developing, and will include complete AI infrastructure for entertainment content, spanning data management, creative intelligence, production and distribution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the joint venture’s financial details were not disclosed, the capital is coming from multiple channels, including SFR’s investment vehicles, global sovereign and institutional investors, and industry partners in film and entertainment, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The JV will start off making Korean content, but aims to expand to other parts of Asia eventually. “Japan is always also a great market,” making it a natural starting point for expansion, Shen noted, adding that she also sees significant potential in China and Thailand.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/03/lg-scions-stock-farm-road-utopai-launch-ai-driven-filmmaking/</guid><pubDate>Mon, 03 Nov 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Microsoft inks $9.7B deal with Australia’s IREN for AI cloud capacity (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/03/microsoft-inks-9-7bil-deal-with-australias-iren-for-ai-cloud-capacity/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-1883327378-e1730136121848.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft is leaving no stone unturned in its quest to secure more compute capacity for meeting its customers’ heavy demand for AI services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, the Redmond-based tech giant signed a $9.7 billion, five-year contract with Australia’s IREN to secure further AI cloud capacity. The deal will give Microsoft access to compute infrastructure built with Nvidia’s GB300 GPUs, which will be deployed over phases through 2026 at IREN’s facility in Childress, Texas, planned to support 750 megawatts of capacity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;IREN said it is separately buying GPUs and equipment from Dell for about $5.8 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal comes after Microsoft last month launched its first production cluster with Nvidia’s GB300 NVL72 systems for Azure, which, the company said, are optimized for reasoning models, agentic AI systems and multi-modal generative AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Microsoft signed a deal with Nscale for approximately 200,000 Nvidia GB300 GPUs to three data centers in Europe and one in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to competitors like CoreWeave, IREN started off as a bitcoin-mining operation, but quickly realized that its massive collection of GPUs were better put to use for AI workloads. The company has benefited massively from the shift in focus. The company’s CEO Daniel Roberts expects the Microsoft deal to take up only 10% of the company’s total capacity and generate about $1.94 billion in annualized revenue, Bloomberg reported.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-1883327378-e1730136121848.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft is leaving no stone unturned in its quest to secure more compute capacity for meeting its customers’ heavy demand for AI services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, the Redmond-based tech giant signed a $9.7 billion, five-year contract with Australia’s IREN to secure further AI cloud capacity. The deal will give Microsoft access to compute infrastructure built with Nvidia’s GB300 GPUs, which will be deployed over phases through 2026 at IREN’s facility in Childress, Texas, planned to support 750 megawatts of capacity.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;IREN said it is separately buying GPUs and equipment from Dell for about $5.8 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal comes after Microsoft last month launched its first production cluster with Nvidia’s GB300 NVL72 systems for Azure, which, the company said, are optimized for reasoning models, agentic AI systems and multi-modal generative AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Microsoft signed a deal with Nscale for approximately 200,000 Nvidia GB300 GPUs to three data centers in Europe and one in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to competitors like CoreWeave, IREN started off as a bitcoin-mining operation, but quickly realized that its massive collection of GPUs were better put to use for AI workloads. The company has benefited massively from the shift in focus. The company’s CEO Daniel Roberts expects the Microsoft deal to take up only 10% of the company’s total capacity and generate about $1.94 billion in annualized revenue, Bloomberg reported.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/03/microsoft-inks-9-7bil-deal-with-australias-iren-for-ai-cloud-capacity/</guid><pubDate>Mon, 03 Nov 2025 14:04:19 +0000</pubDate></item><item><title>[NEW] Microsoft’s $15.2B UAE investment turns Gulf State into test case for US AI diplomacy (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/03/microsofts-15-2b-uae-investment-turns-gulf-state-into-test-case-for-us-ai-diplomacy/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/microsoft-uae.jpg?w=960" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft will invest $15.2 billion in the United Arab Emirates over the next four years, the company announced Monday at the first annual Abu Dhabi Global AI Summit.&amp;nbsp;The investment will include the first-ever shipments of the most advanced Nvidia GPUs to the UAE.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, the U.S. has granted Microsoft a license to export Nvidia chips to the UAE, a move that positions the country as both a proving ground for U.S. export-control diplomacy and a regional anchor of American AI influence. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal allows Microsoft to expand its foothold into the Middle East, a key region in the global fight for AI dominance.&amp;nbsp;In May, President Donald Trump struck a deal with UAE President Sheikh Mohamed bin Zayed al-Nahyan to build an AI data center campus in Abu Dhabi. The project was delayed due to U.S. export controls, which restricted the sale of powerful Nvidia chips needed to run advanced AI systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft became the first company to receive a license from the U.S. Commerce Department to ship the chips to the UAE in September. The move comes as critics say the deal undermines the logic of the U.S.’s export restrictions to China by introducing possible back-channels through a Chinese ally.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Microsoft said it performed substantial work to meet the strong cybersecurity and national security conditions required by the licenses, which has enabled the firm to accumulate the equivalent of 21,500 Nvidia A100 GPUs in the UAE, based on a combination of A100, H100, and H200 chips. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft said it is using the chips to provide access to AI models from OpenAI, Anthropic, open-source providers, and itself.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The $15.2 billion figure includes money Microsoft began spending in the UAE starting in 2023 as part of a new AI initiative in the country. Between 2023 and the end of 2025, Microsoft will have spent just over $7.3 billion in the UAE, including a $1.5 billion equity investment in G42, the UAE’s sovereign AI company, and more than $4.6 billion in capital towards data centers.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the new deal, Microsoft pledges to spend $7.9 billion more in the UAE from the start of 2026 to the end of 2029, including $5.5 billion in capital expenses for ongoing and planned expansion of AI and cloud infrastructure. Microsoft hinted at new steps it will share publicly in Abu Dhabi this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s work in the UAE goes beyond building data centers. The company says it is pairing massive AI infrastructure with deep investment in local talent, training, and governance. The firm is pledging to train a million residents by 2027 and use Abu Dhabi as a regional hub for AI research and model development. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investment comes the same day that Microsoft signed a $9.7 billion deal with Australia’s IREN for AI cloud capacity.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/microsoft-uae.jpg?w=960" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Microsoft will invest $15.2 billion in the United Arab Emirates over the next four years, the company announced Monday at the first annual Abu Dhabi Global AI Summit.&amp;nbsp;The investment will include the first-ever shipments of the most advanced Nvidia GPUs to the UAE.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the deal, the U.S. has granted Microsoft a license to export Nvidia chips to the UAE, a move that positions the country as both a proving ground for U.S. export-control diplomacy and a regional anchor of American AI influence. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal allows Microsoft to expand its foothold into the Middle East, a key region in the global fight for AI dominance.&amp;nbsp;In May, President Donald Trump struck a deal with UAE President Sheikh Mohamed bin Zayed al-Nahyan to build an AI data center campus in Abu Dhabi. The project was delayed due to U.S. export controls, which restricted the sale of powerful Nvidia chips needed to run advanced AI systems.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft became the first company to receive a license from the U.S. Commerce Department to ship the chips to the UAE in September. The move comes as critics say the deal undermines the logic of the U.S.’s export restrictions to China by introducing possible back-channels through a Chinese ally.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a statement, Microsoft said it performed substantial work to meet the strong cybersecurity and national security conditions required by the licenses, which has enabled the firm to accumulate the equivalent of 21,500 Nvidia A100 GPUs in the UAE, based on a combination of A100, H100, and H200 chips. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft said it is using the chips to provide access to AI models from OpenAI, Anthropic, open-source providers, and itself.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The $15.2 billion figure includes money Microsoft began spending in the UAE starting in 2023 as part of a new AI initiative in the country. Between 2023 and the end of 2025, Microsoft will have spent just over $7.3 billion in the UAE, including a $1.5 billion equity investment in G42, the UAE’s sovereign AI company, and more than $4.6 billion in capital towards data centers.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the new deal, Microsoft pledges to spend $7.9 billion more in the UAE from the start of 2026 to the end of 2029, including $5.5 billion in capital expenses for ongoing and planned expansion of AI and cloud infrastructure. Microsoft hinted at new steps it will share publicly in Abu Dhabi this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s work in the UAE goes beyond building data centers. The company says it is pairing massive AI infrastructure with deep investment in local talent, training, and governance. The firm is pledging to train a million residents by 2027 and use Abu Dhabi as a regional hub for AI research and model development. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investment comes the same day that Microsoft signed a $9.7 billion deal with Australia’s IREN for AI cloud capacity.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/03/microsofts-15-2b-uae-investment-turns-gulf-state-into-test-case-for-us-ai-diplomacy/</guid><pubDate>Mon, 03 Nov 2025 14:22:48 +0000</pubDate></item><item><title>[NEW] Strengthening Our Core: Welcoming Karyne Levy as VentureBeat’s New Managing Editor (AI | VentureBeat)</title><link>https://venturebeat.com/ai/strengthening-our-core-welcoming-karyne-levy-as-venturebeats-new-managing</link><description>[unable to retrieve full-text content]&lt;p&gt;I’m thrilled to announce a fantastic new addition to our leadership team: &lt;b&gt;Karyne Levy&lt;/b&gt; is joining VentureBeat as our new Managing Editor. Today is her first day.&lt;/p&gt;&lt;p&gt;Many of you may know Karyne from her most recent role as Deputy Managing Editor at TechCrunch, but her career is a highlight reel of veteran tech journalism. Her resume includes pivotal roles at &lt;b&gt;Protocol, NerdWallet, Business Insider, and CNET&lt;/b&gt;, giving her a deep understanding of this industry from every angle.&lt;/p&gt;&lt;p&gt;Hiring Karyne is a significant step forward for VentureBeat. As we’ve sharpened our focus on serving you – the enterprise technical decision-maker navigating the complexities of AI and data – I’ve been looking for a very specific kind of leader.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The &amp;quot;Organizer&amp;#x27;s Dopamine Hit&amp;quot;&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;In the past, a managing editor was often the final backstop for copy. Today, at a modern, data-focused media company like ours, the role is infinitely more dynamic. It’s the central hub of the entire content operation.&lt;/p&gt;&lt;p&gt;During my search, I found myself talking a lot about the two types of &amp;quot;dopamine hits&amp;quot; in our business. There’s the writer’s hit – seeing your name on a great story. And then there’s the organizer’s hit – the satisfaction that comes from building, tuning, and running the complex machine that allows a dozen different parts of the company to move in a single, powerful direction.&lt;/p&gt;&lt;p&gt;We were looking for the organizer.&lt;/p&gt;&lt;p&gt;When I spoke with Karyne, I explained this vision: a leader who thrives on creating workflows, who loves being the &lt;b&gt;liaison between editorial, our data and survey team, our events, and our marketing operations&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;Her response confirmed she was the one: &amp;quot;Everything you said is exactly my dopamine hit.&amp;quot;&lt;/p&gt;&lt;p&gt;Karyne’s passion is making the entire operation hum. She has a proven track record of managing people, running newsrooms, and interfacing with all parts of a business to ensure everyone is aligned. That operational rigor is precisely what we need for our next chapter.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why This Matters for Our Strategy (and for You)&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;As I’ve written about before, VentureBeat is on a mission to evolve. In an age where experts and companies can publish directly, it’s not enough to be a secondary source. Our goal is to become a &lt;b&gt;primary source&lt;/b&gt; for you.&lt;/p&gt;&lt;p&gt;How? By leveraging our relationship with our community of millions of technical leaders. We are increasingly surveying you directly to generate proprietary insights you can’t get anywhere else. We want to be the first to tell you &lt;i&gt;which&lt;/i&gt; vector stores your peers are &lt;i&gt;actually&lt;/i&gt; implementing, &lt;i&gt;what&lt;/i&gt; governance challenges are most pressing for data scientists, or &lt;i&gt;how&lt;/i&gt; your counterparts are budgeting for generative AI.&lt;/p&gt;&lt;p&gt;This is an ambitious strategy. It requires a tight-knit team where our editorial content, our research surveys and reports, our newsletters, and our VB Transform events are all working from the same playbook.&lt;/p&gt;&lt;p&gt;Karyne is the leader who will help us execute that vision. Her experience at Protocol, which was also dedicated to serving technical and business decision-makers, means she fundamentally understands our audience. She is ideally suited to manage our newsroom and ensure that every piece of content we produce helps you do your job better. She’ll be working alongside Carl Franzen, our executive editor, who continues to drive news decision-making.&lt;/p&gt;&lt;p&gt;This is a fantastic hire for VentureBeat. It’s another sign of our commitment to building the most focused, expert team in enterprise AI and data.&lt;/p&gt;&lt;p&gt;Please join me in welcoming Karyne to the team.
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;I’m thrilled to announce a fantastic new addition to our leadership team: &lt;b&gt;Karyne Levy&lt;/b&gt; is joining VentureBeat as our new Managing Editor. Today is her first day.&lt;/p&gt;&lt;p&gt;Many of you may know Karyne from her most recent role as Deputy Managing Editor at TechCrunch, but her career is a highlight reel of veteran tech journalism. Her resume includes pivotal roles at &lt;b&gt;Protocol, NerdWallet, Business Insider, and CNET&lt;/b&gt;, giving her a deep understanding of this industry from every angle.&lt;/p&gt;&lt;p&gt;Hiring Karyne is a significant step forward for VentureBeat. As we’ve sharpened our focus on serving you – the enterprise technical decision-maker navigating the complexities of AI and data – I’ve been looking for a very specific kind of leader.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The &amp;quot;Organizer&amp;#x27;s Dopamine Hit&amp;quot;&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;In the past, a managing editor was often the final backstop for copy. Today, at a modern, data-focused media company like ours, the role is infinitely more dynamic. It’s the central hub of the entire content operation.&lt;/p&gt;&lt;p&gt;During my search, I found myself talking a lot about the two types of &amp;quot;dopamine hits&amp;quot; in our business. There’s the writer’s hit – seeing your name on a great story. And then there’s the organizer’s hit – the satisfaction that comes from building, tuning, and running the complex machine that allows a dozen different parts of the company to move in a single, powerful direction.&lt;/p&gt;&lt;p&gt;We were looking for the organizer.&lt;/p&gt;&lt;p&gt;When I spoke with Karyne, I explained this vision: a leader who thrives on creating workflows, who loves being the &lt;b&gt;liaison between editorial, our data and survey team, our events, and our marketing operations&lt;/b&gt;.&lt;/p&gt;&lt;p&gt;Her response confirmed she was the one: &amp;quot;Everything you said is exactly my dopamine hit.&amp;quot;&lt;/p&gt;&lt;p&gt;Karyne’s passion is making the entire operation hum. She has a proven track record of managing people, running newsrooms, and interfacing with all parts of a business to ensure everyone is aligned. That operational rigor is precisely what we need for our next chapter.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why This Matters for Our Strategy (and for You)&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;As I’ve written about before, VentureBeat is on a mission to evolve. In an age where experts and companies can publish directly, it’s not enough to be a secondary source. Our goal is to become a &lt;b&gt;primary source&lt;/b&gt; for you.&lt;/p&gt;&lt;p&gt;How? By leveraging our relationship with our community of millions of technical leaders. We are increasingly surveying you directly to generate proprietary insights you can’t get anywhere else. We want to be the first to tell you &lt;i&gt;which&lt;/i&gt; vector stores your peers are &lt;i&gt;actually&lt;/i&gt; implementing, &lt;i&gt;what&lt;/i&gt; governance challenges are most pressing for data scientists, or &lt;i&gt;how&lt;/i&gt; your counterparts are budgeting for generative AI.&lt;/p&gt;&lt;p&gt;This is an ambitious strategy. It requires a tight-knit team where our editorial content, our research surveys and reports, our newsletters, and our VB Transform events are all working from the same playbook.&lt;/p&gt;&lt;p&gt;Karyne is the leader who will help us execute that vision. Her experience at Protocol, which was also dedicated to serving technical and business decision-makers, means she fundamentally understands our audience. She is ideally suited to manage our newsroom and ensure that every piece of content we produce helps you do your job better. She’ll be working alongside Carl Franzen, our executive editor, who continues to drive news decision-making.&lt;/p&gt;&lt;p&gt;This is a fantastic hire for VentureBeat. It’s another sign of our commitment to building the most focused, expert team in enterprise AI and data.&lt;/p&gt;&lt;p&gt;Please join me in welcoming Karyne to the team.
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/strengthening-our-core-welcoming-karyne-levy-as-venturebeats-new-managing</guid><pubDate>Mon, 03 Nov 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI and Amazon ink $38B cloud computing deal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/03/openai-and-amazon-ink-38b-cloud-computing-deal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/amazon-data-center.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI isn’t done securing the AI infrastructure it needs to rapidly scale agentic workloads. The ChatGPT-maker on Monday said it has reached a deal with Amazon to buy $38 billion in cloud computing services over the next seven years. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said it will immediately start using AWS compute, with all capacity targeted to be deployed before the end of 2026, with the ability to expand further into 2027 and beyond. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal follows OpenAI’s restructuring last week, which freed the company from having to secure Microsoft’s approval to buy computing services from other firms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s deal with Amazon is part of its larger mission to grow computing power, spending more than $1 trillion over the next decade. The company has announced new data center buildouts with Oracle, SoftBank, the United Arab Emirates, and others. OpenAI has also secured deals with chipmakers Nvidia, AMD, and Broadcom.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To some analysts, the increased investment form OpenAI and other tech giants signals that the industry is heading towards an AI bubble, wherein massive sums are spent beefing out an unproven, and potentially dangerous, technology with no clear sign of a meaningful return on investment. &amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/amazon-data-center.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI isn’t done securing the AI infrastructure it needs to rapidly scale agentic workloads. The ChatGPT-maker on Monday said it has reached a deal with Amazon to buy $38 billion in cloud computing services over the next seven years. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said it will immediately start using AWS compute, with all capacity targeted to be deployed before the end of 2026, with the ability to expand further into 2027 and beyond. &amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal follows OpenAI’s restructuring last week, which freed the company from having to secure Microsoft’s approval to buy computing services from other firms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s deal with Amazon is part of its larger mission to grow computing power, spending more than $1 trillion over the next decade. The company has announced new data center buildouts with Oracle, SoftBank, the United Arab Emirates, and others. OpenAI has also secured deals with chipmakers Nvidia, AMD, and Broadcom.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To some analysts, the increased investment form OpenAI and other tech giants signals that the industry is heading towards an AI bubble, wherein massive sums are spent beefing out an unproven, and potentially dangerous, technology with no clear sign of a meaningful return on investment. &amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/03/openai-and-amazon-ink-38b-cloud-computing-deal/</guid><pubDate>Mon, 03 Nov 2025 15:21:51 +0000</pubDate></item><item><title>[NEW] AI browsers are a significant security threat (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-browser-security-issue-shadow-ai-malware/</link><description>&lt;p&gt;Among the explosion of AI systems, AI web browsers such as Fellou and Comet from Perplexity have begun to make appearances on the corporate desktop. Such applications are described as the next evolution of the humble browser, and come with AI features built in; they can read and summarise web pages – and, at their most advanced – act on web content autonomously.&lt;/p&gt;&lt;p&gt;In theory, at least, the promise of an AI browser is that it will speed up digital workflows, undertake online research, and retrieve information from internal sources and the wider internet.&lt;/p&gt;&lt;p&gt;However, security research teams are concluding that AI browsers introduce serious risks into the enterprise that simply can’t be ignored.&lt;/p&gt;&lt;p&gt;The problem lies in the fact that AI browsers are highly vulnerable to indirect prompt injection attacks. These are where the model in the browser (or accessed via the browser) receives instructions hidden in specially-crafted websites. By embedding text into web pages or images in ways humans find difficult to discren, AI models can be fed instructions in the form of AI prompts, or amendments to prompts that are input by the user.&lt;/p&gt;&lt;p&gt;The bottom line for IT departments and decision-makers is that AI browsers are not yet suitable for use in the enterprise, and represent a significant security threat.&lt;/p&gt;&lt;h3 id="org9b20853"&gt;Automation meets exposure&lt;/h3&gt;&lt;p&gt;In tests, researchers discovered that embedded text in online content is processed by the AI browser and is interpreted as instructions to the smart model. These instructions can be executed using the user’s privileges, so the greater the degree of access to information that the user has, the greater the risk to the organisation. The autonomy that AI gives users is the same mechanism that magnifies the attack surface, and the more autonomy, the greater the potential scope for data loss.&lt;/p&gt;&lt;p&gt;For example, it’s possible to embed text commands into an image that, when displayed in the browser, could trigger an AI assistant to interact with sensitive assets, like corporate email, or online banking dashboards. Another test showed how an AI assistant’s prompt can be hijacked and made to perform unauthorised actions on the behalf of the user.&lt;/p&gt;&lt;p&gt;These types of vulnerabilities clearly go against all principles of data governance, and are the most obvious example of how ‘shadow AI’ in the form of an unauthorised browser, poses a real threat to an organisation’s data. The AI model acts as a bridge between domains, and circumvents same-origin policies – the rule that prevents the access of data from one domain by another.&lt;/p&gt;&lt;h3 id="org5077fb8"&gt;Implementation and governance challenges&lt;/h3&gt;&lt;p&gt;The root of the problem is the merging of user queries in the browser with live data accessed on the web. If the LLM can’t distinguish between safe and malicious input, then it can blithely access data not requested by its human operator and act on it. When given agentic abilities, the consequences can be far-reaching, and could easily cause a cascade of malicious activity across the enterprise.&lt;/p&gt;&lt;p&gt;For any organisation that relies on data segmentation and access control, a compromised AI layer in a user’s browser can circumvent firewalls, enact token exchanges, and use secure cookies in exactly the same way that a user might. Effectively, the AI browser becomes an insider threat, with access to all the data and facility of its human operator. The browser user will not necessarily be aware of activity ‘under the hood,’ so an infected browser may act for significant periods of time without detection.&lt;/p&gt;&lt;h3 id="org494cf91"&gt;Threat mitigation&lt;/h3&gt;&lt;p&gt;The first generation of AI browsers should be regarded by IT teams in the same way they treat unauthorised installation of third-party software. While it is relatively easy to prevent specific software being installed by users, it’s worth noting that mainstream browsers such as Chrome and Edge are shipping with increased numbers of AI features in the form of Gemini (in Chrome) and Copilot (in Edge). The browser-producing companies are actively exploring AI-augmented browsing capabilities, and agentic features (that grant significant autonomy to the browser) will be quick to appear, driven by the need for competitive advantage between browser companies.&lt;/p&gt;&lt;p&gt;Without proper oversight and controls, organisations are opening themselves to significant risk. Future generations of browsers should be checked for the following features:&lt;/p&gt;&lt;ul class="org-ul"&gt;&lt;li&gt;Prompt isolation, separating user intent from third-party web content before LLM prompt generation.&lt;/li&gt;&lt;li&gt;Gated permissions. AI agents should not be able to execute autonomous actions, including navigation, data retrieval, or file access without explicit user confirmation.&lt;/li&gt;&lt;li&gt;Sandboxing of sensitive browsing (like HR, finance, internal dashboards, etc.) so there is no AI activity in these sensitive areas.&lt;/li&gt;&lt;li&gt;Governance integration. Browser-based AI has to align with data security policies, and the software should provide records to make agentic actions traceable.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;To date, no browser vendor has presented a smart browser with the ability to distinguish between user-driven intent, and model-interpreted commands. Without this, browsers may be coerced to act against the organisation by the use of relatively trivial prompt injection.&lt;/p&gt;&lt;h3 id="org9df418c"&gt;Decision-maker takeaway&lt;/h3&gt;&lt;p&gt;Agentic AI browsers are presented as the next logical evolution in web browsing and automation in the workplace. They are designed deliberately to blur the distinction between user/human activity and become part of interactions with the enterprise’s digital assets. Given the ease with which the LLMs in AI browsers are circumvented and corrupted, the current generation of AI browsers can be regarded as dormant malware.&lt;/p&gt;&lt;p&gt;The major browser vendors look set to embed AI (with or without agentic abilities) into future generations of their platforms, so careful monitoring of each release should be undertaken to ensure security oversight.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Unexploded bomb!” by hugh llewelyn is licensed under CC BY-SA 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Among the explosion of AI systems, AI web browsers such as Fellou and Comet from Perplexity have begun to make appearances on the corporate desktop. Such applications are described as the next evolution of the humble browser, and come with AI features built in; they can read and summarise web pages – and, at their most advanced – act on web content autonomously.&lt;/p&gt;&lt;p&gt;In theory, at least, the promise of an AI browser is that it will speed up digital workflows, undertake online research, and retrieve information from internal sources and the wider internet.&lt;/p&gt;&lt;p&gt;However, security research teams are concluding that AI browsers introduce serious risks into the enterprise that simply can’t be ignored.&lt;/p&gt;&lt;p&gt;The problem lies in the fact that AI browsers are highly vulnerable to indirect prompt injection attacks. These are where the model in the browser (or accessed via the browser) receives instructions hidden in specially-crafted websites. By embedding text into web pages or images in ways humans find difficult to discren, AI models can be fed instructions in the form of AI prompts, or amendments to prompts that are input by the user.&lt;/p&gt;&lt;p&gt;The bottom line for IT departments and decision-makers is that AI browsers are not yet suitable for use in the enterprise, and represent a significant security threat.&lt;/p&gt;&lt;h3 id="org9b20853"&gt;Automation meets exposure&lt;/h3&gt;&lt;p&gt;In tests, researchers discovered that embedded text in online content is processed by the AI browser and is interpreted as instructions to the smart model. These instructions can be executed using the user’s privileges, so the greater the degree of access to information that the user has, the greater the risk to the organisation. The autonomy that AI gives users is the same mechanism that magnifies the attack surface, and the more autonomy, the greater the potential scope for data loss.&lt;/p&gt;&lt;p&gt;For example, it’s possible to embed text commands into an image that, when displayed in the browser, could trigger an AI assistant to interact with sensitive assets, like corporate email, or online banking dashboards. Another test showed how an AI assistant’s prompt can be hijacked and made to perform unauthorised actions on the behalf of the user.&lt;/p&gt;&lt;p&gt;These types of vulnerabilities clearly go against all principles of data governance, and are the most obvious example of how ‘shadow AI’ in the form of an unauthorised browser, poses a real threat to an organisation’s data. The AI model acts as a bridge between domains, and circumvents same-origin policies – the rule that prevents the access of data from one domain by another.&lt;/p&gt;&lt;h3 id="org5077fb8"&gt;Implementation and governance challenges&lt;/h3&gt;&lt;p&gt;The root of the problem is the merging of user queries in the browser with live data accessed on the web. If the LLM can’t distinguish between safe and malicious input, then it can blithely access data not requested by its human operator and act on it. When given agentic abilities, the consequences can be far-reaching, and could easily cause a cascade of malicious activity across the enterprise.&lt;/p&gt;&lt;p&gt;For any organisation that relies on data segmentation and access control, a compromised AI layer in a user’s browser can circumvent firewalls, enact token exchanges, and use secure cookies in exactly the same way that a user might. Effectively, the AI browser becomes an insider threat, with access to all the data and facility of its human operator. The browser user will not necessarily be aware of activity ‘under the hood,’ so an infected browser may act for significant periods of time without detection.&lt;/p&gt;&lt;h3 id="org494cf91"&gt;Threat mitigation&lt;/h3&gt;&lt;p&gt;The first generation of AI browsers should be regarded by IT teams in the same way they treat unauthorised installation of third-party software. While it is relatively easy to prevent specific software being installed by users, it’s worth noting that mainstream browsers such as Chrome and Edge are shipping with increased numbers of AI features in the form of Gemini (in Chrome) and Copilot (in Edge). The browser-producing companies are actively exploring AI-augmented browsing capabilities, and agentic features (that grant significant autonomy to the browser) will be quick to appear, driven by the need for competitive advantage between browser companies.&lt;/p&gt;&lt;p&gt;Without proper oversight and controls, organisations are opening themselves to significant risk. Future generations of browsers should be checked for the following features:&lt;/p&gt;&lt;ul class="org-ul"&gt;&lt;li&gt;Prompt isolation, separating user intent from third-party web content before LLM prompt generation.&lt;/li&gt;&lt;li&gt;Gated permissions. AI agents should not be able to execute autonomous actions, including navigation, data retrieval, or file access without explicit user confirmation.&lt;/li&gt;&lt;li&gt;Sandboxing of sensitive browsing (like HR, finance, internal dashboards, etc.) so there is no AI activity in these sensitive areas.&lt;/li&gt;&lt;li&gt;Governance integration. Browser-based AI has to align with data security policies, and the software should provide records to make agentic actions traceable.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;To date, no browser vendor has presented a smart browser with the ability to distinguish between user-driven intent, and model-interpreted commands. Without this, browsers may be coerced to act against the organisation by the use of relatively trivial prompt injection.&lt;/p&gt;&lt;h3 id="org9df418c"&gt;Decision-maker takeaway&lt;/h3&gt;&lt;p&gt;Agentic AI browsers are presented as the next logical evolution in web browsing and automation in the workplace. They are designed deliberately to blur the distinction between user/human activity and become part of interactions with the enterprise’s digital assets. Given the ease with which the LLMs in AI browsers are circumvented and corrupted, the current generation of AI browsers can be regarded as dormant malware.&lt;/p&gt;&lt;p&gt;The major browser vendors look set to embed AI (with or without agentic abilities) into future generations of their platforms, so careful monitoring of each release should be undertaken to ensure security oversight.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Unexploded bomb!” by hugh llewelyn is licensed under CC BY-SA 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-browser-security-issue-shadow-ai-malware/</guid><pubDate>Mon, 03 Nov 2025 15:35:19 +0000</pubDate></item><item><title>[NEW] OpenAI spreads $600B cloud AI bet across AWS, Oracle, Microsoft (AI News)</title><link>https://www.artificialintelligence-news.com/news/openai-spreads-600b-cloud-ai-bet-aws-oracle-microsoft/</link><description>&lt;p&gt;OpenAI is on a spending spree to secure its AI compute supply chain, signing a new deal with AWS as part of its multi-cloud strategy.&lt;/p&gt;&lt;p&gt;The company recently ended its exclusive cloud-computing partnership with Microsoft. It has since allocated a reported $250 billion back to Microsoft, $300 billion to Oracle, and now, $38 billion to Amazon Web Services (AWS) in a new multi-year pact. This $38 billion AWS deal, while the smallest of the three, is part of OpenAI’s diversification plan.&lt;/p&gt;&lt;p&gt;For industry leaders, OpenAI’s actions show that access to high-performance GPUs is no longer an on-demand commodity. It is now a scarce resource requiring massive long-term capital commitment.&lt;/p&gt;&lt;p&gt;The AWS agreement provides OpenAI with access to hundreds of thousands of NVIDIA GPUs, including the new GB200s and GB300s, and the ability to tap tens of millions of CPUs.&lt;/p&gt;&lt;p&gt;This mighty infrastructure is not just for training tomorrow’s models; it’s needed to run the massive inference workloads of today’s ChatGPT. As OpenAI co-founder and CEO Sam Altman stated, “scaling frontier AI requires massive, reliable compute”.&lt;/p&gt;&lt;p&gt;This spending spree is forcing a competitive response from the hyperscalers. While AWS remains the industry’s largest cloud provider, Microsoft and Google have recently posted faster cloud-revenue growth, often by capturing new AI customers. This AWS deal is a plain attempt to secure a cornerstone AI workload and prove its large-scale AI capabilities, which it claims include running clusters of over 500,000 chips.&lt;/p&gt;&lt;p&gt;AWS is not just providing standard servers. It is building a sophisticated, purpose-built architecture for OpenAI, using EC2 UltraServers to link the GPUs for the low-latency networking that large-scale training demands.&lt;/p&gt;&lt;p&gt;“The breadth and immediate availability of optimised compute demonstrates why AWS is uniquely positioned to support OpenAI’s vast AI workloads,” said Matt Garman, CEO of AWS.&lt;/p&gt;&lt;p&gt;But “immediate” is relative. The full capacity from OpenAI’s latest cloud AI deal will not be fully deployed until the end of 2026, with options to expand further into 2027. This timeline offers a dose of realism for any executive planning an AI rollout: the hardware supply chain is complex and operates on multi-year schedules.&lt;/p&gt;&lt;p&gt;What, then, should enterprise leaders take from this?&lt;/p&gt;&lt;p&gt;First, the “build vs. buy” debate for AI infrastructure is all but over. OpenAI is spending hundreds of billions to build on top of rented hardware. Few, if any, other companies can or should follow suit. This pushes the rest of the market firmly toward managed platforms like Amazon Bedrock, Google Vertex AI, or IBM watsonx, where the hyperscalers absorb this infrastructure risk.&lt;/p&gt;&lt;p&gt;Second, the days of single-cloud sourcing for AI workloads may be numbered. OpenAI’s pivot to a multi-provider model is a textbook case of mitigating concentration risk. For a CIO, relying on one vendor for the compute that runs a core business process is becoming a gamble.&lt;/p&gt;&lt;p&gt;Finally, AI budgeting has left the realm of departmental IT and entered the world of corporate capital planning. These are no longer variable operational expenses. Securing AI compute is now a long-term financial commitment, much like building a new factory or data centre.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Qualcomm unveils AI data centre chips to crack the Inference market&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;OpenAI is on a spending spree to secure its AI compute supply chain, signing a new deal with AWS as part of its multi-cloud strategy.&lt;/p&gt;&lt;p&gt;The company recently ended its exclusive cloud-computing partnership with Microsoft. It has since allocated a reported $250 billion back to Microsoft, $300 billion to Oracle, and now, $38 billion to Amazon Web Services (AWS) in a new multi-year pact. This $38 billion AWS deal, while the smallest of the three, is part of OpenAI’s diversification plan.&lt;/p&gt;&lt;p&gt;For industry leaders, OpenAI’s actions show that access to high-performance GPUs is no longer an on-demand commodity. It is now a scarce resource requiring massive long-term capital commitment.&lt;/p&gt;&lt;p&gt;The AWS agreement provides OpenAI with access to hundreds of thousands of NVIDIA GPUs, including the new GB200s and GB300s, and the ability to tap tens of millions of CPUs.&lt;/p&gt;&lt;p&gt;This mighty infrastructure is not just for training tomorrow’s models; it’s needed to run the massive inference workloads of today’s ChatGPT. As OpenAI co-founder and CEO Sam Altman stated, “scaling frontier AI requires massive, reliable compute”.&lt;/p&gt;&lt;p&gt;This spending spree is forcing a competitive response from the hyperscalers. While AWS remains the industry’s largest cloud provider, Microsoft and Google have recently posted faster cloud-revenue growth, often by capturing new AI customers. This AWS deal is a plain attempt to secure a cornerstone AI workload and prove its large-scale AI capabilities, which it claims include running clusters of over 500,000 chips.&lt;/p&gt;&lt;p&gt;AWS is not just providing standard servers. It is building a sophisticated, purpose-built architecture for OpenAI, using EC2 UltraServers to link the GPUs for the low-latency networking that large-scale training demands.&lt;/p&gt;&lt;p&gt;“The breadth and immediate availability of optimised compute demonstrates why AWS is uniquely positioned to support OpenAI’s vast AI workloads,” said Matt Garman, CEO of AWS.&lt;/p&gt;&lt;p&gt;But “immediate” is relative. The full capacity from OpenAI’s latest cloud AI deal will not be fully deployed until the end of 2026, with options to expand further into 2027. This timeline offers a dose of realism for any executive planning an AI rollout: the hardware supply chain is complex and operates on multi-year schedules.&lt;/p&gt;&lt;p&gt;What, then, should enterprise leaders take from this?&lt;/p&gt;&lt;p&gt;First, the “build vs. buy” debate for AI infrastructure is all but over. OpenAI is spending hundreds of billions to build on top of rented hardware. Few, if any, other companies can or should follow suit. This pushes the rest of the market firmly toward managed platforms like Amazon Bedrock, Google Vertex AI, or IBM watsonx, where the hyperscalers absorb this infrastructure risk.&lt;/p&gt;&lt;p&gt;Second, the days of single-cloud sourcing for AI workloads may be numbered. OpenAI’s pivot to a multi-provider model is a textbook case of mitigating concentration risk. For a CIO, relying on one vendor for the compute that runs a core business process is becoming a gamble.&lt;/p&gt;&lt;p&gt;Finally, AI budgeting has left the realm of departmental IT and entered the world of corporate capital planning. These are no longer variable operational expenses. Securing AI compute is now a long-term financial commitment, much like building a new factory or data centre.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Qualcomm unveils AI data centre chips to crack the Inference market&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/openai-spreads-600b-cloud-ai-bet-aws-oracle-microsoft/</guid><pubDate>Mon, 03 Nov 2025 15:37:32 +0000</pubDate></item><item><title>[NEW] The State of AI: Is China about to win the race? (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/03/1126780/the-state-of-ai-is-china-about-to-win-the-race/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;The State of AI is a collaboration between the Financial Times &amp;amp; MIT Technology Review examining the ways in which AI is reshaping global power. Every Monday for the next six weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;In this conversation, the FT’s tech columnist and Innovation Editor&amp;nbsp;John Thornhill and MIT Technology Review’s Caiwei Chen consider the battle between Silicon Valley and Beijing for technological supremacy.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127512" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR_FT_small.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;John Thornhill writes:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Viewed from abroad, it seems only a matter of time before China emerges as the AI superpower of the 21st century.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Here in the West, our initial instinct is to focus on America’s significant lead in semiconductor expertise, its cutting-edge AI research, and its vast investments in data centers. The legendary investor Warren Buffett once warned: “Never bet against America.” He is right that for more than two centuries, no other “incubator for unleashing human potential” has matched the US.&lt;/p&gt;  &lt;p&gt;Today, however, China has the means, motive, and opportunity to commit the equivalent of technological murder. When it comes to mobilizing the whole-of-society resources needed to develop and deploy AI to maximum effect, it may be just as rash to bet against.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The data highlights the trends. In AI publications and patents, China leads. By 2023, China accounted for 22.6% of all citations, compared with 20.9% from Europe and 13% from the US, according to Stanford University's Artificial Intelligence Index Report 2025. As of 2023, China also accounted for 69.7% of all AI patents. True, the US maintains a strong lead in the top 100 most cited publications (50 versus 34 in 2023), but its share has been steadily declining.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similarly, the US outdoes China in top AI research talent, but the gap is narrowing. According to a report from the US Council of Economic Advisers, 59% of the world’s top AI researchers worked in the US in 2019, compared with 11% in China. But by 2022 those figures were 42% and 28%.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;The Trump administration’s tightening of restrictions for foreign H-1B visa holders may well lead more Chinese AI researchers in the US to return home. The talent ratio could move further in China’s favor.&lt;/p&gt;  &lt;p&gt;Regarding the technology itself, US-based institutions produced 40 of the world’s most notable AI models in 2024, compared with 15 from China. But Chinese researchers have learned to do more with less, and their strongest large language models—including the open-source DeepSeek-V3 and Alibaba's Qwen 2.5-Max—surpass the best US models in terms of algorithmic efficiency.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Where China is really likely to excel in future is in applying these open-source models. The latest report from Air Street Capital shows that China has now overtaken the US in terms of monthly downloads of AI models. In AI-enabled fintech, e-commerce, and logistics, China already outstrips the US.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Perhaps the most intriguing—and potentially the most productive—applications of AI may yet come in hardware, particularly in drones and industrial robotics. With the research field evolving toward embodied AI, China’s advantage in advanced manufacturing will shine through.&lt;/p&gt;  &lt;p&gt;Dan Wang, the tech analyst and author of &lt;em&gt;Breakneck&lt;/em&gt;, has rightly highlighted the strengths of China’s engineering state in developing manufacturing process knowledge—even if he has also shown the damaging effects of applying that engineering mentality in the social sphere. “China has been growing technologically stronger and economically more dynamic in all sorts of ways,” he told me. “But repression is very real. And it is getting worse in all sorts of ways as well.”&lt;/p&gt;  &lt;p&gt;I’d be fascinated to hear from you, Caiwei, about your take on the strengths and weaknesses of China’s AI dream. To what extent will China’s engineered social control hamper its technological ambitions?&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Caiwei Chen responds:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Hi, John!&lt;/p&gt;  &lt;p&gt;You’re right that the US still holds a clear lead in frontier research and infrastructure. But “winning” AI can mean many different things. Jeffrey Ding, in his book &lt;em&gt;Technology and the Rise of Great Powers&lt;/em&gt;, makes a counterintuitive point: For a general-purpose technology like AI, long-term advantage often comes down to how widely and deeply technologies spread across society. And China is in a good position to win that race (although “murder” might be pushing it a bit!).&lt;/p&gt;  &lt;p&gt;Chips will remain China’s biggest bottleneck. Export restrictions have throttled access to top GPUs, pushing buyers into gray markets and forcing labs to recycle or repair banned Nvidia stock. Even as domestic chip programs expand, the performance gap at the very top still stands.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Yet those same constraints have pushed Chinese companies toward a different playbook: pooling compute, optimizing efficiency, and releasing open-weight models. DeepSeek-V3’s training run, for example, used just 2.6 million GPU-hours—far below the scale of US counterparts. But Alibaba’s Qwen models now rank among the most downloaded open-weights globally, and companies like Zhipu and MiniMax are building competitive multimodal and video models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;China’s industrial policy means new models can move from lab to implementation fast. Local governments and major enterprises are already rolling out reasoning models in administration, logistics, and finance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Education is another advantage. Major Chinese universities are implementing AI literacy programs in their curricula, embedding skills before the labor market demands them. The Ministry of Education has also announced plans to integrate AI training for children of all school ages. I’m not sure the phrase “engineering state” fully captures China’s relationship with new technologies, but decades of infrastructure building and top-down coordination have made the system unusually effective at pushing large-scale adoption, often with far less social resistance than you’d see elsewhere. The use at scale, naturally, allows for faster iterative improvements.&lt;/p&gt;  &lt;p&gt;Meanwhile, Stanford HAI’s 2025 AI Index found Chinese respondents to be the most optimistic in the world about AI’s future—far more optimistic than populations in the US or the UK. It’s striking, given that China’s economy has slowed since the pandemic for the first time in over two decades. Many in government and industry now see AI as a much-needed spark. Optimism can be powerful fuel, but whether it can persist through slower growth is still an open question.&lt;/p&gt; 
 &lt;p&gt;Social control remains part of the picture, but a different kind of ambition is taking shape. The Chinese AI founders in this new generation are the most globally minded I’ve seen, moving fluidly between Silicon Valley hackathons and pitch meetings in Dubai. Many are fluent in English and in the rhythms of global venture capital. Having watched the last generation wrestle with the burden of a Chinese label, they now build companies that are quietly transnational from the start.&lt;/p&gt;  &lt;p&gt;The US may still lead in speed and experimentation, but China could shape how AI becomes part of daily life, both at home and abroad. Speed matters, but speed isn’t the same thing as supremacy.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;John Thornhill&lt;/strong&gt; &lt;strong&gt;replies&lt;/strong&gt;:&lt;/p&gt;  &lt;p&gt;You’re right, Caiwei, that speed is not the same as supremacy (and “murder” may be too strong a word). And you’re also right to amplify the point about China’s strength in open-weight models and the US preference for proprietary models. This is not just a struggle between two different countries’ economic models but also between two different ways of deploying technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Even OpenAI’s chief executive, Sam Altman, admitted earlier this year: “We have been on the wrong side of history here and need to figure out a different open-source strategy.” That’s going to be a very interesting subplot to follow. Who’s called that one right?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Further reading on the US-China competition&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There’s been a lot of talk about how people may be using generative AI in their daily lives. This story from the &lt;em&gt;FT&lt;/em&gt;’s visual story team explores the reality&amp;nbsp;&lt;/p&gt;  &lt;p&gt;From China, &lt;em&gt;FT&lt;/em&gt; reporters ask how long Nvidia can maintain its dominance over Chinese rivals&lt;/p&gt;  &lt;p&gt;When it comes to real-world uses, toys and companions devices are a novel but emergent application of AI that is gaining traction in China—but is also heading to the US. This &lt;em&gt;MIT Technology Review&lt;/em&gt; story explored it.&lt;/p&gt;  &lt;p&gt;The once-frantic data center buildout in China has hit walls, and as the sanctions and AI demands shift, this &lt;em&gt;MIT Technology Review&lt;/em&gt; story took an on-the-ground look at how stakeholders are figuring it out.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;The State of AI is a collaboration between the Financial Times &amp;amp; MIT Technology Review examining the ways in which AI is reshaping global power. Every Monday for the next six weeks, writers from both publications will debate one aspect of the generative AI revolution reshaping global power.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;In this conversation, the FT’s tech columnist and Innovation Editor&amp;nbsp;John Thornhill and MIT Technology Review’s Caiwei Chen consider the battle between Silicon Valley and Beijing for technological supremacy.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1127512" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/MITTR_FT_small.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;John Thornhill writes:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Viewed from abroad, it seems only a matter of time before China emerges as the AI superpower of the 21st century.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Here in the West, our initial instinct is to focus on America’s significant lead in semiconductor expertise, its cutting-edge AI research, and its vast investments in data centers. The legendary investor Warren Buffett once warned: “Never bet against America.” He is right that for more than two centuries, no other “incubator for unleashing human potential” has matched the US.&lt;/p&gt;  &lt;p&gt;Today, however, China has the means, motive, and opportunity to commit the equivalent of technological murder. When it comes to mobilizing the whole-of-society resources needed to develop and deploy AI to maximum effect, it may be just as rash to bet against.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The data highlights the trends. In AI publications and patents, China leads. By 2023, China accounted for 22.6% of all citations, compared with 20.9% from Europe and 13% from the US, according to Stanford University's Artificial Intelligence Index Report 2025. As of 2023, China also accounted for 69.7% of all AI patents. True, the US maintains a strong lead in the top 100 most cited publications (50 versus 34 in 2023), but its share has been steadily declining.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similarly, the US outdoes China in top AI research talent, but the gap is narrowing. According to a report from the US Council of Economic Advisers, 59% of the world’s top AI researchers worked in the US in 2019, compared with 11% in China. But by 2022 those figures were 42% and 28%.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;The Trump administration’s tightening of restrictions for foreign H-1B visa holders may well lead more Chinese AI researchers in the US to return home. The talent ratio could move further in China’s favor.&lt;/p&gt;  &lt;p&gt;Regarding the technology itself, US-based institutions produced 40 of the world’s most notable AI models in 2024, compared with 15 from China. But Chinese researchers have learned to do more with less, and their strongest large language models—including the open-source DeepSeek-V3 and Alibaba's Qwen 2.5-Max—surpass the best US models in terms of algorithmic efficiency.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Where China is really likely to excel in future is in applying these open-source models. The latest report from Air Street Capital shows that China has now overtaken the US in terms of monthly downloads of AI models. In AI-enabled fintech, e-commerce, and logistics, China already outstrips the US.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Perhaps the most intriguing—and potentially the most productive—applications of AI may yet come in hardware, particularly in drones and industrial robotics. With the research field evolving toward embodied AI, China’s advantage in advanced manufacturing will shine through.&lt;/p&gt;  &lt;p&gt;Dan Wang, the tech analyst and author of &lt;em&gt;Breakneck&lt;/em&gt;, has rightly highlighted the strengths of China’s engineering state in developing manufacturing process knowledge—even if he has also shown the damaging effects of applying that engineering mentality in the social sphere. “China has been growing technologically stronger and economically more dynamic in all sorts of ways,” he told me. “But repression is very real. And it is getting worse in all sorts of ways as well.”&lt;/p&gt;  &lt;p&gt;I’d be fascinated to hear from you, Caiwei, about your take on the strengths and weaknesses of China’s AI dream. To what extent will China’s engineered social control hamper its technological ambitions?&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;Caiwei Chen responds:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Hi, John!&lt;/p&gt;  &lt;p&gt;You’re right that the US still holds a clear lead in frontier research and infrastructure. But “winning” AI can mean many different things. Jeffrey Ding, in his book &lt;em&gt;Technology and the Rise of Great Powers&lt;/em&gt;, makes a counterintuitive point: For a general-purpose technology like AI, long-term advantage often comes down to how widely and deeply technologies spread across society. And China is in a good position to win that race (although “murder” might be pushing it a bit!).&lt;/p&gt;  &lt;p&gt;Chips will remain China’s biggest bottleneck. Export restrictions have throttled access to top GPUs, pushing buyers into gray markets and forcing labs to recycle or repair banned Nvidia stock. Even as domestic chip programs expand, the performance gap at the very top still stands.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Yet those same constraints have pushed Chinese companies toward a different playbook: pooling compute, optimizing efficiency, and releasing open-weight models. DeepSeek-V3’s training run, for example, used just 2.6 million GPU-hours—far below the scale of US counterparts. But Alibaba’s Qwen models now rank among the most downloaded open-weights globally, and companies like Zhipu and MiniMax are building competitive multimodal and video models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;China’s industrial policy means new models can move from lab to implementation fast. Local governments and major enterprises are already rolling out reasoning models in administration, logistics, and finance.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Education is another advantage. Major Chinese universities are implementing AI literacy programs in their curricula, embedding skills before the labor market demands them. The Ministry of Education has also announced plans to integrate AI training for children of all school ages. I’m not sure the phrase “engineering state” fully captures China’s relationship with new technologies, but decades of infrastructure building and top-down coordination have made the system unusually effective at pushing large-scale adoption, often with far less social resistance than you’d see elsewhere. The use at scale, naturally, allows for faster iterative improvements.&lt;/p&gt;  &lt;p&gt;Meanwhile, Stanford HAI’s 2025 AI Index found Chinese respondents to be the most optimistic in the world about AI’s future—far more optimistic than populations in the US or the UK. It’s striking, given that China’s economy has slowed since the pandemic for the first time in over two decades. Many in government and industry now see AI as a much-needed spark. Optimism can be powerful fuel, but whether it can persist through slower growth is still an open question.&lt;/p&gt; 
 &lt;p&gt;Social control remains part of the picture, but a different kind of ambition is taking shape. The Chinese AI founders in this new generation are the most globally minded I’ve seen, moving fluidly between Silicon Valley hackathons and pitch meetings in Dubai. Many are fluent in English and in the rhythms of global venture capital. Having watched the last generation wrestle with the burden of a Chinese label, they now build companies that are quietly transnational from the start.&lt;/p&gt;  &lt;p&gt;The US may still lead in speed and experimentation, but China could shape how AI becomes part of daily life, both at home and abroad. Speed matters, but speed isn’t the same thing as supremacy.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;John Thornhill&lt;/strong&gt; &lt;strong&gt;replies&lt;/strong&gt;:&lt;/p&gt;  &lt;p&gt;You’re right, Caiwei, that speed is not the same as supremacy (and “murder” may be too strong a word). And you’re also right to amplify the point about China’s strength in open-weight models and the US preference for proprietary models. This is not just a struggle between two different countries’ economic models but also between two different ways of deploying technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;Even OpenAI’s chief executive, Sam Altman, admitted earlier this year: “We have been on the wrong side of history here and need to figure out a different open-source strategy.” That’s going to be a very interesting subplot to follow. Who’s called that one right?&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Further reading on the US-China competition&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;There’s been a lot of talk about how people may be using generative AI in their daily lives. This story from the &lt;em&gt;FT&lt;/em&gt;’s visual story team explores the reality&amp;nbsp;&lt;/p&gt;  &lt;p&gt;From China, &lt;em&gt;FT&lt;/em&gt; reporters ask how long Nvidia can maintain its dominance over Chinese rivals&lt;/p&gt;  &lt;p&gt;When it comes to real-world uses, toys and companions devices are a novel but emergent application of AI that is gaining traction in China—but is also heading to the US. This &lt;em&gt;MIT Technology Review&lt;/em&gt; story explored it.&lt;/p&gt;  &lt;p&gt;The once-frantic data center buildout in China has hit walls, and as the sanctions and AI demands shift, this &lt;em&gt;MIT Technology Review&lt;/em&gt; story took an on-the-ground look at how stakeholders are figuring it out.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/03/1126780/the-state-of-ai-is-china-about-to-win-the-race/</guid><pubDate>Mon, 03 Nov 2025 15:46:26 +0000</pubDate></item><item><title>[NEW] Dia’s AI browser starts adding Arc’s ‘greatest hits’ to its feature set (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/03/dias-ai-browser-starts-adding-arcs-greatest-hits-to-its-feature-set/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/@Mention-Tabs.jpeg?resize=1200,775" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The AI web browser Dia is drawing inspiration from its predecessor, Arc, an earlier experiment in modernizing the web browsing experience that hailed from the startup known as The Browser Company. On Sunday, The Browser Company founder Josh Miller confirmed that the new AI browser will bring “Arc’s greatest hits” to Dia, including things like the sidebar mode, and combine that with AI-native features like memory and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This explanation suggests that Dia, which has since been acquired by Atlassian for $610 million, could have an advantage in the AI browser race, as it builds on the company’s earlier learnings from developing Arc. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The latter was initially released in mid-2023 as a reinvention of the browser designed around the way people use the internet today. That included offering separate workspaces for work and personal browsing, support for pinned tabs, a Command Bar that worked like Apple’s Spotlight search, and a sidebar that included the search bar, tab list, user bookmarks, audio controls, and more. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Tbh we (or i really) duffed the comms in a bunch of ways, but…&lt;/p&gt;&lt;p&gt;1. Dia's architecture is much better for AI, speed, security&lt;/p&gt;&lt;p&gt;2. We're adapting Arc's greatest hits to be native to Dia&lt;/p&gt;&lt;p&gt;3. Sidebar mode for Arc fans&lt;/p&gt;&lt;p&gt;Dia + Arc = snappier, smarter, simpler by default w/ Pro mode&lt;/p&gt;— Josh Miller (@joshm) November 3, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;However, Arc may have tried to push the envelope a bit too far: Miller later admitted that Arc was ultimately too complex for most people to adopt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Arc was simply too different, with too many new things to learn, for too little reward… On top of that, Arc lacked cohesion in both its core features and core values. It was experimental, that was part of its charm, but also its complexity,” Miller wrote in a blog post earlier this year, detailing the company’s decision to wind down Arc and open source it, and refocusing the company’s efforts on building Dia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Arc may not necessarily be a failure, even if it didn’t become a widely adopted consumer product. Instead, the browser gave the company a year-plus’ worth of insights into what sort of modern browser features resonate with users and which ones do not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That could help the company get ahead when building out the feature set for Dia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Miller says in a post on X, “Dia’s architecture is much better for AI, speed, and security,” but it will introduce features that Arc fans loved, like the sidebar mode — which was just spotted in the company’s latest “early birds” release of Dia’s AI browser.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I'm daily-driving @diabrowser as a years-long Arc user and now an Early Bird, and I can say I'm so close to not miss Arc.&lt;/p&gt;&lt;p&gt;Dia browser now has:&lt;br /&gt;– Focus mode&lt;br /&gt;– Vertical tabs&lt;br /&gt;– Pinned tabs (grid-view)&lt;br /&gt;– Google Meet PIP &lt;/p&gt;&lt;p&gt;And I now wait for only three things before deleting Arc&lt;br /&gt;-… pic.twitter.com/qo9RSUUNmV&lt;/p&gt;— BLCNYY (@BLCNYY) November 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Already, Dia has added other features from Arc’s “greatest hits,” like turning Google Meet into a picture-in-picture player automatically when you switch tabs and custom keyboard shortcuts. Miller hinted that the company is exploring how to transition Arc’s Spaces — the distinct browsing areas with their own set of pinned tabs, favorites, themes, history, and cookies — to Dia. And he said Dia’s team is currently testing pinned tabs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Miller additionally solicited feedback about other features to add, like swipeable profiles, and Arc Search-inspired updates for the Dia mobile app coming in 2026. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, Miller notes, Dia will have less bloat and will be AI-native for things like memory and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Following the acquisition by Atlassian, The Browser Company continues to operate independently. As a result, Miller said the company will be able to add more “browser basics,” referring to favorite Arc features, to the Dia browser. He also shared that Dia is developing deeper integrations with Atlassian’s Jira and other apps, like Linear, under its new owner.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/@Mention-Tabs.jpeg?resize=1200,775" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The AI web browser Dia is drawing inspiration from its predecessor, Arc, an earlier experiment in modernizing the web browsing experience that hailed from the startup known as The Browser Company. On Sunday, The Browser Company founder Josh Miller confirmed that the new AI browser will bring “Arc’s greatest hits” to Dia, including things like the sidebar mode, and combine that with AI-native features like memory and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This explanation suggests that Dia, which has since been acquired by Atlassian for $610 million, could have an advantage in the AI browser race, as it builds on the company’s earlier learnings from developing Arc. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The latter was initially released in mid-2023 as a reinvention of the browser designed around the way people use the internet today. That included offering separate workspaces for work and personal browsing, support for pinned tabs, a Command Bar that worked like Apple’s Spotlight search, and a sidebar that included the search bar, tab list, user bookmarks, audio controls, and more. &lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Tbh we (or i really) duffed the comms in a bunch of ways, but…&lt;/p&gt;&lt;p&gt;1. Dia's architecture is much better for AI, speed, security&lt;/p&gt;&lt;p&gt;2. We're adapting Arc's greatest hits to be native to Dia&lt;/p&gt;&lt;p&gt;3. Sidebar mode for Arc fans&lt;/p&gt;&lt;p&gt;Dia + Arc = snappier, smarter, simpler by default w/ Pro mode&lt;/p&gt;— Josh Miller (@joshm) November 3, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;However, Arc may have tried to push the envelope a bit too far: Miller later admitted that Arc was ultimately too complex for most people to adopt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Arc was simply too different, with too many new things to learn, for too little reward… On top of that, Arc lacked cohesion in both its core features and core values. It was experimental, that was part of its charm, but also its complexity,” Miller wrote in a blog post earlier this year, detailing the company’s decision to wind down Arc and open source it, and refocusing the company’s efforts on building Dia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Arc may not necessarily be a failure, even if it didn’t become a widely adopted consumer product. Instead, the browser gave the company a year-plus’ worth of insights into what sort of modern browser features resonate with users and which ones do not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That could help the company get ahead when building out the feature set for Dia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Miller says in a post on X, “Dia’s architecture is much better for AI, speed, and security,” but it will introduce features that Arc fans loved, like the sidebar mode — which was just spotted in the company’s latest “early birds” release of Dia’s AI browser.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;I'm daily-driving @diabrowser as a years-long Arc user and now an Early Bird, and I can say I'm so close to not miss Arc.&lt;/p&gt;&lt;p&gt;Dia browser now has:&lt;br /&gt;– Focus mode&lt;br /&gt;– Vertical tabs&lt;br /&gt;– Pinned tabs (grid-view)&lt;br /&gt;– Google Meet PIP &lt;/p&gt;&lt;p&gt;And I now wait for only three things before deleting Arc&lt;br /&gt;-… pic.twitter.com/qo9RSUUNmV&lt;/p&gt;— BLCNYY (@BLCNYY) November 1, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Already, Dia has added other features from Arc’s “greatest hits,” like turning Google Meet into a picture-in-picture player automatically when you switch tabs and custom keyboard shortcuts. Miller hinted that the company is exploring how to transition Arc’s Spaces — the distinct browsing areas with their own set of pinned tabs, favorites, themes, history, and cookies — to Dia. And he said Dia’s team is currently testing pinned tabs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Miller additionally solicited feedback about other features to add, like swipeable profiles, and Arc Search-inspired updates for the Dia mobile app coming in 2026. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, Miller notes, Dia will have less bloat and will be AI-native for things like memory and agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Following the acquisition by Atlassian, The Browser Company continues to operate independently. As a result, Miller said the company will be able to add more “browser basics,” referring to favorite Arc features, to the Dia browser. He also shared that Dia is developing deeper integrations with Atlassian’s Jira and other apps, like Linear, under its new owner.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/03/dias-ai-browser-starts-adding-arcs-greatest-hits-to-its-feature-set/</guid><pubDate>Mon, 03 Nov 2025 17:01:58 +0000</pubDate></item><item><title>[NEW] OpenAI signs massive AI compute deal with Amazon (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/11/openai-signs-massive-ai-compute-deal-with-amazon/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Deal will provide access to hundreds of thousands of Nvidia chips that power ChatGPT.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A woman hiding behind a cloud." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/hiding_hero_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="A woman hiding behind a cloud." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/hiding_hero_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, OpenAI announced it has signed a seven-year, $38 billion deal to buy cloud services from Amazon Web Services to power products like ChatGPT and Sora. It’s the company’s first big computing deal after a fundamental restructuring last week that gave OpenAI more operational and financial freedom from Microsoft.&lt;/p&gt;
&lt;p&gt;The agreement gives OpenAI access to hundreds of thousands of Nvidia graphics processors to train and run its AI models. “Scaling frontier AI requires massive, reliable compute,” OpenAI CEO Sam Altman said in a statement. “Our partnership with AWS strengthens the broad compute ecosystem that will power this next era and bring advanced AI to everyone.”&lt;/p&gt;
&lt;p&gt;OpenAI will reportedly use Amazon Web Services immediately, with all planned capacity set to come online by the end of 2026 and room to expand further in 2027 and beyond. Amazon plans to roll out hundreds of thousands of chips, including Nvidia’s GB200 and GB300 AI accelerators, in data clusters built to power ChatGPT’s responses, generate AI videos, and train OpenAI’s next wave of models.&lt;/p&gt;
&lt;p&gt;Wall Street apparently liked the deal, because Amazon shares hit an all-time high on Monday morning. Meanwhile, shares for long-time OpenAI investor and partner Microsoft briefly dipped following the announcement.&lt;/p&gt;
&lt;h2&gt;Massive AI compute requirements&lt;/h2&gt;
&lt;p&gt;It’s no secret that running generative AI models for hundreds of millions of people currently requires a lot of computing power. Amid chip shortages over the past few years, finding sources of that computing muscle has been tricky. OpenAI is reportedly working on its own GPU hardware to help alleviate the strain.&lt;/p&gt;
&lt;p&gt;But for now, the company needs to find new sources of Nvidia chips, which accelerate AI computations. Altman has previously said that the company plans to spend $1.4 trillion to develop 30 gigawatts of computing resources, an amount that is enough to roughly power 25 million US homes, according to Reuters.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Altman has also said that eventually, he would like OpenAI to add 1 gigawatt of compute every week. That ambitious plan is complicated by the fact that one gigawatt of power is roughly equivalent to the output of one typical nuclear power plant, and Reuters reports that each gigawatt of compute build-out currently comes with a capital cost of over $40 billion.&lt;/p&gt;
&lt;p&gt;These aspirational numbers are far beyond what long-time cloud partner Microsoft can provide, so OpenAI has been seeking further independence from its wealthy corporate benefactor. OpenAI’s restructuring last week moved the company further from its nonprofit roots and removed Microsoft’s right of first refusal to supply compute services in the new arrangement.&lt;/p&gt;
&lt;p&gt;Even before last week’s restructuring deal with Microsoft, OpenAI had been forced to look elsewhere for computing power: The firm made a deal with Google in June to supply it with cloud services, and the company struck a deal in September with Oracle to buy $300 billion in computing power for about five years.&amp;nbsp; But it’s worth noting that Microsoft’s compute power is still essential for the firm: Last week, OpenAI agreed to purchase $250 billion of Microsoft’s Azure services over time.&lt;/p&gt;
&lt;p&gt;While these types of multi-billion-dollar deals seem to excite investors in the stock market, not everything is hunky dory in the world of AI at the moment. OpenAI’s annualized revenue run rate is expected to reach about $20 billion by year’s end, Reuters notes, and losses in the company are also mounting. Surging valuations of AI companies, oddly circular investments, massive spending commitments (which total more than $1 trillion for OpenAI), and the potential that generative AI might not be as useful as promised have prompted ongoing speculation among both critics and proponents alike that the AI boom is turning into a massive bubble.&lt;/p&gt;
&lt;p&gt;Meanwhile, Reuters has reported that OpenAI is laying the groundwork for an initial public offering that could value the company at up to $1 trillion. Whether that prospective $1 trillion valuation makes sense for a company burning through cash faster than it can make it back is another matter entirely.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Deal will provide access to hundreds of thousands of Nvidia chips that power ChatGPT.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A woman hiding behind a cloud." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/hiding_hero_1-300x169.jpg" width="300" /&gt;
                  &lt;img alt="A woman hiding behind a cloud." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/08/hiding_hero_1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, OpenAI announced it has signed a seven-year, $38 billion deal to buy cloud services from Amazon Web Services to power products like ChatGPT and Sora. It’s the company’s first big computing deal after a fundamental restructuring last week that gave OpenAI more operational and financial freedom from Microsoft.&lt;/p&gt;
&lt;p&gt;The agreement gives OpenAI access to hundreds of thousands of Nvidia graphics processors to train and run its AI models. “Scaling frontier AI requires massive, reliable compute,” OpenAI CEO Sam Altman said in a statement. “Our partnership with AWS strengthens the broad compute ecosystem that will power this next era and bring advanced AI to everyone.”&lt;/p&gt;
&lt;p&gt;OpenAI will reportedly use Amazon Web Services immediately, with all planned capacity set to come online by the end of 2026 and room to expand further in 2027 and beyond. Amazon plans to roll out hundreds of thousands of chips, including Nvidia’s GB200 and GB300 AI accelerators, in data clusters built to power ChatGPT’s responses, generate AI videos, and train OpenAI’s next wave of models.&lt;/p&gt;
&lt;p&gt;Wall Street apparently liked the deal, because Amazon shares hit an all-time high on Monday morning. Meanwhile, shares for long-time OpenAI investor and partner Microsoft briefly dipped following the announcement.&lt;/p&gt;
&lt;h2&gt;Massive AI compute requirements&lt;/h2&gt;
&lt;p&gt;It’s no secret that running generative AI models for hundreds of millions of people currently requires a lot of computing power. Amid chip shortages over the past few years, finding sources of that computing muscle has been tricky. OpenAI is reportedly working on its own GPU hardware to help alleviate the strain.&lt;/p&gt;
&lt;p&gt;But for now, the company needs to find new sources of Nvidia chips, which accelerate AI computations. Altman has previously said that the company plans to spend $1.4 trillion to develop 30 gigawatts of computing resources, an amount that is enough to roughly power 25 million US homes, according to Reuters.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Altman has also said that eventually, he would like OpenAI to add 1 gigawatt of compute every week. That ambitious plan is complicated by the fact that one gigawatt of power is roughly equivalent to the output of one typical nuclear power plant, and Reuters reports that each gigawatt of compute build-out currently comes with a capital cost of over $40 billion.&lt;/p&gt;
&lt;p&gt;These aspirational numbers are far beyond what long-time cloud partner Microsoft can provide, so OpenAI has been seeking further independence from its wealthy corporate benefactor. OpenAI’s restructuring last week moved the company further from its nonprofit roots and removed Microsoft’s right of first refusal to supply compute services in the new arrangement.&lt;/p&gt;
&lt;p&gt;Even before last week’s restructuring deal with Microsoft, OpenAI had been forced to look elsewhere for computing power: The firm made a deal with Google in June to supply it with cloud services, and the company struck a deal in September with Oracle to buy $300 billion in computing power for about five years.&amp;nbsp; But it’s worth noting that Microsoft’s compute power is still essential for the firm: Last week, OpenAI agreed to purchase $250 billion of Microsoft’s Azure services over time.&lt;/p&gt;
&lt;p&gt;While these types of multi-billion-dollar deals seem to excite investors in the stock market, not everything is hunky dory in the world of AI at the moment. OpenAI’s annualized revenue run rate is expected to reach about $20 billion by year’s end, Reuters notes, and losses in the company are also mounting. Surging valuations of AI companies, oddly circular investments, massive spending commitments (which total more than $1 trillion for OpenAI), and the potential that generative AI might not be as useful as promised have prompted ongoing speculation among both critics and proponents alike that the AI boom is turning into a massive bubble.&lt;/p&gt;
&lt;p&gt;Meanwhile, Reuters has reported that OpenAI is laying the groundwork for an initial public offering that could value the company at up to $1 trillion. Whether that prospective $1 trillion valuation makes sense for a company burning through cash faster than it can make it back is another matter entirely.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/11/openai-signs-massive-ai-compute-deal-with-amazon/</guid><pubDate>Mon, 03 Nov 2025 17:23:11 +0000</pubDate></item></channel></rss>