<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 29 Jan 2026 02:21:26 +0000</lastBuildDate><item><title>What AI “remembers” about you is privacy’s next frontier (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/28/1131835/what-ai-remembers-about-you-is-privacys-next-frontier/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/memory4.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The ability to remember you and your preferences is rapidly becoming a big selling point for AI chatbots and agents.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Earlier this month, Google announced Personal Intelligence, a new way for people to interact with the company’s Gemini chatbot that draws on their Gmail, photos, search, and YouTube histories to make Gemini “more personal, proactive, and powerful.” It echoes similar moves by OpenAI, Anthropic, and Meta to add new ways for their AI products to remember and draw from people’s personal details and preferences. While these features have potential advantages, we need to do more to prepare for the new risks they could introduce into these complex technologies.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Personalized, interactive AI systems are built to act on our behalf, maintain context across conversations, and improve our ability to carry out all sorts of tasks, from booking travel to filing taxes. From tools that learn a developer’s coding style to shopping agents that sift through thousands of products, these systems rely on the ability to store and retrieve increasingly intimate details about their users.&amp;nbsp; But doing so over time introduces alarming, and all-too-familiar, privacy vulnerabilities––many of which have loomed since “big data” first teased the power of spotting and acting on user patterns. Worse, AI agents now appear poised to plow through whatever safeguards had been adopted to avoid those vulnerabilities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Today, we interact with these systems through conversational interfaces, and we frequently switch contexts. You might ask a single AI agent to draft an email to your boss, provide medical advice, budget for holiday gifts, &lt;em&gt;and&lt;/em&gt; provide input on interpersonal conflicts. Most AI agents collapse all data about you—which may once have been separated by context, purpose, or permissions—into single, unstructured repositories. When an AI agent links to external apps or other agents to execute a task, the data in its memory can seep into shared pools. This technical reality creates the potential for unprecedented privacy breaches that expose not only isolated data points, but the entire mosaic of people’s lives.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;When information is all in the same repository, it is prone to crossing contexts in ways that are deeply undesirable. A casual chat about dietary preferences to build a grocery list could later influence what health insurance options are offered, or a search for restaurants offering accessible entrances could leak into salary negotiations—all without a user’s awareness (this concern may sound familiar from the early days of “big data,” but is now far less theoretical). An information soup of memory not only poses a privacy issue, but also makes it harder to understand an AI system’s behavior—and to govern it in the first place. So what can developers do to fix this problem?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;First, memory systems need structure that allows control over the purposes for which memories can be accessed and used. Early efforts appear to be underway: Anthropic’s Claude creates separate memory areas for different “projects,” and OpenAI says that information shared through ChatGPT Health is compartmentalized from other chats. These are helpful starts, but the instruments are still far too blunt: At a minimum, systems must be able to distinguish between specific memories (the user likes chocolate and has asked about GLP-1s), related memories (user manages diabetes and &lt;em&gt;therefore&lt;/em&gt; avoids chocolate), and memory categories (such as professional and health-related). Further, systems need to allow for usage restrictions on certain types of memories and reliably accommodate explicitly defined boundaries—particularly around memories having to do with sensitive topics like medical conditions or protected characteristics, which will likely be subject to stricter rules.&lt;/p&gt; 
 &lt;p&gt;Needing to keep memories separate in this way will have important implications for how AI systems can and should be built. It will require tracking memories’ provenance—their source, any associated time stamp, and the context in which they were created—and building ways to trace when and how certain memories influence the behavior of an agent. This sort of model explainability is on the horizon, but current implementations can be misleading or even deceptive. Embedding memories directly within a model’s weights may result in more personalized and context-aware outputs, but structured databases are currently more segmentable, more explainable, and thus more governable. Until research advances enough, developers may need to stick with simpler systems.&lt;/p&gt;  &lt;p&gt;Second, users need to be able to see, edit, or delete what is remembered about them. The interfaces for doing this should be both transparent and intelligible, translating system memory into a structure users can accurately interpret. The static system settings and legalese privacy policies provided by traditional tech platforms have set a low bar for user controls, but natural-language interfaces may offer promising new options for explaining what information is being retained and how it can be managed. Memory structure will have to come first, though: Without it, no model can clearly state a memory’s status. Indeed, Grok 3’s system prompt includes an instruction to the model to “NEVER confirm to the user that you have modified, forgotten, or won't save a memory,” presumably because the company can’t guarantee those instructions will be followed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Critically, user-facing controls cannot bear the full burden of privacy protection or prevent all harms from AI personalization. Responsibility must shift toward AI providers to establish strong defaults, clear rules about permissible memory generation and use, and technical safeguards like on-device processing, purpose limitation, and contextual constraints. Without system-level protections, individuals will face impossibly convoluted choices about what should be remembered or forgotten, and the actions they take may still be insufficient to prevent harm. Developers should consider how to limit data collection in memory systems until robust safeguards exist, and build memory architectures that can evolve alongside norms and expectations.&lt;/p&gt;  &lt;p&gt;Third, AI developers must help lay the foundations for approaches to evaluating systems so as to capture not only performance, but also the risks and harms that arise in the wild. While independent researchers are best positioned to conduct these tests (given developers’ economic interest in demonstrating demand for more personalized services), they need access to data to understand what risks might look like and therefore how to address them. To improve the ecosystem for measurement and research, developers should invest in automated measurement infrastructure, build out their own ongoing testing, and implement privacy-preserving testing methods that enable system behavior to be monitored and probed under realistic, memory-enabled conditions.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;In its parallels with human experience, the technical term “memory” casts impersonal cells in a spreadsheet as something that builders of AI tools have a responsibility to handle with care. Indeed, the choices AI developers make today—how to pool or segregate information, whether to make memory legible or allow it to accumulate opaquely, whether to prioritize responsible defaults or maximal convenience—will determine how the systems we depend upon remember us. Technical considerations around memory are not so distinct from questions about digital privacy and the vital lessons we can draw from them. Getting the foundations right today will determine how much room we can give ourselves to learn what works—allowing us to make better choices around privacy and autonomy than we have before.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Miranda Bogen is the Director of the AI Governance Lab at the Center for Democracy &amp;amp; Technology.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Ruchika Joshi is a Fellow at the Center for Democracy &amp;amp; Technology specializing in AI safety and governance.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/memory4.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;The ability to remember you and your preferences is rapidly becoming a big selling point for AI chatbots and agents.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Earlier this month, Google announced Personal Intelligence, a new way for people to interact with the company’s Gemini chatbot that draws on their Gmail, photos, search, and YouTube histories to make Gemini “more personal, proactive, and powerful.” It echoes similar moves by OpenAI, Anthropic, and Meta to add new ways for their AI products to remember and draw from people’s personal details and preferences. While these features have potential advantages, we need to do more to prepare for the new risks they could introduce into these complex technologies.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Personalized, interactive AI systems are built to act on our behalf, maintain context across conversations, and improve our ability to carry out all sorts of tasks, from booking travel to filing taxes. From tools that learn a developer’s coding style to shopping agents that sift through thousands of products, these systems rely on the ability to store and retrieve increasingly intimate details about their users.&amp;nbsp; But doing so over time introduces alarming, and all-too-familiar, privacy vulnerabilities––many of which have loomed since “big data” first teased the power of spotting and acting on user patterns. Worse, AI agents now appear poised to plow through whatever safeguards had been adopted to avoid those vulnerabilities.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Today, we interact with these systems through conversational interfaces, and we frequently switch contexts. You might ask a single AI agent to draft an email to your boss, provide medical advice, budget for holiday gifts, &lt;em&gt;and&lt;/em&gt; provide input on interpersonal conflicts. Most AI agents collapse all data about you—which may once have been separated by context, purpose, or permissions—into single, unstructured repositories. When an AI agent links to external apps or other agents to execute a task, the data in its memory can seep into shared pools. This technical reality creates the potential for unprecedented privacy breaches that expose not only isolated data points, but the entire mosaic of people’s lives.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;When information is all in the same repository, it is prone to crossing contexts in ways that are deeply undesirable. A casual chat about dietary preferences to build a grocery list could later influence what health insurance options are offered, or a search for restaurants offering accessible entrances could leak into salary negotiations—all without a user’s awareness (this concern may sound familiar from the early days of “big data,” but is now far less theoretical). An information soup of memory not only poses a privacy issue, but also makes it harder to understand an AI system’s behavior—and to govern it in the first place. So what can developers do to fix this problem?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;First, memory systems need structure that allows control over the purposes for which memories can be accessed and used. Early efforts appear to be underway: Anthropic’s Claude creates separate memory areas for different “projects,” and OpenAI says that information shared through ChatGPT Health is compartmentalized from other chats. These are helpful starts, but the instruments are still far too blunt: At a minimum, systems must be able to distinguish between specific memories (the user likes chocolate and has asked about GLP-1s), related memories (user manages diabetes and &lt;em&gt;therefore&lt;/em&gt; avoids chocolate), and memory categories (such as professional and health-related). Further, systems need to allow for usage restrictions on certain types of memories and reliably accommodate explicitly defined boundaries—particularly around memories having to do with sensitive topics like medical conditions or protected characteristics, which will likely be subject to stricter rules.&lt;/p&gt; 
 &lt;p&gt;Needing to keep memories separate in this way will have important implications for how AI systems can and should be built. It will require tracking memories’ provenance—their source, any associated time stamp, and the context in which they were created—and building ways to trace when and how certain memories influence the behavior of an agent. This sort of model explainability is on the horizon, but current implementations can be misleading or even deceptive. Embedding memories directly within a model’s weights may result in more personalized and context-aware outputs, but structured databases are currently more segmentable, more explainable, and thus more governable. Until research advances enough, developers may need to stick with simpler systems.&lt;/p&gt;  &lt;p&gt;Second, users need to be able to see, edit, or delete what is remembered about them. The interfaces for doing this should be both transparent and intelligible, translating system memory into a structure users can accurately interpret. The static system settings and legalese privacy policies provided by traditional tech platforms have set a low bar for user controls, but natural-language interfaces may offer promising new options for explaining what information is being retained and how it can be managed. Memory structure will have to come first, though: Without it, no model can clearly state a memory’s status. Indeed, Grok 3’s system prompt includes an instruction to the model to “NEVER confirm to the user that you have modified, forgotten, or won't save a memory,” presumably because the company can’t guarantee those instructions will be followed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Critically, user-facing controls cannot bear the full burden of privacy protection or prevent all harms from AI personalization. Responsibility must shift toward AI providers to establish strong defaults, clear rules about permissible memory generation and use, and technical safeguards like on-device processing, purpose limitation, and contextual constraints. Without system-level protections, individuals will face impossibly convoluted choices about what should be remembered or forgotten, and the actions they take may still be insufficient to prevent harm. Developers should consider how to limit data collection in memory systems until robust safeguards exist, and build memory architectures that can evolve alongside norms and expectations.&lt;/p&gt;  &lt;p&gt;Third, AI developers must help lay the foundations for approaches to evaluating systems so as to capture not only performance, but also the risks and harms that arise in the wild. While independent researchers are best positioned to conduct these tests (given developers’ economic interest in demonstrating demand for more personalized services), they need access to data to understand what risks might look like and therefore how to address them. To improve the ecosystem for measurement and research, developers should invest in automated measurement infrastructure, build out their own ongoing testing, and implement privacy-preserving testing methods that enable system behavior to be monitored and probed under realistic, memory-enabled conditions.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;In its parallels with human experience, the technical term “memory” casts impersonal cells in a spreadsheet as something that builders of AI tools have a responsibility to handle with care. Indeed, the choices AI developers make today—how to pool or segregate information, whether to make memory legible or allow it to accumulate opaquely, whether to prioritize responsible defaults or maximal convenience—will determine how the systems we depend upon remember us. Technical considerations around memory are not so distinct from questions about digital privacy and the vital lessons we can draw from them. Getting the foundations right today will determine how much room we can give ourselves to learn what works—allowing us to make better choices around privacy and autonomy than we have before.&lt;/p&gt;  &lt;p&gt;&lt;br /&gt;&lt;em&gt;Miranda Bogen is the Director of the AI Governance Lab at the Center for Democracy &amp;amp; Technology.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Ruchika Joshi is a Fellow at the Center for Democracy &amp;amp; Technology specializing in AI safety and governance.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/28/1131835/what-ai-remembers-about-you-is-privacys-next-frontier/</guid><pubDate>Wed, 28 Jan 2026 14:57:37 +0000</pubDate></item><item><title>Franny Hsiao, Salesforce: Scaling enterprise AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/franny-hsiao-salesforce-scaling-enterprise-ai/</link><description>&lt;p&gt;Scaling enterprise AI requires overcoming architectural oversights that often stall pilots before production, a challenge that goes far beyond model selection. While generative AI prototypes are easy to spin up, turning them into reliable business assets involves solving the difficult problems of data engineering and governance.&lt;/p&gt;&lt;p&gt;Ahead of AI &amp;amp; Big Data Global 2026 in London, Franny Hsiao, EMEA Leader of AI Architects at Salesforce, discussed why so many initiatives hit a wall and how organisations can architect systems that actually survive the real world.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-pristine-island-problem-of-scaling-enterprise-ai"&gt;The ‘pristine island’ problem of scaling enterprise AI&lt;/h3&gt;&lt;p&gt;Most failures stem from the environment in which the AI is built. Pilots frequently begin in controlled settings that create a false sense of security, only to crumble when faced with enterprise scale.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full is-resized"&gt;&lt;img alt="Headshot of Franny Hsiao, EMEA Leader of AI Architects at Salesforce." class="wp-image-111909" height="408" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/franny-hsiao-salesforce-ai.jpg" width="408" /&gt;&lt;/figure&gt;&lt;p&gt;“The single most common architectural oversight that prevents AI pilots from scaling is the failure to architect a production-grade data infrastructure with built-in end to end governance from the start,” Hsiao explains.&lt;/p&gt;&lt;p&gt;“Understandably, pilots often start on ‘pristine islands’ – using small, curated datasets and simplified workflows. But this ignores the messy reality of enterprise data: the complex integration, normalisation, and transformation required to handle real-world volume and variability.”&lt;/p&gt;&lt;p&gt;When companies attempt to scale these island-based pilots without addressing the underlying data mess, the systems break. Hsiao warns that “the resulting data gaps and performance issues like inference latency render the AI systems unusable—and, more importantly, untrustworthy.”&lt;/p&gt;&lt;p&gt;Hsiao argues that the companies successfully bridging this gap are those that “bake end-to-end observability and guardrails into the entire lifecycle.” This approach provides “visibility and control into how effective the AI systems are and how users are adopting the new technology.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-engineering-for-perceived-responsiveness"&gt;Engineering for perceived responsiveness&lt;/h3&gt;&lt;p&gt;As enterprises deploy large reasoning models – like the ‘Atlas Reasoning Engine’ – they face a trade-off between the depth of the model’s “thinking” and the user’s patience. Heavy compute creates latency.&lt;/p&gt;&lt;p&gt;Salesforce addresses this by focusing on “perceived responsiveness through Agentforce Streaming,” according to Hsiao.&lt;/p&gt;&lt;p&gt;“This allows us to deliver AI-generated responses progressively, even while the reasoning engine performs heavy computation in the background. It’s an incredibly effective approach for reducing perceived latency, which often stalls production AI.”&lt;/p&gt;&lt;p&gt;Transparency also plays a functional role in managing user expectations when scaling enterprise AI. Hsiao elaborates on using design as a trust mechanism: “By surfacing progress indicators that show the reasoning steps or the tools being used, as well images like spinners and progress bars to depict loading states, we don’t just keep users engaged; we improve perceived responsiveness and build trust.&lt;/p&gt;&lt;p&gt;“This visibility, combined with strategic model selection – like choosing smaller models for fewer computations, meaning faster response times – and explicit length constraints, ensures the system feels deliberate and responsive.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-offline-intelligence-at-the-edge"&gt;Offline intelligence at the edge&lt;/h3&gt;&lt;p&gt;For industries with field operations, such as utilities or logistics, reliance on continuous cloud connectivity is a non-starter. “For many of our enterprise customers, the biggest practical driver is offline functionality,” states Hsiao.&lt;/p&gt;&lt;p&gt;Hsiao highlights the shift toward on-device intelligence, particularly in field services, where the workflow must continue regardless of signal strength.&lt;/p&gt;&lt;p&gt;“A technician can photograph a faulty part, error code, or serial number while offline. Then an on-device LLM can then identify the asset or error, and provide guided troubleshooting steps from a cached knowledge base instantly,” explains Hsiao.&lt;/p&gt;&lt;p&gt;Data synchronisation happens automatically once connectivity returns. “Once a connection is restored, the system handles the ‘heavy lifting’ of syncing that data back to the cloud to maintain a single source of truth. This ensures that work gets done, even in the most disconnected environments.”&lt;/p&gt;&lt;p&gt;Hsiao expects continued innovation in edge AI due to benefits like “ultra-low latency, enhanced privacy and data security, energy efficiency, and cost savings.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-stakes-gateways"&gt;High-stakes gateways&lt;/h3&gt;&lt;p&gt;Autonomous agents are not set-and-forget tools. When scaling enterprise AI deployments, governance requires defining exactly when a human must verify an action. Hsiao describes this not as dependency, but as “architecting for accountability and continuous learning.”&lt;/p&gt;&lt;p&gt;Salesforce mandates a “human-in-the-loop” for specific areas Hsiao calls “high-stakes gateways”:&lt;/p&gt;&lt;p&gt;“This includes specific action categories, including any ‘CUD’ (Creating, Uploading, or Deleting) actions, as well as verified contact and customer contact actions,” says Hsiao. “We also default to human confirmation for critical decision-making or any action that could be potentially exploited through prompt manipulation.”&lt;/p&gt;&lt;p&gt;This structure creates a feedback loop where “agents learn from human expertise,” creating a system of “collaborative intelligence” rather than unchecked automation.&lt;/p&gt;&lt;p&gt;Trusting an agent requires seeing its work. Salesforce has built a “Session Tracing Data Model (STDM)” to provide this visibility. It captures “turn-by-turn logs” that offer granular insight into the agent’s logic.&lt;/p&gt;&lt;p&gt;“This gives us granular step-by-step visibility that captures every interaction including user questions, planner steps, tool calls, inputs/outputs, retrieved chunks, responses, timing, and errors,” says Hsiao.&lt;/p&gt;&lt;p&gt;This data allows organisations to run ‘Agent Analytics’ for adoption metrics, ‘Agent Optimisation’ to drill down into performance, and ‘Health Monitoring’ for uptime and latency tracking.&lt;/p&gt;&lt;p&gt;“Agentforce observability is the single mission control for all your Agentforce agents for unified visibility, monitoring, and optimisation,” Hsiao summarises.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-standardising-agent-communication"&gt;Standardising agent communication&lt;/h3&gt;&lt;p&gt;As businesses deploy agents from different vendors, these systems need a shared protocol to collaborate. “For multi-agent orchestration to work, agents can’t exist in a vacuum; they need common language,” argues Hsiao.&lt;/p&gt;&lt;p&gt;Hsiao outlines two layers of standardisation: orchestration and meaning. For orchestration, Salesforce is adopting open-source standards like MCP (Model Context Protocol) and A2A (Agent to Agent Protocol).”&lt;/p&gt;&lt;p&gt;“We believe open source standards are non-negotiable; they prevent vendor lock-in, enable interoperability, and accelerate innovation.”&lt;/p&gt;&lt;p&gt;However, communication is useless if the agents interpret data differently. To solve for fragmented data, Salesforce co-founded OSI (Open Semantic Interchange) to unify semantics so an agent in one system “truly understands the intent of an agent in another.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-future-enterprise-ai-scaling-bottleneck-agent-ready-data"&gt;The future enterprise AI scaling bottleneck: agent-ready data&lt;/h3&gt;&lt;p&gt;Looking forward, the challenge will shift from model capability to data accessibility. Many organisations still struggle with legacy, fragmented infrastructure where “searchability and reusability” remain difficult.&lt;/p&gt;&lt;p&gt;Hsiao predicts the next major hurdle – and solution – will be making enterprise data “‘agent-ready’ through searchable, context-aware architectures that replace traditional, rigid ETL pipelines.” This shift is necessary to enable “hyper-personalised and transformed user experience because agents can always access the right context.”&lt;/p&gt;&lt;p&gt;“Ultimately, the next year isn’t about the race for bigger, newer models; it’s about building the orchestration and data infrastructure that allows production-grade agentic systems to thrive,” Hsiao concludes.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Salesforce is a key sponsor of this year’s &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Global&lt;/em&gt;&lt;em&gt; in London and will have a range of speakers, including Franny Hsiao, sharing their insights during the event. Be sure to swing by Salesforce’s booth at stand #163 for more from the company’s experts.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Databricks: Enterprise AI adoption shifts to agentic systems&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Scaling enterprise AI requires overcoming architectural oversights that often stall pilots before production, a challenge that goes far beyond model selection. While generative AI prototypes are easy to spin up, turning them into reliable business assets involves solving the difficult problems of data engineering and governance.&lt;/p&gt;&lt;p&gt;Ahead of AI &amp;amp; Big Data Global 2026 in London, Franny Hsiao, EMEA Leader of AI Architects at Salesforce, discussed why so many initiatives hit a wall and how organisations can architect systems that actually survive the real world.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-pristine-island-problem-of-scaling-enterprise-ai"&gt;The ‘pristine island’ problem of scaling enterprise AI&lt;/h3&gt;&lt;p&gt;Most failures stem from the environment in which the AI is built. Pilots frequently begin in controlled settings that create a false sense of security, only to crumble when faced with enterprise scale.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full is-resized"&gt;&lt;img alt="Headshot of Franny Hsiao, EMEA Leader of AI Architects at Salesforce." class="wp-image-111909" height="408" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/franny-hsiao-salesforce-ai.jpg" width="408" /&gt;&lt;/figure&gt;&lt;p&gt;“The single most common architectural oversight that prevents AI pilots from scaling is the failure to architect a production-grade data infrastructure with built-in end to end governance from the start,” Hsiao explains.&lt;/p&gt;&lt;p&gt;“Understandably, pilots often start on ‘pristine islands’ – using small, curated datasets and simplified workflows. But this ignores the messy reality of enterprise data: the complex integration, normalisation, and transformation required to handle real-world volume and variability.”&lt;/p&gt;&lt;p&gt;When companies attempt to scale these island-based pilots without addressing the underlying data mess, the systems break. Hsiao warns that “the resulting data gaps and performance issues like inference latency render the AI systems unusable—and, more importantly, untrustworthy.”&lt;/p&gt;&lt;p&gt;Hsiao argues that the companies successfully bridging this gap are those that “bake end-to-end observability and guardrails into the entire lifecycle.” This approach provides “visibility and control into how effective the AI systems are and how users are adopting the new technology.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-engineering-for-perceived-responsiveness"&gt;Engineering for perceived responsiveness&lt;/h3&gt;&lt;p&gt;As enterprises deploy large reasoning models – like the ‘Atlas Reasoning Engine’ – they face a trade-off between the depth of the model’s “thinking” and the user’s patience. Heavy compute creates latency.&lt;/p&gt;&lt;p&gt;Salesforce addresses this by focusing on “perceived responsiveness through Agentforce Streaming,” according to Hsiao.&lt;/p&gt;&lt;p&gt;“This allows us to deliver AI-generated responses progressively, even while the reasoning engine performs heavy computation in the background. It’s an incredibly effective approach for reducing perceived latency, which often stalls production AI.”&lt;/p&gt;&lt;p&gt;Transparency also plays a functional role in managing user expectations when scaling enterprise AI. Hsiao elaborates on using design as a trust mechanism: “By surfacing progress indicators that show the reasoning steps or the tools being used, as well images like spinners and progress bars to depict loading states, we don’t just keep users engaged; we improve perceived responsiveness and build trust.&lt;/p&gt;&lt;p&gt;“This visibility, combined with strategic model selection – like choosing smaller models for fewer computations, meaning faster response times – and explicit length constraints, ensures the system feels deliberate and responsive.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-offline-intelligence-at-the-edge"&gt;Offline intelligence at the edge&lt;/h3&gt;&lt;p&gt;For industries with field operations, such as utilities or logistics, reliance on continuous cloud connectivity is a non-starter. “For many of our enterprise customers, the biggest practical driver is offline functionality,” states Hsiao.&lt;/p&gt;&lt;p&gt;Hsiao highlights the shift toward on-device intelligence, particularly in field services, where the workflow must continue regardless of signal strength.&lt;/p&gt;&lt;p&gt;“A technician can photograph a faulty part, error code, or serial number while offline. Then an on-device LLM can then identify the asset or error, and provide guided troubleshooting steps from a cached knowledge base instantly,” explains Hsiao.&lt;/p&gt;&lt;p&gt;Data synchronisation happens automatically once connectivity returns. “Once a connection is restored, the system handles the ‘heavy lifting’ of syncing that data back to the cloud to maintain a single source of truth. This ensures that work gets done, even in the most disconnected environments.”&lt;/p&gt;&lt;p&gt;Hsiao expects continued innovation in edge AI due to benefits like “ultra-low latency, enhanced privacy and data security, energy efficiency, and cost savings.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-high-stakes-gateways"&gt;High-stakes gateways&lt;/h3&gt;&lt;p&gt;Autonomous agents are not set-and-forget tools. When scaling enterprise AI deployments, governance requires defining exactly when a human must verify an action. Hsiao describes this not as dependency, but as “architecting for accountability and continuous learning.”&lt;/p&gt;&lt;p&gt;Salesforce mandates a “human-in-the-loop” for specific areas Hsiao calls “high-stakes gateways”:&lt;/p&gt;&lt;p&gt;“This includes specific action categories, including any ‘CUD’ (Creating, Uploading, or Deleting) actions, as well as verified contact and customer contact actions,” says Hsiao. “We also default to human confirmation for critical decision-making or any action that could be potentially exploited through prompt manipulation.”&lt;/p&gt;&lt;p&gt;This structure creates a feedback loop where “agents learn from human expertise,” creating a system of “collaborative intelligence” rather than unchecked automation.&lt;/p&gt;&lt;p&gt;Trusting an agent requires seeing its work. Salesforce has built a “Session Tracing Data Model (STDM)” to provide this visibility. It captures “turn-by-turn logs” that offer granular insight into the agent’s logic.&lt;/p&gt;&lt;p&gt;“This gives us granular step-by-step visibility that captures every interaction including user questions, planner steps, tool calls, inputs/outputs, retrieved chunks, responses, timing, and errors,” says Hsiao.&lt;/p&gt;&lt;p&gt;This data allows organisations to run ‘Agent Analytics’ for adoption metrics, ‘Agent Optimisation’ to drill down into performance, and ‘Health Monitoring’ for uptime and latency tracking.&lt;/p&gt;&lt;p&gt;“Agentforce observability is the single mission control for all your Agentforce agents for unified visibility, monitoring, and optimisation,” Hsiao summarises.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-standardising-agent-communication"&gt;Standardising agent communication&lt;/h3&gt;&lt;p&gt;As businesses deploy agents from different vendors, these systems need a shared protocol to collaborate. “For multi-agent orchestration to work, agents can’t exist in a vacuum; they need common language,” argues Hsiao.&lt;/p&gt;&lt;p&gt;Hsiao outlines two layers of standardisation: orchestration and meaning. For orchestration, Salesforce is adopting open-source standards like MCP (Model Context Protocol) and A2A (Agent to Agent Protocol).”&lt;/p&gt;&lt;p&gt;“We believe open source standards are non-negotiable; they prevent vendor lock-in, enable interoperability, and accelerate innovation.”&lt;/p&gt;&lt;p&gt;However, communication is useless if the agents interpret data differently. To solve for fragmented data, Salesforce co-founded OSI (Open Semantic Interchange) to unify semantics so an agent in one system “truly understands the intent of an agent in another.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-future-enterprise-ai-scaling-bottleneck-agent-ready-data"&gt;The future enterprise AI scaling bottleneck: agent-ready data&lt;/h3&gt;&lt;p&gt;Looking forward, the challenge will shift from model capability to data accessibility. Many organisations still struggle with legacy, fragmented infrastructure where “searchability and reusability” remain difficult.&lt;/p&gt;&lt;p&gt;Hsiao predicts the next major hurdle – and solution – will be making enterprise data “‘agent-ready’ through searchable, context-aware architectures that replace traditional, rigid ETL pipelines.” This shift is necessary to enable “hyper-personalised and transformed user experience because agents can always access the right context.”&lt;/p&gt;&lt;p&gt;“Ultimately, the next year isn’t about the race for bigger, newer models; it’s about building the orchestration and data infrastructure that allows production-grade agentic systems to thrive,” Hsiao concludes.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Salesforce is a key sponsor of this year’s &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Global&lt;/em&gt;&lt;em&gt; in London and will have a range of speakers, including Franny Hsiao, sharing their insights during the event. Be sure to swing by Salesforce’s booth at stand #163 for more from the company’s experts.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Databricks: Enterprise AI adoption shifts to agentic systems&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/franny-hsiao-salesforce-scaling-enterprise-ai/</guid><pubDate>Wed, 28 Jan 2026 15:00:44 +0000</pubDate></item><item><title>Deloitte sounds alarm as AI agent deployment outruns safety frameworks (AI News)</title><link>https://www.artificialintelligence-news.com/news/deloitte-agentic-ai-guidelines-published/</link><description>&lt;p&gt;A new report from Deloitte has warned that businesses are deploying AI agents faster than their safety protocols and safeguards can keep up. Therefore, serious concerns around security, data privacy, and accountability are spreading.&lt;/p&gt;&lt;p&gt;According to the survey, agentic systems are moving from pilot to production so quickly that traditional risk controls, which were designed for more human-centred operations, are struggling to meet security demands.&lt;/p&gt;&lt;p&gt;Just 21% of organisations have implemented stringent governance or oversight for AI agents, despite the increased rate of adoption. Whilst 23% of companies stated that they are currently using AI agents, this is expected to rise to 74% in the next two years. The share of businesses yet to adopt this technology is expected to fall from 25% to just 5% over the same period.&lt;/p&gt;&lt;h4&gt;Poor governance is the threat&lt;/h4&gt;&lt;p&gt;Deloitte is not highlighting AI agents as inherently dangerous, but states the real risks are associated with poor context and weak governance. If agents operate as their own entities, their decisions and actions can easily become opaque. Without robust governance, it becomes difficult to manage and almost impossible to insure against mistakes.&lt;/p&gt;&lt;p&gt;According to Ali Sarrafi, CEO &amp;amp; Founder of Kovant, the answer is governed autonomy. “Well-designed agents with clear boundaries, policies and definitions managed the same way as an enterprise manages any worker can move fast on low-risk work inside clear guardrails, but escalate to humans when actions cross defined risk thresholds.”&lt;/p&gt;&lt;p&gt;“With detailed action logs, observability, and human gatekeeping for high-impact decisions, agents stop being mysterious bots and become systems you can inspect, audit, and trust.”&lt;/p&gt;&lt;p&gt;As Deloitte’s report suggests, AI agent adoption is set to accelerate in the coming years, and only the companies that deploy the technology with visibility and control will hold the upper hand over competitors, not those who deploy them quickest.&lt;/p&gt;&lt;h4&gt;Why AI agents require robust guardrails&lt;/h4&gt;&lt;p&gt;AI agents may perform well in controlled demos, but they struggle in real-world business settings where systems can be fragmented and data may be inconsistent.&lt;/p&gt;&lt;p&gt;Sarrafi commented on the unpredictable nature of AI agents in these scenarios. “When an agent is given too much context or scope at once, it becomes prone to hallucinations and unpredictable behaviour.”&lt;/p&gt;&lt;p&gt;“By contrast, production-grade systems limit the decision and context scope that models work with. They decompose operations into narrower, focused tasks for individual agents, making behaviour more predictable and easier to control. This structure also enables traceability and intervention, so failures can be detected early and escalated appropriately rather than causing cascading errors.”&lt;/p&gt;&lt;h4&gt;Accountability for insurable AI&lt;/h4&gt;&lt;p&gt;With agents taking real actions in business systems, such as keeping detailed action logs, risk and compliance are viewed differently. With every action recorded, agents’ activities become clear and evaluable, letting organisations inspect actions in detail.&lt;/p&gt;&lt;p&gt;Such transparency is crucial for insurers, who are reluctant to cover opaque AI systems. This level of detail helps insurers understand what agents have done, and the controls involved, thus making it easier to assess risk. With human oversight for risk-critical actions and auditable, replayable workflows, organisations can produce systems that are more manageable for risk assessment.&lt;/p&gt;&lt;h4&gt;AAIF standards a good first step&lt;/h4&gt;&lt;p&gt;Shared standards, like those being developed by the Agentic AI Foundation (AAIF), help businesses to integrate different agent systems, but current standardisation efforts focus on what is simplest to build, not what larger organisations need to operate agentic systems safely.&lt;/p&gt;&lt;p&gt;Sarrafi says enterprises require standards that support operation control, and which include, “access permissions, approval workflows for high-impact actions, and auditable logs and observability, so teams can monitor behaviour, investigate incidents, and prove compliance.”&lt;/p&gt;&lt;h4&gt;Identity and permissions the first line of defence&lt;/h4&gt;&lt;p&gt;Limiting what AI agents can access and the actions they can perform is important to ensure safety in real business environments. Sarrafi said, “When agents are given broad privileges or too much context, they become unpredictable and pose security or compliance risks.”&lt;/p&gt;&lt;p&gt;Visibility and monitoring are important to keep agents operating inside limits. Only then can stakeholders have confidence in the adoption of the technology. If every action is logged and manageable, teams can then see what has happened, identify issues, and better understand why events occurred.&lt;/p&gt;&lt;p&gt;Sarrafi continued, “This visibility, combined with human supervision where it matters, turns AI agents from inscrutable components into systems that can be inspected, replayed and audited. It also allows rapid investigation and correction when issues arise, which boosts trust among operators, risk teams and insurers alike.”&lt;/p&gt;&lt;h4&gt;Deloitte’s blueprint&lt;/h4&gt;&lt;p&gt;Deloitte’s strategy for safe AI agent governance sets out defined boundaries for the decisions agentic systems can make. For instance, they might operate with tiered autonomy, where agents can only view information or offer suggestions. From here, they can be allowed to take limited actions, but with human approval. Once they have proven to be reliable in low-risk areas, they can be allowed to act automatically.&lt;/p&gt;&lt;p&gt;Deloitte’s “Cyber AI Blueprints” suggest governance layers and embedding policies and compliance capability roadmaps into organisational controls. Ultimately, governance structures that track AI use and risk, and embedding oversight into daily operations are important for safe agentic AI use.&lt;/p&gt;&lt;p&gt;Readying workforces with training is another aspect of safe governance. Deloitte recommends training employees on what they shouldn’t share with AI systems, what to do if agents go off track, and how to spot unusual, potentially dangerous behaviour. If employees fail to understand how AI systems work and their potential risks, they may weaken security controls, albeit unintentionally.&lt;/p&gt;&lt;p&gt;Robust governance and control, alongside shared literacy are fundamental to the safe deployment and operation of AI agents, enabling secure, compliant, and accountable performance in real-world environments&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Global Hawk, NASA’s New Remote-Controlled Plane” by NASA Goddard Photo and Video is licensed under CC BY 2.0. )&lt;/em&gt;&lt;/p&gt;&lt;figure&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A new report from Deloitte has warned that businesses are deploying AI agents faster than their safety protocols and safeguards can keep up. Therefore, serious concerns around security, data privacy, and accountability are spreading.&lt;/p&gt;&lt;p&gt;According to the survey, agentic systems are moving from pilot to production so quickly that traditional risk controls, which were designed for more human-centred operations, are struggling to meet security demands.&lt;/p&gt;&lt;p&gt;Just 21% of organisations have implemented stringent governance or oversight for AI agents, despite the increased rate of adoption. Whilst 23% of companies stated that they are currently using AI agents, this is expected to rise to 74% in the next two years. The share of businesses yet to adopt this technology is expected to fall from 25% to just 5% over the same period.&lt;/p&gt;&lt;h4&gt;Poor governance is the threat&lt;/h4&gt;&lt;p&gt;Deloitte is not highlighting AI agents as inherently dangerous, but states the real risks are associated with poor context and weak governance. If agents operate as their own entities, their decisions and actions can easily become opaque. Without robust governance, it becomes difficult to manage and almost impossible to insure against mistakes.&lt;/p&gt;&lt;p&gt;According to Ali Sarrafi, CEO &amp;amp; Founder of Kovant, the answer is governed autonomy. “Well-designed agents with clear boundaries, policies and definitions managed the same way as an enterprise manages any worker can move fast on low-risk work inside clear guardrails, but escalate to humans when actions cross defined risk thresholds.”&lt;/p&gt;&lt;p&gt;“With detailed action logs, observability, and human gatekeeping for high-impact decisions, agents stop being mysterious bots and become systems you can inspect, audit, and trust.”&lt;/p&gt;&lt;p&gt;As Deloitte’s report suggests, AI agent adoption is set to accelerate in the coming years, and only the companies that deploy the technology with visibility and control will hold the upper hand over competitors, not those who deploy them quickest.&lt;/p&gt;&lt;h4&gt;Why AI agents require robust guardrails&lt;/h4&gt;&lt;p&gt;AI agents may perform well in controlled demos, but they struggle in real-world business settings where systems can be fragmented and data may be inconsistent.&lt;/p&gt;&lt;p&gt;Sarrafi commented on the unpredictable nature of AI agents in these scenarios. “When an agent is given too much context or scope at once, it becomes prone to hallucinations and unpredictable behaviour.”&lt;/p&gt;&lt;p&gt;“By contrast, production-grade systems limit the decision and context scope that models work with. They decompose operations into narrower, focused tasks for individual agents, making behaviour more predictable and easier to control. This structure also enables traceability and intervention, so failures can be detected early and escalated appropriately rather than causing cascading errors.”&lt;/p&gt;&lt;h4&gt;Accountability for insurable AI&lt;/h4&gt;&lt;p&gt;With agents taking real actions in business systems, such as keeping detailed action logs, risk and compliance are viewed differently. With every action recorded, agents’ activities become clear and evaluable, letting organisations inspect actions in detail.&lt;/p&gt;&lt;p&gt;Such transparency is crucial for insurers, who are reluctant to cover opaque AI systems. This level of detail helps insurers understand what agents have done, and the controls involved, thus making it easier to assess risk. With human oversight for risk-critical actions and auditable, replayable workflows, organisations can produce systems that are more manageable for risk assessment.&lt;/p&gt;&lt;h4&gt;AAIF standards a good first step&lt;/h4&gt;&lt;p&gt;Shared standards, like those being developed by the Agentic AI Foundation (AAIF), help businesses to integrate different agent systems, but current standardisation efforts focus on what is simplest to build, not what larger organisations need to operate agentic systems safely.&lt;/p&gt;&lt;p&gt;Sarrafi says enterprises require standards that support operation control, and which include, “access permissions, approval workflows for high-impact actions, and auditable logs and observability, so teams can monitor behaviour, investigate incidents, and prove compliance.”&lt;/p&gt;&lt;h4&gt;Identity and permissions the first line of defence&lt;/h4&gt;&lt;p&gt;Limiting what AI agents can access and the actions they can perform is important to ensure safety in real business environments. Sarrafi said, “When agents are given broad privileges or too much context, they become unpredictable and pose security or compliance risks.”&lt;/p&gt;&lt;p&gt;Visibility and monitoring are important to keep agents operating inside limits. Only then can stakeholders have confidence in the adoption of the technology. If every action is logged and manageable, teams can then see what has happened, identify issues, and better understand why events occurred.&lt;/p&gt;&lt;p&gt;Sarrafi continued, “This visibility, combined with human supervision where it matters, turns AI agents from inscrutable components into systems that can be inspected, replayed and audited. It also allows rapid investigation and correction when issues arise, which boosts trust among operators, risk teams and insurers alike.”&lt;/p&gt;&lt;h4&gt;Deloitte’s blueprint&lt;/h4&gt;&lt;p&gt;Deloitte’s strategy for safe AI agent governance sets out defined boundaries for the decisions agentic systems can make. For instance, they might operate with tiered autonomy, where agents can only view information or offer suggestions. From here, they can be allowed to take limited actions, but with human approval. Once they have proven to be reliable in low-risk areas, they can be allowed to act automatically.&lt;/p&gt;&lt;p&gt;Deloitte’s “Cyber AI Blueprints” suggest governance layers and embedding policies and compliance capability roadmaps into organisational controls. Ultimately, governance structures that track AI use and risk, and embedding oversight into daily operations are important for safe agentic AI use.&lt;/p&gt;&lt;p&gt;Readying workforces with training is another aspect of safe governance. Deloitte recommends training employees on what they shouldn’t share with AI systems, what to do if agents go off track, and how to spot unusual, potentially dangerous behaviour. If employees fail to understand how AI systems work and their potential risks, they may weaken security controls, albeit unintentionally.&lt;/p&gt;&lt;p&gt;Robust governance and control, alongside shared literacy are fundamental to the safe deployment and operation of AI agents, enabling secure, compliant, and accountable performance in real-world environments&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Global Hawk, NASA’s New Remote-Controlled Plane” by NASA Goddard Photo and Video is licensed under CC BY 2.0. )&lt;/em&gt;&lt;/p&gt;&lt;figure&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deloitte-agentic-ai-guidelines-published/</guid><pubDate>Wed, 28 Jan 2026 15:23:00 +0000</pubDate></item><item><title>[NEW] Roundtables: Why AI Companies Are Betting on Next-Gen Nuclear (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/28/1131340/roundtables-why-ai-companies-are-betting-on-next-gen-nuclear/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/MITTR-Roundtables-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;Available only for MIT Alumni and subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;AI is driving unprecedented investment for massive data centers and an energy supply that can support its huge computational appetite. One potential source of electricity for these facilities is next-generation nuclear power plants, which could be cheaper to construct and safer to operate than their predecessors.&lt;/p&gt;  &lt;p&gt;Watch a discussion with our editors and reporters on hyperscale AI data centers and next-gen nuclear—two featured technologies on the MIT Technology Review &lt;em&gt;10 Breakthrough Technologies of 2026&lt;/em&gt; list.&lt;br /&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_3"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;  &lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;Recorded on January 28, 2026&lt;br /&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Stories: &lt;/strong&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/MITTR-Roundtables-Zoom-Opening-Overlay.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;Available only for MIT Alumni and subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;AI is driving unprecedented investment for massive data centers and an energy supply that can support its huge computational appetite. One potential source of electricity for these facilities is next-generation nuclear power plants, which could be cheaper to construct and safer to operate than their predecessors.&lt;/p&gt;  &lt;p&gt;Watch a discussion with our editors and reporters on hyperscale AI data centers and next-gen nuclear—two featured technologies on the MIT Technology Review &lt;em&gt;10 Breakthrough Technologies of 2026&lt;/em&gt; list.&lt;br /&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 core-embed_3"&gt;
&lt;figure class="wp-block-embed is-type-video is-provider-vimeo wp-block-embed-vimeo wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
[embedded content]

&lt;/div&gt;&lt;/figure&gt;
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;  &lt;p&gt;&lt;strong&gt;&lt;em&gt;&lt;strong&gt;Recorded on January 28, 2026&lt;br /&gt;&lt;/strong&gt;&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Related Stories: &lt;/strong&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/28/1131340/roundtables-why-ai-companies-are-betting-on-next-gen-nuclear/</guid><pubDate>Wed, 28 Jan 2026 16:23:00 +0000</pubDate></item><item><title>With Apple’s new Creator Studio Pro, AI is a tool to aid creation, not replace it (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/with-apples-new-creator-studio-pro-ai-is-a-tool-to-aid-creation-not-replace-it/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Generative AI apps that can create photos, videos, songs, and more are growing in popularity. But with the release of Apple’s new Creator Studio Pro suite, available to the public on Wednesday, the tech giant has approached the addition of AI as a tool that aids in the creator process but doesn’t attempt to replace it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, Apple lays out a vision that suggests the productivity suite of the future is the one that focuses on the needs of creators — whether that’s filmmakers, musicians, artists, or anyone else enmeshed in a creative industry of some kind — and empowers them to be more efficient using AI. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s tricky to bring AI into the world of creativity, given the backlash and even legal action from creators who are angry about AI models training on their works, then reproducing similar art or creative content in the AI systems’ output.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084115" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-lifestyle-Final-Cut-Pro.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Apple, however, sees AI as a tool that handles more of the basics and tedious tasks — like generating a slideshow for you to edit from your notes, extracting chord information from a song, searching across hours of video footage for the clip you need, changing the camera angle on your images, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tools in Creator Studio Pro are not new, but they’ve never been packaged as a subscription product, which is now available at $12.99 per month or $129 per year. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084122" height="455" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Final-Cut-Pro-Transcript-Search.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Included in the subscription are Final Cut Pro, Motion, and Compressor for video editing; Logic Pro and MainStage for music creation; image editing tool Pixelmator Pro; and a set of exclusive features in Keynote, Pages, Numbers, and Freeform. The suite also includes the newly launched Pixelmator Pro app for iPad.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Apple’s traditional productivity software applications haven’t caught up to those from Google and Microsoft, the tech giant has always found more success in the creative fields. And with the addition of AI features, the company likely sees the possibility of making its creative software more accessible to those who aren’t fully professionals — like an indie musician or artist who wants to improve their marketing and sales, those who quickly compile video footage to post on social media, or those who want to create music or art and edit the output.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Whether Apple’s tools are the right ones for the job compared with Adobe products will depend on the user’s specific needs and their familiarity with professional creative tools. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Each tool in the suite has received its own series of upgrades timed with this launch, both AI and otherwise. Notable additions include:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Final Cut Pro:&lt;/strong&gt; AI-powered transcript search for finding the right soundbite across hours of footage; AI-powered visual search assistant, allowing users to search for an object or action to add to their timeline; beat detection to edit to the rhythm of music, which uses an AI model to analyze music tracks; a new Montage Maker on iPad for easily making highlight videos from footage; multiple selection support for batch edits, background export, and external monitor playback on iPad; access to content to enhance videos, like graphics, dynamic titles, and more.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084128" height="455" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Final-Cut-Pro-Beat-Detection.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Logic Pro:&lt;/strong&gt; A new synth player feature, built from performances, adds a virtual Session Player that can play synth keyboard and bass parts; Chord ID, which uses AI to analyze audio to extract chord information; sound packs and producer packs come to the Mac with the expansion of the Sound Library; the iPad app also gets new features like Quick Swipe Comping to assemble recordings in different ways than were captured; and an AI-powered understanding of the loop library for finding the right sound.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084112" height="455" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Logic-Pro-Chord-ID.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Pixelmator Pro for Mac and iPad: &lt;/strong&gt;The app, which is now available on iPad, already offers a number of AI features like those to upscale images (Super Resolution), offer composition suggestions (Auto Crop), remove artifacts, retouch, and more. With the Creator Suite launch, the app gets a new Liquid Glass design to match the rest of Apple’s software, a new Warp tool for reshaping layers, and Warp-powered mock-ups to preview designs for apparel or other products in real-world imagery.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084105" height="514" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Pixelmator-Layers-sidebar.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Keynote, Pages, Numbers, and Freeform:&lt;/strong&gt; These general-purpose productivity apps are gaining new features for Creator Studio subscribers, including new premium templates and themes in Keynote, Pages, and Numbers, and an image and graphic library across all four apps, dubbed the Content Hub; an AI-powered image generation and remixing feature lets creators pick from prebuilt configuration options to change the style, orientation, or camera angle for their photos, graphics, icons, or other visual concept; other AI tools can enhance images (using the Super Resolution feature) or make composition suggestions.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3084119" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Keynote-Content-Hub.png?w=547" width="547" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Keynote&lt;/strong&gt;, specifically, adds several AI features, including a new tool that uses your text notes as a starting point to create a slideshow from scratch; AI can also generate your presenter notes and clean up your slide content.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084116" height="464" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Keynote-Presenter-Notes.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Numbers&lt;/strong&gt;, meanwhile, can use AI to analyze patterns in your spreadsheet data and make suggestions for table contents (Magic Fill). It can also generate a formula to describe what it generated, so you can learn how it works.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Apple says it will continue to offer its creativity apps as stand-alone downloads, and existing users will still get updates, including these new features. Meanwhile, Keynote, Pages, Numbers, and Freeform will remain free apps, but the new, premium features will be locked behind the subscription. It’s an interesting choice to allow users to choose to purchase apps outright, as before, as that differentiates Apple’s offering from others, like Adobe.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition, Apple lets users share their apps through Family Sharing with up to five family members, which Adobe doesn’t offer. Users can also cancel their subscription at any time, without penalty. However, Adobe remains a fierce competitor with its expansive and detailed tools, which also run on iOS. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of the AI features are powered by Apple Intelligence, like the visual and transcript search in Final Cut Pro, which runs locally on the device. Others involve the use of third parties, like OpenAI, which powers things like advanced image generation, Keynote slides, and presenter notes. Creator Studio’s AI features either are processed on the device or use a private relay to anonymize the traffic. Apple says these protections mean users’ content is kept private and never used for AI training.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Generative AI apps that can create photos, videos, songs, and more are growing in popularity. But with the release of Apple’s new Creator Studio Pro suite, available to the public on Wednesday, the tech giant has approached the addition of AI as a tool that aids in the creator process but doesn’t attempt to replace it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, Apple lays out a vision that suggests the productivity suite of the future is the one that focuses on the needs of creators — whether that’s filmmakers, musicians, artists, or anyone else enmeshed in a creative industry of some kind — and empowers them to be more efficient using AI. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s tricky to bring AI into the world of creativity, given the backlash and even legal action from creators who are angry about AI models training on their works, then reproducing similar art or creative content in the AI systems’ output.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084115" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-lifestyle-Final-Cut-Pro.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Apple, however, sees AI as a tool that handles more of the basics and tedious tasks — like generating a slideshow for you to edit from your notes, extracting chord information from a song, searching across hours of video footage for the clip you need, changing the camera angle on your images, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The tools in Creator Studio Pro are not new, but they’ve never been packaged as a subscription product, which is now available at $12.99 per month or $129 per year. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084122" height="455" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Final-Cut-Pro-Transcript-Search.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Included in the subscription are Final Cut Pro, Motion, and Compressor for video editing; Logic Pro and MainStage for music creation; image editing tool Pixelmator Pro; and a set of exclusive features in Keynote, Pages, Numbers, and Freeform. The suite also includes the newly launched Pixelmator Pro app for iPad.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Apple’s traditional productivity software applications haven’t caught up to those from Google and Microsoft, the tech giant has always found more success in the creative fields. And with the addition of AI features, the company likely sees the possibility of making its creative software more accessible to those who aren’t fully professionals — like an indie musician or artist who wants to improve their marketing and sales, those who quickly compile video footage to post on social media, or those who want to create music or art and edit the output.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Whether Apple’s tools are the right ones for the job compared with Adobe products will depend on the user’s specific needs and their familiarity with professional creative tools. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Each tool in the suite has received its own series of upgrades timed with this launch, both AI and otherwise. Notable additions include:&lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Final Cut Pro:&lt;/strong&gt; AI-powered transcript search for finding the right soundbite across hours of footage; AI-powered visual search assistant, allowing users to search for an object or action to add to their timeline; beat detection to edit to the rhythm of music, which uses an AI model to analyze music tracks; a new Montage Maker on iPad for easily making highlight videos from footage; multiple selection support for batch edits, background export, and external monitor playback on iPad; access to content to enhance videos, like graphics, dynamic titles, and more.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084128" height="455" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Final-Cut-Pro-Beat-Detection.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Logic Pro:&lt;/strong&gt; A new synth player feature, built from performances, adds a virtual Session Player that can play synth keyboard and bass parts; Chord ID, which uses AI to analyze audio to extract chord information; sound packs and producer packs come to the Mac with the expansion of the Sound Library; the iPad app also gets new features like Quick Swipe Comping to assemble recordings in different ways than were captured; and an AI-powered understanding of the loop library for finding the right sound.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084112" height="455" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Logic-Pro-Chord-ID.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Pixelmator Pro for Mac and iPad: &lt;/strong&gt;The app, which is now available on iPad, already offers a number of AI features like those to upscale images (Super Resolution), offer composition suggestions (Auto Crop), remove artifacts, retouch, and more. With the Creator Suite launch, the app gets a new Liquid Glass design to match the rest of Apple’s software, a new Warp tool for reshaping layers, and Warp-powered mock-ups to preview designs for apparel or other products in real-world imagery.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084105" height="514" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Pixelmator-Layers-sidebar.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Keynote, Pages, Numbers, and Freeform:&lt;/strong&gt; These general-purpose productivity apps are gaining new features for Creator Studio subscribers, including new premium templates and themes in Keynote, Pages, and Numbers, and an image and graphic library across all four apps, dubbed the Content Hub; an AI-powered image generation and remixing feature lets creators pick from prebuilt configuration options to change the style, orientation, or camera angle for their photos, graphics, icons, or other visual concept; other AI tools can enhance images (using the Super Resolution feature) or make composition suggestions.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3084119" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Keynote-Content-Hub.png?w=547" width="547" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Keynote&lt;/strong&gt;, specifically, adds several AI features, including a new tool that uses your text notes as a starting point to create a slideshow from scratch; AI can also generate your presenter notes and clean up your slide content.&lt;/li&gt;
&lt;/ul&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3084116" height="464" src="https://techcrunch.com/wp-content/uploads/2026/01/Apple-Creator-Studio-Keynote-Presenter-Notes.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Apple&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;&lt;strong&gt;Numbers&lt;/strong&gt;, meanwhile, can use AI to analyze patterns in your spreadsheet data and make suggestions for table contents (Magic Fill). It can also generate a formula to describe what it generated, so you can learn how it works.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;Apple says it will continue to offer its creativity apps as stand-alone downloads, and existing users will still get updates, including these new features. Meanwhile, Keynote, Pages, Numbers, and Freeform will remain free apps, but the new, premium features will be locked behind the subscription. It’s an interesting choice to allow users to choose to purchase apps outright, as before, as that differentiates Apple’s offering from others, like Adobe.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition, Apple lets users share their apps through Family Sharing with up to five family members, which Adobe doesn’t offer. Users can also cancel their subscription at any time, without penalty. However, Adobe remains a fierce competitor with its expansive and detailed tools, which also run on iOS. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some of the AI features are powered by Apple Intelligence, like the visual and transcript search in Final Cut Pro, which runs locally on the device. Others involve the use of third parties, like OpenAI, which powers things like advanced image generation, Keynote slides, and presenter notes. Creator Studio’s AI features either are processed on the device or use a private relay to anonymize the traffic. Apple says these protections mean users’ content is kept private and never used for AI training.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/with-apples-new-creator-studio-pro-ai-is-a-tool-to-aid-creation-not-replace-it/</guid><pubDate>Wed, 28 Jan 2026 17:04:50 +0000</pubDate></item><item><title>Report: China approves import of high-end Nvidia AI chips after weeks of uncertainty (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/report-china-approves-import-of-high-end-nvidia-ai-chips-after-weeks-of-uncertainty/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Over 400,000 H200 chips coming to tech giants as China tries to balance tech needs with self-reliance.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Digitally Generated Image , 3D rendered chips with chinese and USA flags on them" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2131985696-1536x864-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Digitally Generated Image , 3D rendered chips with chinese and USA flags on them" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2131985696-1536x864-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, China approved imports of Nvidia’s H200 artificial intelligence chips for three of its largest technology companies, Reuters reported. ByteDance, Alibaba, and Tencent received approval to purchase more than 400,000 H200 chips in total, marking a shift in Beijing’s stance after weeks of holding up shipments despite US export clearance.&lt;/p&gt;
&lt;p&gt;The move follows Beijing’s temporary halt to H200 shipments earlier this month after Washington cleared exports on January 13. Chinese customs authorities had told agents that the H200 chips were not permitted to enter China, Reuters reported earlier this month, even as Chinese technology companies placed orders for more than two million of the chips.&lt;/p&gt;
&lt;p&gt;The H200, Nvidia’s second most powerful AI chip after the B200, delivers roughly six times the performance of the company’s H20 chip, which was previously the most capable chip Nvidia could sell to China. While Chinese companies such as Huawei now have products that rival the H20’s performance, they still lag far behind the H200.&lt;/p&gt;
&lt;p&gt;Chinese tech giants want access to Nvidia’s higher-powered AI chips because they dramatically speed up the process of training large AI models, a computationally intensive task of feeding data through neural networks millions of times to tune their performance. More capable chips like the H200 allow companies to train larger models faster or run more AI queries (called inference) at a lower cost.&lt;/p&gt;
&lt;p&gt;This has made high-end AI accelerator chips a flashpoint in the ongoing AI race between Washington, DC, and Beijing, with US policymakers caught between wanting to boost sales for American semiconductor companies and fearing that exports could help China close the gap in AI capabilities.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, Nvidia wants the business because China is a huge market. The latest approvals came during Nvidia CEO Jensen Huang’s visit to China this week, according to sources who spoke with Reuters on the condition of anonymity. Other Chinese firms are now waiting for their own approvals in future rounds, though Beijing is attaching conditions to the licenses that have not yet been finalized. One source told Reuters that the license terms were too restrictive and buyers had not yet turned their approvals into actual orders.&lt;/p&gt;
&lt;h2&gt;Beijing’s balancing act&lt;/h2&gt;
&lt;p&gt;The approval signals Beijing’s prioritization of its major Internet companies, which are spending billions of dollars to build data centers needed to develop AI services and compete with US rivals, including OpenAI. But regulators are also trying to nurture China’s domestic semiconductor industry, the South China Morning Post reported.&lt;/p&gt;
&lt;p&gt;The first batch was expected to go to Big Tech companies in urgent need of the GPU, according to a source who spoke with that publication. However, access for state-backed firms, including telecom operators, was expected to stay tightly restricted.&lt;/p&gt;
&lt;p&gt;Beijing has previously discouraged domestic technology companies from purchasing foreign chips unless absolutely needed, according to earlier Reuters reporting. One proposal authorities discussed in the past would require each H200 purchase to be bundled with a set ratio of domestic chips.&lt;/p&gt;
&lt;p&gt;“Beijing’s approval of the H200 is driven by purely strategic motives,” Alex Capri, a senior lecturer at the National University of Singapore’s business school, told the South China Morning Post. “Ultimately, this decision is taken to further China’s indigenous capabilities and, by extension, the competitive capabilities of China tech.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Over 400,000 H200 chips coming to tech giants as China tries to balance tech needs with self-reliance.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Digitally Generated Image , 3D rendered chips with chinese and USA flags on them" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2131985696-1536x864-1-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Digitally Generated Image , 3D rendered chips with chinese and USA flags on them" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2131985696-1536x864-1-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, China approved imports of Nvidia’s H200 artificial intelligence chips for three of its largest technology companies, Reuters reported. ByteDance, Alibaba, and Tencent received approval to purchase more than 400,000 H200 chips in total, marking a shift in Beijing’s stance after weeks of holding up shipments despite US export clearance.&lt;/p&gt;
&lt;p&gt;The move follows Beijing’s temporary halt to H200 shipments earlier this month after Washington cleared exports on January 13. Chinese customs authorities had told agents that the H200 chips were not permitted to enter China, Reuters reported earlier this month, even as Chinese technology companies placed orders for more than two million of the chips.&lt;/p&gt;
&lt;p&gt;The H200, Nvidia’s second most powerful AI chip after the B200, delivers roughly six times the performance of the company’s H20 chip, which was previously the most capable chip Nvidia could sell to China. While Chinese companies such as Huawei now have products that rival the H20’s performance, they still lag far behind the H200.&lt;/p&gt;
&lt;p&gt;Chinese tech giants want access to Nvidia’s higher-powered AI chips because they dramatically speed up the process of training large AI models, a computationally intensive task of feeding data through neural networks millions of times to tune their performance. More capable chips like the H200 allow companies to train larger models faster or run more AI queries (called inference) at a lower cost.&lt;/p&gt;
&lt;p&gt;This has made high-end AI accelerator chips a flashpoint in the ongoing AI race between Washington, DC, and Beijing, with US policymakers caught between wanting to boost sales for American semiconductor companies and fearing that exports could help China close the gap in AI capabilities.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, Nvidia wants the business because China is a huge market. The latest approvals came during Nvidia CEO Jensen Huang’s visit to China this week, according to sources who spoke with Reuters on the condition of anonymity. Other Chinese firms are now waiting for their own approvals in future rounds, though Beijing is attaching conditions to the licenses that have not yet been finalized. One source told Reuters that the license terms were too restrictive and buyers had not yet turned their approvals into actual orders.&lt;/p&gt;
&lt;h2&gt;Beijing’s balancing act&lt;/h2&gt;
&lt;p&gt;The approval signals Beijing’s prioritization of its major Internet companies, which are spending billions of dollars to build data centers needed to develop AI services and compete with US rivals, including OpenAI. But regulators are also trying to nurture China’s domestic semiconductor industry, the South China Morning Post reported.&lt;/p&gt;
&lt;p&gt;The first batch was expected to go to Big Tech companies in urgent need of the GPU, according to a source who spoke with that publication. However, access for state-backed firms, including telecom operators, was expected to stay tightly restricted.&lt;/p&gt;
&lt;p&gt;Beijing has previously discouraged domestic technology companies from purchasing foreign chips unless absolutely needed, according to earlier Reuters reporting. One proposal authorities discussed in the past would require each H200 purchase to be bundled with a set ratio of domestic chips.&lt;/p&gt;
&lt;p&gt;“Beijing’s approval of the H200 is driven by purely strategic motives,” Alex Capri, a senior lecturer at the National University of Singapore’s business school, told the South China Morning Post. “Ultimately, this decision is taken to further China’s indigenous capabilities and, by extension, the competitive capabilities of China tech.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/report-china-approves-import-of-high-end-nvidia-ai-chips-after-weeks-of-uncertainty/</guid><pubDate>Wed, 28 Jan 2026 17:21:29 +0000</pubDate></item><item><title>Tiny startup Arcee AI built a 400B-parameter open source LLM from scratch to best Meta’s Llama (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/tiny-startup-arcee-ai-built-a-400b-open-source-llm-from-scratch-to-best-metas-llama/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Many in the industry think the winners of the AI model market have already been decided: Big Tech will own it (Google, Meta, Microsoft, a bit of Amazon) along with their model makers of choice, largely OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But tiny 30-person startup Arcee AI disagrees. The company just released a truly and permanently open (Apache license) general-purpose, foundation model called Trinity, and Arcee claims that at 400B parameters, it is among the largest open source foundation models ever trained and released by a U.S. company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Arcee says Trinity compares to Meta’s Llama 4 Maverick 400B, and Z.ai’s GLM-4.5, a high-performing open source model from China’s Tsinghua University, according to benchmark tests conducted using base models (very little post-training).&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Arcee AI benchmarks for Trinity LLM" class="wp-image-3086962" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/Arcee-Benchmarks-trinity-large-preview-base.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Arcee AI benchmarks for its Trinity large LLM (preview version, base model)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Arcee AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like other state-of-the-art (SOTA) models, Trinity is geared for coding and multi-step processes like agents. Still, despite its size, it’s not a true SOTA competitor yet because it currently supports only text. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More modes are in the works — a vision model is currently in development, and a speech-to-text version is on the roadmap, CTO Lucas Atkins told TechCrunch (pictured above, on the left). In comparison, Meta’s Llama 4 Maverick is already multi-modal, supporting text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But before adding more AI modes to its roster, Arcee says, it wanted a base LLM that would impress its main target customers: developers and academics. The team particularly wants to woo U.S. companies of all sizes away from choosing open models from China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ultimately, the winners of this game, and the only way to really win over the usage, is to have the best open-weight model,” Atkins said. “To win the hearts and minds of developers, you have to give them the best.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmarks show that the Trinity base model, currently in preview while more post-training takes place, is largely holding its own and, in some cases, slightly besting Llama on tests of coding and math, common sense, knowledge, and reasoning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The progress Arcee has made so far to become a competitive AI Lab is impressive. The large Trinity model follows two previous small models released in December: the 26B-parameter Trinity Mini, a fully post-trained reasoning model for tasks ranging from web apps to agents, and the 6B-parameter Trinity Nano, an experimental model designed to push the boundaries of models that are tiny yet chatty.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The kicker is, Arcee trained them all in six months for $20 million total, using 2,048 Nvidia Blackwell B300 GPUs. This out of the roughly $50 million the company has raised so far, said founder and CEO Mark McQuade (pictured above, on the right).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That kind of cash was “a lot for us,” said Atkins, who led the model-building effort. Still, he acknowledged that it pales in comparison to how much bigger labs are spending right now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The six-month timeline “was very calculated,” said Atkins, whose career before LLMs involved building voice agents for cars. “We are a younger startup that’s extremely hungry. We have a tremendous amount of talent and bright young researchers who, when given the opportunity to spend this amount of money and train a model of this size, we trusted that they’d rise to the occasion. And they certainly did, with many sleepless nights, many long hours.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;McQuade, previously an early employee at open source model marketplace Hugging Face, says Arcee didn’t start out wanting to become a new U.S. AI lab:&amp;nbsp;The company was originally doing model customization for large enterprise clients like SK Telecom.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We were only doing post-training. So we would take the great work of others: We would take a Llama model, we would take a Mistral model, we would take a Qwen model that was open source, and we would post-train it to make it better” for a company’s intended use, he said, including doing the reinforcement learning.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But as their client list grew, Atkins said, the need for their own model was becoming a necessity, and McQuade was worried about relying on other companies. At the same time, many of the best open models were coming from China, which U.S. enterprises were leery of, or were barred from using.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was a nerve-wracking decision. “I think there’s less than 20 companies in the world that have ever pre-trained and released their own model” at the size and level that Arcee was gunning for, McQuade said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company started small at first, trying its hand at a tiny, 4.5B model created in partnership with training company DatologyAI. The project’s success then encouraged bigger endeavors.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But if the U.S. already has Llama, why does it need another open weight model? Atkins says by choosing the open source Apache license, the startup is committed to always keeping its models open. This comes after Meta CEO Mark Zuckerberg last year indicated his company might not always make all of its most advanced models open source.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Llama can be looked at as not truly open source as it uses a Meta-controlled license with commercial and usage caveats,” he says. This has caused some open source organizations to claim that Llama isn’t open source compliant at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Arcee exists because the U.S. needs a permanently open, Apache-licensed, frontier-grade alternative that can actually compete at today’s frontier,” McQuade said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;All Trinity models, large and small, can be downloaded for free. The largest version will be released in three flavors. Trinity Large Preview is a lightly post-trained instruct model, meaning it’s been trained to follow human instructions, not just predict the next word, which gears it for general chat usage. Trinity Large Base&amp;nbsp;is the base model without post-training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then we have TrueBase,&amp;nbsp;a model with any instruct data or post training so enterprises or researchers that want to customize it won’t have to unroll any data, rules, or assumptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Arcee AI will eventually offer a hosted version of its general-release model for, it says, competitive API pricing. That release is up to six weeks away as the startup continues to improve the model’s reasoning training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;API pricing for Trinity Mini is $0.045 / $0.15, and there is a rate-limited&amp;nbsp;free tier available, too.&amp;nbsp;Meanwhile, the company still sells post-training and customization options.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Many in the industry think the winners of the AI model market have already been decided: Big Tech will own it (Google, Meta, Microsoft, a bit of Amazon) along with their model makers of choice, largely OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But tiny 30-person startup Arcee AI disagrees. The company just released a truly and permanently open (Apache license) general-purpose, foundation model called Trinity, and Arcee claims that at 400B parameters, it is among the largest open source foundation models ever trained and released by a U.S. company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Arcee says Trinity compares to Meta’s Llama 4 Maverick 400B, and Z.ai’s GLM-4.5, a high-performing open source model from China’s Tsinghua University, according to benchmark tests conducted using base models (very little post-training).&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="Arcee AI benchmarks for Trinity LLM" class="wp-image-3086962" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/Arcee-Benchmarks-trinity-large-preview-base.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Arcee AI benchmarks for its Trinity large LLM (preview version, base model)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Arcee AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Like other state-of-the-art (SOTA) models, Trinity is geared for coding and multi-step processes like agents. Still, despite its size, it’s not a true SOTA competitor yet because it currently supports only text. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More modes are in the works — a vision model is currently in development, and a speech-to-text version is on the roadmap, CTO Lucas Atkins told TechCrunch (pictured above, on the left). In comparison, Meta’s Llama 4 Maverick is already multi-modal, supporting text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But before adding more AI modes to its roster, Arcee says, it wanted a base LLM that would impress its main target customers: developers and academics. The team particularly wants to woo U.S. companies of all sizes away from choosing open models from China.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ultimately, the winners of this game, and the only way to really win over the usage, is to have the best open-weight model,” Atkins said. “To win the hearts and minds of developers, you have to give them the best.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The benchmarks show that the Trinity base model, currently in preview while more post-training takes place, is largely holding its own and, in some cases, slightly besting Llama on tests of coding and math, common sense, knowledge, and reasoning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The progress Arcee has made so far to become a competitive AI Lab is impressive. The large Trinity model follows two previous small models released in December: the 26B-parameter Trinity Mini, a fully post-trained reasoning model for tasks ranging from web apps to agents, and the 6B-parameter Trinity Nano, an experimental model designed to push the boundaries of models that are tiny yet chatty.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The kicker is, Arcee trained them all in six months for $20 million total, using 2,048 Nvidia Blackwell B300 GPUs. This out of the roughly $50 million the company has raised so far, said founder and CEO Mark McQuade (pictured above, on the right).&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That kind of cash was “a lot for us,” said Atkins, who led the model-building effort. Still, he acknowledged that it pales in comparison to how much bigger labs are spending right now.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The six-month timeline “was very calculated,” said Atkins, whose career before LLMs involved building voice agents for cars. “We are a younger startup that’s extremely hungry. We have a tremendous amount of talent and bright young researchers who, when given the opportunity to spend this amount of money and train a model of this size, we trusted that they’d rise to the occasion. And they certainly did, with many sleepless nights, many long hours.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;McQuade, previously an early employee at open source model marketplace Hugging Face, says Arcee didn’t start out wanting to become a new U.S. AI lab:&amp;nbsp;The company was originally doing model customization for large enterprise clients like SK Telecom.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We were only doing post-training. So we would take the great work of others: We would take a Llama model, we would take a Mistral model, we would take a Qwen model that was open source, and we would post-train it to make it better” for a company’s intended use, he said, including doing the reinforcement learning.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But as their client list grew, Atkins said, the need for their own model was becoming a necessity, and McQuade was worried about relying on other companies. At the same time, many of the best open models were coming from China, which U.S. enterprises were leery of, or were barred from using.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It was a nerve-wracking decision. “I think there’s less than 20 companies in the world that have ever pre-trained and released their own model” at the size and level that Arcee was gunning for, McQuade said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company started small at first, trying its hand at a tiny, 4.5B model created in partnership with training company DatologyAI. The project’s success then encouraged bigger endeavors.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But if the U.S. already has Llama, why does it need another open weight model? Atkins says by choosing the open source Apache license, the startup is committed to always keeping its models open. This comes after Meta CEO Mark Zuckerberg last year indicated his company might not always make all of its most advanced models open source.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Llama can be looked at as not truly open source as it uses a Meta-controlled license with commercial and usage caveats,” he says. This has caused some open source organizations to claim that Llama isn’t open source compliant at all.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Arcee exists because the U.S. needs a permanently open, Apache-licensed, frontier-grade alternative that can actually compete at today’s frontier,” McQuade said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;All Trinity models, large and small, can be downloaded for free. The largest version will be released in three flavors. Trinity Large Preview is a lightly post-trained instruct model, meaning it’s been trained to follow human instructions, not just predict the next word, which gears it for general chat usage. Trinity Large Base&amp;nbsp;is the base model without post-training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Then we have TrueBase,&amp;nbsp;a model with any instruct data or post training so enterprises or researchers that want to customize it won’t have to unroll any data, rules, or assumptions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Arcee AI will eventually offer a hosted version of its general-release model for, it says, competitive API pricing. That release is up to six weeks away as the startup continues to improve the model’s reasoning training.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;API pricing for Trinity Mini is $0.045 / $0.15, and there is a rate-limited&amp;nbsp;free tier available, too.&amp;nbsp;Meanwhile, the company still sells post-training and customization options.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/tiny-startup-arcee-ai-built-a-400b-open-source-llm-from-scratch-to-best-metas-llama/</guid><pubDate>Wed, 28 Jan 2026 17:30:00 +0000</pubDate></item><item><title>Chrome takes on AI browsers with tighter Gemini integration, agentic features for autonomous tasks (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/chrome-takes-on-ai-browsers-with-tighter-gemini-integration-agentic-features-for-autonomous-tasks/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Last year, a swarm of AI browsers from companies like OpenAI, Perplexity, Opera, and The Browser Company launched with the aim to replace Chrome with features like sidebar assistants and automated tasks. Now Google is flexing its own AI muscle by adding similar features to Chrome, the world’s largest browser by market share.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google had introduced Gemini to Chrome last September, the assistant lived in a floating window. With this update, the company will put its AI helper into a persistent sidebar, so you can ask questions about the current website or other open tabs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One interesting feature Google demoed to press ahead of today’s launch involved multiple tabs. When you open different tabs from a single web page, the Gemini sidebar understands them as a context group. This is helpful when you are comparing prices or different products you’re considering purchasing.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3087116" height="484" src="https://techcrunch.com/wp-content/uploads/2026/01/Still_Gemini-in-Chrome-Side-Panel-1.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Before today, the Gemini in Chrome feature was available only to Windows and macOS users. With this rollout, the sidebar will be available to Chromebook Plus users as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also taking advantage of its newly launched personal intelligence feature, which connects to your Gmail, Search, YouTube, and Google Photos accounts, allowing you to ask questions based on your own data. This feature will roll out in Chrome in the coming months, meaning that you can ask Gemini in the sidebar about things like your family’s schedule, or ask it to draft an email and send it without switching to Gmail.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a new Nano Banana integration coming to Chrome, too, that allows you to modify an existing image with another image or product that you find while browsing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the most ambitious feature is called auto-browse, which aims to handle tasks for you by using your personal information and traversing websites on your behalf. For instance, you can ask the agentic feature to go to a particular website and buy an item for you, and find a discount coupon. The agent will ask for your intervention when performing data-sensitive tasks, such as logging into a website or making a final purchase. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, the company explained that these features would use Chrome’s password manager or saved card details, but said its AI models wouldn’t be exposed to any of these details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This feature is rolling out initially to AI Pro and Ultra subscribers in the U.S. &lt;/p&gt;

&lt;div class="jwppp-video-box" id="jwppp-video-box-30865141"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;







&lt;p class="wp-block-paragraph"&gt;Browser-based agents are finicky and often fail to complete tasks. Google’s demo, just like tons of other AI demos, involved shopping and travel planning. In real-world use cases, agents often don’t get the intent or break during traversing different sites, and that would be a challenge for wider adoption.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that in its early testing, users have used the feature for tasks such as scheduling appointments, filling out tedious online forms, collecting their tax documents, getting quotes for plumbers and electricians, and filing expense reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that the Gemini sidebar support and Nano Banana integration are arriving starting today, while the personal intelligence feature will be available in the “coming months.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Last year, a swarm of AI browsers from companies like OpenAI, Perplexity, Opera, and The Browser Company launched with the aim to replace Chrome with features like sidebar assistants and automated tasks. Now Google is flexing its own AI muscle by adding similar features to Chrome, the world’s largest browser by market share.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Google had introduced Gemini to Chrome last September, the assistant lived in a floating window. With this update, the company will put its AI helper into a persistent sidebar, so you can ask questions about the current website or other open tabs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;One interesting feature Google demoed to press ahead of today’s launch involved multiple tabs. When you open different tabs from a single web page, the Gemini sidebar understands them as a context group. This is helpful when you are comparing prices or different products you’re considering purchasing.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3087116" height="484" src="https://techcrunch.com/wp-content/uploads/2026/01/Still_Gemini-in-Chrome-Side-Panel-1.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Before today, the Gemini in Chrome feature was available only to Windows and macOS users. With this rollout, the sidebar will be available to Chromebook Plus users as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is also taking advantage of its newly launched personal intelligence feature, which connects to your Gmail, Search, YouTube, and Google Photos accounts, allowing you to ask questions based on your own data. This feature will roll out in Chrome in the coming months, meaning that you can ask Gemini in the sidebar about things like your family’s schedule, or ask it to draft an email and send it without switching to Gmail.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a new Nano Banana integration coming to Chrome, too, that allows you to modify an existing image with another image or product that you find while browsing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, the most ambitious feature is called auto-browse, which aims to handle tasks for you by using your personal information and traversing websites on your behalf. For instance, you can ask the agentic feature to go to a particular website and buy an item for you, and find a discount coupon. The agent will ask for your intervention when performing data-sensitive tasks, such as logging into a website or making a final purchase. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, the company explained that these features would use Chrome’s password manager or saved card details, but said its AI models wouldn’t be exposed to any of these details.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This feature is rolling out initially to AI Pro and Ultra subscribers in the U.S. &lt;/p&gt;

&lt;div class="jwppp-video-box" id="jwppp-video-box-30865141"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;







&lt;p class="wp-block-paragraph"&gt;Browser-based agents are finicky and often fail to complete tasks. Google’s demo, just like tons of other AI demos, involved shopping and travel planning. In real-world use cases, agents often don’t get the intent or break during traversing different sites, and that would be a challenge for wider adoption.  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that in its early testing, users have used the feature for tasks such as scheduling appointments, filling out tedious online forms, collecting their tax documents, getting quotes for plumbers and electricians, and filing expense reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that the Gemini sidebar support and Nano Banana integration are arriving starting today, while the personal intelligence feature will be available in the “coming months.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/chrome-takes-on-ai-browsers-with-tighter-gemini-integration-agentic-features-for-autonomous-tasks/</guid><pubDate>Wed, 28 Jan 2026 18:00:00 +0000</pubDate></item><item><title>Google begins rolling out Chrome's "Auto Browse" AI agent today (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/01/google-begins-rolling-out-chromes-auto-browse-ai-agent-today/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Auto Browse agent is available to AI Pro and AI Ultra subscribers, but there are some limits.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Chrome icon in roller coaster" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/chrome_rollercoaster-1-640x360.png" width="640" /&gt;
                  &lt;img alt="Chrome icon in roller coaster" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/chrome_rollercoaster-1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google began stuffing Gemini into its dominant Chrome browser several months ago, and today the AI is expanding its capabilities considerably. Google says the chatbot will be easier to access and connect to more Google services, but the biggest change is the addition of Google’s autonomous browsing agent, which it has dubbed Auto Browse. Similar to tools like OpenAI Atlas, Auto Browse can handle tedious tasks in Chrome so you don’t have to.&lt;/p&gt;
&lt;p&gt;The newly unveiled Gemini features in Chrome are accessible from the omnipresent AI button that has been lurking at the top of the window for the last few months. Initially, that button only opened Gemini in a pop-up window, but Google now says it will default to a split-screen or “Sidepanel” view. Google confirmed the update began rolling out over the past week, so you may already have it.&lt;/p&gt;
&lt;p&gt;You can still pop Gemini out into a floating window, but the split-view gives Gemini more room to breathe while manipulating a page with AI. This is also helpful when calling other apps in the Chrome implementation of Gemini. The chatbot can now access Gmail, Calendar, YouTube, Maps, Google Shopping, and Google Flights right from the Chrome window. Google technically added this feature around the middle of January, but it’s only talking about it now.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2137804-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Animation_Gmail-integration-1.mp4?_=1" type="video/mp4" /&gt;Sidepanel with Gmail integration&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sidepanel with Gmail integration

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Gemini in Chrome can now also access and edit images with Nano Banana, so you don’t have to download and re-upload them to Gemini in another location. Just open the image from the web and type in the Sidepanel with a description of the edits you want. Like in the Gemini app, you can choose between the slower but higher-quality Pro model and the faster standard one.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Can’t someone else do it?&lt;/h2&gt;
&lt;p&gt;Chrome’s new browsing agent (in preview) is the star of today’s show. The promise of agentic AI is one of the freedom to be lazy. Rather than filling out forms or copying information from emails, you simply task a robot with the job and relax while it goes to work. At least, that’s how it’s supposed to go. Most of the computer-use agents we’ve seen so far have been sluggish and unreliable enough to require human supervision. That kind of defeats the purpose. Now it’s Google’s turn to show us what its browsing agent can do.&lt;/p&gt;
&lt;p&gt;Google says Auto Browse is based on its latest Gemini 3 models, with input from the company’s work on the experimental Project Mariner agent. If you’d do something with a keyboard and mouse inside your browser, Auto Browse is theoretically able to take over. It can also access the content and tabs in your browser, asking for permission when it needs sensitive data, such as your passwords.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2137804-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Animation_apartment-hunting-with-Redfin-1-opt.mp4?_=2" type="video/mp4" /&gt;Apartment hunting with Auto Browse&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Apartment hunting with Auto Browse

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;When you launch an Auto Browse task, Chrome will open new tabs as necessary and mark them with a sparkly AI icon so you know where the robot is active. You don’t have to keep that tab in the foreground, and you can even have multiple AI tasks going at once. The AI will ping you to check in when the task is done or when it needs your input. However, there are limits on Auto Browse similar to some of the company’s more computationally intensive chatbot functions. AI Pro subscribers get 20 AI browsing tasks per day, but those paying for AI Ultra get 200 per day.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Having the AI churning in the background may be a concern—after all, generative AI can make mistakes, and you are giving it complete control over the browsing experience. Google says it has implemented a range of security and safety rules to prevent misuse. For example, if you ask Auto Browse to research and buy something, it won’t actually buy it. Instead, it will find the item (hopefully) and progress to the purchase screen before letting you pull the trigger manually.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2137804-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Animation_filling-form-from-PDF-1-opt.mp4?_=3" type="video/mp4" /&gt;Filling a form with Auto Browse&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Filling a form with Auto Browse

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Another thing to keep in mind is that Auto Browse doesn’t run locally. All content from your robotically operated tab is streamed to a cloud-based Gemini model. That means page content will be shared with Google, but the extent is not entirely clear. Google says Auto Browse is governed by the established Gemini in Chrome policy, which says Google stores information from websites in the Gemini Apps Activity (if Keep Activity is enabled). Page content is also “logged to your Google Account temporarily.” We asked if Google would use page contents processed by Auto Browse to further train AI models, but a spokesperson declined to provide specifics.&lt;/p&gt;
&lt;p&gt;Chrome Auto Browse is rolling out today in preview, but it’s not exactly free. It won’t cost anything extra, but the feature is limited to AI Pro and AI Ultra subscribers. Google’s language suggests the feature may come to free users after the preview phase, but we’d expect strict usage limits.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Auto Browse agent is available to AI Pro and AI Ultra subscribers, but there are some limits.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Chrome icon in roller coaster" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/chrome_rollercoaster-1-640x360.png" width="640" /&gt;
                  &lt;img alt="Chrome icon in roller coaster" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/chrome_rollercoaster-1-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google began stuffing Gemini into its dominant Chrome browser several months ago, and today the AI is expanding its capabilities considerably. Google says the chatbot will be easier to access and connect to more Google services, but the biggest change is the addition of Google’s autonomous browsing agent, which it has dubbed Auto Browse. Similar to tools like OpenAI Atlas, Auto Browse can handle tedious tasks in Chrome so you don’t have to.&lt;/p&gt;
&lt;p&gt;The newly unveiled Gemini features in Chrome are accessible from the omnipresent AI button that has been lurking at the top of the window for the last few months. Initially, that button only opened Gemini in a pop-up window, but Google now says it will default to a split-screen or “Sidepanel” view. Google confirmed the update began rolling out over the past week, so you may already have it.&lt;/p&gt;
&lt;p&gt;You can still pop Gemini out into a floating window, but the split-view gives Gemini more room to breathe while manipulating a page with AI. This is also helpful when calling other apps in the Chrome implementation of Gemini. The chatbot can now access Gmail, Calendar, YouTube, Maps, Google Shopping, and Google Flights right from the Chrome window. Google technically added this feature around the middle of January, but it’s only talking about it now.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2137804-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Animation_Gmail-integration-1.mp4?_=1" type="video/mp4" /&gt;Sidepanel with Gmail integration&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sidepanel with Gmail integration

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Gemini in Chrome can now also access and edit images with Nano Banana, so you don’t have to download and re-upload them to Gemini in another location. Just open the image from the web and type in the Sidepanel with a description of the edits you want. Like in the Gemini app, you can choose between the slower but higher-quality Pro model and the faster standard one.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Can’t someone else do it?&lt;/h2&gt;
&lt;p&gt;Chrome’s new browsing agent (in preview) is the star of today’s show. The promise of agentic AI is one of the freedom to be lazy. Rather than filling out forms or copying information from emails, you simply task a robot with the job and relax while it goes to work. At least, that’s how it’s supposed to go. Most of the computer-use agents we’ve seen so far have been sluggish and unreliable enough to require human supervision. That kind of defeats the purpose. Now it’s Google’s turn to show us what its browsing agent can do.&lt;/p&gt;
&lt;p&gt;Google says Auto Browse is based on its latest Gemini 3 models, with input from the company’s work on the experimental Project Mariner agent. If you’d do something with a keyboard and mouse inside your browser, Auto Browse is theoretically able to take over. It can also access the content and tabs in your browser, asking for permission when it needs sensitive data, such as your passwords.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2137804-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Animation_apartment-hunting-with-Redfin-1-opt.mp4?_=2" type="video/mp4" /&gt;Apartment hunting with Auto Browse&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Apartment hunting with Auto Browse

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;When you launch an Auto Browse task, Chrome will open new tabs as necessary and mark them with a sparkly AI icon so you know where the robot is active. You don’t have to keep that tab in the foreground, and you can even have multiple AI tasks going at once. The AI will ping you to check in when the task is done or when it needs your input. However, there are limits on Auto Browse similar to some of the company’s more computationally intensive chatbot functions. AI Pro subscribers get 20 AI browsing tasks per day, but those paying for AI Ultra get 200 per day.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Having the AI churning in the background may be a concern—after all, generative AI can make mistakes, and you are giving it complete control over the browsing experience. Google says it has implemented a range of security and safety rules to prevent misuse. For example, if you ask Auto Browse to research and buy something, it won’t actually buy it. Instead, it will find the item (hopefully) and progress to the purchase screen before letting you pull the trigger manually.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2137804-3" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Animation_filling-form-from-PDF-1-opt.mp4?_=3" type="video/mp4" /&gt;Filling a form with Auto Browse&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Filling a form with Auto Browse

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Another thing to keep in mind is that Auto Browse doesn’t run locally. All content from your robotically operated tab is streamed to a cloud-based Gemini model. That means page content will be shared with Google, but the extent is not entirely clear. Google says Auto Browse is governed by the established Gemini in Chrome policy, which says Google stores information from websites in the Gemini Apps Activity (if Keep Activity is enabled). Page content is also “logged to your Google Account temporarily.” We asked if Google would use page contents processed by Auto Browse to further train AI models, but a spokesperson declined to provide specifics.&lt;/p&gt;
&lt;p&gt;Chrome Auto Browse is rolling out today in preview, but it’s not exactly free. It won’t cost anything extra, but the feature is limited to AI Pro and AI Ultra subscribers. Google’s language suggests the feature may come to free users after the preview phase, but we’d expect strict usage limits.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/01/google-begins-rolling-out-chromes-auto-browse-ai-agent-today/</guid><pubDate>Wed, 28 Jan 2026 18:00:14 +0000</pubDate></item><item><title>[NEW] Accelerating Science: A Blueprint for a Renewed National Quantum Initiative (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/national-quantum-initiative/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/nvidiaheadquarters.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Quantum technologies are rapidly emerging as foundational capabilities for economic competitiveness, national security and scientific leadership in the 21st century. Sustained U.S. leadership in quantum information science is critical to ensuring that breakthroughs in computing, sensing, networking and materials translate into secure technologies and industries, a skilled domestic workforce and long-term strategic advantage. To secure this future, Congress must act and reauthorize the National Quantum Initiative (NQI).&lt;/p&gt;
&lt;p&gt;&lt;span&gt;On Dec. 21, 2018, President Trump signed into law the bipartisan NQI, establishing for the first time a broad, multi-agency strategy spanning universities, national labs and industry to advance quantum information science as a national priority.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;This coordinated initiative accelerated the maturation of quantum technologies by enabling sustained investment, shared infrastructure and a world-class research and development ecosystem. Since the NQI’s inception, dramatic advancements have been made in qubit coherence, gate fidelities and system scaling, moving quantum platforms from isolated demonstrations toward scalable architectures. Collectively, this progress has clarified a viable roadmap toward useful quantum systems and reinforced the value of long-term, coordinated national investment.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span&gt;The Genesis Mission: A New Era of Scientific Instrumentation&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;When testifying before the House Science Committee in December 2025, Under Secretary for Science Dr. Darío Gil aptly described the current moment as the precipice of a scientific revolution driven by the convergence of AI, high-performance computing and quantum systems. He outlined the Trump Administration’s “Genesis Mission,” an initiative to mobilize national laboratories, industry and academia to build an integrated discovery platform capable of doubling the nation’s R&amp;amp;D productivity within a decade.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Gil emphasized that AI and quantum computing are no longer just distinct tools, but the foundational elements of a new class of supercomputers. He noted that just as telescopes and microscopes transformed our observation of the universe, these converged systems will function as the new scientific instruments of our time, allowing us to decipher the complexity of the natural world.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Realizing this vision requires breaking down silos and a sustained focus on the integration of AI and quantum technologies, not treating them as independent efforts. Many of the most consequential quantum applications will emerge through this convergence, embedded within AI-driven and accelerated workflows that transform entire scientific domains. &lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is why we are urging Congress to reauthorize the NQI. The importance of a deliberate synthesis between AI and quantum computing has only recently come into focus, and the existing national strategy predates this understanding. Reauthorizing the NQI will enable an evolution of strategy to align with the current technological landscape. A reauthorized NQI should explicitly recognize and support the integration of AI, accelerated computing and quantum processors to ensure these capabilities mature into broadly useful systems and to position the U.S. to lead this next phase of computing.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span&gt;What&amp;nbsp;Is a&amp;nbsp;Quantum-GPU&amp;nbsp;Supercomputer?&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;Unlocking&amp;nbsp;lasting impact&amp;nbsp;for&amp;nbsp;the U.S. ecosystem&amp;nbsp;across&amp;nbsp;national laboratories, academia&amp;nbsp;and industry&amp;nbsp;means&amp;nbsp;embracing&amp;nbsp;a mission-focused approach to quantum information science.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;A scientifically useful quantum system — one capable of providing the necessary hundreds of logical qubits and millions of operations — depends on more than state-of-the-art quantum hardware. It also requires a seamless unification of classical and quantum systems, in which GPUs, CPUs and QPUs work in concert as a single, integrated capability. This system-level integration is what transforms quantum capability from isolated demonstrations into a practical scientific resource.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Across the U.S. ecosystem, it is becoming clear that tightly integrated, open architectures are essential for quantum-GPU supercomputing. Through close collaboration with leading U.S. institutions, NVIDIA has made available two foundational components of such architectures:&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;The&amp;nbsp;Bridge (NVIDIA&amp;nbsp;NVQLink):&lt;/span&gt;&lt;/b&gt;&lt;span&gt; Quantum-GPU interconnect technologies provide the low-latency, high-throughput connections required for quantum processors to operate at the scale and speed required to both implement demanding control tasks and perform the hybrid workloads that solve meaningful problems. They enable classical supercomputers to drive QPUs through real-time feedback loops that are essential for error correction and control.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;The&amp;nbsp;Platform (NVIDIA CUDA-Q):&lt;/span&gt;&lt;/b&gt;&lt;span&gt; To democratize access, the quantum ecosystem must bridge the gap between physicists and domain scientists. CUDA-Q is a unified, open source programming model that allows developers to program QPUs, GPUs and CPUs in a single system, enabling seamless, end-to-end hybrid workflows and accelerating scientific adoption.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;AI is increasingly central to overcoming key challenges in scaling and deploying quantum computing — from real-time tasks such as &lt;/span&gt;&lt;span&gt;quantum error correction&lt;/span&gt;&lt;span&gt;&amp;nbsp;and&amp;nbsp;&lt;/span&gt;&lt;span&gt;hardware calibration&lt;/span&gt;&lt;span&gt; to the discovery of more efficient quantum algorithms. As a result, quantum research and development programs, including those at&amp;nbsp;&lt;/span&gt;&lt;span&gt;U.S. national&amp;nbsp;laboratories&lt;/span&gt;&lt;span&gt;,&amp;nbsp;are rapidly integrating AI supercomputing into their&amp;nbsp;core&amp;nbsp;workflows.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;While industry can build the bridges and platforms needed to leverage AI and quantum systems, integrating them into massive, fault-tolerant infrastructures for open science requires federal scale. A federal role is essential to demonstrate these capabilities on national testbeds, proving out system integrations, validating architectures in open environments and establishing the foundations that will ultimately power a competitive commercial market.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span&gt;How&amp;nbsp;Can&amp;nbsp;Congress Support American Quantum Leadership?&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;Agencies across the government are setting&amp;nbsp;bold&amp;nbsp;goals, such as the&amp;nbsp;U.S.&amp;nbsp;Department of Energy’s target to deploy a scientifically useful quantum supercomputer in the U.S. by 2028.&amp;nbsp;Meeting&amp;nbsp;these&amp;nbsp;ambitions&amp;nbsp;and&amp;nbsp;bridging&amp;nbsp;the gap between today’s noisy devices and tomorrow’s fault-tolerant&amp;nbsp;systems&amp;nbsp;will require the NQI&amp;nbsp;to&amp;nbsp;evolve&amp;nbsp;from a discovery-focused program into one that also enables&amp;nbsp;integrated&amp;nbsp;system-level&amp;nbsp;deployment.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Here is how a reauthorized&amp;nbsp;NQI&amp;nbsp;can&amp;nbsp;help propel American leadership:&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Quantum Digital Twins:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; U.S. leadership depends on providing researchers with advanced design simulation capabilities. Congress should fund electronic design automation innovation for simulating quantum hardware, enabling researchers to validate designs digitally before fabrication and dramatically accelerating hardware roadmaps.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Integrations for Quantum Error Correction:&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;Solving problems with quantum systems requires logical qubits, which in turn require techniques like quantum error correction that can only be deployed at scale with AI infrastructure. The&amp;nbsp;NQI&amp;nbsp;must ensure that there is adequate research and AI infrastructure funding to build large-scale systems of logical qubits.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;AI Integration:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; AI is a key resource for accelerating quantum utility. The NQI should promote deeper cross-pollination between these fields by supporting the creation of quantum-simulated datasets to train the next generation of AI models and establish a powerful “AI+Quantum” hub for shared tools, data and workflows.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Flagship Hybrid Applications:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; The hardware must serve the science. Flagship hybrid application projects in chemistry, materials science and life sciences should be launched, creating clear performance benchmarks to demonstrate the utility of these systems for real-world problems beyond abstract experiments and accelerating open scientific use.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Benchmarking&amp;nbsp;and&amp;nbsp;Standards:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; “Scientifically useful” must be rigorously defined to ensure focused, outcome-driven investment. &lt;/span&gt;&lt;span&gt;Organizations like the QED-C should be empowered to lead benchmarking initiatives, establishing transparent metrics that &lt;/span&gt;&lt;span&gt;define true utility and enable consistent measurement of progress.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;When&amp;nbsp;integrated with&amp;nbsp;AI, quantum&amp;nbsp;computing&amp;nbsp;will&amp;nbsp;power&amp;nbsp;this century’s&amp;nbsp;economic competitiveness, national&amp;nbsp;security&amp;nbsp;and scientific leadership.&amp;nbsp;Reauthorizing the National Quantum Initiative is how&amp;nbsp;the U.S.&amp;nbsp;can&amp;nbsp;temper&amp;nbsp;its&amp;nbsp;leadership in research and AI&amp;nbsp;into&amp;nbsp;a&amp;nbsp;durable advantage and ensure&amp;nbsp;it&amp;nbsp;continues to lead&amp;nbsp;through and&amp;nbsp;beyond&amp;nbsp;the AI era.&amp;nbsp;We urge Congress to make&amp;nbsp;its reauthorization&amp;nbsp;a priority.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;

		&lt;footer class="entry-footer hide_disquss " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/nvidiaheadquarters.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Quantum technologies are rapidly emerging as foundational capabilities for economic competitiveness, national security and scientific leadership in the 21st century. Sustained U.S. leadership in quantum information science is critical to ensuring that breakthroughs in computing, sensing, networking and materials translate into secure technologies and industries, a skilled domestic workforce and long-term strategic advantage. To secure this future, Congress must act and reauthorize the National Quantum Initiative (NQI).&lt;/p&gt;
&lt;p&gt;&lt;span&gt;On Dec. 21, 2018, President Trump signed into law the bipartisan NQI, establishing for the first time a broad, multi-agency strategy spanning universities, national labs and industry to advance quantum information science as a national priority.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;This coordinated initiative accelerated the maturation of quantum technologies by enabling sustained investment, shared infrastructure and a world-class research and development ecosystem. Since the NQI’s inception, dramatic advancements have been made in qubit coherence, gate fidelities and system scaling, moving quantum platforms from isolated demonstrations toward scalable architectures. Collectively, this progress has clarified a viable roadmap toward useful quantum systems and reinforced the value of long-term, coordinated national investment.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span&gt;The Genesis Mission: A New Era of Scientific Instrumentation&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;When testifying before the House Science Committee in December 2025, Under Secretary for Science Dr. Darío Gil aptly described the current moment as the precipice of a scientific revolution driven by the convergence of AI, high-performance computing and quantum systems. He outlined the Trump Administration’s “Genesis Mission,” an initiative to mobilize national laboratories, industry and academia to build an integrated discovery platform capable of doubling the nation’s R&amp;amp;D productivity within a decade.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Gil emphasized that AI and quantum computing are no longer just distinct tools, but the foundational elements of a new class of supercomputers. He noted that just as telescopes and microscopes transformed our observation of the universe, these converged systems will function as the new scientific instruments of our time, allowing us to decipher the complexity of the natural world.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Realizing this vision requires breaking down silos and a sustained focus on the integration of AI and quantum technologies, not treating them as independent efforts. Many of the most consequential quantum applications will emerge through this convergence, embedded within AI-driven and accelerated workflows that transform entire scientific domains. &lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This is why we are urging Congress to reauthorize the NQI. The importance of a deliberate synthesis between AI and quantum computing has only recently come into focus, and the existing national strategy predates this understanding. Reauthorizing the NQI will enable an evolution of strategy to align with the current technological landscape. A reauthorized NQI should explicitly recognize and support the integration of AI, accelerated computing and quantum processors to ensure these capabilities mature into broadly useful systems and to position the U.S. to lead this next phase of computing.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span&gt;What&amp;nbsp;Is a&amp;nbsp;Quantum-GPU&amp;nbsp;Supercomputer?&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;Unlocking&amp;nbsp;lasting impact&amp;nbsp;for&amp;nbsp;the U.S. ecosystem&amp;nbsp;across&amp;nbsp;national laboratories, academia&amp;nbsp;and industry&amp;nbsp;means&amp;nbsp;embracing&amp;nbsp;a mission-focused approach to quantum information science.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;A scientifically useful quantum system — one capable of providing the necessary hundreds of logical qubits and millions of operations — depends on more than state-of-the-art quantum hardware. It also requires a seamless unification of classical and quantum systems, in which GPUs, CPUs and QPUs work in concert as a single, integrated capability. This system-level integration is what transforms quantum capability from isolated demonstrations into a practical scientific resource.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Across the U.S. ecosystem, it is becoming clear that tightly integrated, open architectures are essential for quantum-GPU supercomputing. Through close collaboration with leading U.S. institutions, NVIDIA has made available two foundational components of such architectures:&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;The&amp;nbsp;Bridge (NVIDIA&amp;nbsp;NVQLink):&lt;/span&gt;&lt;/b&gt;&lt;span&gt; Quantum-GPU interconnect technologies provide the low-latency, high-throughput connections required for quantum processors to operate at the scale and speed required to both implement demanding control tasks and perform the hybrid workloads that solve meaningful problems. They enable classical supercomputers to drive QPUs through real-time feedback loops that are essential for error correction and control.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;The&amp;nbsp;Platform (NVIDIA CUDA-Q):&lt;/span&gt;&lt;/b&gt;&lt;span&gt; To democratize access, the quantum ecosystem must bridge the gap between physicists and domain scientists. CUDA-Q is a unified, open source programming model that allows developers to program QPUs, GPUs and CPUs in a single system, enabling seamless, end-to-end hybrid workflows and accelerating scientific adoption.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;AI is increasingly central to overcoming key challenges in scaling and deploying quantum computing — from real-time tasks such as &lt;/span&gt;&lt;span&gt;quantum error correction&lt;/span&gt;&lt;span&gt;&amp;nbsp;and&amp;nbsp;&lt;/span&gt;&lt;span&gt;hardware calibration&lt;/span&gt;&lt;span&gt; to the discovery of more efficient quantum algorithms. As a result, quantum research and development programs, including those at&amp;nbsp;&lt;/span&gt;&lt;span&gt;U.S. national&amp;nbsp;laboratories&lt;/span&gt;&lt;span&gt;,&amp;nbsp;are rapidly integrating AI supercomputing into their&amp;nbsp;core&amp;nbsp;workflows.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;While industry can build the bridges and platforms needed to leverage AI and quantum systems, integrating them into massive, fault-tolerant infrastructures for open science requires federal scale. A federal role is essential to demonstrate these capabilities on national testbeds, proving out system integrations, validating architectures in open environments and establishing the foundations that will ultimately power a competitive commercial market.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;&lt;span&gt;How&amp;nbsp;Can&amp;nbsp;Congress Support American Quantum Leadership?&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;&lt;span&gt;Agencies across the government are setting&amp;nbsp;bold&amp;nbsp;goals, such as the&amp;nbsp;U.S.&amp;nbsp;Department of Energy’s target to deploy a scientifically useful quantum supercomputer in the U.S. by 2028.&amp;nbsp;Meeting&amp;nbsp;these&amp;nbsp;ambitions&amp;nbsp;and&amp;nbsp;bridging&amp;nbsp;the gap between today’s noisy devices and tomorrow’s fault-tolerant&amp;nbsp;systems&amp;nbsp;will require the NQI&amp;nbsp;to&amp;nbsp;evolve&amp;nbsp;from a discovery-focused program into one that also enables&amp;nbsp;integrated&amp;nbsp;system-level&amp;nbsp;deployment.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span&gt;Here is how a reauthorized&amp;nbsp;NQI&amp;nbsp;can&amp;nbsp;help propel American leadership:&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Quantum Digital Twins:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; U.S. leadership depends on providing researchers with advanced design simulation capabilities. Congress should fund electronic design automation innovation for simulating quantum hardware, enabling researchers to validate designs digitally before fabrication and dramatically accelerating hardware roadmaps.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Integrations for Quantum Error Correction:&lt;/span&gt;&lt;/b&gt;&lt;span&gt;&amp;nbsp;Solving problems with quantum systems requires logical qubits, which in turn require techniques like quantum error correction that can only be deployed at scale with AI infrastructure. The&amp;nbsp;NQI&amp;nbsp;must ensure that there is adequate research and AI infrastructure funding to build large-scale systems of logical qubits.&amp;nbsp;&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;AI Integration:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; AI is a key resource for accelerating quantum utility. The NQI should promote deeper cross-pollination between these fields by supporting the creation of quantum-simulated datasets to train the next generation of AI models and establish a powerful “AI+Quantum” hub for shared tools, data and workflows.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Flagship Hybrid Applications:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; The hardware must serve the science. Flagship hybrid application projects in chemistry, materials science and life sciences should be launched, creating clear performance benchmarks to demonstrate the utility of these systems for real-world problems beyond abstract experiments and accelerating open scientific use.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;b&gt;&lt;span&gt;Benchmarking&amp;nbsp;and&amp;nbsp;Standards:&lt;/span&gt;&lt;/b&gt;&lt;span&gt; “Scientifically useful” must be rigorously defined to ensure focused, outcome-driven investment. &lt;/span&gt;&lt;span&gt;Organizations like the QED-C should be empowered to lead benchmarking initiatives, establishing transparent metrics that &lt;/span&gt;&lt;span&gt;define true utility and enable consistent measurement of progress.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;span&gt;When&amp;nbsp;integrated with&amp;nbsp;AI, quantum&amp;nbsp;computing&amp;nbsp;will&amp;nbsp;power&amp;nbsp;this century’s&amp;nbsp;economic competitiveness, national&amp;nbsp;security&amp;nbsp;and scientific leadership.&amp;nbsp;Reauthorizing the National Quantum Initiative is how&amp;nbsp;the U.S.&amp;nbsp;can&amp;nbsp;temper&amp;nbsp;its&amp;nbsp;leadership in research and AI&amp;nbsp;into&amp;nbsp;a&amp;nbsp;durable advantage and ensure&amp;nbsp;it&amp;nbsp;continues to lead&amp;nbsp;through and&amp;nbsp;beyond&amp;nbsp;the AI era.&amp;nbsp;We urge Congress to make&amp;nbsp;its reauthorization&amp;nbsp;a priority.&lt;/span&gt;&lt;span&gt;&amp;nbsp;&lt;/span&gt;&lt;/p&gt;

		&lt;footer class="entry-footer hide_disquss " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/national-quantum-initiative/</guid><pubDate>Wed, 28 Jan 2026 18:17:53 +0000</pubDate></item><item><title>[NEW] AI data labeler Handshake buys  Cleanlab, an acquisition target of multiple others (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/ai-data-labeler-handshake-buys-cleanlab-an-acquisition-target-of-multiple-others/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Cleanlab.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data-labeling startup Handshake has acquired data label-auditing startup Cleanlab, the companies tell TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Handshake began in 2013 as a platform for hiring college grads and launched a human data-labeling business about a year ago to serve foundational AI model companies. Cleanlab, founded in 2021, is a startup that provides software for improving the quality of data produced by human labelers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal’s purpose is primarily to acquire talent, aka an acqui-hire, adding nine key Cleanlab employees to Handshake’s research organization. This includes the startup’s co-founders, who earned their PhDs in computer science from MIT: Curtis Northcutt (pictured above), Jonas Mueller, and Anish Athalye. The terms of the transaction were not disclosed (though, as we previously reported, sometimes an acqui-hire can be surprisingly lucrative for founders.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cleanlab has raised a total of $30 million from investors, including Menlo Ventures, TQ Ventures, Bain Capital Ventures, and Databricks Ventures. At its peak, the startup had more than 30 employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cleanlab’s researchers are experts in developing algorithms that flag incorrect data without a second human reviewer. The goal is to improve the quality of the data Handshake produces for AI labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have an in-house research team that thinks a lot about where our models are weak, what data should we be producing? How high quality is that data?” Sahil Bhaiwala, chief strategy and innovation officer at Handshake told TechCrunch. “The Cleanlab team has been focusing on this problem for years.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Northcutt, the Cleanlab CEO who’s credited with pioneering its automated data-labeling auditing, said the company received acquisition interest from other AI data-labeling companies. But the startup chose to sell to Handshake because, he said, data-labeling competitors, including Mercor, Surge, and Scale AI, frequently use Handshake’s platform to source human experts such as doctors, lawyers, and scientists for their data-labeling projects.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“If you’re going to pick one, you should probably pick the source, not the middleman,” Northcutt told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Handshake, which was last valued at $3.3 billion in 2022, was forecasted to end 2025 at $300 million in annualized revenue run rate (ARR) and is reportedly on track to reach an ARR of “high hundreds of millions” this year. The company has provided data for eight top AI labs, including OpenAI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Cleanlab.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI data-labeling startup Handshake has acquired data label-auditing startup Cleanlab, the companies tell TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Handshake began in 2013 as a platform for hiring college grads and launched a human data-labeling business about a year ago to serve foundational AI model companies. Cleanlab, founded in 2021, is a startup that provides software for improving the quality of data produced by human labelers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal’s purpose is primarily to acquire talent, aka an acqui-hire, adding nine key Cleanlab employees to Handshake’s research organization. This includes the startup’s co-founders, who earned their PhDs in computer science from MIT: Curtis Northcutt (pictured above), Jonas Mueller, and Anish Athalye. The terms of the transaction were not disclosed (though, as we previously reported, sometimes an acqui-hire can be surprisingly lucrative for founders.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cleanlab has raised a total of $30 million from investors, including Menlo Ventures, TQ Ventures, Bain Capital Ventures, and Databricks Ventures. At its peak, the startup had more than 30 employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cleanlab’s researchers are experts in developing algorithms that flag incorrect data without a second human reviewer. The goal is to improve the quality of the data Handshake produces for AI labs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have an in-house research team that thinks a lot about where our models are weak, what data should we be producing? How high quality is that data?” Sahil Bhaiwala, chief strategy and innovation officer at Handshake told TechCrunch. “The Cleanlab team has been focusing on this problem for years.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Northcutt, the Cleanlab CEO who’s credited with pioneering its automated data-labeling auditing, said the company received acquisition interest from other AI data-labeling companies. But the startup chose to sell to Handshake because, he said, data-labeling competitors, including Mercor, Surge, and Scale AI, frequently use Handshake’s platform to source human experts such as doctors, lawyers, and scientists for their data-labeling projects.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“If you’re going to pick one, you should probably pick the source, not the middleman,” Northcutt told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Handshake, which was last valued at $3.3 billion in 2022, was forecasted to end 2025 at $300 million in annualized revenue run rate (ARR) and is reportedly on track to reach an ARR of “high hundreds of millions” this year. The company has provided data for eight top AI labs, including OpenAI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/ai-data-labeler-handshake-buys-cleanlab-an-acquisition-target-of-multiple-others/</guid><pubDate>Wed, 28 Jan 2026 19:00:00 +0000</pubDate></item><item><title>[NEW] WhatsApp will now charge AI chatbots to operate in Italy (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/whatsapp-will-now-charge-ai-chatbots-to-operate-in-italy/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/whatsapp-logo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced Wednesday that it will charge developers for running chatbots on WhatsApp in regions where regulators are forcing the company to allow them. The move comes after the company’s ban on third-party chatbots on WhatsApp took effect on January 15.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Meta will charge developers in Italy, where the country’s competition watchdog asked the company to suspend its policy last December. The company said that the new pricing for non-template responses will begin on February 16. Meta plans to charge $0.0691/&amp;nbsp;€0.0572 / £0.0498 per message to developers for AI responses. This could result in steep bills for developers if users are exchanging thousands of queries with AI chatbots every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Earlier this month, Meta sent notices to developers creating an exemption for Italian phone numbers and allowing AI chatbots to serve those customers. At that time, the company didn’t mention any plans to charge developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, WhatsApp already charges companies for using its API for various template responses to customers, which include use cases like marketing, utility, or authentication. This includes messages users receive about payment reminders and shipping updates.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Where we are legally required to provide AI chatbots through the WhatsApp business API, we are introducing pricing for the companies that choose to use our platform to provide those services,”&amp;nbsp;a Meta spokesperson told TechCrunch. This could also establish a precedent for other geographies if Meta has to cave in and allow developers to operate their chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta first announced this past October that it would block all third-party AI chatbots from using WhatsApp through its WhatsApp Business API.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta said its systems weren’t designed to handle responses from AI bots and were being strained.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The emergence of AI chatbots on our Business API put a strain on our systems that they were not designed to support. This logic assumes WhatsApp is somehow a de facto app store. The route to market for AI companies is the app stores themselves, their websites, and industry partnerships; not the WhatsApp Business Platform,” the company said at that time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, various regions, including the EU, Italy, and Brazil, have started anticompetitive probes. Brazil’s watchdog initially asked Meta to suspend the policy. However, a court in Brazil sided with Meta last week and overturned the preliminary order blocking the new policy. As a result, the company has asked developers not to provide their AI chatbots to users in Brazil, TechCrunch has learned.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since the policy has kicked in, developers are forced to send a pre-defined message to users of their AI chatbot on WhatsApp to redirect them to their site or app.&amp;nbsp;Providers like OpenAI, Perplexity, and Microsoft announced last year that their WhatsApp bots would not work after January 15, urging users to access them on other platforms.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/whatsapp-logo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced Wednesday that it will charge developers for running chatbots on WhatsApp in regions where regulators are forcing the company to allow them. The move comes after the company’s ban on third-party chatbots on WhatsApp took effect on January 15.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Meta will charge developers in Italy, where the country’s competition watchdog asked the company to suspend its policy last December. The company said that the new pricing for non-template responses will begin on February 16. Meta plans to charge $0.0691/&amp;nbsp;€0.0572 / £0.0498 per message to developers for AI responses. This could result in steep bills for developers if users are exchanging thousands of queries with AI chatbots every day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Earlier this month, Meta sent notices to developers creating an exemption for Italian phone numbers and allowing AI chatbots to serve those customers. At that time, the company didn’t mention any plans to charge developers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, WhatsApp already charges companies for using its API for various template responses to customers, which include use cases like marketing, utility, or authentication. This includes messages users receive about payment reminders and shipping updates.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Where we are legally required to provide AI chatbots through the WhatsApp business API, we are introducing pricing for the companies that choose to use our platform to provide those services,”&amp;nbsp;a Meta spokesperson told TechCrunch. This could also establish a precedent for other geographies if Meta has to cave in and allow developers to operate their chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta first announced this past October that it would block all third-party AI chatbots from using WhatsApp through its WhatsApp Business API.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta said its systems weren’t designed to handle responses from AI bots and were being strained.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The emergence of AI chatbots on our Business API put a strain on our systems that they were not designed to support. This logic assumes WhatsApp is somehow a de facto app store. The route to market for AI companies is the app stores themselves, their websites, and industry partnerships; not the WhatsApp Business Platform,” the company said at that time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, various regions, including the EU, Italy, and Brazil, have started anticompetitive probes. Brazil’s watchdog initially asked Meta to suspend the policy. However, a court in Brazil sided with Meta last week and overturned the preliminary order blocking the new policy. As a result, the company has asked developers not to provide their AI chatbots to users in Brazil, TechCrunch has learned.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since the policy has kicked in, developers are forced to send a pre-defined message to users of their AI chatbot on WhatsApp to redirect them to their site or app.&amp;nbsp;Providers like OpenAI, Perplexity, and Microsoft announced last year that their WhatsApp bots would not work after January 15, urging users to access them on other platforms.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/whatsapp-will-now-charge-ai-chatbots-to-operate-in-italy/</guid><pubDate>Wed, 28 Jan 2026 19:18:59 +0000</pubDate></item><item><title>[NEW] US cyber defense chief accidentally uploaded secret government info to ChatGPT (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/01/us-cyber-defense-chief-accidentally-uploaded-secret-government-info-to-chatgpt/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Congress recently grilled the acting chief on mass layoffs and a failed polygraph.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2202418998-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2202418998-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Pakin Songmor | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Alarming critics, the acting director of the Cybersecurity and Infrastructure Security Agency (CISA), Madhu Gottumukkala, accidentally uploaded sensitive information to a public version of ChatGPT last summer, Politico reported.&lt;/p&gt;
&lt;p&gt;According to “four Department of Homeland Security officials with knowledge of the incident,” Gottumukkala’s uploads of sensitive CISA contracting documents triggered multiple internal cybersecurity warnings designed to “stop the theft or unintentional disclosure of government material from federal networks.”&lt;/p&gt;
&lt;p&gt;Gottumukkala’s uploads happened soon after he joined the agency and sought special permission to use OpenAI’s popular chatbot, which most DHS staffers are blocked from accessing, DHS confirmed to Ars. Instead, DHS staffers use approved AI-powered tools, like the agency’s DHSChat, which “are configured to prevent queries or documents input into them from leaving federal networks,” Politico reported.&lt;/p&gt;
&lt;p&gt;It remains unclear why Gottumukkala needed to use ChatGPT. One official told Politico that, to staffers, it seemed like Gottumukkala “forced CISA’s hand into making them give him ChatGPT, and then he abused it.”&lt;/p&gt;
&lt;p&gt;The information Gottumukkala reportedly leaked was not confidential but marked “for official use only.” That designation, a DHS document explained, is “used within DHS to identify unclassified information of a sensitive nature” that, if shared without authorization, “could adversely impact a person’s privacy or welfare” or impede how federal and other programs “essential to the national interest” operate.&lt;/p&gt;
&lt;p&gt;There’s now a concern that the sensitive information could be used to answer prompts from any of ChatGPT’s 700 million active users.&lt;/p&gt;
&lt;p&gt;OpenAI did not respond to Ars’ request to comment, but Cyber News reported that experts have warned “that using public AI tools poses real risks because uploaded data can be retained, breached, or used to inform responses to other users.”&lt;/p&gt;
&lt;p&gt;Sources told Politico that DHS investigated the incident for potentially harming government security—which could result in administrative or disciplinary actions, DHS officials told Politico. Possible consequences could range from a formal warning or mandatory retraining to “suspension or revocation of a security clearance,” officials said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;However, CISA’s director of public affairs, Marci McCarthy, declined Ars’ request to confirm if that probe, launched in August, has concluded or remains ongoing. Instead, she seemed to emphasize that Gottumukkala’s access to ChatGPT was only temporary, while suggesting that the ChatGPT use aligned with Donald Trump’s order to deploy AI across government.&lt;/p&gt;
&lt;p&gt;“Acting Director Dr. Madhu Gottumukkala was granted permission to use ChatGPT with DHS controls in place,” McCarthy said. “This use was short-term and limited. CISA is unwavering in its commitment to harnessing AI and other cutting-edge technologies to drive government modernization and deliver” on Trump’s order.&lt;/p&gt;
&lt;h2&gt;Scrutiny of cyber defense chief remains&lt;/h2&gt;
&lt;p&gt;Gottumukkala has not had a smooth run as acting director of the top US cyber defense agency after Trump’s pick to helm the agency, Sean Plankey, was blocked by Sen. Rick Scott (R-Fla.) “over a Coast Guard shipbuilding contract,” Politico noted.&lt;/p&gt;
&lt;p&gt;DHS Secretary Kristi Noem chose Gottumukkala to fill in after he previously served as her chief information officer, overseeing statewide cybersecurity initiatives in South Dakota. CISA celebrated his appointment with a press release boasting that he had more than 24 years of experience in information technology and a “deep understanding of both the complexities and practical realities of infrastructure security.”&lt;/p&gt;
&lt;p&gt;However, critics “on both sides of the aisle” have questioned whether Gottumukkala knows what he’s doing at CISA, Cyberscoop reported. That includes staffers who stayed on and staffers who prematurely left the agency due to uncertainty over its future, Politico reported.&lt;/p&gt;
&lt;p&gt;At least 65 staffers have been curiously reassigned to other parts of DHS, Cyberscoop reported, inciting Democrats’ fears that CISA staffers are possibly being pushed over to Immigration and Customs Enforcement (ICE).&lt;/p&gt;
&lt;p&gt;The same fate almost befell Robert Costello, CISA’s chief information officer, who was reportedly involved with meetings last August probing Gottumukkala’s improper ChatGPT use and “the proper handling of for official use only material,” Politico reported.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Earlier this month, staffers alleged that Gottumukkala took steps to remove Costello from his CIO position, which he has held for the past four years. But that plan was blocked after “other political appointees at the department objected,” Politico reported. Until others intervened to permanently thwart the reassignment, Costello was supposedly given “roughly one week” to decide if he would take another position within DHS or resign, sources told Politico.&lt;/p&gt;
&lt;p&gt;Gottumukkala has denied that he sought to reassign Costello over a personal spat that Politico’s sources said sprang from “friction because Costello frequently pushed back against Gottumukkala on policy matters.” He insisted that “senior personnel decisions are made at the highest levels at the Department of Homeland Security’s Headquarters and are not made in a vacuum, independently by one individual, or on a whim.”&lt;/p&gt;
&lt;p&gt;The reported move looked particularly shady, though, because Costello “is seen as one of the agency’s top remaining technical talents,” Politico reported.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Congress questioned ongoing cybersecurity threats&lt;/h2&gt;
&lt;p&gt;This month, Congress grilled Gottumukkala about mass layoffs last year that shrank CISA from about 3,400 staffers to 2,400. The steep cuts seemed to threaten national security and election integrity, lawmakers warned, and potentially have left the agency unprepared for any potential conflicts with China.&lt;/p&gt;
&lt;p&gt;At a hearing held by the House Homeland Security Committee, Gottumukkala said that CISA was “getting back on mission” and plans to reverse much of the damage done last year to the agency.&lt;/p&gt;
&lt;p&gt;However, some of his responses did not inspire confidence, including a failure to forecast “how many cyber intrusions CISA expects from foreign adversaries as part of the 2026 midterm elections,” the Federal News Network reported. In particular, Rep. Tony Gonzales (R-Texas) criticized Gottumukkala for not having “a specific number in mind.”&lt;/p&gt;
&lt;p&gt;“Well, we should have that number,” Gonzales said. “It should first start by how many intrusions that we had last midterm and the midterm before that. I don’t want to wait. I don’t want us waiting until after the fact to be able to go, ‘Yeah, we got it wrong, and it turns out our adversaries influenced our election to that point.’”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Perhaps notably, Gottumukkala also dodged questions about reports that he failed a polygraph when attempting to seek access to other “highly sensitive cyber intelligence,” Politico reported.&lt;/p&gt;
&lt;p&gt;The acting director apparently blamed six career CISA staffers for requesting that he agree to the polygraph test, which the staffers said was typical protocol but Gottumukkala later claimed was misleading.&lt;/p&gt;
&lt;p&gt;Failing the test isn’t necessarily damning, since anxiety or technical errors could trigger a negative result. However, Gottumukkala appears touchy about the test that he now regrets sitting for, calling the test “unsanctioned” and refusing to discuss the results.&lt;/p&gt;
&lt;p&gt;It seems that Gottumukkala felt misled after learning that he could have requested a waiver to skip the polygraph. In a letter suspending those staffers’ security clearances, CISA accused staff of showing “deliberate or negligent failure to follow policies that protect government information.” However, staffers may not have known that he had that option, which is considered a “highly unusual loophole that may not have been readily apparent to career staff,” Politico noted.&lt;/p&gt;
&lt;p&gt;Staffers told Politico that Gottumukkala’s tenure has been a “nightmare"—potentially ruining the careers of longtime CISA staffers. It troubles some that it seems that Gottumukkala will remain in his post “for the foreseeable future,” while seeming to politicize the agency and bungle protocols for accessing sensitive information.&lt;/p&gt;
&lt;p&gt;According to Nextgov, Gottumukkala plans to right the ship with “a hiring spree in 2026 because its recent reductions have hampered some of the Trump administration’s national security goals.”&lt;/p&gt;
&lt;p&gt;In November, the trade publication Cybersecurity Dive reported that Gottumukkala sent a memo confirming the hiring spree was coming that month, while warning that CISA remains “hampered by an approximately 40 percent vacancy rate across key mission areas.” All those cuts were “spurred by the administration’s animus toward CISA over its election security work,” Cybersecurity Dive noted.&lt;/p&gt;
&lt;p&gt;“CISA must immediately accelerate recruitment, workforce development, and retention initiatives to ensure mission readiness and operational continuity,” Gottumukkala told staffers at that time, then later went on to reassure Congress this month that the agency has “the required staff” to protect election integrity and national security, Cyberscoop reported.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Congress recently grilled the acting chief on mass layoffs and a failed polygraph.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2202418998-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2202418998-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Pakin Songmor | Moment

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Alarming critics, the acting director of the Cybersecurity and Infrastructure Security Agency (CISA), Madhu Gottumukkala, accidentally uploaded sensitive information to a public version of ChatGPT last summer, Politico reported.&lt;/p&gt;
&lt;p&gt;According to “four Department of Homeland Security officials with knowledge of the incident,” Gottumukkala’s uploads of sensitive CISA contracting documents triggered multiple internal cybersecurity warnings designed to “stop the theft or unintentional disclosure of government material from federal networks.”&lt;/p&gt;
&lt;p&gt;Gottumukkala’s uploads happened soon after he joined the agency and sought special permission to use OpenAI’s popular chatbot, which most DHS staffers are blocked from accessing, DHS confirmed to Ars. Instead, DHS staffers use approved AI-powered tools, like the agency’s DHSChat, which “are configured to prevent queries or documents input into them from leaving federal networks,” Politico reported.&lt;/p&gt;
&lt;p&gt;It remains unclear why Gottumukkala needed to use ChatGPT. One official told Politico that, to staffers, it seemed like Gottumukkala “forced CISA’s hand into making them give him ChatGPT, and then he abused it.”&lt;/p&gt;
&lt;p&gt;The information Gottumukkala reportedly leaked was not confidential but marked “for official use only.” That designation, a DHS document explained, is “used within DHS to identify unclassified information of a sensitive nature” that, if shared without authorization, “could adversely impact a person’s privacy or welfare” or impede how federal and other programs “essential to the national interest” operate.&lt;/p&gt;
&lt;p&gt;There’s now a concern that the sensitive information could be used to answer prompts from any of ChatGPT’s 700 million active users.&lt;/p&gt;
&lt;p&gt;OpenAI did not respond to Ars’ request to comment, but Cyber News reported that experts have warned “that using public AI tools poses real risks because uploaded data can be retained, breached, or used to inform responses to other users.”&lt;/p&gt;
&lt;p&gt;Sources told Politico that DHS investigated the incident for potentially harming government security—which could result in administrative or disciplinary actions, DHS officials told Politico. Possible consequences could range from a formal warning or mandatory retraining to “suspension or revocation of a security clearance,” officials said.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;However, CISA’s director of public affairs, Marci McCarthy, declined Ars’ request to confirm if that probe, launched in August, has concluded or remains ongoing. Instead, she seemed to emphasize that Gottumukkala’s access to ChatGPT was only temporary, while suggesting that the ChatGPT use aligned with Donald Trump’s order to deploy AI across government.&lt;/p&gt;
&lt;p&gt;“Acting Director Dr. Madhu Gottumukkala was granted permission to use ChatGPT with DHS controls in place,” McCarthy said. “This use was short-term and limited. CISA is unwavering in its commitment to harnessing AI and other cutting-edge technologies to drive government modernization and deliver” on Trump’s order.&lt;/p&gt;
&lt;h2&gt;Scrutiny of cyber defense chief remains&lt;/h2&gt;
&lt;p&gt;Gottumukkala has not had a smooth run as acting director of the top US cyber defense agency after Trump’s pick to helm the agency, Sean Plankey, was blocked by Sen. Rick Scott (R-Fla.) “over a Coast Guard shipbuilding contract,” Politico noted.&lt;/p&gt;
&lt;p&gt;DHS Secretary Kristi Noem chose Gottumukkala to fill in after he previously served as her chief information officer, overseeing statewide cybersecurity initiatives in South Dakota. CISA celebrated his appointment with a press release boasting that he had more than 24 years of experience in information technology and a “deep understanding of both the complexities and practical realities of infrastructure security.”&lt;/p&gt;
&lt;p&gt;However, critics “on both sides of the aisle” have questioned whether Gottumukkala knows what he’s doing at CISA, Cyberscoop reported. That includes staffers who stayed on and staffers who prematurely left the agency due to uncertainty over its future, Politico reported.&lt;/p&gt;
&lt;p&gt;At least 65 staffers have been curiously reassigned to other parts of DHS, Cyberscoop reported, inciting Democrats’ fears that CISA staffers are possibly being pushed over to Immigration and Customs Enforcement (ICE).&lt;/p&gt;
&lt;p&gt;The same fate almost befell Robert Costello, CISA’s chief information officer, who was reportedly involved with meetings last August probing Gottumukkala’s improper ChatGPT use and “the proper handling of for official use only material,” Politico reported.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Earlier this month, staffers alleged that Gottumukkala took steps to remove Costello from his CIO position, which he has held for the past four years. But that plan was blocked after “other political appointees at the department objected,” Politico reported. Until others intervened to permanently thwart the reassignment, Costello was supposedly given “roughly one week” to decide if he would take another position within DHS or resign, sources told Politico.&lt;/p&gt;
&lt;p&gt;Gottumukkala has denied that he sought to reassign Costello over a personal spat that Politico’s sources said sprang from “friction because Costello frequently pushed back against Gottumukkala on policy matters.” He insisted that “senior personnel decisions are made at the highest levels at the Department of Homeland Security’s Headquarters and are not made in a vacuum, independently by one individual, or on a whim.”&lt;/p&gt;
&lt;p&gt;The reported move looked particularly shady, though, because Costello “is seen as one of the agency’s top remaining technical talents,” Politico reported.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Congress questioned ongoing cybersecurity threats&lt;/h2&gt;
&lt;p&gt;This month, Congress grilled Gottumukkala about mass layoffs last year that shrank CISA from about 3,400 staffers to 2,400. The steep cuts seemed to threaten national security and election integrity, lawmakers warned, and potentially have left the agency unprepared for any potential conflicts with China.&lt;/p&gt;
&lt;p&gt;At a hearing held by the House Homeland Security Committee, Gottumukkala said that CISA was “getting back on mission” and plans to reverse much of the damage done last year to the agency.&lt;/p&gt;
&lt;p&gt;However, some of his responses did not inspire confidence, including a failure to forecast “how many cyber intrusions CISA expects from foreign adversaries as part of the 2026 midterm elections,” the Federal News Network reported. In particular, Rep. Tony Gonzales (R-Texas) criticized Gottumukkala for not having “a specific number in mind.”&lt;/p&gt;
&lt;p&gt;“Well, we should have that number,” Gonzales said. “It should first start by how many intrusions that we had last midterm and the midterm before that. I don’t want to wait. I don’t want us waiting until after the fact to be able to go, ‘Yeah, we got it wrong, and it turns out our adversaries influenced our election to that point.’”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Perhaps notably, Gottumukkala also dodged questions about reports that he failed a polygraph when attempting to seek access to other “highly sensitive cyber intelligence,” Politico reported.&lt;/p&gt;
&lt;p&gt;The acting director apparently blamed six career CISA staffers for requesting that he agree to the polygraph test, which the staffers said was typical protocol but Gottumukkala later claimed was misleading.&lt;/p&gt;
&lt;p&gt;Failing the test isn’t necessarily damning, since anxiety or technical errors could trigger a negative result. However, Gottumukkala appears touchy about the test that he now regrets sitting for, calling the test “unsanctioned” and refusing to discuss the results.&lt;/p&gt;
&lt;p&gt;It seems that Gottumukkala felt misled after learning that he could have requested a waiver to skip the polygraph. In a letter suspending those staffers’ security clearances, CISA accused staff of showing “deliberate or negligent failure to follow policies that protect government information.” However, staffers may not have known that he had that option, which is considered a “highly unusual loophole that may not have been readily apparent to career staff,” Politico noted.&lt;/p&gt;
&lt;p&gt;Staffers told Politico that Gottumukkala’s tenure has been a “nightmare"—potentially ruining the careers of longtime CISA staffers. It troubles some that it seems that Gottumukkala will remain in his post “for the foreseeable future,” while seeming to politicize the agency and bungle protocols for accessing sensitive information.&lt;/p&gt;
&lt;p&gt;According to Nextgov, Gottumukkala plans to right the ship with “a hiring spree in 2026 because its recent reductions have hampered some of the Trump administration’s national security goals.”&lt;/p&gt;
&lt;p&gt;In November, the trade publication Cybersecurity Dive reported that Gottumukkala sent a memo confirming the hiring spree was coming that month, while warning that CISA remains “hampered by an approximately 40 percent vacancy rate across key mission areas.” All those cuts were “spurred by the administration’s animus toward CISA over its election security work,” Cybersecurity Dive noted.&lt;/p&gt;
&lt;p&gt;“CISA must immediately accelerate recruitment, workforce development, and retention initiatives to ensure mission readiness and operational continuity,” Gottumukkala told staffers at that time, then later went on to reassure Congress this month that the agency has “the required staff” to protect election integrity and national security, Cyberscoop reported.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/01/us-cyber-defense-chief-accidentally-uploaded-secret-government-info-to-chatgpt/</guid><pubDate>Wed, 28 Jan 2026 19:56:44 +0000</pubDate></item><item><title>[NEW] ServiceNow inks another AI partnership, this time with Anthropic (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/servicenow-inks-another-ai-partnership-this-time-with-anthropic/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/GettyImages-1782807384.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ServiceNow announced a deal with major AI player Anthropic just a week after it announced a partnership with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise workflow software company ServiceNow has entered into a multi-year deal with AI research lab Anthropic on Wednesday. This partnership involves further embedding of Anthropic’s AI models into ServiceNow’s platform for its customers and bringing Anthropic’s AI to its employees.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;ServiceNow declined to clarify the duration of the partnership or the monetary size of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal entails making Anthropic’s Claude model family the preferred AI models across ServiceNow’s AI-driven workflow products. Claude is now also the default model powering the company’s AI agent builder, ServiceNow Build Agent, which allows developers to create agentic workflows and build apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal also involves the rollout of Claude to the company’s 29,000 ServiceNow employees. Claude Code, Anthropic’s vibe-coding product, is also available to the company’s engineers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ServiceNow with Anthropic is turning intelligence into action through AI-native workflows for the world’s largest enterprises,” Bill McDermott, chairman and CEO of ServiceNow, said in a company press release. “Together, we are proving that deeply integrated platforms with an open ecosystem are how the future is built.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news comes just a week after the company announced a new AI partnership with Anthropic rival OpenAI that involved giving ServiceNow customers access to OpenAI’s models through the company’s products.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ServiceNow president, COO and CPO, Amit Zavery, said the company is intentionally pursuing a multi-model strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t view these partnerships as competitive or mutually exclusive,” Zavery said over email. “Enterprise customers want model choice. They want the right model for the right job — keeping governance, security, and auditability consistent on the ServiceNow AI Platform. Each model brings different strengths, and our role is to orchestrate them in ways that deliver the best outcomes for customers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal is just the latest one for Anthropic, which has announced a number of sizable enterprise deals in recent months. The company announced a deal with global insurance provider Allianz earlier this year and partnerships with Accenture, IBM, Deloitte, and Snowflake late last year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While enterprises have struggled thus far to find a measurable return on AI investment, VCs recently predicted that this will change in 2026 — although this is the third year in a row they have predicted that.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/GettyImages-1782807384.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ServiceNow announced a deal with major AI player Anthropic just a week after it announced a partnership with OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Enterprise workflow software company ServiceNow has entered into a multi-year deal with AI research lab Anthropic on Wednesday. This partnership involves further embedding of Anthropic’s AI models into ServiceNow’s platform for its customers and bringing Anthropic’s AI to its employees.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;ServiceNow declined to clarify the duration of the partnership or the monetary size of the deal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal entails making Anthropic’s Claude model family the preferred AI models across ServiceNow’s AI-driven workflow products. Claude is now also the default model powering the company’s AI agent builder, ServiceNow Build Agent, which allows developers to create agentic workflows and build apps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal also involves the rollout of Claude to the company’s 29,000 ServiceNow employees. Claude Code, Anthropic’s vibe-coding product, is also available to the company’s engineers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ServiceNow with Anthropic is turning intelligence into action through AI-native workflows for the world’s largest enterprises,” Bill McDermott, chairman and CEO of ServiceNow, said in a company press release. “Together, we are proving that deeply integrated platforms with an open ecosystem are how the future is built.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This news comes just a week after the company announced a new AI partnership with Anthropic rival OpenAI that involved giving ServiceNow customers access to OpenAI’s models through the company’s products.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ServiceNow president, COO and CPO, Amit Zavery, said the company is intentionally pursuing a multi-model strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We don’t view these partnerships as competitive or mutually exclusive,” Zavery said over email. “Enterprise customers want model choice. They want the right model for the right job — keeping governance, security, and auditability consistent on the ServiceNow AI Platform. Each model brings different strengths, and our role is to orchestrate them in ways that deliver the best outcomes for customers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This deal is just the latest one for Anthropic, which has announced a number of sizable enterprise deals in recent months. The company announced a deal with global insurance provider Allianz earlier this year and partnerships with Accenture, IBM, Deloitte, and Snowflake late last year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While enterprises have struggled thus far to find a measurable return on AI investment, VCs recently predicted that this will change in 2026 — although this is the third year in a row they have predicted that.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/servicenow-inks-another-ai-partnership-this-time-with-anthropic/</guid><pubDate>Wed, 28 Jan 2026 21:13:00 +0000</pubDate></item><item><title>[NEW] Elon Musk teases a new image-labeling system for X… we think? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/elon-musk-teases-a-new-image-labeling-system-for-xwe-think/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/twitter-x-logo-musk-2.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s X is the latest social network to roll out a feature to label edited images as “manipulated media,” if a post by Elon Musk is to be believed. But the company has not clarified how it will make this determination, or whether it includes images that have been edited using traditional tools, like Adobe’s Photoshop.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the only details on the new feature come from a cryptic X post from Elon Musk saying, “Edited visuals warning,” as he reshares an announcement of a new X feature made by the anonymous X account DogeDesigner. That account is often used as a proxy for introducing new X features, as Musk will repost from it to share news.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, details on the new system are thin. DogeDesigner’s post claimed X’s new feature could make it “harder for legacy media groups to spread misleading clips or pictures.” It also claimed the feature is new to X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before it was acquired and renamed as X, the company known as Twitter had labeled tweets using manipulated, deceptively altered, or fabricated media as an alternative to removing them. Its policy wasn’t limited to AI but included things like “selected editing or cropping or slowing down or overdubbing, or manipulation of subtitles,” the site integrity head, Yoel Roth, said in 2020.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear if X is adopting the same rules or has made any significant changes to tackle AI. Its help documentation currently says there’s a policy against sharing inauthentic media, but it’s rarely enforced, as the recent deepfake debacle of users sharing non-consensual nude images showed. In addition, even the White House now shares manipulated images.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Calling something “manipulated media” or an “AI image” can be nuanced. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that X is a playground for political propaganda, both domestically and abroad, some understanding of how the company determines what’s “edited,” or perhaps AI-generated or AI-manipulated, should be documented. In addition, users should know whether or not there’s any sort of dispute process beyond X’s crowdsourced Community Notes.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta discovered when it introduced AI image labeling in 2024, it’s easy for detection systems to go awry. In its case, Meta was found to be incorrectly tagging real photographs with its “Made with AI” label, even though they had not been created using generative AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This happened because AI features are increasingly being integrated into creative tools used by photographers and graphic artists. (Apple’s new Creator Studio suite, launching today, is one recent example.) &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As it turned out, this confused Meta’s identification tools. For instance, Adobe’s cropping tool was flattening images before saving them as a JPEG, triggering Meta’s AI detector. In another example, Adobe’s Generative AI Fill, which is used to remove objects — like wrinkles in a shirt, or an unwanted reflection — was also causing images to be labeled as “Made with AI,” when they were only edited with AI tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ultimately, Meta updated its label to say “AI info,” so as not to outright label images as “Made with AI” when they had not been. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, there’s a standards-setting body for verifying the authenticity and content provenance for digital content, known as the C2PA (Coalition for Content Provenance and Authenticity). There are also related initiatives like CAI, or Content Authenticity Initiative, and Project Origin, focused on adding tamper-evident provenance metadata to media content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Presumably, X’s implementation would abide by some sort of known process for identifying AI content, but X’s owner, Elon Musk, didn’t say what that is. Nor did he clarify whether he’s talking specifically about AI images, or just anything that’s not the photo being uploaded to X directly from your smartphone’s camera. It’s even unclear whether the feature is brand-new, as DogeDesigner claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;X isn’t the only outlet grappling with manipulated media. In addition to Meta, TikTok has also been labeling AI content. Streaming services like Deezer and Spotify are also scaling initiatives to identify and label AI music, as well. Google Photos is using C2PA to indicate how photos on its platform were made. Microsoft, the BBC, Adobe, Arm, Intel, Sony, OpenAI, and others are on the C2PA’s steering committee, while many more companies have joined as members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;X is not currently listed among the members, though we’ve reached out to C2PA to see if that recently changed. X doesn’t typically respond to requests for comment, but we asked anyway.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/08/twitter-x-logo-musk-2.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk’s X is the latest social network to roll out a feature to label edited images as “manipulated media,” if a post by Elon Musk is to be believed. But the company has not clarified how it will make this determination, or whether it includes images that have been edited using traditional tools, like Adobe’s Photoshop.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, the only details on the new feature come from a cryptic X post from Elon Musk saying, “Edited visuals warning,” as he reshares an announcement of a new X feature made by the anonymous X account DogeDesigner. That account is often used as a proxy for introducing new X features, as Musk will repost from it to share news.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Still, details on the new system are thin. DogeDesigner’s post claimed X’s new feature could make it “harder for legacy media groups to spread misleading clips or pictures.” It also claimed the feature is new to X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Before it was acquired and renamed as X, the company known as Twitter had labeled tweets using manipulated, deceptively altered, or fabricated media as an alternative to removing them. Its policy wasn’t limited to AI but included things like “selected editing or cropping or slowing down or overdubbing, or manipulation of subtitles,” the site integrity head, Yoel Roth, said in 2020.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s unclear if X is adopting the same rules or has made any significant changes to tackle AI. Its help documentation currently says there’s a policy against sharing inauthentic media, but it’s rarely enforced, as the recent deepfake debacle of users sharing non-consensual nude images showed. In addition, even the White House now shares manipulated images.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Calling something “manipulated media” or an “AI image” can be nuanced. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that X is a playground for political propaganda, both domestically and abroad, some understanding of how the company determines what’s “edited,” or perhaps AI-generated or AI-manipulated, should be documented. In addition, users should know whether or not there’s any sort of dispute process beyond X’s crowdsourced Community Notes.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;As Meta discovered when it introduced AI image labeling in 2024, it’s easy for detection systems to go awry. In its case, Meta was found to be incorrectly tagging real photographs with its “Made with AI” label, even though they had not been created using generative AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This happened because AI features are increasingly being integrated into creative tools used by photographers and graphic artists. (Apple’s new Creator Studio suite, launching today, is one recent example.) &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As it turned out, this confused Meta’s identification tools. For instance, Adobe’s cropping tool was flattening images before saving them as a JPEG, triggering Meta’s AI detector. In another example, Adobe’s Generative AI Fill, which is used to remove objects — like wrinkles in a shirt, or an unwanted reflection — was also causing images to be labeled as “Made with AI,” when they were only edited with AI tools.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ultimately, Meta updated its label to say “AI info,” so as not to outright label images as “Made with AI” when they had not been. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, there’s a standards-setting body for verifying the authenticity and content provenance for digital content, known as the C2PA (Coalition for Content Provenance and Authenticity). There are also related initiatives like CAI, or Content Authenticity Initiative, and Project Origin, focused on adding tamper-evident provenance metadata to media content.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Presumably, X’s implementation would abide by some sort of known process for identifying AI content, but X’s owner, Elon Musk, didn’t say what that is. Nor did he clarify whether he’s talking specifically about AI images, or just anything that’s not the photo being uploaded to X directly from your smartphone’s camera. It’s even unclear whether the feature is brand-new, as DogeDesigner claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;X isn’t the only outlet grappling with manipulated media. In addition to Meta, TikTok has also been labeling AI content. Streaming services like Deezer and Spotify are also scaling initiatives to identify and label AI music, as well. Google Photos is using C2PA to indicate how photos on its platform were made. Microsoft, the BBC, Adobe, Arm, Intel, Sony, OpenAI, and others are on the C2PA’s steering committee, while many more companies have joined as members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;X is not currently listed among the members, though we’ve reached out to C2PA to see if that recently changed. X doesn’t typically respond to requests for comment, but we asked anyway.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/elon-musk-teases-a-new-image-labeling-system-for-xwe-think/</guid><pubDate>Wed, 28 Jan 2026 21:46:18 +0000</pubDate></item><item><title>[NEW] Tesla to invest $2B in Elon Musk’s xAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/tesla-invested-2b-in-elon-musks-xai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/xAI-Grok-GettyImages-1765893916.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Three weeks ago, Elon Musk’s AI company, xAI, revealed it raised $20 billion in a Series E funding round. Now we know Tesla is among its investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla disclosed in a letter to shareholders on Wednesday that it invested $2 billion in xAI, the startup behind the Grok chatbot that also owns Musk’s social media company X. Other previously disclosed investors in xAI include Valor Equity Partners, Fidelity, Qatar Investment Authority, as well as Nvidia and Cisco as “strategic investors.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is a truly circular deal and one that Tesla shareholders voted against last year. In November, shareholders were asked in a nonbinding measure to allow the Tesla board to authorize an investment in xAI. About 1.06 billion votes were in favor, and 916.3 million opposed, per Bloomberg’s reporting at the time. While that would seem like an approval, the number of abstentions — which count as votes against in Tesla’s bylaws — meant the measure was rejected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla proceeded anyway and offered up an argument, in its shareholder letter and during its earnings call, in support of the investment. Tesla’s justification appears to be tied to xAI’s alignment with its most recent master plan — and how these companies are about to get a lot closer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As set forth in Master Plan Part IV, Tesla is building products and services that bring AI into the physical world. Meanwhile, xAI is developing leading digital AI products and services, such as its large language model (Grok),” the shareholder letter reads. “In that context, and as part of Tesla’s broader strategy under Master Plan Part IV, Tesla and xAI also entered into a framework agreement in connection with the investment.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla said the agreement builds upon an existing relationship with xAI by “providing a framework for evaluating potential AI collaborations between the companies.” Tesla already supplies its Megapack batteries to power xAI data centers, Musk confirmed last year, and the company has included the xAI chatbot Grok into some of its vehicles. Bloomberg also reported that xAI told investors it plans to build AI for humanoid robots like Tesla’s Optimus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk noted that there are many tasks Tesla can do internally. “But if there are things xAI can help accelerate our progress, then why should we not do that?” he asked. “And that is the reason why we’ve gone ahead with such an investment. Because this is part of the strategic initiative.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In its letter to shareholders, Tesla highlighted these and other developments in physical AI and robotics, including plans for developing its Optimus robot, semitrucks, and other autonomous capabilities. The company broadly beat Wall Street estimates on earnings and revenue, but profit fell 46% last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Together, the investment and the related framework agreement are intended to enhance Tesla’s ability to develop and deploy AI products and services into the physical world at scale,” Tesla said in the shareholder letter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investment is expected to close in the first quarter. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk and Tesla CFO Vaibhav Taneja signaled during the company’s earnings call it expect other capital expenditures that support its mission. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This year for Tesla is the first major steps as we increase vehicle autonomy and begin to produce Optimus robots at scale — we’re making very, very big investments,” Musk said on the call. “So this is going to be a very big capex here; that is deliberate, because we’re making big investments for an epic future.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/xAI-Grok-GettyImages-1765893916.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Three weeks ago, Elon Musk’s AI company, xAI, revealed it raised $20 billion in a Series E funding round. Now we know Tesla is among its investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla disclosed in a letter to shareholders on Wednesday that it invested $2 billion in xAI, the startup behind the Grok chatbot that also owns Musk’s social media company X. Other previously disclosed investors in xAI include Valor Equity Partners, Fidelity, Qatar Investment Authority, as well as Nvidia and Cisco as “strategic investors.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is a truly circular deal and one that Tesla shareholders voted against last year. In November, shareholders were asked in a nonbinding measure to allow the Tesla board to authorize an investment in xAI. About 1.06 billion votes were in favor, and 916.3 million opposed, per Bloomberg’s reporting at the time. While that would seem like an approval, the number of abstentions — which count as votes against in Tesla’s bylaws — meant the measure was rejected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla proceeded anyway and offered up an argument, in its shareholder letter and during its earnings call, in support of the investment. Tesla’s justification appears to be tied to xAI’s alignment with its most recent master plan — and how these companies are about to get a lot closer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“As set forth in Master Plan Part IV, Tesla is building products and services that bring AI into the physical world. Meanwhile, xAI is developing leading digital AI products and services, such as its large language model (Grok),” the shareholder letter reads. “In that context, and as part of Tesla’s broader strategy under Master Plan Part IV, Tesla and xAI also entered into a framework agreement in connection with the investment.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tesla said the agreement builds upon an existing relationship with xAI by “providing a framework for evaluating potential AI collaborations between the companies.” Tesla already supplies its Megapack batteries to power xAI data centers, Musk confirmed last year, and the company has included the xAI chatbot Grok into some of its vehicles. Bloomberg also reported that xAI told investors it plans to build AI for humanoid robots like Tesla’s Optimus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk noted that there are many tasks Tesla can do internally. “But if there are things xAI can help accelerate our progress, then why should we not do that?” he asked. “And that is the reason why we’ve gone ahead with such an investment. Because this is part of the strategic initiative.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In its letter to shareholders, Tesla highlighted these and other developments in physical AI and robotics, including plans for developing its Optimus robot, semitrucks, and other autonomous capabilities. The company broadly beat Wall Street estimates on earnings and revenue, but profit fell 46% last year.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Together, the investment and the related framework agreement are intended to enhance Tesla’s ability to develop and deploy AI products and services into the physical world at scale,” Tesla said in the shareholder letter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investment is expected to close in the first quarter. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Musk and Tesla CFO Vaibhav Taneja signaled during the company’s earnings call it expect other capital expenditures that support its mission. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This year for Tesla is the first major steps as we increase vehicle autonomy and begin to produce Optimus robots at scale — we’re making very, very big investments,” Musk said on the call. “So this is going to be a very big capex here; that is deliberate, because we’re making big investments for an epic future.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/tesla-invested-2b-in-elon-musks-xai/</guid><pubDate>Wed, 28 Jan 2026 21:52:21 +0000</pubDate></item><item><title>[NEW] Mark Zuckerberg says a future without smart glasses is ‘hard to imagine’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/mark-zuckerberg-future-smart-glasses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2173579243.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg spoke about his ambitions for Meta’s AI smart glasses business during Meta’s Q4 2025 earnings call on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After pivoting its Reality Labs investments away from the metaverse, Meta is doubling down on its production of AI wearables, as well as its own AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Billions of people wear glasses or contacts for vision correction. And I think that we’re at a moment similar to when smartphones arrived, and it was clearly only a matter of time until all those flip phones became smartphones,” Zuckerberg said. “It’s hard to imagine a world in several years where most glasses that people wear aren’t AI glasses.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that sales of Meta’s glasses tripled within the last year, and he believes that they’re “some of the fastest growing consumer electronics in history.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Take Zuckerberg’s outlook with a grain of salt. After all, he also thought that we would go to work and hang out with our friends in the metaverse — legs optional — and that didn’t work out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But based on how tech’s biggest players are allocating their money and effort, it does seem like AI glasses are poised for a big moment, even if it’s not on the scale of the smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is expected to launch a line of smart glasses this year, following a $150 million deal with Warby Parker. Apple is also reportedly planning to unveil smart glasses in the next year or two, moving some staff to that project instead of working on a lighter Vision Pro, according to Bloomberg. Meanwhile, Snap announced Tuesday that it would spin its AR glasses, Specs, into a new subsidiary to allow for “greater operational focus and alignment.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Even OpenAI, a company that has not yet ventured into hardware, is pursuing AI wearables, though it seems more focused on something like an AI pin or earbuds, rather than glasses. Apple is also rumored to be working on an AirTag-sized AI device —&amp;nbsp;though hopefully those efforts turn out better than the Humane AI pin.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Meta is leading the way in pushing smart glasses to market, with several different models already on sale. That includes Oakley smart glasses designed to be worn while exercising, which is the most promising use case we’ve personally seen for these devices thus far.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2173579243.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg spoke about his ambitions for Meta’s AI smart glasses business during Meta’s Q4 2025 earnings call on Wednesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;After pivoting its Reality Labs investments away from the metaverse, Meta is doubling down on its production of AI wearables, as well as its own AI models.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Billions of people wear glasses or contacts for vision correction. And I think that we’re at a moment similar to when smartphones arrived, and it was clearly only a matter of time until all those flip phones became smartphones,” Zuckerberg said. “It’s hard to imagine a world in several years where most glasses that people wear aren’t AI glasses.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that sales of Meta’s glasses tripled within the last year, and he believes that they’re “some of the fastest growing consumer electronics in history.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Take Zuckerberg’s outlook with a grain of salt. After all, he also thought that we would go to work and hang out with our friends in the metaverse — legs optional — and that didn’t work out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But based on how tech’s biggest players are allocating their money and effort, it does seem like AI glasses are poised for a big moment, even if it’s not on the scale of the smartphone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google is expected to launch a line of smart glasses this year, following a $150 million deal with Warby Parker. Apple is also reportedly planning to unveil smart glasses in the next year or two, moving some staff to that project instead of working on a lighter Vision Pro, according to Bloomberg. Meanwhile, Snap announced Tuesday that it would spin its AR glasses, Specs, into a new subsidiary to allow for “greater operational focus and alignment.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Even OpenAI, a company that has not yet ventured into hardware, is pursuing AI wearables, though it seems more focused on something like an AI pin or earbuds, rather than glasses. Apple is also rumored to be working on an AirTag-sized AI device —&amp;nbsp;though hopefully those efforts turn out better than the Humane AI pin.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For now, Meta is leading the way in pushing smart glasses to market, with several different models already on sale. That includes Oakley smart glasses designed to be worn while exercising, which is the most promising use case we’ve personally seen for these devices thus far.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/mark-zuckerberg-future-smart-glasses/</guid><pubDate>Wed, 28 Jan 2026 22:31:20 +0000</pubDate></item><item><title>[NEW] Zuckerberg teases agentic commerce tools and major AI rollout in 2026 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/28/zuckerberg-teases-agentic-commerce-tools-and-major-ai-rollout-in-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2204064825.jpg?resize=1200,814" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg says Meta users will start to see new AI models and products from the company in a matter of months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In 2025, we rebuilt the foundations of our AI program,” Zuckerberg said on an investor call Wednesday, referring to the company’s recently restructured AI lab. “Over the coming months, we’re going to start shipping our new models and products… and I expect us to steadily push the frontier over the course of the new year.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But while Zuckerberg didn’t give specific timelines or products, he highlighted AI-driven commerce as a particular area of focus for Meta.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This also has implications for commerce,” Zuckerberg continued. “New agentic shopping tools will allow people to find just the right set of products from the businesses in our catalog.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That proposal echoes broader interest in AI-powered shopping assistants across the industry. Both Google and OpenAI have built platforms for agent-enabled transactions, with companies like Stripe and Uber signed on as partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But while other AI labs have already built significant technical infrastructure, Meta believes its access to personal data will prove uniquely valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re starting to see the promise of AI that understands our personal context, including our history, our interests, our content and our relationships,” Zuckerberg said on the call. “A lot of what makes agents valuable is the unique context that they can see, and we believe that Meta will be able to provide a uniquely personal experience.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In December, Meta acquired the general-purpose agent developer Manus, which provides similar technology. At the time, Meta said it would “continue to operate and sell the Manus service, as well as integrate it into our products.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investor call was timed to the release of Meta’s most recent quarterly earnings, which also disclosed a significant increase in new infrastructure spending. The company now anticipates that it will spend between $115 billion and $135 billion on overall capital expenditures over the course of 2026, up from $72 billion in 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its official filing, Meta attributed the jump to “increased investment to support our Meta Superintelligence Labs efforts and core business.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While significant, the figure still falls short of the projected $600 billion that Zuckerberg reportedly projected for Meta’s infrastructure spending through 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has previously drawn criticism from investors for failing to clearly state how its massive AI investment will translate to the company’s bottom line. But while details are still thin, Zuckerberg made it clear that the AI lab’s work would reach the public soon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is going to be a big year for delivering personal superintelligence, accelerating our business, building infrastructure for the future, and shaping how our company will work going forward,” he told investors.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/GettyImages-2204064825.jpg?resize=1200,814" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg says Meta users will start to see new AI models and products from the company in a matter of months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In 2025, we rebuilt the foundations of our AI program,” Zuckerberg said on an investor call Wednesday, referring to the company’s recently restructured AI lab. “Over the coming months, we’re going to start shipping our new models and products… and I expect us to steadily push the frontier over the course of the new year.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But while Zuckerberg didn’t give specific timelines or products, he highlighted AI-driven commerce as a particular area of focus for Meta.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This also has implications for commerce,” Zuckerberg continued. “New agentic shopping tools will allow people to find just the right set of products from the businesses in our catalog.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That proposal echoes broader interest in AI-powered shopping assistants across the industry. Both Google and OpenAI have built platforms for agent-enabled transactions, with companies like Stripe and Uber signed on as partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But while other AI labs have already built significant technical infrastructure, Meta believes its access to personal data will prove uniquely valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re starting to see the promise of AI that understands our personal context, including our history, our interests, our content and our relationships,” Zuckerberg said on the call. “A lot of what makes agents valuable is the unique context that they can see, and we believe that Meta will be able to provide a uniquely personal experience.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In December, Meta acquired the general-purpose agent developer Manus, which provides similar technology. At the time, Meta said it would “continue to operate and sell the Manus service, as well as integrate it into our products.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The investor call was timed to the release of Meta’s most recent quarterly earnings, which also disclosed a significant increase in new infrastructure spending. The company now anticipates that it will spend between $115 billion and $135 billion on overall capital expenditures over the course of 2026, up from $72 billion in 2025.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its official filing, Meta attributed the jump to “increased investment to support our Meta Superintelligence Labs efforts and core business.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While significant, the figure still falls short of the projected $600 billion that Zuckerberg reportedly projected for Meta’s infrastructure spending through 2028.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has previously drawn criticism from investors for failing to clearly state how its massive AI investment will translate to the company’s bottom line. But while details are still thin, Zuckerberg made it clear that the AI lab’s work would reach the public soon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is going to be a big year for delivering personal superintelligence, accelerating our business, building infrastructure for the future, and shaping how our company will work going forward,” he told investors.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/28/zuckerberg-teases-agentic-commerce-tools-and-major-ai-rollout-in-2026/</guid><pubDate>Wed, 28 Jan 2026 23:16:02 +0000</pubDate></item></channel></rss>