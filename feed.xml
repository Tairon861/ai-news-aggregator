<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 02 Sep 2025 12:43:45 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>U.S. and Indian VCs just formed a $1B+ alliance to fund India’s deep tech startups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/01/u-s-and-indian-vcs-just-formed-a-1b-alliance-to-fund-indias-deep-tech-startups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/india-flag.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Eight U.S. and Indian venture capital and private equity firms — including storied investors Accel, Blume Ventures, Celesta Capital, and Premji Invest — have formed an unusual coalition to back India’s deep tech startups, pledging more than $1 billion over the next decade to strengthen U.S.-India tech ties.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The alliance addresses longstanding funding concerns. In April, Indian Commerce Minister Piyush Goyal drew criticism after slamming domestic startups for focusing on food delivery instead of innovation, contrasting them with Chinese firms in a presentation titled “India vs. China: The Startup Reality Check.” Several investors and founders countered that India lacks capital for deep tech ventures and said Goyal’s comments overlooked the determination of founders building for the local market. The new alliance appears to address these concerns, aiming to channel long-term private capital into deep tech ventures that many founders say have struggled to secure funding in India.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The move stands out because investors typically compete for deals rather than formally band together under a named alliance with binding pledges. While VCs often co-invest on a deal-by-deal basis, most cross-border collaboration occurs informally through individual fund strategies, rather than through coordinated capital blocs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called the India Deep Tech Investment Alliance, the group brings together Celesta Capital, Accel, Blume Ventures, Gaja Capital, Ideaspring Capital, Premji Invest, Tenacity Ventures, and Venture Catalysts, the firms said in a joint statement on Tuesday. The launch follows the Indian government’s approval of a ₹1 trillion (approximately $11 billion) Research, Development, and Innovation (RDI) scheme, announced in the national budget earlier this year to boost deep tech R&amp;amp;D.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the alliance, each member will commit private capital over a 5- to 10-year period to Indian-domiciled deep tech startups, the firms said. For now, there are relatively few such companies, as many of India’s best-known deep tech ventures with Indian founders are incorporated in the U.S. But New Delhi has made local incorporation a requirement for incentives under its new RDI scheme, which the alliance members aim to leverage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to funding, the members will offer mentorship and network access. The firms also plan to utilize the alliance to help their portfolio companies expand into the Indian market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is in line with the strategic interests of both India and the U.S. at the governmental level, focusing on critical and emerging technologies,” said Celesta Capital managing partner Arun Kumar, who will be the inaugural chair of the alliance, in an interview.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the geopolitical backdrop is complicated. In February, President Donald Trump and Prime Minister Narendra Modi launched the TRUST (Transforming the Relationship Utilizing Strategic Technology) initiative to deepen U.S.–India tech ties. But relations soon showed strain, as Trump imposed a 50% tariff on Indian goods last month over New Delhi’s continued purchases of Russian oil, a move analysts say has put the two leaders on opposite sides of a widening trade and geopolitical rift.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite those tensions, the alliance — notwithstanding the geopolitical rift between the two leaders — is betting on India as a hub for startups developing foundational technologies such as AI, semiconductors, space, quantum, robotics, biotech, energy, and climate tech.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We find India as a particularly interesting market, not just for the opportunities that exist for new companies that get started in India, but also for companies in the U.S. that are seeking to expand into the Indian market,” Sriram Vishwanathan, founding managing partner at Celesta Capital, told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Celesta Capital — an early backer of Indian startups such as space-tech venture Agnikul, drone maker IdeaForge, and AI-driven cancer diagnostics firm OneCell Diagnostics — spearheaded the effort after discussions with industry stakeholders and the Indian government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have put this thing together to actually energize the ecosystem and bring like-minded investors together,” Vishwanathan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The alliance will focus on early-stage startups — from seed to Series B — while steering clear of late-stage investments, Vishwanathan noted. He also stated that the billion-dollar-plus commitment is just the beginning, as “any long journey starts with the first step.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You could expect more firms to join this alliance, both financial VC firms and private equity firms,” he said. “You should also expect corporates to join who have pretty significant investment programs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the alliance does not set its own eligibility criteria for new members, Vishwanathan said participants must meet the Indian government’s conditions under the RDI scheme — including investing in “sunrise” sectors, backing India-domiciled startups, and securing local regulatory approvals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The alliance is just a platform for engaging with the government,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a group, the investors in the alliance plan to engage with the Indian government on policy and incentives to advance private industry’s interests and act as a unified voice, Vishwanathan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, regulatory changes rolled out without industry input have led to turmoil in India. Some such moves have drawn intense criticism from U.S. investors and were subsequently withdrawn following widespread outrage.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The alliance’s members will share information voluntarily and coordinate on pipeline development, due diligence and co-investment opportunities, the firms said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An advisory committee, comprising representatives from Accel, Premji Invest, and Venture Catalysts, among the early participants, will help establish shared objectives and ensure coordination while preserving the independence of each fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kumar stated that while he is the inaugural chair, the alliance’s leadership will rotate as it moves forward.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The alliance could prove a double-edged sword for Indian deep tech startups. While pooling long-term capital and giving a unified voice to the government appears to be a boon, there is risk if coordination falters, leaving promising companies caught in the gaps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the next decade, startups will build in India and export breakthrough solutions to the world. The tailwinds are in place: ambition, talent, policy intent, and patient capital,” said Accel partner Anand Daniel in a prepared statement.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/india-flag.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Eight U.S. and Indian venture capital and private equity firms — including storied investors Accel, Blume Ventures, Celesta Capital, and Premji Invest — have formed an unusual coalition to back India’s deep tech startups, pledging more than $1 billion over the next decade to strengthen U.S.-India tech ties.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The alliance addresses longstanding funding concerns. In April, Indian Commerce Minister Piyush Goyal drew criticism after slamming domestic startups for focusing on food delivery instead of innovation, contrasting them with Chinese firms in a presentation titled “India vs. China: The Startup Reality Check.” Several investors and founders countered that India lacks capital for deep tech ventures and said Goyal’s comments overlooked the determination of founders building for the local market. The new alliance appears to address these concerns, aiming to channel long-term private capital into deep tech ventures that many founders say have struggled to secure funding in India.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The move stands out because investors typically compete for deals rather than formally band together under a named alliance with binding pledges. While VCs often co-invest on a deal-by-deal basis, most cross-border collaboration occurs informally through individual fund strategies, rather than through coordinated capital blocs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Called the India Deep Tech Investment Alliance, the group brings together Celesta Capital, Accel, Blume Ventures, Gaja Capital, Ideaspring Capital, Premji Invest, Tenacity Ventures, and Venture Catalysts, the firms said in a joint statement on Tuesday. The launch follows the Indian government’s approval of a ₹1 trillion (approximately $11 billion) Research, Development, and Innovation (RDI) scheme, announced in the national budget earlier this year to boost deep tech R&amp;amp;D.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the alliance, each member will commit private capital over a 5- to 10-year period to Indian-domiciled deep tech startups, the firms said. For now, there are relatively few such companies, as many of India’s best-known deep tech ventures with Indian founders are incorporated in the U.S. But New Delhi has made local incorporation a requirement for incentives under its new RDI scheme, which the alliance members aim to leverage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to funding, the members will offer mentorship and network access. The firms also plan to utilize the alliance to help their portfolio companies expand into the Indian market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This is in line with the strategic interests of both India and the U.S. at the governmental level, focusing on critical and emerging technologies,” said Celesta Capital managing partner Arun Kumar, who will be the inaugural chair of the alliance, in an interview.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the geopolitical backdrop is complicated. In February, President Donald Trump and Prime Minister Narendra Modi launched the TRUST (Transforming the Relationship Utilizing Strategic Technology) initiative to deepen U.S.–India tech ties. But relations soon showed strain, as Trump imposed a 50% tariff on Indian goods last month over New Delhi’s continued purchases of Russian oil, a move analysts say has put the two leaders on opposite sides of a widening trade and geopolitical rift.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite those tensions, the alliance — notwithstanding the geopolitical rift between the two leaders — is betting on India as a hub for startups developing foundational technologies such as AI, semiconductors, space, quantum, robotics, biotech, energy, and climate tech.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We find India as a particularly interesting market, not just for the opportunities that exist for new companies that get started in India, but also for companies in the U.S. that are seeking to expand into the Indian market,” Sriram Vishwanathan, founding managing partner at Celesta Capital, told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Celesta Capital — an early backer of Indian startups such as space-tech venture Agnikul, drone maker IdeaForge, and AI-driven cancer diagnostics firm OneCell Diagnostics — spearheaded the effort after discussions with industry stakeholders and the Indian government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have put this thing together to actually energize the ecosystem and bring like-minded investors together,” Vishwanathan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The alliance will focus on early-stage startups — from seed to Series B — while steering clear of late-stage investments, Vishwanathan noted. He also stated that the billion-dollar-plus commitment is just the beginning, as “any long journey starts with the first step.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You could expect more firms to join this alliance, both financial VC firms and private equity firms,” he said. “You should also expect corporates to join who have pretty significant investment programs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the alliance does not set its own eligibility criteria for new members, Vishwanathan said participants must meet the Indian government’s conditions under the RDI scheme — including investing in “sunrise” sectors, backing India-domiciled startups, and securing local regulatory approvals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The alliance is just a platform for engaging with the government,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a group, the investors in the alliance plan to engage with the Indian government on policy and incentives to advance private industry’s interests and act as a unified voice, Vishwanathan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the past, regulatory changes rolled out without industry input have led to turmoil in India. Some such moves have drawn intense criticism from U.S. investors and were subsequently withdrawn following widespread outrage.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The alliance’s members will share information voluntarily and coordinate on pipeline development, due diligence and co-investment opportunities, the firms said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An advisory committee, comprising representatives from Accel, Premji Invest, and Venture Catalysts, among the early participants, will help establish shared objectives and ensure coordination while preserving the independence of each fund.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kumar stated that while he is the inaugural chair, the alliance’s leadership will rotate as it moves forward.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The alliance could prove a double-edged sword for Indian deep tech startups. While pooling long-term capital and giving a unified voice to the government appears to be a boon, there is risk if coordination falters, leaving promising companies caught in the gaps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Over the next decade, startups will build in India and export breakthrough solutions to the world. The tailwinds are in place: ambition, talent, policy intent, and patient capital,” said Accel partner Anand Daniel in a prepared statement.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/01/u-s-and-indian-vcs-just-formed-a-1b-alliance-to-fund-indias-deep-tech-startups/</guid><pubDate>Tue, 02 Sep 2025 03:30:00 +0000</pubDate></item><item><title>[NEW] Therapists are secretly using ChatGPT. Clients are triggered. (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122871/therapists-using-chatgpt-secretly/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/IMG_9643.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;  &lt;p&gt;“Suddenly, I was watching him use ChatGPT,” says Declan, 31, who lives in Los Angeles. “He was taking what I was saying and putting it into ChatGPT, and then summarizing or cherry-picking answers.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan was so shocked he didn’t say anything, and for the rest of the session he was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen. The session became even more surreal when Declan began echoing ChatGPT in his own responses, preempting his therapist.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I became the best patient ever,” he says, “because ChatGPT would be like, ‘Well, do you consider that your way of thinking might be a little too black and white?’ And I would be like, ‘Huh, you know, I think my way of thinking might be too black and white,’ and [my therapist would] be like, ‘&lt;em&gt;Exactly&lt;/em&gt;.’ I’m sure it was his dream session.”&lt;/p&gt; 
 &lt;p&gt;Among the questions racing through Declan’s mind was, “Is this legal?” When Declan raised the incident with his therapist at the next session—“It was super awkward, like a weird breakup”—the therapist cried. He explained he had felt they’d hit a wall and had begun looking for answers elsewhere.&lt;em&gt; &lt;/em&gt;“I was still charged for that session,” Declan says, laughing.&lt;/p&gt;  &lt;p&gt;The large language model (LLM) boom of the past few years has had unexpected ramifications for the field of psychotherapy, mostly due to the growing number of people substituting the likes of ChatGPT for human therapists. But less discussed is how some therapists themselves are integrating AI into their practice. As in many other professions, generative AI promises tantalizing efficiency savings, but its adoption risks compromising sensitive patient data and undermining a relationship in which trust is paramount.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Suspicious sentiments&lt;/h3&gt;  &lt;p&gt;Declan is not alone, as I can attest from personal experience. When I received a recent email from my therapist that seemed longer and more polished than usual, I initially felt heartened. It seemed to convey a kind, validating message, and its length made me feel that she’d taken the time to reflect on all of the points in my (rather sensitive) email.&lt;/p&gt;  &lt;p&gt;On closer inspection, though, her email seemed a little strange. It was in a new font, and the text displayed several AI “tells,” including liberal use of the Americanized em dash (we’re both from the UK), the signature impersonal style, and the habit of addressing each point made in the original email line by line.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;My positive feelings quickly drained away, to be replaced by disappointment and mistrust, once I realized ChatGPT likely had a hand in drafting the message—which my therapist confirmed when I asked her.&lt;/p&gt;  &lt;p&gt;Despite her assurance that she simply dictates longer emails using AI, I still felt uncertainty over the extent to which she, as opposed to the bot, was responsible for the sentiments expressed. I also couldn’t entirely shake the suspicion that she might have pasted my highly personal email wholesale into ChatGPT.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;When I took to the internet to see whether others had had similar experiences, I found plenty of examples of people receiving what they suspected were AI-generated communiqués from their therapists. Many, including Declan, had taken to Reddit to solicit emotional support and advice.&lt;/p&gt;  &lt;p&gt;So had Hope, 25, who lives on the east coast of the US, and had direct-messaged her therapist about the death of her dog. She soon received a message back. It would have been consoling and thoughtful—expressing how hard it must be “not having him by your side right now”—were it not for the reference to the AI prompt accidentally preserved at the top: “Here’s a more human, heartfelt version with a gentle, conversational tone.”&lt;/p&gt;  &lt;p&gt;Hope says she felt “honestly really surprised and confused.” “It was just a very strange feeling,” she says. “Then I started to feel kind of betrayed. … It definitely affected my trust in her.” This was especially problematic, she adds, because “part of why I was seeing her was for my trust issues.”&lt;/p&gt;  &lt;p&gt;Hope had believed her therapist to be competent and empathetic, and therefore “never would have suspected her to feel the need to use AI.” Her therapist was apologetic when confronted, and she explained that because she’d never had a pet herself, she’d turned to AI for help expressing the appropriate sentiment.&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;A disclosure dilemma&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Betrayal or not, there may be some merit to the argument that AI could help therapists better communicate with their clients. A 2025 study published in &lt;em&gt;PLOS Mental Health&lt;/em&gt; asked therapists to use ChatGPT to respond to vignettes describing problems of the kind patients might raise in therapy. Not only was a panel of 830 participants unable to distinguish between the human and AI responses, but AI responses were rated as conforming better to therapeutic best practice.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, when participants suspected responses to have been written by ChatGPT, they ranked them lower. (Responses written by ChatGPT but misattributed to therapists received the highest ratings overall.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similarly, Cornell University researchers found in a 2023 study that AI-generated messages can increase feelings of closeness and cooperation between interlocutors, but only if the recipient remains oblivious to the role of AI. The mere suspicion of its use was found to rapidly sour goodwill.&lt;/p&gt;  &lt;p&gt;“People value authenticity, particularly in psychotherapy,” says Adrian Aguilera, a clinical psychologist and professor at the University of California, Berkeley. “I think [using AI] can feel like, ‘You’re not taking my relationship seriously.’ Do I ChatGPT a response to my wife or my kids? That wouldn’t feel genuine.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In 2023, in the early days of generative AI, the online therapy service Koko conducted a clandestine experiment on its users, mixing in responses generated by GPT-3 with ones drafted by humans. They discovered that users tended to rate the AI-generated responses more positively. The revelation that users had unwittingly been experimented on, however, sparked outrage.&lt;/p&gt;  &lt;p&gt;The online therapy provider BetterHelp has also been subject to claims that its therapists have used AI to draft responses. In a Medium post, photographer Brendan Keen said his BetterHelp therapist admitted to using AI in their replies, leading to “an acute sense of betrayal” and persistent worry, despite reassurances, that his data privacy had been breached. He ended the relationship thereafter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A BetterHelp spokesperson told us the company “prohibits therapists from disclosing any member’s personal or health information to third-party artificial intelligence, or using AI to craft messages to members to the extent it might directly or indirectly have the potential to identify someone.”&lt;/p&gt;  &lt;p&gt;All these examples relate to undisclosed AI usage. Aguilera believes time-strapped therapists can make use of LLMs, but transparency is essential. “We have to be up-front and tell people, ‘Hey, I’m going to use this tool for X, Y, and Z’ and provide a rationale,” he says. People then receive AI-generated messages with that prior context, rather than assuming their therapist is “trying to be sneaky.”&lt;/p&gt; 
 &lt;p&gt;Psychologists are often working at the limits of their capacity, and levels of burnout in the profession are high, according to 2023 research conducted by the American Psychological Association. That context makes the appeal of AI-powered tools obvious.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But lack of disclosure risks permanently damaging trust. Hope decided to continue seeing her therapist, though she stopped working with her a little later for reasons she says were unrelated. “But I always thought about the AI Incident whenever I saw her,” she says.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Risking patient privacy&lt;/h3&gt;  &lt;p&gt;Beyond the transparency issue, many therapists are leery of using LLMs in the first place, says Margaret Morris, a clinical psychologist and affiliate faculty member at the University of Washington.&lt;/p&gt;  &lt;p&gt;“I think these tools might be really valuable for learning,” she says, noting that therapists should continue developing their expertise over the course of their career. “But I think we have to be super careful about patient data.” Morris calls Declan’s experience “alarming.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Therapists need to be aware that general-purpose AI chatbots like ChatGPT are not approved by the US Food and Drug Administration and are not HIPAA compliant, says Pardis Emami-Naeini, assistant professor of computer science at Duke University, who has researched the privacy and security implications of LLMs in a health context. (HIPAA is a set of US federal regulations that protect people’s sensitive health information.)&lt;/p&gt;  &lt;p&gt;“This creates significant risks for patient privacy if any information about the patient is disclosed or can be inferred by the AI,” she says.&lt;/p&gt;  &lt;p&gt;In a recent paper, Emami-Naeini found that many users wrongly believe ChatGPT &lt;em&gt;is&lt;/em&gt; HIPAA compliant, creating an unwarranted sense of trust in the tool. “I expect some therapists may share this misconception,” she says.&lt;/p&gt;  &lt;p&gt;As a relatively open person, Declan says, he wasn’t completely distraught to learn how his therapist was using ChatGPT. “Personally, I am not thinking, ‘Oh, my God, I have deep, dark secrets,’” he said. But it did still feel violating: “I can imagine that if I was suicidal, or on drugs, or cheating on my girlfriend … I wouldn’t want that to be put into ChatGPT.”&lt;/p&gt; 
 &lt;p&gt;When using AI to help with email, “it’s not as simple as removing obvious identifiers such as names and addresses,” says Emami-Naeini. “Sensitive information can often be inferred from seemingly nonsensitive details.”&lt;/p&gt;  &lt;p&gt;She adds, “Identifying and rephrasing all potential sensitive data requires time and expertise, which may conflict with the intended convenience of using AI tools. In all cases, therapists should disclose their use of AI to patients and seek consent.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A growing number of companies, including Heidi Health, Upheal, Lyssn, and Blueprint, are marketing specialized tools to therapists, such as AI-assisted note-taking, training, and transcription services. These companies say they are HIPAA compliant and store data securely using encryption and pseudonymization where necessary. But many therapists are still wary of the privacy implications—particularly of services that necessitate the recording of entire sessions.&lt;/p&gt;  &lt;p&gt;“Even if privacy protections are improved, there is always some risk of information leakage or secondary uses of data,” says Emami-Naeini.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;A 2020 hack on a Finnish mental health company, which resulted in tens of thousands of clients’ treatment records being accessed, serves as a warning. People on the list were blackmailed, and subsequently the entire trove was publicly released, revealing extremely sensitive details such as peoples’ experiences of child abuse and addiction problems.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What therapists stand to lose&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In addition to violation of data privacy, other risks are involved when psychotherapists consult LLMs on behalf of a client. Studies have found that although some specialized therapy bots can rival human-delivered interventions, advice from the likes of ChatGPT can cause more harm than good.&lt;/p&gt;  &lt;p&gt;A recent Stanford University study, for example, found that chatbots can fuel delusions and psychopathy by blindly validating a user rather than challenging them, as well as suffer from biases and engage in sycophancy. The same flaws could make it risky for therapists to consult chatbots on behalf of their clients. They could, for example, baselessly validate a therapist’s hunch, or lead them down the wrong path.&lt;/p&gt;  &lt;p&gt;Aguilera says he has played around with tools like ChatGPT while teaching mental health trainees, such as by entering hypothetical symptoms and asking the AI chatbot to make a diagnosis. The tool will produce lots of possible conditions, but it’s rather thin in its analysis, he says. The American Counseling Association recommends that AI not be used for mental health diagnosis at present.&lt;/p&gt;  &lt;p&gt;A study published in 2024 of an earlier version of ChatGPT similarly found it was too vague and general to be truly useful in diagnosis or devising treatment plans, and it was heavily biased toward suggesting people seek cognitive behavioral therapy as opposed to other types of therapy that might be more suitable.&lt;/p&gt;  &lt;p&gt;Daniel Kimmel, a psychiatrist and neuroscientist at Columbia University, conducted experiments with ChatGPT where he posed as a client having relationship troubles. He says he found the chatbot was a decent mimic when it came to “stock-in-trade” therapeutic responses, like normalizing and validating, asking for additional information, or highlighting certain cognitive or emotional associations.&lt;/p&gt;  &lt;p&gt;However, “it didn’t do a lot of digging,” he says. It didn’t attempt “to link seemingly or superficially unrelated things together into something cohesive … to come up with a story, an idea, a theory.”&lt;/p&gt;  &lt;p&gt;“I would be skeptical about using it to do the thinking for you,” he says. Thinking, he says, should be the job of therapists.&lt;/p&gt;  &lt;p&gt;Therapists could save time using AI-powered tech, but this benefit should be weighed against the needs of patients, says Morris: “Maybe you’re saving yourself a couple of minutes. But what are you giving away?”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/IMG_9643.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;  &lt;p&gt;“Suddenly, I was watching him use ChatGPT,” says Declan, 31, who lives in Los Angeles. “He was taking what I was saying and putting it into ChatGPT, and then summarizing or cherry-picking answers.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan was so shocked he didn’t say anything, and for the rest of the session he was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen. The session became even more surreal when Declan began echoing ChatGPT in his own responses, preempting his therapist.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I became the best patient ever,” he says, “because ChatGPT would be like, ‘Well, do you consider that your way of thinking might be a little too black and white?’ And I would be like, ‘Huh, you know, I think my way of thinking might be too black and white,’ and [my therapist would] be like, ‘&lt;em&gt;Exactly&lt;/em&gt;.’ I’m sure it was his dream session.”&lt;/p&gt; 
 &lt;p&gt;Among the questions racing through Declan’s mind was, “Is this legal?” When Declan raised the incident with his therapist at the next session—“It was super awkward, like a weird breakup”—the therapist cried. He explained he had felt they’d hit a wall and had begun looking for answers elsewhere.&lt;em&gt; &lt;/em&gt;“I was still charged for that session,” Declan says, laughing.&lt;/p&gt;  &lt;p&gt;The large language model (LLM) boom of the past few years has had unexpected ramifications for the field of psychotherapy, mostly due to the growing number of people substituting the likes of ChatGPT for human therapists. But less discussed is how some therapists themselves are integrating AI into their practice. As in many other professions, generative AI promises tantalizing efficiency savings, but its adoption risks compromising sensitive patient data and undermining a relationship in which trust is paramount.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Suspicious sentiments&lt;/h3&gt;  &lt;p&gt;Declan is not alone, as I can attest from personal experience. When I received a recent email from my therapist that seemed longer and more polished than usual, I initially felt heartened. It seemed to convey a kind, validating message, and its length made me feel that she’d taken the time to reflect on all of the points in my (rather sensitive) email.&lt;/p&gt;  &lt;p&gt;On closer inspection, though, her email seemed a little strange. It was in a new font, and the text displayed several AI “tells,” including liberal use of the Americanized em dash (we’re both from the UK), the signature impersonal style, and the habit of addressing each point made in the original email line by line.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;My positive feelings quickly drained away, to be replaced by disappointment and mistrust, once I realized ChatGPT likely had a hand in drafting the message—which my therapist confirmed when I asked her.&lt;/p&gt;  &lt;p&gt;Despite her assurance that she simply dictates longer emails using AI, I still felt uncertainty over the extent to which she, as opposed to the bot, was responsible for the sentiments expressed. I also couldn’t entirely shake the suspicion that she might have pasted my highly personal email wholesale into ChatGPT.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;When I took to the internet to see whether others had had similar experiences, I found plenty of examples of people receiving what they suspected were AI-generated communiqués from their therapists. Many, including Declan, had taken to Reddit to solicit emotional support and advice.&lt;/p&gt;  &lt;p&gt;So had Hope, 25, who lives on the east coast of the US, and had direct-messaged her therapist about the death of her dog. She soon received a message back. It would have been consoling and thoughtful—expressing how hard it must be “not having him by your side right now”—were it not for the reference to the AI prompt accidentally preserved at the top: “Here’s a more human, heartfelt version with a gentle, conversational tone.”&lt;/p&gt;  &lt;p&gt;Hope says she felt “honestly really surprised and confused.” “It was just a very strange feeling,” she says. “Then I started to feel kind of betrayed. … It definitely affected my trust in her.” This was especially problematic, she adds, because “part of why I was seeing her was for my trust issues.”&lt;/p&gt;  &lt;p&gt;Hope had believed her therapist to be competent and empathetic, and therefore “never would have suspected her to feel the need to use AI.” Her therapist was apologetic when confronted, and she explained that because she’d never had a pet herself, she’d turned to AI for help expressing the appropriate sentiment.&amp;nbsp;&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;A disclosure dilemma&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Betrayal or not, there may be some merit to the argument that AI could help therapists better communicate with their clients. A 2025 study published in &lt;em&gt;PLOS Mental Health&lt;/em&gt; asked therapists to use ChatGPT to respond to vignettes describing problems of the kind patients might raise in therapy. Not only was a panel of 830 participants unable to distinguish between the human and AI responses, but AI responses were rated as conforming better to therapeutic best practice.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, when participants suspected responses to have been written by ChatGPT, they ranked them lower. (Responses written by ChatGPT but misattributed to therapists received the highest ratings overall.)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Similarly, Cornell University researchers found in a 2023 study that AI-generated messages can increase feelings of closeness and cooperation between interlocutors, but only if the recipient remains oblivious to the role of AI. The mere suspicion of its use was found to rapidly sour goodwill.&lt;/p&gt;  &lt;p&gt;“People value authenticity, particularly in psychotherapy,” says Adrian Aguilera, a clinical psychologist and professor at the University of California, Berkeley. “I think [using AI] can feel like, ‘You’re not taking my relationship seriously.’ Do I ChatGPT a response to my wife or my kids? That wouldn’t feel genuine.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In 2023, in the early days of generative AI, the online therapy service Koko conducted a clandestine experiment on its users, mixing in responses generated by GPT-3 with ones drafted by humans. They discovered that users tended to rate the AI-generated responses more positively. The revelation that users had unwittingly been experimented on, however, sparked outrage.&lt;/p&gt;  &lt;p&gt;The online therapy provider BetterHelp has also been subject to claims that its therapists have used AI to draft responses. In a Medium post, photographer Brendan Keen said his BetterHelp therapist admitted to using AI in their replies, leading to “an acute sense of betrayal” and persistent worry, despite reassurances, that his data privacy had been breached. He ended the relationship thereafter.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A BetterHelp spokesperson told us the company “prohibits therapists from disclosing any member’s personal or health information to third-party artificial intelligence, or using AI to craft messages to members to the extent it might directly or indirectly have the potential to identify someone.”&lt;/p&gt;  &lt;p&gt;All these examples relate to undisclosed AI usage. Aguilera believes time-strapped therapists can make use of LLMs, but transparency is essential. “We have to be up-front and tell people, ‘Hey, I’m going to use this tool for X, Y, and Z’ and provide a rationale,” he says. People then receive AI-generated messages with that prior context, rather than assuming their therapist is “trying to be sneaky.”&lt;/p&gt; 
 &lt;p&gt;Psychologists are often working at the limits of their capacity, and levels of burnout in the profession are high, according to 2023 research conducted by the American Psychological Association. That context makes the appeal of AI-powered tools obvious.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But lack of disclosure risks permanently damaging trust. Hope decided to continue seeing her therapist, though she stopped working with her a little later for reasons she says were unrelated. “But I always thought about the AI Incident whenever I saw her,” she says.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Risking patient privacy&lt;/h3&gt;  &lt;p&gt;Beyond the transparency issue, many therapists are leery of using LLMs in the first place, says Margaret Morris, a clinical psychologist and affiliate faculty member at the University of Washington.&lt;/p&gt;  &lt;p&gt;“I think these tools might be really valuable for learning,” she says, noting that therapists should continue developing their expertise over the course of their career. “But I think we have to be super careful about patient data.” Morris calls Declan’s experience “alarming.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Therapists need to be aware that general-purpose AI chatbots like ChatGPT are not approved by the US Food and Drug Administration and are not HIPAA compliant, says Pardis Emami-Naeini, assistant professor of computer science at Duke University, who has researched the privacy and security implications of LLMs in a health context. (HIPAA is a set of US federal regulations that protect people’s sensitive health information.)&lt;/p&gt;  &lt;p&gt;“This creates significant risks for patient privacy if any information about the patient is disclosed or can be inferred by the AI,” she says.&lt;/p&gt;  &lt;p&gt;In a recent paper, Emami-Naeini found that many users wrongly believe ChatGPT &lt;em&gt;is&lt;/em&gt; HIPAA compliant, creating an unwarranted sense of trust in the tool. “I expect some therapists may share this misconception,” she says.&lt;/p&gt;  &lt;p&gt;As a relatively open person, Declan says, he wasn’t completely distraught to learn how his therapist was using ChatGPT. “Personally, I am not thinking, ‘Oh, my God, I have deep, dark secrets,’” he said. But it did still feel violating: “I can imagine that if I was suicidal, or on drugs, or cheating on my girlfriend … I wouldn’t want that to be put into ChatGPT.”&lt;/p&gt; 
 &lt;p&gt;When using AI to help with email, “it’s not as simple as removing obvious identifiers such as names and addresses,” says Emami-Naeini. “Sensitive information can often be inferred from seemingly nonsensitive details.”&lt;/p&gt;  &lt;p&gt;She adds, “Identifying and rephrasing all potential sensitive data requires time and expertise, which may conflict with the intended convenience of using AI tools. In all cases, therapists should disclose their use of AI to patients and seek consent.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A growing number of companies, including Heidi Health, Upheal, Lyssn, and Blueprint, are marketing specialized tools to therapists, such as AI-assisted note-taking, training, and transcription services. These companies say they are HIPAA compliant and store data securely using encryption and pseudonymization where necessary. But many therapists are still wary of the privacy implications—particularly of services that necessitate the recording of entire sessions.&lt;/p&gt;  &lt;p&gt;“Even if privacy protections are improved, there is always some risk of information leakage or secondary uses of data,” says Emami-Naeini.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;A 2020 hack on a Finnish mental health company, which resulted in tens of thousands of clients’ treatment records being accessed, serves as a warning. People on the list were blackmailed, and subsequently the entire trove was publicly released, revealing extremely sensitive details such as peoples’ experiences of child abuse and addiction problems.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What therapists stand to lose&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In addition to violation of data privacy, other risks are involved when psychotherapists consult LLMs on behalf of a client. Studies have found that although some specialized therapy bots can rival human-delivered interventions, advice from the likes of ChatGPT can cause more harm than good.&lt;/p&gt;  &lt;p&gt;A recent Stanford University study, for example, found that chatbots can fuel delusions and psychopathy by blindly validating a user rather than challenging them, as well as suffer from biases and engage in sycophancy. The same flaws could make it risky for therapists to consult chatbots on behalf of their clients. They could, for example, baselessly validate a therapist’s hunch, or lead them down the wrong path.&lt;/p&gt;  &lt;p&gt;Aguilera says he has played around with tools like ChatGPT while teaching mental health trainees, such as by entering hypothetical symptoms and asking the AI chatbot to make a diagnosis. The tool will produce lots of possible conditions, but it’s rather thin in its analysis, he says. The American Counseling Association recommends that AI not be used for mental health diagnosis at present.&lt;/p&gt;  &lt;p&gt;A study published in 2024 of an earlier version of ChatGPT similarly found it was too vague and general to be truly useful in diagnosis or devising treatment plans, and it was heavily biased toward suggesting people seek cognitive behavioral therapy as opposed to other types of therapy that might be more suitable.&lt;/p&gt;  &lt;p&gt;Daniel Kimmel, a psychiatrist and neuroscientist at Columbia University, conducted experiments with ChatGPT where he posed as a client having relationship troubles. He says he found the chatbot was a decent mimic when it came to “stock-in-trade” therapeutic responses, like normalizing and validating, asking for additional information, or highlighting certain cognitive or emotional associations.&lt;/p&gt;  &lt;p&gt;However, “it didn’t do a lot of digging,” he says. It didn’t attempt “to link seemingly or superficially unrelated things together into something cohesive … to come up with a story, an idea, a theory.”&lt;/p&gt;  &lt;p&gt;“I would be skeptical about using it to do the thinking for you,” he says. Thinking, he says, should be the job of therapists.&lt;/p&gt;  &lt;p&gt;Therapists could save time using AI-powered tech, but this benefit should be weighed against the needs of patients, says Morris: “Maybe you’re saving yourself a couple of minutes. But what are you giving away?”&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122871/therapists-using-chatgpt-secretly/</guid><pubDate>Tue, 02 Sep 2025 08:38:24 +0000</pubDate></item><item><title>[NEW] Can an AI doppelgänger help me do my job? (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122856/can-an-ai-doppelganger-help-me-do-my-job/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250926-james-ai2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Everywhere I look, I see AI clones. On X and LinkedIn, “thought leaders” and influencers offer their followers a chance to ask questions of their digital replicas. OnlyFans creators are having AI models of themselves chat, for a price, with followers. “Virtual human” salespeople in China are reportedly outselling real humans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Digital clones—AI models that replicate a specific person—package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention. But they’re also offering something the ChatGPTs of the world cannot: an AI that’s not smart in the general sense, but that 'thinks' like &lt;em&gt;you&lt;/em&gt; do.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Who are they for? Delphi, a startup that recently raised $16 million from funders including Anthropic and actor/director Olivia Wilde’s venture capital firm, Proximity Ventures, helps famous people create replicas that can speak with their fans in both chat and voice calls. It feels like MasterClass—the platform for instructional seminars led by celebrities—vaulted into the AI age. On its website, Delphi writes that modern leaders “possess potentially life-altering knowledge and wisdom, but their time is limited and access is constrained.”&lt;/p&gt;  &lt;p&gt;It has a library of official clones created by famous figures that you can speak with. Arnold Schwarzenegger, for example, told me, “I’m here to cut the crap and help you get stronger and happier,” before informing me cheerily that I’ve now been signed up to receive the &lt;em&gt;Arnold’s Pump Club&lt;/em&gt; newsletter. Even if his or other celebrities’ clones fall short of Delphi’s lofty vision of spreading “personalized wisdom at scale,” they at least seem to serve as a funnel to find fans, build mailing lists, or sell supplements.&lt;/p&gt; 
 &lt;p&gt;But what about for the rest of us? Could well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. I could see a replica popping into a virtual meeting with a PR representative, not to trick them into thinking it’s the real me, but simply to take a brief call on my behalf. A recording of this call might summarize how it went.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To find out, I tried making a clone. Tavus, a Y Combinator alum that raised $18 million last year, will build a video avatar of you (plans start at $59 per month) that can be coached to reflect your personality and can join video calls. These clones have the “emotional intelligence of humans, with the reach of machines,” according to the company. “Reporter’s assistant” does not appear on the company’s site as an example use case, but it does mention therapists, physician’s assistants, and other roles that could benefit from an AI clone.&lt;/p&gt; 
 &lt;p&gt;For Tavus’s onboarding process, I turned on my camera, read through a script to help it learn my voice (which also acted as a waiver, with me agreeing to lend my likeness to Tavus), and recorded one minute of me just sitting in silence. Within a few hours, my avatar was ready. Upon meeting this digital me, I found it looked and spoke like I do (though I hated its teeth). But faking my appearance was the easy part. Could it learn enough about me and what topics I cover to serve as a stand-in with minimal risk of embarrassing me?&lt;/p&gt;  &lt;p&gt;Via a helpful chatbot interface, Tavus walked me through how to craft my clone’s personality, asking what I wanted the replica to do. It then helped me formulate instructions that became its operating manual. I uploaded three dozen of my stories that it could use to reference what I cover. It may have benefited from having more of my content—interviews, reporting notes, and the like—but I would never share that data for a host of reasons, not the least of which being that the other people who appear in it have not consented to their sides of our conversations being used to train an AI replica.&lt;/p&gt;  &lt;p&gt;So in the realm of AI—where models learn from entire libraries of data—I didn’t give my clone all that much to learn from, but I was still hopeful it had enough to be useful.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Alas, conversationally it was a wild card. It acted overly excited about story pitches I would never pursue. It repeated itself, and it kept saying it was checking my schedule to set up a meeting with the real me, which it could not do as I never gave it access to my calendar. It spoke in loops, with no way for the person on the other end to wrap up the conversation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These are common early quirks, Tavus’s cofounder Quinn Favret told me. The clones typically rely on Meta’s Llama model, which “often aims to be more helpful than it truly is,” Favret says, and developers building on top of Tavus’s platform are often the ones who set instructions for how the clones finish conversations or access calendars.&lt;/p&gt;  &lt;p&gt;For my purposes, it was a bust. To be useful to me, my AI clone would need to show at least some basic instincts for understanding what I cover, and at the very least not creep out whoever’s on the other side of the conversation. My clone fell short.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Such a clone could be helpful in other jobs, though. If you’re an influencer looking for ways to engage with more fans, or a salesperson for whom work is a numbers game and a clone could give you a leg up, it might just work. You run the risk that your replica could go off the rails or embarrass the real you, but the tradeoffs might be reasonable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Favret told me some of Tavus’s bigger customers are companies using clones for health-care intake and job interviews. Replicas are also being used in corporate role-play, for practicing sales pitches or having HR-related conversations with employees, for example.&lt;/p&gt; 

 &lt;p&gt;But companies building clones are promising that they will be much more than cold-callers or telemarketing machines. Delphi says its clones will offer “meaningful, personal interactions at infinite scale,” and Tavus says its replicas have “a face, a brain, and memories” that enable “meaningful face-to-face conversations.” Favret also told me a growing number of Tavus’s customers are building clones for mentorship and even decision-making, like AI loan officers who use clones to qualify and filter applicants.&lt;/p&gt;  &lt;p&gt;Which is sort of the crux of it. Teaching an AI clone discernment, critical thinking, and taste—never mind the quirks of a specific person—is still the stuff of science fiction. That’s all fine when the person chatting with a clone is in on the bit (most of us know that Schwarzenegger’s replica, for example, will not coach me to be a better athlete).&lt;/p&gt;  &lt;p&gt;But as companies polish clones with “human” features and exaggerate their capabilities, I worry that people chasing efficiency will start using their replicas at best for roles that are cringeworthy, and at worst for making decisions they should never be entrusted with. In the end, these models are designed for scale, not fidelity. They can flatter us, amplify us, even sell for us—but they can’t quite become us.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250926-james-ai2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Everywhere I look, I see AI clones. On X and LinkedIn, “thought leaders” and influencers offer their followers a chance to ask questions of their digital replicas. OnlyFans creators are having AI models of themselves chat, for a price, with followers. “Virtual human” salespeople in China are reportedly outselling real humans.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Digital clones—AI models that replicate a specific person—package together a few technologies that have been around for a while now: hyperrealistic video models to match your appearance, lifelike voices based on just a couple of minutes of speech recordings, and conversational chatbots increasingly capable of holding our attention. But they’re also offering something the ChatGPTs of the world cannot: an AI that’s not smart in the general sense, but that 'thinks' like &lt;em&gt;you&lt;/em&gt; do.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Who are they for? Delphi, a startup that recently raised $16 million from funders including Anthropic and actor/director Olivia Wilde’s venture capital firm, Proximity Ventures, helps famous people create replicas that can speak with their fans in both chat and voice calls. It feels like MasterClass—the platform for instructional seminars led by celebrities—vaulted into the AI age. On its website, Delphi writes that modern leaders “possess potentially life-altering knowledge and wisdom, but their time is limited and access is constrained.”&lt;/p&gt;  &lt;p&gt;It has a library of official clones created by famous figures that you can speak with. Arnold Schwarzenegger, for example, told me, “I’m here to cut the crap and help you get stronger and happier,” before informing me cheerily that I’ve now been signed up to receive the &lt;em&gt;Arnold’s Pump Club&lt;/em&gt; newsletter. Even if his or other celebrities’ clones fall short of Delphi’s lofty vision of spreading “personalized wisdom at scale,” they at least seem to serve as a funnel to find fans, build mailing lists, or sell supplements.&lt;/p&gt; 
 &lt;p&gt;But what about for the rest of us? Could well-crafted clones serve as our stand-ins? I certainly feel stretched thin at work sometimes, wishing I could be in two places at once, and I bet you do too. I could see a replica popping into a virtual meeting with a PR representative, not to trick them into thinking it’s the real me, but simply to take a brief call on my behalf. A recording of this call might summarize how it went.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;To find out, I tried making a clone. Tavus, a Y Combinator alum that raised $18 million last year, will build a video avatar of you (plans start at $59 per month) that can be coached to reflect your personality and can join video calls. These clones have the “emotional intelligence of humans, with the reach of machines,” according to the company. “Reporter’s assistant” does not appear on the company’s site as an example use case, but it does mention therapists, physician’s assistants, and other roles that could benefit from an AI clone.&lt;/p&gt; 
 &lt;p&gt;For Tavus’s onboarding process, I turned on my camera, read through a script to help it learn my voice (which also acted as a waiver, with me agreeing to lend my likeness to Tavus), and recorded one minute of me just sitting in silence. Within a few hours, my avatar was ready. Upon meeting this digital me, I found it looked and spoke like I do (though I hated its teeth). But faking my appearance was the easy part. Could it learn enough about me and what topics I cover to serve as a stand-in with minimal risk of embarrassing me?&lt;/p&gt;  &lt;p&gt;Via a helpful chatbot interface, Tavus walked me through how to craft my clone’s personality, asking what I wanted the replica to do. It then helped me formulate instructions that became its operating manual. I uploaded three dozen of my stories that it could use to reference what I cover. It may have benefited from having more of my content—interviews, reporting notes, and the like—but I would never share that data for a host of reasons, not the least of which being that the other people who appear in it have not consented to their sides of our conversations being used to train an AI replica.&lt;/p&gt;  &lt;p&gt;So in the realm of AI—where models learn from entire libraries of data—I didn’t give my clone all that much to learn from, but I was still hopeful it had enough to be useful.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Alas, conversationally it was a wild card. It acted overly excited about story pitches I would never pursue. It repeated itself, and it kept saying it was checking my schedule to set up a meeting with the real me, which it could not do as I never gave it access to my calendar. It spoke in loops, with no way for the person on the other end to wrap up the conversation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;These are common early quirks, Tavus’s cofounder Quinn Favret told me. The clones typically rely on Meta’s Llama model, which “often aims to be more helpful than it truly is,” Favret says, and developers building on top of Tavus’s platform are often the ones who set instructions for how the clones finish conversations or access calendars.&lt;/p&gt;  &lt;p&gt;For my purposes, it was a bust. To be useful to me, my AI clone would need to show at least some basic instincts for understanding what I cover, and at the very least not creep out whoever’s on the other side of the conversation. My clone fell short.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Such a clone could be helpful in other jobs, though. If you’re an influencer looking for ways to engage with more fans, or a salesperson for whom work is a numbers game and a clone could give you a leg up, it might just work. You run the risk that your replica could go off the rails or embarrass the real you, but the tradeoffs might be reasonable.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Favret told me some of Tavus’s bigger customers are companies using clones for health-care intake and job interviews. Replicas are also being used in corporate role-play, for practicing sales pitches or having HR-related conversations with employees, for example.&lt;/p&gt; 

 &lt;p&gt;But companies building clones are promising that they will be much more than cold-callers or telemarketing machines. Delphi says its clones will offer “meaningful, personal interactions at infinite scale,” and Tavus says its replicas have “a face, a brain, and memories” that enable “meaningful face-to-face conversations.” Favret also told me a growing number of Tavus’s customers are building clones for mentorship and even decision-making, like AI loan officers who use clones to qualify and filter applicants.&lt;/p&gt;  &lt;p&gt;Which is sort of the crux of it. Teaching an AI clone discernment, critical thinking, and taste—never mind the quirks of a specific person—is still the stuff of science fiction. That’s all fine when the person chatting with a clone is in on the bit (most of us know that Schwarzenegger’s replica, for example, will not coach me to be a better athlete).&lt;/p&gt;  &lt;p&gt;But as companies polish clones with “human” features and exaggerate their capabilities, I worry that people chasing efficiency will start using their replicas at best for roles that are cringeworthy, and at worst for making decisions they should never be entrusted with. In the end, these models are designed for scale, not fidelity. They can flatter us, amplify us, even sell for us—but they can’t quite become us.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122856/can-an-ai-doppelganger-help-me-do-my-job/</guid><pubDate>Tue, 02 Sep 2025 09:00:00 +0000</pubDate></item><item><title>[NEW] How healthcare accelerator programs are changing care (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122698/how-healthcare-accelerator-programs-are-changing-care/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As healthcare faces mounting pressures, from rising costs and an aging population to widening disparities, forward thinking innovations are more essential than ever.&lt;/p&gt;  &lt;p&gt;Accelerator programs have proven to be powerful launchpads for health tech companies, often combining resources, mentorship, and technology that startups otherwise would not have access to. By joining these fast-moving platforms, startups are better able to rapidly innovate, enhance, and scale their healthcare solutions, bringing transformative approaches to hospitals and patients faster.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So, why are healthcare accelerators becoming essential to the evolution of the industry? There are key reasons why these programs are reshaping health innovation and explanations how they are helping to make care more personalized, proactive, and accessible.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122699" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-2160720116.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Empowering growth and scaling impact &lt;/strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs offer a powerful combination of guidance, resources, and connections to help early-stage startups grow, scale, and succeed in a complex industry.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Participants typically benefit from:&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;Expert mentorship from seasoned healthcare professionals, entrepreneurs, and industry leaders to navigate clinical, regulatory, and business challenges&lt;/li&gt;    &lt;li&gt;Access to valuable resources such as clinical data, testing environments, and technical infrastructure to refine and validate health tech solutions&lt;/li&gt;    &lt;li&gt;Strategic support for growth including investor introductions, partnership opportunities, and go-to-market guidance to expand reach and impact&amp;nbsp;&lt;/li&gt; &lt;/ul&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Speeding up innovation&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Accelerators help startups and early-stage companies bring their solutions to market faster by streamlining the path through one of the most complex industries: healthcare. Traditionally, innovation in this space is slowed by regulatory hurdles, extended sales cycles, clinical validation requirements, and fragmented data systems.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Through structured support, accelerators help companies refine their product market fit, navigate compliance and regulatory landscapes, integrate with healthcare systems, and gather the clinical evidence needed to build trust and credibility. They also open doors to early pilot opportunities, customer feedback, and strategic partnerships, compressing what could take years into just a few months.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By removing barriers and accelerating critical early steps, these programs enable digital health innovators to reach the market more efficiently, with stronger solutions and a clearer path to impact.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Connecting startups with key stakeholders&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Today, many accelerator programs are developed by large healthcare organizations that are driving change from within. These accelerator programs are especially beneficial to startups since they have strong partnerships with hospitals, pharma companies, insurance providers, and regulators. This gives startups a chance to validate their ideas in real-world settings, gather clinical feedback early, and scale more effectively.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Many accelerators also bring together people from different fields; doctors, engineers, data scientists, and designers, encouraging fresh perspectives on persistent problems like chronic disease management, preventative care, data interoperability, and patient engagement.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Breaking barriers to global expansion&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs act as gateways for international digital health companies looking to enter the U.S. market, often considered one of the most complex and highly regulated healthcare landscapes in the world. These programs provide tailored support to navigate U.S. compliance standards, understand payer and provider dynamics, and tailor offerings to meet the needs of U.S. patients and care delivery models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Through market-specific mentorship, strategic introductions, and access to a robust health innovation ecosystem, accelerators help international startups overcome geographic and regulatory barriers, enabling global ideas to scale and make an impact where they’re needed most.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building the future of healthcare&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The role of healthcare accelerator programs extends far beyond startup support. They are helping to redefine how innovation happens, shifting it from isolated efforts to collaborative ecosystems of change. By bridging gaps between early-stage technology and real-world implementation, these programs play a critical role in making healthcare more personalized, preventative, and equitable.&lt;/p&gt;  &lt;p&gt;As the digital transformation of healthcare continues, accelerator programs will remain indispensable in cultivating the next generation of breakthroughs, ensuring that bold ideas are not only born, but brought to life in meaningful, measurable ways.&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Spotlight: Mayo Clinic Platform_Accelerate&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One standout example of this innovation-forward approach is Mayo Clinic Platform_Accelerate, a 30-week accelerator program designed to help health tech startups reach market readiness. Participants gain access to de-identified clinical data, prototyping labs, and guidance from experts across clinical, regulatory, and business domains.&lt;/p&gt;  &lt;p&gt;By combining Mayo Clinic’s legacy of clinical excellence with a forward-thinking innovation model, the Mayo Clinic Platform_Accelerate program helps promising startups to refine their solutions and prepare for meaningful scale, transforming how care is delivered across the continuum.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding value in accelerator programs&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In a time when healthcare must evolve faster than ever, accelerator programs have become vital to the industry’s future. By supporting early-stage innovators with the tools, mentorship, and networks they need to succeed, these programs are paving the way for smarter, safer, and more connected care.&lt;/p&gt;  &lt;p&gt;Whether tackling chronic disease, reimagining patient engagement, or unlocking the power of data, the startups nurtured in accelerator programs are helping to shape a more resilient and responsive health system, one innovation at a time.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As healthcare faces mounting pressures, from rising costs and an aging population to widening disparities, forward thinking innovations are more essential than ever.&lt;/p&gt;  &lt;p&gt;Accelerator programs have proven to be powerful launchpads for health tech companies, often combining resources, mentorship, and technology that startups otherwise would not have access to. By joining these fast-moving platforms, startups are better able to rapidly innovate, enhance, and scale their healthcare solutions, bringing transformative approaches to hospitals and patients faster.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So, why are healthcare accelerators becoming essential to the evolution of the industry? There are key reasons why these programs are reshaping health innovation and explanations how they are helping to make care more personalized, proactive, and accessible.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122699" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-2160720116.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Empowering growth and scaling impact &lt;/strong&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs offer a powerful combination of guidance, resources, and connections to help early-stage startups grow, scale, and succeed in a complex industry.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Participants typically benefit from:&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;Expert mentorship from seasoned healthcare professionals, entrepreneurs, and industry leaders to navigate clinical, regulatory, and business challenges&lt;/li&gt;    &lt;li&gt;Access to valuable resources such as clinical data, testing environments, and technical infrastructure to refine and validate health tech solutions&lt;/li&gt;    &lt;li&gt;Strategic support for growth including investor introductions, partnership opportunities, and go-to-market guidance to expand reach and impact&amp;nbsp;&lt;/li&gt; &lt;/ul&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Speeding up innovation&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Accelerators help startups and early-stage companies bring their solutions to market faster by streamlining the path through one of the most complex industries: healthcare. Traditionally, innovation in this space is slowed by regulatory hurdles, extended sales cycles, clinical validation requirements, and fragmented data systems.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Through structured support, accelerators help companies refine their product market fit, navigate compliance and regulatory landscapes, integrate with healthcare systems, and gather the clinical evidence needed to build trust and credibility. They also open doors to early pilot opportunities, customer feedback, and strategic partnerships, compressing what could take years into just a few months.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;By removing barriers and accelerating critical early steps, these programs enable digital health innovators to reach the market more efficiently, with stronger solutions and a clearer path to impact.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Connecting startups with key stakeholders&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Today, many accelerator programs are developed by large healthcare organizations that are driving change from within. These accelerator programs are especially beneficial to startups since they have strong partnerships with hospitals, pharma companies, insurance providers, and regulators. This gives startups a chance to validate their ideas in real-world settings, gather clinical feedback early, and scale more effectively.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Many accelerators also bring together people from different fields; doctors, engineers, data scientists, and designers, encouraging fresh perspectives on persistent problems like chronic disease management, preventative care, data interoperability, and patient engagement.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Breaking barriers to global expansion&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Healthcare accelerator programs act as gateways for international digital health companies looking to enter the U.S. market, often considered one of the most complex and highly regulated healthcare landscapes in the world. These programs provide tailored support to navigate U.S. compliance standards, understand payer and provider dynamics, and tailor offerings to meet the needs of U.S. patients and care delivery models.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Through market-specific mentorship, strategic introductions, and access to a robust health innovation ecosystem, accelerators help international startups overcome geographic and regulatory barriers, enabling global ideas to scale and make an impact where they’re needed most.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building the future of healthcare&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The role of healthcare accelerator programs extends far beyond startup support. They are helping to redefine how innovation happens, shifting it from isolated efforts to collaborative ecosystems of change. By bridging gaps between early-stage technology and real-world implementation, these programs play a critical role in making healthcare more personalized, preventative, and equitable.&lt;/p&gt;  &lt;p&gt;As the digital transformation of healthcare continues, accelerator programs will remain indispensable in cultivating the next generation of breakthroughs, ensuring that bold ideas are not only born, but brought to life in meaningful, measurable ways.&lt;/p&gt; 

 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Spotlight: Mayo Clinic Platform_Accelerate&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One standout example of this innovation-forward approach is Mayo Clinic Platform_Accelerate, a 30-week accelerator program designed to help health tech startups reach market readiness. Participants gain access to de-identified clinical data, prototyping labs, and guidance from experts across clinical, regulatory, and business domains.&lt;/p&gt;  &lt;p&gt;By combining Mayo Clinic’s legacy of clinical excellence with a forward-thinking innovation model, the Mayo Clinic Platform_Accelerate program helps promising startups to refine their solutions and prepare for meaningful scale, transforming how care is delivered across the continuum.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Finding value in accelerator programs&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In a time when healthcare must evolve faster than ever, accelerator programs have become vital to the industry’s future. By supporting early-stage innovators with the tools, mentorship, and networks they need to succeed, these programs are paving the way for smarter, safer, and more connected care.&lt;/p&gt;  &lt;p&gt;Whether tackling chronic disease, reimagining patient engagement, or unlocking the power of data, the startups nurtured in accelerator programs are helping to shape a more resilient and responsive health system, one innovation at a time.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122698/how-healthcare-accelerator-programs-are-changing-care/</guid><pubDate>Tue, 02 Sep 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] What health care providers actually want from AI (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122688/what-health-care-providers-actually-want-from-ai/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In a market flooded with AI promises, health care decision-makers are no longer dazzled by flashy demos or abstract potential. &lt;a&gt;Today, they want pragmatic and pressure-tested products.&amp;nbsp;They want solutions that work for their clinicians, staff, patients, and their bottom line.&lt;/p&gt;  &lt;p&gt;To gain traction in 2025 and beyond, health care providers are looking for real-world solutions in AI right now.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122693" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-1477482140.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Solutions that fix real problems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems are looking at AI-enabled solutions that target their most urgent pain points: staffing shortages, clinician burnout, rising costs, and patient bottlenecks. These operational realities keep leadership up at night, and AI solutions&amp;nbsp; must directly address them.&lt;/p&gt;  &lt;p&gt;For instance, hospitals and health systems are eager for AI tools that can reduce documentation burden for physicians and nurses. Natural language processing (NLP) solutions that auto-generate clinical notes or streamline coding to free up time for direct patient care are far more compelling pitches than generic efficiency gains. Similarly, predictive analytics that help optimize staffing levels or manage patient flows can directly address operational workflow and improve throughput.&lt;/p&gt; 
 &lt;p&gt;Ultimately, if an AI solution doesn’t target these critical issues and deliver tangible benefits, it’s unlikely to capture serious buyer interest.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Demonstrate real-world results &lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AI solutions need validation in environments that mirror actual care settings. The first step toward that is to leverage high-quality, well-curated real-world data to drive reliable insights and avoid misleading results when building and refining AI models.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Then, hospitals and health systems need evidence that the solution does what it claims to do, for instance through independent-third party validation, pilot projects, peer-reviewed publications, or documented case studies.&lt;/p&gt;  &lt;p&gt;Mayo Clinic Platform offers a rigorous independent process where clinical, data science, and regulatory experts evaluate a solution for intended use, proposed value, and clinical and algorithmic performance, which gives innovators the credibility their solutions need to win the confidence of health-care leaders.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Integration with existing systems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;With so many demands, health-care IT leaders have little patience for standalone AI tools that create additional complexity. They want solutions that integrate seamlessly into existing systems and workflows. Compatibility with major electronic health record (EHR) platforms, robust APIs, and smooth data ingestion processes are now baseline requirements.&lt;/p&gt;  &lt;p&gt;Custom integrations that require significant IT resources—or worse, create duplicative work—are deal breakers for many organizations already stretched thin. The less disruption an AI solution introduces, the more likely it is to gain traction. This is the reason solution developers are turning to platforms like Mayo Clinic Platform Solutions Studio, a program that provides seamless integration, single implementation, expert guidance to reduce risk, and a simplified process to accelerate solution adoption among healthcare providers.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Explainability and transparency&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The importance of trust cannot be overstated when it comes to health care, and transparency and explainability are critical to establishing trust in AI. As AI models grow more complex, health-care providers recognize that simply knowing what an algorithm predicts isn’t enough. They also need to understand how it arrived at that insight.&lt;/p&gt;  &lt;p&gt;Health-care organizations are increasingly wary of black-box AI systems whose logic remains opaque. Instead, they’re demanding solutions that offer clear, understandable explanations clinicians can relay confidently to peers, patients, and regulators.&lt;/p&gt;  &lt;p&gt;As McKinsey research shows, organizations that embed explainability into their AI strategy not only reduce risk but also see higher adoption, better performance outcomes, and stronger financial returns. Solution developers that can demystify their models, provide transparent performance metrics, and build trust at every level will have a significant edge in today’s health-care market.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Clear ROI and low implementation burden&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems want to know precisely how quickly an AI solution will pay for itself, how much staff time it will save, and what costs it will help offset. The more specific and evidence-backed the answers, the better rate of adoption.&lt;/p&gt; 

 &lt;p&gt;Solution developers that offer comprehensive training and responsive support are far more likely to win deals and keep customers satisfied over the long term.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Alignment with regulatory and compliance needs&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;As AI adoption grows, so does regulatory scrutiny. Health-care providers are increasingly focused on ensuring that any new solution complies with HIPAA, data privacy laws, and emerging guidelines around AI governance and bias mitigation.&lt;/p&gt;  &lt;p&gt;Solution developers that can proactively demonstrate compliance provide significant peace of mind. Transparent data handling practices, rigorous security measures, and alignment with ethical AI principles are all becoming essential selling points as well.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A solution developer &lt;/strong&gt;&lt;strong&gt;that&lt;/strong&gt;&lt;strong&gt; understands health care&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Finally, it’s not just about the technology. Health-care providers want partners that genuinely understand the complexities of clinical care and hospital operations. They’re looking for partners that speak the language of health care, grasp the nuances of change management, and appreciate the realities of delivering patient care under tight margins and high stakes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Successful AI vendors recognize that even the best technology must fit into a highly human-centered and often unpredictable environment. Long-term partnerships, not short-term sales, are the goal.&lt;/p&gt;  &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Delivering true value with AI&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;  &lt;p&gt;To earn their trust and investment, AI developers must focus relentlessly on solving real problems, demonstrating proven results, integrating without friction, and maintaining transparency and compliance.&lt;/p&gt;  &lt;p&gt;Those that deliver on these expectations will have the chance to help shape the future of health care.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;Provided by&lt;/span&gt;Mayo Clinic Platform&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In a market flooded with AI promises, health care decision-makers are no longer dazzled by flashy demos or abstract potential. &lt;a&gt;Today, they want pragmatic and pressure-tested products.&amp;nbsp;They want solutions that work for their clinicians, staff, patients, and their bottom line.&lt;/p&gt;  &lt;p&gt;To gain traction in 2025 and beyond, health care providers are looking for real-world solutions in AI right now.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1122693" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/iStock-1477482140.jpg" /&gt;&lt;/figure&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Solutions that fix real problems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems are looking at AI-enabled solutions that target their most urgent pain points: staffing shortages, clinician burnout, rising costs, and patient bottlenecks. These operational realities keep leadership up at night, and AI solutions&amp;nbsp; must directly address them.&lt;/p&gt;  &lt;p&gt;For instance, hospitals and health systems are eager for AI tools that can reduce documentation burden for physicians and nurses. Natural language processing (NLP) solutions that auto-generate clinical notes or streamline coding to free up time for direct patient care are far more compelling pitches than generic efficiency gains. Similarly, predictive analytics that help optimize staffing levels or manage patient flows can directly address operational workflow and improve throughput.&lt;/p&gt; 
 &lt;p&gt;Ultimately, if an AI solution doesn’t target these critical issues and deliver tangible benefits, it’s unlikely to capture serious buyer interest.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Demonstrate real-world results &lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;AI solutions need validation in environments that mirror actual care settings. The first step toward that is to leverage high-quality, well-curated real-world data to drive reliable insights and avoid misleading results when building and refining AI models.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Then, hospitals and health systems need evidence that the solution does what it claims to do, for instance through independent-third party validation, pilot projects, peer-reviewed publications, or documented case studies.&lt;/p&gt;  &lt;p&gt;Mayo Clinic Platform offers a rigorous independent process where clinical, data science, and regulatory experts evaluate a solution for intended use, proposed value, and clinical and algorithmic performance, which gives innovators the credibility their solutions need to win the confidence of health-care leaders.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Integration with existing systems&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;With so many demands, health-care IT leaders have little patience for standalone AI tools that create additional complexity. They want solutions that integrate seamlessly into existing systems and workflows. Compatibility with major electronic health record (EHR) platforms, robust APIs, and smooth data ingestion processes are now baseline requirements.&lt;/p&gt;  &lt;p&gt;Custom integrations that require significant IT resources—or worse, create duplicative work—are deal breakers for many organizations already stretched thin. The less disruption an AI solution introduces, the more likely it is to gain traction. This is the reason solution developers are turning to platforms like Mayo Clinic Platform Solutions Studio, a program that provides seamless integration, single implementation, expert guidance to reduce risk, and a simplified process to accelerate solution adoption among healthcare providers.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Explainability and transparency&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The importance of trust cannot be overstated when it comes to health care, and transparency and explainability are critical to establishing trust in AI. As AI models grow more complex, health-care providers recognize that simply knowing what an algorithm predicts isn’t enough. They also need to understand how it arrived at that insight.&lt;/p&gt;  &lt;p&gt;Health-care organizations are increasingly wary of black-box AI systems whose logic remains opaque. Instead, they’re demanding solutions that offer clear, understandable explanations clinicians can relay confidently to peers, patients, and regulators.&lt;/p&gt;  &lt;p&gt;As McKinsey research shows, organizations that embed explainability into their AI strategy not only reduce risk but also see higher adoption, better performance outcomes, and stronger financial returns. Solution developers that can demystify their models, provide transparent performance metrics, and build trust at every level will have a significant edge in today’s health-care market.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Clear ROI and low implementation burden&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Hospitals and health systems want to know precisely how quickly an AI solution will pay for itself, how much staff time it will save, and what costs it will help offset. The more specific and evidence-backed the answers, the better rate of adoption.&lt;/p&gt; 

 &lt;p&gt;Solution developers that offer comprehensive training and responsive support are far more likely to win deals and keep customers satisfied over the long term.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Alignment with regulatory and compliance needs&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;As AI adoption grows, so does regulatory scrutiny. Health-care providers are increasingly focused on ensuring that any new solution complies with HIPAA, data privacy laws, and emerging guidelines around AI governance and bias mitigation.&lt;/p&gt;  &lt;p&gt;Solution developers that can proactively demonstrate compliance provide significant peace of mind. Transparent data handling practices, rigorous security measures, and alignment with ethical AI principles are all becoming essential selling points as well.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;A solution developer &lt;/strong&gt;&lt;strong&gt;that&lt;/strong&gt;&lt;strong&gt; understands health care&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Finally, it’s not just about the technology. Health-care providers want partners that genuinely understand the complexities of clinical care and hospital operations. They’re looking for partners that speak the language of health care, grasp the nuances of change management, and appreciate the realities of delivering patient care under tight margins and high stakes.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Successful AI vendors recognize that even the best technology must fit into a highly human-centered and often unpredictable environment. Long-term partnerships, not short-term sales, are the goal.&lt;/p&gt;  &lt;h2 class="wp-block-heading"&gt;&lt;strong&gt;Delivering true value with AI&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;  &lt;p&gt;To earn their trust and investment, AI developers must focus relentlessly on solving real problems, demonstrating proven results, integrating without friction, and maintaining transparency and compliance.&lt;/p&gt;  &lt;p&gt;Those that deliver on these expectations will have the chance to help shape the future of health care.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Mayo Clinic Platform. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122688/what-health-care-providers-actually-want-from-ai/</guid><pubDate>Tue, 02 Sep 2025 12:00:00 +0000</pubDate></item><item><title>[NEW] The Download: therapists secretly using AI, and Apple AirPods’ hearing aid potential (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/02/1122877/the-download-therapists-secretly-using-ai-and-apple-airpods-hearing-aid-potential/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Therapists are secretly using ChatGPT. Clients are triggered.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;&lt;p&gt;For the rest of the session, Declan was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen, who was taking what Declan was saying, putting it into ChatGPT, and then parroting its answers.&lt;/p&gt;  &lt;p&gt;But Declan is not alone. In fact, a growing number of people are reporting receiving AI-generated communiqués from their therapists. Clients’ trust and privacy are being abandoned in the process. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Laurie Clarke&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Apple AirPods: a gateway hearing aid&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ashley Shew&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;When the US Food and Drug Administration approved hearing-aid software for Apple’s AirPods Pro in September 2024, with a device price point around $200, I was excited.&lt;/p&gt;&lt;p&gt;I have hearing loss and tinnitus, and my everyday hearing aids cost just over $2,000. Ninety percent of the hearing-aid market is concentrated in the hands of a few companies, and there’s little competitive pricing. So I was thrilled that a major tech company has entered this field with the AirPods Pro 2. Here’s what I made of them.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from our new print edition, which is all about the future of security. &lt;/strong&gt;&lt;strong&gt;Subscribe here&lt;/strong&gt;&lt;strong&gt; to catch future copies when they land.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 MAHA is in chaos&lt;/strong&gt;&lt;br /&gt;RFK Jr’s movement is tearing itself apart over what it wants to achieve. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Trying to pressure food companies to alter their products is unlikely to work. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Ultra-processed food makes up a sizable proportion of the American diet. &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;RFK Jr’s plan to improve America’s diet is missing the point. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 DOGE is using AI to target SEC rules to ditch&lt;/strong&gt;&lt;br /&gt;Experts fear its decisions won’t be checked by qualified humans. (The Information $)&lt;br /&gt;+ &lt;em&gt;Can AI help DOGE slash government budgets? It’s complex. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Salesforce has replaced around 4,000 jobs with AI agents&lt;/strong&gt;&lt;br /&gt;It’s slashed its support staff team nearly in half. (SF Chronicle $)&lt;br /&gt;+ &lt;em&gt;Workers are trying to weather the AI-induced storm. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;AI is coming for the job market, security, and prosperity. &lt;/em&gt;(MIT Technology Review)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 What’s up with China’s EV industry?&lt;br /&gt;&lt;/strong&gt;Its cutthroat competitive practices are starting to grate on the government. (NYT $)&lt;br /&gt;+ &lt;em&gt;The country’s robotmakers are on the rise. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 A “nearly naked” black hole has been spotted&lt;/strong&gt;&lt;br /&gt;The never-before-seen black hole may have been created moments after the big bang. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 How to make quantum computers useful&lt;br /&gt;&lt;/strong&gt;Researchers have turned their attention towards making software for the machines. (FT $)&lt;br /&gt;+ &lt;em&gt;Why AI could eat quantum computing’s lunch. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 OnlyFans has a piracy problem&lt;br /&gt;&lt;/strong&gt;Adult creators’ content isn’t staying behind the paywall. (404 Media)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;8 These humans are paid to fix AI slop&lt;/strong&gt;&lt;br /&gt;Anyone can prompt AI, but the results aren’t always good. (NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The hottest gadget for kids is a landline phone&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;And they’re learning phone etiquette for the first time. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Meet iTunes’ diehard fans&lt;/strong&gt;&lt;br /&gt;They’re eschewing streaming platforms in favor of their digital libraries. (WP $)&lt;br /&gt;+ &lt;em&gt;How to break free of Spotify’s algorithm. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The calculator doesn’t construct facts about world knowledge and give them to you.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Elisha Roberts, assistant director at the nonprofit Colorado Education Initiative, tells Bloomberg she doesn’t buy the idea that AI is comparable to other classroom tools like the calculator.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/06/1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Supershoes are reshaping distance running&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Since 2016, when Nike introduced the Vaporfly, a paradigm-­shifting shoe that helped athletes run more efficiently (and therefore faster), the elite running world has muddled through a period of soul-searching over the impact of high-tech footwear on the sport.&lt;/p&gt;&lt;p&gt;“Supershoes” —which combine a lightweight, energy-­returning foam with a carbon-fiber plate for stiffness—have been behind every broken world record in distances from 5,000 meters to the marathon since 2020.&lt;/p&gt;&lt;p&gt;To some, this is a sign of progress. In much of the world, elite running lacks a widespread following. Record-breaking adds a layer of excitement. And the shoes have benefits beyond the clock: most important, they help minimize wear on the body and enable faster recovery from hard workouts and races.&lt;/p&gt;&lt;p&gt;Still, some argue that they’ve changed the sport too quickly. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Happy birthday to Keanu Reeves, who turns 61 today! Here’s a compilation of his hilariously bad acting in Bram Stroker’s Dracula.&lt;br /&gt;+ Why do some cats hate water, yet others love it?&lt;br /&gt;+ If you fancy setting a Guinness World Record, there’s a few still up for grabs.&lt;br /&gt;+ To mark world coconut day (what do you mean, you forgot?), check out these delicious-looking recipes 🥥&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Therapists are secretly using ChatGPT. Clients are triggered.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Declan would never have found out his therapist was using ChatGPT had it not been for a technical mishap. The connection was patchy during one of their online sessions, so Declan suggested they turn off their video feeds. Instead, his therapist began inadvertently sharing his screen.&lt;/p&gt;&lt;p&gt;For the rest of the session, Declan was privy to a real-time stream of ChatGPT analysis rippling across his therapist’s screen, who was taking what Declan was saying, putting it into ChatGPT, and then parroting its answers.&lt;/p&gt;  &lt;p&gt;But Declan is not alone. In fact, a growing number of people are reporting receiving AI-generated communiqués from their therapists. Clients’ trust and privacy are being abandoned in the process. Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Laurie Clarke&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Apple AirPods: a gateway hearing aid&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ashley Shew&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;When the US Food and Drug Administration approved hearing-aid software for Apple’s AirPods Pro in September 2024, with a device price point around $200, I was excited.&lt;/p&gt;&lt;p&gt;I have hearing loss and tinnitus, and my everyday hearing aids cost just over $2,000. Ninety percent of the hearing-aid market is concentrated in the hands of a few companies, and there’s little competitive pricing. So I was thrilled that a major tech company has entered this field with the AirPods Pro 2. Here’s what I made of them.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from our new print edition, which is all about the future of security. &lt;/strong&gt;&lt;strong&gt;Subscribe here&lt;/strong&gt;&lt;strong&gt; to catch future copies when they land.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 MAHA is in chaos&lt;/strong&gt;&lt;br /&gt;RFK Jr’s movement is tearing itself apart over what it wants to achieve. (WSJ $)&lt;br /&gt;+ &lt;em&gt;Trying to pressure food companies to alter their products is unlikely to work. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;Ultra-processed food makes up a sizable proportion of the American diet. &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;RFK Jr’s plan to improve America’s diet is missing the point. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 DOGE is using AI to target SEC rules to ditch&lt;/strong&gt;&lt;br /&gt;Experts fear its decisions won’t be checked by qualified humans. (The Information $)&lt;br /&gt;+ &lt;em&gt;Can AI help DOGE slash government budgets? It’s complex. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Salesforce has replaced around 4,000 jobs with AI agents&lt;/strong&gt;&lt;br /&gt;It’s slashed its support staff team nearly in half. (SF Chronicle $)&lt;br /&gt;+ &lt;em&gt;Workers are trying to weather the AI-induced storm. &lt;/em&gt;(Vox)&lt;br /&gt;+ &lt;em&gt;AI is coming for the job market, security, and prosperity. &lt;/em&gt;(MIT Technology Review)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;4 What’s up with China’s EV industry?&lt;br /&gt;&lt;/strong&gt;Its cutthroat competitive practices are starting to grate on the government. (NYT $)&lt;br /&gt;+ &lt;em&gt;The country’s robotmakers are on the rise. &lt;/em&gt;(FT $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 A “nearly naked” black hole has been spotted&lt;/strong&gt;&lt;br /&gt;The never-before-seen black hole may have been created moments after the big bang. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 How to make quantum computers useful&lt;br /&gt;&lt;/strong&gt;Researchers have turned their attention towards making software for the machines. (FT $)&lt;br /&gt;+ &lt;em&gt;Why AI could eat quantum computing’s lunch. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 OnlyFans has a piracy problem&lt;br /&gt;&lt;/strong&gt;Adult creators’ content isn’t staying behind the paywall. (404 Media)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;8 These humans are paid to fix AI slop&lt;/strong&gt;&lt;br /&gt;Anyone can prompt AI, but the results aren’t always good. (NBC News)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 The hottest gadget for kids is a landline phone&lt;/strong&gt;&amp;nbsp;&lt;br /&gt;And they’re learning phone etiquette for the first time. (Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Meet iTunes’ diehard fans&lt;/strong&gt;&lt;br /&gt;They’re eschewing streaming platforms in favor of their digital libraries. (WP $)&lt;br /&gt;+ &lt;em&gt;How to break free of Spotify’s algorithm. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“The calculator doesn’t construct facts about world knowledge and give them to you.”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Elisha Roberts, assistant director at the nonprofit Colorado Education Initiative, tells Bloomberg she doesn’t buy the idea that AI is comparable to other classroom tools like the calculator.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/06/1.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Supershoes are reshaping distance running&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Since 2016, when Nike introduced the Vaporfly, a paradigm-­shifting shoe that helped athletes run more efficiently (and therefore faster), the elite running world has muddled through a period of soul-searching over the impact of high-tech footwear on the sport.&lt;/p&gt;&lt;p&gt;“Supershoes” —which combine a lightweight, energy-­returning foam with a carbon-fiber plate for stiffness—have been behind every broken world record in distances from 5,000 meters to the marathon since 2020.&lt;/p&gt;&lt;p&gt;To some, this is a sign of progress. In much of the world, elite running lacks a widespread following. Record-breaking adds a layer of excitement. And the shoes have benefits beyond the clock: most important, they help minimize wear on the body and enable faster recovery from hard workouts and races.&lt;/p&gt;&lt;p&gt;Still, some argue that they’ve changed the sport too quickly. Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ Happy birthday to Keanu Reeves, who turns 61 today! Here’s a compilation of his hilariously bad acting in Bram Stroker’s Dracula.&lt;br /&gt;+ Why do some cats hate water, yet others love it?&lt;br /&gt;+ If you fancy setting a Guinness World Record, there’s a few still up for grabs.&lt;br /&gt;+ To mark world coconut day (what do you mean, you forgot?), check out these delicious-looking recipes 🥥&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/02/1122877/the-download-therapists-secretly-using-ai-and-apple-airpods-hearing-aid-potential/</guid><pubDate>Tue, 02 Sep 2025 12:10:00 +0000</pubDate></item></channel></rss>