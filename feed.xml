<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sun, 13 Jul 2025 02:03:56 +0000</lastBuildDate><item><title>xAI and Grok apologize for ‘horrific behavior’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/12/xai-and-grok-apologize-for-horrific-behavior/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2223576505.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In a series of posts on X, the AI chatbot Grok apologized for what it admitted was “horrific behavior.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The posts appear to be an official statement from xAI, the Elon Musk-led company behind Grok, as opposed to an AI-generated explanation for Grok’s posts. (xAI recently acquired X, where Grok is prominently featured.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Grok’s latest controversy comes after Musk had indicated he wanted to make the chatbot less “politically correct,” then declared on July 4 that the company had “improved @Grok significantly.” In short order, the chatbot was making posts criticizing Democrats and Hollywood’s “Jewish executives,” repeating antisemitic memes, and even expressing support for Adolf Hitler and referring to itself as “MechaHitler.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, xAI deleted some of Grok’s posts, temporarily took the chatbot offline, and updated its public system prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Turkey also banned the chatbot for insulting the country’s president, and X CEO Linda Yaccarino even announced that she was stepping down this week, although her announcement did not reference the latest Grok controversy and her departure was reportedly months in the making.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So after all that, on Saturday, xAI said, “First off, we deeply apologize for the horrific behavior that many experienced.” The company then blamed an “update to a code path upstream of the @grok bot,” which it emphasized was “independent of the underlying language model that powers @grok.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This update supposedly made Grok “susceptible to existing X user posts; including when such posts contained extremist views.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;xAI added that an “unintended action” had led to Grok receiving instructions such as, “You tell like it is and you are not afraid to offend people who are politically correct.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s explanation echoes Musk’s comments earlier this week claiming that Grok was “too compliant to user prompts” and “too eager to please and be manipulated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI’s posts do not mention reporting by TechCrunch and others who examined the chain-of-thought summaries for the just-launched Grok 4, finding that the latest version of the chatbot seems to consult Musk’s viewpoints and social media posts before addressing controversial topics.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And historian Angus Johnston pushed back against the idea that Grok was simply manipulated into posting offensive content. He wrote on Bluesky that xAI and Musk’s explanations are “easily falsified.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the most widely shared examples of Grok antisemitism was initiated by Grok with no previous bigoted posting in the thread — and with multiple users pushing back against Grok to no avail,” Johnston said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, Grok has also posted repeatedly about “white genocide,” expressed skepticism about the death toll of the Holocaust, and briefly censored unflattering facts about Musk and his then-ally Donald Trump. In those cases, xAI blamed “unauthorized” changes and rogue employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the controversy, Musk says Grok is coming to Tesla vehicles next week.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2223576505.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In a series of posts on X, the AI chatbot Grok apologized for what it admitted was “horrific behavior.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The posts appear to be an official statement from xAI, the Elon Musk-led company behind Grok, as opposed to an AI-generated explanation for Grok’s posts. (xAI recently acquired X, where Grok is prominently featured.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Grok’s latest controversy comes after Musk had indicated he wanted to make the chatbot less “politically correct,” then declared on July 4 that the company had “improved @Grok significantly.” In short order, the chatbot was making posts criticizing Democrats and Hollywood’s “Jewish executives,” repeating antisemitic memes, and even expressing support for Adolf Hitler and referring to itself as “MechaHitler.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, xAI deleted some of Grok’s posts, temporarily took the chatbot offline, and updated its public system prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Turkey also banned the chatbot for insulting the country’s president, and X CEO Linda Yaccarino even announced that she was stepping down this week, although her announcement did not reference the latest Grok controversy and her departure was reportedly months in the making.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So after all that, on Saturday, xAI said, “First off, we deeply apologize for the horrific behavior that many experienced.” The company then blamed an “update to a code path upstream of the @grok bot,” which it emphasized was “independent of the underlying language model that powers @grok.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This update supposedly made Grok “susceptible to existing X user posts; including when such posts contained extremist views.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;July 15&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;xAI added that an “unintended action” had led to Grok receiving instructions such as, “You tell like it is and you are not afraid to offend people who are politically correct.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s explanation echoes Musk’s comments earlier this week claiming that Grok was “too compliant to user prompts” and “too eager to please and be manipulated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI’s posts do not mention reporting by TechCrunch and others who examined the chain-of-thought summaries for the just-launched Grok 4, finding that the latest version of the chatbot seems to consult Musk’s viewpoints and social media posts before addressing controversial topics.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And historian Angus Johnston pushed back against the idea that Grok was simply manipulated into posting offensive content. He wrote on Bluesky that xAI and Musk’s explanations are “easily falsified.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One of the most widely shared examples of Grok antisemitism was initiated by Grok with no previous bigoted posting in the thread — and with multiple users pushing back against Grok to no avail,” Johnston said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In recent months, Grok has also posted repeatedly about “white genocide,” expressed skepticism about the death toll of the Holocaust, and briefly censored unflattering facts about Musk and his then-ally Donald Trump. In those cases, xAI blamed “unauthorized” changes and rogue employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the controversy, Musk says Grok is coming to Tesla vehicles next week.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/12/xai-and-grok-apologize-for-horrific-behavior/</guid><pubDate>Sat, 12 Jul 2025 17:13:39 +0000</pubDate></item><item><title>[NEW] Building voice AI that listens to everyone: Transfer learning and synthetic speech in action (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/building-voice-ai-that-listens-to-everyone-transfer-learning-and-synthetic-speech-in-action/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Have you ever thought about what it is like to use a voice assistant when your own voice does not match what the system expects? AI is not just reshaping how we hear the world; it is transforming who gets to be heard. In the age of conversational AI, accessibility has become a crucial benchmark for innovation. Voice assistants, transcription tools and audio-enabled interfaces are everywhere. One downside is that for millions of people with speech disabilities, these systems can often fall short.&lt;/p&gt;



&lt;p&gt;As someone who has worked extensively on speech and voice interfaces across automotive, consumer and mobile platforms, I have seen the promise of AI in enhancing how we communicate. In my experience leading development of hands-free calling, beamforming arrays and wake-word systems, I have often asked: What happens when a user’s voice falls outside the model’s comfort zone? That question has pushed me to think about inclusion not just as a feature but a responsibility.&lt;/p&gt;



&lt;p&gt;In this article, we will explore a new frontier: AI that can not only enhance voice clarity and performance, but fundamentally enable conversation for those who have been left behind by traditional voice technology.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-rethinking-conversational-ai-for-accessibility"&gt;Rethinking conversational AI for accessibility&lt;/h2&gt;



&lt;p&gt;To better understand how inclusive AI speech systems work, let us consider a high-level architecture that begins with nonstandard speech data and leverages transfer learning to fine-tune models. These models are designed specifically for atypical speech patterns, producing both recognized text and even synthetic voice outputs tailored for the user.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014133" height="145" src="https://venturebeat.com/wp-content/uploads/2025/07/image1.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Standard speech recognition systems struggle when faced with atypical speech patterns. Whether due to cerebral palsy, ALS, stuttering or vocal trauma, people with speech impairments are often misheard or ignored by current systems. But deep learning is helping change that. By training models on nonstandard speech data and applying transfer learning techniques, conversational AI systems can begin to understand a wider range of voices.&lt;/p&gt;



&lt;p&gt;Beyond recognition, generative AI is now being used to create synthetic voices based on small samples from users with speech disabilities. This allows users to train their own voice avatar, enabling more natural communication in digital spaces and preserving personal vocal identity.&lt;/p&gt;



&lt;p&gt;There are even platforms being developed where individuals can contribute their speech patterns, helping to expand public datasets and improve future inclusivity. These crowdsourced datasets could become critical assets for making AI systems truly universal.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-assistive-features-in-action"&gt;Assistive features in action&lt;/h2&gt;



&lt;p&gt;Real-time assistive voice augmentation systems follow a layered flow. Starting with speech input that may be disfluent or delayed, AI modules apply enhancement techniques, emotional inference and contextual modulation before producing clear, expressive synthetic speech. These systems help users speak not only intelligibly but meaningfully.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014134" height="138" src="https://venturebeat.com/wp-content/uploads/2025/07/image2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Have you ever imagined what it would feel like to speak fluidly with assistance from AI, even if your speech is impaired? Real-time voice augmentation is one such feature making strides. By enhancing articulation, filling in pauses or smoothing out disfluencies, AI acts like a co-pilot in conversation, helping users maintain control while improving intelligibility. For individuals using text-to-speech interfaces, conversational AI can now offer dynamic responses, sentiment-based phrasing, and prosody that matches user intent, bringing personality back to computer-mediated communication.&lt;/p&gt;



&lt;p&gt;Another promising area is predictive language modeling. Systems can learn a user’s unique phrasing or vocabulary tendencies, improve predictive text and speed up interaction. Paired with accessible interfaces such as eye-tracking keyboards or sip-and-puff controls, these models create a responsive and fluent conversation flow.&lt;/p&gt;



&lt;p&gt;Some developers are even integrating facial expression analysis to add more contextual understanding when speech is difficult. By combining multimodal input streams, AI systems can create a more nuanced and effective response pattern tailored to each individual’s mode of communication.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-personal-glimpse-voice-beyond-acoustics"&gt;A personal glimpse: Voice beyond acoustics&lt;/h2&gt;



&lt;p&gt;I once helped evaluate a prototype that synthesized speech from residual vocalizations of a user with late-stage ALS. Despite limited physical ability, the system adapted to her breathy phonations and reconstructed full-sentence speech with tone and emotion. Seeing her light up when she heard her “voice” speak again was a humbling reminder: AI is not just about performance metrics. It is about human dignity.&lt;/p&gt;



&lt;p&gt;I have worked on systems where emotional nuance was the last challenge to overcome. For people who rely on assistive technologies, being understood is important, but feeling understood is transformational. Conversational AI that adapts to emotions can help make this leap.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-implications-for-builders-of-conversational-ai"&gt;Implications for builders of conversational AI&lt;/h2&gt;



&lt;p&gt;For those designing the next generation of virtual assistants and voice-first platforms, accessibility should be built-in, not bolted on. This means collecting diverse training data, supporting non-verbal inputs, and using federated learning to preserve privacy while continuously improving models. It also means investing in low-latency edge processing, so users do not face delays that disrupt the natural rhythm of dialogue.&lt;/p&gt;



&lt;p&gt;Enterprises adopting AI-powered interfaces must consider not only usability, but inclusion. Supporting users with disabilities is not just ethical, it is a market opportunity. According to the World Health Organization, more than 1 billion people live with some form of disability. Accessible AI benefits everyone, from aging populations to multilingual users to those temporarily impaired.&lt;/p&gt;



&lt;p&gt;Additionally, there is a growing interest in explainable AI tools that help users understand how their input is processed. Transparency can build trust, especially among users with disabilities who rely on AI as a communication bridge.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-looking-forward"&gt;Looking forward&lt;/h2&gt;



&lt;p&gt;The promise of conversational AI is not just to understand speech, it is to understand people. For too long, voice technology has worked best for those who speak clearly, quickly and within a narrow acoustic range. With AI, we have the tools to build systems that listen more broadly and respond more compassionately.&lt;/p&gt;



&lt;p&gt;If we want the future of conversation to be truly intelligent, it must also be inclusive. And that starts with every voice in mind.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Harshal Shah is a voice technology specialist passionate about bridging human expression and machine understanding through inclusive voice solutions.&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Have you ever thought about what it is like to use a voice assistant when your own voice does not match what the system expects? AI is not just reshaping how we hear the world; it is transforming who gets to be heard. In the age of conversational AI, accessibility has become a crucial benchmark for innovation. Voice assistants, transcription tools and audio-enabled interfaces are everywhere. One downside is that for millions of people with speech disabilities, these systems can often fall short.&lt;/p&gt;



&lt;p&gt;As someone who has worked extensively on speech and voice interfaces across automotive, consumer and mobile platforms, I have seen the promise of AI in enhancing how we communicate. In my experience leading development of hands-free calling, beamforming arrays and wake-word systems, I have often asked: What happens when a user’s voice falls outside the model’s comfort zone? That question has pushed me to think about inclusion not just as a feature but a responsibility.&lt;/p&gt;



&lt;p&gt;In this article, we will explore a new frontier: AI that can not only enhance voice clarity and performance, but fundamentally enable conversation for those who have been left behind by traditional voice technology.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-rethinking-conversational-ai-for-accessibility"&gt;Rethinking conversational AI for accessibility&lt;/h2&gt;



&lt;p&gt;To better understand how inclusive AI speech systems work, let us consider a high-level architecture that begins with nonstandard speech data and leverages transfer learning to fine-tune models. These models are designed specifically for atypical speech patterns, producing both recognized text and even synthetic voice outputs tailored for the user.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014133" height="145" src="https://venturebeat.com/wp-content/uploads/2025/07/image1.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Standard speech recognition systems struggle when faced with atypical speech patterns. Whether due to cerebral palsy, ALS, stuttering or vocal trauma, people with speech impairments are often misheard or ignored by current systems. But deep learning is helping change that. By training models on nonstandard speech data and applying transfer learning techniques, conversational AI systems can begin to understand a wider range of voices.&lt;/p&gt;



&lt;p&gt;Beyond recognition, generative AI is now being used to create synthetic voices based on small samples from users with speech disabilities. This allows users to train their own voice avatar, enabling more natural communication in digital spaces and preserving personal vocal identity.&lt;/p&gt;



&lt;p&gt;There are even platforms being developed where individuals can contribute their speech patterns, helping to expand public datasets and improve future inclusivity. These crowdsourced datasets could become critical assets for making AI systems truly universal.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-assistive-features-in-action"&gt;Assistive features in action&lt;/h2&gt;



&lt;p&gt;Real-time assistive voice augmentation systems follow a layered flow. Starting with speech input that may be disfluent or delayed, AI modules apply enhancement techniques, emotional inference and contextual modulation before producing clear, expressive synthetic speech. These systems help users speak not only intelligibly but meaningfully.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3014134" height="138" src="https://venturebeat.com/wp-content/uploads/2025/07/image2.jpg?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Have you ever imagined what it would feel like to speak fluidly with assistance from AI, even if your speech is impaired? Real-time voice augmentation is one such feature making strides. By enhancing articulation, filling in pauses or smoothing out disfluencies, AI acts like a co-pilot in conversation, helping users maintain control while improving intelligibility. For individuals using text-to-speech interfaces, conversational AI can now offer dynamic responses, sentiment-based phrasing, and prosody that matches user intent, bringing personality back to computer-mediated communication.&lt;/p&gt;



&lt;p&gt;Another promising area is predictive language modeling. Systems can learn a user’s unique phrasing or vocabulary tendencies, improve predictive text and speed up interaction. Paired with accessible interfaces such as eye-tracking keyboards or sip-and-puff controls, these models create a responsive and fluent conversation flow.&lt;/p&gt;



&lt;p&gt;Some developers are even integrating facial expression analysis to add more contextual understanding when speech is difficult. By combining multimodal input streams, AI systems can create a more nuanced and effective response pattern tailored to each individual’s mode of communication.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-personal-glimpse-voice-beyond-acoustics"&gt;A personal glimpse: Voice beyond acoustics&lt;/h2&gt;



&lt;p&gt;I once helped evaluate a prototype that synthesized speech from residual vocalizations of a user with late-stage ALS. Despite limited physical ability, the system adapted to her breathy phonations and reconstructed full-sentence speech with tone and emotion. Seeing her light up when she heard her “voice” speak again was a humbling reminder: AI is not just about performance metrics. It is about human dignity.&lt;/p&gt;



&lt;p&gt;I have worked on systems where emotional nuance was the last challenge to overcome. For people who rely on assistive technologies, being understood is important, but feeling understood is transformational. Conversational AI that adapts to emotions can help make this leap.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-implications-for-builders-of-conversational-ai"&gt;Implications for builders of conversational AI&lt;/h2&gt;



&lt;p&gt;For those designing the next generation of virtual assistants and voice-first platforms, accessibility should be built-in, not bolted on. This means collecting diverse training data, supporting non-verbal inputs, and using federated learning to preserve privacy while continuously improving models. It also means investing in low-latency edge processing, so users do not face delays that disrupt the natural rhythm of dialogue.&lt;/p&gt;



&lt;p&gt;Enterprises adopting AI-powered interfaces must consider not only usability, but inclusion. Supporting users with disabilities is not just ethical, it is a market opportunity. According to the World Health Organization, more than 1 billion people live with some form of disability. Accessible AI benefits everyone, from aging populations to multilingual users to those temporarily impaired.&lt;/p&gt;



&lt;p&gt;Additionally, there is a growing interest in explainable AI tools that help users understand how their input is processed. Transparency can build trust, especially among users with disabilities who rely on AI as a communication bridge.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-looking-forward"&gt;Looking forward&lt;/h2&gt;



&lt;p&gt;The promise of conversational AI is not just to understand speech, it is to understand people. For too long, voice technology has worked best for those who speak clearly, quickly and within a narrow acoustic range. With AI, we have the tools to build systems that listen more broadly and respond more compassionately.&lt;/p&gt;



&lt;p&gt;If we want the future of conversation to be truly intelligent, it must also be inclusive. And that starts with every voice in mind.&lt;/p&gt;



&lt;p&gt;&lt;em&gt;Harshal Shah is a voice technology specialist passionate about bridging human expression and machine understanding through inclusive voice solutions.&lt;/em&gt;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/building-voice-ai-that-listens-to-everyone-transfer-learning-and-synthetic-speech-in-action/</guid><pubDate>Sat, 12 Jul 2025 20:45:00 +0000</pubDate></item><item><title>[NEW] A United Nations research institute created an AI refugee avatar (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/12/a-united-nations-research-institute-created-an-ai-refugee-avatar/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/AminaImage.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A research institute connected to the United Nations has created two AI-powered avatars designed to teach people about refugee issues.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;404 Media wrote about an experiment conducted by a class at the United Nations University Center for Policy Research that resulted in the creation of two AI agents or avatars — Amina, a fictional woman who fled Sudan and is living in a refugee camp in Chad, and Abdalla, a fictional soldier with the Rapid Support Forces, a paramilitary force in Sudan.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users are supposed to be able to talk to Amina and Abdalla on the experiment’s website, though I received an error message when I tried to register on Saturday afternoon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eduardo Albrecht, a Columbia professor and a senior fellow at the UNU-CPR, told 404 Media that he and his students were “just playing around with the concept” and not proposing this as a solution for the UN.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A paper summarizing this work suggested that these avatars could eventually be used “to quickly make a case to donors.” However, it also noted that many workshop attendees who interacted with the agents responded negatively, for example saying that refugees “are very capable of speaking for themselves in real life.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/AminaImage.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A research institute connected to the United Nations has created two AI-powered avatars designed to teach people about refugee issues.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;404 Media wrote about an experiment conducted by a class at the United Nations University Center for Policy Research that resulted in the creation of two AI agents or avatars — Amina, a fictional woman who fled Sudan and is living in a refugee camp in Chad, and Abdalla, a fictional soldier with the Rapid Support Forces, a paramilitary force in Sudan.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Users are supposed to be able to talk to Amina and Abdalla on the experiment’s website, though I received an error message when I tried to register on Saturday afternoon.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eduardo Albrecht, a Columbia professor and a senior fellow at the UNU-CPR, told 404 Media that he and his students were “just playing around with the concept” and not proposing this as a solution for the UN.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A paper summarizing this work suggested that these avatars could eventually be used “to quickly make a case to donors.” However, it also noted that many workshop attendees who interacted with the agents responded negatively, for example saying that refugees “are very capable of speaking for themselves in real life.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/12/a-united-nations-research-institute-created-an-ai-refugee-avatar/</guid><pubDate>Sat, 12 Jul 2025 21:03:39 +0000</pubDate></item></channel></rss>