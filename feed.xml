<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 07 Jan 2026 18:37:01 +0000</lastBuildDate><item><title>Grab brings robotics in-house to manage delivery costs (AI News)</title><link>https://www.artificialintelligence-news.com/news/grab-brings-robotics-in-house-to-manage-delivery-costs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Grab-brings-robotics-in-house-to-manage-delivery-costs-scaled-e1767752940871.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Rising labour costs and tighter delivery margins are pushing large platform operators like Grab to look at automation. It’s moved to bring robotics capability in-house by its acquisition of Infermove.&lt;/p&gt;&lt;p&gt;Grab operates at a scale where small efficiency gains can have out-sized effects. Its platform supports millions of deliveries in Southeast Asia, many of them carried out by riders on scooters and bicycles in dense urban areas, producing complexity that limits how much automation could replace human labour. By acquiring a company focused on robots designed for unstructured settings, Grab sees physical-world AI as mature enough to use in cases outside pilot programmes.&lt;/p&gt;&lt;h3&gt;Delivery automation close to core operations&lt;/h3&gt;&lt;p&gt;Rather than relying on off-the-shelf systems, Grab is opting to internalise the development loop. Infermove’s technology is designed to learn from real-world movement data, including information generated by non-motorised delivery vehicles. In practical terms, that means robots trained on how people actually navigate pavements, crossings, and crowded drop-off points, rather than how those spaces appear in simulations.&lt;/p&gt;&lt;p&gt;For a delivery operator like Grab, that distinction matters. Simulated environments can support early development, but they often struggle with the edge cases that define real cities. Bringing that learning process in-house allows Grab to shape how automation behaves under its own operating constraints, rather than adapting its delivery network to fit a third-party system.&lt;/p&gt;&lt;p&gt;From an enterprise perspective, the strategic value lies in control. Owning the technology gives Grab more influence over deployment pace, operating scope, and cost trade-offs. It also reduces long-term dependence on vendors whose priorities may not match Grab’s regional footprint or economic realities.&lt;/p&gt;&lt;p&gt;Automation, however, is not positioned as a replacement for human riders. Even as robots take on parts of the workflow, people remain central to service delivery. Grab’s interest appears focused on selective use, like structured first-mile or last-mile segments where tasks are repetitive and distances are short. In these areas, robots may help smooth demand spikes, reduce delays during peak hours, and ease pressure during labour shortages.&lt;/p&gt;&lt;h3&gt;Managing cost pressure without breaking service&lt;/h3&gt;&lt;p&gt;During an internal meeting in December, Grab’s chief technology officer Suthen Thomas described Infermove’s progress as “impressive,” highlighting both the technology and its early commercial use. He also said the company would continue to operate independently, with its founder reporting directly to him. The structure suggests Grab is prioritising execution and continuity rather than rapid organisational integration.&lt;/p&gt;&lt;p&gt;The approach reflects a broader shift among large digital platforms. Instead of treating AI as a layer added on top of existing systems, companies are embedding it deeper into core operations. In delivery and logistics, that often means moving beyond optimisation software into physical automation, where the risks and costs are higher but the potential gains are more structural.&lt;/p&gt;&lt;p&gt;The timing is also telling. On-demand delivery volumes continue to grow, but margins remain under pressure. Customers expect faster service and lower fees, while operators face rising wages, fuel costs, and tighter regulation. In that environment, automation becomes less about novelty and more about sustaining service levels without eroding profitability.&lt;/p&gt;&lt;p&gt;Bringing robotics development closer to operations may also help align incentives around data use. Training physical AI systems requires large amounts of real-world data, which delivery platforms already generate at scale. Keeping that feedback loop internal can speed iteration and reduce the need to share sensitive operational data externally.&lt;/p&gt;&lt;p&gt;There are still limits. Robots designed for pavements and short routes are unlikely to replace human couriers in an entire network anytime soon. Weather, local rules, and customer acceptance will continue to shape where automation can realistically operate. Expanding in multiple countries adds further complexity, as infrastructure and regulations vary widely.&lt;/p&gt;&lt;p&gt;Industry forecasts suggest rapid growth in last-mile delivery robotics, but those figures offer limited guidance for operators. The more immediate question is whether automation can lower cost per delivery without introducing new failure points. That depends less on market size and more on performance in live environments.&lt;/p&gt;&lt;p&gt;Seen through an enterprise lens, the acquisition of Infermove is not a bet on robotics as a product category. It is a move to tighten the link between AI, data, and physical operations. For platform companies built on logistics and mobility, that integration may become a key factor in managing growth under sustained cost pressure.&lt;/p&gt;&lt;p&gt;(Photo by Afif Ramdhasuma)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: The Law Society: Current laws are fit for the AI era&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/Grab-brings-robotics-in-house-to-manage-delivery-costs-scaled-e1767752940871.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Rising labour costs and tighter delivery margins are pushing large platform operators like Grab to look at automation. It’s moved to bring robotics capability in-house by its acquisition of Infermove.&lt;/p&gt;&lt;p&gt;Grab operates at a scale where small efficiency gains can have out-sized effects. Its platform supports millions of deliveries in Southeast Asia, many of them carried out by riders on scooters and bicycles in dense urban areas, producing complexity that limits how much automation could replace human labour. By acquiring a company focused on robots designed for unstructured settings, Grab sees physical-world AI as mature enough to use in cases outside pilot programmes.&lt;/p&gt;&lt;h3&gt;Delivery automation close to core operations&lt;/h3&gt;&lt;p&gt;Rather than relying on off-the-shelf systems, Grab is opting to internalise the development loop. Infermove’s technology is designed to learn from real-world movement data, including information generated by non-motorised delivery vehicles. In practical terms, that means robots trained on how people actually navigate pavements, crossings, and crowded drop-off points, rather than how those spaces appear in simulations.&lt;/p&gt;&lt;p&gt;For a delivery operator like Grab, that distinction matters. Simulated environments can support early development, but they often struggle with the edge cases that define real cities. Bringing that learning process in-house allows Grab to shape how automation behaves under its own operating constraints, rather than adapting its delivery network to fit a third-party system.&lt;/p&gt;&lt;p&gt;From an enterprise perspective, the strategic value lies in control. Owning the technology gives Grab more influence over deployment pace, operating scope, and cost trade-offs. It also reduces long-term dependence on vendors whose priorities may not match Grab’s regional footprint or economic realities.&lt;/p&gt;&lt;p&gt;Automation, however, is not positioned as a replacement for human riders. Even as robots take on parts of the workflow, people remain central to service delivery. Grab’s interest appears focused on selective use, like structured first-mile or last-mile segments where tasks are repetitive and distances are short. In these areas, robots may help smooth demand spikes, reduce delays during peak hours, and ease pressure during labour shortages.&lt;/p&gt;&lt;h3&gt;Managing cost pressure without breaking service&lt;/h3&gt;&lt;p&gt;During an internal meeting in December, Grab’s chief technology officer Suthen Thomas described Infermove’s progress as “impressive,” highlighting both the technology and its early commercial use. He also said the company would continue to operate independently, with its founder reporting directly to him. The structure suggests Grab is prioritising execution and continuity rather than rapid organisational integration.&lt;/p&gt;&lt;p&gt;The approach reflects a broader shift among large digital platforms. Instead of treating AI as a layer added on top of existing systems, companies are embedding it deeper into core operations. In delivery and logistics, that often means moving beyond optimisation software into physical automation, where the risks and costs are higher but the potential gains are more structural.&lt;/p&gt;&lt;p&gt;The timing is also telling. On-demand delivery volumes continue to grow, but margins remain under pressure. Customers expect faster service and lower fees, while operators face rising wages, fuel costs, and tighter regulation. In that environment, automation becomes less about novelty and more about sustaining service levels without eroding profitability.&lt;/p&gt;&lt;p&gt;Bringing robotics development closer to operations may also help align incentives around data use. Training physical AI systems requires large amounts of real-world data, which delivery platforms already generate at scale. Keeping that feedback loop internal can speed iteration and reduce the need to share sensitive operational data externally.&lt;/p&gt;&lt;p&gt;There are still limits. Robots designed for pavements and short routes are unlikely to replace human couriers in an entire network anytime soon. Weather, local rules, and customer acceptance will continue to shape where automation can realistically operate. Expanding in multiple countries adds further complexity, as infrastructure and regulations vary widely.&lt;/p&gt;&lt;p&gt;Industry forecasts suggest rapid growth in last-mile delivery robotics, but those figures offer limited guidance for operators. The more immediate question is whether automation can lower cost per delivery without introducing new failure points. That depends less on market size and more on performance in live environments.&lt;/p&gt;&lt;p&gt;Seen through an enterprise lens, the acquisition of Infermove is not a bet on robotics as a product category. It is a move to tighten the link between AI, data, and physical operations. For platform companies built on logistics and mobility, that integration may become a key factor in managing growth under sustained cost pressure.&lt;/p&gt;&lt;p&gt;(Photo by Afif Ramdhasuma)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: The Law Society: Current laws are fit for the AI era&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/grab-brings-robotics-in-house-to-manage-delivery-costs/</guid><pubDate>Wed, 07 Jan 2026 10:00:00 +0000</pubDate></item><item><title>The man who made India digital isn’t done yet (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/07/1129748/aadhaar-nandan-nilekani-india-digital-biometric-identity-data/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Nandan Nilekani can’t stop trying to push India into the future. He started nearly 30 years ago, masterminding an ongoing experiment in technological state capacity that started with Aadhaar—the world’s largest digital identity system. Aadhaar means “foundation” in Hindi, and on that bedrock Nilekani and people working with him went on to build a sprawling collection of free, interoperating online tools that add up to nothing less than a digital infrastructure for society. They cover government services, digital payments, banking, credit, and health care, offering convenience and access that would be eye-popping in wealthy countries a tenth of India’s size. In India those systems are called, collectively, “digital public infrastructure,” or DPI.&lt;/p&gt;  &lt;p&gt;At 70 years old, Nilekani should be retired. But he has a few more ideas. India’s electrical grid is creaky and prone to failure; Nilekani wants to add a layer of digital communication to stabilize it. And then there’s his idea to expand the financial functions in DPI to the rest of the world, creating a global digital backbone for commerce that he calls the “finternet.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;“It sounds like some crazy stuff,” Nilekani says. “But I think these are all big ideas, which over the next five years will have demonstrable, material impact.” As a last act in public life, why not Aadhaarize the world?&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;India’s digital backbone&lt;/h3&gt;  &lt;p&gt;Today, a farmer in a village in India, hours from the nearest bank, can collect welfare payments or transfer money by simply pressing a thumb to a fingerprint scanner at the local store. Digitally authenticated copies of driver’s licenses, birth certificates, and educational records can be accessed and shared via a digital wallet that sits on your smartphone.&lt;/p&gt; 
 &lt;p&gt;In big cities, where cash is less and less common (just trying to break a bill can be a major headache), mobile payments are ubiquitous, whether you’re buying a TV from a high-street retailer or a coconut from a roadside cart. There are no fees, and any payment app or bank account can send money to any other. The country’s chaotic patchwork of public and private hospitals have begun digitizing all their medical records and uploading them to a nationwide platform. On the Open Network for Digital Commerce (ONDC), people can do online shopping searches on whatever app they want, and the results show sellers from an array of &lt;em&gt;other&lt;/em&gt; platforms, too. The idea is to liberate small merchants and consumers from the walled gardens of online shopping giants like Amazon and the domestic giant Flipkart.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In the most populous nation on Earth—with 1.4 billion people—a large portion of the bureaucracy anyone encounters in daily life happens seamlessly and in the cloud.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;At the heart of all these tools is Aadhaar. The system gives every Indian a 12-digit number that, in combination with either a fingerprint scan or an SMS code, allows access to government services, SIM cards, basic bank accounts, digital signature services, and social welfare payments. The Indian government says that since its inception in 2009, Aadhaar has saved 3.48 trillion rupees ($39.2 billion) by boosting efficiency, bypassing corrupt officials, and cutting other types of fraud. The system is controversial and imperfect—a database with 1.4 billion people in it comes with inherent security and privacy concerns. Still, in the most populous nation on Earth, a big portion of the bureaucracy anyone might encounter in daily life just happens in the cloud.&lt;/p&gt; 
 &lt;p&gt;Nilekani was behind much of that innovation, marshaling an army of civil servants, tech companies, and volunteers. Now he sees it in action every day. “It reinforces that what you have done is not some abstract stuff, but real stuff for real people,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;By his own admission, Nilekani is entering the twilight of his career. But it’s not over yet. He’s now “chief mentor” for the India Energy Stack (IES), a government initiative to connect the fragmented data held by companies responsible for generating, transmitting, and distributing power. India’s grids are unstable and disparate, but Nilekani hopes an Aadhaar-like move will help. IES aims to give unique digital identities not only to power plants and energy storage facilities but even to rooftop solar panels and electric vehicles. All the data attached to those things—device characteristics, energy rating certifications, usage information—will be in a common, machine-readable format and shared on the same open protocols.&lt;/p&gt;  &lt;p&gt;Ideally, that’ll give grid operators a real-time view of energy supply and demand. And if it works, it might also make it simpler and cheaper for &lt;em&gt;anyone&lt;/em&gt; to connect to the grid—even everyday folks selling excess power from their rooftop solar rigs, says RS Sharma, the chair of the project and Nilekani’s deputy while building Aadhaar.&lt;/p&gt;  &lt;p&gt;Nilekani’s other side hustle is even more ambitious. His idea for a global “finternet” combines Aadhaarization with blockchains—creating digital representations called tokens for not only financial instruments like stocks or bonds but also real-world assets like houses or jewelry. Anyone from a bank to an asset manager or even a company could create and manage these tokens, but Nilekani’s team especially hopes the idea will help poor people trade their assets, or use them as loan collateral—expanding financial services to those who otherwise couldn’t access them.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;It sounds almost wild-eyed. Yet the finternet project has 30 partners across four continents. Nilekani says it’ll launch next year.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A call to service&lt;/h3&gt;  &lt;p&gt;Nilekani was born in Bengaluru, in 1955. His family was middle class and, Nilekani says, “seized with societal issues and challenges.” His upbringing was also steeped in the kind of socialism espoused by the newish nation’s first prime minister, Jawaharlal Nehru.&lt;/p&gt;  &lt;p&gt;After studying electrical engineering at the Indian Institute of Technology, in 1981 Nilekani helped found Infosys, an information technology company that pioneered outsourcing and helped turned India into the world’s IT back office. In 1999, he was part of a government-appointed task force trying to upgrade the infrastructure and services in Bengaluru, then emerging as India’s tech capital. But Nilekani was at the time leery of being viewed as just another techno-optimist. “I didn’t want to be seen as naive enough to believe that tech could solve everything,” he says.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Nilekani holds a device to one eye" class="wp-image-1129867" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/GettyImages-526255786.jpg?w=910" /&gt;&lt;figcaption class="wp-element-caption"&gt;Nilekani demonstrates the biometric technology at the heart of Aadhaar, the system he spearheaded that provides a unique digital identity number to all Indians.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;PALLAVA BAGLA/CORBIS/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Seeing the scope of the problem changed his mind—sclerotic bureaucracy, endemic corruption, and financial exclusion were intractable without technological solutions. In 2008 Nilekani published a book, &lt;em&gt;Imagining India: The Idea of a Renewed Nation&lt;/em&gt;. It was a manifesto for an India that could leapfrog into a networked future.&lt;/p&gt; 

 &lt;p&gt;And it got him a job. At the time more than half the births in the country were not recorded, and up to 400 million Indians had no official identity document. Manmohan Singh, the prime minister, asked Nilekani to put into action an ill-defined plan to create a national identity card.&lt;/p&gt;  &lt;p&gt;Nilekani’s team made a still-controversial decision to rely on biometrics. A system based on people’s fingerprints and retina scans meant nobody could sign up twice, and nobody had to carry paperwork. In terms of execution, it was like trying to achieve industrialization but skip a steam era. Deployment required a monumental data collection effort, as well as new infrastructure that could compare each new enrollment against hundreds of millions of existing records in seconds. At its peak, the Unique Identification Authority of India (UIDAI), the agency responsible for administering Aadhaar, was registering more than a million new users a day. That happened with a technical team of just about 50 developers, and in the end cost slightly less than half a billion dollars.&lt;/p&gt;  &lt;p&gt;Buoyed by their success, Nilekani and his allies started casting around for other problems they could solve using the same digitize-the-real-world playbook. “We built more and more layers of capability,” Nilekani says, “and then this became a wider-ranging idea. More grandiose.”&lt;/p&gt;  &lt;p&gt;While other countries were building digital backbones with full state control (as in China) or in public-private partnerships that favored profit-seeking corporate approaches (as in the US), Nilekani thought India needed something else. He wanted critical technologies in areas like identity, payments, and data sharing to be open and interoperable, not monopolized by either the state or private industry. So the tools that make up DPI use open standards and open APIs, meaning that anyone can plug into the system. No single company or institution controls access—no walled gardens.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;A contested legacy&lt;/h3&gt;  &lt;p&gt;Of course, another way to look at putting financial and government services and records into giant databases is that it’s a massive risk to personal liberty. Aadhaar, in particular, has faced criticism from privacy advocates concerned about the potential for surveillance. Several high-profile data breaches of Aadhaar records held by government entities have shaken confidence in the system, most recently in 2023, when security researchers found hackers selling the records of more than 800 million Indians on the dark web.&lt;/p&gt;  &lt;p&gt;Technically, this shouldn’t matter—an Aadhaar number ought to be useless without biometric or SMS-based authentication. It’s “a myth that this random number is a very powerful number,” says Sharma, the onetime co-lead of UIDAI. “I don’t have any example where somebody’s Aadhaar disclosure would have harmed somebody.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;One problem is that in everyday use, Aadhaar users often bypass the biometric authentication system. To ensure that people use a genuine address at registration, Aadhaar administrators give people their numbers on an official-looking document. Indians co-opted this paperwork as a proof of identity on its own. And since the document—Indians even call it an “Aadhaar card”—doesn’t have an expiration date, it’s possible for people to get multiple valid cards with different details by changing their address or date of birth. That’s quite a loophole. In 2018 an NGO report found that 67% of people using Aadhaar to open a bank account relied on this verification document rather than digital authentication. That report was the last time anyone published data on the problem, so nobody knows how bad it is today. “Everybody’s living on anecdotes,” says Kiran Jonnalagadda, an anti-Aadhaar activist.&lt;/p&gt;  &lt;p&gt;In other cases, flaws in Aadhaar’s biometric technology have caused people to be denied essential government services. The government downplays these risks, but again, it’s impossible to tell how serious the problem is because the UIDAI won’t disclose numbers. “There needs to be a much more honest acknowledgment, documentation, and then an examination of how those exclusions can be mitigated,” says Apar Gupta, director of the Internet Freedom Foundation.&lt;/p&gt; 
 &lt;p&gt;Beyond the potential for fraud, it’s also true that the free and interoperable tools haven’t reached all the people who might find them useful, especially among India’s rural and poorer populations. Nilekani’s hopes for openness haven’t fully come to pass. Big e-commerce companies still dominate, and retail sales on ONDC have been dropping steadily since 2024, when financial incentives to participate began to taper off. The digital payments and government documentation services have hundreds of millions of users, numbers most global technology companies would love to see—but in a country as large as India, that leaves a lot of people out.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Going global&lt;/h3&gt;  &lt;p&gt;The usually calm Nilekani bristles at that criticism; he has heard it before. Detractors overlook the dysfunction that preceded these efforts, he says, and he remains convinced that technology was the only way forward. “How do you move a country of 1.4 billion people?” he asks. “There’s no other way you can fix it.”&lt;/p&gt; 
 &lt;p&gt;The proof is self-evident, he says. Indians have opened more than 500 million basic bank accounts using Aadhaar; before it came into use, millions of those people had been completely unbanked. Earlier this year, India’s Unified Payments Interface overtook Visa as the world’s largest real-time payments system. “There is no way Aadhaar could have worked but for the fact that people needed this thing,” Nilekani says. “There’s no way payments would have worked without people needing it. So the voice of the people—they’re voting with their feet.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1129868" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/GettyImages-2234533815.jpg?w=1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;A street vendor in Kolkata displays a QR code that lets him get paid via India’s Unified Payments Interface, part of the digital public infrastructure Nilekani helped build. The Reserve Bank of India says more than 657 million people used the system in the financial year 2024–2025.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;DEBAJYOTI CHAKRABORTY/NURPHOTO/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;That need might be present in countries beyond India. “Many countries don’t have a proper birth registration system. Many countries don’t have a payment system. Many countries don’t have a way for data to be leveraged,” Nilekani says. “So this is a very powerful idea.” It seems to be spreading. Foreign governments regularly send delegations to Bengaluru to study India’s DPI tools. The World Bank and the United Nations have tried to introduce the concept to other developing countries equally eager to bring their economies into the digital age. The Gates Foundation has established projects to promote digital infrastructure, and Nilekani has set up and funded a network of think tanks, research institutes, and other NGOs aimed at, as he says, “propagating the gospel.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;Still, he admits he might not live to see DPI go global. “There are two races,” Nilekani says. “My personal race against time and India’s race against time.” He worries that the economic potential of its vast young population—the so-called demographic dividend—could turn into a demographic disaster. Despite rapid growth, gains have been uneven. Youth unemployment remains stubbornly high—a particularly volatile problem in a large and economically turbulent country.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Maybe I’m a junkie,” he says. “Why the hell am I doing all this? I think I need it. I think I need to keep curious and alive and looking at the future.” But that’s the thing about building the future: It never quite arrives.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Edd Gent is a journalist based in Bengaluru, India.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Nandan Nilekani can’t stop trying to push India into the future. He started nearly 30 years ago, masterminding an ongoing experiment in technological state capacity that started with Aadhaar—the world’s largest digital identity system. Aadhaar means “foundation” in Hindi, and on that bedrock Nilekani and people working with him went on to build a sprawling collection of free, interoperating online tools that add up to nothing less than a digital infrastructure for society. They cover government services, digital payments, banking, credit, and health care, offering convenience and access that would be eye-popping in wealthy countries a tenth of India’s size. In India those systems are called, collectively, “digital public infrastructure,” or DPI.&lt;/p&gt;  &lt;p&gt;At 70 years old, Nilekani should be retired. But he has a few more ideas. India’s electrical grid is creaky and prone to failure; Nilekani wants to add a layer of digital communication to stabilize it. And then there’s his idea to expand the financial functions in DPI to the rest of the world, creating a global digital backbone for commerce that he calls the “finternet.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;“It sounds like some crazy stuff,” Nilekani says. “But I think these are all big ideas, which over the next five years will have demonstrable, material impact.” As a last act in public life, why not Aadhaarize the world?&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;India’s digital backbone&lt;/h3&gt;  &lt;p&gt;Today, a farmer in a village in India, hours from the nearest bank, can collect welfare payments or transfer money by simply pressing a thumb to a fingerprint scanner at the local store. Digitally authenticated copies of driver’s licenses, birth certificates, and educational records can be accessed and shared via a digital wallet that sits on your smartphone.&lt;/p&gt; 
 &lt;p&gt;In big cities, where cash is less and less common (just trying to break a bill can be a major headache), mobile payments are ubiquitous, whether you’re buying a TV from a high-street retailer or a coconut from a roadside cart. There are no fees, and any payment app or bank account can send money to any other. The country’s chaotic patchwork of public and private hospitals have begun digitizing all their medical records and uploading them to a nationwide platform. On the Open Network for Digital Commerce (ONDC), people can do online shopping searches on whatever app they want, and the results show sellers from an array of &lt;em&gt;other&lt;/em&gt; platforms, too. The idea is to liberate small merchants and consumers from the walled gardens of online shopping giants like Amazon and the domestic giant Flipkart.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;In the most populous nation on Earth—with 1.4 billion people—a large portion of the bureaucracy anyone encounters in daily life happens seamlessly and in the cloud.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;At the heart of all these tools is Aadhaar. The system gives every Indian a 12-digit number that, in combination with either a fingerprint scan or an SMS code, allows access to government services, SIM cards, basic bank accounts, digital signature services, and social welfare payments. The Indian government says that since its inception in 2009, Aadhaar has saved 3.48 trillion rupees ($39.2 billion) by boosting efficiency, bypassing corrupt officials, and cutting other types of fraud. The system is controversial and imperfect—a database with 1.4 billion people in it comes with inherent security and privacy concerns. Still, in the most populous nation on Earth, a big portion of the bureaucracy anyone might encounter in daily life just happens in the cloud.&lt;/p&gt; 
 &lt;p&gt;Nilekani was behind much of that innovation, marshaling an army of civil servants, tech companies, and volunteers. Now he sees it in action every day. “It reinforces that what you have done is not some abstract stuff, but real stuff for real people,” he says.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;By his own admission, Nilekani is entering the twilight of his career. But it’s not over yet. He’s now “chief mentor” for the India Energy Stack (IES), a government initiative to connect the fragmented data held by companies responsible for generating, transmitting, and distributing power. India’s grids are unstable and disparate, but Nilekani hopes an Aadhaar-like move will help. IES aims to give unique digital identities not only to power plants and energy storage facilities but even to rooftop solar panels and electric vehicles. All the data attached to those things—device characteristics, energy rating certifications, usage information—will be in a common, machine-readable format and shared on the same open protocols.&lt;/p&gt;  &lt;p&gt;Ideally, that’ll give grid operators a real-time view of energy supply and demand. And if it works, it might also make it simpler and cheaper for &lt;em&gt;anyone&lt;/em&gt; to connect to the grid—even everyday folks selling excess power from their rooftop solar rigs, says RS Sharma, the chair of the project and Nilekani’s deputy while building Aadhaar.&lt;/p&gt;  &lt;p&gt;Nilekani’s other side hustle is even more ambitious. His idea for a global “finternet” combines Aadhaarization with blockchains—creating digital representations called tokens for not only financial instruments like stocks or bonds but also real-world assets like houses or jewelry. Anyone from a bank to an asset manager or even a company could create and manage these tokens, but Nilekani’s team especially hopes the idea will help poor people trade their assets, or use them as loan collateral—expanding financial services to those who otherwise couldn’t access them.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;It sounds almost wild-eyed. Yet the finternet project has 30 partners across four continents. Nilekani says it’ll launch next year.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;A call to service&lt;/h3&gt;  &lt;p&gt;Nilekani was born in Bengaluru, in 1955. His family was middle class and, Nilekani says, “seized with societal issues and challenges.” His upbringing was also steeped in the kind of socialism espoused by the newish nation’s first prime minister, Jawaharlal Nehru.&lt;/p&gt;  &lt;p&gt;After studying electrical engineering at the Indian Institute of Technology, in 1981 Nilekani helped found Infosys, an information technology company that pioneered outsourcing and helped turned India into the world’s IT back office. In 1999, he was part of a government-appointed task force trying to upgrade the infrastructure and services in Bengaluru, then emerging as India’s tech capital. But Nilekani was at the time leery of being viewed as just another techno-optimist. “I didn’t want to be seen as naive enough to believe that tech could solve everything,” he says.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Nilekani holds a device to one eye" class="wp-image-1129867" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/GettyImages-526255786.jpg?w=910" /&gt;&lt;figcaption class="wp-element-caption"&gt;Nilekani demonstrates the biometric technology at the heart of Aadhaar, the system he spearheaded that provides a unique digital identity number to all Indians.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;PALLAVA BAGLA/CORBIS/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Seeing the scope of the problem changed his mind—sclerotic bureaucracy, endemic corruption, and financial exclusion were intractable without technological solutions. In 2008 Nilekani published a book, &lt;em&gt;Imagining India: The Idea of a Renewed Nation&lt;/em&gt;. It was a manifesto for an India that could leapfrog into a networked future.&lt;/p&gt; 

 &lt;p&gt;And it got him a job. At the time more than half the births in the country were not recorded, and up to 400 million Indians had no official identity document. Manmohan Singh, the prime minister, asked Nilekani to put into action an ill-defined plan to create a national identity card.&lt;/p&gt;  &lt;p&gt;Nilekani’s team made a still-controversial decision to rely on biometrics. A system based on people’s fingerprints and retina scans meant nobody could sign up twice, and nobody had to carry paperwork. In terms of execution, it was like trying to achieve industrialization but skip a steam era. Deployment required a monumental data collection effort, as well as new infrastructure that could compare each new enrollment against hundreds of millions of existing records in seconds. At its peak, the Unique Identification Authority of India (UIDAI), the agency responsible for administering Aadhaar, was registering more than a million new users a day. That happened with a technical team of just about 50 developers, and in the end cost slightly less than half a billion dollars.&lt;/p&gt;  &lt;p&gt;Buoyed by their success, Nilekani and his allies started casting around for other problems they could solve using the same digitize-the-real-world playbook. “We built more and more layers of capability,” Nilekani says, “and then this became a wider-ranging idea. More grandiose.”&lt;/p&gt;  &lt;p&gt;While other countries were building digital backbones with full state control (as in China) or in public-private partnerships that favored profit-seeking corporate approaches (as in the US), Nilekani thought India needed something else. He wanted critical technologies in areas like identity, payments, and data sharing to be open and interoperable, not monopolized by either the state or private industry. So the tools that make up DPI use open standards and open APIs, meaning that anyone can plug into the system. No single company or institution controls access—no walled gardens.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;A contested legacy&lt;/h3&gt;  &lt;p&gt;Of course, another way to look at putting financial and government services and records into giant databases is that it’s a massive risk to personal liberty. Aadhaar, in particular, has faced criticism from privacy advocates concerned about the potential for surveillance. Several high-profile data breaches of Aadhaar records held by government entities have shaken confidence in the system, most recently in 2023, when security researchers found hackers selling the records of more than 800 million Indians on the dark web.&lt;/p&gt;  &lt;p&gt;Technically, this shouldn’t matter—an Aadhaar number ought to be useless without biometric or SMS-based authentication. It’s “a myth that this random number is a very powerful number,” says Sharma, the onetime co-lead of UIDAI. “I don’t have any example where somebody’s Aadhaar disclosure would have harmed somebody.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;One problem is that in everyday use, Aadhaar users often bypass the biometric authentication system. To ensure that people use a genuine address at registration, Aadhaar administrators give people their numbers on an official-looking document. Indians co-opted this paperwork as a proof of identity on its own. And since the document—Indians even call it an “Aadhaar card”—doesn’t have an expiration date, it’s possible for people to get multiple valid cards with different details by changing their address or date of birth. That’s quite a loophole. In 2018 an NGO report found that 67% of people using Aadhaar to open a bank account relied on this verification document rather than digital authentication. That report was the last time anyone published data on the problem, so nobody knows how bad it is today. “Everybody’s living on anecdotes,” says Kiran Jonnalagadda, an anti-Aadhaar activist.&lt;/p&gt;  &lt;p&gt;In other cases, flaws in Aadhaar’s biometric technology have caused people to be denied essential government services. The government downplays these risks, but again, it’s impossible to tell how serious the problem is because the UIDAI won’t disclose numbers. “There needs to be a much more honest acknowledgment, documentation, and then an examination of how those exclusions can be mitigated,” says Apar Gupta, director of the Internet Freedom Foundation.&lt;/p&gt; 
 &lt;p&gt;Beyond the potential for fraud, it’s also true that the free and interoperable tools haven’t reached all the people who might find them useful, especially among India’s rural and poorer populations. Nilekani’s hopes for openness haven’t fully come to pass. Big e-commerce companies still dominate, and retail sales on ONDC have been dropping steadily since 2024, when financial incentives to participate began to taper off. The digital payments and government documentation services have hundreds of millions of users, numbers most global technology companies would love to see—but in a country as large as India, that leaves a lot of people out.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Going global&lt;/h3&gt;  &lt;p&gt;The usually calm Nilekani bristles at that criticism; he has heard it before. Detractors overlook the dysfunction that preceded these efforts, he says, and he remains convinced that technology was the only way forward. “How do you move a country of 1.4 billion people?” he asks. “There’s no other way you can fix it.”&lt;/p&gt; 
 &lt;p&gt;The proof is self-evident, he says. Indians have opened more than 500 million basic bank accounts using Aadhaar; before it came into use, millions of those people had been completely unbanked. Earlier this year, India’s Unified Payments Interface overtook Visa as the world’s largest real-time payments system. “There is no way Aadhaar could have worked but for the fact that people needed this thing,” Nilekani says. “There’s no way payments would have worked without people needing it. So the voice of the people—they’re voting with their feet.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1129868" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/GettyImages-2234533815.jpg?w=1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;A street vendor in Kolkata displays a QR code that lets him get paid via India’s Unified Payments Interface, part of the digital public infrastructure Nilekani helped build. The Reserve Bank of India says more than 657 million people used the system in the financial year 2024–2025.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;DEBAJYOTI CHAKRABORTY/NURPHOTO/GETTY IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;That need might be present in countries beyond India. “Many countries don’t have a proper birth registration system. Many countries don’t have a payment system. Many countries don’t have a way for data to be leveraged,” Nilekani says. “So this is a very powerful idea.” It seems to be spreading. Foreign governments regularly send delegations to Bengaluru to study India’s DPI tools. The World Bank and the United Nations have tried to introduce the concept to other developing countries equally eager to bring their economies into the digital age. The Gates Foundation has established projects to promote digital infrastructure, and Nilekani has set up and funded a network of think tanks, research institutes, and other NGOs aimed at, as he says, “propagating the gospel.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;Still, he admits he might not live to see DPI go global. “There are two races,” Nilekani says. “My personal race against time and India’s race against time.” He worries that the economic potential of its vast young population—the so-called demographic dividend—could turn into a demographic disaster. Despite rapid growth, gains have been uneven. Youth unemployment remains stubbornly high—a particularly volatile problem in a large and economically turbulent country.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Maybe I’m a junkie,” he says. “Why the hell am I doing all this? I think I need it. I think I need to keep curious and alive and looking at the future.” But that’s the thing about building the future: It never quite arrives.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Edd Gent is a journalist based in Bengaluru, India.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/07/1129748/aadhaar-nandan-nilekani-india-digital-biometric-identity-data/</guid><pubDate>Wed, 07 Jan 2026 11:00:00 +0000</pubDate></item><item><title>LLMs contain a LOT of parameters. But what’s a parameter? (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/07/1130795/what-even-is-a-parameter/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250825_parameter.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt; Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. &lt;/em&gt;&lt;em&gt;You can read more from the series here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;I am writing this because one of my editors woke up in the middle of the night and scribbled on a bedside notepad: “What is a parameter?” Unlike a lot of thoughts that hit at 4 a.m., it’s a really good question—one that goes right to the heart of how large language models work. And I’m not just saying that because he’s my boss. (Hi, Boss!)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;A large language model’s parameters are often said to be the dials and levers that control how it behaves. Think of a planet-size pinball machine that sends its balls pinging from one end to the other via billions of paddles and bumpers set just so. Tweak those settings and the balls will behave in a different way.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;OpenAI’s GPT-3, released in 2020, had 175 billion parameters. Google DeepMind’s latest LLM, Gemini 3, may have at least a trillion—some think it’s probably more like 7 trillion—but the company isn’t saying. (With competition now fierce, AI firms no longer share information about how their models are built.)&lt;/p&gt; 
 &lt;p&gt;But the basics of what parameters are and how they make LLMs do the remarkable things that they do are the same across different models. Ever wondered what makes an LLM really tick—what’s behind the colorful pinball-machine metaphors? Let’s dive in.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What is a parameter?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Think back to middle school algebra, like 2&lt;em&gt;a&lt;/em&gt; + &lt;em&gt;b&lt;/em&gt;. Those letters are parameters: Assign them values and you get a result. In math or coding, parameters are used to set limits or determine output. The parameters inside LLMs work in a similar way, just on a mind-boggling scale.&amp;nbsp;&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;How are they assigned their values?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Short answer: an algorithm. When a model is trained, each parameter is set to a random value. The training process then involves an iterative series of calculations (known as training steps) that update those values. In the early stages of training, a model will make errors. The training algorithm looks at each error and goes back through the model, tweaking the value of each of the model’s many parameters so that next time that error is smaller. This happens over and over again until the model behaves in the way its makers want it to. At that point, training stops and the values of the model’s parameters are fixed.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Sounds straightforward …&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In theory! In practice, because LLMs are trained on so much data and contain so many parameters, training them requires a huge number of steps and an eye-watering amount of computation. During training, the 175 billion parameters inside a medium-size LLM like GPT-3 will each get updated tens of thousands of times. In total, that adds up to quadrillions (a number with 15 zeros) of individual calculations. That’s why training an LLM takes so much energy. We’re talking about thousands of specialized high-speed computers running nonstop for months.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Oof. What are all these parameters for, exactly?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;There are three different types of parameters inside an LLM that get their values assigned through training: embeddings, weights, and biases. Let’s take each of those in turn.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Okay! So, what are embeddings?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;An embedding is the mathematical representation of a word (or part of a word, known as a token) in an LLM’s vocabulary. An LLM’s vocabulary, which might contain up to a few hundred thousand unique tokens, is set by its designers before training starts. But there’s no meaning attached to those words. That comes during training.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;When a model is trained, each word in its vocabulary is assigned a numerical value that captures the meaning of that word in relation to all the other words, based on how the word appears in countless examples across the model’s training data.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Each word gets replaced by a kind of code?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Yeah. But there’s a bit more to it. The numerical value—the embedding—that represents each word is in fact a &lt;em&gt;list&lt;/em&gt; of numbers, with each number in the list representing a different facet of meaning that the model has extracted from its training data. The length of this list of numbers is another thing that LLM designers can specify before an LLM is trained. A common size is 4,096.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Every word inside an LLM is represented by a list of 4,096 numbers?&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Yup, that’s an embedding. And each of those numbers is tweaked during training. An LLM with embeddings that are 4,096 numbers long is said to have 4,096 dimensions.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Why 4,096?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;It might look like a strange number. But LLMs (like anything that runs on a computer chip) work best with powers of two—2, 4, 8, 16, 32, 64, and so on. LLM engineers have found that 4,096 is a power of two that hits a sweet spot between capability and efficiency. Models with fewer dimensions are less capable; models with more dimensions are too expensive or slow to train and run.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Using more numbers allows the LLM to capture very fine-grained information about how a word is used in many different contexts, what subtle connotations it might have, how it relates to other words, and so on.&lt;/p&gt;  &lt;p&gt;Back in February, OpenAI released GPT-4.5, the firm’s largest LLM yet (some estimates have put its parameter count at more than 10 trillion). Nick Ryder, a research scientist at OpenAI who worked on the model, told me at the time that bigger models can work with extra information, like emotional cues, such as when a speaker’s words signal hostility: “All of these subtle patterns that come through a human conversation—those are the bits that these larger and larger models will pick up on.”&lt;/p&gt;  &lt;p&gt;The upshot is that all the words inside an LLM get encoded into a high-dimensional space. Picture thousands of words floating in the air around you. Words that are closer together have similar meanings. For example, “table” and “chair” will be closer to each other than they are to “astronaut,” which is close to “moon” and “Musk.” Way off in the distance you can see “prestidigitation.” It’s a little like that, but instead of being related to each other across three dimensions, the words inside an LLM are related across 4,096 dimensions.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Yikes.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;It’s dizzying stuff. In effect, an LLM compresses the entire internet into a single monumental mathematical structure that encodes an unfathomable amount of interconnected information. It’s both why LLMs can do astonishing things and why they’re impossible to fully understand.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Okay. So that’s embeddings. What about weights?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;A weight is a parameter that represents the strength of a connection between different parts of a model—and one of the most common types of dial for tuning a model’s behavior. Weights are used when an LLM processes text.&lt;/p&gt;  &lt;p&gt;When an LLM reads a sentence (or a book chapter), it first looks up the embeddings for all the words and then passes those embeddings through a series of neural networks, known as transformers, that are designed to process sequences of data (like text) all at once. Every word in the sentence gets processed in relation to every other word.&lt;/p&gt;  &lt;p&gt;This is where weights come in. An embedding represents the meaning of a word without context. When a word appears in a specific sentence, transformers use weights to process the meaning of that word in that new context. (In practice, this involves multiplying each embedding by the weights for all other words.)&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;And biases?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Biases are another type of dial that complement the effects of the weights. Weights set the thresholds at which different parts of a model fire (and thus pass data on to the next part). Biases are used to adjust those thresholds so that an embedding can trigger activity even when its value is low. (Biases are values that are added to an embedding rather than multiplied with it.)&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;By shifting the thresholds at which parts of a model fire, biases allow the model to pick up information that might otherwise be missed. Imagine you’re trying to hear what somebody is saying in a noisy room. Weights would amplify the loudest voices the most; biases are like a knob on a listening device that pushes quieter voices up in the mix.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here’s the TL;DR: Weights and biases are two different ways that an LLM extracts as much information as it can out of the text it is given. And both types of parameters are adjusted over and over again during training to make sure they do this.&amp;nbsp;&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Okay. What about neurons? Are they a type of parameter too?&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;No, neurons are more a way to organize all this math—containers for the weights and biases, strung together by a web of pathways between them. It’s all very loosely inspired by biological neurons inside animal brains, with signals from one neuron triggering new signals from the next and so on.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Each neuron in a model holds a single bias and weights for every one of the model’s dimensions. In other words, if a model has 4,096 dimensions—and therefore its embeddings are lists of 4,096 numbers—then each of the neurons in that model will hold one bias and 4,096 weights.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Neurons are arranged in layers. In most LLMs, each neuron in one layer is connected to every neuron in the layer above. A 175-billion-parameter model like GPT-3 might have around 100 layers with a few tens of thousands of neurons in each layer. And each neuron is running tens of thousands of computations at a time.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Dizzy again. That’s a lot of math.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;That’s a lot of math.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;And how does all of that fit together? How does an LLM take a bunch of words and decide what words to give back?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When an LLM processes a piece of text, the numerical representation of that text—the embedding—gets passed through multiple layers of the model. In each layer, the value of the embedding (that list of 4,096 numbers) gets updated many times by a series of computations involving the model’s weights and biases (attached to the neurons) until it gets to the final layer.&lt;/p&gt;  &lt;p&gt;The idea is that all the meaning and nuance and context of that input text is captured by the final value of the embedding after it has gone through a mind-boggling series of computations. That value is then used to calculate the next word that the LLM should spit out.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It won’t be a surprise that this is more complicated than it sounds: The model in fact calculates, for every word in its vocabulary, how likely that word is to come next and ranks the results. It then picks the top word. (Kind of. See below …)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That word is appended to the previous block of text, and the whole process repeats until the LLM calculates that the most likely next word to spit out is one that signals the end of its output.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;That’s it?&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Sure. Well …&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Go on.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;LLM designers can also specify a handful of other parameters, known as hyperparameters. The main ones are called temperature, top-p, and top-k.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;You’re making this up.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Temperature is a parameter that acts as a kind of creativity dial. It influences the model’s choice of what word comes next. I just said that the model ranks the words in its vocabulary and picks the top one. But the temperature parameter can be used to push the model to choose the most probable next word, making its output more factual and relevant, or a less probable word, making the output more surprising and less robotic.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Top-p and top-k are two more dials that control the model’s choice of next words. They are settings that force the model to pick a word at random from a pool of most probable words instead of the top word. These parameters affect how the model comes across—quirky and creative versus trustworthy and dull.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;One last question! There has been a lot of buzz about small models that can outperform big models. How does a small model do more with fewer parameters?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;That’s one of the hottest questions in AI right now. There are a lot of different ways it can happen. Researchers have found that the amount of training data makes a huge difference. First you need to make sure the model sees enough data: An LLM trained on too little text won’t make the most of all its parameters, and a smaller model trained on the same amount of data could outperform it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another trick researchers have hit on is overtraining. Showing models far more data than previously thought necessary seems to make them perform better. The result is that a small model trained on a lot of data can outperform a larger model trained on less data. Take Meta’s Llama LLMs. The 70-billion-parameter Llama 2 was trained on around 2 trillion words of text; the 8-billion-parameter Llama 3 was trained on around 15 trillion words of text. The far smaller Llama 3 is the better model.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A third technique, known as distillation, uses a larger model to train a smaller one. The smaller model is trained not only on the raw training data but also on the outputs of the larger model’s internal computations. The idea is that the hard-won lessons encoded in the parameters of the larger model trickle down into the parameters of the smaller model, giving it a boost.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, the days of single monolithic models may be over. Even the largest models on the market, like OpenAI’s GPT-5 and Google DeepMind’s Gemini 3, can be thought of as several small models in a trench coat. Using a technique called “mixture of experts,” large models can turn on just the parts of themselves (the “experts”) that are required to process a specific piece of text. This combines the abilities of a large model with the speed and lower power consumption of a small one.&lt;/p&gt;  &lt;p&gt;But that’s not the end of it. Researchers are still figuring out ways to get the most out of a model’s parameters. As the gains from straight-up scaling tail off, jacking up the number of parameters no longer seems to make the difference it once did. It’s not so much how many you have, but what you do with them.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Can I see one?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;You want to &lt;em&gt;see&lt;/em&gt; a parameter? Knock yourself out: Here's an embedding. &lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/08/250825_parameter.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt; Explains: Let our writers untangle the complex, messy world of technology to help you understand what’s coming next. &lt;/em&gt;&lt;em&gt;You can read more from the series here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;I am writing this because one of my editors woke up in the middle of the night and scribbled on a bedside notepad: “What is a parameter?” Unlike a lot of thoughts that hit at 4 a.m., it’s a really good question—one that goes right to the heart of how large language models work. And I’m not just saying that because he’s my boss. (Hi, Boss!)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;A large language model’s parameters are often said to be the dials and levers that control how it behaves. Think of a planet-size pinball machine that sends its balls pinging from one end to the other via billions of paddles and bumpers set just so. Tweak those settings and the balls will behave in a different way.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;OpenAI’s GPT-3, released in 2020, had 175 billion parameters. Google DeepMind’s latest LLM, Gemini 3, may have at least a trillion—some think it’s probably more like 7 trillion—but the company isn’t saying. (With competition now fierce, AI firms no longer share information about how their models are built.)&lt;/p&gt; 
 &lt;p&gt;But the basics of what parameters are and how they make LLMs do the remarkable things that they do are the same across different models. Ever wondered what makes an LLM really tick—what’s behind the colorful pinball-machine metaphors? Let’s dive in.&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;What is a parameter?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Think back to middle school algebra, like 2&lt;em&gt;a&lt;/em&gt; + &lt;em&gt;b&lt;/em&gt;. Those letters are parameters: Assign them values and you get a result. In math or coding, parameters are used to set limits or determine output. The parameters inside LLMs work in a similar way, just on a mind-boggling scale.&amp;nbsp;&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;How are they assigned their values?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Short answer: an algorithm. When a model is trained, each parameter is set to a random value. The training process then involves an iterative series of calculations (known as training steps) that update those values. In the early stages of training, a model will make errors. The training algorithm looks at each error and goes back through the model, tweaking the value of each of the model’s many parameters so that next time that error is smaller. This happens over and over again until the model behaves in the way its makers want it to. At that point, training stops and the values of the model’s parameters are fixed.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Sounds straightforward …&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In theory! In practice, because LLMs are trained on so much data and contain so many parameters, training them requires a huge number of steps and an eye-watering amount of computation. During training, the 175 billion parameters inside a medium-size LLM like GPT-3 will each get updated tens of thousands of times. In total, that adds up to quadrillions (a number with 15 zeros) of individual calculations. That’s why training an LLM takes so much energy. We’re talking about thousands of specialized high-speed computers running nonstop for months.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Oof. What are all these parameters for, exactly?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;There are three different types of parameters inside an LLM that get their values assigned through training: embeddings, weights, and biases. Let’s take each of those in turn.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Okay! So, what are embeddings?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;An embedding is the mathematical representation of a word (or part of a word, known as a token) in an LLM’s vocabulary. An LLM’s vocabulary, which might contain up to a few hundred thousand unique tokens, is set by its designers before training starts. But there’s no meaning attached to those words. That comes during training.&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;When a model is trained, each word in its vocabulary is assigned a numerical value that captures the meaning of that word in relation to all the other words, based on how the word appears in countless examples across the model’s training data.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Each word gets replaced by a kind of code?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Yeah. But there’s a bit more to it. The numerical value—the embedding—that represents each word is in fact a &lt;em&gt;list&lt;/em&gt; of numbers, with each number in the list representing a different facet of meaning that the model has extracted from its training data. The length of this list of numbers is another thing that LLM designers can specify before an LLM is trained. A common size is 4,096.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Every word inside an LLM is represented by a list of 4,096 numbers?&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Yup, that’s an embedding. And each of those numbers is tweaked during training. An LLM with embeddings that are 4,096 numbers long is said to have 4,096 dimensions.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Why 4,096?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;It might look like a strange number. But LLMs (like anything that runs on a computer chip) work best with powers of two—2, 4, 8, 16, 32, 64, and so on. LLM engineers have found that 4,096 is a power of two that hits a sweet spot between capability and efficiency. Models with fewer dimensions are less capable; models with more dimensions are too expensive or slow to train and run.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Using more numbers allows the LLM to capture very fine-grained information about how a word is used in many different contexts, what subtle connotations it might have, how it relates to other words, and so on.&lt;/p&gt;  &lt;p&gt;Back in February, OpenAI released GPT-4.5, the firm’s largest LLM yet (some estimates have put its parameter count at more than 10 trillion). Nick Ryder, a research scientist at OpenAI who worked on the model, told me at the time that bigger models can work with extra information, like emotional cues, such as when a speaker’s words signal hostility: “All of these subtle patterns that come through a human conversation—those are the bits that these larger and larger models will pick up on.”&lt;/p&gt;  &lt;p&gt;The upshot is that all the words inside an LLM get encoded into a high-dimensional space. Picture thousands of words floating in the air around you. Words that are closer together have similar meanings. For example, “table” and “chair” will be closer to each other than they are to “astronaut,” which is close to “moon” and “Musk.” Way off in the distance you can see “prestidigitation.” It’s a little like that, but instead of being related to each other across three dimensions, the words inside an LLM are related across 4,096 dimensions.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Yikes.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;It’s dizzying stuff. In effect, an LLM compresses the entire internet into a single monumental mathematical structure that encodes an unfathomable amount of interconnected information. It’s both why LLMs can do astonishing things and why they’re impossible to fully understand.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Okay. So that’s embeddings. What about weights?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;A weight is a parameter that represents the strength of a connection between different parts of a model—and one of the most common types of dial for tuning a model’s behavior. Weights are used when an LLM processes text.&lt;/p&gt;  &lt;p&gt;When an LLM reads a sentence (or a book chapter), it first looks up the embeddings for all the words and then passes those embeddings through a series of neural networks, known as transformers, that are designed to process sequences of data (like text) all at once. Every word in the sentence gets processed in relation to every other word.&lt;/p&gt;  &lt;p&gt;This is where weights come in. An embedding represents the meaning of a word without context. When a word appears in a specific sentence, transformers use weights to process the meaning of that word in that new context. (In practice, this involves multiplying each embedding by the weights for all other words.)&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;And biases?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Biases are another type of dial that complement the effects of the weights. Weights set the thresholds at which different parts of a model fire (and thus pass data on to the next part). Biases are used to adjust those thresholds so that an embedding can trigger activity even when its value is low. (Biases are values that are added to an embedding rather than multiplied with it.)&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;By shifting the thresholds at which parts of a model fire, biases allow the model to pick up information that might otherwise be missed. Imagine you’re trying to hear what somebody is saying in a noisy room. Weights would amplify the loudest voices the most; biases are like a knob on a listening device that pushes quieter voices up in the mix.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Here’s the TL;DR: Weights and biases are two different ways that an LLM extracts as much information as it can out of the text it is given. And both types of parameters are adjusted over and over again during training to make sure they do this.&amp;nbsp;&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Okay. What about neurons? Are they a type of parameter too?&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;No, neurons are more a way to organize all this math—containers for the weights and biases, strung together by a web of pathways between them. It’s all very loosely inspired by biological neurons inside animal brains, with signals from one neuron triggering new signals from the next and so on.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Each neuron in a model holds a single bias and weights for every one of the model’s dimensions. In other words, if a model has 4,096 dimensions—and therefore its embeddings are lists of 4,096 numbers—then each of the neurons in that model will hold one bias and 4,096 weights.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Neurons are arranged in layers. In most LLMs, each neuron in one layer is connected to every neuron in the layer above. A 175-billion-parameter model like GPT-3 might have around 100 layers with a few tens of thousands of neurons in each layer. And each neuron is running tens of thousands of computations at a time.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Dizzy again. That’s a lot of math.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;That’s a lot of math.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;And how does all of that fit together? How does an LLM take a bunch of words and decide what words to give back?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;When an LLM processes a piece of text, the numerical representation of that text—the embedding—gets passed through multiple layers of the model. In each layer, the value of the embedding (that list of 4,096 numbers) gets updated many times by a series of computations involving the model’s weights and biases (attached to the neurons) until it gets to the final layer.&lt;/p&gt;  &lt;p&gt;The idea is that all the meaning and nuance and context of that input text is captured by the final value of the embedding after it has gone through a mind-boggling series of computations. That value is then used to calculate the next word that the LLM should spit out.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;It won’t be a surprise that this is more complicated than it sounds: The model in fact calculates, for every word in its vocabulary, how likely that word is to come next and ranks the results. It then picks the top word. (Kind of. See below …)&amp;nbsp;&lt;/p&gt;  &lt;p&gt;That word is appended to the previous block of text, and the whole process repeats until the LLM calculates that the most likely next word to spit out is one that signals the end of its output.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;That’s it?&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Sure. Well …&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Go on.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;LLM designers can also specify a handful of other parameters, known as hyperparameters. The main ones are called temperature, top-p, and top-k.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;You’re making this up.&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Temperature is a parameter that acts as a kind of creativity dial. It influences the model’s choice of what word comes next. I just said that the model ranks the words in its vocabulary and picks the top one. But the temperature parameter can be used to push the model to choose the most probable next word, making its output more factual and relevant, or a less probable word, making the output more surprising and less robotic.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Top-p and top-k are two more dials that control the model’s choice of next words. They are settings that force the model to pick a word at random from a pool of most probable words instead of the top word. These parameters affect how the model comes across—quirky and creative versus trustworthy and dull.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;One last question! There has been a lot of buzz about small models that can outperform big models. How does a small model do more with fewer parameters?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;That’s one of the hottest questions in AI right now. There are a lot of different ways it can happen. Researchers have found that the amount of training data makes a huge difference. First you need to make sure the model sees enough data: An LLM trained on too little text won’t make the most of all its parameters, and a smaller model trained on the same amount of data could outperform it.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another trick researchers have hit on is overtraining. Showing models far more data than previously thought necessary seems to make them perform better. The result is that a small model trained on a lot of data can outperform a larger model trained on less data. Take Meta’s Llama LLMs. The 70-billion-parameter Llama 2 was trained on around 2 trillion words of text; the 8-billion-parameter Llama 3 was trained on around 15 trillion words of text. The far smaller Llama 3 is the better model.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A third technique, known as distillation, uses a larger model to train a smaller one. The smaller model is trained not only on the raw training data but also on the outputs of the larger model’s internal computations. The idea is that the hard-won lessons encoded in the parameters of the larger model trickle down into the parameters of the smaller model, giving it a boost.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In fact, the days of single monolithic models may be over. Even the largest models on the market, like OpenAI’s GPT-5 and Google DeepMind’s Gemini 3, can be thought of as several small models in a trench coat. Using a technique called “mixture of experts,” large models can turn on just the parts of themselves (the “experts”) that are required to process a specific piece of text. This combines the abilities of a large model with the speed and lower power consumption of a small one.&lt;/p&gt;  &lt;p&gt;But that’s not the end of it. Researchers are still figuring out ways to get the most out of a model’s parameters. As the gains from straight-up scaling tail off, jacking up the number of parameters no longer seems to make the difference it once did. It’s not so much how many you have, but what you do with them.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Can I see one?&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;You want to &lt;em&gt;see&lt;/em&gt; a parameter? Knock yourself out: Here's an embedding. &lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/07/1130795/what-even-is-a-parameter/</guid><pubDate>Wed, 07 Jan 2026 11:23:47 +0000</pubDate></item><item><title>Intel spinout Articul8 raises more than half of $70M round at $500M valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/intel-spin-off-articul8-is-halfway-to-70m-ai-funding-round-at-500m-valuation/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Articul8, an enterprise AI company spun out of Intel in early 2024, has secured more than half of a planned $70 million funding round at a $500 million pre-money valuation, according to its CEO, as it looks to capitalize on growing demand for AI systems in regulated industries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Series B funding round is structured in two installments, with the first led by Spain’s Adara Ventures, Articul8 founder and CEO Arun K. Subramaniyan (pictured above, center) said in an interview. He declined to disclose the size of the initial installment, but said the company expects to close the round in the first quarter of this year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Articul8’s valuation for its current funding round marks a roughly fivefold increase from the company’s $100 million post-money Series A valuation in January 2024. Since then, the Santa Clara-based company said it has surpassed $90 million in total contract value — the cumulative value of all signed customer contracts — from 29 paying customers, including Hitachi Energy, AWS, Franklin Templeton, and Intel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subramaniyan told TechCrunch that Articul8 was not under pressure to raise capital, describing the company as revenue-positive following a series of large enterprise contracts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are not cash-strapped,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company expects to finish the year with annual recurring revenue of just over $57 million, Subramaniyan said, with roughly 45% to 50% of that already recognized.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Articul8 develops specialized AI systems that operate within customers’ own IT environments, rather than relying on shared, general-purpose models. Instead of selling standalone models, the company packages its technology as software applications and AI agents tailored to specific business functions, targeting regulated industries such as energy, manufacturing, aerospace, financial services, and semiconductors, where accuracy, auditability, and data control are critical.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Articul8 knowledge graph" class="wp-image-3080549" height="1226" src="https://techcrunch.com/wp-content/uploads/2026/01/articul8-knowledge-graph.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Articul8’s knowledge graph view&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Articul8&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Our competition is pretty much everybody,” said Subramaniyan. “But today, the major competitors are the cloud service providers, because they have realized that their model, as the general-purpose [offerings], are all commodities.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that Articul8’s focus on specialized systems appeals to customers who need predictable results and clear audit trails, something that is harder to achieve with general-purpose models run on shared cloud platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Articul8 plans to use the Series B proceeds primarily to expand research and product development and to scale its operations internationally, with a focus on Europe and parts of Asia.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Adara Ventures’ participation will help speed-up the European expansion plan, as the European Investment Fund backs the Madrid-based VC firm’s energy fund, Subramaniyan said. The company is also looking to scale in markets including Japan and South Korea, where it has begun working with large enterprise customers, he noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India’s Aditya Birla Ventures also participated in the ongoing round, Subramaniyan stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Articul8 works with large tech groups including Nvidia and Google Cloud, Subramaniyan said, adding that Amazon Web Services is both a customer and a partner for the company on some deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company employs 75 people, with about 80% focused on R&amp;amp;D, and teams spread across the U.S., Brazil, and India.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Articul8, an enterprise AI company spun out of Intel in early 2024, has secured more than half of a planned $70 million funding round at a $500 million pre-money valuation, according to its CEO, as it looks to capitalize on growing demand for AI systems in regulated industries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Series B funding round is structured in two installments, with the first led by Spain’s Adara Ventures, Articul8 founder and CEO Arun K. Subramaniyan (pictured above, center) said in an interview. He declined to disclose the size of the initial installment, but said the company expects to close the round in the first quarter of this year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Articul8’s valuation for its current funding round marks a roughly fivefold increase from the company’s $100 million post-money Series A valuation in January 2024. Since then, the Santa Clara-based company said it has surpassed $90 million in total contract value — the cumulative value of all signed customer contracts — from 29 paying customers, including Hitachi Energy, AWS, Franklin Templeton, and Intel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Subramaniyan told TechCrunch that Articul8 was not under pressure to raise capital, describing the company as revenue-positive following a series of large enterprise contracts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are not cash-strapped,” he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company expects to finish the year with annual recurring revenue of just over $57 million, Subramaniyan said, with roughly 45% to 50% of that already recognized.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Articul8 develops specialized AI systems that operate within customers’ own IT environments, rather than relying on shared, general-purpose models. Instead of selling standalone models, the company packages its technology as software applications and AI agents tailored to specific business functions, targeting regulated industries such as energy, manufacturing, aerospace, financial services, and semiconductors, where accuracy, auditability, and data control are critical.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Articul8 knowledge graph" class="wp-image-3080549" height="1226" src="https://techcrunch.com/wp-content/uploads/2026/01/articul8-knowledge-graph.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Articul8’s knowledge graph view&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Articul8&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Our competition is pretty much everybody,” said Subramaniyan. “But today, the major competitors are the cloud service providers, because they have realized that their model, as the general-purpose [offerings], are all commodities.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that Articul8’s focus on specialized systems appeals to customers who need predictable results and clear audit trails, something that is harder to achieve with general-purpose models run on shared cloud platforms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Articul8 plans to use the Series B proceeds primarily to expand research and product development and to scale its operations internationally, with a focus on Europe and parts of Asia.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Adara Ventures’ participation will help speed-up the European expansion plan, as the European Investment Fund backs the Madrid-based VC firm’s energy fund, Subramaniyan said. The company is also looking to scale in markets including Japan and South Korea, where it has begun working with large enterprise customers, he noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India’s Aditya Birla Ventures also participated in the ongoing round, Subramaniyan stated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Articul8 works with large tech groups including Nvidia and Google Cloud, Subramaniyan said, adding that Amazon Web Services is both a customer and a partner for the company on some deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company employs 75 people, with about 80% focused on R&amp;amp;D, and teams spread across the U.S., Brazil, and India.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/intel-spin-off-articul8-is-halfway-to-70m-ai-funding-round-at-500m-valuation/</guid><pubDate>Wed, 07 Jan 2026 12:00:00 +0000</pubDate></item><item><title>[NEW] The Download: war in Europe, and the company that wants to cool the planet (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/07/1130806/the-download-war-in-europe-and-the-company-that-wants-to-cool-the-planet/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Europe’s drone-filled vision for the future of war&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Last spring, 3,000 British soldiers deployed an invisible automated intelligence network, known as a “digital targeting web,” as part of a NATO exercise called Hedgehog in the damp forests of Estonia’s eastern territories.&lt;/p&gt;&lt;p&gt;The system had been cobbled together over the course of four months—an astonishing pace for weapons development, which is usually measured in years. Its purpose is to connect everything that looks for targets—“sensors,” in military lingo—and everything that fires on them (“shooters”) to a single, shared wireless electronic brain.&lt;/p&gt;&lt;p&gt;Eighty years after total war last transformed the continent, the Hedgehog tests signal a brutal new calculus of European defense. But leaning too much on this new mathematics of warfare could be a risky bet.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Arthur Holland Michel&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the next print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive it once it lands.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How one controversial startup hopes to cool the planet&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Stardust Solutions believes that it can solve climate change—for a price.&lt;/p&gt;&lt;p&gt;The Israel-based geoengineering startup has said it expects nations will soon pay it more than a billion dollars a year to launch specially equipped aircraft into the stratosphere. Once they’ve reached the necessary altitude, those planes will disperse particles engineered to reflect away enough sunlight to cool down the planet, purportedly without causing environmental side effects.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But numerous solar geoengineering researchers are skeptical that Stardust will line up the customers it needs to carry out a global deployment in the next decade. They’re also highly critical of the idea of a private company setting the global temperature for us.&lt;/p&gt;  &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Amazon has been accused of listing products without retailers’ consent&lt;/strong&gt;&lt;br /&gt;Small shop owners claim Amazon’s AI tool sold their goods without their permission. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It also listed products the shops didn’t actually have in stock. &lt;/em&gt;(CNBC)&lt;br /&gt;+ &lt;em&gt;A new feature called “Shop Direct” appears to be to blame. &lt;/em&gt;(Insider $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Data centers are a political issue&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Opposition to them is uniting communities across the political divide. (WP $)&lt;br /&gt;+ &lt;em&gt;Power-grid operators have suggested the centers power down at certain times. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;The data center boom in the desert. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Things are looking up for the nuclear power industry&lt;/strong&gt;&lt;br /&gt;The Trump administration is pumping money into it—but success is not guaranteed. (NYT $)&lt;br /&gt;+ &lt;em&gt;Why the grid relies on nuclear reactors in the winter. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 A new form of climate modelling pins blame on specific companies&lt;br /&gt;It may not be too long until we see the first case of how attribution science holds up in court. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Google, Amazon and the problem with Big Tech’s climate claims. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Meta has paused the launch of its Ray-Ban smartglasses &lt;/strong&gt;&lt;strong&gt;🕶️&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;They’re just too darn popular, apparently. (Engadget)&lt;br /&gt;+ &lt;em&gt;Europe and Canada will just have to wait. &lt;/em&gt;(Gizmodo)&lt;br /&gt;+ &lt;em&gt;It’s blaming supply shortages and “unprecedented” demand. &lt;/em&gt;(Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Sperm contains information about a father’s fitness and diet&lt;br /&gt;&lt;/strong&gt;New research is shedding light on how we think about heredity. (Quanta Magazine)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Meta is selling online gambling ads in countries where it’s illegal&lt;br /&gt;&lt;/strong&gt;It’s ignoring local laws across Asia and the Middle East. (Rest of World)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;8 AI isn’t always trying to steal your job&lt;br /&gt;&lt;/strong&gt;Sometimes it makes your toy robot a better companion. (The Verge)&lt;br /&gt;+ &lt;em&gt;How cuddly robots could change dementia care. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 How to lock down a job at one of tech’s biggest companies&lt;/strong&gt;&lt;br /&gt;You’re more likely to be accepted into Harvard, apparently. (Fast Company $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Millennials are falling out of love with the internet&lt;br /&gt;&lt;/strong&gt;Is a better future still possible? (Vox)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I want to keep up with the latest doom.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Author Margaret Atwood explains why she doomscrolls to Wired.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1130809" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/image_daa428.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside the decades-long fight over Yahoo’s misdeeds in China&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When you think of Big Tech these days, Yahoo is probably not top of mind. But for Chinese dissident Xu Wanping, the company still looms large—and has for nearly two decades.&lt;/p&gt;&lt;p&gt;In 2005, Xu was arrested for signing online petitions relating to anti-Japanese protests. He didn’t use his real name, but he did use his Yahoo email address. Yahoo China violated its users’ trust—providing information on certain email accounts to Chinese law enforcement, which in turn allowed the government to identify and arrest some users.&lt;/p&gt;&lt;p&gt;Xu was one of them; he would serve nine years in prison. Now, he and five other Chinese former political prisoners are suing Yahoo and a slate of co-defendants—not because of the company’s information-sharing (which was the focus of an earlier lawsuit filed by other plaintiffs), but rather because of what came after. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Eileen Guo&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ It’s time to celebrate the life and legacy of Cecilia Giménez Zueco, the legendary Spanish amateur painter whose botched fresco restoration reached viral fame in 2012.&lt;br /&gt;+ If you’re a sci-fi literature fan, there’s plenty of new releases to look forward to in 2026.&lt;br /&gt;+ Last week’s wolf supermoon was a sight to behold.&lt;br /&gt;+ This Mississippi restaurant is putting its giant lazy Susan to good use.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Europe’s drone-filled vision for the future of war&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Last spring, 3,000 British soldiers deployed an invisible automated intelligence network, known as a “digital targeting web,” as part of a NATO exercise called Hedgehog in the damp forests of Estonia’s eastern territories.&lt;/p&gt;&lt;p&gt;The system had been cobbled together over the course of four months—an astonishing pace for weapons development, which is usually measured in years. Its purpose is to connect everything that looks for targets—“sensors,” in military lingo—and everything that fires on them (“shooters”) to a single, shared wireless electronic brain.&lt;/p&gt;&lt;p&gt;Eighty years after total war last transformed the continent, the Hedgehog tests signal a brutal new calculus of European defense. But leaning too much on this new mathematics of warfare could be a risky bet.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Arthur Holland Michel&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;This story is from the next print issue of&lt;em&gt; MIT Technology Review&lt;/em&gt; magazine. If you haven’t already, &lt;/strong&gt;&lt;strong&gt;subscribe now&lt;/strong&gt;&lt;strong&gt; to receive it once it lands.&lt;/strong&gt;&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;MIT Technology Review Narrated: How one controversial startup hopes to cool the planet&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Stardust Solutions believes that it can solve climate change—for a price.&lt;/p&gt;&lt;p&gt;The Israel-based geoengineering startup has said it expects nations will soon pay it more than a billion dollars a year to launch specially equipped aircraft into the stratosphere. Once they’ve reached the necessary altitude, those planes will disperse particles engineered to reflect away enough sunlight to cool down the planet, purportedly without causing environmental side effects.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But numerous solar geoengineering researchers are skeptical that Stardust will line up the customers it needs to carry out a global deployment in the next decade. They’re also highly critical of the idea of a private company setting the global temperature for us.&lt;/p&gt;  &lt;p&gt;This is our latest story to be turned into a MIT Technology Review Narrated podcast, which we’re publishing each week on Spotify and Apple Podcasts. Just navigate to MIT Technology Review Narrated on either platform, and follow us to get all our new content as it’s released.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Amazon has been accused of listing products without retailers’ consent&lt;/strong&gt;&lt;br /&gt;Small shop owners claim Amazon’s AI tool sold their goods without their permission. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;It also listed products the shops didn’t actually have in stock. &lt;/em&gt;(CNBC)&lt;br /&gt;+ &lt;em&gt;A new feature called “Shop Direct” appears to be to blame. &lt;/em&gt;(Insider $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Data centers are a political issue&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;Opposition to them is uniting communities across the political divide. (WP $)&lt;br /&gt;+ &lt;em&gt;Power-grid operators have suggested the centers power down at certain times. &lt;/em&gt;(WSJ $)&lt;br /&gt;+ &lt;em&gt;The data center boom in the desert. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 

 &lt;p&gt;&lt;strong&gt;3 Things are looking up for the nuclear power industry&lt;/strong&gt;&lt;br /&gt;The Trump administration is pumping money into it—but success is not guaranteed. (NYT $)&lt;br /&gt;+ &lt;em&gt;Why the grid relies on nuclear reactors in the winter. &lt;/em&gt;(MIT Technology Review)&lt;strong&gt;&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;4 A new form of climate modelling pins blame on specific companies&lt;br /&gt;It may not be too long until we see the first case of how attribution science holds up in court. (New Scientist $)&lt;br /&gt;+ &lt;em&gt;Google, Amazon and the problem with Big Tech’s climate claims. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 Meta has paused the launch of its Ray-Ban smartglasses &lt;/strong&gt;&lt;strong&gt;🕶️&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;They’re just too darn popular, apparently. (Engadget)&lt;br /&gt;+ &lt;em&gt;Europe and Canada will just have to wait. &lt;/em&gt;(Gizmodo)&lt;br /&gt;+ &lt;em&gt;It’s blaming supply shortages and “unprecedented” demand. &lt;/em&gt;(Insider $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;6 Sperm contains information about a father’s fitness and diet&lt;br /&gt;&lt;/strong&gt;New research is shedding light on how we think about heredity. (Quanta Magazine)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 Meta is selling online gambling ads in countries where it’s illegal&lt;br /&gt;&lt;/strong&gt;It’s ignoring local laws across Asia and the Middle East. (Rest of World)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;8 AI isn’t always trying to steal your job&lt;br /&gt;&lt;/strong&gt;Sometimes it makes your toy robot a better companion. (The Verge)&lt;br /&gt;+ &lt;em&gt;How cuddly robots could change dementia care. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 How to lock down a job at one of tech’s biggest companies&lt;/strong&gt;&lt;br /&gt;You’re more likely to be accepted into Harvard, apparently. (Fast Company $)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;10 Millennials are falling out of love with the internet&lt;br /&gt;&lt;/strong&gt;Is a better future still possible? (Vox)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“I want to keep up with the latest doom.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Author Margaret Atwood explains why she doomscrolls to Wired.&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1130809" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/image_daa428.png" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside the decades-long fight over Yahoo’s misdeeds in China&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;When you think of Big Tech these days, Yahoo is probably not top of mind. But for Chinese dissident Xu Wanping, the company still looms large—and has for nearly two decades.&lt;/p&gt;&lt;p&gt;In 2005, Xu was arrested for signing online petitions relating to anti-Japanese protests. He didn’t use his real name, but he did use his Yahoo email address. Yahoo China violated its users’ trust—providing information on certain email accounts to Chinese law enforcement, which in turn allowed the government to identify and arrest some users.&lt;/p&gt;&lt;p&gt;Xu was one of them; he would serve nine years in prison. Now, he and five other Chinese former political prisoners are suing Yahoo and a slate of co-defendants—not because of the company’s information-sharing (which was the focus of an earlier lawsuit filed by other plaintiffs), but rather because of what came after. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Eileen Guo&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ It’s time to celebrate the life and legacy of Cecilia Giménez Zueco, the legendary Spanish amateur painter whose botched fresco restoration reached viral fame in 2012.&lt;br /&gt;+ If you’re a sci-fi literature fan, there’s plenty of new releases to look forward to in 2026.&lt;br /&gt;+ Last week’s wolf supermoon was a sight to behold.&lt;br /&gt;+ This Mississippi restaurant is putting its giant lazy Susan to good use.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/07/1130806/the-download-war-in-europe-and-the-company-that-wants-to-cool-the-planet/</guid><pubDate>Wed, 07 Jan 2026 13:10:00 +0000</pubDate></item><item><title>[NEW] Deploying a hybrid approach to Web3 in the AI era (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/07/1129490/deploying-a-hybrid-approach-to-web3-in-the-ai-era/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;AIOZ Network&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;When the concept of “Web 3.0” first emerged about a decade ago the idea was clear: Create a more user-controlled internet that lets you do everything you can now, except without servers or intermediaries to manage the flow of information.&lt;/p&gt;  &lt;p&gt;Where Web2, which emerged in the early 2000s, relies on centralized systems to store data and supply compute, all owned—and monetized by—a handful of global conglomerates, Web3 turns that structure on its head. Instead, data and compute are decentralized through technologies like blockchain and peer-to-peer networks.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1129492" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/AIOZ-Network-3.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;What was once a futuristic concept is quickly becoming a more concrete reality, even at a time when Web2 still dominates. Six out of ten Fortune 500 companies are exploring blockchain-based solutions, most taking a hybrid approach that combines traditional Web2 business models and infrastructure with the decentralized technologies and principles of Web3.&lt;/p&gt;  &lt;p&gt;Popular use cases include cloud services, supply chain management, and, most notably financial services. In fact, at one point, the daily volume of transactions processed on decentralized finance exchanges exceeded $10 billion.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Gaining a Web3 edge&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Among the advantages of Web3 for the enterprise are greater ownership and control of sensitive data, says Erman Tjiputra, founder and CEO of the AIOZ Network, which is building infrastructure for Web3, powered by decentralized physical infrastructure networks (DePIN), blockchain-based systems that govern physical infrastructure assets.&lt;/p&gt;  &lt;p&gt;More cost-effective compute is another benefit, as is enhanced security and privacy as the cyberattack landscape grows more hostile, he adds. And it could even help protect companies from outages caused by a single point of failure, which can lead to downtime, data loss, and revenue deficits.&lt;/p&gt; 
 &lt;p&gt;But perhaps the most exciting opportunity, says Tjiputra, is the ability to build and scale AI reliably and affordably. By leveraging a people-powered internet infrastructure, companies can far more easily access—and contribute to—shared resource like bandwidth, storage, and processing power to run AI inference, train models, and store data. All while using familiar developer tooling and open, usage-based incentives.&lt;/p&gt;  &lt;p&gt;“We’re in a compute crunch where requirements are insatiable, and Web3 creates this ability to benefit while contributing,” explains Tjiputra.&lt;/p&gt;  &lt;p&gt;In 2025, AIOZ Network launched a distributed compute platform and marketplace where developers and enterprises can access and monetize AI assets, and run AI inference or training on AIOZ Network’s more than 300,000 contributing devices. The model allows companies to move away from opaque datasets and models and scale flexibly, without centralized lock in.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Overcoming &lt;/strong&gt;&lt;strong&gt;Web3 deployment challenges&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite the promise, it is still early days for Web3, and core systemic challenges are leaving senior leadership and developers hesitant about its applicability at scale.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;One hurdle is a lack of interoperability. The current fragmentation of blockchain networks creates a segregated ecosystem that makes it challenging to transfer assets or data between platforms. This often complicates transactions and introduces new security risks due to the reliance on mechanisms such as cross-chain bridges. These are tools that allow asset transfers between platforms but which have been shown to be vulnerable to targeted attacks.&lt;/p&gt;  &lt;p&gt;“We have countless blockchains running on different protocols and consensus models,” says Tjiputra. “These blockchains need to work with each other so applications can communicate regardless of which chain they are on. This makes interoperability fundamental.”&lt;/p&gt;  &lt;p&gt;Regulatory uncertainty is also a challenge. Outdated legal frameworks can sit at odds with decentralized infrastructures, especially when it comes to compliance with data protection and anti-money laundering regulations.&lt;/p&gt;  &lt;p&gt;“Enterprises care about verifiability and compliance as much as innovation, so we need frameworks where on-chain transparency strengthens accountability instead of adding friction,” Tjiputra says.&lt;/p&gt; 

 &lt;p&gt;And this is compounded by user experience (UX) challenges, says Tjiputra. “The biggest setback in Web3 today is UX,” he says. “For example, in Web2, if I forget my bank username or password, I can still contact the bank, log in and access my assets. The trade-off in Web3 is that, should that key be compromised or lost, we lose access to those assets. So, key recovery is a real problem.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building a bridge to Web3&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Although such systemic challenges won’t be solved overnight, by leveraging DePIN networks, enterprises can bridge the gap between Web2 and Web3, without making a wholesale switch. This can minimize risk while harnessing much of the potential.&lt;/p&gt;  &lt;p&gt;AIOZ Network’s own ecosystem includes capacity for media streaming, AI compute, and distributed storage that can be plugged into an existing Web2 tech stack. “You don’t need to go full Web3,” says Tjiputra. “You can start by plugging distributed storage into your workflow, test it, measure it, and see the benefits firsthand.”&lt;/p&gt;  &lt;p&gt;The AIOZ Storage solution, for example, offers scalable distributed object storage by leveraging the global network of contributor devices on AIOZ DePIN. It is also compatible with existing storage systems or commonly used web application programming interfaces (APIs).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Say we have a programmer or developer who uses Amazon S3 Storage or REST APIs, then all they need to do is just repoint the endpoints,” explains Tjiputra. “That's it. It’s the same tools, it's really simple. Even with media, with a single one-stop shop, developers can do transcoding and streaming with a simple REST API.”&lt;/p&gt;  &lt;p&gt;Built on Cosmos, a network of hundreds of different blockchains that can communicate with each other, and a standardized framework enabled by Ethereum Virtual Machine (EVM), AIOZ Network has also prioritized interoperability. “Applications shouldn’t care which chain they’re on. Developers should target APIs without worrying about consensus mechanisms. That’s why we built on Cosmos and EVM—interoperability first.”&lt;/p&gt;  &lt;p&gt;This hybrid model, which allows enterprises to use both Web2 and Web3 advantages in tandem, underpins what Tjiputra sees as the longer-term ambition for the much-hyped next iteration of the internet.&lt;/p&gt;  &lt;p&gt;“Our vision is a truly peer-to-peer foundation for a people-powered internet, one that minimizes single points of failure through multi-region, multi-operator design,” says Tjiputra. “By distributing compute and storage across contributors, we gain both cost efficiency and end-to-end security by default.&lt;/p&gt; 
 &lt;p&gt;“Ideally, we want to evolve the internet toward a more people-powered model, but we’re not there yet. We’re still at the starting point and growing.”&lt;/p&gt;  &lt;p&gt;Indeed, Web3 isn’t quite snapping at the heels of the world’s Web2 giants, but its commercial advantages in an era of AI have become much harder to ignore. And with DePIN bridging the gap, enterprises and developers can step into that potential while keeping one foot on surer ground.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;To learn more from AIOZ Network, you can read the&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;AIOZ Network Vision Paper&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;AIOZ Network&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;When the concept of “Web 3.0” first emerged about a decade ago the idea was clear: Create a more user-controlled internet that lets you do everything you can now, except without servers or intermediaries to manage the flow of information.&lt;/p&gt;  &lt;p&gt;Where Web2, which emerged in the early 2000s, relies on centralized systems to store data and supply compute, all owned—and monetized by—a handful of global conglomerates, Web3 turns that structure on its head. Instead, data and compute are decentralized through technologies like blockchain and peer-to-peer networks.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1129492" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/AIOZ-Network-3.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;What was once a futuristic concept is quickly becoming a more concrete reality, even at a time when Web2 still dominates. Six out of ten Fortune 500 companies are exploring blockchain-based solutions, most taking a hybrid approach that combines traditional Web2 business models and infrastructure with the decentralized technologies and principles of Web3.&lt;/p&gt;  &lt;p&gt;Popular use cases include cloud services, supply chain management, and, most notably financial services. In fact, at one point, the daily volume of transactions processed on decentralized finance exchanges exceeded $10 billion.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Gaining a Web3 edge&lt;/strong&gt;&lt;strong&gt;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Among the advantages of Web3 for the enterprise are greater ownership and control of sensitive data, says Erman Tjiputra, founder and CEO of the AIOZ Network, which is building infrastructure for Web3, powered by decentralized physical infrastructure networks (DePIN), blockchain-based systems that govern physical infrastructure assets.&lt;/p&gt;  &lt;p&gt;More cost-effective compute is another benefit, as is enhanced security and privacy as the cyberattack landscape grows more hostile, he adds. And it could even help protect companies from outages caused by a single point of failure, which can lead to downtime, data loss, and revenue deficits.&lt;/p&gt; 
 &lt;p&gt;But perhaps the most exciting opportunity, says Tjiputra, is the ability to build and scale AI reliably and affordably. By leveraging a people-powered internet infrastructure, companies can far more easily access—and contribute to—shared resource like bandwidth, storage, and processing power to run AI inference, train models, and store data. All while using familiar developer tooling and open, usage-based incentives.&lt;/p&gt;  &lt;p&gt;“We’re in a compute crunch where requirements are insatiable, and Web3 creates this ability to benefit while contributing,” explains Tjiputra.&lt;/p&gt;  &lt;p&gt;In 2025, AIOZ Network launched a distributed compute platform and marketplace where developers and enterprises can access and monetize AI assets, and run AI inference or training on AIOZ Network’s more than 300,000 contributing devices. The model allows companies to move away from opaque datasets and models and scale flexibly, without centralized lock in.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Overcoming &lt;/strong&gt;&lt;strong&gt;Web3 deployment challenges&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Despite the promise, it is still early days for Web3, and core systemic challenges are leaving senior leadership and developers hesitant about its applicability at scale.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;One hurdle is a lack of interoperability. The current fragmentation of blockchain networks creates a segregated ecosystem that makes it challenging to transfer assets or data between platforms. This often complicates transactions and introduces new security risks due to the reliance on mechanisms such as cross-chain bridges. These are tools that allow asset transfers between platforms but which have been shown to be vulnerable to targeted attacks.&lt;/p&gt;  &lt;p&gt;“We have countless blockchains running on different protocols and consensus models,” says Tjiputra. “These blockchains need to work with each other so applications can communicate regardless of which chain they are on. This makes interoperability fundamental.”&lt;/p&gt;  &lt;p&gt;Regulatory uncertainty is also a challenge. Outdated legal frameworks can sit at odds with decentralized infrastructures, especially when it comes to compliance with data protection and anti-money laundering regulations.&lt;/p&gt;  &lt;p&gt;“Enterprises care about verifiability and compliance as much as innovation, so we need frameworks where on-chain transparency strengthens accountability instead of adding friction,” Tjiputra says.&lt;/p&gt; 

 &lt;p&gt;And this is compounded by user experience (UX) challenges, says Tjiputra. “The biggest setback in Web3 today is UX,” he says. “For example, in Web2, if I forget my bank username or password, I can still contact the bank, log in and access my assets. The trade-off in Web3 is that, should that key be compromised or lost, we lose access to those assets. So, key recovery is a real problem.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Building a bridge to Web3&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Although such systemic challenges won’t be solved overnight, by leveraging DePIN networks, enterprises can bridge the gap between Web2 and Web3, without making a wholesale switch. This can minimize risk while harnessing much of the potential.&lt;/p&gt;  &lt;p&gt;AIOZ Network’s own ecosystem includes capacity for media streaming, AI compute, and distributed storage that can be plugged into an existing Web2 tech stack. “You don’t need to go full Web3,” says Tjiputra. “You can start by plugging distributed storage into your workflow, test it, measure it, and see the benefits firsthand.”&lt;/p&gt;  &lt;p&gt;The AIOZ Storage solution, for example, offers scalable distributed object storage by leveraging the global network of contributor devices on AIOZ DePIN. It is also compatible with existing storage systems or commonly used web application programming interfaces (APIs).&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Say we have a programmer or developer who uses Amazon S3 Storage or REST APIs, then all they need to do is just repoint the endpoints,” explains Tjiputra. “That's it. It’s the same tools, it's really simple. Even with media, with a single one-stop shop, developers can do transcoding and streaming with a simple REST API.”&lt;/p&gt;  &lt;p&gt;Built on Cosmos, a network of hundreds of different blockchains that can communicate with each other, and a standardized framework enabled by Ethereum Virtual Machine (EVM), AIOZ Network has also prioritized interoperability. “Applications shouldn’t care which chain they’re on. Developers should target APIs without worrying about consensus mechanisms. That’s why we built on Cosmos and EVM—interoperability first.”&lt;/p&gt;  &lt;p&gt;This hybrid model, which allows enterprises to use both Web2 and Web3 advantages in tandem, underpins what Tjiputra sees as the longer-term ambition for the much-hyped next iteration of the internet.&lt;/p&gt;  &lt;p&gt;“Our vision is a truly peer-to-peer foundation for a people-powered internet, one that minimizes single points of failure through multi-region, multi-operator design,” says Tjiputra. “By distributing compute and storage across contributors, we gain both cost efficiency and end-to-end security by default.&lt;/p&gt; 
 &lt;p&gt;“Ideally, we want to evolve the internet toward a more people-powered model, but we’re not there yet. We’re still at the starting point and growing.”&lt;/p&gt;  &lt;p&gt;Indeed, Web3 isn’t quite snapping at the heels of the world’s Web2 giants, but its commercial advantages in an era of AI have become much harder to ignore. And with DePIN bridging the gap, enterprises and developers can step into that potential while keeping one foot on surer ground.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;To learn more from AIOZ Network, you can read the&lt;/strong&gt;&lt;strong&gt; &lt;/strong&gt;AIOZ Network Vision Paper&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/07/1129490/deploying-a-hybrid-approach-to-web3-in-the-ai-era/</guid><pubDate>Wed, 07 Jan 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] Computer scientist Yann LeCun: “Intelligence really is about learning” (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/computer-scientist-yann-lecun-intelligence-really-is-about-learning/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The AI pioneer talks about stepping down from Meta, limits of large language models.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of Yann LeCun" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of Yann LeCun" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Financial Times

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;I arrive 10 minutes ahead of schedule from an early morning Eurostar and see Yann LeCun is already waiting for me, nestled between two plastic Christmas trees in the nearly empty winter garden of Michelin-starred restaurant Pavyllon.&lt;/p&gt;
&lt;p&gt;The restaurant is next to Paris’s Grand Palais, where President Emmanuel Macron kick-started 2025 by hosting an international AI summit, a glitzy showcase packed with French exceptionalism and international tech luminaries including LeCun, who is considered one of the “godfathers” of modern AI.&lt;/p&gt;
&lt;p&gt;LeCun gets up to hug me in greeting, wearing his signature black Ray-Ban Wayfarer glasses. He looks well rested for a man who has spent nearly a week running around town plotting world domination. Or, more precisely, “total world assistance” or “intelligent amplification, if you want.” Domination “sounds scary with AI,” he acknowledges.&lt;/p&gt;
&lt;p&gt;The last time I met him was at a summer conference in Paris, where he was unveiling the latest iteration of his vision for superintelligent machines as Meta’s chief AI scientist. Now, he is preparing to leave his longtime employer, and fundraising for a new start-up that will bring that vision to life.&lt;/p&gt;
&lt;p&gt;LeCun’s schedule has been relentless since the Financial Times broke the news that he was leaving Meta. “It basically pushed us to accelerate the calendar,” he says. Macron sent him a WhatsApp message after the story came out. LeCun declines to tell me exactly what the president said, but does hint that he was pleased the new “worldwide” company will have a strong connection to France.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m a scientist, a visionary… I’m pretty good at guessing what type of technology will work or not. But I can’t be a&amp;nbsp;CEO&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;LeCun will not be the company’s chief executive, but the executive chair, allowing him the same kind of freedom to do research that he had at Meta. (Since our lunch, the FT has reported that LeCun’s new venture is called Advanced Machine Intelligence Labs and will be led by Alex LeBrun, the co-founder and chief executive of French health care AI start-up Nabla.)&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I’m a scientist, a visionary. I can inspire people to work on interesting things. I’m pretty good at guessing what type of technology will work or not. But I can’t be a CEO,” LeCun says. “I’m both too disorganized for this, and also too old!”&lt;/p&gt;
&lt;p&gt;The waitress offers us champagne to start. I opt for a glass of alcohol-free Blanc de Blancs. LeCun, a fan of wines, is curious to try it too. We clink glasses.&lt;/p&gt;
&lt;p&gt;Things have changed for me as well since we last met: I am pregnant. I make a joke that I too am growing my own superintelligence. “It is the most efficient way,” he says.&lt;/p&gt;
&lt;p&gt;LeCun would know, as he has been gestating ideas for the creation of such intelligence in machines for decades. He has also been vocal about his disdain for large language models (LLMs) and their potential to reach superhuman intelligence, which is the current obsession of Silicon Valley. He argues that LLMs are useful but fundamentally limited and constrained by language. To achieve human-level intelligence, you have to understand how our physical world works too.&lt;/p&gt;
&lt;p&gt;His solution for achieving that relies on an architecture called V-JEPA, a so-called world model. World models aim to understand the physical world by learning from videos and spatial data, rather than just language. They are also able to plan, reason, and have persistent memory. He calls this kind of intelligence Advanced Machine Intelligence, or AMI.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Born in 1960 and raised in the suburbs of Paris,&lt;/strong&gt; LeCun has been fascinated by the question of how human intelligence emerged since he was a young boy.&lt;/p&gt;
&lt;p&gt;It was the film &lt;em&gt;2001: A Space Odyssey&lt;/em&gt;, which he saw when he was 8 or 9 years old, that set him on the path he is on today. He gestures having his mind blown.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;LeCun’s father, an aeronautical engineer and “a bit of an inventor,” instilled a love of building and tinkering with things. LeCun grew up constructing model aeroplanes and playing woodwind instruments such as the recorder and the crumhorn, a “weird Renaissance instrument,” which he played in a Renaissance dance music band.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m sure there’s a lot of people at Meta who would like me to not tell the world that LLMs basically are a dead end when it comes to&amp;nbsp;superintelligence&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;We’ve both chosen the four-course “Champs-Élysées” lunch set menu. As we tuck into our starters (soft-boiled eggs, tuna tartare with smoked pike roe and croutons for LeCun, and a broth of root vegetables and horseradish ravioli with Chartreuse sauce for me), he tells me how a teacher deemed him too bad at math to study it at university, so he decided to pursue engineering.&lt;/p&gt;
&lt;p&gt;The waitress comes to check on us, and LeCun orders a glass of Chassagne-Montrachet from Burgundy. “What Americans would call Chardonnay,” he says, jokingly.&lt;/p&gt;
&lt;p&gt;LeCun’s lightbulb moment came as a student at the École Supérieure d’Ingénieurs en Électrotechnique et Électronique in Paris in the 1980s, when he read a book about a debate on nature versus nurture between the linguist Noam Chomsky and Jean Piaget, a psychologist. Chomsky argued that humans have an inbuilt capacity for language, while Piaget said there is some structure but most of it is learnt.&lt;/p&gt;
&lt;p&gt;“I’m not gonna make friends saying this… ” he tells me, “but I was reading this and I thought everything that Chomsky… was saying could not possibly be true, [because] we learn everything. Intelligence really is about learning.”&lt;/p&gt;
&lt;p&gt;AI research—or neural networks, as the technology was then called, which loosely mimic how the brain functions—was practically a dead field and considered taboo by the scientific community, after early iterations of the technology failed to impress. But LeCun sought out other researchers studying neural networks and found intellectual “soulmates” in the likes of Geoffrey Hinton, then a faculty member at Carnegie Mellon.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He later joined Hinton at the University of Toronto as a postdoc researcher. The two, along with Yoshua Bengio, went on to lay the groundwork for deep learning and modern AI, which saw them rewarded in 2018 with the Turing Award, the most prestigious prize in computer science.&lt;/p&gt;
&lt;p&gt;The waitress lays our second, gorgeous, dish in front of us and launches into an enthusiastic description of the meal in French. I nod along equally enthusiastically, understanding nothing.&lt;/p&gt;
&lt;p&gt;“Did you get that?” LeCun asks. “This is the foie gras, and this is the Comté soufflé, and the Comté is 18 months aged.” When in France, I think, and take a bite of the liver.&lt;/p&gt;
&lt;p&gt;LeCun is the brain behind important early AI technologies. In the late 1980s and 1990s, while a researcher at AT&amp;amp;T Bell Labs in New Jersey—once known as the leading industry research lab in the world—he developed convolutional neural networks, an architecture used in image recognition technology, which he built into a system that was widely used by banks to read checks.&lt;/p&gt;
&lt;p&gt;He had conceived of the research at Toronto, but was able to roll it out in the real world thanks to the seemingly unlimited coffers of cash and cutting-edge technology available at Bell Labs.&lt;/p&gt;
&lt;p&gt;LeCun recounts something his boss at the time, Larry Jackel, told him when he first joined. “He said, ‘You know, at Bell Labs? You don’t get famous by saving money.’”&lt;/p&gt;
&lt;p&gt;Our main dish arrives, a portion of cod with herbed breadcrumbs and fried capers. LeCun is in a jovial mood, and I find myself engrossed in his colorful stories about the early years of AI research.&lt;/p&gt;
&lt;p&gt;He, along with his pharmacist wife, Isabelle, and their three sons, ended up settling in New Jersey for good, although he visits Paris every five weeks or so. America was a “culture shock,” he says.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The party at Bell Labs was destined to end. A corporate shake-up meant the lab lost significant funding and was spun off to different subsidiaries. LeCun rejoined academia and started a new project at NYU aimed at researching neural networks, frequenting Greenwich Village’s jazz clubs after his lectures.&lt;/p&gt;
&lt;p&gt;By 2013, it was clear that deep learning was going to work, with image recognition applications showing impressive results. Google had just started Google Brain, and a year later would acquire British AI lab DeepMind.&lt;/p&gt;
&lt;p&gt;It was also then that Mark Zuckerberg called. He wanted to start an AI unit at Facebook, and to woo LeCun invited him over for dinner at his California home. A private chef prepared “chicken with some pretty good white wine,” LeCun recalls.&lt;/p&gt;
&lt;p&gt;LeCun agreed to join on three conditions. He wouldn’t have to quit his job at NYU. He wouldn’t move to California. And the research results of the new lab had to be made publicly available.&lt;/p&gt;
&lt;p&gt;Zuckerberg agreed, and the deal was done. LeCun was to join Facebook, one of the biggest technology companies in the world, to set up a new AI research lab focusing on fundamental research, called Facebook Artificial Intelligence Research (Fair).&lt;/p&gt;
&lt;p&gt;Facebook was a “tabula rasa with a carte blanche,” LeCun says. “Money was clearly not going to be a problem.”&lt;/p&gt;
&lt;p&gt;The waitress interrupts us to bring our dessert, bricelets. “&lt;em&gt;Magnifique&lt;/em&gt;,” LeCun says, as the dish is placed in front of him.&lt;/p&gt;
&lt;p&gt;I shift the conversation to a more tumultuous time. In early 2022, pre-ChatGPT, all the major AI labs had some version of the technology kicking around, but it was seen as largely experimental. It was a small, relatively unknown AI lab called OpenAI that kick-started today’s AI mania, when it quietly launched the technology as an easily accessible chatbot.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;We had a lot of new ideas and really cool stuff… But they were just going for things that were safe and proved. When you do this, you fall&amp;nbsp;behind&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;ChatGPT caused a frantic scramble at Meta. The company’s leadership decided to put all their chips into work developing Llama, a large language model. Zuckerberg reshuffled the organization to create a generative AI unit, which was tasked with accelerating research into products. LeCun insisted the model was released openly.&lt;/p&gt;
&lt;p&gt;Llama 2, released with open weights for all users, meaning people could download and tweak it for free, was a “watershed” moment, which “changed the entire industry,” LeCun says. The model became the gold standard in powerful open LLMs, and championed an approach that was counter to the extreme concentration of power that Google and OpenAI were pushing. Meta was seen as the good guys in AI research.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Meta switched gears aggressively&lt;/strong&gt; on AI last year. Zuckerberg placed more pressure on the GenAI unit to accelerate AI development and deployment, which led to a communication breakdown, LeCun says.&lt;/p&gt;
&lt;p&gt;“We had a lot of new ideas and really cool stuff that they should implement. But they were just going for things that were essentially safe and proved,” he says. “When you do this, you fall behind.”&lt;/p&gt;
&lt;p&gt;The subsequent Llama models were duds. Llama 4, which was released in April 2025, was a flop, and the company was accused of gaming benchmarks to make it look more impressive. LeCun admits that the “results were fudged a little bit,” and the team used different models for different benchmarks to give better results.&lt;/p&gt;
&lt;p&gt;“Mark was really upset and basically lost confidence in everyone who was involved in this. And so basically sidelined the entire GenAI organization. A lot of people have left, a lot of people who haven’t yet left will leave.”&lt;/p&gt;
&lt;p&gt;Last June, Meta invested $15 billion in data-labeling start-up Scale AI and hired its 28-year-old chief executive and co-founder Alexandr Wang. Wang took the reins of the company’s new bet on AI and its research unit, called TBD Lab. The lab is tasked with developing new frontier AI models.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta made headlines for trying to poach elite researchers from competitors with offers of $100 million sign-on bonuses. “The future will say whether that was a good idea or not,” LeCun says, deadpan.&lt;/p&gt;
&lt;p&gt;LeCun calls Wang, who was hired to lead the organization, “young” and “inexperienced.”&lt;/p&gt;
&lt;p&gt;“He learns fast, he knows what he doesn’t know… There’s no experience with research or how you practice research, how you do it. Or what would be attractive or repulsive to a researcher.”&lt;/p&gt;
&lt;p&gt;Wang also became LeCun’s manager. I ask LeCun how he felt about this shift in hierarchy. He initially brushes it off, saying he’s used to working with young people. “The average age of a Facebook engineer at the time was 27. I was twice the age of the average engineer.”&lt;/p&gt;
&lt;p&gt;But those 27-year-olds weren’t telling him what to do, I point out.&lt;/p&gt;
&lt;p&gt;“Alex [Wang] isn’t telling me what to do either,” he says. “You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to do.”&lt;/p&gt;
&lt;p&gt;LeCun doesn’t mince his words about why he ultimately decided to leave Meta after more than a decade. Staying became politically difficult, he tells me. And while Zuckerberg likes LeCun’s world model research, the crowd who were hired for the company’s new superintelligence push are “completely LLM-pilled.”&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to&amp;nbsp;do&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;This clearly alienated LeCun. “I’m sure there’s a lot of people at Meta, including perhaps Alex, who would like me to not tell the world that LLMs basically are a dead end when it comes to superintelligence,” he says. “But I’m not gonna change my mind because some dude thinks I’m wrong. I’m not wrong. My integrity as a scientist cannot allow me to do this.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Another driver to leave was that his work with world models and AMI was also proving to have potential uses that were not interesting to Meta, such as jet engines and heavy industry. And LeCun had no trouble finding investors who were willing to bet on the next generation of AI technologies.&lt;/p&gt;
&lt;p&gt;In his next chapter, LeCun believes that setting up a “neolab,” meaning a start-up that does fundamental research, is the new, most fertile ground. He cites OpenAI former chief technology officer Mira Murati’s Thinking Machines (“I hope the investors know what they do”) and OpenAI’s co-founder and chief scientist Ilya Sutskever’s Safe Superintelligence (“There I know the investors have no idea what they do”) as good examples.&lt;/p&gt;
&lt;p&gt;His new architecture uses videos to give AI models an understanding of the physics of our world, which will allow them to make better predictions of what will happen next. The model also relies on “emotions,” meaning past experiences and evaluations, to guide its predictions.&lt;/p&gt;
&lt;p&gt;“If I pinch you, you’re going to feel pain. But then your mental model of me is going to be affected by the fact that I just pinched you. And the next time I approach my arm to yours, you’re going to recoil. That’s your prediction, and the emotion it evokes is fear or avoidance of pain,” he says.&lt;/p&gt;
&lt;p&gt;LeCun says we will see “baby” versions of this within 12 months, and on a larger scale within a few years. It’s not quite yet superintelligence, but a path toward it. “Maybe there is an obstacle we’re not seeing yet, but at least there is hope.”&lt;/p&gt;
&lt;p&gt;After three and a half hours, we are now the only customers left in the restaurant. I ask him what he wants his legacy to be.&lt;/p&gt;
&lt;p&gt;Increasing the amount of intelligence in the world, he replies, without batting an eyelid. “Intelligence is really the thing that we should have more of,” he says, adding that with more intelligence, there’s less human suffering, more rational decisions, and more understanding of the world and the universe.&lt;/p&gt;
&lt;p&gt;“We suffer from stupidity.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Melissa Heikkilä is the FT’s AI correspondent.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2026 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The AI pioneer talks about stepping down from Meta, limits of large language models.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of Yann LeCun" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Illustration of Yann LeCun" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/lecun-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Financial Times

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;I arrive 10 minutes ahead of schedule from an early morning Eurostar and see Yann LeCun is already waiting for me, nestled between two plastic Christmas trees in the nearly empty winter garden of Michelin-starred restaurant Pavyllon.&lt;/p&gt;
&lt;p&gt;The restaurant is next to Paris’s Grand Palais, where President Emmanuel Macron kick-started 2025 by hosting an international AI summit, a glitzy showcase packed with French exceptionalism and international tech luminaries including LeCun, who is considered one of the “godfathers” of modern AI.&lt;/p&gt;
&lt;p&gt;LeCun gets up to hug me in greeting, wearing his signature black Ray-Ban Wayfarer glasses. He looks well rested for a man who has spent nearly a week running around town plotting world domination. Or, more precisely, “total world assistance” or “intelligent amplification, if you want.” Domination “sounds scary with AI,” he acknowledges.&lt;/p&gt;
&lt;p&gt;The last time I met him was at a summer conference in Paris, where he was unveiling the latest iteration of his vision for superintelligent machines as Meta’s chief AI scientist. Now, he is preparing to leave his longtime employer, and fundraising for a new start-up that will bring that vision to life.&lt;/p&gt;
&lt;p&gt;LeCun’s schedule has been relentless since the Financial Times broke the news that he was leaving Meta. “It basically pushed us to accelerate the calendar,” he says. Macron sent him a WhatsApp message after the story came out. LeCun declines to tell me exactly what the president said, but does hint that he was pleased the new “worldwide” company will have a strong connection to France.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m a scientist, a visionary… I’m pretty good at guessing what type of technology will work or not. But I can’t be a&amp;nbsp;CEO&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;LeCun will not be the company’s chief executive, but the executive chair, allowing him the same kind of freedom to do research that he had at Meta. (Since our lunch, the FT has reported that LeCun’s new venture is called Advanced Machine Intelligence Labs and will be led by Alex LeBrun, the co-founder and chief executive of French health care AI start-up Nabla.)&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“I’m a scientist, a visionary. I can inspire people to work on interesting things. I’m pretty good at guessing what type of technology will work or not. But I can’t be a CEO,” LeCun says. “I’m both too disorganized for this, and also too old!”&lt;/p&gt;
&lt;p&gt;The waitress offers us champagne to start. I opt for a glass of alcohol-free Blanc de Blancs. LeCun, a fan of wines, is curious to try it too. We clink glasses.&lt;/p&gt;
&lt;p&gt;Things have changed for me as well since we last met: I am pregnant. I make a joke that I too am growing my own superintelligence. “It is the most efficient way,” he says.&lt;/p&gt;
&lt;p&gt;LeCun would know, as he has been gestating ideas for the creation of such intelligence in machines for decades. He has also been vocal about his disdain for large language models (LLMs) and their potential to reach superhuman intelligence, which is the current obsession of Silicon Valley. He argues that LLMs are useful but fundamentally limited and constrained by language. To achieve human-level intelligence, you have to understand how our physical world works too.&lt;/p&gt;
&lt;p&gt;His solution for achieving that relies on an architecture called V-JEPA, a so-called world model. World models aim to understand the physical world by learning from videos and spatial data, rather than just language. They are also able to plan, reason, and have persistent memory. He calls this kind of intelligence Advanced Machine Intelligence, or AMI.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Born in 1960 and raised in the suburbs of Paris,&lt;/strong&gt; LeCun has been fascinated by the question of how human intelligence emerged since he was a young boy.&lt;/p&gt;
&lt;p&gt;It was the film &lt;em&gt;2001: A Space Odyssey&lt;/em&gt;, which he saw when he was 8 or 9 years old, that set him on the path he is on today. He gestures having his mind blown.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;LeCun’s father, an aeronautical engineer and “a bit of an inventor,” instilled a love of building and tinkering with things. LeCun grew up constructing model aeroplanes and playing woodwind instruments such as the recorder and the crumhorn, a “weird Renaissance instrument,” which he played in a Renaissance dance music band.&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;I’m sure there’s a lot of people at Meta who would like me to not tell the world that LLMs basically are a dead end when it comes to&amp;nbsp;superintelligence&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;We’ve both chosen the four-course “Champs-Élysées” lunch set menu. As we tuck into our starters (soft-boiled eggs, tuna tartare with smoked pike roe and croutons for LeCun, and a broth of root vegetables and horseradish ravioli with Chartreuse sauce for me), he tells me how a teacher deemed him too bad at math to study it at university, so he decided to pursue engineering.&lt;/p&gt;
&lt;p&gt;The waitress comes to check on us, and LeCun orders a glass of Chassagne-Montrachet from Burgundy. “What Americans would call Chardonnay,” he says, jokingly.&lt;/p&gt;
&lt;p&gt;LeCun’s lightbulb moment came as a student at the École Supérieure d’Ingénieurs en Électrotechnique et Électronique in Paris in the 1980s, when he read a book about a debate on nature versus nurture between the linguist Noam Chomsky and Jean Piaget, a psychologist. Chomsky argued that humans have an inbuilt capacity for language, while Piaget said there is some structure but most of it is learnt.&lt;/p&gt;
&lt;p&gt;“I’m not gonna make friends saying this… ” he tells me, “but I was reading this and I thought everything that Chomsky… was saying could not possibly be true, [because] we learn everything. Intelligence really is about learning.”&lt;/p&gt;
&lt;p&gt;AI research—or neural networks, as the technology was then called, which loosely mimic how the brain functions—was practically a dead field and considered taboo by the scientific community, after early iterations of the technology failed to impress. But LeCun sought out other researchers studying neural networks and found intellectual “soulmates” in the likes of Geoffrey Hinton, then a faculty member at Carnegie Mellon.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He later joined Hinton at the University of Toronto as a postdoc researcher. The two, along with Yoshua Bengio, went on to lay the groundwork for deep learning and modern AI, which saw them rewarded in 2018 with the Turing Award, the most prestigious prize in computer science.&lt;/p&gt;
&lt;p&gt;The waitress lays our second, gorgeous, dish in front of us and launches into an enthusiastic description of the meal in French. I nod along equally enthusiastically, understanding nothing.&lt;/p&gt;
&lt;p&gt;“Did you get that?” LeCun asks. “This is the foie gras, and this is the Comté soufflé, and the Comté is 18 months aged.” When in France, I think, and take a bite of the liver.&lt;/p&gt;
&lt;p&gt;LeCun is the brain behind important early AI technologies. In the late 1980s and 1990s, while a researcher at AT&amp;amp;T Bell Labs in New Jersey—once known as the leading industry research lab in the world—he developed convolutional neural networks, an architecture used in image recognition technology, which he built into a system that was widely used by banks to read checks.&lt;/p&gt;
&lt;p&gt;He had conceived of the research at Toronto, but was able to roll it out in the real world thanks to the seemingly unlimited coffers of cash and cutting-edge technology available at Bell Labs.&lt;/p&gt;
&lt;p&gt;LeCun recounts something his boss at the time, Larry Jackel, told him when he first joined. “He said, ‘You know, at Bell Labs? You don’t get famous by saving money.’”&lt;/p&gt;
&lt;p&gt;Our main dish arrives, a portion of cod with herbed breadcrumbs and fried capers. LeCun is in a jovial mood, and I find myself engrossed in his colorful stories about the early years of AI research.&lt;/p&gt;
&lt;p&gt;He, along with his pharmacist wife, Isabelle, and their three sons, ended up settling in New Jersey for good, although he visits Paris every five weeks or so. America was a “culture shock,” he says.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The party at Bell Labs was destined to end. A corporate shake-up meant the lab lost significant funding and was spun off to different subsidiaries. LeCun rejoined academia and started a new project at NYU aimed at researching neural networks, frequenting Greenwich Village’s jazz clubs after his lectures.&lt;/p&gt;
&lt;p&gt;By 2013, it was clear that deep learning was going to work, with image recognition applications showing impressive results. Google had just started Google Brain, and a year later would acquire British AI lab DeepMind.&lt;/p&gt;
&lt;p&gt;It was also then that Mark Zuckerberg called. He wanted to start an AI unit at Facebook, and to woo LeCun invited him over for dinner at his California home. A private chef prepared “chicken with some pretty good white wine,” LeCun recalls.&lt;/p&gt;
&lt;p&gt;LeCun agreed to join on three conditions. He wouldn’t have to quit his job at NYU. He wouldn’t move to California. And the research results of the new lab had to be made publicly available.&lt;/p&gt;
&lt;p&gt;Zuckerberg agreed, and the deal was done. LeCun was to join Facebook, one of the biggest technology companies in the world, to set up a new AI research lab focusing on fundamental research, called Facebook Artificial Intelligence Research (Fair).&lt;/p&gt;
&lt;p&gt;Facebook was a “tabula rasa with a carte blanche,” LeCun says. “Money was clearly not going to be a problem.”&lt;/p&gt;
&lt;p&gt;The waitress interrupts us to bring our dessert, bricelets. “&lt;em&gt;Magnifique&lt;/em&gt;,” LeCun says, as the dish is placed in front of him.&lt;/p&gt;
&lt;p&gt;I shift the conversation to a more tumultuous time. In early 2022, pre-ChatGPT, all the major AI labs had some version of the technology kicking around, but it was seen as largely experimental. It was a small, relatively unknown AI lab called OpenAI that kick-started today’s AI mania, when it quietly launched the technology as an easily accessible chatbot.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;We had a lot of new ideas and really cool stuff… But they were just going for things that were safe and proved. When you do this, you fall&amp;nbsp;behind&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;ChatGPT caused a frantic scramble at Meta. The company’s leadership decided to put all their chips into work developing Llama, a large language model. Zuckerberg reshuffled the organization to create a generative AI unit, which was tasked with accelerating research into products. LeCun insisted the model was released openly.&lt;/p&gt;
&lt;p&gt;Llama 2, released with open weights for all users, meaning people could download and tweak it for free, was a “watershed” moment, which “changed the entire industry,” LeCun says. The model became the gold standard in powerful open LLMs, and championed an approach that was counter to the extreme concentration of power that Google and OpenAI were pushing. Meta was seen as the good guys in AI research.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Meta switched gears aggressively&lt;/strong&gt; on AI last year. Zuckerberg placed more pressure on the GenAI unit to accelerate AI development and deployment, which led to a communication breakdown, LeCun says.&lt;/p&gt;
&lt;p&gt;“We had a lot of new ideas and really cool stuff that they should implement. But they were just going for things that were essentially safe and proved,” he says. “When you do this, you fall behind.”&lt;/p&gt;
&lt;p&gt;The subsequent Llama models were duds. Llama 4, which was released in April 2025, was a flop, and the company was accused of gaming benchmarks to make it look more impressive. LeCun admits that the “results were fudged a little bit,” and the team used different models for different benchmarks to give better results.&lt;/p&gt;
&lt;p&gt;“Mark was really upset and basically lost confidence in everyone who was involved in this. And so basically sidelined the entire GenAI organization. A lot of people have left, a lot of people who haven’t yet left will leave.”&lt;/p&gt;
&lt;p&gt;Last June, Meta invested $15 billion in data-labeling start-up Scale AI and hired its 28-year-old chief executive and co-founder Alexandr Wang. Wang took the reins of the company’s new bet on AI and its research unit, called TBD Lab. The lab is tasked with developing new frontier AI models.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta made headlines for trying to poach elite researchers from competitors with offers of $100 million sign-on bonuses. “The future will say whether that was a good idea or not,” LeCun says, deadpan.&lt;/p&gt;
&lt;p&gt;LeCun calls Wang, who was hired to lead the organization, “young” and “inexperienced.”&lt;/p&gt;
&lt;p&gt;“He learns fast, he knows what he doesn’t know… There’s no experience with research or how you practice research, how you do it. Or what would be attractive or repulsive to a researcher.”&lt;/p&gt;
&lt;p&gt;Wang also became LeCun’s manager. I ask LeCun how he felt about this shift in hierarchy. He initially brushes it off, saying he’s used to working with young people. “The average age of a Facebook engineer at the time was 27. I was twice the age of the average engineer.”&lt;/p&gt;
&lt;p&gt;But those 27-year-olds weren’t telling him what to do, I point out.&lt;/p&gt;
&lt;p&gt;“Alex [Wang] isn’t telling me what to do either,” he says. “You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to do.”&lt;/p&gt;
&lt;p&gt;LeCun doesn’t mince his words about why he ultimately decided to leave Meta after more than a decade. Staying became politically difficult, he tells me. And while Zuckerberg likes LeCun’s world model research, the crowd who were hired for the company’s new superintelligence push are “completely LLM-pilled.”&lt;/p&gt;
&lt;blockquote class="ars-pullquote large "&gt;&lt;div class="pullquote-content"&gt;You don’t tell a researcher what to do. You certainly don’t tell a researcher like me what to&amp;nbsp;do&lt;/div&gt;&lt;/blockquote&gt;
&lt;p&gt;This clearly alienated LeCun. “I’m sure there’s a lot of people at Meta, including perhaps Alex, who would like me to not tell the world that LLMs basically are a dead end when it comes to superintelligence,” he says. “But I’m not gonna change my mind because some dude thinks I’m wrong. I’m not wrong. My integrity as a scientist cannot allow me to do this.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Another driver to leave was that his work with world models and AMI was also proving to have potential uses that were not interesting to Meta, such as jet engines and heavy industry. And LeCun had no trouble finding investors who were willing to bet on the next generation of AI technologies.&lt;/p&gt;
&lt;p&gt;In his next chapter, LeCun believes that setting up a “neolab,” meaning a start-up that does fundamental research, is the new, most fertile ground. He cites OpenAI former chief technology officer Mira Murati’s Thinking Machines (“I hope the investors know what they do”) and OpenAI’s co-founder and chief scientist Ilya Sutskever’s Safe Superintelligence (“There I know the investors have no idea what they do”) as good examples.&lt;/p&gt;
&lt;p&gt;His new architecture uses videos to give AI models an understanding of the physics of our world, which will allow them to make better predictions of what will happen next. The model also relies on “emotions,” meaning past experiences and evaluations, to guide its predictions.&lt;/p&gt;
&lt;p&gt;“If I pinch you, you’re going to feel pain. But then your mental model of me is going to be affected by the fact that I just pinched you. And the next time I approach my arm to yours, you’re going to recoil. That’s your prediction, and the emotion it evokes is fear or avoidance of pain,” he says.&lt;/p&gt;
&lt;p&gt;LeCun says we will see “baby” versions of this within 12 months, and on a larger scale within a few years. It’s not quite yet superintelligence, but a path toward it. “Maybe there is an obstacle we’re not seeing yet, but at least there is hope.”&lt;/p&gt;
&lt;p&gt;After three and a half hours, we are now the only customers left in the restaurant. I ask him what he wants his legacy to be.&lt;/p&gt;
&lt;p&gt;Increasing the amount of intelligence in the world, he replies, without batting an eyelid. “Intelligence is really the thing that we should have more of,” he says, adding that with more intelligence, there’s less human suffering, more rational decisions, and more understanding of the world and the universe.&lt;/p&gt;
&lt;p&gt;“We suffer from stupidity.”&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Melissa Heikkilä is the FT’s AI correspondent.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2026 The Financial Times Ltd. All rights reserved. Not to be redistributed, copied, or modified in any way.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/computer-scientist-yann-lecun-intelligence-really-is-about-learning/</guid><pubDate>Wed, 07 Jan 2026 15:06:53 +0000</pubDate></item><item><title>[NEW] Optimism for AI-powered productivity: Deloitte (AI News)</title><link>https://www.artificialintelligence-news.com/news/deloitte-survey-takes-cfo-and-it-temperature-around-technology-and-ai/</link><description>&lt;p&gt;Deloitte’s latest UK CFO Survey presents an improving outlook for large UK businesses, with technology investment – particularly in AI – emerging as a dominant strategy. The survey offers the signal that while macroeconomic and geopolitical risks remain elevated, boards are converging increasingly on digital ability as a primary route to productivity and medium-term growth.&lt;/p&gt;&lt;p&gt;The strongest finding concerns technology investment. An overwhelming 96% of CFOs expect UK companies to increase investment in technology over the next five years, with 77% anticipating improvement to productivity and business performance. The figures are distinctive for a CFO-destined paper, and indicate digital spend is not viewed as discretionary or cyclical, but is treated as structural (akin to capital investment in previous industrial phases). For IT leaders, the paper shows sustained funding is available, but also points out the heightened expectations for delivery, integration, and measurable returns from the technology.&lt;/p&gt;&lt;p&gt;Artificial intelligence sits at the centre of the paper and CFO sentiment in general. The proportion of CFOs becoming ‘more optimistic’ about AI’s ability to improve organisational performance has risen to 59%, up from 39% in Q3 2024. This change isn’t incremental, suggesting AI has crossed from experiment into mainstream financial confidence. Importantly, the survey does not indicate a wholesale rise in risk-taking to accompany the new-found optimism. Risk appetite, while improving, remains subdued at 15%, below the longer average of 25%. This combination – confidence in AI but continued balance-sheet caution – has implications for how AI initiatives are likely to be governed and controlled. Finance functions are likely to need tightly-scoped uses and productivity metrics over open-ended experiments and trials.&lt;/p&gt;&lt;p&gt;For finance professionals, the environment reinforces the role of the CFO as a steward of technology, rather than a passive consumer of IT budgets. The survey positions finance chiefs as shaping digital strategy where AI is concerned. The paper’s emphasis on productivity gains suggests a preference for applications that automate processes and help with financial forecasting, not just customer-facing innovation. IT teams should expect closer scrutiny of business cases presented to them, more involved work from finance professionals, and a translation of technical ability to financial outcomes.&lt;/p&gt;&lt;p&gt;Despite improving sentiment metrics, the survey also highlights some notable constraints. Business confidence remains negative at net -13%, below its long-term average, despite optimism having lifted from lows recorded in earlier iterations of the CFO Survey from Deloitte. Capital expenditure is a priority, but only 17% of CFOs describe it as a ‘strong priority’, only just above the long-term average. This suggests while investment is protected, it’s not immune: Programmes perceived as speculative, poorly governed, or badly aligned with productivity are still unlikely to survive.&lt;/p&gt;&lt;p&gt;External uncertainty, though declining, remains notable. 38% of CFOs still rate their uncertainty in the future as ‘high’ or ‘very high’, and geopolitics still dominates the risk landscape, as cited by 65% of respondents. UK competitiveness and productivity follow closely, with a historically high risk rating of 62. Systems resilience, data security, energy efficiency, and supply-chain visibility are likely to command attention as well as the overall goal of efficiencies created by the use of AI in operations.&lt;/p&gt;&lt;p&gt;A notable subtext of the survey is the human dimension of the technology’s adoption. Deloitte’s leadership realises AI’s value depends on combining technology with human skills and the need to upskill workforces. While this is not quantified in the survey data, it aligns with the broader pattern of cautious optimism: CFOs are willing to invest, but not to assume that technology, as of itself, delivers outcomes. This strengthens the case among IT leaderships for embedding change management, training, governance, and oversight into new digital programmes.&lt;/p&gt;&lt;p&gt;The Deloitte CFO Survey shows a pragmatic and decisive turn towards technology-led productivity in UK businesses. Its evidence is strongest around sustained digital investment and the noteworthy rise in confidence in AI. There’s continued caution on risk and a recognition of a challenging external environment. For Finance professionals, the priority is allocation of capital to initiatives that can improve performance demonstrably. For IT staff, opportunity is expanding, but so is accountability. Digital ambition will be funded in all likelihood, but only where it can be translated into credible, auditable business value.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Deloitte exposure” by zilverbat. is licensed under CC BY-NC 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Deloitte’s latest UK CFO Survey presents an improving outlook for large UK businesses, with technology investment – particularly in AI – emerging as a dominant strategy. The survey offers the signal that while macroeconomic and geopolitical risks remain elevated, boards are converging increasingly on digital ability as a primary route to productivity and medium-term growth.&lt;/p&gt;&lt;p&gt;The strongest finding concerns technology investment. An overwhelming 96% of CFOs expect UK companies to increase investment in technology over the next five years, with 77% anticipating improvement to productivity and business performance. The figures are distinctive for a CFO-destined paper, and indicate digital spend is not viewed as discretionary or cyclical, but is treated as structural (akin to capital investment in previous industrial phases). For IT leaders, the paper shows sustained funding is available, but also points out the heightened expectations for delivery, integration, and measurable returns from the technology.&lt;/p&gt;&lt;p&gt;Artificial intelligence sits at the centre of the paper and CFO sentiment in general. The proportion of CFOs becoming ‘more optimistic’ about AI’s ability to improve organisational performance has risen to 59%, up from 39% in Q3 2024. This change isn’t incremental, suggesting AI has crossed from experiment into mainstream financial confidence. Importantly, the survey does not indicate a wholesale rise in risk-taking to accompany the new-found optimism. Risk appetite, while improving, remains subdued at 15%, below the longer average of 25%. This combination – confidence in AI but continued balance-sheet caution – has implications for how AI initiatives are likely to be governed and controlled. Finance functions are likely to need tightly-scoped uses and productivity metrics over open-ended experiments and trials.&lt;/p&gt;&lt;p&gt;For finance professionals, the environment reinforces the role of the CFO as a steward of technology, rather than a passive consumer of IT budgets. The survey positions finance chiefs as shaping digital strategy where AI is concerned. The paper’s emphasis on productivity gains suggests a preference for applications that automate processes and help with financial forecasting, not just customer-facing innovation. IT teams should expect closer scrutiny of business cases presented to them, more involved work from finance professionals, and a translation of technical ability to financial outcomes.&lt;/p&gt;&lt;p&gt;Despite improving sentiment metrics, the survey also highlights some notable constraints. Business confidence remains negative at net -13%, below its long-term average, despite optimism having lifted from lows recorded in earlier iterations of the CFO Survey from Deloitte. Capital expenditure is a priority, but only 17% of CFOs describe it as a ‘strong priority’, only just above the long-term average. This suggests while investment is protected, it’s not immune: Programmes perceived as speculative, poorly governed, or badly aligned with productivity are still unlikely to survive.&lt;/p&gt;&lt;p&gt;External uncertainty, though declining, remains notable. 38% of CFOs still rate their uncertainty in the future as ‘high’ or ‘very high’, and geopolitics still dominates the risk landscape, as cited by 65% of respondents. UK competitiveness and productivity follow closely, with a historically high risk rating of 62. Systems resilience, data security, energy efficiency, and supply-chain visibility are likely to command attention as well as the overall goal of efficiencies created by the use of AI in operations.&lt;/p&gt;&lt;p&gt;A notable subtext of the survey is the human dimension of the technology’s adoption. Deloitte’s leadership realises AI’s value depends on combining technology with human skills and the need to upskill workforces. While this is not quantified in the survey data, it aligns with the broader pattern of cautious optimism: CFOs are willing to invest, but not to assume that technology, as of itself, delivers outcomes. This strengthens the case among IT leaderships for embedding change management, training, governance, and oversight into new digital programmes.&lt;/p&gt;&lt;p&gt;The Deloitte CFO Survey shows a pragmatic and decisive turn towards technology-led productivity in UK businesses. Its evidence is strongest around sustained digital investment and the noteworthy rise in confidence in AI. There’s continued caution on risk and a recognition of a challenging external environment. For Finance professionals, the priority is allocation of capital to initiatives that can improve performance demonstrably. For IT staff, opportunity is expanding, but so is accountability. Digital ambition will be funded in all likelihood, but only where it can be translated into credible, auditable business value.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image source: “Deloitte exposure” by zilverbat. is licensed under CC BY-NC 2.0.)&lt;/em&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/deloitte-survey-takes-cfo-and-it-temperature-around-technology-and-ai/</guid><pubDate>Wed, 07 Jan 2026 15:59:47 +0000</pubDate></item><item><title>[NEW] Caterpillar taps Nvidia to bring AI to its construction equipment (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/caterpillar-taps-nvidia-to-bring-ai-to-its-construction-equipment/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ces-caterpillar.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Caterpillar is diving deeper into incorporating AI and automation into its fleet of construction machinery through a partnership with semiconductor giant Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The construction equipment giant is piloting an AI assistive system in its mid-size Cat 306 CR Mini Excavator. Dubbed “Cat AI,” the system was built using Nvidia’s Jetson Thor physical AI platform, and is being demoed at CES on Wednesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Brandon Hootman, vice president of data and AI at Caterpillar, told TechCrunch that Cat AI was built on a fleet of AI agents and can help answer a machine operator’s questions, allow them to access resources, offer safety tips, and schedule services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the biggest benefits of bringing this tech into these machines is the data that these systems collect and send back out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our customers don’t live in front of a laptop day in and day out; they live in the dirt,” Hootman said. “The ability to get the insights and take the action that they need while they’re doing the work is very important to them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Caterpillar is also piloting digital twins of construction sites using Nvidia’s Omniverse library of simulation resources to test scheduling scenarios and better calculate how much building material a project will need. Hootman said Caterpillar’s machines send roughly 2,000 messages back to the company every second. This data will help them build these simulations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company already has fully autonomous vehicles in the mining sector, and Hootman said that these pilot programs are a great next step as the company looks to bring more automation to its portfolio.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason that we started here was it was a real challenge of our our customers today that needed to be addressed, and also something that we had some some real momentum on and we felt like we could we could bring to market pretty quickly,” Hootman said. “What we also liked is that provided a kind of a technology&amp;nbsp;foundation&amp;nbsp;for us to then build upon.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Working with companies like Caterpillar — a legacy brand that doesn’t often intertwine with the tech industry — seems to fit right into Nvidia’s physical AI strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bill Dally, Nvidia’s chief scientist, told TechCrunch in 2025 that the chipmaker considers physical AI to be the next frontier for the company and its powerful GPUs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During its CES keynote on Monday, Nvidia laid out plans for its full-stack ecosystem for physical AI, which includes open AI models like the company’s Cosmos model family, simulation tools, and developer kits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some may think physical AI is just for robotics companies, Deepu Talla, the vice president of robotics and edge AI at Nvidia, told TechCrunch the company takes a much broader definition as everyone is building robotics today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Physical AI is the next wave of AI,” Talla said. “Nvidia is pioneering that with computers that train the models, that do the simulation to test the models and deploy the models into the robots, whether [that’s] an autonomous car or a Caterpillar machine.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s CES coverage here. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/ces-caterpillar.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Caterpillar is diving deeper into incorporating AI and automation into its fleet of construction machinery through a partnership with semiconductor giant Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The construction equipment giant is piloting an AI assistive system in its mid-size Cat 306 CR Mini Excavator. Dubbed “Cat AI,” the system was built using Nvidia’s Jetson Thor physical AI platform, and is being demoed at CES on Wednesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Brandon Hootman, vice president of data and AI at Caterpillar, told TechCrunch that Cat AI was built on a fleet of AI agents and can help answer a machine operator’s questions, allow them to access resources, offer safety tips, and schedule services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One of the biggest benefits of bringing this tech into these machines is the data that these systems collect and send back out.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our customers don’t live in front of a laptop day in and day out; they live in the dirt,” Hootman said. “The ability to get the insights and take the action that they need while they’re doing the work is very important to them.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Caterpillar is also piloting digital twins of construction sites using Nvidia’s Omniverse library of simulation resources to test scheduling scenarios and better calculate how much building material a project will need. Hootman said Caterpillar’s machines send roughly 2,000 messages back to the company every second. This data will help them build these simulations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company already has fully autonomous vehicles in the mining sector, and Hootman said that these pilot programs are a great next step as the company looks to bring more automation to its portfolio.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“The reason that we started here was it was a real challenge of our our customers today that needed to be addressed, and also something that we had some some real momentum on and we felt like we could we could bring to market pretty quickly,” Hootman said. “What we also liked is that provided a kind of a technology&amp;nbsp;foundation&amp;nbsp;for us to then build upon.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Working with companies like Caterpillar — a legacy brand that doesn’t often intertwine with the tech industry — seems to fit right into Nvidia’s physical AI strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bill Dally, Nvidia’s chief scientist, told TechCrunch in 2025 that the chipmaker considers physical AI to be the next frontier for the company and its powerful GPUs.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;During its CES keynote on Monday, Nvidia laid out plans for its full-stack ecosystem for physical AI, which includes open AI models like the company’s Cosmos model family, simulation tools, and developer kits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some may think physical AI is just for robotics companies, Deepu Talla, the vice president of robotics and edge AI at Nvidia, told TechCrunch the company takes a much broader definition as everyone is building robotics today.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Physical AI is the next wave of AI,” Talla said. “Nvidia is pioneering that with computers that train the models, that do the simulation to test the models and deploy the models into the robots, whether [that’s] an autonomous car or a Caterpillar machine.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Follow along with all of TechCrunch’s CES coverage here. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/caterpillar-taps-nvidia-to-bring-ai-to-its-construction-equipment/</guid><pubDate>Wed, 07 Jan 2026 17:00:00 +0000</pubDate></item><item><title>[NEW] Agentic AI scaling requires new memory architecture (AI News)</title><link>https://www.artificialintelligence-news.com/news/agentic-ai-scaling-requires-new-memory-architecture/</link><description>&lt;p&gt;Agentic AI represents a distinct evolution from stateless chatbots toward complex workflows, and scaling it requires new memory architecture.&lt;/p&gt;&lt;p&gt;As foundation models scale toward trillions of parameters and context windows reach millions of tokens, the computational cost of remembering history is rising faster than the ability to process it.&lt;/p&gt;&lt;p&gt;Organisations deploying these systems now face a bottleneck where the sheer volume of “long-term memory” (technically known as Key-Value (KV) cache) overwhelms existing hardware architectures.&lt;/p&gt;&lt;p&gt;Current infrastructure forces a binary choice: store inference context in scarce, high-bandwidth GPU memory (HBM) or relegate it to slow, general-purpose storage. The former is prohibitively expensive for large contexts; the latter creates latency that renders real-time agentic interactions unviable.&lt;/p&gt;&lt;p&gt;To address this widening disparity that is holding back the scaling of agentic AI, NVIDIA has introduced the Inference Context Memory Storage (ICMS) platform within its Rubin architecture, proposing a new storage tier designed specifically to handle the ephemeral and high-velocity nature of AI memory.&lt;/p&gt;&lt;p&gt;“AI is revolutionising the entire computing stack—and now, storage,” Huang said. “AI is no longer about one-shot chatbots but intelligent collaborators that understand the physical world, reason over long horizons, stay grounded in facts, use tools to do real work, and retain both short- and long-term memory.”&lt;/p&gt;&lt;p&gt;The operational challenge lies in the specific behaviour of transformer-based models. To avoid recomputing an entire conversation history for every new word generated, models store previous states in the KV cache. In agentic workflows, this cache acts as persistent memory across tools and sessions, growing linearly with sequence length.&lt;/p&gt;&lt;p&gt;This creates a distinct data class. Unlike financial records or customer logs, KV cache is derived data; it is essential for immediate performance but does not require the heavy durability guarantees of enterprise file systems. General-purpose storage stacks, running on standard CPUs, expend energy on metadata management and replication that agentic workloads do not require.&lt;/p&gt;&lt;p&gt;The current hierarchy, spanning from GPU HBM (G1) to shared storage (G4), is becoming inefficient:&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111516" height="396" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-1-1024x396.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;(Credit: NVIDIA)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As context spills from the GPU (G1) to system RAM (G2) and eventually to shared storage (G4), efficiency plummets. Moving active context to the G4 tier introduces millisecond-level latency and increases the power cost per token, leaving expensive GPUs idle while they await data.&lt;/p&gt;&lt;p&gt;For the enterprise, this manifests as a bloated Total Cost of Ownership (TCO), where power is wasted on infrastructure overhead rather than active reasoning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-new-memory-tier-for-the-ai-factory"&gt;A new memory tier for the AI factory&lt;/h3&gt;&lt;p&gt;The industry response involves inserting a purpose-built layer into this hierarchy. The ICMS platform establishes a “G3.5” tier—an Ethernet-attached flash layer designed explicitly for gigascale inference.&lt;/p&gt;&lt;p&gt;This approach integrates storage directly into the compute pod. By utilising the NVIDIA BlueField-4 data processor, the platform offloads the management of this context data from the host CPU. The system provides petabytes of shared capacity per pod, boosting the scaling of agentic AI by allowing agents to retain massive amounts of history without occupying expensive HBM.&lt;/p&gt;&lt;p&gt;The operational benefit is quantifiable in throughput and energy. By keeping relevant context in this intermediate tier – which is faster than standard storage, but cheaper than HBM – the system can “prestage” memory back to the GPU before it is needed. This reduces the idle time of the GPU decoder, enabling up to 5x higher tokens-per-second (TPS) for long-context workloads.&lt;/p&gt;&lt;p&gt;From an energy perspective, the implications are equally measurable. Because the architecture removes the overhead of general-purpose storage protocols, it delivers 5x better power efficiency than traditional methods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-integrating-the-data-plane"&gt;Integrating the data plane&lt;/h3&gt;&lt;p&gt;Implementing this architecture requires a change in how IT teams view storage networking. The ICMS platform relies on NVIDIA Spectrum-X Ethernet to provide the high-bandwidth, low-jitter connectivity required to treat flash storage almost as if it were local memory.&lt;/p&gt;&lt;p&gt;For enterprise infrastructure teams, the integration point is the orchestration layer. Frameworks such as NVIDIA Dynamo and the Inference Transfer Library (NIXL) manage the movement of KV blocks between tiers.&lt;/p&gt;&lt;p&gt;These tools coordinate with the storage layer to ensure that the correct context is loaded into the GPU memory (G1) or host memory (G2) exactly when the AI model requires it. The NVIDIA DOCA framework further supports this by providing a KV communication layer that treats context cache as a first-class resource.&lt;/p&gt;&lt;p&gt;Major storage vendors are already aligning with this architecture. Companies including AIC, Cloudian, DDN, Dell Technologies, HPE, Hitachi Vantara, IBM, Nutanix, Pure Storage, Supermicro, VAST Data, and WEKA are building platforms with BlueField-4. These solutions are expected to be available in the second half of this year.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-redefining-infrastructure-for-scaling-agentic-ai"&gt;Redefining infrastructure for scaling agentic AI&lt;/h3&gt;&lt;p&gt;Adopting a dedicated context memory tier impacts capacity planning and datacentre design.&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Reclassifying data:&lt;/strong&gt; CIOs must recognise KV cache as a unique data type. It is “ephemeral but latency-sensitive,” distinct from “durable and cold” compliance data. The G3.5 tier handles the former, allowing durable G4 storage to focus on long-term logs and artifacts.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Orchestration maturity:&lt;/strong&gt; Success depends on software that can intelligently place workloads. The system uses topology-aware orchestration (via NVIDIA Grove) to place jobs near their cached context, minimising data movement across the fabric.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Power density:&lt;/strong&gt; By fitting more usable capacity into the same rack footprint, organisations can extend the life of existing facilities. However, this increases the density of compute per square metre, requiring adequate cooling and power distribution planning.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The transition to agentic AI forces a physical reconfiguration of the datacentre. The prevailing model of separating compute completely from slow, persistent storage is incompatible with the real-time retrieval needs of agents with photographic memories.&lt;/p&gt;&lt;p&gt;By introducing a specialised context tier, enterprises can decouple the growth of model memory from the cost of GPU HBM. This architecture for agentic AI allows multiple agents to share a massive low-power memory pool to reduce the cost of serving complex queries and boosts scaling by enabling high-throughput reasoning.&lt;/p&gt;&lt;p&gt;As organisations plan their next cycle of infrastructure investment, evaluating the efficiency of the memory hierarchy will be as vital as selecting the GPU itself.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;2025’s AI chip wars: What enterprise leaders learned about supply chain reality&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111183" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Agentic AI represents a distinct evolution from stateless chatbots toward complex workflows, and scaling it requires new memory architecture.&lt;/p&gt;&lt;p&gt;As foundation models scale toward trillions of parameters and context windows reach millions of tokens, the computational cost of remembering history is rising faster than the ability to process it.&lt;/p&gt;&lt;p&gt;Organisations deploying these systems now face a bottleneck where the sheer volume of “long-term memory” (technically known as Key-Value (KV) cache) overwhelms existing hardware architectures.&lt;/p&gt;&lt;p&gt;Current infrastructure forces a binary choice: store inference context in scarce, high-bandwidth GPU memory (HBM) or relegate it to slow, general-purpose storage. The former is prohibitively expensive for large contexts; the latter creates latency that renders real-time agentic interactions unviable.&lt;/p&gt;&lt;p&gt;To address this widening disparity that is holding back the scaling of agentic AI, NVIDIA has introduced the Inference Context Memory Storage (ICMS) platform within its Rubin architecture, proposing a new storage tier designed specifically to handle the ephemeral and high-velocity nature of AI memory.&lt;/p&gt;&lt;p&gt;“AI is revolutionising the entire computing stack—and now, storage,” Huang said. “AI is no longer about one-shot chatbots but intelligent collaborators that understand the physical world, reason over long horizons, stay grounded in facts, use tools to do real work, and retain both short- and long-term memory.”&lt;/p&gt;&lt;p&gt;The operational challenge lies in the specific behaviour of transformer-based models. To avoid recomputing an entire conversation history for every new word generated, models store previous states in the KV cache. In agentic workflows, this cache acts as persistent memory across tools and sessions, growing linearly with sequence length.&lt;/p&gt;&lt;p&gt;This creates a distinct data class. Unlike financial records or customer logs, KV cache is derived data; it is essential for immediate performance but does not require the heavy durability guarantees of enterprise file systems. General-purpose storage stacks, running on standard CPUs, expend energy on metadata management and replication that agentic workloads do not require.&lt;/p&gt;&lt;p&gt;The current hierarchy, spanning from GPU HBM (G1) to shared storage (G4), is becoming inefficient:&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111516" height="396" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-1-1024x396.png" width="1024" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;(Credit: NVIDIA)&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;As context spills from the GPU (G1) to system RAM (G2) and eventually to shared storage (G4), efficiency plummets. Moving active context to the G4 tier introduces millisecond-level latency and increases the power cost per token, leaving expensive GPUs idle while they await data.&lt;/p&gt;&lt;p&gt;For the enterprise, this manifests as a bloated Total Cost of Ownership (TCO), where power is wasted on infrastructure overhead rather than active reasoning.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-new-memory-tier-for-the-ai-factory"&gt;A new memory tier for the AI factory&lt;/h3&gt;&lt;p&gt;The industry response involves inserting a purpose-built layer into this hierarchy. The ICMS platform establishes a “G3.5” tier—an Ethernet-attached flash layer designed explicitly for gigascale inference.&lt;/p&gt;&lt;p&gt;This approach integrates storage directly into the compute pod. By utilising the NVIDIA BlueField-4 data processor, the platform offloads the management of this context data from the host CPU. The system provides petabytes of shared capacity per pod, boosting the scaling of agentic AI by allowing agents to retain massive amounts of history without occupying expensive HBM.&lt;/p&gt;&lt;p&gt;The operational benefit is quantifiable in throughput and energy. By keeping relevant context in this intermediate tier – which is faster than standard storage, but cheaper than HBM – the system can “prestage” memory back to the GPU before it is needed. This reduces the idle time of the GPU decoder, enabling up to 5x higher tokens-per-second (TPS) for long-context workloads.&lt;/p&gt;&lt;p&gt;From an energy perspective, the implications are equally measurable. Because the architecture removes the overhead of general-purpose storage protocols, it delivers 5x better power efficiency than traditional methods.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-integrating-the-data-plane"&gt;Integrating the data plane&lt;/h3&gt;&lt;p&gt;Implementing this architecture requires a change in how IT teams view storage networking. The ICMS platform relies on NVIDIA Spectrum-X Ethernet to provide the high-bandwidth, low-jitter connectivity required to treat flash storage almost as if it were local memory.&lt;/p&gt;&lt;p&gt;For enterprise infrastructure teams, the integration point is the orchestration layer. Frameworks such as NVIDIA Dynamo and the Inference Transfer Library (NIXL) manage the movement of KV blocks between tiers.&lt;/p&gt;&lt;p&gt;These tools coordinate with the storage layer to ensure that the correct context is loaded into the GPU memory (G1) or host memory (G2) exactly when the AI model requires it. The NVIDIA DOCA framework further supports this by providing a KV communication layer that treats context cache as a first-class resource.&lt;/p&gt;&lt;p&gt;Major storage vendors are already aligning with this architecture. Companies including AIC, Cloudian, DDN, Dell Technologies, HPE, Hitachi Vantara, IBM, Nutanix, Pure Storage, Supermicro, VAST Data, and WEKA are building platforms with BlueField-4. These solutions are expected to be available in the second half of this year.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-redefining-infrastructure-for-scaling-agentic-ai"&gt;Redefining infrastructure for scaling agentic AI&lt;/h3&gt;&lt;p&gt;Adopting a dedicated context memory tier impacts capacity planning and datacentre design.&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Reclassifying data:&lt;/strong&gt; CIOs must recognise KV cache as a unique data type. It is “ephemeral but latency-sensitive,” distinct from “durable and cold” compliance data. The G3.5 tier handles the former, allowing durable G4 storage to focus on long-term logs and artifacts.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Orchestration maturity:&lt;/strong&gt; Success depends on software that can intelligently place workloads. The system uses topology-aware orchestration (via NVIDIA Grove) to place jobs near their cached context, minimising data movement across the fabric.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;&lt;strong&gt;Power density:&lt;/strong&gt; By fitting more usable capacity into the same rack footprint, organisations can extend the life of existing facilities. However, this increases the density of compute per square metre, requiring adequate cooling and power distribution planning.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The transition to agentic AI forces a physical reconfiguration of the datacentre. The prevailing model of separating compute completely from slow, persistent storage is incompatible with the real-time retrieval needs of agents with photographic memories.&lt;/p&gt;&lt;p&gt;By introducing a specialised context tier, enterprises can decouple the growth of model memory from the cost of GPU HBM. This architecture for agentic AI allows multiple agents to share a massive low-power memory pool to reduce the cost of serving complex queries and boosts scaling by enabling high-throughput reasoning.&lt;/p&gt;&lt;p&gt;As organisations plan their next cycle of infrastructure investment, evaluating the efficiency of the memory hierarchy will be as vital as selecting the GPU itself.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;2025’s AI chip wars: What enterprise leaders learned about supply chain reality&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111183" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/agentic-ai-scaling-requires-new-memory-architecture/</guid><pubDate>Wed, 07 Jan 2026 17:13:19 +0000</pubDate></item><item><title>[NEW] Google Classroom’s new tool uses Gemini to transform lessons into podcast episodes (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/google-classrooms-new-tool-uses-gemini-to-transform-lessons-into-podcast-episodes/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/05/usb-microphones-fullres-0663_preview.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has introduced a new way to grab the attention of students who are avid podcast listeners. Now available in Google Classroom, teachers can use a new Gemini-powered tool that generates podcast-style audio lessons, meant to promote deeper comprehension of educational material.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To begin, educators simply go to the Gemini tab within Google Classroom. There, they can select different customization options, such as selecting the appropriate grade level, defining topics, and setting clear learning objectives. They can then further personalize the audio experience by choosing the number of speakers or selecting different conversational styles, such as interviews, roundtable discussions, or casual dialogues.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This new feature is currently available to users subscribed to Google Workspace Education Fundamentals, Standard, and Plus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing this familiar format into the classroom, teachers can tap into their students’ interests. Research shows that students spend significant time listening to podcasts, with an estimated 35 million Gen Z monthly listeners in the U.S.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, the popularity of podcasts as educational resources has grown rapidly; many universities now produce their own podcasts, and students increasingly seek out popular educational series on their own time. Podcast-style lessons might also encourage independent learning, since students can replay episodes whenever they need a refresher or missed a class.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, teachers are still grappling with integrating AI tools into their teaching practices. Many teachers express concerns about students’ increased reliance on generative AI tools, such as ChatGPT, to complete assignments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google urges teachers to practice responsible AI and carefully review and, if necessary, edit all AI-generated content to ensure accuracy and appropriateness for their specific classroom context and local policies.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini for Classroom first launched in 2024, and Google has continually added new features since then. Most recently, the company rolled out major updates last June, including features that help teachers brainstorm, develop lesson plans, and customize instructional materials for their students.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/05/usb-microphones-fullres-0663_preview.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google has introduced a new way to grab the attention of students who are avid podcast listeners. Now available in Google Classroom, teachers can use a new Gemini-powered tool that generates podcast-style audio lessons, meant to promote deeper comprehension of educational material.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To begin, educators simply go to the Gemini tab within Google Classroom. There, they can select different customization options, such as selecting the appropriate grade level, defining topics, and setting clear learning objectives. They can then further personalize the audio experience by choosing the number of speakers or selecting different conversational styles, such as interviews, roundtable discussions, or casual dialogues.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This new feature is currently available to users subscribed to Google Workspace Education Fundamentals, Standard, and Plus.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By bringing this familiar format into the classroom, teachers can tap into their students’ interests. Research shows that students spend significant time listening to podcasts, with an estimated 35 million Gen Z monthly listeners in the U.S.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, the popularity of podcasts as educational resources has grown rapidly; many universities now produce their own podcasts, and students increasingly seek out popular educational series on their own time. Podcast-style lessons might also encourage independent learning, since students can replay episodes whenever they need a refresher or missed a class.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, teachers are still grappling with integrating AI tools into their teaching practices. Many teachers express concerns about students’ increased reliance on generative AI tools, such as ChatGPT, to complete assignments.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google urges teachers to practice responsible AI and carefully review and, if necessary, edit all AI-generated content to ensure accuracy and appropriateness for their specific classroom context and local policies.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini for Classroom first launched in 2024, and Google has continually added new features since then. Most recently, the company rolled out major updates last June, including features that help teachers brainstorm, develop lesson plans, and customize instructional materials for their students.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/google-classrooms-new-tool-uses-gemini-to-transform-lessons-into-podcast-episodes/</guid><pubDate>Wed, 07 Jan 2026 17:55:35 +0000</pubDate></item><item><title>[NEW] Skylight debuts Calendar 2 to keep your family organized (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/skylight-debuts-calendar-2-to-keep-your-family-organized/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Skylight may have started as a digital picture frame, but today, the company is more focused on helping families stay organized with shared calendars, lists, meal planning tools and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At CES 2026, the company debuted its latest product: the Skylight Calendar 2, which offers a sleeker design than the original 15-inch calendar, but smaller than the 27-inch wall-mounted Calendar Max. Like its larger counterpart, the new digital calendar app and family organizer also lets you swap out the frame for different colors to better match your home’s decor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The biggest selling point isn’t the digital screen itself, but the underlying software and AI capabilities. The primary feature — the calendar — is actually a mashup of all your family’s calendars from whatever services you use, whether that’s Google Calendar, iCal, Microsoft, or even your kids’ sports apps, like TeamSnap&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The calendar is color-coded to see everyone’s schedules with a glance, and can even import “calendars” that are really just emails with a few key dates or flyers sent home in junior’s backpack. (The latter is an AI feature where you snap a photo of the paper and the calendar updates with the new events).&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image credits: sarah perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also trying to address other pain points for families such as managing grocery lists, reminders for appointments, meal planning, and recipe discovery. Of course, it can still display your family photos’ too, when otherwise not in use. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is well-designed to be easy to read with simple navigation, pops of color, and even imagery that makes it possible for little kids to use. For instance, they can check off their chores by looking for a picture, even if they can’t yet read. Parents also like the ability to plan meals, whether that’s noting simply that Tuesday will be taco night, or going as far as finding a recipe and preparing a shopping list. Skylight’s helpful here too, as it can automatically create the shopping list of ingredients for you or even add it to your Instacart app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another clever AI feature lets you snap a photo of what’s in your fridge and get a recipe recommendation based on what you have on hand.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The need for such a system is clearly resonating with customers. Skylight, a bootstrapped and profitable company from day one, now has 1.3 million-plus families using its digital calendars so far, and likely more to come as the new design ships.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Skylight may have started as a digital picture frame, but today, the company is more focused on helping families stay organized with shared calendars, lists, meal planning tools and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At CES 2026, the company debuted its latest product: the Skylight Calendar 2, which offers a sleeker design than the original 15-inch calendar, but smaller than the 27-inch wall-mounted Calendar Max. Like its larger counterpart, the new digital calendar app and family organizer also lets you swap out the frame for different colors to better match your home’s decor.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The biggest selling point isn’t the digital screen itself, but the underlying software and AI capabilities. The primary feature — the calendar — is actually a mashup of all your family’s calendars from whatever services you use, whether that’s Google Calendar, iCal, Microsoft, or even your kids’ sports apps, like TeamSnap&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The calendar is color-coded to see everyone’s schedules with a glance, and can even import “calendars” that are really just emails with a few key dates or flyers sent home in junior’s backpack. (The latter is an AI feature where you snap a photo of the paper and the calendar updates with the new events).&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3080785" height="510" src="https://techcrunch.com/wp-content/uploads/2026/01/skylight-calendar-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Image credits: sarah perez&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also trying to address other pain points for families such as managing grocery lists, reminders for appointments, meal planning, and recipe discovery. Of course, it can still display your family photos’ too, when otherwise not in use. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app is well-designed to be easy to read with simple navigation, pops of color, and even imagery that makes it possible for little kids to use. For instance, they can check off their chores by looking for a picture, even if they can’t yet read. Parents also like the ability to plan meals, whether that’s noting simply that Tuesday will be taco night, or going as far as finding a recipe and preparing a shopping list. Skylight’s helpful here too, as it can automatically create the shopping list of ingredients for you or even add it to your Instacart app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another clever AI feature lets you snap a photo of what’s in your fridge and get a recipe recommendation based on what you have on hand.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The need for such a system is clearly resonating with customers. Skylight, a bootstrapped and profitable company from day one, now has 1.3 million-plus families using its digital calendars so far, and likely more to come as the new design ships.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/skylight-debuts-calendar-2-to-keep-your-family-organized/</guid><pubDate>Wed, 07 Jan 2026 18:00:00 +0000</pubDate></item><item><title>[NEW] VC predicts the consumer AI products OpenAI ‘won’t want to kill’ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/investing-in-the-consumer-ai-products-openai-wont-want-to-kill/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/230829_NEA_MenloPark_VanessaLarco_0087-e1718215170281.jpg?resize=926,1200" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vanessa Larco,&amp;nbsp;partner at&amp;nbsp;Premise&amp;nbsp;and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco,&amp;nbsp;who’s&amp;nbsp;been investing in consumer and&amp;nbsp;prosumer&amp;nbsp;for years, thinks&amp;nbsp;we’re&amp;nbsp;about to see&amp;nbsp;a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps,&amp;nbsp;or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for&amp;nbsp;themselves?&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s&amp;nbsp;Equity&amp;nbsp;podcast, Rebecca Bellan sat down with Larco to talk about why consumer is back, what OpenAI&amp;nbsp;&lt;em&gt;won’t&lt;/em&gt;&amp;nbsp;kill, and where the real opportunities are hiding.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why Larco thinks OpenAI&amp;nbsp;won’t&amp;nbsp;build marketplace businesses that require managing real humans.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Larco’s take on “disposable software” and why AI apps “should be treated like Word docs.”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How Meta Ray-Ban smart glasses turned Larco into a believer in voice interfaces (and why she thinks screens are optional for most tasks).&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;More predictions for 2026, including another huge year for M&amp;amp;A.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What new business models stablecoins could&amp;nbsp;unlock.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/230829_NEA_MenloPark_VanessaLarco_0087-e1718215170281.jpg?resize=926,1200" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vanessa Larco,&amp;nbsp;partner at&amp;nbsp;Premise&amp;nbsp;and former partner at NEA, thinks 2026 will finally be the year of consumer AI.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Larco,&amp;nbsp;who’s&amp;nbsp;been investing in consumer and&amp;nbsp;prosumer&amp;nbsp;for years, thinks&amp;nbsp;we’re&amp;nbsp;about to see&amp;nbsp;a shift in how consumers spend time online, with AI powering “concierge-like” services. The question is, will legacy consumer products like WebMD and TripAdvisor continue to exist as standalone apps,&amp;nbsp;or will they just get absorbed into ChatGPT or Meta AI? And where can startups carve out an AI-powered niche for&amp;nbsp;themselves?&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s&amp;nbsp;Equity&amp;nbsp;podcast, Rebecca Bellan sat down with Larco to talk about why consumer is back, what OpenAI&amp;nbsp;&lt;em&gt;won’t&lt;/em&gt;&amp;nbsp;kill, and where the real opportunities are hiding.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why Larco thinks OpenAI&amp;nbsp;won’t&amp;nbsp;build marketplace businesses that require managing real humans.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Larco’s take on “disposable software” and why AI apps “should be treated like Word docs.”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How Meta Ray-Ban smart glasses turned Larco into a believer in voice interfaces (and why she thinks screens are optional for most tasks).&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;More predictions for 2026, including another huge year for M&amp;amp;A.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;What new business models stablecoins could&amp;nbsp;unlock.&amp;nbsp;&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/investing-in-the-consumer-ai-products-openai-wont-want-to-kill/</guid><pubDate>Wed, 07 Jan 2026 18:15:00 +0000</pubDate></item><item><title>[NEW] Anthropic reportedly raising $10B at $350B valuation (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/07/anthropic-reportedly-raising-10b-at-350b-valuation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is gearing up to raise a fresh $10 billion at a $350 billion valuation, according to The Wall Street Journal.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Claude-maker last raised a $13 billion Series F round at a $183 billion valuation three months ago, so this raise nearly doubles the AI firm’s value. In March, Anthropic secured $3.5 billion at a $61.5 billion valuation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Coatue Management and GIC, Singapore’s sovereign wealth fund, will lead the new round, per the WSJ, which cited sources familiar with the matter. Anthropic is expected to close its latest financing in the coming weeks, and the total deal amount could change.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This round would be separate to the $15 billion Nvidia and Microsoft recently committed to invest in Anthropic, a “circular” deal that would see Anthropic buying $30 billion of compute capacity from Microsoft Azure running on Nvidia’s chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh capital comes as Anthropic continues to win over developer hearts with Claude Code, its tool designed to automate coding, powered by Claude Opus 4.5. It also comes as Anthropic prepares for a potential IPO this year alongside its main rival OpenAI. OpenAI is also in talks to raise as much as $100 billion at a $750 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Anthropic for comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic is gearing up to raise a fresh $10 billion at a $350 billion valuation, according to The Wall Street Journal.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Claude-maker last raised a $13 billion Series F round at a $183 billion valuation three months ago, so this raise nearly doubles the AI firm’s value. In March, Anthropic secured $3.5 billion at a $61.5 billion valuation.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Coatue Management and GIC, Singapore’s sovereign wealth fund, will lead the new round, per the WSJ, which cited sources familiar with the matter. Anthropic is expected to close its latest financing in the coming weeks, and the total deal amount could change.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This round would be separate to the $15 billion Nvidia and Microsoft recently committed to invest in Anthropic, a “circular” deal that would see Anthropic buying $30 billion of compute capacity from Microsoft Azure running on Nvidia’s chips.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The fresh capital comes as Anthropic continues to win over developer hearts with Claude Code, its tool designed to automate coding, powered by Claude Opus 4.5. It also comes as Anthropic prepares for a potential IPO this year alongside its main rival OpenAI. OpenAI is also in talks to raise as much as $100 billion at a $750 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Anthropic for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/07/anthropic-reportedly-raising-10b-at-350b-valuation/</guid><pubDate>Wed, 07 Jan 2026 18:36:53 +0000</pubDate></item></channel></rss>