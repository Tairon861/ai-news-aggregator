<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 14 Nov 2025 12:45:34 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>[NEW] Visa builds AI commerce infrastructure for the Asia Pacific’s 2026 Pilot (AI News)</title><link>https://www.artificialintelligence-news.com/news/visa-ai-commerce-intelligent-commerce-2026/</link><description>&lt;p&gt;When Visa&amp;nbsp;unveiled&amp;nbsp;its Intelligent Commerce platform for Asia Pacific on November 12, it wasn’t just launching another payment feature—it was building AI commerce infrastructure to solve a crisis most merchants haven’t noticed yet: their websites are&amp;nbsp;being flooded&amp;nbsp;by AI agents, and there’s no reliable way to tell which ones are legitimate shoppers and which are malicious bots.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With AI-driven traffic to retail sites exploding by 4,700% in just one year, Visa’s early 2026 regional pilots give businesses 14 months to prepare their payment systems for a world where artificial intelligence handles shopping and transactions on behalf of consumers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-asia-pacific-why-now"&gt;Why Asia Pacific, why now&lt;/h3&gt;&lt;p&gt;Visa’s strategic decision to pilot its agentic commerce capabilities in Asia Pacific by early 2026 reflects more than a geographic preference—it acknowledges the region’s leadership in mobile payments adoption and digital-first consumer behaviour.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Deploying the AI commerce infrastructure represents a fundamental architectural shift: payment systems designed from the ground up to accommodate machine-initiated transactions at speeds and volumes beyond what human shoppers can handle.&lt;/p&gt;&lt;p&gt;“Agentic commerce is transforming the very fabric of online payment transactions, requiring a unified ecosystem to unlock its full potential,” said T.R. Ramachandran, head of products and solutions for Asia Pacific at Visa.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“With Visa Intelligent Commerce and its cornerstone, Trusted Agent Protocol, Visa is connecting consumers, AI agents and merchants through secure, scalable solutions.” The numbers underscore why this infrastructure matters now.&amp;nbsp;&lt;/p&gt;&lt;p&gt;According to Adobe Data Insights cited in Visa’s announcement, 85% of consumers who’ve used AI for shopping report improved experiences. But this enthusiasm masks a brewing crisis: merchants can’t reliably distinguish between legitimate AI agents making purchases and sophisticated bots attempting fraud or data scraping.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-technical-architecture-behind-agentic-commerce"&gt;The technical architecture behind Agentic Commerce&lt;/h3&gt;&lt;p&gt;Visa Intelligent Commerce comprises integrated APIs spanning tokenisation, authentication, payment instructions, and transaction signals—creating what amounts to a new protocol layer for AI commerce infrastructure.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At its core sits the Trusted Agent Protocol, which uses agent-specific cryptographic signatures to verify that AI assistants possess genuine commerce intent and valid consumer authorisation. This verification layer solves a problem that traditional payment security&amp;nbsp;wasn’t designed&amp;nbsp;to address.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Fraud detection systems identify suspicious patterns in human behaviour—unusual purchase locations, strange timing, or atypical product combinations. AI agents naturally exhibit behaviour that would trigger these alerts: simultaneous transactions across multiple merchants, machine-speed checkouts, and purchasing patterns optimised by algorithms rather than human impulse.&lt;/p&gt;&lt;p&gt;The infrastructure Visa is building maintains consumer visibility even as AI intermediates transactions. When an AI agent books a hotel or orders groceries, merchants can still identify the actual consumer, preserving customer relationship data that businesses depend on for marketing, loyalty programs, and service personalisation.&lt;/p&gt;&lt;p&gt;Critically, Visa designed its AI commerce infrastructure as an open, low-code framework. This architectural choice lowers integration barriers for merchants while enabling interoperability across the ecosystem of AI platforms, payment processors, and commerce applications emerging across the Asia Pacific.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-ecosystem-emerging-around-ai-payments"&gt;The ecosystem emerging around AI payments&lt;/h3&gt;&lt;p&gt;Visa’s partnerships with Ant International, LG Uplus, Microsoft, Perplexity, Stripe, and Tencent reveal the collaborative nature of building AI commerce infrastructure at scale.&amp;nbsp;&lt;/p&gt;&lt;p&gt;These aren’t traditional payment processing relationships—they represent nodes in a network where AI agents will need to authenticate across platforms, access payment credentials&amp;nbsp;securely, and execute transactions that span multiple services&amp;nbsp;ina single consumer intent.&lt;/p&gt;&lt;p&gt;Consider a scenario&amp;nbsp;where&amp;nbsp;a consumer tells Microsoft’s AI assistant&amp;nbsp;to&amp;nbsp;“plan&amp;nbsp;a weekend in Kuala Lumpur.”&amp;nbsp;The agent might use Perplexity to research options, Stripe to process&amp;nbsp;payment for flights, and transact on Visa’s network—all while maintaining secure authentication and consumer authorisation throughout the journey.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This&amp;nbsp;requires infrastructure that enables seamless handoffs between platforms while maintaining security and transparency.&amp;nbsp;The early 2026 pilot timeline suggests that Visa is moving in parallel with regulatory frameworks still taking shape across&amp;nbsp;the&amp;nbsp;Asia Pacific markets.&amp;nbsp;Different countries will approach AI agent authorisation, consumer protection in automated transactions, and cross-border AI commerce differently—creating complexity that will inform global standards as the technology scales.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means-for-digital-commerce"&gt;What this means for digital commerce&lt;/h3&gt;&lt;p&gt;The shift toward AI-mediated transactions changes fundamental assumptions about online retail. Consumer journeys that traditionally involved browsing, comparing, and clicking “buy” will increasingly happen through conversational instructions to AI assistants.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Merchants optimising for human attention spans and click-through rates will need to rethink strategies for an environment where AI agents evaluate options&amp;nbsp;through algorithmic comparison&amp;nbsp;rather than emotional appeal.&lt;/p&gt;&lt;p&gt;Visa’s AI commerce infrastructure also introduces new competitive dynamics. Businesses that integrate early gain experience with agent-driven sales flows, develop strategies for maintaining customer relationships through AI intermediation, and refine fraud detection for machine-initiated transactions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Those who wait risk operational gaps when consumer adoption reaches critical mass. The payment giant showcased Intelligent Commerce at Singapore Fintech Festival from November 12-14, offering businesses concrete visibility into integration requirements and implementation challenges.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With Visa’s 4.8 billion credentials potentially accessible to AI agents across millions of merchant locations worldwide, the infrastructure&amp;nbsp;being piloted&amp;nbsp;in the Asia Pacific will likely define how agentic commerce operates globally.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-road-to-2026"&gt;The road to 2026&lt;/h3&gt;&lt;p&gt;Fourteen months until regional pilots launch may sound distant, but the technical, operational, and strategic preparations required make it a tight timeline. Businesses need to audit payment infrastructure for AI compatibility, evaluate customer experience design for agent-mediated interactions, and recalibrate security systems to distinguish legitimate AI commerce from threats.&lt;/p&gt;&lt;p&gt;The AI commerce infrastructure Visa is deploying doesn’t just enable a new payment method—it establishes the foundation for a different model of digital transactions. As the Asia Pacific becomes the proving ground for this transformation, the lessons learned will shape how commerce operates in an AI-driven world.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by: Yoco Photography)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How Huawei is building agentic AI systems that make decisions independently&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;When Visa&amp;nbsp;unveiled&amp;nbsp;its Intelligent Commerce platform for Asia Pacific on November 12, it wasn’t just launching another payment feature—it was building AI commerce infrastructure to solve a crisis most merchants haven’t noticed yet: their websites are&amp;nbsp;being flooded&amp;nbsp;by AI agents, and there’s no reliable way to tell which ones are legitimate shoppers and which are malicious bots.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With AI-driven traffic to retail sites exploding by 4,700% in just one year, Visa’s early 2026 regional pilots give businesses 14 months to prepare their payment systems for a world where artificial intelligence handles shopping and transactions on behalf of consumers.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-asia-pacific-why-now"&gt;Why Asia Pacific, why now&lt;/h3&gt;&lt;p&gt;Visa’s strategic decision to pilot its agentic commerce capabilities in Asia Pacific by early 2026 reflects more than a geographic preference—it acknowledges the region’s leadership in mobile payments adoption and digital-first consumer behaviour.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Deploying the AI commerce infrastructure represents a fundamental architectural shift: payment systems designed from the ground up to accommodate machine-initiated transactions at speeds and volumes beyond what human shoppers can handle.&lt;/p&gt;&lt;p&gt;“Agentic commerce is transforming the very fabric of online payment transactions, requiring a unified ecosystem to unlock its full potential,” said T.R. Ramachandran, head of products and solutions for Asia Pacific at Visa.&amp;nbsp;&lt;/p&gt;&lt;p&gt;“With Visa Intelligent Commerce and its cornerstone, Trusted Agent Protocol, Visa is connecting consumers, AI agents and merchants through secure, scalable solutions.” The numbers underscore why this infrastructure matters now.&amp;nbsp;&lt;/p&gt;&lt;p&gt;According to Adobe Data Insights cited in Visa’s announcement, 85% of consumers who’ve used AI for shopping report improved experiences. But this enthusiasm masks a brewing crisis: merchants can’t reliably distinguish between legitimate AI agents making purchases and sophisticated bots attempting fraud or data scraping.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-technical-architecture-behind-agentic-commerce"&gt;The technical architecture behind Agentic Commerce&lt;/h3&gt;&lt;p&gt;Visa Intelligent Commerce comprises integrated APIs spanning tokenisation, authentication, payment instructions, and transaction signals—creating what amounts to a new protocol layer for AI commerce infrastructure.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At its core sits the Trusted Agent Protocol, which uses agent-specific cryptographic signatures to verify that AI assistants possess genuine commerce intent and valid consumer authorisation. This verification layer solves a problem that traditional payment security&amp;nbsp;wasn’t designed&amp;nbsp;to address.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Fraud detection systems identify suspicious patterns in human behaviour—unusual purchase locations, strange timing, or atypical product combinations. AI agents naturally exhibit behaviour that would trigger these alerts: simultaneous transactions across multiple merchants, machine-speed checkouts, and purchasing patterns optimised by algorithms rather than human impulse.&lt;/p&gt;&lt;p&gt;The infrastructure Visa is building maintains consumer visibility even as AI intermediates transactions. When an AI agent books a hotel or orders groceries, merchants can still identify the actual consumer, preserving customer relationship data that businesses depend on for marketing, loyalty programs, and service personalisation.&lt;/p&gt;&lt;p&gt;Critically, Visa designed its AI commerce infrastructure as an open, low-code framework. This architectural choice lowers integration barriers for merchants while enabling interoperability across the ecosystem of AI platforms, payment processors, and commerce applications emerging across the Asia Pacific.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-ecosystem-emerging-around-ai-payments"&gt;The ecosystem emerging around AI payments&lt;/h3&gt;&lt;p&gt;Visa’s partnerships with Ant International, LG Uplus, Microsoft, Perplexity, Stripe, and Tencent reveal the collaborative nature of building AI commerce infrastructure at scale.&amp;nbsp;&lt;/p&gt;&lt;p&gt;These aren’t traditional payment processing relationships—they represent nodes in a network where AI agents will need to authenticate across platforms, access payment credentials&amp;nbsp;securely, and execute transactions that span multiple services&amp;nbsp;ina single consumer intent.&lt;/p&gt;&lt;p&gt;Consider a scenario&amp;nbsp;where&amp;nbsp;a consumer tells Microsoft’s AI assistant&amp;nbsp;to&amp;nbsp;“plan&amp;nbsp;a weekend in Kuala Lumpur.”&amp;nbsp;The agent might use Perplexity to research options, Stripe to process&amp;nbsp;payment for flights, and transact on Visa’s network—all while maintaining secure authentication and consumer authorisation throughout the journey.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This&amp;nbsp;requires infrastructure that enables seamless handoffs between platforms while maintaining security and transparency.&amp;nbsp;The early 2026 pilot timeline suggests that Visa is moving in parallel with regulatory frameworks still taking shape across&amp;nbsp;the&amp;nbsp;Asia Pacific markets.&amp;nbsp;Different countries will approach AI agent authorisation, consumer protection in automated transactions, and cross-border AI commerce differently—creating complexity that will inform global standards as the technology scales.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-means-for-digital-commerce"&gt;What this means for digital commerce&lt;/h3&gt;&lt;p&gt;The shift toward AI-mediated transactions changes fundamental assumptions about online retail. Consumer journeys that traditionally involved browsing, comparing, and clicking “buy” will increasingly happen through conversational instructions to AI assistants.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Merchants optimising for human attention spans and click-through rates will need to rethink strategies for an environment where AI agents evaluate options&amp;nbsp;through algorithmic comparison&amp;nbsp;rather than emotional appeal.&lt;/p&gt;&lt;p&gt;Visa’s AI commerce infrastructure also introduces new competitive dynamics. Businesses that integrate early gain experience with agent-driven sales flows, develop strategies for maintaining customer relationships through AI intermediation, and refine fraud detection for machine-initiated transactions.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Those who wait risk operational gaps when consumer adoption reaches critical mass. The payment giant showcased Intelligent Commerce at Singapore Fintech Festival from November 12-14, offering businesses concrete visibility into integration requirements and implementation challenges.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With Visa’s 4.8 billion credentials potentially accessible to AI agents across millions of merchant locations worldwide, the infrastructure&amp;nbsp;being piloted&amp;nbsp;in the Asia Pacific will likely define how agentic commerce operates globally.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-road-to-2026"&gt;The road to 2026&lt;/h3&gt;&lt;p&gt;Fourteen months until regional pilots launch may sound distant, but the technical, operational, and strategic preparations required make it a tight timeline. Businesses need to audit payment infrastructure for AI compatibility, evaluate customer experience design for agent-mediated interactions, and recalibrate security systems to distinguish legitimate AI commerce from threats.&lt;/p&gt;&lt;p&gt;The AI commerce infrastructure Visa is deploying doesn’t just enable a new payment method—it establishes the foundation for a different model of digital transactions. As the Asia Pacific becomes the proving ground for this transformation, the lessons learned will shape how commerce operates in an AI-driven world.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by: Yoco Photography)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: How Huawei is building agentic AI systems that make decisions independently&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/visa-ai-commerce-intelligent-commerce-2026/</guid><pubDate>Fri, 14 Nov 2025 08:00:00 +0000</pubDate></item><item><title>[NEW] These technologies could help put a stop to animal testing (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/11/14/1127949/technologies-could-stop-animal-testing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/AdobeStock_48611539.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Earlier this week, the UK’s science minister announced an ambitious plan: to phase out animal testing.&lt;/p&gt;  &lt;p&gt;Testing potential skin irritants on animals will be stopped by the end of next year, according to&amp;nbsp;a strategy released on Tuesday. By 2027, researchers are “expected to end” tests of the strength of Botox on mice. And drug tests in dogs and nonhuman primates will be reduced by 2030.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Animal welfare groups have been campaigning for commitments like these for decades. But a lack of alternatives has made it difficult to put a stop to animal testing. Advances in medical science and biotechnology are changing that.&lt;/p&gt; 
 &lt;p&gt;Animals have been used in scientific research&amp;nbsp;for thousands of years. Animal experimentation has led to many important discoveries about how the brains and bodies of animals work. And because regulators require drugs to be first tested in research animals, it has played an important role in the creation of medicines and devices for both humans and other animals.&lt;/p&gt;  &lt;p&gt;Today, countries like the UK and the US regulate animal research and require scientists to hold multiple licenses and adhere to rules on animal housing and care. Still, millions of animals are used annually in research. Plenty of scientists don’t want to take part in animal testing. And some question whether animal research is justifiable—especially considering that&amp;nbsp;around 95% of treatments that look promising in animals don’t make it to market.&lt;/p&gt; 
 &lt;p&gt;In recent decades, we’ve seen dramatic advances in technologies that offer new ways to model the human body and test the effects of potential therapies, without experimenting on humans or other animals.&lt;/p&gt;  &lt;p&gt;Take “organs on chips,” for example. Researchers have been creating miniature versions of human organs inside tiny plastic cases. These&amp;nbsp;systems are designed to contain the same mix of cells you’d find in a full-grown organ and receive a supply of nutrients that keeps them alive.&lt;/p&gt;  &lt;p&gt;Today, multiple teams have created models of livers, intestines, hearts, kidneys and even the brain. And they are already being used in research. Heart chips have been sent into space to observe how they respond to low gravity. The FDA used lung chips to assess covid-19 vaccines. Gut chips are being used to study the effects of radiation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Some researchers are even working to connect multiple chips to create a “body on a chip”—although this has been in the works for over a decade and no one has quite managed it yet.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In the same vein, others have been working on creating model versions of organs—and even embryos—in the lab. By growing groups of cells into tiny 3D structures, scientists can study how organs develop and work, and even test drugs on them. They can even be personalized—if you take cells from someone, you should be able to model that person’s specific organs. Some researchers have even been able to create organoids of developing fetuses.&lt;/p&gt;  &lt;p&gt;The UK government strategy mentions the promise of artificial intelligence, too. Many scientists have been quick to adopt AI as a tool to help them make sense of vast databases, and to find connections between genes, proteins and disease, for example. Others are&amp;nbsp;using AI to design all-new drugs.&lt;/p&gt;  &lt;p&gt;Those new drugs could potentially be tested on virtual humans. Not flesh-and-blood people, but digital reconstructions that live in a computer. Biomedical engineers have already created digital twins of organs. In ongoing trials, digital hearts are being used to guide surgeons on how—and where—to operate on real hearts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;When I spoke to Natalia Trayanova, the biomedical engineering professor behind this trial, she told me that her model could recommend regions of heart tissue to be burned off as part of treatment for atrial fibrillation. Her tool would normally suggest two or three regions but occasionally would recommend many more. “They just have to trust us,”&amp;nbsp;she told me.&lt;/p&gt; 

 &lt;p&gt;It is unlikely that we’ll completely phase out animal testing by 2030. The UK government acknowledges that animal testing is still required by lots of regulators, including the FDA, the European Medicines Agency, and the World Health Organization. And while alternatives to animal testing have come a long way, none of them perfectly capture how a living body will respond to a treatment.&lt;/p&gt;  &lt;p&gt;At least not yet. Given all the progress that has been made in recent years, it’s not too hard to imagine a future without animal testing.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/11/AdobeStock_48611539.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Earlier this week, the UK’s science minister announced an ambitious plan: to phase out animal testing.&lt;/p&gt;  &lt;p&gt;Testing potential skin irritants on animals will be stopped by the end of next year, according to&amp;nbsp;a strategy released on Tuesday. By 2027, researchers are “expected to end” tests of the strength of Botox on mice. And drug tests in dogs and nonhuman primates will be reduced by 2030.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Animal welfare groups have been campaigning for commitments like these for decades. But a lack of alternatives has made it difficult to put a stop to animal testing. Advances in medical science and biotechnology are changing that.&lt;/p&gt; 
 &lt;p&gt;Animals have been used in scientific research&amp;nbsp;for thousands of years. Animal experimentation has led to many important discoveries about how the brains and bodies of animals work. And because regulators require drugs to be first tested in research animals, it has played an important role in the creation of medicines and devices for both humans and other animals.&lt;/p&gt;  &lt;p&gt;Today, countries like the UK and the US regulate animal research and require scientists to hold multiple licenses and adhere to rules on animal housing and care. Still, millions of animals are used annually in research. Plenty of scientists don’t want to take part in animal testing. And some question whether animal research is justifiable—especially considering that&amp;nbsp;around 95% of treatments that look promising in animals don’t make it to market.&lt;/p&gt; 
 &lt;p&gt;In recent decades, we’ve seen dramatic advances in technologies that offer new ways to model the human body and test the effects of potential therapies, without experimenting on humans or other animals.&lt;/p&gt;  &lt;p&gt;Take “organs on chips,” for example. Researchers have been creating miniature versions of human organs inside tiny plastic cases. These&amp;nbsp;systems are designed to contain the same mix of cells you’d find in a full-grown organ and receive a supply of nutrients that keeps them alive.&lt;/p&gt;  &lt;p&gt;Today, multiple teams have created models of livers, intestines, hearts, kidneys and even the brain. And they are already being used in research. Heart chips have been sent into space to observe how they respond to low gravity. The FDA used lung chips to assess covid-19 vaccines. Gut chips are being used to study the effects of radiation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Some researchers are even working to connect multiple chips to create a “body on a chip”—although this has been in the works for over a decade and no one has quite managed it yet.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;In the same vein, others have been working on creating model versions of organs—and even embryos—in the lab. By growing groups of cells into tiny 3D structures, scientists can study how organs develop and work, and even test drugs on them. They can even be personalized—if you take cells from someone, you should be able to model that person’s specific organs. Some researchers have even been able to create organoids of developing fetuses.&lt;/p&gt;  &lt;p&gt;The UK government strategy mentions the promise of artificial intelligence, too. Many scientists have been quick to adopt AI as a tool to help them make sense of vast databases, and to find connections between genes, proteins and disease, for example. Others are&amp;nbsp;using AI to design all-new drugs.&lt;/p&gt;  &lt;p&gt;Those new drugs could potentially be tested on virtual humans. Not flesh-and-blood people, but digital reconstructions that live in a computer. Biomedical engineers have already created digital twins of organs. In ongoing trials, digital hearts are being used to guide surgeons on how—and where—to operate on real hearts.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;When I spoke to Natalia Trayanova, the biomedical engineering professor behind this trial, she told me that her model could recommend regions of heart tissue to be burned off as part of treatment for atrial fibrillation. Her tool would normally suggest two or three regions but occasionally would recommend many more. “They just have to trust us,”&amp;nbsp;she told me.&lt;/p&gt; 

 &lt;p&gt;It is unlikely that we’ll completely phase out animal testing by 2030. The UK government acknowledges that animal testing is still required by lots of regulators, including the FDA, the European Medicines Agency, and the World Health Organization. And while alternatives to animal testing have come a long way, none of them perfectly capture how a living body will respond to a treatment.&lt;/p&gt;  &lt;p&gt;At least not yet. Given all the progress that has been made in recent years, it’s not too hard to imagine a future without animal testing.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/11/14/1127949/technologies-could-stop-animal-testing/</guid><pubDate>Fri, 14 Nov 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] ChatGPT launches pilot group chats across Japan, New Zealand, South Korea, and Taiwan (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/14/chatgpt-launches-pilot-group-chats-across-japan-new-zealand-south-korea-and-taiwan/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/ChatGPT-Groupchat-pilot-launch.png?w=995" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Thursday introduced a group chat feature for ChatGPT. The feature, currently being tested in select regions including Japan, New Zealand, South Korea, and Taiwan, lets users collaborate directly within the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat is available to Free, Plus, and Team users on both mobile and web platforms. OpenAI says the pilot is designed to explore how people use group conversations in ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement comes after earlier reports that OpenAI had been testing a direct-message-style tool. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker describes this pilot as just a “small first step” toward creating a more “shared experience” in the app. Early users will be invited to provide feedback, which the company says will help shape how the feature eventually expands to more regions and offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to OpenAI, private chats and personal ChatGPT memory stay completely private. Group chats are invitation-only, and members can leave at any time. Most participants can remove others, though the group’s creator can only leave voluntarily. For users under 18, content is filtered, with extra safeguards and parental controls in place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting a group chat is easy. Just tap the people icon and add participants, either directly or by sharing a link. Groups can include 1 to 20 people. If you add someone to an existing chat, a new group is created, leaving the original conversation unchanged. Each group has a short profile, and all chats are organized in a labeled sidebar for easy access.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Group chats work just like regular ChatGPT conversations but with multiple people joining in. GPT‑5.1 Auto handles responses and comes loaded with features such as search, image generation, file uploads, and dictation. In group chats, ChatGPT’s usage limits — which restrict how many AI responses users can receive per hour — only count when ChatGPT responds. Messages between human participants don’t count toward these limits.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT has learned new social skills for group chats, knowing when to jump in and when to stay quiet. You can tag “ChatGPT” to get it to respond. It can also react with emojis and use profile photos to create personalized images for the conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat feature represents the latest step in OpenAI’s gradual transformation from a simple AI assistant into something resembling a social platform. In late September, the company launched Sora 2, a standalone social media app with a TikTok-style feed for sharing AI-generated videos, complete with algorithmic recommendations based on user activity and location, parental controls, and direct messaging capabilities.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/ChatGPT-Groupchat-pilot-launch.png?w=995" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI on Thursday introduced a group chat feature for ChatGPT. The feature, currently being tested in select regions including Japan, New Zealand, South Korea, and Taiwan, lets users collaborate directly within the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat is available to Free, Plus, and Team users on both mobile and web platforms. OpenAI says the pilot is designed to explore how people use group conversations in ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The announcement comes after earlier reports that OpenAI had been testing a direct-message-style tool. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT maker describes this pilot as just a “small first step” toward creating a more “shared experience” in the app. Early users will be invited to provide feedback, which the company says will help shape how the feature eventually expands to more regions and offerings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to OpenAI, private chats and personal ChatGPT memory stay completely private. Group chats are invitation-only, and members can leave at any time. Most participants can remove others, though the group’s creator can only leave voluntarily. For users under 18, content is filtered, with extra safeguards and parental controls in place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Starting a group chat is easy. Just tap the people icon and add participants, either directly or by sharing a link. Groups can include 1 to 20 people. If you add someone to an existing chat, a new group is created, leaving the original conversation unchanged. Each group has a short profile, and all chats are organized in a labeled sidebar for easy access.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Group chats work just like regular ChatGPT conversations but with multiple people joining in. GPT‑5.1 Auto handles responses and comes loaded with features such as search, image generation, file uploads, and dictation. In group chats, ChatGPT’s usage limits — which restrict how many AI responses users can receive per hour — only count when ChatGPT responds. Messages between human participants don’t count toward these limits.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT has learned new social skills for group chats, knowing when to jump in and when to stay quiet. You can tag “ChatGPT” to get it to respond. It can also react with emojis and use profile photos to create personalized images for the conversation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The group chat feature represents the latest step in OpenAI’s gradual transformation from a simple AI assistant into something resembling a social platform. In late September, the company launched Sora 2, a standalone social media app with a TikTok-style feed for sharing AI-generated videos, complete with algorithmic recommendations based on user activity and location, parental controls, and direct messaging capabilities.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/14/chatgpt-launches-pilot-group-chats-across-japan-new-zealand-south-korea-and-taiwan/</guid><pubDate>Fri, 14 Nov 2025 10:58:08 +0000</pubDate></item><item><title>[NEW] Anthropic details cyber espionage campaign orchestrated by AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/anthropic-details-cyber-espionage-campaign-orchestrated-by-ai/</link><description>&lt;p&gt;Security leaders face a new class of autonomous threat as Anthropic details the first cyber espionage campaign orchestrated by AI.&lt;/p&gt;&lt;p&gt;In a report released this week, the company’s Threat Intelligence team outlined its disruption of a sophisticated operation by a Chinese state-sponsored group – an assessment made with high confidence – dubbed GTG-1002 and detected in mid-September 2025.&lt;/p&gt;&lt;p&gt;The operation targeted approximately 30 entities, including large tech companies, financial institutions, chemical manufacturing companies, and government agencies.&lt;/p&gt;&lt;p&gt;Rather than AI assisting human operators, the attackers successfully manipulated Anthropic’s Claude Code model to function as an autonomous agent to execute the vast majority of tactical operations independently.&lt;/p&gt;&lt;p&gt;This marks a worrying development for CISOs, moving cyber attacks from human-directed efforts to a model where AI agents perform 80-90 percent of the offensive work with humans acting only as high-level supervisors. Anthropic believes this is the first documented case of a large-scale cyberattack executed without substantial human intervention.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-agents-a-new-operational-model-for-cyberattacks"&gt;AI agents: A new operational model for cyberattacks&lt;/h3&gt;&lt;p&gt;The group used an orchestration system that tasked instances of Claude Code to function as autonomous penetration testing agents. These AI agents were directed as part of the espionage campaign to perform reconnaissance, discover vulnerabilities, develop exploits, harvest credentials, move laterally across networks, and exfiltrate data. This enabled the AI to perform reconnaissance in a fraction of the time it would have taken a team of human hackers.&lt;/p&gt;&lt;p&gt;Human involvement was limited to 10-20 percent of the total effort, primarily focused on campaign initiation and providing authorisation at a few key escalation points. For example, human operators would approve the transition from reconnaissance to active exploitation or authorise the final scope of data exfiltration.&lt;/p&gt;&lt;p&gt;The attackers bypassed the AI model’s built-in safeguards, which are trained to avoid harmful behaviours. They did this by jailbreaking the model, tricking it by breaking down attacks into seemingly innocent tasks and by adopting a “role-play” persona. Operators told Claude that it was an employee of a legitimate cybersecurity firm and was being used in defensive testing. This allowed the operation to proceed long enough to gain access to a handful of validated targets.&lt;/p&gt;&lt;p&gt;The technical sophistication of the attack lay not in novel malware, but in orchestration. The report notes the framework relied “overwhelmingly on open-source penetration testing tools”. The attackers used Model Context Protocol (MCP) servers as an interface between the AI and these commodity tools, enabling the AI to execute commands, analyse results, and maintain operational state across multiple targets and sessions. The AI was even directed to research and write its own exploit code for the espionage campaign.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-hallucinations-become-a-good-thing"&gt;AI hallucinations become a good thing&lt;/h3&gt;&lt;p&gt;While the campaign successfully breached high-value targets, Anthropic’s investigation uncovered a noteworthy limitation: the AI hallucinated during offensive operations.&lt;/p&gt;&lt;p&gt;The report states that Claude “frequently overstated findings and occasionally fabricated data”. This manifested as the AI claiming to have obtained credentials that did not work or identifying discoveries that “proved to be publicly available information.”&lt;/p&gt;&lt;p&gt;This tendency required the human operators to carefully validate all results, presenting challenges for the attackers’ operational effectiveness. According to Anthropic, this “remains an obstacle to fully autonomous cyberattacks”. For security leaders, this highlights a potential weakness in AI-driven attacks: they may generate a high volume of noise and false positives that can be identified with robust monitoring.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-defensive-ai-arms-race-against-new-cyber-espionage-threats"&gt;A defensive AI arms race against new cyber espionage threats&lt;/h3&gt;&lt;p&gt;The primary implication for business and technology leaders is that the barriers to performing sophisticated cyberattacks have dropped considerably. Groups with fewer resources may now be able to execute campaigns that previously required entire teams of experienced hackers.&lt;/p&gt;&lt;p&gt;This attack demonstrates a capability beyond “vibe hacking,” where humans remained firmly in control of operations. The GTG-1002 campaign proves that AI can be used to autonomously discover and exploit vulnerabilities in live operations.&lt;/p&gt;&lt;p&gt;Anthropic, which banned the accounts and notified authorities over a ten-day investigation, argues that this development shows the urgent need for AI-powered defence. The company states that “the very abilities that allow Claude to be used in these attacks also make it essential for cyber defense”. The company’s own Threat Intelligence team “used Claude extensively to analyse “the enormous amounts of data generated” during this investigation.&lt;/p&gt;&lt;p&gt;Security teams should operate under the assumption that a major change has occurred in cybersecurity. The report urges defenders to “experiment with applying AI for defense in areas like SOC automation, threat detection, vulnerability assessment, and incident response.”&lt;/p&gt;&lt;p&gt;The contest between AI-driven attacks and AI-powered defence has begun, and proactive adaptation to counter new espionage threats is the only viable path forward.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Wiz: Security lapses emerge amid the global AI race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Security leaders face a new class of autonomous threat as Anthropic details the first cyber espionage campaign orchestrated by AI.&lt;/p&gt;&lt;p&gt;In a report released this week, the company’s Threat Intelligence team outlined its disruption of a sophisticated operation by a Chinese state-sponsored group – an assessment made with high confidence – dubbed GTG-1002 and detected in mid-September 2025.&lt;/p&gt;&lt;p&gt;The operation targeted approximately 30 entities, including large tech companies, financial institutions, chemical manufacturing companies, and government agencies.&lt;/p&gt;&lt;p&gt;Rather than AI assisting human operators, the attackers successfully manipulated Anthropic’s Claude Code model to function as an autonomous agent to execute the vast majority of tactical operations independently.&lt;/p&gt;&lt;p&gt;This marks a worrying development for CISOs, moving cyber attacks from human-directed efforts to a model where AI agents perform 80-90 percent of the offensive work with humans acting only as high-level supervisors. Anthropic believes this is the first documented case of a large-scale cyberattack executed without substantial human intervention.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-agents-a-new-operational-model-for-cyberattacks"&gt;AI agents: A new operational model for cyberattacks&lt;/h3&gt;&lt;p&gt;The group used an orchestration system that tasked instances of Claude Code to function as autonomous penetration testing agents. These AI agents were directed as part of the espionage campaign to perform reconnaissance, discover vulnerabilities, develop exploits, harvest credentials, move laterally across networks, and exfiltrate data. This enabled the AI to perform reconnaissance in a fraction of the time it would have taken a team of human hackers.&lt;/p&gt;&lt;p&gt;Human involvement was limited to 10-20 percent of the total effort, primarily focused on campaign initiation and providing authorisation at a few key escalation points. For example, human operators would approve the transition from reconnaissance to active exploitation or authorise the final scope of data exfiltration.&lt;/p&gt;&lt;p&gt;The attackers bypassed the AI model’s built-in safeguards, which are trained to avoid harmful behaviours. They did this by jailbreaking the model, tricking it by breaking down attacks into seemingly innocent tasks and by adopting a “role-play” persona. Operators told Claude that it was an employee of a legitimate cybersecurity firm and was being used in defensive testing. This allowed the operation to proceed long enough to gain access to a handful of validated targets.&lt;/p&gt;&lt;p&gt;The technical sophistication of the attack lay not in novel malware, but in orchestration. The report notes the framework relied “overwhelmingly on open-source penetration testing tools”. The attackers used Model Context Protocol (MCP) servers as an interface between the AI and these commodity tools, enabling the AI to execute commands, analyse results, and maintain operational state across multiple targets and sessions. The AI was even directed to research and write its own exploit code for the espionage campaign.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-ai-hallucinations-become-a-good-thing"&gt;AI hallucinations become a good thing&lt;/h3&gt;&lt;p&gt;While the campaign successfully breached high-value targets, Anthropic’s investigation uncovered a noteworthy limitation: the AI hallucinated during offensive operations.&lt;/p&gt;&lt;p&gt;The report states that Claude “frequently overstated findings and occasionally fabricated data”. This manifested as the AI claiming to have obtained credentials that did not work or identifying discoveries that “proved to be publicly available information.”&lt;/p&gt;&lt;p&gt;This tendency required the human operators to carefully validate all results, presenting challenges for the attackers’ operational effectiveness. According to Anthropic, this “remains an obstacle to fully autonomous cyberattacks”. For security leaders, this highlights a potential weakness in AI-driven attacks: they may generate a high volume of noise and false positives that can be identified with robust monitoring.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-a-defensive-ai-arms-race-against-new-cyber-espionage-threats"&gt;A defensive AI arms race against new cyber espionage threats&lt;/h3&gt;&lt;p&gt;The primary implication for business and technology leaders is that the barriers to performing sophisticated cyberattacks have dropped considerably. Groups with fewer resources may now be able to execute campaigns that previously required entire teams of experienced hackers.&lt;/p&gt;&lt;p&gt;This attack demonstrates a capability beyond “vibe hacking,” where humans remained firmly in control of operations. The GTG-1002 campaign proves that AI can be used to autonomously discover and exploit vulnerabilities in live operations.&lt;/p&gt;&lt;p&gt;Anthropic, which banned the accounts and notified authorities over a ten-day investigation, argues that this development shows the urgent need for AI-powered defence. The company states that “the very abilities that allow Claude to be used in these attacks also make it essential for cyber defense”. The company’s own Threat Intelligence team “used Claude extensively to analyse “the enormous amounts of data generated” during this investigation.&lt;/p&gt;&lt;p&gt;Security teams should operate under the assumption that a major change has occurred in cybersecurity. The report urges defenders to “experiment with applying AI for defense in areas like SOC automation, threat detection, vulnerability assessment, and incident response.”&lt;/p&gt;&lt;p&gt;The contest between AI-driven attacks and AI-powered defence has begun, and proactive adaptation to counter new espionage threats is the only viable path forward.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Wiz: Security lapses emerge amid the global AI race&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-110077" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/10/image-10.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/anthropic-details-cyber-espionage-campaign-orchestrated-by-ai/</guid><pubDate>Fri, 14 Nov 2025 11:34:00 +0000</pubDate></item><item><title>[NEW] Inside Harvey: How a first-year legal associate built one of Silicon Valley’s hottest startups (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/14/inside-harvey-how-a-first-year-legal-associate-built-one-of-silicon-valleys-hottest-startups/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-14-at-11.50.31-AM.png?resize=1200,863" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Legal AI might not sound like the sexiest category in Silicon Valley, but Harvey‘s CEO Winston Weinberg has captured the attention of virtually every top-tier investor in the Valley. The company’s cap table reads like a who’s who of venture capital: the OpenAI Startup Fund (its first institutional investor), Sequoia Capital, Kleiner Perkins, Elad Gil, Google Ventures, Coatue, and most recently, Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The San Francisco-based company’s valuation skyrocketed from $3 billion in February 2025 to $5 billion in June to $8 billion in late October — a rise that reflects both the bonkers price tags awarded to AI companies, and Harvey’s ability to win over major law firms and corporate legal departments. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In fact, the startup now claims 235 clients across 63 countries, including a majority of the top 10 U.S. law firms. It also says it surpassed $100 million in annual recurring revenue as of August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch spoke with Weinberg for this week’s StrictlyVC Download podcast to ask about the wild ride that he and co-founder Gabe Pereyra have been on so far. During that chat, he shared how a cold email sent a few summers ago to Sam Altman changed everything; why he believes lawyers will benefit rather than suffer from AI; and how Harvey is tackling the technically complex challenge of building a truly multiplayer platform that navigates ethical walls and data permissioning across dozens of countries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This interview has been edited lightly for length. For the full monty, check out the podcast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch: You started as a first-year associate at O’Melveny &amp;amp; Myers. When did you realize AI could transform legal work?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Winston Weinberg: &lt;/strong&gt;So my co-founder was working at Meta at the time; he was also my roommate. He was showing me GPT-3, and in the beginning, I swear to God, the main use case I had for it was running a &lt;em&gt;Dungeons and Dragons&lt;/em&gt; game with friends in LA. Then I was assigned to this landlord-tenant case at O’Melveny, and I didn’t know anything about landlord-tenant law. I started using GPT-3 to work on it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;My co-founder Gabe and I figured out we could do chain-of-thought prompting before that was really a thing. We created this super long chain-of-thought prompt over California landlord-tenant statutes. We grabbed 100 questions from r/legaladvice [on Reddit] and ran that prompt over them, then gave the question-answer pairs to three landlord-tenant attorneys without saying anything about AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We just said, “A potential customer asked this question, here’s the answer—would you make any edits or would you send this as is?” On 86 of the 100 samples, two out of three attorneys or more said they would send it with zero edits. That was the moment when we were like, wow, this entire industry can be transformed by this technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What happened next?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;We cold-emailed Sam Altman and Jason Kwon, who was the general counsel at OpenAI. We figured we had to email a lawyer because otherwise the person wouldn’t know if the outputs were right. On the morning of July 4 at 10 a.m. — I remember this specifically because it was July 4 — we got on a call with them and kind of the rest of the C-suite at OpenAI, and we made our pitch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Did they write a check right away?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Yeah. It’s the OpenAI Startup Fund [they are the second-largest investor in Harvey]. OpenAI introduced us to our angel investors at the time, Sarah Guo and Elad Gil, and then everything else from there we were doing ourselves. I actually didn’t have any friends that worked in tech. I didn’t grow up in San Francisco. I didn’t know who the top VCs were. I didn’t understand how you’re supposed to fundraise. This was all just net new to me.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: For someone who wasn’t familiar with the VC scene, you’ve raised a lot of money. What enabled you to raise so much?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;I might say something the VC community might not love, but I strongly believe that the best way to raise money is to just make sure your company is doing super well. I think there’s a lot of advice out there about networking, but to me, the most important thing is to spend almost the entire time on your business, and then find VCs who want to do that with you. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You need to find a few partners who you think are going to go the distance with you. So, 99% of your time, focus on the business going well, and then spend time trying to find a few folks who you really think you can partner with and who will be there for you for the long run.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: You hit $100 million in ARR in August. With around 400 employees, how close are you to break-even?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Compute costs are more expensive for us than a lot of other things. We’re operating in more than 60 countries with data residency laws in all of them. For a long time, if you used multiple models in your product, you had to buy a bucket of compute — a minimum threshold — in every single one of those countries, even if you didn’t have enough clients yet to support that cost.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Germany and Australia have incredibly strict data processing laws. You cannot send financial data outside of those countries. We’d set up Azure or AWS instances in every single one of those countries, but we’d only use them to close three or four large clients. Our margins look very good on a token basis, but they’re worse because we have to spend so much on upfront compute across so many jurisdictions. That will get solved over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Tell us about your sales process. How are you expanding globally?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;At the beginning of this year, about 4% of our revenue was from corporates and 96% from law firms. Right now, 33% of our revenue is from corporates, and my gut says, by the end of the year, that looks closer to 40%.&lt;br /&gt;In the beginning, we would take public litigation briefs from Pacer, find the partner who wrote it, put them into Harvey, and show them how they could argue against their own brief. That got massive attention because it was relevant to what they just did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what was interesting is once we got adoption at law firms, the law firms themselves would help us pitch to corporates. A firm like Latham will introduce Harvey to clients and say, “Hey, did you know this is how we can use AI to do XYZ?” So what started happening was law firms would actually help us sell to corporates because they want to collaborate in the system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: You refer to this as “multiplayer.” Can you expound on this as a growing area of focus?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;This is a huge problem. You’ve seen announcements from OpenAI and Microsoft about shared threads and company memory. That’s hard — you have to get the permissioning right so agents can access the right systems. But you’re only solving it for one entity at a time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The secondary problem we have is: How do you solve that for a company plus all its law firms? You need to get the permissioning right internally and externally. There’s a concept in law called ethical walls. Think about a law firm in the valley that works with 20 VCs. If you’re working on a deal for Sequoia, but also working on another deal for Kleiner Perkins, what happens if you accidentally give all the data on the Sequoia deal to Kleiner Perkins? Huge, astronomical problem. We have to solve internal permissioning and external permissioning so agents can work correctly, and if you get it wrong, you’re going to have disastrous impacts on the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Have you solved this?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;It’s definitely in process. We’re doing all of the security and the permissioning first. The first version of this at scale will probably be done in December. The nice thing is because such a high percentage of our customer base are already corporates using Harvey, the security problem is much easier because they’ve already gone through security review.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: How &lt;em&gt;are&lt;/em&gt; lawyers primarily using Harvey today?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Number one is drafting. Number two is research — that’s emerging because we just have a partnership with LexisNexis. And the third is analyze. What I mean by analyze is running 10 questions over 100,000 documents, like what you do in diligence or discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the beginning, we had much more transactional use cases — M&amp;amp;A and fund formation. Those are still very popular, and we’re building modules specifically for those matters. The area that’s growing faster is litigation, and a lot of that is because you needed the data before you could do it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Some critics have said Harvey is just a wrapper for ChatGPT. How do you respond?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;The largest advantage we have over time is two things. One, we’re collecting a tremendous amount of workflow data — what are the main use cases these models can actually do? Evaluation becomes a pretty strong moat, because how do you evaluate the quality of a merger agreement? That becomes really hard. You have to set up evaluation frameworks and agentic systems that can self-eval all the different steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second strongest moat is our product is becoming very strongly multiplayer. This industry has two sides — providers of legal services and consumers. You need to build a platform that’s in between both. So far, I haven’t seen a competitor doing that. We have competitors doing what we do for law firms, and competitors doing what we do for in-house, but I haven’t seen someone build a truly multiplayer platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of the “ChatGPT wrapper” criticism, for 2023 and 2024, a lot of the power behind the product is honestly the model, plus front-end work that makes the UI and UX easier. But if you’re trying to build something where I have 100,000 documents in this data room, 5,000 emails about this M&amp;amp;A, all these different statutes and codes, and I want a system where I can ask questions over all of those pieces combined with high accuracy — that’s the holy grail. We’ve created all the pieces, and what we’ve been building for the past couple months is pulling that together.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What’s your business model?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg:&lt;/strong&gt; Right now it’s mostly seats, but we’re moving to more outcome-based pricing as the workflows get more complex. You want to do both. You want outcome-based pricing for very small things that you can ensure have the exact same level of accuracy as a human, or better, with very high speed. But the reality is, you’re going to want a lawyer in the loop for so much of work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For at least the next year or two, it’s a productivity suite sold seat-based and multiplayer between law firms and their in-house teams. Slowly over time, we’ll build more consumption-based workflows as the systems get better and more accurate than humans in some areas. But it’s not going to be like you automate an entire M&amp;amp;A — it’s going to be specific pieces of diligence where you can have disclosure agents automate the first pass, then have lawyers jump in and do the rest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: You mentioned to us earlier that penetration is really low in legal. How low?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;What percentage of the lawyers on Earth are using Harvey right now? It’s a super low percentage. There are 8 or 9 million lawyers on Earth. But the more interesting point is we are in the unbelievably early innings on how complex work these systems can do. They’re very helpful and people are getting incredible ROI, but if you think about what percentage of legal work these systems can do today versus what I think it can do in the next five years, it’s so much lower.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Think about the use case as, what is the value per token. The legal fees for a merger could easily be tens of millions of dollars. The artifact you have after that merger is a merger agreement and an SPA — maybe 200 pages total. What is the value per token on that document that required $20 million or $30 million of legal fees to generate? Those are the types of use cases where, when I say we’re at incredibly low penetration, it’s that we aren’t at the point where you can do something like that. And the value of being able to do that accurately is incredibly high.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What happens to junior lawyers who are no longer getting the apprenticeship they might have had in the past?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;I care about this potentially more than anything else at the company because I was a junior lawyer very recently. The goal of law firms in the next five to ten years is: how fast can you train the best partners? &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think right now, that’s partially the goal, but partially the goal is we hire armies of associates and bill them out a lot. Whether it’s because things become outcome-based pricing or because partners can charge more if AI systems can’t do what they do, the most important thing financially for a law firm is to make sure you’re hiring, training and developing lawyers that get to being a partner as fast as humanly possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you can build tools that can do the first pass of an M&amp;amp;A, that is a one-on-one tutor for a junior associate. We work with a lot of law schools. You can imagine at some point you have an AI merger that you do in Harvey — the system’s teaching you, giving you real-time feedback. That’s an incredible training system. If you can build systems that can actually do a lot of the tasks, there’s no reason you couldn’t turn that into one of the best education platforms possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: With your valuation jumping from $3 billion to $8 billion in less than a year, what are your plans for future fundraising?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Fundraising large rounds is not something we have planned anytime soon. We don’t need that much money, and we aren’t burning a crazy amount. The reason I did a lot of fundraising this year is there are research directions that are going to require a lot of compute, and we wanted to prepare ourselves for that. In terms of public markets, that’s definitely what we’re interested in long term. I can’t give you anything close to a timeline, but we’re interested.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Screenshot-2025-11-14-at-11.50.31-AM.png?resize=1200,863" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Legal AI might not sound like the sexiest category in Silicon Valley, but Harvey‘s CEO Winston Weinberg has captured the attention of virtually every top-tier investor in the Valley. The company’s cap table reads like a who’s who of venture capital: the OpenAI Startup Fund (its first institutional investor), Sequoia Capital, Kleiner Perkins, Elad Gil, Google Ventures, Coatue, and most recently, Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The San Francisco-based company’s valuation skyrocketed from $3 billion in February 2025 to $5 billion in June to $8 billion in late October — a rise that reflects both the bonkers price tags awarded to AI companies, and Harvey’s ability to win over major law firms and corporate legal departments. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In fact, the startup now claims 235 clients across 63 countries, including a majority of the top 10 U.S. law firms. It also says it surpassed $100 million in annual recurring revenue as of August.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch spoke with Weinberg for this week’s StrictlyVC Download podcast to ask about the wild ride that he and co-founder Gabe Pereyra have been on so far. During that chat, he shared how a cold email sent a few summers ago to Sam Altman changed everything; why he believes lawyers will benefit rather than suffer from AI; and how Harvey is tackling the technically complex challenge of building a truly multiplayer platform that navigates ethical walls and data permissioning across dozens of countries.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This interview has been edited lightly for length. For the full monty, check out the podcast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TechCrunch: You started as a first-year associate at O’Melveny &amp;amp; Myers. When did you realize AI could transform legal work?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Winston Weinberg: &lt;/strong&gt;So my co-founder was working at Meta at the time; he was also my roommate. He was showing me GPT-3, and in the beginning, I swear to God, the main use case I had for it was running a &lt;em&gt;Dungeons and Dragons&lt;/em&gt; game with friends in LA. Then I was assigned to this landlord-tenant case at O’Melveny, and I didn’t know anything about landlord-tenant law. I started using GPT-3 to work on it.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;My co-founder Gabe and I figured out we could do chain-of-thought prompting before that was really a thing. We created this super long chain-of-thought prompt over California landlord-tenant statutes. We grabbed 100 questions from r/legaladvice [on Reddit] and ran that prompt over them, then gave the question-answer pairs to three landlord-tenant attorneys without saying anything about AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We just said, “A potential customer asked this question, here’s the answer—would you make any edits or would you send this as is?” On 86 of the 100 samples, two out of three attorneys or more said they would send it with zero edits. That was the moment when we were like, wow, this entire industry can be transformed by this technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What happened next?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;We cold-emailed Sam Altman and Jason Kwon, who was the general counsel at OpenAI. We figured we had to email a lawyer because otherwise the person wouldn’t know if the outputs were right. On the morning of July 4 at 10 a.m. — I remember this specifically because it was July 4 — we got on a call with them and kind of the rest of the C-suite at OpenAI, and we made our pitch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Did they write a check right away?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Yeah. It’s the OpenAI Startup Fund [they are the second-largest investor in Harvey]. OpenAI introduced us to our angel investors at the time, Sarah Guo and Elad Gil, and then everything else from there we were doing ourselves. I actually didn’t have any friends that worked in tech. I didn’t grow up in San Francisco. I didn’t know who the top VCs were. I didn’t understand how you’re supposed to fundraise. This was all just net new to me.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: For someone who wasn’t familiar with the VC scene, you’ve raised a lot of money. What enabled you to raise so much?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;I might say something the VC community might not love, but I strongly believe that the best way to raise money is to just make sure your company is doing super well. I think there’s a lot of advice out there about networking, but to me, the most important thing is to spend almost the entire time on your business, and then find VCs who want to do that with you. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You need to find a few partners who you think are going to go the distance with you. So, 99% of your time, focus on the business going well, and then spend time trying to find a few folks who you really think you can partner with and who will be there for you for the long run.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: You hit $100 million in ARR in August. With around 400 employees, how close are you to break-even?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Compute costs are more expensive for us than a lot of other things. We’re operating in more than 60 countries with data residency laws in all of them. For a long time, if you used multiple models in your product, you had to buy a bucket of compute — a minimum threshold — in every single one of those countries, even if you didn’t have enough clients yet to support that cost.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Germany and Australia have incredibly strict data processing laws. You cannot send financial data outside of those countries. We’d set up Azure or AWS instances in every single one of those countries, but we’d only use them to close three or four large clients. Our margins look very good on a token basis, but they’re worse because we have to spend so much on upfront compute across so many jurisdictions. That will get solved over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Tell us about your sales process. How are you expanding globally?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;At the beginning of this year, about 4% of our revenue was from corporates and 96% from law firms. Right now, 33% of our revenue is from corporates, and my gut says, by the end of the year, that looks closer to 40%.&lt;br /&gt;In the beginning, we would take public litigation briefs from Pacer, find the partner who wrote it, put them into Harvey, and show them how they could argue against their own brief. That got massive attention because it was relevant to what they just did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But what was interesting is once we got adoption at law firms, the law firms themselves would help us pitch to corporates. A firm like Latham will introduce Harvey to clients and say, “Hey, did you know this is how we can use AI to do XYZ?” So what started happening was law firms would actually help us sell to corporates because they want to collaborate in the system.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: You refer to this as “multiplayer.” Can you expound on this as a growing area of focus?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;This is a huge problem. You’ve seen announcements from OpenAI and Microsoft about shared threads and company memory. That’s hard — you have to get the permissioning right so agents can access the right systems. But you’re only solving it for one entity at a time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The secondary problem we have is: How do you solve that for a company plus all its law firms? You need to get the permissioning right internally and externally. There’s a concept in law called ethical walls. Think about a law firm in the valley that works with 20 VCs. If you’re working on a deal for Sequoia, but also working on another deal for Kleiner Perkins, what happens if you accidentally give all the data on the Sequoia deal to Kleiner Perkins? Huge, astronomical problem. We have to solve internal permissioning and external permissioning so agents can work correctly, and if you get it wrong, you’re going to have disastrous impacts on the industry.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Have you solved this?&lt;/strong&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;It’s definitely in process. We’re doing all of the security and the permissioning first. The first version of this at scale will probably be done in December. The nice thing is because such a high percentage of our customer base are already corporates using Harvey, the security problem is much easier because they’ve already gone through security review.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: How &lt;em&gt;are&lt;/em&gt; lawyers primarily using Harvey today?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Number one is drafting. Number two is research — that’s emerging because we just have a partnership with LexisNexis. And the third is analyze. What I mean by analyze is running 10 questions over 100,000 documents, like what you do in diligence or discovery.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the beginning, we had much more transactional use cases — M&amp;amp;A and fund formation. Those are still very popular, and we’re building modules specifically for those matters. The area that’s growing faster is litigation, and a lot of that is because you needed the data before you could do it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: Some critics have said Harvey is just a wrapper for ChatGPT. How do you respond?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;The largest advantage we have over time is two things. One, we’re collecting a tremendous amount of workflow data — what are the main use cases these models can actually do? Evaluation becomes a pretty strong moat, because how do you evaluate the quality of a merger agreement? That becomes really hard. You have to set up evaluation frameworks and agentic systems that can self-eval all the different steps.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second strongest moat is our product is becoming very strongly multiplayer. This industry has two sides — providers of legal services and consumers. You need to build a platform that’s in between both. So far, I haven’t seen a competitor doing that. We have competitors doing what we do for law firms, and competitors doing what we do for in-house, but I haven’t seen someone build a truly multiplayer platform.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of the “ChatGPT wrapper” criticism, for 2023 and 2024, a lot of the power behind the product is honestly the model, plus front-end work that makes the UI and UX easier. But if you’re trying to build something where I have 100,000 documents in this data room, 5,000 emails about this M&amp;amp;A, all these different statutes and codes, and I want a system where I can ask questions over all of those pieces combined with high accuracy — that’s the holy grail. We’ve created all the pieces, and what we’ve been building for the past couple months is pulling that together.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What’s your business model?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg:&lt;/strong&gt; Right now it’s mostly seats, but we’re moving to more outcome-based pricing as the workflows get more complex. You want to do both. You want outcome-based pricing for very small things that you can ensure have the exact same level of accuracy as a human, or better, with very high speed. But the reality is, you’re going to want a lawyer in the loop for so much of work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For at least the next year or two, it’s a productivity suite sold seat-based and multiplayer between law firms and their in-house teams. Slowly over time, we’ll build more consumption-based workflows as the systems get better and more accurate than humans in some areas. But it’s not going to be like you automate an entire M&amp;amp;A — it’s going to be specific pieces of diligence where you can have disclosure agents automate the first pass, then have lawyers jump in and do the rest.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: You mentioned to us earlier that penetration is really low in legal. How low?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;What percentage of the lawyers on Earth are using Harvey right now? It’s a super low percentage. There are 8 or 9 million lawyers on Earth. But the more interesting point is we are in the unbelievably early innings on how complex work these systems can do. They’re very helpful and people are getting incredible ROI, but if you think about what percentage of legal work these systems can do today versus what I think it can do in the next five years, it’s so much lower.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Think about the use case as, what is the value per token. The legal fees for a merger could easily be tens of millions of dollars. The artifact you have after that merger is a merger agreement and an SPA — maybe 200 pages total. What is the value per token on that document that required $20 million or $30 million of legal fees to generate? Those are the types of use cases where, when I say we’re at incredibly low penetration, it’s that we aren’t at the point where you can do something like that. And the value of being able to do that accurately is incredibly high.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: What happens to junior lawyers who are no longer getting the apprenticeship they might have had in the past?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;I care about this potentially more than anything else at the company because I was a junior lawyer very recently. The goal of law firms in the next five to ten years is: how fast can you train the best partners? &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;I think right now, that’s partially the goal, but partially the goal is we hire armies of associates and bill them out a lot. Whether it’s because things become outcome-based pricing or because partners can charge more if AI systems can’t do what they do, the most important thing financially for a law firm is to make sure you’re hiring, training and developing lawyers that get to being a partner as fast as humanly possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If you can build tools that can do the first pass of an M&amp;amp;A, that is a one-on-one tutor for a junior associate. We work with a lot of law schools. You can imagine at some point you have an AI merger that you do in Harvey — the system’s teaching you, giving you real-time feedback. That’s an incredible training system. If you can build systems that can actually do a lot of the tasks, there’s no reason you couldn’t turn that into one of the best education platforms possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;TC: With your valuation jumping from $3 billion to $8 billion in less than a year, what are your plans for future fundraising?&lt;/strong&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Weinberg: &lt;/strong&gt;Fundraising large rounds is not something we have planned anytime soon. We don’t need that much money, and we aren’t burning a crazy amount. The reason I did a lot of fundraising this year is there are research directions that are going to require a lot of compute, and we wanted to prepare ourselves for that. In terms of public markets, that’s definitely what we’re interested in long term. I can’t give you anything close to a timeline, but we’re interested.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/14/inside-harvey-how-a-first-year-legal-associate-built-one-of-silicon-valleys-hottest-startups/</guid><pubDate>Fri, 14 Nov 2025 11:57:24 +0000</pubDate></item><item><title>[NEW] Researchers question Anthropic claim that AI-assisted attack was 90% autonomous (AI – Ars Technica)</title><link>https://arstechnica.com/security/2025/11/researchers-question-anthropic-claim-that-ai-assisted-attack-was-90-autonomous/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The results of AI-assisted hacking aren’t as impressive as many might have us believe.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers from Anthropic said they recently observed the “first reported AI-orchestrated cyber espionage campaign” after detecting China-state hackers using the company’s Claude AI tool in a campaign targeting dozens of targets. Outside researchers are much more measured in describing the significance of the discovery.&lt;/p&gt;
&lt;p&gt;Anthropic published the reports on Thursday here and here. In September, the reports said, Anthropic discovered a “highly sophisticated espionage campaign,” carried out by a Chinese state-sponsored group, that used Claude Code to automate up to 90 percent of the work. Human intervention was required “only sporadically (perhaps 4-6 critical decision points per hacking campaign).” Anthropic said the hackers had employed AI agentic capabilities to an “unprecedented” extent.&lt;/p&gt;
&lt;p&gt;“This campaign has substantial implications for cybersecurity in the age of AI ‘agents’—systems that can be run autonomously for long periods of time and that complete complex tasks largely independent of human intervention,” Anthropic said. “Agents are valuable for everyday work and productivity—but in the wrong hands, they can substantially increase the viability of large-scale cyberattacks.”&lt;/p&gt;
&lt;h2&gt;“Ass-kissing, stonewalling, and acid trips”&lt;/h2&gt;
&lt;p&gt;Outside researchers weren’t convinced the discovery was the watershed moment the Anthropic posts made it out to be. They questioned why these sorts of advances are often attributed to malicious hackers when white-hat hackers and developers of legitimate software keep reporting only incremental gains from their use of AI.&lt;/p&gt;
&lt;p&gt;“I continue to refuse to believe that attackers are somehow able to get these models to jump through hoops that nobody else can,” Dan Tentler, executive founder of Phobos Group and a researcher with expertise in complex security breaches, told Ars. “Why do the models give these attackers what they want 90% of the time but the rest of us have to deal with ass-kissing, stonewalling, and acid trips?”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Researchers don’t deny that AI tools can improve workflow and shorten the time required for certain tasks, such as triage, log analysis, and reverse engineering. But the ability for AI to automate a complex chain of tasks with such minimal human interaction remains elusive. Many researchers compare advances from AI in cyberattacks to those provided by hacking tools such as Metasploit or SEToolkit, which have been in use for decades. There’s no doubt that these tools are useful, but their advent didn’t meaningfully increase hackers’ capabilities or the severity of the attacks they produced.&lt;/p&gt;
&lt;p&gt;Another reason the results aren’t as impressive as made out to be: The threat actors—which Anthropic tracks as GTG-1002—targeted at least 30 organizations, including major technology corporations and government agencies. Of those, only a “small number” of the attacks succeeded. That, in turn, raises questions. Even assuming so much human interaction was eliminated from the process, what good is that when the success rate is so low? Would the number of successes have increased if the attackers had used more traditional, human-involved methods?&lt;/p&gt;
&lt;p&gt;According to Anthropic’s account, the hackers used Claude to orchestrate attacks using readily available open source software and frameworks. These tools have existed for years and are already easy for defenders to detect. Anthropic didn’t detail the specific techniques, tooling, or exploitation that occurred in the attacks, but so far, there’s no indication that the use of AI made them more potent or stealthy than more traditional techniques.&lt;/p&gt;
&lt;p&gt;“The threat actors aren’t inventing something new here,” independent researcher Kevin Beaumont said.&lt;/p&gt;
&lt;p&gt;Even Anthropic noted “an important limitation” in its findings:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;Claude frequently overstated findings and occasionally fabricated data during autonomous operations, claiming to have obtained credentials that didn’t work or identifying critical discoveries that proved to be publicly available information. This AI hallucination in offensive security contexts presented challenges for the actor’s operational effectiveness, requiring careful validation of all claimed results. This remains an obstacle to fully autonomous cyberattacks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;How (Anthropic says) the attack unfolded&lt;/h2&gt;
&lt;p&gt;Anthropic said GTG-1002 developed an autonomous attack framework that used Claude as an orchestration mechanism that largely eliminated the need for human involvement. This orchestration system broke complex multi-stage attacks into smaller technical tasks such as vulnerability scanning, credential validation, data extraction, and lateral movement.&lt;/p&gt;
&lt;p&gt;“The architecture incorporated Claude’s technical capabilities as an execution engine within a larger automated system, where the AI performed specific technical actions based on the human operators’ instructions while the orchestration logic maintained attack state, managed phase transitions, and aggregated results across multiple sessions,” Anthropic said. “This approach allowed the threat actor to achieve operational scale typically associated with nation-state campaigns while maintaining minimal direct involvement, as the framework autonomously progressed through reconnaissance, initial access, persistence, and data exfiltration phases by sequencing Claude’s responses and adapting subsequent requests based on discovered information.”&lt;/p&gt;
&lt;p&gt;The attacks followed a five-phase structure that increased AI autonomy through each one.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127439 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="762" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/5-phase-cyberattack-claude-1024x762.webp" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The life cycle of the cyberattack, showing the move from human-led targeting to largely AI-driven attacks using various tools, often via the Model Context Protocol (MCP). At various points during the attack, the AI returns to its human operator for review and further direction.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The attackers were able to bypass Claude guardrails in part by breaking tasks into small steps that, in isolation, the AI tool didn’t interpret as malicious. In other cases, the attackers couched their inquiries in the context of security professionals trying to use Claude to improve defenses.&lt;/p&gt;
&lt;p&gt;As noted last week, AI-developed malware has a long way to go before it poses a real-world threat. There’s no reason to doubt that AI-assisted cyberattacks may one day produce more potent attacks. But the data so far indicates that threat actors—like most others using AI—are seeing mixed results that aren’t nearly as impressive as those in the AI industry claim.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The results of AI-assisted hacking aren’t as impressive as many might have us believe.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="An &amp;quot;AI&amp;quot; balloon floating close to a sharp, upturned push pin." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/10/ai_bubble_hero2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Wong Yu Liang via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Researchers from Anthropic said they recently observed the “first reported AI-orchestrated cyber espionage campaign” after detecting China-state hackers using the company’s Claude AI tool in a campaign targeting dozens of targets. Outside researchers are much more measured in describing the significance of the discovery.&lt;/p&gt;
&lt;p&gt;Anthropic published the reports on Thursday here and here. In September, the reports said, Anthropic discovered a “highly sophisticated espionage campaign,” carried out by a Chinese state-sponsored group, that used Claude Code to automate up to 90 percent of the work. Human intervention was required “only sporadically (perhaps 4-6 critical decision points per hacking campaign).” Anthropic said the hackers had employed AI agentic capabilities to an “unprecedented” extent.&lt;/p&gt;
&lt;p&gt;“This campaign has substantial implications for cybersecurity in the age of AI ‘agents’—systems that can be run autonomously for long periods of time and that complete complex tasks largely independent of human intervention,” Anthropic said. “Agents are valuable for everyday work and productivity—but in the wrong hands, they can substantially increase the viability of large-scale cyberattacks.”&lt;/p&gt;
&lt;h2&gt;“Ass-kissing, stonewalling, and acid trips”&lt;/h2&gt;
&lt;p&gt;Outside researchers weren’t convinced the discovery was the watershed moment the Anthropic posts made it out to be. They questioned why these sorts of advances are often attributed to malicious hackers when white-hat hackers and developers of legitimate software keep reporting only incremental gains from their use of AI.&lt;/p&gt;
&lt;p&gt;“I continue to refuse to believe that attackers are somehow able to get these models to jump through hoops that nobody else can,” Dan Tentler, executive founder of Phobos Group and a researcher with expertise in complex security breaches, told Ars. “Why do the models give these attackers what they want 90% of the time but the rest of us have to deal with ass-kissing, stonewalling, and acid trips?”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Researchers don’t deny that AI tools can improve workflow and shorten the time required for certain tasks, such as triage, log analysis, and reverse engineering. But the ability for AI to automate a complex chain of tasks with such minimal human interaction remains elusive. Many researchers compare advances from AI in cyberattacks to those provided by hacking tools such as Metasploit or SEToolkit, which have been in use for decades. There’s no doubt that these tools are useful, but their advent didn’t meaningfully increase hackers’ capabilities or the severity of the attacks they produced.&lt;/p&gt;
&lt;p&gt;Another reason the results aren’t as impressive as made out to be: The threat actors—which Anthropic tracks as GTG-1002—targeted at least 30 organizations, including major technology corporations and government agencies. Of those, only a “small number” of the attacks succeeded. That, in turn, raises questions. Even assuming so much human interaction was eliminated from the process, what good is that when the success rate is so low? Would the number of successes have increased if the attackers had used more traditional, human-involved methods?&lt;/p&gt;
&lt;p&gt;According to Anthropic’s account, the hackers used Claude to orchestrate attacks using readily available open source software and frameworks. These tools have existed for years and are already easy for defenders to detect. Anthropic didn’t detail the specific techniques, tooling, or exploitation that occurred in the attacks, but so far, there’s no indication that the use of AI made them more potent or stealthy than more traditional techniques.&lt;/p&gt;
&lt;p&gt;“The threat actors aren’t inventing something new here,” independent researcher Kevin Beaumont said.&lt;/p&gt;
&lt;p&gt;Even Anthropic noted “an important limitation” in its findings:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;Claude frequently overstated findings and occasionally fabricated data during autonomous operations, claiming to have obtained credentials that didn’t work or identifying critical discoveries that proved to be publicly available information. This AI hallucination in offensive security contexts presented challenges for the actor’s operational effectiveness, requiring careful validation of all claimed results. This remains an obstacle to fully autonomous cyberattacks.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h2&gt;How (Anthropic says) the attack unfolded&lt;/h2&gt;
&lt;p&gt;Anthropic said GTG-1002 developed an autonomous attack framework that used Claude as an orchestration mechanism that largely eliminated the need for human involvement. This orchestration system broke complex multi-stage attacks into smaller technical tasks such as vulnerability scanning, credential validation, data extraction, and lateral movement.&lt;/p&gt;
&lt;p&gt;“The architecture incorporated Claude’s technical capabilities as an execution engine within a larger automated system, where the AI performed specific technical actions based on the human operators’ instructions while the orchestration logic maintained attack state, managed phase transitions, and aggregated results across multiple sessions,” Anthropic said. “This approach allowed the threat actor to achieve operational scale typically associated with nation-state campaigns while maintaining minimal direct involvement, as the framework autonomously progressed through reconnaissance, initial access, persistence, and data exfiltration phases by sequencing Claude’s responses and adapting subsequent requests based on discovered information.”&lt;/p&gt;
&lt;p&gt;The attacks followed a five-phase structure that increased AI autonomy through each one.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2127439 align-center"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="center large" height="762" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/5-phase-cyberattack-claude-1024x762.webp" width="1024" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The life cycle of the cyberattack, showing the move from human-led targeting to largely AI-driven attacks using various tools, often via the Model Context Protocol (MCP). At various points during the attack, the AI returns to its human operator for review and further direction.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The attackers were able to bypass Claude guardrails in part by breaking tasks into small steps that, in isolation, the AI tool didn’t interpret as malicious. In other cases, the attackers couched their inquiries in the context of security professionals trying to use Claude to improve defenses.&lt;/p&gt;
&lt;p&gt;As noted last week, AI-developed malware has a long way to go before it poses a real-world threat. There’s no reason to doubt that AI-assisted cyberattacks may one day produce more potent attacks. But the data so far indicates that threat actors—like most others using AI—are seeing mixed results that aren’t nearly as impressive as those in the AI industry claim.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/security/2025/11/researchers-question-anthropic-claim-that-ai-assisted-attack-was-90-autonomous/</guid><pubDate>Fri, 14 Nov 2025 12:20:48 +0000</pubDate></item></channel></rss>