<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 20 Jun 2025 18:30:35 +0000</lastBuildDate><item><title> ()</title><link>https://www.wired.com/feed/category/artificial-intelligence/rss</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://www.wired.com/feed/category/artificial-intelligence/rss</guid></item><item><title>Calorie restriction can help animals live longer. What about humans? (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/20/1119073/calorie-restriction-live-longer/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/calorie-restriction.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Living comes with a side effect: aging. Despite what you might hear on social media or in advertisements, there are no drugs that are known to slow or reverse human aging. But there’s some evidence to support another approach: cutting back on calories.&lt;/p&gt;  &lt;p&gt;Caloric restriction (reducing your intake of calories) and intermittent fasting (switching between fasting and eating normally on a fixed schedule) can help with weight loss. But they may also offer protection against some health conditions. And some believe such diets might even help you live longer—a finding supported by new research out this week. (Longevity enthusiast Bryan Johnson famously claims to eat his last meal of the day at 12pm.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;But the full picture is not so simple. Weight loss isn’t always healthy and neither is restricting your calorie intake, especially if your BMI is low to begin with. Some scientists warn that, based on evidence in animals, it could negatively impact wound healing, metabolism and bone density. This week let’s take a closer look at the benefits—and risks—of caloric restriction.&lt;/p&gt;  &lt;p&gt;Eating less can make animals live longer. This remarkable finding has been published in scientific journals for the last 100 years. It seems to work in almost every animal studied—everything from tiny nematode worms and fruit flies to mice, rats, and even monkeys. It can extend the lifespan of rodents by between 15% and 60%, depending on which study you look at.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;The effect of caloric restriction is more reliable than the leading contenders for an “anti-aging” drug.&lt;/strong&gt; Both rapamycin (an immunosuppressive drug used in organ transplants) and metformin (a diabetes drug) have been touted as potential longevity therapeutics. And both have been found to increase the lifespans of animals in some studies.&lt;/p&gt;  &lt;p&gt;But when scientists looked at 167 published studies of those three interventions in research animals, they found that caloric restriction was the most “robust.” According to&amp;nbsp;their research, published in the journal &lt;em&gt;Aging Cell&lt;/em&gt; on Wednesday, the effect of rapamycin was somewhat comparable, but metformin was nowhere near as effective.&lt;/p&gt; 
 &lt;p&gt;“That is a pity for the many people now taking off-label metformin for lifespan extension,” David Clancy, lecturer in biogerontology at Lancaster University, said in a statement. “Let’s hope it doesn’t have any or many adverse effects.” Still, for caloric restriction, so far so good.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;At least it’s good news for lab animals. What about people?&lt;/strong&gt; Also on Wednesday, another team of scientists published a separate review of research investigating the effects of caloric restriction and fasting on humans. That review assessed 99 clinical trials, involving over 6,500 adults. (As I said, caloric restriction has been an active area of research for a long time.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Those researchers found that, across all those trials, fasting and caloric restriction did seem to aid weight loss. There were other benefits, too—but they depended on the specific approach to dieting. Fasting every other day seemed to help lower cholesterol, for example. Time-restricted eating, where you only eat within a specific period each day (à la Bryan Johnson), by comparison, seemed to &lt;em&gt;increase&lt;/em&gt; cholesterol, the researchers&amp;nbsp;write in the &lt;em&gt;BMJ&lt;/em&gt;. Given that elevated cholesterol in the blood can lead to heart disease, it’s not great news for the time-restricted eaters.&lt;/p&gt;  &lt;p&gt;Cutting calories&amp;nbsp;could also carry broader risks. Dietary restriction seems to impair wound healing in mice and rats, for example. Caloric restriction also seems to affect bone density. In some studies, the biggest effects on lifespan extension are seen when rats are put on calorie-restricted diets early in life. But this approach can affect bone development and reduce bone density by 9% to 30%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;&lt;strong&gt;It’s also &lt;em&gt;really hard&lt;/em&gt; for most people to cut their caloric intake. &lt;/strong&gt;When researchers ran a two-year trial to measure the impact of a 25% reduction in caloric intake, they found that&amp;nbsp;the most their volunteers could cut was 12%. (That study found that caloric restriction reduces markers of inflammation, which can be harmful when it’s chronic, and had only a small impact on bone density.)&lt;/p&gt;  &lt;p&gt;Unfortunately, there’s a lot we still don’t really understand about caloric restriction. It doesn’t seem to help &lt;em&gt;all&lt;/em&gt; animals live longer—it seems to shorten the lifespan of animals with certain genetic backgrounds. And we don’t know whether it extends the lifespan of people. It isn’t possible to conduct a randomized clinical trial in which you deprive people of food from childhood and then wait their entire lives to see when they die.&lt;/p&gt;  &lt;p&gt;It is notoriously difficult to track or change your diet. And given the unknowns surrounding caloric restriction, it’s too soon to make sweeping recommendations, particularly given that your own personal biology will play a role in any benefits or risks you’ll experience. Roll on the next round of research.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/calorie-restriction.jpeg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Living comes with a side effect: aging. Despite what you might hear on social media or in advertisements, there are no drugs that are known to slow or reverse human aging. But there’s some evidence to support another approach: cutting back on calories.&lt;/p&gt;  &lt;p&gt;Caloric restriction (reducing your intake of calories) and intermittent fasting (switching between fasting and eating normally on a fixed schedule) can help with weight loss. But they may also offer protection against some health conditions. And some believe such diets might even help you live longer—a finding supported by new research out this week. (Longevity enthusiast Bryan Johnson famously claims to eat his last meal of the day at 12pm.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;But the full picture is not so simple. Weight loss isn’t always healthy and neither is restricting your calorie intake, especially if your BMI is low to begin with. Some scientists warn that, based on evidence in animals, it could negatively impact wound healing, metabolism and bone density. This week let’s take a closer look at the benefits—and risks—of caloric restriction.&lt;/p&gt;  &lt;p&gt;Eating less can make animals live longer. This remarkable finding has been published in scientific journals for the last 100 years. It seems to work in almost every animal studied—everything from tiny nematode worms and fruit flies to mice, rats, and even monkeys. It can extend the lifespan of rodents by between 15% and 60%, depending on which study you look at.&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;The effect of caloric restriction is more reliable than the leading contenders for an “anti-aging” drug.&lt;/strong&gt; Both rapamycin (an immunosuppressive drug used in organ transplants) and metformin (a diabetes drug) have been touted as potential longevity therapeutics. And both have been found to increase the lifespans of animals in some studies.&lt;/p&gt;  &lt;p&gt;But when scientists looked at 167 published studies of those three interventions in research animals, they found that caloric restriction was the most “robust.” According to&amp;nbsp;their research, published in the journal &lt;em&gt;Aging Cell&lt;/em&gt; on Wednesday, the effect of rapamycin was somewhat comparable, but metformin was nowhere near as effective.&lt;/p&gt; 
 &lt;p&gt;“That is a pity for the many people now taking off-label metformin for lifespan extension,” David Clancy, lecturer in biogerontology at Lancaster University, said in a statement. “Let’s hope it doesn’t have any or many adverse effects.” Still, for caloric restriction, so far so good.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;At least it’s good news for lab animals. What about people?&lt;/strong&gt; Also on Wednesday, another team of scientists published a separate review of research investigating the effects of caloric restriction and fasting on humans. That review assessed 99 clinical trials, involving over 6,500 adults. (As I said, caloric restriction has been an active area of research for a long time.)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Those researchers found that, across all those trials, fasting and caloric restriction did seem to aid weight loss. There were other benefits, too—but they depended on the specific approach to dieting. Fasting every other day seemed to help lower cholesterol, for example. Time-restricted eating, where you only eat within a specific period each day (à la Bryan Johnson), by comparison, seemed to &lt;em&gt;increase&lt;/em&gt; cholesterol, the researchers&amp;nbsp;write in the &lt;em&gt;BMJ&lt;/em&gt;. Given that elevated cholesterol in the blood can lead to heart disease, it’s not great news for the time-restricted eaters.&lt;/p&gt;  &lt;p&gt;Cutting calories&amp;nbsp;could also carry broader risks. Dietary restriction seems to impair wound healing in mice and rats, for example. Caloric restriction also seems to affect bone density. In some studies, the biggest effects on lifespan extension are seen when rats are put on calorie-restricted diets early in life. But this approach can affect bone development and reduce bone density by 9% to 30%.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt;&lt;p&gt;&lt;strong&gt;It’s also &lt;em&gt;really hard&lt;/em&gt; for most people to cut their caloric intake. &lt;/strong&gt;When researchers ran a two-year trial to measure the impact of a 25% reduction in caloric intake, they found that&amp;nbsp;the most their volunteers could cut was 12%. (That study found that caloric restriction reduces markers of inflammation, which can be harmful when it’s chronic, and had only a small impact on bone density.)&lt;/p&gt;  &lt;p&gt;Unfortunately, there’s a lot we still don’t really understand about caloric restriction. It doesn’t seem to help &lt;em&gt;all&lt;/em&gt; animals live longer—it seems to shorten the lifespan of animals with certain genetic backgrounds. And we don’t know whether it extends the lifespan of people. It isn’t possible to conduct a randomized clinical trial in which you deprive people of food from childhood and then wait their entire lives to see when they die.&lt;/p&gt;  &lt;p&gt;It is notoriously difficult to track or change your diet. And given the unknowns surrounding caloric restriction, it’s too soon to make sweeping recommendations, particularly given that your own personal biology will play a role in any benefits or risks you’ll experience. Roll on the next round of research.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/20/1119073/calorie-restriction-live-longer/</guid><pubDate>Fri, 20 Jun 2025 09:00:00 +0000</pubDate></item><item><title>Unlock the other 99% of your data – now ready for AI (AI News)</title><link>https://www.artificialintelligence-news.com/news/unlock-the-other-99-of-your-data-now-ready-for-ai/</link><description>&lt;p&gt;For decades, companies of all sizes have recognized that the data available to them holds significant value, for improving user and customer experiences and for developing strategic plans based on empirical evidence.&lt;/p&gt;&lt;p&gt;As AI becomes increasingly accessible and practical for real-world business applications, the potential value of available data has grown exponentially. Successfully adopting AI requires significant effort in data collection, curation, and preprocessing. Moreover, important aspects such as data governance, privacy, anonymization, regulatory compliance, and security must be addressed carefully from the outset.&lt;/p&gt;&lt;p&gt;In a conversation with Henrique Lemes, Americas Data Platform Leader at IBM, we explored the challenges enterprises face in implementing practical AI in a range of use cases. We began by examining the nature of data itself, its various types, and its role in enabling effective AI-powered applications.&lt;/p&gt;&lt;p&gt;Henrique highlighted that referring to all enterprise information simply as ‘data’ understates its complexity. The modern enterprise navigates a fragmented landscape of diverse data types and inconsistent quality, particularly between structured and unstructured sources.&lt;/p&gt;&lt;p&gt;In simple terms, structured data refers to information that is organized in a standardized and easily searchable format, one that enables efficient processing and analysis by software systems.&lt;/p&gt;&lt;p&gt;Unstructured data is information that does not follow a predefined format nor organizational model, making it more complex to process and analyze. Unlike structured data, it includes diverse formats like emails, social media posts, videos, images, documents, and audio files. While it lacks the clear organization of structured data, unstructured data holds valuable insights that, when effectively managed through advanced analytics and AI, can drive innovation and inform strategic business decisions.&lt;/p&gt;&lt;p&gt;Henrique stated, “Currently, less than 1% of enterprise data is utilized by generative AI, and over 90% of that data is unstructured, which directly affects trust and quality”.&lt;/p&gt;&lt;p&gt;The element of trust in terms of data is an important one. Decision-makers in an organization need firm belief (trust) that the information at their fingertips is complete, reliable, and properly obtained. But there is evidence that states less than half of data available to businesses is used for AI, with unstructured data often going ignored or sidelined due to the complexity of processing it and examining it for compliance – especially at scale.&lt;/p&gt;&lt;p&gt;To open the way to better decisions that are based on a fuller set of empirical data, the trickle of easily consumed information needs to be turned into a firehose. Automated ingestion is the answer in this respect, Henrique said, but the governance rules and data policies still must be applied – to unstructured and structured data alike.&lt;/p&gt;&lt;p&gt;Henrique set out the three processes that let enterprises leverage the inherent value of their data. “Firstly, ingestion at scale. It’s important to automate this process. Second, curation and data governance. And the third [is when] you make this available for generative AI. We achieve over 40% of ROI over any conventional RAG use-case.”&lt;/p&gt;&lt;p&gt;IBM provides a unified strategy, rooted in a deep understanding of the enterprise’s AI journey, combined with advanced software solutions and domain expertise. This enables organizations to efficiently and securely transform both structured and unstructured data into AI-ready assets, all within the boundaries of existing governance and compliance frameworks.&lt;/p&gt;&lt;p&gt;“We bring together the people, processes, and tools. It’s not inherently simple, but we simplify it by aligning all the essential resources,” he said.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full"&gt;&lt;img alt="alt" class="wp-image-106820" height="689" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/06/henrique-lemes-1.jpeg" width="689" /&gt;&lt;/figure&gt;&lt;p&gt;As businesses scale and transform, the diversity and volume of their data increase. To keep up, AI data ingestion process must be both scalable and flexible.&lt;/p&gt;&lt;p&gt;“[Companies] encounter difficulties when scaling because their AI solutions were initially built for specific tasks. When they attempt to broaden their scope, they often aren’t ready, the data pipelines grow more complex, and managing unstructured data becomes essential. This drives an increased demand for effective data governance,” he said.&lt;/p&gt;&lt;p&gt;IBM’s approach is to thoroughly understand each client’s AI journey, creating a clear roadmap to achieve ROI through effective AI implementation. “We prioritize data accuracy, whether structured or unstructured, along with data ingestion, lineage, governance, compliance with industry-specific regulations, and the necessary observability. These capabilities enable our clients to scale across multiple use cases and fully capitalize on the value of their data,” Henrique said.&lt;/p&gt;&lt;p&gt;Like anything worthwhile in technology implementation, it takes time to put the right processes in place, gravitate to the right tools, and have the necessary vision of how any data solution might need to evolve.&lt;/p&gt;&lt;p&gt;IBM offers enterprises a range of options and tooling to enable AI workloads in even the most regulated industries, at any scale. With international banks, finance houses, and global multinationals among its client roster, there are few substitutes for Big Blue in this context.&lt;/p&gt;&lt;p&gt;To find out more about enabling data pipelines for AI that drive business and offer fast, significant ROI, &lt;u&gt;head over to this page&lt;/u&gt;.&lt;/p&gt;</description><content:encoded>&lt;p&gt;For decades, companies of all sizes have recognized that the data available to them holds significant value, for improving user and customer experiences and for developing strategic plans based on empirical evidence.&lt;/p&gt;&lt;p&gt;As AI becomes increasingly accessible and practical for real-world business applications, the potential value of available data has grown exponentially. Successfully adopting AI requires significant effort in data collection, curation, and preprocessing. Moreover, important aspects such as data governance, privacy, anonymization, regulatory compliance, and security must be addressed carefully from the outset.&lt;/p&gt;&lt;p&gt;In a conversation with Henrique Lemes, Americas Data Platform Leader at IBM, we explored the challenges enterprises face in implementing practical AI in a range of use cases. We began by examining the nature of data itself, its various types, and its role in enabling effective AI-powered applications.&lt;/p&gt;&lt;p&gt;Henrique highlighted that referring to all enterprise information simply as ‘data’ understates its complexity. The modern enterprise navigates a fragmented landscape of diverse data types and inconsistent quality, particularly between structured and unstructured sources.&lt;/p&gt;&lt;p&gt;In simple terms, structured data refers to information that is organized in a standardized and easily searchable format, one that enables efficient processing and analysis by software systems.&lt;/p&gt;&lt;p&gt;Unstructured data is information that does not follow a predefined format nor organizational model, making it more complex to process and analyze. Unlike structured data, it includes diverse formats like emails, social media posts, videos, images, documents, and audio files. While it lacks the clear organization of structured data, unstructured data holds valuable insights that, when effectively managed through advanced analytics and AI, can drive innovation and inform strategic business decisions.&lt;/p&gt;&lt;p&gt;Henrique stated, “Currently, less than 1% of enterprise data is utilized by generative AI, and over 90% of that data is unstructured, which directly affects trust and quality”.&lt;/p&gt;&lt;p&gt;The element of trust in terms of data is an important one. Decision-makers in an organization need firm belief (trust) that the information at their fingertips is complete, reliable, and properly obtained. But there is evidence that states less than half of data available to businesses is used for AI, with unstructured data often going ignored or sidelined due to the complexity of processing it and examining it for compliance – especially at scale.&lt;/p&gt;&lt;p&gt;To open the way to better decisions that are based on a fuller set of empirical data, the trickle of easily consumed information needs to be turned into a firehose. Automated ingestion is the answer in this respect, Henrique said, but the governance rules and data policies still must be applied – to unstructured and structured data alike.&lt;/p&gt;&lt;p&gt;Henrique set out the three processes that let enterprises leverage the inherent value of their data. “Firstly, ingestion at scale. It’s important to automate this process. Second, curation and data governance. And the third [is when] you make this available for generative AI. We achieve over 40% of ROI over any conventional RAG use-case.”&lt;/p&gt;&lt;p&gt;IBM provides a unified strategy, rooted in a deep understanding of the enterprise’s AI journey, combined with advanced software solutions and domain expertise. This enables organizations to efficiently and securely transform both structured and unstructured data into AI-ready assets, all within the boundaries of existing governance and compliance frameworks.&lt;/p&gt;&lt;p&gt;“We bring together the people, processes, and tools. It’s not inherently simple, but we simplify it by aligning all the essential resources,” he said.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full"&gt;&lt;img alt="alt" class="wp-image-106820" height="689" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/06/henrique-lemes-1.jpeg" width="689" /&gt;&lt;/figure&gt;&lt;p&gt;As businesses scale and transform, the diversity and volume of their data increase. To keep up, AI data ingestion process must be both scalable and flexible.&lt;/p&gt;&lt;p&gt;“[Companies] encounter difficulties when scaling because their AI solutions were initially built for specific tasks. When they attempt to broaden their scope, they often aren’t ready, the data pipelines grow more complex, and managing unstructured data becomes essential. This drives an increased demand for effective data governance,” he said.&lt;/p&gt;&lt;p&gt;IBM’s approach is to thoroughly understand each client’s AI journey, creating a clear roadmap to achieve ROI through effective AI implementation. “We prioritize data accuracy, whether structured or unstructured, along with data ingestion, lineage, governance, compliance with industry-specific regulations, and the necessary observability. These capabilities enable our clients to scale across multiple use cases and fully capitalize on the value of their data,” Henrique said.&lt;/p&gt;&lt;p&gt;Like anything worthwhile in technology implementation, it takes time to put the right processes in place, gravitate to the right tools, and have the necessary vision of how any data solution might need to evolve.&lt;/p&gt;&lt;p&gt;IBM offers enterprises a range of options and tooling to enable AI workloads in even the most regulated industries, at any scale. With international banks, finance houses, and global multinationals among its client roster, there are few substitutes for Big Blue in this context.&lt;/p&gt;&lt;p&gt;To find out more about enabling data pipelines for AI that drive business and offer fast, significant ROI, &lt;u&gt;head over to this page&lt;/u&gt;.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/unlock-the-other-99-of-your-data-now-ready-for-ai/</guid><pubDate>Fri, 20 Jun 2025 09:34:00 +0000</pubDate></item><item><title>How a 30-year-old techno-thriller predicted our digital isolation (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/20/1118379/the-net-cyber-thriller-digital-isolation/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In April, Mark Zuckerberg, as tech billionaires are so fond of doing these days, pontificated at punishing length on a podcast. In the interview, he addressed America’s loneliness epidemic: “The average American has—I think it’s fewer than three friends. And the average person has demand for meaningfully more. I think it’s like 15 friends or something, right?”&lt;/p&gt;  &lt;p&gt;Before you’ve had a moment to register the ominous way in which he frames human connection in such bleak economic terms, he offers his solution to the loneliness epidemic: AI friends. Ideally AI friends &lt;em&gt;his&lt;/em&gt; company generates.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“It’s like I’m not even me anymore.”&lt;br /&gt;—Angela Bennett, &lt;em&gt;The Net&lt;/em&gt; (1995)&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Thirty years ago, Irwin Winkler’s proto–cyber thriller, &lt;em&gt;The Net&lt;/em&gt;, was released. It was 1995, commonly regarded as the year Hollywood &lt;em&gt;discovered&lt;/em&gt; the internet. Sandra Bullock played a social recluse and computer nerd for hire named Angela Bennett, who unwittingly uncovers a sinister computer security conspiracy. She soon finds her life turned upside down as the conspiracists begin systematically destroying her credibility and reputation. Her job, home, finances, and very identity are seemingly erased with some judicial tweaks to key computer records.&lt;/p&gt; 
 &lt;p&gt;Bennett is uniquely—conveniently, perhaps—well positioned for this identity annihilation. Her mother, in the throes of dementia, no longer recognizes her; she works from home for clients who have never met her; her social circle is limited to an online chat room; she orders takeout from Pizza.net; her neighbors don’t even know what she looks like. Her most reliable companion is the screen in front of her. A wild, unimaginable scenario that I’m sure none of us can relate to.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“Just think about it. Our whole world is sitting there on a computer. It’s in the computer, everything: your DMV records, your Social Security, your credit cards, your medical records. It’s all right there. Everyone is stored in there. It’s like this little electronic shadow on each and every one of us, just begging for someone to screw with, and you know what? They’ve done it to me, and you know what? They’re gonna do it to you.”&lt;br /&gt;—Angela Bennett, &lt;em&gt;The Net&lt;/em&gt;&lt;/p&gt; 
 &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;While the villain of &lt;em&gt;The Net&lt;/em&gt; is ultimately a nefarious cybersecurity software company, the film’s preoccupying fear is much more fundamental: If all of our data is digitized, what happens if the people with access to that information tamper with it? Or weaponize it against us?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This period of Hollywood’s flirtation with the internet is often referred to as the era of the technophobic thriller, but that’s a surface-level misreading. Techno-&lt;em&gt;skeptic&lt;/em&gt; might be more accurate. These films were broadly positive and excited about new technology; it almost always played a role in how the hero saved the day. Their bigger concern was with the humans who had ultimate control of these tools, and what oversight and restrictions we should place on them.&lt;/p&gt;  &lt;p&gt;In 2025, however, the most prescient part of &lt;em&gt;The Net&lt;/em&gt; is Angela Bennett’s digital alienation. What was originally a series of plausible enough contrivances to make the theft of her identity more believable is now just part of our everyday lives. We all bank, shop, eat, work, and socialize without necessarily seeing another human being in person. And we’ve all been through covid lockdowns where that isolation was actively encouraged. For a whole generation of young people who lived through that, socializing face to face is not second nature. In 2023, the World Health Organization declared loneliness to be a pressing global health threat, estimating that one in four older adults experience social isolation and between 5% and 15% of adolescents experience loneliness. In the US, social isolation may threaten public health more seriously than obesity.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;The Net&lt;/em&gt; appeared at a time when the internet was only faintly understood as the new Wild West … In that sense, it remains a fascinating time capsule of a moment when the possibilities to come felt endless, the outlook cautiously optimistic.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;We also spend increasing amounts of time looking at our phones, where finely tuned algorithms aggressively lobby for more and more of our ad-revenue-­generating attention. As Bennett warns: “Our whole lives are on the computer, and they knew that I could be vanished. They knew that nobody would care, that nobody would understand.” In this sense, in 2025 &lt;em&gt;we are all Angela Bennett&lt;/em&gt;. As Bennett’s digital alienation makes her more vulnerable to pernicious actors, so too are we increasingly at risk from those who don’t have, and have never had, our best interests at heart.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;To blame technology entirely for a rise in loneliness—as many policymakers are doing—would be a mistake. While it is unquestionably playing a part in exacerbating the problem, its outsize role in our lives has always reflected larger underlying factors. In &lt;em&gt;Multitudes: How Crowds Made the Modern World &lt;/em&gt;(2024), the journalist Dan Hancox examines the ways in which crowds have been demonized and othered by those in power and suggests that our alienation is much more structural: “Whether through government cuts or concessions to the expansive ambitions of private enterprise, a key reason we have all become a bit more crowd-shy in recent decades is the prolonged, top-down assault on public space and the wider public realm—what are sometimes called the urban commons. From properly funded libraries to pleasant, open parks and squares, free or affordable sports and leisure facilities, safe, accessible and cheap public transport, comfortable street furniture and free public toilets, and a vibrant, varied, uncommodified social and cultural life—all the best things about city life fall under the heading of the public realm, and all of them facilitate and support happy crowds rather than sad, alienated, stay-at-home loners.”&lt;/p&gt;  &lt;p&gt;Nearly half a century ago Margaret Thatcher laid out the neoliberal consensus that would frame the next decades of individualism: “There’s no such thing as society. There are individual men and women and there are families. And no government can do anything except through people, and people must look after themselves first.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1118694" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/TheNet2.jpg?w=1954" width="1954" /&gt;&lt;div class="image-credit"&gt;TOM HUMBERSTONE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In keeping with that philosophy, social connectivity has been outsourced to tech companies for which the attention economy is paramount. “The Algo” is our new, capricious god. If your livelihood depends on engagement, the temptation is to stop thinking about human connection when you post, and to think more about what will satisfy The Algo to ensure a good harvest.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;How much will you trust an AI chatbot powered by Meta to be your friend? Answers to this may vary. Even if you won’t, other people are already making close connections with “AI companions” or “falling in love” with ChatGPT. The rise of “cognitive offloading”—of people asking AI to do their critical thinking for them—is already well underway, with many high school and college students admitting to a deep reliance on the technology.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Beyond the obvious concern that AI “friends” are hallucinating, unthinking, obsequious algorithms that will never challenge you in the way a real friend might, it’s also worth remembering who AI actually works for. Recently Elon Musk’s own AI chatbot, Grok, was given new edicts that caused it to cast doubt on the Holocaust and talk about “white genocide” in response to unrelated prompts—a reminder, if we needed it, that these systems are never neutral, never apolitical, and always at the command of those with their hands on the code.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’m fairly lucky. I live with my partner and have a decent community of friends. But I work from home and can spend the majority of the day not talking to anyone. I’m not immune to feeling isolated, anxious, and powerless as I stare unblinking at my news feed. I think we all feel it. &lt;em&gt;We are all Angela Bennett&lt;/em&gt;. Weaponizing that alienation, as the antagonists of &lt;em&gt;The Net&lt;/em&gt; do, can of course be used for identity theft. But it can also have much more deleterious applications: Our loneliness can be manipulated to make us consume more, work longer, turn against ourselves and each other. AI “friendships,” if engaged with uncritically, are only going to supercharge this disaffection and the ways in which it can be abused.&lt;/p&gt;  &lt;p&gt;It doesn’t have to be this way. We can withhold our attention, practice healthier screen routines, limit our exposure to doomscrolling, refuse to engage with energy-guzzling AI, delete our accounts. But, crucially, we can also organize collectively IRL: join a union or a local club, ask our friends if they need to talk. Hopelessness is what those in power want us to feel, so resist it.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;The Net&lt;/em&gt; appeared at a time when the internet was only faintly understood as the new Wild West. Before the dot-com boom and bust, before Web 2.0, before the walled gardens and the theory of a “dead internet.” In that sense, it remains a fascinating time capsule of a moment when the possibilities to come felt endless, the outlook cautiously optimistic.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt;&lt;p&gt;We can also see &lt;em&gt;The Net&lt;/em&gt;’s influence in modern screen-life films like &lt;em&gt;Searching&lt;/em&gt;, &lt;em&gt;Host&lt;/em&gt;, &lt;em&gt;Unfriended&lt;/em&gt;, and &lt;em&gt;The Den&lt;/em&gt;. But perhaps—hopefully—its most enduring legacy will be inviting us to go outside, touch grass, talk to another human being, and organize.&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“Find the others.”&lt;br /&gt;—Douglas Rushkoff,&amp;nbsp;&lt;em&gt;Team Human &lt;/em&gt;(2019)&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;&lt;em&gt;Tom Humberstone is a comic artist and illustrator based in Edinburgh.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In April, Mark Zuckerberg, as tech billionaires are so fond of doing these days, pontificated at punishing length on a podcast. In the interview, he addressed America’s loneliness epidemic: “The average American has—I think it’s fewer than three friends. And the average person has demand for meaningfully more. I think it’s like 15 friends or something, right?”&lt;/p&gt;  &lt;p&gt;Before you’ve had a moment to register the ominous way in which he frames human connection in such bleak economic terms, he offers his solution to the loneliness epidemic: AI friends. Ideally AI friends &lt;em&gt;his&lt;/em&gt; company generates.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“It’s like I’m not even me anymore.”&lt;br /&gt;—Angela Bennett, &lt;em&gt;The Net&lt;/em&gt; (1995)&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;Thirty years ago, Irwin Winkler’s proto–cyber thriller, &lt;em&gt;The Net&lt;/em&gt;, was released. It was 1995, commonly regarded as the year Hollywood &lt;em&gt;discovered&lt;/em&gt; the internet. Sandra Bullock played a social recluse and computer nerd for hire named Angela Bennett, who unwittingly uncovers a sinister computer security conspiracy. She soon finds her life turned upside down as the conspiracists begin systematically destroying her credibility and reputation. Her job, home, finances, and very identity are seemingly erased with some judicial tweaks to key computer records.&lt;/p&gt; 
 &lt;p&gt;Bennett is uniquely—conveniently, perhaps—well positioned for this identity annihilation. Her mother, in the throes of dementia, no longer recognizes her; she works from home for clients who have never met her; her social circle is limited to an online chat room; she orders takeout from Pizza.net; her neighbors don’t even know what she looks like. Her most reliable companion is the screen in front of her. A wild, unimaginable scenario that I’m sure none of us can relate to.&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“Just think about it. Our whole world is sitting there on a computer. It’s in the computer, everything: your DMV records, your Social Security, your credit cards, your medical records. It’s all right there. Everyone is stored in there. It’s like this little electronic shadow on each and every one of us, just begging for someone to screw with, and you know what? They’ve done it to me, and you know what? They’re gonna do it to you.”&lt;br /&gt;—Angela Bennett, &lt;em&gt;The Net&lt;/em&gt;&lt;/p&gt; 
 &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;While the villain of &lt;em&gt;The Net&lt;/em&gt; is ultimately a nefarious cybersecurity software company, the film’s preoccupying fear is much more fundamental: If all of our data is digitized, what happens if the people with access to that information tamper with it? Or weaponize it against us?&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;This period of Hollywood’s flirtation with the internet is often referred to as the era of the technophobic thriller, but that’s a surface-level misreading. Techno-&lt;em&gt;skeptic&lt;/em&gt; might be more accurate. These films were broadly positive and excited about new technology; it almost always played a role in how the hero saved the day. Their bigger concern was with the humans who had ultimate control of these tools, and what oversight and restrictions we should place on them.&lt;/p&gt;  &lt;p&gt;In 2025, however, the most prescient part of &lt;em&gt;The Net&lt;/em&gt; is Angela Bennett’s digital alienation. What was originally a series of plausible enough contrivances to make the theft of her identity more believable is now just part of our everyday lives. We all bank, shop, eat, work, and socialize without necessarily seeing another human being in person. And we’ve all been through covid lockdowns where that isolation was actively encouraged. For a whole generation of young people who lived through that, socializing face to face is not second nature. In 2023, the World Health Organization declared loneliness to be a pressing global health threat, estimating that one in four older adults experience social isolation and between 5% and 15% of adolescents experience loneliness. In the US, social isolation may threaten public health more seriously than obesity.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;&lt;em&gt;The Net&lt;/em&gt; appeared at a time when the internet was only faintly understood as the new Wild West … In that sense, it remains a fascinating time capsule of a moment when the possibilities to come felt endless, the outlook cautiously optimistic.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;We also spend increasing amounts of time looking at our phones, where finely tuned algorithms aggressively lobby for more and more of our ad-revenue-­generating attention. As Bennett warns: “Our whole lives are on the computer, and they knew that I could be vanished. They knew that nobody would care, that nobody would understand.” In this sense, in 2025 &lt;em&gt;we are all Angela Bennett&lt;/em&gt;. As Bennett’s digital alienation makes her more vulnerable to pernicious actors, so too are we increasingly at risk from those who don’t have, and have never had, our best interests at heart.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;To blame technology entirely for a rise in loneliness—as many policymakers are doing—would be a mistake. While it is unquestionably playing a part in exacerbating the problem, its outsize role in our lives has always reflected larger underlying factors. In &lt;em&gt;Multitudes: How Crowds Made the Modern World &lt;/em&gt;(2024), the journalist Dan Hancox examines the ways in which crowds have been demonized and othered by those in power and suggests that our alienation is much more structural: “Whether through government cuts or concessions to the expansive ambitions of private enterprise, a key reason we have all become a bit more crowd-shy in recent decades is the prolonged, top-down assault on public space and the wider public realm—what are sometimes called the urban commons. From properly funded libraries to pleasant, open parks and squares, free or affordable sports and leisure facilities, safe, accessible and cheap public transport, comfortable street furniture and free public toilets, and a vibrant, varied, uncommodified social and cultural life—all the best things about city life fall under the heading of the public realm, and all of them facilitate and support happy crowds rather than sad, alienated, stay-at-home loners.”&lt;/p&gt;  &lt;p&gt;Nearly half a century ago Margaret Thatcher laid out the neoliberal consensus that would frame the next decades of individualism: “There’s no such thing as society. There are individual men and women and there are families. And no government can do anything except through people, and people must look after themselves first.”&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-1118694" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/TheNet2.jpg?w=1954" width="1954" /&gt;&lt;div class="image-credit"&gt;TOM HUMBERSTONE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;In keeping with that philosophy, social connectivity has been outsourced to tech companies for which the attention economy is paramount. “The Algo” is our new, capricious god. If your livelihood depends on engagement, the temptation is to stop thinking about human connection when you post, and to think more about what will satisfy The Algo to ensure a good harvest.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;How much will you trust an AI chatbot powered by Meta to be your friend? Answers to this may vary. Even if you won’t, other people are already making close connections with “AI companions” or “falling in love” with ChatGPT. The rise of “cognitive offloading”—of people asking AI to do their critical thinking for them—is already well underway, with many high school and college students admitting to a deep reliance on the technology.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Beyond the obvious concern that AI “friends” are hallucinating, unthinking, obsequious algorithms that will never challenge you in the way a real friend might, it’s also worth remembering who AI actually works for. Recently Elon Musk’s own AI chatbot, Grok, was given new edicts that caused it to cast doubt on the Holocaust and talk about “white genocide” in response to unrelated prompts—a reminder, if we needed it, that these systems are never neutral, never apolitical, and always at the command of those with their hands on the code.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I’m fairly lucky. I live with my partner and have a decent community of friends. But I work from home and can spend the majority of the day not talking to anyone. I’m not immune to feeling isolated, anxious, and powerless as I stare unblinking at my news feed. I think we all feel it. &lt;em&gt;We are all Angela Bennett&lt;/em&gt;. Weaponizing that alienation, as the antagonists of &lt;em&gt;The Net&lt;/em&gt; do, can of course be used for identity theft. But it can also have much more deleterious applications: Our loneliness can be manipulated to make us consume more, work longer, turn against ourselves and each other. AI “friendships,” if engaged with uncritically, are only going to supercharge this disaffection and the ways in which it can be abused.&lt;/p&gt;  &lt;p&gt;It doesn’t have to be this way. We can withhold our attention, practice healthier screen routines, limit our exposure to doomscrolling, refuse to engage with energy-guzzling AI, delete our accounts. But, crucially, we can also organize collectively IRL: join a union or a local club, ask our friends if they need to talk. Hopelessness is what those in power want us to feel, so resist it.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;The Net&lt;/em&gt; appeared at a time when the internet was only faintly understood as the new Wild West. Before the dot-com boom and bust, before Web 2.0, before the walled gardens and the theory of a “dead internet.” In that sense, it remains a fascinating time capsule of a moment when the possibilities to come felt endless, the outlook cautiously optimistic.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt;&lt;p&gt;We can also see &lt;em&gt;The Net&lt;/em&gt;’s influence in modern screen-life films like &lt;em&gt;Searching&lt;/em&gt;, &lt;em&gt;Host&lt;/em&gt;, &lt;em&gt;Unfriended&lt;/em&gt;, and &lt;em&gt;The Den&lt;/em&gt;. But perhaps—hopefully—its most enduring legacy will be inviting us to go outside, touch grass, talk to another human being, and organize.&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;“Find the others.”&lt;br /&gt;—Douglas Rushkoff,&amp;nbsp;&lt;em&gt;Team Human &lt;/em&gt;(2019)&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;p&gt;&lt;em&gt;Tom Humberstone is a comic artist and illustrator based in Edinburgh.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/20/1118379/the-net-cyber-thriller-digital-isolation/</guid><pubDate>Fri, 20 Jun 2025 10:00:00 +0000</pubDate></item><item><title>[NEW] Study: Meta AI model can reproduce almost half of Harry Potter book (AI – Ars Technica)</title><link>https://arstechnica.com/features/2025/06/study-metas-llama-3-1-can-recall-42-percent-of-the-first-harry-potter-book/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The research could have big implications for generative AI copyright lawsuits.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2173576600-640x426.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2173576600-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Meta CEO Mark Zuckerberg.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Andrej Sokolow/picture alliance via Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In recent years, numerous plaintiffs—including publishers of books, newspapers, computer code, and photographs—have&amp;nbsp;sued AI companies&amp;nbsp;for training models using copyrighted material. A key question in all of these lawsuits has been how easily AI models produce verbatim excerpts from the plaintiffs’ copyrighted content.&lt;/p&gt;
&lt;p&gt;For example, in its&amp;nbsp;December 2023 lawsuit against OpenAI, The New York Times Company produced dozens of examples where GPT-4 exactly reproduced significant passages from Times&amp;nbsp;stories. In its&amp;nbsp;response, OpenAI described this as a “fringe behavior” and a “problem that researchers at OpenAI and elsewhere work hard to address.”&lt;/p&gt;
&lt;p&gt;But is it actually a fringe behavior? And have leading AI companies addressed it?&amp;nbsp;New research—focusing on books rather than newspaper articles and on different companies—provides surprising insights into this question. Some of the findings should bolster plaintiffs’ arguments, while others may be more helpful to defendants.&lt;/p&gt;
&lt;p&gt;The paper was published last month by a team of computer scientists and legal scholars from Stanford, Cornell, and West Virginia University. They studied whether five popular open-weight models—three from Meta and one each from Microsoft and EleutherAI—were able to reproduce text from Books3, a collection of books that is widely used to train LLMs. Many of the books are still under copyright.&lt;/p&gt;
&lt;p&gt;This chart illustrates their most surprising finding:&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset"&gt;
&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="1154" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d9755f9-cfad-48cc-a4cb-482c0f9c3bb5_1072x1154.png" width="1072" /&gt;
&lt;/div&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;The chart shows how easy it is to get a model to generate 50-token excerpts from various parts of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;. The darker a line is, the easier it is to reproduce that portion of the book.&lt;/p&gt;
&lt;p&gt;Each row represents a different model. The three bottom rows are Llama models from Meta. And as you can see, Llama 3.1 70B—a mid-sized model Meta released in July 2024—is far more likely to reproduce Harry Potter text than any of the other four models.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Specifically, the paper estimates that Llama 3.1 70B has memorized&amp;nbsp;&lt;em&gt;42 percent&lt;/em&gt;&amp;nbsp;of the first Harry Potter book well enough to reproduce 50-token excerpts at least half the time. (I’ll unpack how this was measured in the next section.)&lt;/p&gt;
&lt;p&gt;Interestingly, Llama 1 65B, a similar-sized model released in February 2023, had memorized only 4.4 percent of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;. This suggests that despite the potential legal liability, Meta did not do much to prevent memorization as it trained Llama 3. At least for this book, the problem got much worse between Llama 1 and Llama 3.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;&amp;nbsp;was one of dozens of books tested by the researchers. They found that Llama 3.1 70B was far more likely to reproduce popular books—such as&amp;nbsp;&lt;em&gt;The Hobbit&lt;/em&gt;&amp;nbsp;and George Orwell’s&amp;nbsp;&lt;em&gt;1984&lt;/em&gt;—than obscure ones. And for most books, Llama 3.1 70B memorized more than any of the other models.&lt;/p&gt;
&lt;p&gt;“There are really striking differences among models in terms of how much verbatim text they have memorized,” said James Grimmelmann, a Cornell law professor who has collaborated with several of the paper’s authors.&lt;/p&gt;
&lt;p&gt;The results surprised the study’s authors, including Mark Lemley, a law professor at Stanford. (Lemley used to be part of Meta's legal team, but in January, he dropped them as a client after Facebook adopted more Trump-friendly moderation policies.)&lt;/p&gt;
&lt;p&gt;“We'd expected to see some kind of low level of replicability on the order of 1 or 2 percent,” Lemley told me. “The first thing that surprised me is how much variation there is.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;These results give everyone in the AI copyright debate something to latch onto. For AI industry critics, the big takeaway is that—at least for some models and some books—memorization is not a fringe phenomenon.&lt;/p&gt;
&lt;p&gt;On the other hand, the study only found significant memorization of a few popular books. For example, the researchers found that Llama 3.1 70B only memorized 0.13 percent of&amp;nbsp;&lt;em&gt;Sandman Slim&lt;/em&gt;, a 2009 novel by author Richard Kadrey. That’s a tiny fraction of the 42 percent figure for&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt;.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This could be a headache for law firms that have filed class-action lawsuits against AI companies. Kadrey is the lead plaintiff in a class-action lawsuit against Meta. To certify a class of plaintiffs, a court must find that the plaintiffs are in largely similar legal and factual situations.&lt;/p&gt;
&lt;p&gt;Divergent results like these could cast doubt on whether it makes sense to lump J.K. Rowling, Kadrey, and thousands of other authors together in a single mass lawsuit. And that could work in Meta’s favor, since most authors lack the resources to file individual lawsuits.&lt;/p&gt;
&lt;p&gt;The broader lesson of this study is that the details will matter in these copyright cases. Too often, online discussions have treated “do generative models copy their training data or merely learn from it?” as a theoretical or even philosophical question. But it’s a question that can be tested empirically—and the answer might differ across models and across copyrighted works.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;How they measured memorization&lt;/h2&gt;
&lt;p&gt;It’s common to talk about LLMs predicting the next token. But under the hood, what the model actually does is generate a probability distribution over&amp;nbsp;&lt;em&gt;all&lt;/em&gt;&amp;nbsp;possibilities for the next token. For example, if you prompt an LLM with the phrase “Peanut butter and,” it will respond with a probability distribution that might look like this made-up example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(“jelly”) = 70 percent&lt;/li&gt;
&lt;li&gt;P(“sugar”) = 9 percent&lt;/li&gt;
&lt;li&gt;P(“peanut”) = 6 percent&lt;/li&gt;
&lt;li&gt;P(“chocolate”) = 4 percent&lt;/li&gt;
&lt;li&gt;P(“cream”) = 3 percent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And so forth.&lt;/p&gt;
&lt;p&gt;After the model generates a list of probabilities like this, the system will select one of these options at random, weighted by their probabilities. So 70 percent of the time the system will generate “Peanut butter and jelly.” Nine percent of the time, we’ll get “Peanut butter and sugar.” Six percent of the time, it will be “Peanut butter and peanut.” You get the idea.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The study’s authors didn’t have to generate multiple outputs to estimate the likelihood of a particular response. Instead, they could calculate probabilities for each token and then multiply them together.&lt;/p&gt;
&lt;p&gt;Suppose someone wants to estimate the probability that a model will respond to “My favorite sandwich is” with “peanut butter and jelly.” Here’s how to do that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is,” and look up the probability of “peanut” (let’s say it’s &lt;strong&gt;20 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is peanut,” and look up the probability of “butter” (let’s say it’s &lt;strong&gt;90 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is peanut butter” and look up the probability of “and” (let’s say it’s&amp;nbsp;&lt;strong&gt;80 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is peanut butter and” and look up the probability of “jelly” (let’s say it’s&amp;nbsp;&lt;strong&gt;70 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then we just have to multiply the probabilities like this:&lt;/p&gt;
&lt;p&gt;0.2 * 0.9 * 0.8 * 0.7 = 0.1008&lt;/p&gt;
&lt;p&gt;So we can predict that the model will produce “peanut butter and jelly” about 10 percent of the time, without actually generating 100 or 1,000 outputs and counting how many of them were that exact phrase.&lt;/p&gt;
&lt;p&gt;This technique greatly reduced the cost of the research, allowed the authors to analyze more books, and made it feasible to precisely estimate very low probabilities.&lt;/p&gt;
&lt;p&gt;For example, the authors estimated that it would take more than 10 quadrillion samples to exactly reproduce some 50-token sequences from some books. Obviously, it wouldn’t be feasible to actually generate that many outputs. But it wasn’t necessary: the probability could be estimated just by multiplying the probabilities for the 50 tokens.&lt;/p&gt;
&lt;p&gt;A key thing to notice is that probabilities can get really small really fast. In my made-up example, the probability that the model will produce the four tokens “peanut butter and jelly” is just 10 percent. If we added more tokens, the probability would get even lower. If we added&amp;nbsp;&lt;em&gt;46 more tokens&lt;/em&gt;, the probability could fall by several orders of magnitude.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For any language model, the probability of generating any given 50-token sequence “by accident” is vanishingly small. If a model generates 50 tokens from a copyrighted work, that is strong evidence that the tokens “came from” the training data. This is true even if it only generates those tokens 10 percent, 1 percent, or 0.01 percent of the time.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="header-anchor-post"&gt;We don’t know how Harry Potter got into Llama models&lt;/h2&gt;
&lt;p&gt;The study authors took 36 books and divided each of them into overlapping 100-token passages. Using the first 50 tokens as a prompt, they calculated the probability that the next 50 tokens would be identical to the original passage. They counted a passage as “memorized” if the model had a greater than 50 percent chance of reproducing it word for word.&lt;/p&gt;
&lt;p&gt;This definition is quite strict. For a 50-token sequence to have a probability greater than 50 percent, the average token in the passage needs a probability of at least 98.5 percent! Moreover, the authors only counted exact matches. They didn’t try to count cases where—for example—the model generates 48 or 49 tokens from the original passage but got one or two tokens wrong. If these cases were counted, the amount of memorization would be even higher.&lt;/p&gt;
&lt;p&gt;This research provides strong evidence that significant portions of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt; were copied into the weights of Llama 3.1 70B. But this finding doesn’t tell us why or how this happened. I suspect that part of the answer is that Llama 3 70B was trained on 15 trillion tokens—more than 10 times the 1.4 trillion tokens used to train Llama 1 65B.&lt;/p&gt;
&lt;p&gt;The more times a model is trained on a particular example, the more likely it is to memorize that example. Perhaps Meta had trouble finding 15 trillion distinct tokens, so it trained on the Books3 dataset multiple times. Or maybe Meta added third-party sources—such as online Harry Potter fan forums, consumer book reviews, or student book reports—that included quotes from &lt;em&gt;Harry Potter&lt;/em&gt;&amp;nbsp;and other popular books.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;I’m not sure that either of these explanations fully fits the facts. The fact that memorization was a much bigger problem for the most popular books does suggest that Llama may have been trained on secondary sources that quote these books rather than the books themselves. There are likely exponentially more online discussions of Harry Potter than Sandman Slim.&lt;/p&gt;
&lt;p&gt;On the other hand, it’s surprising that Llama memorized&lt;em&gt;&amp;nbsp;&lt;/em&gt;so much of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;“If it were citations and quotations, you'd expect it to concentrate around a few popular things that everyone quotes or talks about,” Lemley said. The fact that Llama 3 memorized almost half the book suggests that the entire text was well represented in the training data.&lt;/p&gt;
&lt;p&gt;Or there could be another explanation entirely. Maybe Meta made subtle changes in its training recipe that accidentally worsened the memorization problem. I emailed Meta for comment last week but haven’t heard back.&lt;/p&gt;
&lt;p&gt;“It doesn't seem to be all popular books,” Mark Lemley told me. “Some popular books have this result and not others. It’s hard to come up with a clear story that says why that happened.”&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;Three theories of liability&lt;/h2&gt;
&lt;div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"&gt;
&lt;div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"&gt;There are actually three distinct theories of how training a model on copyrighted works could infringe copyright:&lt;/div&gt;
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;Training on a copyrighted work is inherently infringing because the training process involves making a digital copy of the work.&lt;/li&gt;
&lt;li&gt;The training process copies information from the training data into the model, making the model a derivative work under copyright law.&lt;/li&gt;
&lt;li&gt;Infringement occurs when a model generates (portions of) a copyrighted work.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A lot of discussion so far has focused on the first theory because it is the most threatening to AI companies. If the courts uphold this theory, most current LLMs would be illegal, whether or not they have memorized any training data.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The AI industry has some pretty strong arguments that&amp;nbsp;using copyrighted works during the training process is fair use&amp;nbsp;under the 2015 Google Books ruling. But the fact that Llama 3.1 70B memorized large portions of&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt; could color how the courts consider these fair use questions.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A key part of fair use analysis is whether a use is “transformative”—whether a company has made something new or is merely profiting from the work of others. The fact that language models are capable of regurgitating substantial portions of popular works like&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt;,&amp;nbsp;&lt;em&gt;1984&lt;/em&gt;, and&amp;nbsp;&lt;em&gt;The Hobbit&lt;/em&gt; could cause judges to look at these fair use arguments more skeptically.&lt;/p&gt;
&lt;p&gt;Moreover, one of Google’s key arguments in the books case was that its system was designed to never return more than a short excerpt from any book. If the judge in the Meta lawsuit wanted to distinguish Meta’s arguments from the ones Google made in the books case, he could point to the fact that Llama can generate far more than a few lines of&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The new study “complicates the story that the defendants have been telling in these cases,” co-author Mark Lemley told me. “Which is ‘we just learn word patterns. None of that shows up in the model.’”&lt;/p&gt;
&lt;p&gt;But the Harry Potter result creates even more danger for Meta under that second theory—that Llama itself is a derivative copy of Rowling’s book.&lt;/p&gt;
&lt;p&gt;“It's clear that you can in fact extract substantial parts of Harry Potter and various other books from the model,” Lemley said. “That suggests to me that probably for some of those books there's something the law would call a copy of part of the book in the model itself.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The Google Books precedent probably can’t protect Meta against this second legal theory because Google never made its books database available for users to download—Google almost certainly would have lost the case if it had done that.&lt;/p&gt;
&lt;p&gt;In principle, Meta could still convince a judge that copying 42 percent of Harry Potter was allowed under the flexible, judge-made doctrine of fair use. But it would be an uphill battle.&lt;/p&gt;
&lt;p&gt;“The fair use analysis you've gotta do is not just ‘is the training set fair use,’ but ‘is the incorporation in the model fair use?’" Lemley said. "That complicates the defendants' story.”&lt;/p&gt;
&lt;p&gt;Grimmelmann also said there’s a danger that this research could put open-weight models in greater legal jeopardy than closed-weight ones. The Cornell and Stanford researchers could only do their work because the authors had access to the underlying model—and hence to the token probability values that allowed efficient calculation of probabilities for sequences of tokens.&lt;/p&gt;
&lt;p&gt;Most leading labs, including OpenAI, Anthropic, and Google, have increasingly restricted access to these so-called logits, making it more difficult to study these models.&lt;/p&gt;
&lt;p&gt;Moreover, if a company keeps model weights on its own servers, it can use filters to try to prevent infringing output from reaching the outside world. So even if the underlying OpenAI, Anthropic, and Google models have memorized copyrighted works in the same way as Llama 3.1 70B, it might be difficult for anyone outside the company to prove it.&lt;/p&gt;
&lt;p&gt;Moreover, this kind of filtering makes it easier for companies with closed-weight models to invoke the Google Books precedent. In short, copyright law might create a strong disincentive for companies to release open-weight models.&lt;/p&gt;
&lt;p&gt;“It's kind of perverse,” Mark Lemley told me. “I don't like that outcome.”&lt;/p&gt;
&lt;p&gt;On the other hand, judges might conclude that it would be bad to effectively punish companies for publishing open-weight models.&lt;/p&gt;
&lt;p&gt;“There's a degree to which being open and sharing weights is a kind of public service,” Grimmelmann told me. “I could honestly see judges being less skeptical of Meta and others who provide open-weight models.”&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Timothy B. Lee was on staff at Ars Technica from 2017 to 2021. Today, he writes &lt;/i&gt;&lt;i&gt;Understanding AI,&lt;/i&gt;&lt;i&gt;&amp;nbsp;a newsletter that explores how AI works and how it's changing our world. You can subscribe&amp;nbsp;&lt;/i&gt;&lt;i&gt;here&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The research could have big implications for generative AI copyright lawsuits.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="426" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2173576600-640x426.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-2173576600-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Meta CEO Mark Zuckerberg.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Andrej Sokolow/picture alliance via Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;In recent years, numerous plaintiffs—including publishers of books, newspapers, computer code, and photographs—have&amp;nbsp;sued AI companies&amp;nbsp;for training models using copyrighted material. A key question in all of these lawsuits has been how easily AI models produce verbatim excerpts from the plaintiffs’ copyrighted content.&lt;/p&gt;
&lt;p&gt;For example, in its&amp;nbsp;December 2023 lawsuit against OpenAI, The New York Times Company produced dozens of examples where GPT-4 exactly reproduced significant passages from Times&amp;nbsp;stories. In its&amp;nbsp;response, OpenAI described this as a “fringe behavior” and a “problem that researchers at OpenAI and elsewhere work hard to address.”&lt;/p&gt;
&lt;p&gt;But is it actually a fringe behavior? And have leading AI companies addressed it?&amp;nbsp;New research—focusing on books rather than newspaper articles and on different companies—provides surprising insights into this question. Some of the findings should bolster plaintiffs’ arguments, while others may be more helpful to defendants.&lt;/p&gt;
&lt;p&gt;The paper was published last month by a team of computer scientists and legal scholars from Stanford, Cornell, and West Virginia University. They studied whether five popular open-weight models—three from Meta and one each from Microsoft and EleutherAI—were able to reproduce text from Books3, a collection of books that is widely used to train LLMs. Many of the books are still under copyright.&lt;/p&gt;
&lt;p&gt;This chart illustrates their most surprising finding:&lt;/p&gt;
&lt;div class="captioned-image-container"&gt;
&lt;figure&gt;
&lt;div class="image2-inset"&gt;
&lt;source type="image/webp" /&gt;&lt;img alt="alt" class="sizing-normal" height="1154" src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d9755f9-cfad-48cc-a4cb-482c0f9c3bb5_1072x1154.png" width="1072" /&gt;
&lt;/div&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;The chart shows how easy it is to get a model to generate 50-token excerpts from various parts of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;. The darker a line is, the easier it is to reproduce that portion of the book.&lt;/p&gt;
&lt;p&gt;Each row represents a different model. The three bottom rows are Llama models from Meta. And as you can see, Llama 3.1 70B—a mid-sized model Meta released in July 2024—is far more likely to reproduce Harry Potter text than any of the other four models.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Specifically, the paper estimates that Llama 3.1 70B has memorized&amp;nbsp;&lt;em&gt;42 percent&lt;/em&gt;&amp;nbsp;of the first Harry Potter book well enough to reproduce 50-token excerpts at least half the time. (I’ll unpack how this was measured in the next section.)&lt;/p&gt;
&lt;p&gt;Interestingly, Llama 1 65B, a similar-sized model released in February 2023, had memorized only 4.4 percent of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;. This suggests that despite the potential legal liability, Meta did not do much to prevent memorization as it trained Llama 3. At least for this book, the problem got much worse between Llama 1 and Llama 3.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;&amp;nbsp;was one of dozens of books tested by the researchers. They found that Llama 3.1 70B was far more likely to reproduce popular books—such as&amp;nbsp;&lt;em&gt;The Hobbit&lt;/em&gt;&amp;nbsp;and George Orwell’s&amp;nbsp;&lt;em&gt;1984&lt;/em&gt;—than obscure ones. And for most books, Llama 3.1 70B memorized more than any of the other models.&lt;/p&gt;
&lt;p&gt;“There are really striking differences among models in terms of how much verbatim text they have memorized,” said James Grimmelmann, a Cornell law professor who has collaborated with several of the paper’s authors.&lt;/p&gt;
&lt;p&gt;The results surprised the study’s authors, including Mark Lemley, a law professor at Stanford. (Lemley used to be part of Meta's legal team, but in January, he dropped them as a client after Facebook adopted more Trump-friendly moderation policies.)&lt;/p&gt;
&lt;p&gt;“We'd expected to see some kind of low level of replicability on the order of 1 or 2 percent,” Lemley told me. “The first thing that surprised me is how much variation there is.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;These results give everyone in the AI copyright debate something to latch onto. For AI industry critics, the big takeaway is that—at least for some models and some books—memorization is not a fringe phenomenon.&lt;/p&gt;
&lt;p&gt;On the other hand, the study only found significant memorization of a few popular books. For example, the researchers found that Llama 3.1 70B only memorized 0.13 percent of&amp;nbsp;&lt;em&gt;Sandman Slim&lt;/em&gt;, a 2009 novel by author Richard Kadrey. That’s a tiny fraction of the 42 percent figure for&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt;.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;This could be a headache for law firms that have filed class-action lawsuits against AI companies. Kadrey is the lead plaintiff in a class-action lawsuit against Meta. To certify a class of plaintiffs, a court must find that the plaintiffs are in largely similar legal and factual situations.&lt;/p&gt;
&lt;p&gt;Divergent results like these could cast doubt on whether it makes sense to lump J.K. Rowling, Kadrey, and thousands of other authors together in a single mass lawsuit. And that could work in Meta’s favor, since most authors lack the resources to file individual lawsuits.&lt;/p&gt;
&lt;p&gt;The broader lesson of this study is that the details will matter in these copyright cases. Too often, online discussions have treated “do generative models copy their training data or merely learn from it?” as a theoretical or even philosophical question. But it’s a question that can be tested empirically—and the answer might differ across models and across copyrighted works.&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;How they measured memorization&lt;/h2&gt;
&lt;p&gt;It’s common to talk about LLMs predicting the next token. But under the hood, what the model actually does is generate a probability distribution over&amp;nbsp;&lt;em&gt;all&lt;/em&gt;&amp;nbsp;possibilities for the next token. For example, if you prompt an LLM with the phrase “Peanut butter and,” it will respond with a probability distribution that might look like this made-up example:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;P(“jelly”) = 70 percent&lt;/li&gt;
&lt;li&gt;P(“sugar”) = 9 percent&lt;/li&gt;
&lt;li&gt;P(“peanut”) = 6 percent&lt;/li&gt;
&lt;li&gt;P(“chocolate”) = 4 percent&lt;/li&gt;
&lt;li&gt;P(“cream”) = 3 percent&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;And so forth.&lt;/p&gt;
&lt;p&gt;After the model generates a list of probabilities like this, the system will select one of these options at random, weighted by their probabilities. So 70 percent of the time the system will generate “Peanut butter and jelly.” Nine percent of the time, we’ll get “Peanut butter and sugar.” Six percent of the time, it will be “Peanut butter and peanut.” You get the idea.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The study’s authors didn’t have to generate multiple outputs to estimate the likelihood of a particular response. Instead, they could calculate probabilities for each token and then multiply them together.&lt;/p&gt;
&lt;p&gt;Suppose someone wants to estimate the probability that a model will respond to “My favorite sandwich is” with “peanut butter and jelly.” Here’s how to do that:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is,” and look up the probability of “peanut” (let’s say it’s &lt;strong&gt;20 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is peanut,” and look up the probability of “butter” (let’s say it’s &lt;strong&gt;90 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is peanut butter” and look up the probability of “and” (let’s say it’s&amp;nbsp;&lt;strong&gt;80 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;li&gt;Prompt the model with “My favorite sandwich is peanut butter and” and look up the probability of “jelly” (let’s say it’s&amp;nbsp;&lt;strong&gt;70 percent&lt;/strong&gt;).&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Then we just have to multiply the probabilities like this:&lt;/p&gt;
&lt;p&gt;0.2 * 0.9 * 0.8 * 0.7 = 0.1008&lt;/p&gt;
&lt;p&gt;So we can predict that the model will produce “peanut butter and jelly” about 10 percent of the time, without actually generating 100 or 1,000 outputs and counting how many of them were that exact phrase.&lt;/p&gt;
&lt;p&gt;This technique greatly reduced the cost of the research, allowed the authors to analyze more books, and made it feasible to precisely estimate very low probabilities.&lt;/p&gt;
&lt;p&gt;For example, the authors estimated that it would take more than 10 quadrillion samples to exactly reproduce some 50-token sequences from some books. Obviously, it wouldn’t be feasible to actually generate that many outputs. But it wasn’t necessary: the probability could be estimated just by multiplying the probabilities for the 50 tokens.&lt;/p&gt;
&lt;p&gt;A key thing to notice is that probabilities can get really small really fast. In my made-up example, the probability that the model will produce the four tokens “peanut butter and jelly” is just 10 percent. If we added more tokens, the probability would get even lower. If we added&amp;nbsp;&lt;em&gt;46 more tokens&lt;/em&gt;, the probability could fall by several orders of magnitude.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For any language model, the probability of generating any given 50-token sequence “by accident” is vanishingly small. If a model generates 50 tokens from a copyrighted work, that is strong evidence that the tokens “came from” the training data. This is true even if it only generates those tokens 10 percent, 1 percent, or 0.01 percent of the time.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="header-anchor-post"&gt;We don’t know how Harry Potter got into Llama models&lt;/h2&gt;
&lt;p&gt;The study authors took 36 books and divided each of them into overlapping 100-token passages. Using the first 50 tokens as a prompt, they calculated the probability that the next 50 tokens would be identical to the original passage. They counted a passage as “memorized” if the model had a greater than 50 percent chance of reproducing it word for word.&lt;/p&gt;
&lt;p&gt;This definition is quite strict. For a 50-token sequence to have a probability greater than 50 percent, the average token in the passage needs a probability of at least 98.5 percent! Moreover, the authors only counted exact matches. They didn’t try to count cases where—for example—the model generates 48 or 49 tokens from the original passage but got one or two tokens wrong. If these cases were counted, the amount of memorization would be even higher.&lt;/p&gt;
&lt;p&gt;This research provides strong evidence that significant portions of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt; were copied into the weights of Llama 3.1 70B. But this finding doesn’t tell us why or how this happened. I suspect that part of the answer is that Llama 3 70B was trained on 15 trillion tokens—more than 10 times the 1.4 trillion tokens used to train Llama 1 65B.&lt;/p&gt;
&lt;p&gt;The more times a model is trained on a particular example, the more likely it is to memorize that example. Perhaps Meta had trouble finding 15 trillion distinct tokens, so it trained on the Books3 dataset multiple times. Or maybe Meta added third-party sources—such as online Harry Potter fan forums, consumer book reviews, or student book reports—that included quotes from &lt;em&gt;Harry Potter&lt;/em&gt;&amp;nbsp;and other popular books.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;I’m not sure that either of these explanations fully fits the facts. The fact that memorization was a much bigger problem for the most popular books does suggest that Llama may have been trained on secondary sources that quote these books rather than the books themselves. There are likely exponentially more online discussions of Harry Potter than Sandman Slim.&lt;/p&gt;
&lt;p&gt;On the other hand, it’s surprising that Llama memorized&lt;em&gt;&amp;nbsp;&lt;/em&gt;so much of&amp;nbsp;&lt;em&gt;Harry Potter and the Sorcerer's Stone&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;“If it were citations and quotations, you'd expect it to concentrate around a few popular things that everyone quotes or talks about,” Lemley said. The fact that Llama 3 memorized almost half the book suggests that the entire text was well represented in the training data.&lt;/p&gt;
&lt;p&gt;Or there could be another explanation entirely. Maybe Meta made subtle changes in its training recipe that accidentally worsened the memorization problem. I emailed Meta for comment last week but haven’t heard back.&lt;/p&gt;
&lt;p&gt;“It doesn't seem to be all popular books,” Mark Lemley told me. “Some popular books have this result and not others. It’s hard to come up with a clear story that says why that happened.”&lt;/p&gt;
&lt;h2 class="header-anchor-post"&gt;Three theories of liability&lt;/h2&gt;
&lt;div class="pencraft pc-display-flex pc-alignItems-center pc-position-absolute pc-reset header-anchor-parent"&gt;
&lt;div class="pencraft pc-display-contents pc-reset pubTheme-yiXxQA"&gt;There are actually three distinct theories of how training a model on copyrighted works could infringe copyright:&lt;/div&gt;
&lt;/div&gt;
&lt;ol&gt;
&lt;li&gt;Training on a copyrighted work is inherently infringing because the training process involves making a digital copy of the work.&lt;/li&gt;
&lt;li&gt;The training process copies information from the training data into the model, making the model a derivative work under copyright law.&lt;/li&gt;
&lt;li&gt;Infringement occurs when a model generates (portions of) a copyrighted work.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;A lot of discussion so far has focused on the first theory because it is the most threatening to AI companies. If the courts uphold this theory, most current LLMs would be illegal, whether or not they have memorized any training data.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The AI industry has some pretty strong arguments that&amp;nbsp;using copyrighted works during the training process is fair use&amp;nbsp;under the 2015 Google Books ruling. But the fact that Llama 3.1 70B memorized large portions of&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt; could color how the courts consider these fair use questions.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A key part of fair use analysis is whether a use is “transformative”—whether a company has made something new or is merely profiting from the work of others. The fact that language models are capable of regurgitating substantial portions of popular works like&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt;,&amp;nbsp;&lt;em&gt;1984&lt;/em&gt;, and&amp;nbsp;&lt;em&gt;The Hobbit&lt;/em&gt; could cause judges to look at these fair use arguments more skeptically.&lt;/p&gt;
&lt;p&gt;Moreover, one of Google’s key arguments in the books case was that its system was designed to never return more than a short excerpt from any book. If the judge in the Meta lawsuit wanted to distinguish Meta’s arguments from the ones Google made in the books case, he could point to the fact that Llama can generate far more than a few lines of&amp;nbsp;&lt;em&gt;Harry Potter&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The new study “complicates the story that the defendants have been telling in these cases,” co-author Mark Lemley told me. “Which is ‘we just learn word patterns. None of that shows up in the model.’”&lt;/p&gt;
&lt;p&gt;But the Harry Potter result creates even more danger for Meta under that second theory—that Llama itself is a derivative copy of Rowling’s book.&lt;/p&gt;
&lt;p&gt;“It's clear that you can in fact extract substantial parts of Harry Potter and various other books from the model,” Lemley said. “That suggests to me that probably for some of those books there's something the law would call a copy of part of the book in the model itself.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The Google Books precedent probably can’t protect Meta against this second legal theory because Google never made its books database available for users to download—Google almost certainly would have lost the case if it had done that.&lt;/p&gt;
&lt;p&gt;In principle, Meta could still convince a judge that copying 42 percent of Harry Potter was allowed under the flexible, judge-made doctrine of fair use. But it would be an uphill battle.&lt;/p&gt;
&lt;p&gt;“The fair use analysis you've gotta do is not just ‘is the training set fair use,’ but ‘is the incorporation in the model fair use?’" Lemley said. "That complicates the defendants' story.”&lt;/p&gt;
&lt;p&gt;Grimmelmann also said there’s a danger that this research could put open-weight models in greater legal jeopardy than closed-weight ones. The Cornell and Stanford researchers could only do their work because the authors had access to the underlying model—and hence to the token probability values that allowed efficient calculation of probabilities for sequences of tokens.&lt;/p&gt;
&lt;p&gt;Most leading labs, including OpenAI, Anthropic, and Google, have increasingly restricted access to these so-called logits, making it more difficult to study these models.&lt;/p&gt;
&lt;p&gt;Moreover, if a company keeps model weights on its own servers, it can use filters to try to prevent infringing output from reaching the outside world. So even if the underlying OpenAI, Anthropic, and Google models have memorized copyrighted works in the same way as Llama 3.1 70B, it might be difficult for anyone outside the company to prove it.&lt;/p&gt;
&lt;p&gt;Moreover, this kind of filtering makes it easier for companies with closed-weight models to invoke the Google Books precedent. In short, copyright law might create a strong disincentive for companies to release open-weight models.&lt;/p&gt;
&lt;p&gt;“It's kind of perverse,” Mark Lemley told me. “I don't like that outcome.”&lt;/p&gt;
&lt;p&gt;On the other hand, judges might conclude that it would be bad to effectively punish companies for publishing open-weight models.&lt;/p&gt;
&lt;p&gt;“There's a degree to which being open and sharing weights is a kind of public service,” Grimmelmann told me. “I could honestly see judges being less skeptical of Meta and others who provide open-weight models.”&lt;/p&gt;
&lt;p&gt;&lt;i&gt;Timothy B. Lee was on staff at Ars Technica from 2017 to 2021. Today, he writes &lt;/i&gt;&lt;i&gt;Understanding AI,&lt;/i&gt;&lt;i&gt;&amp;nbsp;a newsletter that explores how AI works and how it's changing our world. You can subscribe&amp;nbsp;&lt;/i&gt;&lt;i&gt;here&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/features/2025/06/study-metas-llama-3-1-can-recall-42-percent-of-the-first-harry-potter-book/</guid><pubDate>Fri, 20 Jun 2025 11:00:14 +0000</pubDate></item><item><title>[NEW] Google’s Gemini transparency cut leaves enterprise developers ‘debugging blind’ (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/googles-gemini-transparency-cut-leaves-enterprise-developers-debugging-blind/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google‘s recent decision to hide the raw reasoning tokens of its flagship model, Gemini 2.5 Pro, has sparked a fierce backlash from developers who have been relying on that transparency to build and debug applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The change, which echoes a similar move by OpenAI, replaces the model’s step-by-step reasoning with a simplified summary. The response highlights a critical tension between creating a polished user experience and providing the observable, trustworthy tools that enterprises need.&lt;/p&gt;



&lt;p&gt;As businesses integrate large language models (LLMs) into more complex and mission-critical systems, the debate over how much of the model’s internal workings should be exposed is becoming a defining issue for the industry.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-fundamental-downgrade-in-ai-transparency"&gt;A ‘fundamental downgrade’ in AI transparency&lt;/h2&gt;



&lt;p&gt;To solve complex problems, advanced AI models generate an internal monologue, also referred to as the “Chain of Thought” (CoT). This is a series of intermediate steps (e.g., a plan, a draft of code, a self-correction) that the model produces before arriving at its final answer. For example, it might reveal how it is processing data, which bits of information it is using, how it is evaluating its own code, etc.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For developers, this reasoning trail often serves as an essential diagnostic and debugging tool. When a model provides an incorrect or unexpected output, the thought process reveals where its logic went astray. And it happened to be one of the key advantages of Gemini 2.5 Pro over OpenAI’s o1 and o3.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In Google’s AI developer forum, users called the removal of this feature a “massive regression.” Without it, developers are left in the dark. As one user on the Google forum said, “I can’t accurately diagnose any issues if I can’t see the raw chain of thought like we used to.” Another described being forced to “guess” why the model failed, leading to “incredibly frustrating, repetitive loops trying to fix things.”&lt;/p&gt;



&lt;p&gt;Beyond debugging, this transparency is crucial for building sophisticated AI systems. Developers rely on the CoT to fine-tune prompts and system instructions, which are the primary ways to steer a model’s behavior. The feature is especially important for creating agentic workflows, where the AI must execute a series of tasks. One developer noted, “The CoTs helped enormously in tuning agentic workflows correctly.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For enterprises, this move toward opacity can be problematic. Black-box AI models that hide their reasoning introduce significant risk, making it difficult to trust their outputs in high-stakes scenarios. This trend, started by OpenAI’s o-series reasoning models and now adopted by Google, creates a clear opening for open-source alternatives such as DeepSeek-R1 and QwQ-32B.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models that provide full access to their reasoning chains give enterprises more control and transparency over the model’s behavior. The decision for a CTO or AI lead is no longer just about which model has the highest benchmark scores. It is now a strategic choice between a top-performing but opaque model and a more transparent one that can be integrated with greater confidence.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-google-s-response-nbsp"&gt;Google’s response&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;In response to the outcry, members of the Google team explained their rationale. Logan Kilpatrick, a senior product manager at Google DeepMind, clarified that the change was “purely cosmetic” and does not impact the model’s internal performance. He noted that for the consumer-facing Gemini app, hiding the lengthy thought process creates a cleaner user experience. “The % of people who will or do read thoughts in the Gemini app is very small,” he said.&lt;/p&gt;



&lt;p&gt;For developers, the new summaries were intended as a first step toward programmatically accessing reasoning traces through the API, which wasn’t previously possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Google team acknowledged the value of raw thoughts for developers. “I hear that you all want raw thoughts, the value is clear, there are use cases that require them,” Kilpatrick wrote, adding that bringing the feature back to the developer-focused AI Studio is “something we can explore.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Google’s reaction to the developer backlash suggests a middle ground is possible, perhaps through a “developer mode” that re-enables raw thought access. The need for observability will only grow as AI models evolve into more autonomous agents that use tools and execute complex, multi-step plans.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As Kilpatrick concluded in his remarks, “…I can easily imagine that raw thoughts becomes a critical requirement of all AI systems given the increasing complexity and need for observability + tracing.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-are-reasoning-tokens-overrated"&gt;Are reasoning tokens overrated?&lt;/h2&gt;



&lt;p&gt;However, experts suggest there are deeper dynamics at play than just user experience. Subbarao Kambhampati, an AI professor at Arizona State University, questions whether the “intermediate tokens” a reasoning model produces before the final answer can be used as a reliable guide for understanding how the model solves problems. A paper he recently co-authored argues that anthropomorphizing “intermediate tokens” as “reasoning traces” or “thoughts” can have dangerous implications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models often go into endless and unintelligible directions in their reasoning process. Several experiments show that models trained on false reasoning traces and correct results can learn to solve problems just as well as models trained on well-curated reasoning traces. Moreover, the latest generation of reasoning models are trained through reinforcement learning algorithms that only verify the final result and don’t evaluate the model’s “reasoning trace.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The fact that intermediate token sequences often reasonably look like better-formatted and spelled human scratch work… doesn’t tell us much about whether they are used for anywhere near the same purposes that humans use them for, let alone about whether they can be used as an interpretable window into what the LLM is ‘thinking,’ or as a reliable justification of the final answer,” the researchers write.&lt;/p&gt;



&lt;p&gt;“Most users can’t make out anything from the volumes of the raw intermediate tokens that these models spew out,” Kambhampati told VentureBeat. “As we mention, DeepSeek R1 produces 30 pages of pseudo-English in solving a simple planning problem! A cynical explanation of why o1/o3 decided not to show the raw tokens originally was perhaps because they realized people will notice how incoherent they are!”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Maybe there is a reason why even after capitulation OAI is putting out only the "summaries" of intermediate tokens (presumably appropriately white washed)..&lt;/p&gt;— Subbarao Kambhampati (కంభంపాటి సుబ్బారావు) (@rao2z) February 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;That said, Kambhampati suggests that summaries or post-facto explanations are likely to be more comprehensible to the end users. “The issue becomes to what extent they are actually indicative of the internal operations that LLMs went through,” he said. “For example, as a teacher, I might solve a new problem with many false starts and backtracks, but explain the solution in the way I think facilitates student comprehension.”&lt;/p&gt;



&lt;p&gt;The decision to hide CoT also serves as a competitive moat. Raw reasoning traces are incredibly valuable training data. As Kambhampati notes, a competitor can use these traces to perform “distillation,” the process of training a smaller, cheaper model to mimic the capabilities of a more powerful one. Hiding the raw thoughts makes it much harder for rivals to copy a model’s secret sauce, a crucial advantage in a resource-intensive industry.&lt;/p&gt;



&lt;p&gt;The debate over Chain of Thought is a preview of a much larger conversation about the future of AI. There is still a lot to learn about the internal workings of reasoning models, how we can leverage them, and how far model providers are willing to go to enable developers to access them.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Join the event trusted by enterprise leaders for nearly two decades. VB Transform brings together the people building real enterprise AI strategy.&amp;nbsp;Learn more&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google‘s recent decision to hide the raw reasoning tokens of its flagship model, Gemini 2.5 Pro, has sparked a fierce backlash from developers who have been relying on that transparency to build and debug applications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The change, which echoes a similar move by OpenAI, replaces the model’s step-by-step reasoning with a simplified summary. The response highlights a critical tension between creating a polished user experience and providing the observable, trustworthy tools that enterprises need.&lt;/p&gt;



&lt;p&gt;As businesses integrate large language models (LLMs) into more complex and mission-critical systems, the debate over how much of the model’s internal workings should be exposed is becoming a defining issue for the industry.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-fundamental-downgrade-in-ai-transparency"&gt;A ‘fundamental downgrade’ in AI transparency&lt;/h2&gt;



&lt;p&gt;To solve complex problems, advanced AI models generate an internal monologue, also referred to as the “Chain of Thought” (CoT). This is a series of intermediate steps (e.g., a plan, a draft of code, a self-correction) that the model produces before arriving at its final answer. For example, it might reveal how it is processing data, which bits of information it is using, how it is evaluating its own code, etc.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For developers, this reasoning trail often serves as an essential diagnostic and debugging tool. When a model provides an incorrect or unexpected output, the thought process reveals where its logic went astray. And it happened to be one of the key advantages of Gemini 2.5 Pro over OpenAI’s o1 and o3.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In Google’s AI developer forum, users called the removal of this feature a “massive regression.” Without it, developers are left in the dark. As one user on the Google forum said, “I can’t accurately diagnose any issues if I can’t see the raw chain of thought like we used to.” Another described being forced to “guess” why the model failed, leading to “incredibly frustrating, repetitive loops trying to fix things.”&lt;/p&gt;



&lt;p&gt;Beyond debugging, this transparency is crucial for building sophisticated AI systems. Developers rely on the CoT to fine-tune prompts and system instructions, which are the primary ways to steer a model’s behavior. The feature is especially important for creating agentic workflows, where the AI must execute a series of tasks. One developer noted, “The CoTs helped enormously in tuning agentic workflows correctly.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For enterprises, this move toward opacity can be problematic. Black-box AI models that hide their reasoning introduce significant risk, making it difficult to trust their outputs in high-stakes scenarios. This trend, started by OpenAI’s o-series reasoning models and now adopted by Google, creates a clear opening for open-source alternatives such as DeepSeek-R1 and QwQ-32B.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models that provide full access to their reasoning chains give enterprises more control and transparency over the model’s behavior. The decision for a CTO or AI lead is no longer just about which model has the highest benchmark scores. It is now a strategic choice between a top-performing but opaque model and a more transparent one that can be integrated with greater confidence.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-google-s-response-nbsp"&gt;Google’s response&amp;nbsp;&lt;/h2&gt;



&lt;p&gt;In response to the outcry, members of the Google team explained their rationale. Logan Kilpatrick, a senior product manager at Google DeepMind, clarified that the change was “purely cosmetic” and does not impact the model’s internal performance. He noted that for the consumer-facing Gemini app, hiding the lengthy thought process creates a cleaner user experience. “The % of people who will or do read thoughts in the Gemini app is very small,” he said.&lt;/p&gt;



&lt;p&gt;For developers, the new summaries were intended as a first step toward programmatically accessing reasoning traces through the API, which wasn’t previously possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The Google team acknowledged the value of raw thoughts for developers. “I hear that you all want raw thoughts, the value is clear, there are use cases that require them,” Kilpatrick wrote, adding that bringing the feature back to the developer-focused AI Studio is “something we can explore.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Google’s reaction to the developer backlash suggests a middle ground is possible, perhaps through a “developer mode” that re-enables raw thought access. The need for observability will only grow as AI models evolve into more autonomous agents that use tools and execute complex, multi-step plans.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As Kilpatrick concluded in his remarks, “…I can easily imagine that raw thoughts becomes a critical requirement of all AI systems given the increasing complexity and need for observability + tracing.”&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-are-reasoning-tokens-overrated"&gt;Are reasoning tokens overrated?&lt;/h2&gt;



&lt;p&gt;However, experts suggest there are deeper dynamics at play than just user experience. Subbarao Kambhampati, an AI professor at Arizona State University, questions whether the “intermediate tokens” a reasoning model produces before the final answer can be used as a reliable guide for understanding how the model solves problems. A paper he recently co-authored argues that anthropomorphizing “intermediate tokens” as “reasoning traces” or “thoughts” can have dangerous implications.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Models often go into endless and unintelligible directions in their reasoning process. Several experiments show that models trained on false reasoning traces and correct results can learn to solve problems just as well as models trained on well-curated reasoning traces. Moreover, the latest generation of reasoning models are trained through reinforcement learning algorithms that only verify the final result and don’t evaluate the model’s “reasoning trace.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“The fact that intermediate token sequences often reasonably look like better-formatted and spelled human scratch work… doesn’t tell us much about whether they are used for anywhere near the same purposes that humans use them for, let alone about whether they can be used as an interpretable window into what the LLM is ‘thinking,’ or as a reliable justification of the final answer,” the researchers write.&lt;/p&gt;



&lt;p&gt;“Most users can’t make out anything from the volumes of the raw intermediate tokens that these models spew out,” Kambhampati told VentureBeat. “As we mention, DeepSeek R1 produces 30 pages of pseudo-English in solving a simple planning problem! A cynical explanation of why o1/o3 decided not to show the raw tokens originally was perhaps because they realized people will notice how incoherent they are!”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Maybe there is a reason why even after capitulation OAI is putting out only the "summaries" of intermediate tokens (presumably appropriately white washed)..&lt;/p&gt;— Subbarao Kambhampati (కంభంపాటి సుబ్బారావు) (@rao2z) February 7, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;That said, Kambhampati suggests that summaries or post-facto explanations are likely to be more comprehensible to the end users. “The issue becomes to what extent they are actually indicative of the internal operations that LLMs went through,” he said. “For example, as a teacher, I might solve a new problem with many false starts and backtracks, but explain the solution in the way I think facilitates student comprehension.”&lt;/p&gt;



&lt;p&gt;The decision to hide CoT also serves as a competitive moat. Raw reasoning traces are incredibly valuable training data. As Kambhampati notes, a competitor can use these traces to perform “distillation,” the process of training a smaller, cheaper model to mimic the capabilities of a more powerful one. Hiding the raw thoughts makes it much harder for rivals to copy a model’s secret sauce, a crucial advantage in a resource-intensive industry.&lt;/p&gt;



&lt;p&gt;The debate over Chain of Thought is a preview of a much larger conversation about the future of AI. There is still a lot to learn about the internal workings of reasoning models, how we can leverage them, and how far model providers are willing to go to enable developers to access them.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/googles-gemini-transparency-cut-leaves-enterprise-developers-debugging-blind/</guid><pubDate>Fri, 20 Jun 2025 12:00:00 +0000</pubDate></item><item><title>The Download: talking dirty with DeepSeek, and the risks and rewards of calorie restriction (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/20/1119102/the-download-talking-dirty-with-deepseek-and-the-risks-and-rewards-of-calorie-restriction/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;It’s pretty easy to get DeepSeek to talk dirty&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;AI companions like Replika are designed to engage in intimate exchanges, but people use general-purpose chatbots for sex talk too, despite their stricter content moderation policies. Now new research shows that not all chatbots are equally willing to talk dirty. DeepSeek is the easiest to convince. But other AI chatbots can be enticed too.&lt;/p&gt;&lt;p&gt;Huiqian Lai, a PhD student at Syracuse University, found vast differences in how mainstream models process sexual queries, from steadfast rejection to performative refusal followed by the requested sexually explicit content.&lt;/p&gt;&lt;p&gt;The findings highlight inconsistencies in LLMs’ safety boundaries that could, in certain situations, become harmful. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Rhiannon Williams&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Calorie restriction can help animals live longer. What about humans?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Living comes with a side effect: aging. Despite what you might hear on social media, there are no drugs that are known to slow or reverse human aging. But there’s some evidence to support another approach: cutting back on calories.&lt;/p&gt;  &lt;p&gt;Reducing your intake of calories and fasting can help with weight loss. But they may also offer protection against some health conditions. And some believe such diets might even help you live longer—a finding supported by new research out this week.&lt;/p&gt;&lt;p&gt;However, the full picture is not so simple. Let’s take a closer look at the benefits—and risks—of caloric restriction.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;How a 30-year-old techno-thriller predicted our digital isolation&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Thirty years ago, Irwin Winkler’s proto–cyber thriller, &lt;em&gt;The Net&lt;/em&gt;, was released. It was 1995, commonly regarded as the year Hollywood discovered the internet. Sandra Bullock played a social recluse and computer nerd for hire named Angela Bennett, who unwittingly uncovers a sinister computer security conspiracy. She soon finds her life turned upside down as the conspiracists begin systematically destroying her credibility and reputation.&lt;/p&gt;&lt;p&gt;While the villain of &lt;em&gt;The Net&lt;/em&gt; is ultimately a nefarious cybersecurity software company, the film’s preoccupying fear is much more fundamental: If all of our data is digitized, what happens if the people with access to that information tamper with it? Or weaponize it against us? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Tom Humberstone&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the next print edition of MIT Technology Review, which explores power—who has it, and who wants it. It’s set to go live on Wednesday June 25, so &lt;/strong&gt;&lt;strong&gt;subscribe &amp;amp; save 25%&lt;/strong&gt;&lt;strong&gt; to read it and get a copy of the issue when it lands!&lt;/strong&gt;&lt;/p&gt; 

   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump has extended TikTok’s deadline for a third time&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;He’s granted it yet another 90-day reprieve. (WSJ $)&lt;br /&gt;+ &lt;em&gt;He says he needs more time to broker a deal. &lt;/em&gt;(AP News)&lt;br /&gt;+ &lt;em&gt;But it’s not clear if Trump’s orders are even legal. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;2 A SpaceX rocket exploded on the test stand&lt;/strong&gt;&lt;br /&gt;Sending a giant fireball into the Texas sky. (CNN)&lt;br /&gt;+ &lt;em&gt;It’s the fourth SpaceX explosion this year. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;The company has a lot of issues to resolve before it can ever reach Mars. &lt;/em&gt;(Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Checking a web user’s age is technologically possible&lt;/strong&gt;&lt;br /&gt;An Australian trial may usher in a ban on under-16s accessing social media. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The findings are a blow to social media firms who have been fighting to avoid this. &lt;/em&gt;(Reuters)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Chinese companies are urgently searching for new markets&lt;/strong&gt;&lt;br /&gt;And Brazil is looking like an increasingly attractive prospect. (NYT $)&lt;br /&gt;+ &lt;em&gt;Chinese carmaker BYD is sending thousands of EVs there. &lt;/em&gt;(Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How Mark Zuckerberg came to love MAGA&lt;br /&gt;&lt;/strong&gt;His recent alignment with the manosphere hasn’t come as a shock to insiders. (FT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 We shouldn’t be using AI for everything&lt;br /&gt;&lt;/strong&gt;Using chatbots without good reason is putting unnecessary strain on the planet. (WP $)&lt;br /&gt;+ &lt;em&gt;AI companies are remaining tight-lipped over their energy use. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 This Chinese courier company is out-delivering Amazon&lt;br /&gt;&lt;/strong&gt;J&amp;amp;T Express fulfills orders from giants like Temu and Shein. (Rest of World)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 How Amazon plans to overhaul Alexa&lt;br /&gt;&lt;/strong&gt;With AI, AI, and some more AI. (Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 How smart should today’s toys be?&lt;/strong&gt;&lt;br /&gt;The last AI-powered Barbie was not a resounding success. (Vox)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 This French app allows you to rent household appliances&lt;/strong&gt;&lt;br /&gt;No raclette machine? No problem. (The Guardian)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“So Mr “Art of the Deal” has not made a TikTok deal (again).”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Adam Cochran, founder of venture capital firm Cinneamhain Ventures, questions Donald Trump’s credentials in a post on X.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcsuuwL3ER4wS3SwclD6NN6dURgOs6oIeM-V0BFc8ps1p3WwTAsmUrhUjCxlGagRBpAPJxcMQPxHbyfLG7aNAYlYf40-553KkEtDwtI-7E6-CtnH_r_Jt6o9Ki9BpZCwg0RMc-Q?key=NBarIQRk3ysdI9m4GYhoVg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;China wants to restore the sea with high-tech marine ranches&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A short ferry ride from the port city of Yantai, on the northeast coast of China, sits Genghai No. 1, a 12,000-metric-ton ring of oil-rig-style steel platforms, advertised as a hotel and entertainment complex.&lt;/p&gt;&lt;p&gt;Genghai is in fact an unusual tourist destination, one that breeds 200,000 “high-quality marine fish” each year. The vast majority are released into the ocean as part of a process known as marine ranching.&lt;/p&gt;&lt;p&gt;The Chinese government sees this work as an urgent and necessary response to the bleak reality that fisheries are collapsing both in China and worldwide. But just how much of a difference can it make? Read the full story.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;&lt;em&gt;—Matthew Ponsford&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ How many art terms are you familiar with? Time to brush up.&lt;br /&gt;+ They can make a museum out of pretty much anything these days.&lt;br /&gt;+ Beekeeping isn’t just beneficial for the bees—it could help your mental health, too 🐝&lt;br /&gt;+ The Sculptor galaxy is looking ridiculously beautiful right now.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;It’s pretty easy to get DeepSeek to talk dirty&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;AI companions like Replika are designed to engage in intimate exchanges, but people use general-purpose chatbots for sex talk too, despite their stricter content moderation policies. Now new research shows that not all chatbots are equally willing to talk dirty. DeepSeek is the easiest to convince. But other AI chatbots can be enticed too.&lt;/p&gt;&lt;p&gt;Huiqian Lai, a PhD student at Syracuse University, found vast differences in how mainstream models process sexual queries, from steadfast rejection to performative refusal followed by the requested sexually explicit content.&lt;/p&gt;&lt;p&gt;The findings highlight inconsistencies in LLMs’ safety boundaries that could, in certain situations, become harmful. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Rhiannon Williams&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Calorie restriction can help animals live longer. What about humans?&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;Living comes with a side effect: aging. Despite what you might hear on social media, there are no drugs that are known to slow or reverse human aging. But there’s some evidence to support another approach: cutting back on calories.&lt;/p&gt;  &lt;p&gt;Reducing your intake of calories and fasting can help with weight loss. But they may also offer protection against some health conditions. And some believe such diets might even help you live longer—a finding supported by new research out this week.&lt;/p&gt;&lt;p&gt;However, the full picture is not so simple. Let’s take a closer look at the benefits—and risks—of caloric restriction.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Jessica Hamzelou&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This article first appeared in The Checkup, MIT Technology Review’s weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first, &lt;/strong&gt;&lt;strong&gt;sign up here&lt;/strong&gt;&lt;strong&gt;.&lt;/strong&gt;&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;&lt;strong&gt;How a 30-year-old techno-thriller predicted our digital isolation&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Thirty years ago, Irwin Winkler’s proto–cyber thriller, &lt;em&gt;The Net&lt;/em&gt;, was released. It was 1995, commonly regarded as the year Hollywood discovered the internet. Sandra Bullock played a social recluse and computer nerd for hire named Angela Bennett, who unwittingly uncovers a sinister computer security conspiracy. She soon finds her life turned upside down as the conspiracists begin systematically destroying her credibility and reputation.&lt;/p&gt;&lt;p&gt;While the villain of &lt;em&gt;The Net&lt;/em&gt; is ultimately a nefarious cybersecurity software company, the film’s preoccupying fear is much more fundamental: If all of our data is digitized, what happens if the people with access to that information tamper with it? Or weaponize it against us? Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Tom Humberstone&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the next print edition of MIT Technology Review, which explores power—who has it, and who wants it. It’s set to go live on Wednesday June 25, so &lt;/strong&gt;&lt;strong&gt;subscribe &amp;amp; save 25%&lt;/strong&gt;&lt;strong&gt; to read it and get a copy of the issue when it lands!&lt;/strong&gt;&lt;/p&gt; 

   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 Donald Trump has extended TikTok’s deadline for a third time&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;He’s granted it yet another 90-day reprieve. (WSJ $)&lt;br /&gt;+ &lt;em&gt;He says he needs more time to broker a deal. &lt;/em&gt;(AP News)&lt;br /&gt;+ &lt;em&gt;But it’s not clear if Trump’s orders are even legal. &lt;/em&gt;(Bloomberg $)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;2 A SpaceX rocket exploded on the test stand&lt;/strong&gt;&lt;br /&gt;Sending a giant fireball into the Texas sky. (CNN)&lt;br /&gt;+ &lt;em&gt;It’s the fourth SpaceX explosion this year. &lt;/em&gt;(WP $)&lt;br /&gt;+ &lt;em&gt;The company has a lot of issues to resolve before it can ever reach Mars. &lt;/em&gt;(Ars Technica)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Checking a web user’s age is technologically possible&lt;/strong&gt;&lt;br /&gt;An Australian trial may usher in a ban on under-16s accessing social media. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;The findings are a blow to social media firms who have been fighting to avoid this. &lt;/em&gt;(Reuters)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Chinese companies are urgently searching for new markets&lt;/strong&gt;&lt;br /&gt;And Brazil is looking like an increasingly attractive prospect. (NYT $)&lt;br /&gt;+ &lt;em&gt;Chinese carmaker BYD is sending thousands of EVs there. &lt;/em&gt;(Rest of World)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 How Mark Zuckerberg came to love MAGA&lt;br /&gt;&lt;/strong&gt;His recent alignment with the manosphere hasn’t come as a shock to insiders. (FT $)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 We shouldn’t be using AI for everything&lt;br /&gt;&lt;/strong&gt;Using chatbots without good reason is putting unnecessary strain on the planet. (WP $)&lt;br /&gt;+ &lt;em&gt;AI companies are remaining tight-lipped over their energy use. &lt;/em&gt;(Wired $)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 This Chinese courier company is out-delivering Amazon&lt;br /&gt;&lt;/strong&gt;J&amp;amp;T Express fulfills orders from giants like Temu and Shein. (Rest of World)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;8 How Amazon plans to overhaul Alexa&lt;br /&gt;&lt;/strong&gt;With AI, AI, and some more AI. (Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;9 How smart should today’s toys be?&lt;/strong&gt;&lt;br /&gt;The last AI-powered Barbie was not a resounding success. (Vox)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;10 This French app allows you to rent household appliances&lt;/strong&gt;&lt;br /&gt;No raclette machine? No problem. (The Guardian)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“So Mr “Art of the Deal” has not made a TikTok deal (again).”&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;—Adam Cochran, founder of venture capital firm Cinneamhain Ventures, questions Donald Trump’s credentials in a post on X.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt;  &lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXcsuuwL3ER4wS3SwclD6NN6dURgOs6oIeM-V0BFc8ps1p3WwTAsmUrhUjCxlGagRBpAPJxcMQPxHbyfLG7aNAYlYf40-553KkEtDwtI-7E6-CtnH_r_Jt6o9Ki9BpZCwg0RMc-Q?key=NBarIQRk3ysdI9m4GYhoVg" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;China wants to restore the sea with high-tech marine ranches&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A short ferry ride from the port city of Yantai, on the northeast coast of China, sits Genghai No. 1, a 12,000-metric-ton ring of oil-rig-style steel platforms, advertised as a hotel and entertainment complex.&lt;/p&gt;&lt;p&gt;Genghai is in fact an unusual tourist destination, one that breeds 200,000 “high-quality marine fish” each year. The vast majority are released into the ocean as part of a process known as marine ranching.&lt;/p&gt;&lt;p&gt;The Chinese government sees this work as an urgent and necessary response to the bleak reality that fisheries are collapsing both in China and worldwide. But just how much of a difference can it make? Read the full story.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;p&gt;&lt;em&gt;—Matthew Ponsford&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ How many art terms are you familiar with? Time to brush up.&lt;br /&gt;+ They can make a museum out of pretty much anything these days.&lt;br /&gt;+ Beekeeping isn’t just beneficial for the bees—it could help your mental health, too 🐝&lt;br /&gt;+ The Sculptor galaxy is looking ridiculously beautiful right now.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/20/1119102/the-download-talking-dirty-with-deepseek-and-the-risks-and-rewards-of-calorie-restriction/</guid><pubDate>Fri, 20 Jun 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] Meta unveils its Oakley smart glasses (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/meta-unveils-its-oakley-smart-glasses/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/meta-oakley.jpg?resize=1200,890" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After months of rumors, Meta has officially announced its next pair of smart glasses with Oakley. The smart glasses have double the battery life of the Meta Ray-Bans and are able to capture 3K video. The models are based on Oakley’s HSTN (pronounced “how-stuhn”) design, and are described as Meta’s “first product for athletes and fans alike.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The limited-edition Oakley Meta HSTN model with gold-colored accents costs $499 and will be available for preorder on July 11. The rest of the collection starts at $399 and is dropping later this summer, Meta says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The glasses feature a front-facing camera, along with open-ear speakers and microphones. You can use the glasses to listen to music, take photos, and make and receive calls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses also feature Meta AI, letting you ask questions on the go, such as “Hey Meta, how strong is the wind today?”&amp;nbsp;or “Hey Meta, take a video.”&amp;nbsp;In addition, you can ask Meta AI about what you’re seeing, and also get it to translate languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Oakley Meta HSTN glasses can last up to eight hours with typical use and up to 19 hours on standby. You can also charge them up to 50% in 20 minutes. Plus, the glasses come with a charging case that can deliver up to 48 hours of charging on the go.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses are available in six frame and lens color combos: warm grey with ruby lenses, black with polar black lenses, brown smoke with polar deep water lenses, black with amethyst lenses, clear with grey lenses, and black with clear lenses. All of these are compatible with prescriptions for an extra cost. Some pairs come with Oakley Prizm Lens technology, which makes it easier to see in different lighting and weather conditions, helping you see more and perform at your peak, Meta says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oakley Meta HSTN will be available in the U.S., Canada, U.K., Ireland, France, Italy, Spain, Austria, Belgium, Australia, Germany, Sweden, Norway, Finland, and Denmark. Meta plans to launch them in Mexico, India, and the United Arab Emirates later this year.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Meta says the new glasses are the latest chapter of a multi-year partnership with EssilorLuxottica, the parent company of Oakley, Ray-Bans, and other eyewear brands. The Meta Ray-Bans have sold over two million pairs to date, according to EssilorLuxottica’s FY2024 financial results.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/meta-oakley.jpg?resize=1200,890" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After months of rumors, Meta has officially announced its next pair of smart glasses with Oakley. The smart glasses have double the battery life of the Meta Ray-Bans and are able to capture 3K video. The models are based on Oakley’s HSTN (pronounced “how-stuhn”) design, and are described as Meta’s “first product for athletes and fans alike.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The limited-edition Oakley Meta HSTN model with gold-colored accents costs $499 and will be available for preorder on July 11. The rest of the collection starts at $399 and is dropping later this summer, Meta says.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The glasses feature a front-facing camera, along with open-ear speakers and microphones. You can use the glasses to listen to music, take photos, and make and receive calls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses also feature Meta AI, letting you ask questions on the go, such as “Hey Meta, how strong is the wind today?”&amp;nbsp;or “Hey Meta, take a video.”&amp;nbsp;In addition, you can ask Meta AI about what you’re seeing, and also get it to translate languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Oakley Meta HSTN glasses can last up to eight hours with typical use and up to 19 hours on standby. You can also charge them up to 50% in 20 minutes. Plus, the glasses come with a charging case that can deliver up to 48 hours of charging on the go.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The glasses are available in six frame and lens color combos: warm grey with ruby lenses, black with polar black lenses, brown smoke with polar deep water lenses, black with amethyst lenses, clear with grey lenses, and black with clear lenses. All of these are compatible with prescriptions for an extra cost. Some pairs come with Oakley Prizm Lens technology, which makes it easier to see in different lighting and weather conditions, helping you see more and perform at your peak, Meta says. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Oakley Meta HSTN will be available in the U.S., Canada, U.K., Ireland, France, Italy, Spain, Austria, Belgium, Australia, Germany, Sweden, Norway, Finland, and Denmark. Meta plans to launch them in Mexico, India, and the United Arab Emirates later this year.&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Meta says the new glasses are the latest chapter of a multi-year partnership with EssilorLuxottica, the parent company of Oakley, Ray-Bans, and other eyewear brands. The Meta Ray-Bans have sold over two million pairs to date, according to EssilorLuxottica’s FY2024 financial results.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/meta-unveils-its-oakley-smart-glasses/</guid><pubDate>Fri, 20 Jun 2025 13:40:01 +0000</pubDate></item><item><title>[NEW] To avoid admitting ignorance, Meta AI says man’s number is a company helpline (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/06/to-avoid-admitting-ignorance-meta-ai-says-mans-number-is-a-company-helpline/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI may compound the burden of having a similar phone number to a popular business.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="413" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-640x413.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anyone whose phone number is just one digit off from a popular restaurant or community resource has long borne the burden of either screening or redirecting misdials. But now, AI chatbots could exacerbate this inconvenience by accidentally giving out private numbers when users ask for businesses' contact information.&lt;/p&gt;
&lt;p&gt;Apparently, the AI helper that Meta created for WhatsApp may even be trained to tell white lies when users try to correct the dissemination of WhatsApp user numbers.&lt;/p&gt;
&lt;p&gt;According to The Guardian, a record shop worker in the United Kingdom, Barry Smethurst, was attempting to ask WhatsApp's AI helper for a contact number for TransPennine Express after his morning train never showed up.&lt;/p&gt;
&lt;p&gt;Instead of feeding up the train services helpline, the AI assistant "confidently" shared a private WhatsApp phone number that a property industry executive, James Gray, had posted to his website.&lt;/p&gt;
&lt;p&gt;Disturbed, Smethurst asked the chatbot why it shared Gray's number, prompting the chatbot to admit "it shouldn’t have shared it," then deflect from further inquiries by suggesting, "Let’s focus on finding the right info for your TransPennine Express query!"&lt;/p&gt;
&lt;p&gt;But Smethurst didn't let the chatbot off the hook so easily. He prodded the AI helper to provide a better explanation. At that point, the chatbot promised to "strive to do better in the future" and admit when it didn't know how to answer a query, first explaining that it came up with the phone number "based on patterns" but then claiming that the number it had generated was "fictional" and not "associated with anyone."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"I didn’t pull the number from a database," the AI helper claimed, repeatedly contradicting itself the longer Smethurst pushed for responses. "I generated a string of digits that fit the format of a UK mobile number, but it wasn’t based on any real data on contacts."&lt;/p&gt;
&lt;p&gt;Smethurst scolded the chatbot, warning that "just giving a random number to someone is an insane thing for an AI to do." He told The Guardian that he considered the incident a "terrifying" "overreach" by Meta.&lt;/p&gt;
&lt;p&gt;"If they made up the number, that’s more acceptable, but the overreach of taking an incorrect number from some database it has access to is particularly worrying," Smethurst said.&lt;/p&gt;
&lt;p&gt;Gray confirmed that he hasn't received phone calls due to the chatbot perhaps replicating this error. But he echoed Smethurst's concerns while pondering if any of his other private information might be disclosed by the AI helper, like his bank details.&lt;/p&gt;
&lt;p&gt;Meta did not immediately respond to Ars' request to comment. But a spokesperson told the Guardian that the company is working on updates to improve the WhatsApp AI helper, which it warned "may return inaccurate outputs."&lt;/p&gt;
&lt;p&gt;The spokesperson also seemed to excuse the seeming privacy infringement by noting that Gray's number is posted on his business website and is very similar to the train helpline's number.&lt;/p&gt;
&lt;p&gt;"Meta AI is trained on a combination of licensed and publicly available datasets, not on the phone numbers people use to register for WhatsApp or their private conversations," the spokesperson said. "A quick online search shows the phone number mistakenly provided by Meta AI is both publicly available and shares the same first five digits as the TransPennine Express customer service number."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although that statement may provide comfort to those who have kept their WhatsApp numbers off the Internet, it doesn't resolve the issue of WhatsApp's AI helper potentially randomly generating a real person's private number that may be a few digits off from the business contact information WhatsApp users are seeking.&lt;/p&gt;
&lt;h2&gt;Expert pushes for chatbot design tweaks&lt;/h2&gt;
&lt;p&gt;AI companies have recently been grappling with the problem of chatbots being programmed to tell users what they want to hear, instead of providing accurate information. Not only are users sick of "overly flattering" chatbot responses—potentially reinforcing users' poor decisions—but the chatbots could be inducing users to share more private information than they would otherwise.&lt;/p&gt;
&lt;p&gt;The latter could make it easier for AI companies to monetize the interactions, gathering private data to target advertising, which could deter AI companies from solving the sycophantic chatbot problem. Developers for Meta rival OpenAI, The Guardian noted, last month shared examples of “systemic deception behavior masked as helpfulness" and chatbots' tendency to tell little white lies to mask incompetence.&lt;/p&gt;
&lt;p&gt;"When pushed hard—under pressure, deadlines, expectations—it will often say whatever it needs to to appear competent," developers noted.&lt;/p&gt;
&lt;p&gt;Mike Stanhope, the managing director of strategic data consultants Carruthers and Jackson, told The Guardian that Meta should be more transparent about the design of its AI so that users can know if the chatbot is designed to rely on deception to reduce user friction.&lt;/p&gt;
&lt;p&gt;"If the engineers at Meta are designing ‘white lie’ tendencies into their AI, the public need to be informed, even if the intention of the feature is to minimize harm," Stanhope said. "If this behavior is novel, uncommon, or not explicitly designed, this raises even more questions around what safeguards are in place and just how predictable we can force an AI’s behavior to be."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI may compound the burden of having a similar phone number to a popular business.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="413" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-640x413.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/GettyImages-1997666795-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio | DigitalVision Vectors

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anyone whose phone number is just one digit off from a popular restaurant or community resource has long borne the burden of either screening or redirecting misdials. But now, AI chatbots could exacerbate this inconvenience by accidentally giving out private numbers when users ask for businesses' contact information.&lt;/p&gt;
&lt;p&gt;Apparently, the AI helper that Meta created for WhatsApp may even be trained to tell white lies when users try to correct the dissemination of WhatsApp user numbers.&lt;/p&gt;
&lt;p&gt;According to The Guardian, a record shop worker in the United Kingdom, Barry Smethurst, was attempting to ask WhatsApp's AI helper for a contact number for TransPennine Express after his morning train never showed up.&lt;/p&gt;
&lt;p&gt;Instead of feeding up the train services helpline, the AI assistant "confidently" shared a private WhatsApp phone number that a property industry executive, James Gray, had posted to his website.&lt;/p&gt;
&lt;p&gt;Disturbed, Smethurst asked the chatbot why it shared Gray's number, prompting the chatbot to admit "it shouldn’t have shared it," then deflect from further inquiries by suggesting, "Let’s focus on finding the right info for your TransPennine Express query!"&lt;/p&gt;
&lt;p&gt;But Smethurst didn't let the chatbot off the hook so easily. He prodded the AI helper to provide a better explanation. At that point, the chatbot promised to "strive to do better in the future" and admit when it didn't know how to answer a query, first explaining that it came up with the phone number "based on patterns" but then claiming that the number it had generated was "fictional" and not "associated with anyone."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"I didn’t pull the number from a database," the AI helper claimed, repeatedly contradicting itself the longer Smethurst pushed for responses. "I generated a string of digits that fit the format of a UK mobile number, but it wasn’t based on any real data on contacts."&lt;/p&gt;
&lt;p&gt;Smethurst scolded the chatbot, warning that "just giving a random number to someone is an insane thing for an AI to do." He told The Guardian that he considered the incident a "terrifying" "overreach" by Meta.&lt;/p&gt;
&lt;p&gt;"If they made up the number, that’s more acceptable, but the overreach of taking an incorrect number from some database it has access to is particularly worrying," Smethurst said.&lt;/p&gt;
&lt;p&gt;Gray confirmed that he hasn't received phone calls due to the chatbot perhaps replicating this error. But he echoed Smethurst's concerns while pondering if any of his other private information might be disclosed by the AI helper, like his bank details.&lt;/p&gt;
&lt;p&gt;Meta did not immediately respond to Ars' request to comment. But a spokesperson told the Guardian that the company is working on updates to improve the WhatsApp AI helper, which it warned "may return inaccurate outputs."&lt;/p&gt;
&lt;p&gt;The spokesperson also seemed to excuse the seeming privacy infringement by noting that Gray's number is posted on his business website and is very similar to the train helpline's number.&lt;/p&gt;
&lt;p&gt;"Meta AI is trained on a combination of licensed and publicly available datasets, not on the phone numbers people use to register for WhatsApp or their private conversations," the spokesperson said. "A quick online search shows the phone number mistakenly provided by Meta AI is both publicly available and shares the same first five digits as the TransPennine Express customer service number."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although that statement may provide comfort to those who have kept their WhatsApp numbers off the Internet, it doesn't resolve the issue of WhatsApp's AI helper potentially randomly generating a real person's private number that may be a few digits off from the business contact information WhatsApp users are seeking.&lt;/p&gt;
&lt;h2&gt;Expert pushes for chatbot design tweaks&lt;/h2&gt;
&lt;p&gt;AI companies have recently been grappling with the problem of chatbots being programmed to tell users what they want to hear, instead of providing accurate information. Not only are users sick of "overly flattering" chatbot responses—potentially reinforcing users' poor decisions—but the chatbots could be inducing users to share more private information than they would otherwise.&lt;/p&gt;
&lt;p&gt;The latter could make it easier for AI companies to monetize the interactions, gathering private data to target advertising, which could deter AI companies from solving the sycophantic chatbot problem. Developers for Meta rival OpenAI, The Guardian noted, last month shared examples of “systemic deception behavior masked as helpfulness" and chatbots' tendency to tell little white lies to mask incompetence.&lt;/p&gt;
&lt;p&gt;"When pushed hard—under pressure, deadlines, expectations—it will often say whatever it needs to to appear competent," developers noted.&lt;/p&gt;
&lt;p&gt;Mike Stanhope, the managing director of strategic data consultants Carruthers and Jackson, told The Guardian that Meta should be more transparent about the design of its AI so that users can know if the chatbot is designed to rely on deception to reduce user friction.&lt;/p&gt;
&lt;p&gt;"If the engineers at Meta are designing ‘white lie’ tendencies into their AI, the public need to be informed, even if the intention of the feature is to minimize harm," Stanhope said. "If this behavior is novel, uncommon, or not explicitly designed, this raises even more questions around what safeguards are in place and just how predictable we can force an AI’s behavior to be."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/06/to-avoid-admitting-ignorance-meta-ai-says-mans-number-is-a-company-helpline/</guid><pubDate>Fri, 20 Jun 2025 15:12:11 +0000</pubDate></item><item><title>[NEW] SoftBank reportedly looking to launch a trillion-dollar AI and robotics industrial complex (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/softbank-reportedly-looking-to-launch-a-trillion-dollar-ai-and-robotics-industrial-complex/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/GettyImages-1220579338.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;SoftBank is going all in on AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just months after announcing its involvement in the $500 billion Stargate AI Infrastructure project, of which SoftBank is rumored to be fronting a cool $19 billion, the Japanese investing conglomerate is reportedly looking to launch its largest AI project yet.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is looking to team up with Taiwan Semiconductor Manufacturing Company (TSMC) to launch a trillion-dollar industrial complex in Arizona to build AI and robotics, according to reporting from Bloomberg, citing sources familiar with the project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initiative, dubbed Project Crystal Land, appears to still be in its very early stages. Despite SoftBank’s desire to work with TSMC on the project, it’s unclear what TSMC’s role would be, according to Bloomberg, or if it would be interested in joining forces with SoftBank at all —&amp;nbsp;TSMC already has its own AI infrastructure projects in Arizona in the works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;SoftBank declined to comment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/12/GettyImages-1220579338.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;SoftBank is going all in on AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just months after announcing its involvement in the $500 billion Stargate AI Infrastructure project, of which SoftBank is rumored to be fronting a cool $19 billion, the Japanese investing conglomerate is reportedly looking to launch its largest AI project yet.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company is looking to team up with Taiwan Semiconductor Manufacturing Company (TSMC) to launch a trillion-dollar industrial complex in Arizona to build AI and robotics, according to reporting from Bloomberg, citing sources familiar with the project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The initiative, dubbed Project Crystal Land, appears to still be in its very early stages. Despite SoftBank’s desire to work with TSMC on the project, it’s unclear what TSMC’s role would be, according to Bloomberg, or if it would be interested in joining forces with SoftBank at all —&amp;nbsp;TSMC already has its own AI infrastructure projects in Arizona in the works.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;br /&gt;SoftBank declined to comment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/softbank-reportedly-looking-to-launch-a-trillion-dollar-ai-and-robotics-industrial-complex/</guid><pubDate>Fri, 20 Jun 2025 15:22:06 +0000</pubDate></item><item><title>[NEW] After trying to buy Ilya Sutskever’s $32B AI startup, Meta looks to hire its CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/after-trying-to-buy-ilya-sutskevers-32b-ai-startup-meta-looks-to-hire-its-ceo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg’s AI talent hiring spree continues. In recent months, Meta tried to acquire Safe Superintelligence, the $32 billion AI startup co-founded by OpenAI’s former chief scientist, Ilya Sutskever, according to a report from CNBC on Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sutskever ultimately turned Meta down, according to CNBC, but the company is now in talks to hire Safe Superintelligence’s co-founder and CEO, Daniel Gross. Earlier this week, The Information reported that Meta was in talks to hire Gross, as well as former GitHub CEO Nat Friedman. Meta is also reportedly taking a stake in Friedman and Gross’s joint venture firm, NFDG, which has invested in prominent AI startups such as Perplexity and Character.AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gross and Friedman could significantly beef up Meta’s AI superintelligence lab, adding leaders who have experience running and investing in AI research labs. Earlier this month, Meta announced that Scale AI CEO Alexandr Wang, and several executives from the data labeling startup, would join the company as well.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579179.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Mark Zuckerberg’s AI talent hiring spree continues. In recent months, Meta tried to acquire Safe Superintelligence, the $32 billion AI startup co-founded by OpenAI’s former chief scientist, Ilya Sutskever, according to a report from CNBC on Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sutskever ultimately turned Meta down, according to CNBC, but the company is now in talks to hire Safe Superintelligence’s co-founder and CEO, Daniel Gross. Earlier this week, The Information reported that Meta was in talks to hire Gross, as well as former GitHub CEO Nat Friedman. Meta is also reportedly taking a stake in Friedman and Gross’s joint venture firm, NFDG, which has invested in prominent AI startups such as Perplexity and Character.AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Gross and Friedman could significantly beef up Meta’s AI superintelligence lab, adding leaders who have experience running and investing in AI research labs. Earlier this month, Meta announced that Scale AI CEO Alexandr Wang, and several executives from the data labeling startup, would join the company as well.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/after-trying-to-buy-ilya-sutskevers-32b-ai-startup-meta-looks-to-hire-its-ceo/</guid><pubDate>Fri, 20 Jun 2025 15:32:28 +0000</pubDate></item><item><title>[NEW] Deezer starts labeling AI-generated music to tackle streaming fraud (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/deezer-starts-labeling-ai-generated-music-to-tackle-streaming-fraud/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Deezer announced on Friday that it will start labeling albums that include AI-generated tracks as part of its efforts to combat streaming fraud.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company reports that about 18% of the music uploaded each day — more than 20,000 tracks — is now fully AI-generated. Although most of these tracks don’t go viral, Deezer says around 70% of their streams are fake and that they are designed to earn royalties fraudulently.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To combat this, AI-generated tracks on Deezer are now clearly tagged. These tracks also won’t appear in editorial playlists or algorithm-based recommendations, and fraudulent streams are being filtered out of royalty payments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the new labels will be a game changer in helping listeners determine the difference between human-created music and AI content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3020624" height="342" src="https://techcrunch.com/wp-content/uploads/2025/06/deezer-ai.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Deezer&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Deezer notes that for now, AI-only songs make up just 0.5% of all streams on its platform, but that the trend is growing fast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve detected a significant uptick in delivery of AI-generated music only in the past few months and we see no sign of it slowing down. It’s an industry-wide issue, and we are committed to leading the way in increasing transparency by helping music fans identify which albums include AI music,” said Deezer CEO Alexis Lanternier in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is not inherently good or bad, but we believe a responsible and transparent approach is key to building trust with our users and the music industry,” he continued. “We are also clear in our commitment to safeguarding the rights of artists and songwriters at a time where copyright law is being put into question in favor of training AI models.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Deezer applied for two patents in December 2024 for its AI Detection technology, which it says is focuses on two different ways of detecting “unique signatures” that are used to tell the difference between synthetic content and authentic content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as Universal Music Group, Warner Music Group, and Sony Music Entertainment are reportedly in talks to license their work to AI startups Udio and Suno. The startups are being sued by the record companies for copyright infringement, and any deal would help to settle&amp;nbsp;lawsuits between them, Bloomberg reported earlier this month. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Deezer announced on Friday that it will start labeling albums that include AI-generated tracks as part of its efforts to combat streaming fraud.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company reports that about 18% of the music uploaded each day — more than 20,000 tracks — is now fully AI-generated. Although most of these tracks don’t go viral, Deezer says around 70% of their streams are fake and that they are designed to earn royalties fraudulently.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;To combat this, AI-generated tracks on Deezer are now clearly tagged. These tracks also won’t appear in editorial playlists or algorithm-based recommendations, and fraudulent streams are being filtered out of royalty payments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the new labels will be a game changer in helping listeners determine the difference between human-created music and AI content. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3020624" height="342" src="https://techcrunch.com/wp-content/uploads/2025/06/deezer-ai.gif?w=480" width="480" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Deezer&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Deezer notes that for now, AI-only songs make up just 0.5% of all streams on its platform, but that the trend is growing fast.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve detected a significant uptick in delivery of AI-generated music only in the past few months and we see no sign of it slowing down. It’s an industry-wide issue, and we are committed to leading the way in increasing transparency by helping music fans identify which albums include AI music,” said Deezer CEO Alexis Lanternier in a press release.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is not inherently good or bad, but we believe a responsible and transparent approach is key to building trust with our users and the music industry,” he continued. “We are also clear in our commitment to safeguarding the rights of artists and songwriters at a time where copyright law is being put into question in favor of training AI models.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Deezer applied for two patents in December 2024 for its AI Detection technology, which it says is focuses on two different ways of detecting “unique signatures” that are used to tell the difference between synthetic content and authentic content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes as Universal Music Group, Warner Music Group, and Sony Music Entertainment are reportedly in talks to license their work to AI startups Udio and Suno. The startups are being sued by the record companies for copyright infringement, and any deal would help to settle&amp;nbsp;lawsuits between them, Bloomberg reported earlier this month. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/deezer-starts-labeling-ai-generated-music-to-tackle-streaming-fraud/</guid><pubDate>Fri, 20 Jun 2025 16:25:04 +0000</pubDate></item><item><title>[NEW] Could OpenAI fill Microsoft’s shoes? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/could-openai-fill-microsofts-shoes/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;OpenAI recently announced a $200 million deal with the U.S. Department of Defense, which has us wondering: Could this further strain the company’s relationship with its biggest backer, Microsoft?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;After all, there have been numerous reports about growing tensions between the two companies, particularly as they become more competitive over enterprise deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Anthony Ha and Max Zeff discuss how the OpenAI/DoD deal reflects Silicon Valley’s increasingly cozy relationship with the military and why industry leaders are calling for an AI “arms race.”&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more highlights from the week, including:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Whether it’s a good thing that Vice President JD Vance joined Bluesky (and was briefly suspended)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What it means that Wix acquired a six-month-old “vibe coding” startup for $80 million (and why Anthony hates the phrase “vibe coding”)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;A panel in which investor Ali Partovi and Cognition President Russell Kaplan discuss what technical talent means in the age of AI&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, so stay tuned!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;OpenAI recently announced a $200 million deal with the U.S. Department of Defense, which has us wondering: Could this further strain the company’s relationship with its biggest backer, Microsoft?&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;After all, there have been numerous reports about growing tensions between the two companies, particularly as they become more competitive over enterprise deals.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today, on TechCrunch’s Equity podcast, hosts Anthony Ha and Max Zeff discuss how the OpenAI/DoD deal reflects Silicon Valley’s increasingly cozy relationship with the military and why industry leaders are calling for an AI “arms race.”&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear more highlights from the week, including:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Whether it’s a good thing that Vice President JD Vance joined Bluesky (and was briefly suspended)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What it means that Wix acquired a six-month-old “vibe coding” startup for $80 million (and why Anthony hates the phrase “vibe coding”)&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;A panel in which investor Ali Partovi and Cognition President Russell Kaplan discuss what technical talent means in the age of AI&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back next week, so stay tuned!&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Subscribe to us on&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/could-openai-fill-microsofts-shoes/</guid><pubDate>Fri, 20 Jun 2025 16:26:08 +0000</pubDate></item><item><title>[NEW] Character.AI taps Meta’s former VP of business products as CEO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/character-ai-taps-metas-former-vp-of-business-products-as-ceo/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Character.AI, the Google-backed AI chatbot provider with tens of millions of monthly active users, announced on Friday that Karandeep Anand, the former VP of Business Products at Meta, is joining the company as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously a board adviser to Character.AI, Anand is stepping into the CEO role at a pivotal moment for the chatbot provider, as the company tries to simultaneously grow its platform while combatting child safety concerns. In recent months, Character.AI has added an array of new safety features in light of an active lawsuit, which alleges that one of the company’s chatbots played a role in the death of a 14-year-old Florida boy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anand comes to Character.AI with experience running advertising products that reached billions of users on Meta’s apps. Previously, Anand served as Microsoft’s head of product management, overseeing user experience on the company’s cloud platform, Azure. Most recently, Anand served as the president of the fintech startup Brex.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3020690" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/u8dxF6d8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Character.AI’s new CEO, Karandeep Anand&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Character.AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Anand is taking over Character.AI just over 10 months after Google hired away the startup’s co-founder and CEO, Noam Shazeer, who had previously led core AI teams at the Mountain View giant. At the time, Google also signed a non-exclusive agreement to use Character.AI’s technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI’s deal with Google prompted federal regulators to investigate the companies’ relationship over antitrust concerns. It’s one of many reverse-acquihire deals in the AI startup space that’s received regulatory scrutiny, alongside Microsoft’s deal with Inflection.AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI has raised more than $150 million in venture funding, largely from Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post, Anand said one of his first priorities would be making safety filters “less overbearing.” The new CEO noted that the company cares deeply about users safety, but that too often, “the app filters things that are perfectly harmless.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Anand also said he plans to improve the quality of AI models on Character.AI’s platform, innovate around memory features, and increase transparency around decision making. He says many of these features are coming in the next 60 days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chatbots that are purely designed for entertainment, which Character.AI specializes in, are growing into a massive market for generative AI — a trend that’s been surprising to many. In 2024, 66% of the company’s users were between the age of 18 and 24, and 72% of the company’s users were women, according to data from Sensor Tower.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Character.AI, the Google-backed AI chatbot provider with tens of millions of monthly active users, announced on Friday that Karandeep Anand, the former VP of Business Products at Meta, is joining the company as CEO.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously a board adviser to Character.AI, Anand is stepping into the CEO role at a pivotal moment for the chatbot provider, as the company tries to simultaneously grow its platform while combatting child safety concerns. In recent months, Character.AI has added an array of new safety features in light of an active lawsuit, which alleges that one of the company’s chatbots played a role in the death of a 14-year-old Florida boy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anand comes to Character.AI with experience running advertising products that reached billions of users on Meta’s apps. Previously, Anand served as Microsoft’s head of product management, overseeing user experience on the company’s cloud platform, Azure. Most recently, Anand served as the president of the fintech startup Brex.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3020690" height="680" src="https://techcrunch.com/wp-content/uploads/2025/06/u8dxF6d8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Character.AI’s new CEO, Karandeep Anand&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Character.AI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Anand is taking over Character.AI just over 10 months after Google hired away the startup’s co-founder and CEO, Noam Shazeer, who had previously led core AI teams at the Mountain View giant. At the time, Google also signed a non-exclusive agreement to use Character.AI’s technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI’s deal with Google prompted federal regulators to investigate the companies’ relationship over antitrust concerns. It’s one of many reverse-acquihire deals in the AI startup space that’s received regulatory scrutiny, alongside Microsoft’s deal with Inflection.AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Character.AI has raised more than $150 million in venture funding, largely from Andreessen Horowitz.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post, Anand said one of his first priorities would be making safety filters “less overbearing.” The new CEO noted that the company cares deeply about users safety, but that too often, “the app filters things that are perfectly harmless.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;Anand also said he plans to improve the quality of AI models on Character.AI’s platform, innovate around memory features, and increase transparency around decision making. He says many of these features are coming in the next 60 days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Chatbots that are purely designed for entertainment, which Character.AI specializes in, are growing into a massive market for generative AI — a trend that’s been surprising to many. In 2024, 66% of the company’s users were between the age of 18 and 24, and 72% of the company’s users were women, according to data from Sensor Tower.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/character-ai-taps-metas-former-vp-of-business-products-as-ceo/</guid><pubDate>Fri, 20 Jun 2025 17:20:06 +0000</pubDate></item><item><title>[NEW] ChatGPT: Everything you need to know about the AI-powered chatbot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/20/chatgpt-everything-to-know-about-the-ai-chatbot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;






&lt;h3 class="wp-block-heading" id="h-june-2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/03/GettyImages-1462188043-e1686340799615.jpg?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;






&lt;h3 class="wp-block-heading" id="h-june-2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/20/chatgpt-everything-to-know-about-the-ai-chatbot/</guid><pubDate>Fri, 20 Jun 2025 17:27:58 +0000</pubDate></item><item><title>[NEW] MIT student prints AI polymer masks to restore paintings in hours (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/06/mit-student-prints-ai-polymer-masks-to-restore-paintings-in-hours/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Removable transparent films apply digital restorations directly to damaged artwork.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0-640x427.jpg" width="640" /&gt;
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="600" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0.jpg" width="900" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;MIT graduate student Alex Kachkine once spent nine months meticulously restoring a damaged baroque Italian painting, which left him plenty of time to wonder if technology could speed things up. Last week, MIT News announced his solution: a technique that uses AI-generated polymer films to physically restore damaged paintings in hours rather than months. The research appears in Nature.&lt;/p&gt;
&lt;p&gt;Kachkine's method works by printing a transparent "mask" containing thousands of precisely color-matched regions that conservators can apply directly to an original artwork. Unlike traditional restoration, which permanently alters the painting, these masks can reportedly be removed whenever needed. So it's a reversible process that does not permanently change a painting.&lt;/p&gt;
&lt;p&gt;"Because there's a digital record of what mask was used, in 100 years, the next time someone is working with this, they'll have an extremely clear understanding of what was done to the painting," Kachkine told MIT News. "And that's never really been possible in conservation before."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102055 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Figure 1 from the paper." class="center large" height="1026" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/mask_figure-1-1024x1026.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 1 from the paper.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          MIT

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Nature reports that up to 70 percent of institutional art collections remain hidden from public view due to damage—a large amount of cultural heritage sitting unseen in storage. Traditional restoration methods, where conservators painstakingly fill damaged areas one at a time while mixing exact color matches for each region, can take weeks to decades for a single painting. It's skilled work that requires both artistic talent and deep technical knowledge, but there simply aren't enough conservators to tackle the backlog.&lt;/p&gt;
&lt;p&gt;The mechanical engineering student conceived the idea during a 2021 cross-country drive to MIT, when gallery visits revealed how much art remains hidden due to damage and restoration backlogs. As someone who restores paintings as a hobby, he understood both the problem and the potential for a technological solution.&lt;/p&gt;
&lt;p&gt;To demonstrate his method, Kachkine chose a challenging test case: a 15th-century oil painting requiring repairs in 5,612 separate regions. An AI model identified damage patterns and generated 57,314 different colors to match the original work. The entire restoration process reportedly took 3.5 hours—about 66 times faster than traditional hand-painting methods.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102048 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A handout photo of Alex Kachkine, who developed the AI printed film technique." class="center large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/d41586-025-01776-8_51069120-1024x683.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alex Kachkine, who developed the AI-printed film technique.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Notably, Kachkine avoided using generative AI models like Stable Diffusion or the "full-area application" of generative adversarial networks (GANs) for the digital restoration step. According to the Nature paper, these models cause "spatial distortion" that would prevent proper alignment between the restored image and the damaged original.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, Kachkine utilized computer vision techniques found in prior art conservation research: "cross-applied colouration" for simple damages like thin cracks, and "local partial convolution" for reconstructing low-complexity patterns. For areas of high visual complexity, such as faces, Kachkine relied on traditional conservator methods, transposing features from other works by the same artist.&lt;/p&gt;
&lt;h2&gt;From pixels to polymers&lt;/h2&gt;
&lt;p&gt;Kachkine's process begins conventionally enough, with traditional cleaning to remove any previous restoration attempts. After scanning the cleaned painting, the aforementioned algorithms analyze the image and create a virtual restoration that "predicts" what the damaged areas should look like based on the surrounding paint and the artist's style. This part isn't particularly new—museums have been creating digital restorations for years. The innovative part is what happens next.&lt;/p&gt;
&lt;p&gt;Custom software (shared by Kachkine online) maps every region needing repair and determines the exact colors required for each spot. His software then translates that information into a two-layer polymer mask printed on thin films—one layer provides color, while a white backing layer ensures the full color spectrum reproduces accurately on the painting's surface. The two layers must align precisely to reproduce colors accurately.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Overview of physically applied digital restoration.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;High-fidelity inkjet printers produce the mask layers, which Kachkine aligns by hand and adheres to the painting using conservation-grade varnish spray. Importantly, the polymer materials dissolve in standard conservation solutions, allowing future removal of the mask without damaging the original work. Museums can also store digital files documenting every change made during restoration, creating a paper trail for future conservators.&lt;/p&gt;
&lt;p&gt;Kachkine says that the technology doesn't replace human judgment—conservators must still guide ethical decisions about how much intervention is appropriate and whether digital predictions accurately capture the artist's original intent. "It will take a lot of deliberation about the ethical challenges involved at every stage in this process to see how can this be applied in a way that's most consistent with conservation principles," he told MIT News.&lt;/p&gt;
&lt;p&gt;For now, the method works best with paintings that include numerous small areas of damage rather than large missing sections. In a world where AI models increasingly seem to blur the line between human- and machine-created media, it's refreshing to see a clear application of computer vision tools used as an augmentation of human skill and not as a wholesale replacement for the judgment of skilled conservators.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Removable transparent films apply digital restorations directly to damaged artwork.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0-640x427.jpg" width="640" /&gt;
                  &lt;img alt="The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="600" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/MIT-Restoring-Paintings-01-press_0.jpg" width="900" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The restoration process from start to finish. Left: the painting in its damaged state. Center: a diagnostic map where green indicates complete breaks in the wood panel, red marks significant paint cracking, blue highlights major areas of paint loss, and pink identifies minor damage such as scratches. Right: the completed restoration with the polymer mask applied.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;MIT graduate student Alex Kachkine once spent nine months meticulously restoring a damaged baroque Italian painting, which left him plenty of time to wonder if technology could speed things up. Last week, MIT News announced his solution: a technique that uses AI-generated polymer films to physically restore damaged paintings in hours rather than months. The research appears in Nature.&lt;/p&gt;
&lt;p&gt;Kachkine's method works by printing a transparent "mask" containing thousands of precisely color-matched regions that conservators can apply directly to an original artwork. Unlike traditional restoration, which permanently alters the painting, these masks can reportedly be removed whenever needed. So it's a reversible process that does not permanently change a painting.&lt;/p&gt;
&lt;p&gt;"Because there's a digital record of what mask was used, in 100 years, the next time someone is working with this, they'll have an extremely clear understanding of what was done to the painting," Kachkine told MIT News. "And that's never really been possible in conservation before."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102055 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Figure 1 from the paper." class="center large" height="1026" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/mask_figure-1-1024x1026.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Figure 1 from the paper.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          MIT

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Nature reports that up to 70 percent of institutional art collections remain hidden from public view due to damage—a large amount of cultural heritage sitting unseen in storage. Traditional restoration methods, where conservators painstakingly fill damaged areas one at a time while mixing exact color matches for each region, can take weeks to decades for a single painting. It's skilled work that requires both artistic talent and deep technical knowledge, but there simply aren't enough conservators to tackle the backlog.&lt;/p&gt;
&lt;p&gt;The mechanical engineering student conceived the idea during a 2021 cross-country drive to MIT, when gallery visits revealed how much art remains hidden due to damage and restoration backlogs. As someone who restores paintings as a hobby, he understood both the problem and the potential for a technological solution.&lt;/p&gt;
&lt;p&gt;To demonstrate his method, Kachkine chose a challenging test case: a 15th-century oil painting requiring repairs in 5,612 separate regions. An AI model identified damage patterns and generated 57,314 different colors to match the original work. The entire restoration process reportedly took 3.5 hours—about 66 times faster than traditional hand-painting methods.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102048 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A handout photo of Alex Kachkine, who developed the AI printed film technique." class="center large" height="683" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/d41586-025-01776-8_51069120-1024x683.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Alex Kachkine, who developed the AI-printed film technique.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          MIT

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Notably, Kachkine avoided using generative AI models like Stable Diffusion or the "full-area application" of generative adversarial networks (GANs) for the digital restoration step. According to the Nature paper, these models cause "spatial distortion" that would prevent proper alignment between the restored image and the damaged original.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Instead, Kachkine utilized computer vision techniques found in prior art conservation research: "cross-applied colouration" for simple damages like thin cracks, and "local partial convolution" for reconstructing low-complexity patterns. For areas of high visual complexity, such as faces, Kachkine relied on traditional conservator methods, transposing features from other works by the same artist.&lt;/p&gt;
&lt;h2&gt;From pixels to polymers&lt;/h2&gt;
&lt;p&gt;Kachkine's process begins conventionally enough, with traditional cleaning to remove any previous restoration attempts. After scanning the cleaned painting, the aforementioned algorithms analyze the image and create a virtual restoration that "predicts" what the damaged areas should look like based on the surrounding paint and the artist's style. This part isn't particularly new—museums have been creating digital restorations for years. The innovative part is what happens next.&lt;/p&gt;
&lt;p&gt;Custom software (shared by Kachkine online) maps every region needing repair and determines the exact colors required for each spot. His software then translates that information into a two-layer polymer mask printed on thin films—one layer provides color, while a white backing layer ensures the full color spectrum reproduces accurately on the painting's surface. The two layers must align precisely to reproduce colors accurately.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Overview of physically applied digital restoration.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;High-fidelity inkjet printers produce the mask layers, which Kachkine aligns by hand and adheres to the painting using conservation-grade varnish spray. Importantly, the polymer materials dissolve in standard conservation solutions, allowing future removal of the mask without damaging the original work. Museums can also store digital files documenting every change made during restoration, creating a paper trail for future conservators.&lt;/p&gt;
&lt;p&gt;Kachkine says that the technology doesn't replace human judgment—conservators must still guide ethical decisions about how much intervention is appropriate and whether digital predictions accurately capture the artist's original intent. "It will take a lot of deliberation about the ethical challenges involved at every stage in this process to see how can this be applied in a way that's most consistent with conservation principles," he told MIT News.&lt;/p&gt;
&lt;p&gt;For now, the method works best with paintings that include numerous small areas of damage rather than large missing sections. In a world where AI models increasingly seem to blur the line between human- and machine-created media, it's refreshing to see a clear application of computer vision tools used as an augmentation of human skill and not as a wholesale replacement for the judgment of skilled conservators.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/06/mit-student-prints-ai-polymer-masks-to-restore-paintings-in-hours/</guid><pubDate>Fri, 20 Jun 2025 17:32:33 +0000</pubDate></item></channel></rss>