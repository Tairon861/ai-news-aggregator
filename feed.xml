<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 29 Nov 2025 01:44:09 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>The race to regulate AI has sparked a federal vs state showdown (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/28/the-race-to-regulate-ai-has-sparked-a-federal-vs-state-showdown/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the first time, Washington is getting close to deciding how to regulate artificial intelligence. And the fight that’s brewing isn’t about the technology, it’s about who gets to do the regulating.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the absence of a meaningful federal AI standard that focuses on consumer safety, states have introduced dozens of bills to protect residents against AI-related harms, including California’s AI safety bill SB-53 and Texas’s Responsible AI Governance Act, which prohibits intentional misuse of AI systems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The tech giants and buzzy startups born out of Silicon Valley argue such laws create an unworkable patchwork that threatens innovation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s going to slow us in the race against China,” Josh Vlasto, co-founder of pro-AI PAC Leading the Future, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The industry, and several of its transplants in the White House, is pushing for a national standard or none at all. In the trenches of that all-or-nothing battle, new efforts have emerged to prohibit states from enacting their own AI legislation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;House lawmakers are reportedly trying to use the National Defense Authorization Act (NDAA) to block state AI laws. At the same time, a leaked draft of a White House executive order also demonstrates strong support for preempting state efforts to regulate AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A sweeping preemption that would take away states’ rights to regulate AI is unpopular in Congress, which voted overwhelmingly against a similar moratorium earlier this year. Lawmakers have argued that without a federal standard in place, blocking states will leave consumers exposed to harm, and tech companies free to operate without oversight.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To create that national standard, Rep. Ted Lieu (D-CA) and the bipartisan House AI Task Force are preparing a package of federal AI bills that cover a range of consumer protections, including fraud, healthcare, transparency, child safety, and catastrophic risk. A megabill such as this will likely take months, if not years, to become law, underscoring why the current rush to limit state authority has become one of the most contentious fights in AI policy.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-battle-lines-ndaa-and-the-eo"&gt;&lt;strong&gt;The battle lines: NDAA and the EO&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="US President Donald Trump displays an executive order on artificial intelligence he signed at the &amp;quot;Winning the AI Race&amp;quot; AI Summit at the Andrew W." class="wp-image-3030829" height="454" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Trump displays an executive order on AI he signed on July 23, 2025. (Photo by ANDREW CABALLERO-REYNOLDS / AFP) &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;ANDREW CABALLERO-REYNOLDS/AFP / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Efforts to block states from regulating AI have ramped up in recent weeks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The House has considered tucking language in the NDAA that would prevent states from regulating AI, Majority Leader Steve Scalise (R-LA) told Punchbowl News. Congress was reportedly working to finalize a deal on the defense bill before Thanksgiving, Politico reported. A source familiar with the matter told TechCrunch negotiations have focused on narrowing the scope to potentially preserve state authority over areas like kids’ safety and transparency.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meanwhile, a leaked White House EO draft reveals the administration’s own potential preemption strategy. The EO, which has reportedly been put on hold, would create an “AI Litigation Task Force” to challenge state AI laws in court, direct agencies to evaluate state laws deemed “onerous,” and push the Federal Communications Commission and Federal Trade Commission towards national standards that override state rules.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the EO would give David Sacks – Trump’s AI and Crypto Czar and co-founder of VC firm Craft Ventures – co-lead authority on creating a uniform legal framework. This would give Sacks direct influence over AI policy that supersedes the typical role of the White House Office of Science and Technology Policy, and its head Michael Kratsios.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks has publicly advocated for blocking state regulation and keeping federal oversight menial, favoring industry self-regulation to “maximize growth.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-patchwork-argument"&gt;&lt;strong&gt;The patchwork argument&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks’s position mirrors the viewpoint of much of the AI industry. Several pro-AI super PACs have emerged in recent months, throwing hundreds of millions of dollars into local and state elections to oppose candidates who support AI regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading the Future – backed by Andreessen Horowitz, OpenAI president Greg Brockman, Perplexity, and Palantir co-founder Joe Lonsdale – has raised more than $100 million. This week, Leading the Future launched a $10 million campaign pushing Congress to craft a national AI policy that overrides state laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you’re trying to drive innovation in the tech sector, you can’t have a situation where all these laws keep popping up from people who don’t necessarily have the technical expertise,” Vlasto told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that a patchwork of state regulations will “slow us in the race against China.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Leamer, executive director of Build American AI, the PAC’s advocacy arm, confirmed the group supports preemption without AI-specific federal consumer protections in place. Leamer argued that existing laws, like those addressing fraud or product liability, are sufficient to handle AI harms. Where state laws often seek to prevent problems before they arise, Leamer favors a more reactive approach: let companies move fast, address problems in court later.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-no-preemption-without-representation"&gt;&lt;strong&gt;No preemption without representation&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Alex Bores speaking at an event in Washington, D.C., on November 17, 2025." class="wp-image-3068604" height="510" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_9933.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Alex Bores speaking at an event in Washington, D.C., on November 17, 2025. &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Bores, a New York Assembly member running for Congress, is one of Leading the Future’s first targets. He sponsored the RAISE Act, which requires large AI labs to have safety plans to prevent critical harms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I believe in the power of AI, and that is why it is so important to have reasonable regulations,” Bores told TechCrunch. “Ultimately, the AI that’s going to win in the marketplace is going to be trustworthy AI, and often the marketplace undervalues or puts poor short-term incentives on investing in safety.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores supports a national AI policy, but argues states can move faster to address emerging risks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And it’s true that states move quicker.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of November 2025, 38 states have adopted more than 100 AI-related laws this year, mainly targeting deepfakes, transparency and disclosure, and government use of AI. (A recent study found that 69% of those laws impose no requirements on AI developers at all.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Activity in Congress provides more evidence of the slower-than-states argument. Hundreds of AI bills have been introduced, but few have passed. Since 2015, Rep. Lieu has introduced 67 bills to the House Science Committee. Only one became law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More than 200 lawmakers signed an open letter opposing preemption in the NDAA, arguing that “states serve as laboratories of democracies” that must “retain the flexibility to confront new digital challenges as they arise.” Nearly 40 state attorneys general also sent an open letter opposing a state AI regulation ban.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cybersecurity expert Bruce Schneier and data scientist Nathan E. Sanders – authors of &lt;em&gt;Rewiring Democracy:&lt;/em&gt;&lt;em&gt; How AI Will Transform Our Politics, Government, and Citizenship &lt;/em&gt;– argue the patchwork complaint is overblown.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies already comply with tougher EU regulations, they note, and most industries find a way to operate under varying state laws. The real motive, they say, is avoiding accountability.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-what-could-a-federal-standard-look-like"&gt;&lt;strong&gt;What could a federal standard look like?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu is drafting an over 200-page megabill he hopes to introduce in December. It covers a range of issues, like fraud penalties, deepfake protections, whistleblower protections, compute resources for academia, and mandatory testing and disclosure for large language model companies.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That last provision would require AI labs to test their models and publish results – something most do voluntarily now. Lieu hasn’t yet introduced the bill, but he said it doesn’t direct any federal agencies to review AI models directly. That differs from a similar bill introduced by Sens Josh Hawley (R-MS) and Richard Blumenthal (D-CN) which would require a government-run evaluation program for advanced AI systems before they deployed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu acknowledged his bill wouldn’t be as strict, but he said it had a better chance at making it into law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My goal is to get something into law this term,” Lieu said, noting that House Majority Leader Scalise is openly hostile to AI regulation. “I’m not writing a bill that I’d have if I were king. I’m trying to write a bill that could pass a Republican-controlled House, a Republican-controlled Senate, and a Republican-controlled White House.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For the first time, Washington is getting close to deciding how to regulate artificial intelligence. And the fight that’s brewing isn’t about the technology, it’s about who gets to do the regulating.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the absence of a meaningful federal AI standard that focuses on consumer safety, states have introduced dozens of bills to protect residents against AI-related harms, including California’s AI safety bill SB-53 and Texas’s Responsible AI Governance Act, which prohibits intentional misuse of AI systems.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The tech giants and buzzy startups born out of Silicon Valley argue such laws create an unworkable patchwork that threatens innovation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s going to slow us in the race against China,” Josh Vlasto, co-founder of pro-AI PAC Leading the Future, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The industry, and several of its transplants in the White House, is pushing for a national standard or none at all. In the trenches of that all-or-nothing battle, new efforts have emerged to prohibit states from enacting their own AI legislation.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;House lawmakers are reportedly trying to use the National Defense Authorization Act (NDAA) to block state AI laws. At the same time, a leaked draft of a White House executive order also demonstrates strong support for preempting state efforts to regulate AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A sweeping preemption that would take away states’ rights to regulate AI is unpopular in Congress, which voted overwhelmingly against a similar moratorium earlier this year. Lawmakers have argued that without a federal standard in place, blocking states will leave consumers exposed to harm, and tech companies free to operate without oversight.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;To create that national standard, Rep. Ted Lieu (D-CA) and the bipartisan House AI Task Force are preparing a package of federal AI bills that cover a range of consumer protections, including fraud, healthcare, transparency, child safety, and catastrophic risk. A megabill such as this will likely take months, if not years, to become law, underscoring why the current rush to limit state authority has become one of the most contentious fights in AI policy.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-battle-lines-ndaa-and-the-eo"&gt;&lt;strong&gt;The battle lines: NDAA and the EO&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="US President Donald Trump displays an executive order on artificial intelligence he signed at the &amp;quot;Winning the AI Race&amp;quot; AI Summit at the Andrew W." class="wp-image-3030829" height="454" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Trump displays an executive order on AI he signed on July 23, 2025. (Photo by ANDREW CABALLERO-REYNOLDS / AFP) &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;ANDREW CABALLERO-REYNOLDS/AFP / Getty Images&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Efforts to block states from regulating AI have ramped up in recent weeks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The House has considered tucking language in the NDAA that would prevent states from regulating AI, Majority Leader Steve Scalise (R-LA) told Punchbowl News. Congress was reportedly working to finalize a deal on the defense bill before Thanksgiving, Politico reported. A source familiar with the matter told TechCrunch negotiations have focused on narrowing the scope to potentially preserve state authority over areas like kids’ safety and transparency.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Meanwhile, a leaked White House EO draft reveals the administration’s own potential preemption strategy. The EO, which has reportedly been put on hold, would create an “AI Litigation Task Force” to challenge state AI laws in court, direct agencies to evaluate state laws deemed “onerous,” and push the Federal Communications Commission and Federal Trade Commission towards national standards that override state rules.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the EO would give David Sacks – Trump’s AI and Crypto Czar and co-founder of VC firm Craft Ventures – co-lead authority on creating a uniform legal framework. This would give Sacks direct influence over AI policy that supersedes the typical role of the White House Office of Science and Technology Policy, and its head Michael Kratsios.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks has publicly advocated for blocking state regulation and keeping federal oversight menial, favoring industry self-regulation to “maximize growth.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-patchwork-argument"&gt;&lt;strong&gt;The patchwork argument&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Sacks’s position mirrors the viewpoint of much of the AI industry. Several pro-AI super PACs have emerged in recent months, throwing hundreds of millions of dollars into local and state elections to oppose candidates who support AI regulation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leading the Future – backed by Andreessen Horowitz, OpenAI president Greg Brockman, Perplexity, and Palantir co-founder Joe Lonsdale – has raised more than $100 million. This week, Leading the Future launched a $10 million campaign pushing Congress to craft a national AI policy that overrides state laws.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you’re trying to drive innovation in the tech sector, you can’t have a situation where all these laws keep popping up from people who don’t necessarily have the technical expertise,” Vlasto told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He argued that a patchwork of state regulations will “slow us in the race against China.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nathan Leamer, executive director of Build American AI, the PAC’s advocacy arm, confirmed the group supports preemption without AI-specific federal consumer protections in place. Leamer argued that existing laws, like those addressing fraud or product liability, are sufficient to handle AI harms. Where state laws often seek to prevent problems before they arise, Leamer favors a more reactive approach: let companies move fast, address problems in court later.&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-no-preemption-without-representation"&gt;&lt;strong&gt;No preemption without representation&lt;/strong&gt;&lt;/h3&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Alex Bores speaking at an event in Washington, D.C., on November 17, 2025." class="wp-image-3068604" height="510" src="https://techcrunch.com/wp-content/uploads/2025/11/IMG_9933.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Alex Bores speaking at an event in Washington, D.C., on November 17, 2025. &lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alex Bores, a New York Assembly member running for Congress, is one of Leading the Future’s first targets. He sponsored the RAISE Act, which requires large AI labs to have safety plans to prevent critical harms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I believe in the power of AI, and that is why it is so important to have reasonable regulations,” Bores told TechCrunch. “Ultimately, the AI that’s going to win in the marketplace is going to be trustworthy AI, and often the marketplace undervalues or puts poor short-term incentives on investing in safety.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bores supports a national AI policy, but argues states can move faster to address emerging risks.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And it’s true that states move quicker.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As of November 2025, 38 states have adopted more than 100 AI-related laws this year, mainly targeting deepfakes, transparency and disclosure, and government use of AI. (A recent study found that 69% of those laws impose no requirements on AI developers at all.)&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Activity in Congress provides more evidence of the slower-than-states argument. Hundreds of AI bills have been introduced, but few have passed. Since 2015, Rep. Lieu has introduced 67 bills to the House Science Committee. Only one became law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;More than 200 lawmakers signed an open letter opposing preemption in the NDAA, arguing that “states serve as laboratories of democracies” that must “retain the flexibility to confront new digital challenges as they arise.” Nearly 40 state attorneys general also sent an open letter opposing a state AI regulation ban.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cybersecurity expert Bruce Schneier and data scientist Nathan E. Sanders – authors of &lt;em&gt;Rewiring Democracy:&lt;/em&gt;&lt;em&gt; How AI Will Transform Our Politics, Government, and Citizenship &lt;/em&gt;– argue the patchwork complaint is overblown.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI companies already comply with tougher EU regulations, they note, and most industries find a way to operate under varying state laws. The real motive, they say, is avoiding accountability.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-what-could-a-federal-standard-look-like"&gt;&lt;strong&gt;What could a federal standard look like?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu is drafting an over 200-page megabill he hopes to introduce in December. It covers a range of issues, like fraud penalties, deepfake protections, whistleblower protections, compute resources for academia, and mandatory testing and disclosure for large language model companies.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That last provision would require AI labs to test their models and publish results – something most do voluntarily now. Lieu hasn’t yet introduced the bill, but he said it doesn’t direct any federal agencies to review AI models directly. That differs from a similar bill introduced by Sens Josh Hawley (R-MS) and Richard Blumenthal (D-CN) which would require a government-run evaluation program for advanced AI systems before they deployed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lieu acknowledged his bill wouldn’t be as strict, but he said it had a better chance at making it into law.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“My goal is to get something into law this term,” Lieu said, noting that House Majority Leader Scalise is openly hostile to AI regulation. “I’m not writing a bill that I’d have if I were king. I’m trying to write a bill that could pass a Republican-controlled House, a Republican-controlled Senate, and a Republican-controlled White House.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/28/the-race-to-regulate-ai-has-sparked-a-federal-vs-state-showdown/</guid><pubDate>Fri, 28 Nov 2025 15:00:00 +0000</pubDate></item><item><title>How OpenAI and Google see AI changing go-to-market strategies (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/28/how-openai-and-google-see-ai-changing-go-to-market-strategies/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/gtm-disrupt-2025.jpeg?resize=1200,745" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, when it was time for startups to start selling their product, they could turn to any number of traditional playbooks. But as with so many things, AI is changing how companies prepare to go to market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can do more with less than ever before,” Max Altschuler, general partner at GTMfund, told the audience at TechCrunch Disrupt last month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The challenge for founders and operators, though, will be threading the needle. While there has been some chatter of startups hiring developers more versed and loosing them on typical GTM problems, he said, there’s still a need for more specific domain expertise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you have great advisors around you can learn some of the tried-and-true playbooks. Those things haven’t gone out the window. I think it’s still necessary that you have a general understanding of how and why certain things work in marketing,” Altschuler said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alison Wagonfeld, vice president of marketing at Google Cloud, said the craft of marketing is still very much required.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “You certainly need the AI knowledge, the AI curiosity, the technologists, but also understanding what the purpose of marketing is, to understand customer insights, to do research, to see what great creative is like,” Wagonfeld said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Teams that adopt AI, though, can move more quickly “You can just get out there with so many more messages faster, and then you can think more holistically about what metrics am I driving for,” , she added. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Marc Manara, head of startups at OpenAI, has found many startups have embraced AI in their GTM strategy, though it’s not necessarily with the sole focus of minimizing how many resources they put toward it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s a movement of, yes, you can do more with less, but you can also be very focused with how you do it,” he said. “The degree of personalization and signal following that you can do with AI is differentiated now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Specifically, he said there are tools that help build leads which are much more sophisticated than in the past. Rather than just a simple query of a database, AI prompts can help startups find prospective customers that fit a very specific set of requirements.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inbound marketing has changed, too, he added, by using the results of those prompts to qualify and score inbound leads “with a lot more precision could have been in the past.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When it comes time for a startup to begin crafting its go-to-market strategy, Wagonfeld said its important to consider what qualities it might want in a GTM team.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a change in hiring perspective, where the past it was more about hiring specialists, people who really knew, sometimes even like a sub-specialty within marketing or within sales. And now it’s hiring for a sense of curiosity and understanding,” she said. “It’s almost the top thing to hire for now.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/gtm-disrupt-2025.jpeg?resize=1200,745" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For years, when it was time for startups to start selling their product, they could turn to any number of traditional playbooks. But as with so many things, AI is changing how companies prepare to go to market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can do more with less than ever before,” Max Altschuler, general partner at GTMfund, told the audience at TechCrunch Disrupt last month.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The challenge for founders and operators, though, will be threading the needle. While there has been some chatter of startups hiring developers more versed and loosing them on typical GTM problems, he said, there’s still a need for more specific domain expertise.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you have great advisors around you can learn some of the tried-and-true playbooks. Those things haven’t gone out the window. I think it’s still necessary that you have a general understanding of how and why certain things work in marketing,” Altschuler said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alison Wagonfeld, vice president of marketing at Google Cloud, said the craft of marketing is still very much required.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt; “You certainly need the AI knowledge, the AI curiosity, the technologists, but also understanding what the purpose of marketing is, to understand customer insights, to do research, to see what great creative is like,” Wagonfeld said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Teams that adopt AI, though, can move more quickly “You can just get out there with so many more messages faster, and then you can think more holistically about what metrics am I driving for,” , she added. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Marc Manara, head of startups at OpenAI, has found many startups have embraced AI in their GTM strategy, though it’s not necessarily with the sole focus of minimizing how many resources they put toward it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There’s a movement of, yes, you can do more with less, but you can also be very focused with how you do it,” he said. “The degree of personalization and signal following that you can do with AI is differentiated now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Specifically, he said there are tools that help build leads which are much more sophisticated than in the past. Rather than just a simple query of a database, AI prompts can help startups find prospective customers that fit a very specific set of requirements.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Inbound marketing has changed, too, he added, by using the results of those prompts to qualify and score inbound leads “with a lot more precision could have been in the past.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When it comes time for a startup to begin crafting its go-to-market strategy, Wagonfeld said its important to consider what qualities it might want in a GTM team.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s a change in hiring perspective, where the past it was more about hiring specialists, people who really knew, sometimes even like a sub-specialty within marketing or within sales. And now it’s hiring for a sense of curiosity and understanding,” she said. “It’s almost the top thing to hire for now.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/28/how-openai-and-google-see-ai-changing-go-to-market-strategies/</guid><pubDate>Fri, 28 Nov 2025 16:00:00 +0000</pubDate></item><item><title>What to be thankful for in AI in 2025 (AI | VentureBeat)</title><link>https://venturebeat.com/ai/what-to-be-thankful-for-in-ai-in-2025</link><description>[unable to retrieve full-text content]&lt;p&gt;Hello, dear readers. Happy belated Thanksgiving and Black Friday!&lt;/p&gt;&lt;p&gt;This year has felt like living inside a permanent DevDay. Every week, some lab drops a new model, a new agent framework, or a new “this changes everything” demo. It’s overwhelming. But it’s also the first year I’ve felt like AI is finally diversifying — not just one or two frontier models in the cloud, but a whole ecosystem: open and closed, giant and tiny, Western and Chinese, cloud and local.&lt;/p&gt;&lt;p&gt;So for this Thanksgiving edition, here’s what I’m genuinely thankful for in AI in 2025 — the releases that feel like they’ll matter in 12–24 months, not just during this week’s hype cycle.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;1. OpenAI kept shipping strong: GPT-5, GPT-5.1, Atlas, Sora 2 and open weights&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As the company that undeniably birthed the &amp;quot;generative AI&amp;quot; era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings. &lt;/p&gt;&lt;p&gt;Thankfully, OpenAI rose to the challenge and then some. Its headline act was GPT-5, unveiled in August as the next frontier reasoning model, followed in &lt;a href="https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5"&gt;November by GPT-5.1 &lt;/a&gt;with new Instant and Thinking variants that dynamically adjust how much “thinking time” they spend per task. &lt;/p&gt;&lt;p&gt;In practice, GPT-5’s launch was bumpy — VentureBeat documented early math and coding failures and a cooler-than-expected community reaction in “&lt;a href="https://venturebeat.com/ai/openais-gpt-5-rollout-is-not-going-smoothly"&gt;OpenAI’s GPT-5 rollout is not going smoothly&lt;/a&gt;,&amp;quot; but it quickly course corrected based on user feedback and, as a daily user of this model, I&amp;#x27;m personally pleased with it and impressed with it. &lt;/p&gt;&lt;p&gt;At the same time, enterprises actually using the models are reporting solid gains. &lt;a href="https://www.linkedin.com/company/zendesk-global/"&gt;ZenDesk Global&lt;/a&gt;, for example, &lt;a href="https://venturebeat.com/ai/zendesk-reports-30-faster-response-95-reliability-after-gpt-5-integration?utm_source=chatgpt.com"&gt;says GPT-5-powered agents now resolve more than half of customer tickets&lt;/a&gt;, with some customers seeing 80–90% resolution rates. That’s the quiet story: these models may not always impress the chattering classes on X, but they’re starting to move real KPIs.&lt;/p&gt;&lt;p&gt;On the tooling side, OpenAI finally gave developers a serious AI engineer with GPT-5.1-Codex-Max, a new coding model that can run long, agentic workflows and is already the default in OpenAI’s Codex environment. VentureBeat covered it in detail in “&lt;a href="https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24"&gt;OpenAI debuts GPT-5.1-Codex-Max coding model and it already completed a 24-hour task internally&lt;/a&gt;.” &lt;/p&gt;&lt;p&gt;Then there’s ChatGPT Atlas, &lt;a href="https://venturebeat.com/ai/openai-releases-chatgpt-atlas-an-ai-enabled-web-browser-to-challenge-google"&gt;a full browser with ChatGPT baked into the chrome itself&lt;/a&gt; — sidebar summaries, on-page analysis, and search tightly integrated into regular browsing. It’s the clearest sign yet that “assistant” and “browser” are on a collision course.&lt;/p&gt;&lt;p&gt;On the media side, Sora 2 turned the original Sora video demo into a full video-and-audio model with better physics, synchronized sound and dialogue, and more control over style and shot structure, plus &lt;a href="https://venturebeat.com/ai/openai-debuts-sora-2-ai-video-generator-app-with-sound-and-self-insertion"&gt;a dedicated Sora app&lt;/a&gt; with a full fledged social networking component, allowing any user to &lt;a href="https://www.linkedin.com/pulse/your-own-personalized-tv-network-pocket-reflections-sora-mwz3e/?trackingId=F0O9AmNbiyBUvYozY3z8Dw%3D%3D"&gt;create their own TV network in their pocket&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Finally — and maybe most symbolically — &lt;a href="https://venturebeat.com/ai/openai-returns-to-open-source-roots-with-new-models-gpt-oss-120b-and-gpt-oss-20b"&gt;OpenAI released gpt-oss-120B and gpt-oss-20B&lt;/a&gt;, open-weight MoE reasoning models under an Apache 2.0–style license. Whatever you think of their quality (and early open-source users have been loud about their complaints), this is the first time since GPT-2 that OpenAI has put serious weights into the public commons.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;2. China’s open-source wave goes mainstream&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2023–24 was about Llama and Mistral, 2025 belongs to China’s open-weight ecosystem.&lt;/p&gt;&lt;p&gt;A study from MIT and Hugging Face found that &lt;a href="https://www.ft.com/content/931c8218-a9d7-4cbd-8b08-27516637ff41?utm_source=chatgpt.com"&gt;China now slightly leads the U.S. in global open-model downloads&lt;/a&gt;, largely thanks to DeepSeek and Alibaba’s Qwen family. &lt;/p&gt;&lt;p&gt;Highlights:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;DeepSeek-R1 &lt;/b&gt;&lt;a href="https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek"&gt;dropped in January&lt;/a&gt; as an open-source reasoning model rivaling OpenAI’s o1, with MIT-licensed weights and a family of distilled smaller models. VentureBeat has followed the story from its release to its &lt;a href="https://venturebeat.com/security/deepseek-helps-speed-up-threat-detection-while-raising-national-security-concerns"&gt;cybersecurity impact&lt;/a&gt; to &lt;a href="https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh?utm_source=chatgpt.com"&gt;performance-tuned R1 variants&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Kimi K2 Thinking &lt;/b&gt;from Moonshot, a “thinking” open-source model that reasons step-by-step with tools, very much in the o1/R1 mold, and is positioned as &lt;a href="https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming"&gt;the best open reasoning model so far in the world.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Z.ai&lt;/b&gt; shipped &lt;a href="https://venturebeat.com/ai/chinese-startup-z-ai-launches-powerful-open-source-glm-4-5-model-family-with-powerpoint-creation"&gt;GLM-4.5 and GLM-4.5-Air&lt;/a&gt; as “agentic” models, open-sourcing base and hybrid reasoning variants on GitHub.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Baidu’s &lt;b&gt;ERNIE 4.5 &lt;/b&gt;family arrived as a fully open-sourced, multimodal MoE suite under Apache 2.0, including a 0.3B dense model and visual “&lt;a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5"&gt;Thinking&lt;/a&gt;” variants focused on charts, STEM, and tool use.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Alibaba’s &lt;b&gt;Qwen3 &lt;/b&gt;line — including Qwen3-Coder, large reasoning models, and the Qwen3-VL series released over the summer and fall months of 2025 — continues to set a high bar for open weights in coding, translation, and multimodal reasoning, leading me to declare this past summer as &amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/its-qwens-summer-new-open-source-qwen3-235b-a22b-thinking-2507-tops-openai-gemini-reasoning-models-on-key-benchmarks"&gt;Qwen&amp;#x27;s summer.&lt;/a&gt;&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;VentureBeat has been tracking these shifts, including Chinese math and reasoning models like &lt;a href="https://venturebeat.com/ai/new-open-source-math-model-light-r1-32b-surpasses-equivalent-deepseek-performance-with-only-1000-in-training-costs?utm_source=chatgpt.com"&gt;Light-R1-32B&lt;/a&gt; and Weibo’s tiny &lt;a href="https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on"&gt;VibeThinker-1.5B&lt;/a&gt;, which beat DeepSeek baselines on shoestring training budgets.&lt;/p&gt;&lt;p&gt;If you care about open ecosystems or on-premise options, this is the year China’s open-weight scene stopped being a curiosity and became a serious alternative.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3. Small and local models grow up&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Another thing I’m thankful for: we’re finally getting &lt;i&gt;good&lt;/i&gt; small models, not just toys.&lt;/p&gt;&lt;p&gt;Liquid AI spent 2025 pushing its Liquid Foundation Models (LFM2) and &lt;a href="https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model"&gt;LFM2-VL vision-language variants&lt;/a&gt;, designed from day one for low-latency, device-aware deployments — edge boxes, robots, and constrained servers, not just giant clusters. The newer &lt;a href="https://www.liquid.ai/blog/lfm2-vl-3b-a-new-efficient-vision-language-for-the-edge"&gt;LFM2-VL-3B&lt;/a&gt; targets embedded robotics and industrial autonomy, with demos planned at ROSCon. &lt;/p&gt;&lt;p&gt;On the big-tech side, &lt;a href="https://venturebeat.com/ai/google-unveils-open-source-gemma-3-model-with-128k-context-window"&gt;Google’s Gemma 3 line&lt;/a&gt; made a strong case that “tiny” can still be capable. Gemma 3 spans from 270M parameters up through 27B, all with open weights and multimodal support in the larger variants. &lt;/p&gt;&lt;p&gt;The standout is Gemma 3 270M, a compact model purpose-built for fine-tuning and structured text tasks — think custom formatters, routers, and watchdogs — covered both in Google’s developer blog and community discussions in local-LLM circles. &lt;/p&gt;&lt;p&gt;These models may never trend on X, but they’re exactly what you need for privacy-sensitive workloads, offline workflows, thin-client devices, and “agent swarms” where you don’t want every tool call hitting a giant frontier LLM.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4. Meta + Midjourney: aesthetics as a service&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;One of the stranger twists this year: Meta partnered with Midjourney instead of simply trying to beat it.&lt;/p&gt;&lt;p&gt;In August, Meta announced a deal to license Midjourney’s “aesthetic technology” — its image and video generation stack — and integrate it into Meta’s future models and products, from Facebook and Instagram feeds to Meta AI features.&lt;/p&gt;&lt;p&gt;VentureBeat covered the partnership in “&lt;a href="https://venturebeat.com/ai/meta-is-partnering-with-midjourney-and-will-license-its-technology-for-future-models-and-products"&gt;Meta is partnering with Midjourney and will license its technology for future models and products&lt;/a&gt;,” raising the obvious question: does this slow or reshape Midjourney’s own API roadmap? Still awaiting an answer there, but unfortunately, stated plans for an API release have yet to materialize, suggesting that it has. &lt;/p&gt;&lt;p&gt;For creators and brands, though, the immediate implication is simple: Midjourney-grade visuals start to show up in mainstream social tools instead of being locked away in a Discord bot. That could normalize higher-quality AI art for a much wider audience — and force rivals like OpenAI, Google, and Black Forest Labs to keep raising the bar.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;5. Google’s Gemini 3 and Nano Banana Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google tried to answer GPT-5 with Gemini 3, billed as its most capable model yet, with better reasoning, coding, and multimodal understanding, plus a new Deep Think mode for slow, hard problems. &lt;/p&gt;&lt;p&gt;VentureBeat’s coverage, “&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google unveils Gemini 3 claiming the lead in math, science, multimodal and agentic AI&lt;/a&gt;,” framed it as a direct shot at frontier benchmarks and agentic workflows. &lt;/p&gt;&lt;p&gt;But the surprise hit is &lt;a href="https://venturebeat.com/ai/googles-upgraded-nano-banana-pro-ai-image-model-hailed-as-absolutely-bonkers"&gt;Nano Banana Pro (Gemini 3 Pro Image), Google’s new flagship image generator&lt;/a&gt;. It specializes in infographics, diagrams, multi-subject scenes, and multilingual text that actually renders legibly across 2K and 4K resolutions. &lt;/p&gt;&lt;p&gt;In the world of enterprise AI — where charts, product schematics, and “explain this system visually” images matter more than fantasy dragons — that’s a big deal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;6. Wild cards I’m keeping an eye on&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;A few more releases I’m thankful for, even if they don’t fit neatly into one bucket:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Black Forest Labs’ Flux.2&lt;/b&gt; image models, which launched just earlier this week with ambitions to challenge both Nano Banana Pro and Midjourney on quality and control. VentureBeat dug into the details in “&lt;a href="https://venturebeat.com/ai/black-forest-labs-launches-flux-2-ai-image-models-to-challenge-nano-banana"&gt;Black Forest Labs launches Flux.2 AI image models to challenge Nano Banana Pro and Midjourney&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Anthropic’s Claude Opus 4.5&lt;/b&gt;, a new flagship that aims for cheaper, more capable coding and long-horizon task execution, covered in “&lt;a href="https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding-skills-that-beat-humans"&gt;Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans&lt;/a&gt;.&amp;quot; &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A steady drumbeat of open math/reasoning models — from Light-R1 to VibeThinker and others — that show you don’t need $100M training runs to move the needle.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Last thought (for now)&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2024 was the year of “one big model in the cloud,” 2025 is the year the map exploded: multiple frontiers at the top, China taking the lead in open models, small and efficient systems maturing fast, and creative ecosystems like Midjourney getting pulled into big-tech stacks.&lt;/p&gt;&lt;p&gt;I’m thankful not just for any single model, but for the fact that we now have &lt;i&gt;options&lt;/i&gt; — closed and open, local and hosted, reasoning-first and media-first. For journalists, builders, and enterprises, that diversity is the real story of 2025.&lt;/p&gt;&lt;p&gt;Happy holidays and best to you and your loved ones!&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Hello, dear readers. Happy belated Thanksgiving and Black Friday!&lt;/p&gt;&lt;p&gt;This year has felt like living inside a permanent DevDay. Every week, some lab drops a new model, a new agent framework, or a new “this changes everything” demo. It’s overwhelming. But it’s also the first year I’ve felt like AI is finally diversifying — not just one or two frontier models in the cloud, but a whole ecosystem: open and closed, giant and tiny, Western and Chinese, cloud and local.&lt;/p&gt;&lt;p&gt;So for this Thanksgiving edition, here’s what I’m genuinely thankful for in AI in 2025 — the releases that feel like they’ll matter in 12–24 months, not just during this week’s hype cycle.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;1. OpenAI kept shipping strong: GPT-5, GPT-5.1, Atlas, Sora 2 and open weights&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;As the company that undeniably birthed the &amp;quot;generative AI&amp;quot; era with its viral hit product ChatGPT in late 2022, OpenAI arguably had among the hardest tasks of any AI company in 2025: continue its growth trajectory even as well-funded competitors like Google with its Gemini models and other startups like Anthropic fielded their own highly competitive offerings. &lt;/p&gt;&lt;p&gt;Thankfully, OpenAI rose to the challenge and then some. Its headline act was GPT-5, unveiled in August as the next frontier reasoning model, followed in &lt;a href="https://venturebeat.com/ai/openai-reboots-chatgpt-experience-with-gpt-5-1-after-mixed-reviews-of-gpt-5"&gt;November by GPT-5.1 &lt;/a&gt;with new Instant and Thinking variants that dynamically adjust how much “thinking time” they spend per task. &lt;/p&gt;&lt;p&gt;In practice, GPT-5’s launch was bumpy — VentureBeat documented early math and coding failures and a cooler-than-expected community reaction in “&lt;a href="https://venturebeat.com/ai/openais-gpt-5-rollout-is-not-going-smoothly"&gt;OpenAI’s GPT-5 rollout is not going smoothly&lt;/a&gt;,&amp;quot; but it quickly course corrected based on user feedback and, as a daily user of this model, I&amp;#x27;m personally pleased with it and impressed with it. &lt;/p&gt;&lt;p&gt;At the same time, enterprises actually using the models are reporting solid gains. &lt;a href="https://www.linkedin.com/company/zendesk-global/"&gt;ZenDesk Global&lt;/a&gt;, for example, &lt;a href="https://venturebeat.com/ai/zendesk-reports-30-faster-response-95-reliability-after-gpt-5-integration?utm_source=chatgpt.com"&gt;says GPT-5-powered agents now resolve more than half of customer tickets&lt;/a&gt;, with some customers seeing 80–90% resolution rates. That’s the quiet story: these models may not always impress the chattering classes on X, but they’re starting to move real KPIs.&lt;/p&gt;&lt;p&gt;On the tooling side, OpenAI finally gave developers a serious AI engineer with GPT-5.1-Codex-Max, a new coding model that can run long, agentic workflows and is already the default in OpenAI’s Codex environment. VentureBeat covered it in detail in “&lt;a href="https://venturebeat.com/ai/openai-debuts-gpt-5-1-codex-max-coding-model-and-it-already-completed-a-24"&gt;OpenAI debuts GPT-5.1-Codex-Max coding model and it already completed a 24-hour task internally&lt;/a&gt;.” &lt;/p&gt;&lt;p&gt;Then there’s ChatGPT Atlas, &lt;a href="https://venturebeat.com/ai/openai-releases-chatgpt-atlas-an-ai-enabled-web-browser-to-challenge-google"&gt;a full browser with ChatGPT baked into the chrome itself&lt;/a&gt; — sidebar summaries, on-page analysis, and search tightly integrated into regular browsing. It’s the clearest sign yet that “assistant” and “browser” are on a collision course.&lt;/p&gt;&lt;p&gt;On the media side, Sora 2 turned the original Sora video demo into a full video-and-audio model with better physics, synchronized sound and dialogue, and more control over style and shot structure, plus &lt;a href="https://venturebeat.com/ai/openai-debuts-sora-2-ai-video-generator-app-with-sound-and-self-insertion"&gt;a dedicated Sora app&lt;/a&gt; with a full fledged social networking component, allowing any user to &lt;a href="https://www.linkedin.com/pulse/your-own-personalized-tv-network-pocket-reflections-sora-mwz3e/?trackingId=F0O9AmNbiyBUvYozY3z8Dw%3D%3D"&gt;create their own TV network in their pocket&lt;/a&gt;. &lt;/p&gt;&lt;p&gt;Finally — and maybe most symbolically — &lt;a href="https://venturebeat.com/ai/openai-returns-to-open-source-roots-with-new-models-gpt-oss-120b-and-gpt-oss-20b"&gt;OpenAI released gpt-oss-120B and gpt-oss-20B&lt;/a&gt;, open-weight MoE reasoning models under an Apache 2.0–style license. Whatever you think of their quality (and early open-source users have been loud about their complaints), this is the first time since GPT-2 that OpenAI has put serious weights into the public commons.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;2. China’s open-source wave goes mainstream&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2023–24 was about Llama and Mistral, 2025 belongs to China’s open-weight ecosystem.&lt;/p&gt;&lt;p&gt;A study from MIT and Hugging Face found that &lt;a href="https://www.ft.com/content/931c8218-a9d7-4cbd-8b08-27516637ff41?utm_source=chatgpt.com"&gt;China now slightly leads the U.S. in global open-model downloads&lt;/a&gt;, largely thanks to DeepSeek and Alibaba’s Qwen family. &lt;/p&gt;&lt;p&gt;Highlights:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;DeepSeek-R1 &lt;/b&gt;&lt;a href="https://venturebeat.com/ai/why-everyone-in-ai-is-freaking-out-about-deepseek"&gt;dropped in January&lt;/a&gt; as an open-source reasoning model rivaling OpenAI’s o1, with MIT-licensed weights and a family of distilled smaller models. VentureBeat has followed the story from its release to its &lt;a href="https://venturebeat.com/security/deepseek-helps-speed-up-threat-detection-while-raising-national-security-concerns"&gt;cybersecurity impact&lt;/a&gt; to &lt;a href="https://venturebeat.com/ai/holy-smokes-a-new-200-faster-deepseek-r1-0528-variant-appears-from-german-lab-tng-technology-consulting-gmbh?utm_source=chatgpt.com"&gt;performance-tuned R1 variants&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Kimi K2 Thinking &lt;/b&gt;from Moonshot, a “thinking” open-source model that reasons step-by-step with tools, very much in the o1/R1 mold, and is positioned as &lt;a href="https://venturebeat.com/ai/moonshots-kimi-k2-thinking-emerges-as-leading-open-source-ai-outperforming"&gt;the best open reasoning model so far in the world.&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Z.ai&lt;/b&gt; shipped &lt;a href="https://venturebeat.com/ai/chinese-startup-z-ai-launches-powerful-open-source-glm-4-5-model-family-with-powerpoint-creation"&gt;GLM-4.5 and GLM-4.5-Air&lt;/a&gt; as “agentic” models, open-sourcing base and hybrid reasoning variants on GitHub.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Baidu’s &lt;b&gt;ERNIE 4.5 &lt;/b&gt;family arrived as a fully open-sourced, multimodal MoE suite under Apache 2.0, including a 0.3B dense model and visual “&lt;a href="https://venturebeat.com/ai/baidu-just-dropped-an-open-source-multimodal-ai-that-it-claims-beats-gpt-5"&gt;Thinking&lt;/a&gt;” variants focused on charts, STEM, and tool use.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Alibaba’s &lt;b&gt;Qwen3 &lt;/b&gt;line — including Qwen3-Coder, large reasoning models, and the Qwen3-VL series released over the summer and fall months of 2025 — continues to set a high bar for open weights in coding, translation, and multimodal reasoning, leading me to declare this past summer as &amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://venturebeat.com/ai/its-qwens-summer-new-open-source-qwen3-235b-a22b-thinking-2507-tops-openai-gemini-reasoning-models-on-key-benchmarks"&gt;Qwen&amp;#x27;s summer.&lt;/a&gt;&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;VentureBeat has been tracking these shifts, including Chinese math and reasoning models like &lt;a href="https://venturebeat.com/ai/new-open-source-math-model-light-r1-32b-surpasses-equivalent-deepseek-performance-with-only-1000-in-training-costs?utm_source=chatgpt.com"&gt;Light-R1-32B&lt;/a&gt; and Weibo’s tiny &lt;a href="https://venturebeat.com/ai/weibos-new-open-source-ai-model-vibethinker-1-5b-outperforms-deepseek-r1-on"&gt;VibeThinker-1.5B&lt;/a&gt;, which beat DeepSeek baselines on shoestring training budgets.&lt;/p&gt;&lt;p&gt;If you care about open ecosystems or on-premise options, this is the year China’s open-weight scene stopped being a curiosity and became a serious alternative.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;3. Small and local models grow up&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Another thing I’m thankful for: we’re finally getting &lt;i&gt;good&lt;/i&gt; small models, not just toys.&lt;/p&gt;&lt;p&gt;Liquid AI spent 2025 pushing its Liquid Foundation Models (LFM2) and &lt;a href="https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model"&gt;LFM2-VL vision-language variants&lt;/a&gt;, designed from day one for low-latency, device-aware deployments — edge boxes, robots, and constrained servers, not just giant clusters. The newer &lt;a href="https://www.liquid.ai/blog/lfm2-vl-3b-a-new-efficient-vision-language-for-the-edge"&gt;LFM2-VL-3B&lt;/a&gt; targets embedded robotics and industrial autonomy, with demos planned at ROSCon. &lt;/p&gt;&lt;p&gt;On the big-tech side, &lt;a href="https://venturebeat.com/ai/google-unveils-open-source-gemma-3-model-with-128k-context-window"&gt;Google’s Gemma 3 line&lt;/a&gt; made a strong case that “tiny” can still be capable. Gemma 3 spans from 270M parameters up through 27B, all with open weights and multimodal support in the larger variants. &lt;/p&gt;&lt;p&gt;The standout is Gemma 3 270M, a compact model purpose-built for fine-tuning and structured text tasks — think custom formatters, routers, and watchdogs — covered both in Google’s developer blog and community discussions in local-LLM circles. &lt;/p&gt;&lt;p&gt;These models may never trend on X, but they’re exactly what you need for privacy-sensitive workloads, offline workflows, thin-client devices, and “agent swarms” where you don’t want every tool call hitting a giant frontier LLM.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;4. Meta + Midjourney: aesthetics as a service&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;One of the stranger twists this year: Meta partnered with Midjourney instead of simply trying to beat it.&lt;/p&gt;&lt;p&gt;In August, Meta announced a deal to license Midjourney’s “aesthetic technology” — its image and video generation stack — and integrate it into Meta’s future models and products, from Facebook and Instagram feeds to Meta AI features.&lt;/p&gt;&lt;p&gt;VentureBeat covered the partnership in “&lt;a href="https://venturebeat.com/ai/meta-is-partnering-with-midjourney-and-will-license-its-technology-for-future-models-and-products"&gt;Meta is partnering with Midjourney and will license its technology for future models and products&lt;/a&gt;,” raising the obvious question: does this slow or reshape Midjourney’s own API roadmap? Still awaiting an answer there, but unfortunately, stated plans for an API release have yet to materialize, suggesting that it has. &lt;/p&gt;&lt;p&gt;For creators and brands, though, the immediate implication is simple: Midjourney-grade visuals start to show up in mainstream social tools instead of being locked away in a Discord bot. That could normalize higher-quality AI art for a much wider audience — and force rivals like OpenAI, Google, and Black Forest Labs to keep raising the bar.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;5. Google’s Gemini 3 and Nano Banana Pro&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;Google tried to answer GPT-5 with Gemini 3, billed as its most capable model yet, with better reasoning, coding, and multimodal understanding, plus a new Deep Think mode for slow, hard problems. &lt;/p&gt;&lt;p&gt;VentureBeat’s coverage, “&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt;Google unveils Gemini 3 claiming the lead in math, science, multimodal and agentic AI&lt;/a&gt;,” framed it as a direct shot at frontier benchmarks and agentic workflows. &lt;/p&gt;&lt;p&gt;But the surprise hit is &lt;a href="https://venturebeat.com/ai/googles-upgraded-nano-banana-pro-ai-image-model-hailed-as-absolutely-bonkers"&gt;Nano Banana Pro (Gemini 3 Pro Image), Google’s new flagship image generator&lt;/a&gt;. It specializes in infographics, diagrams, multi-subject scenes, and multilingual text that actually renders legibly across 2K and 4K resolutions. &lt;/p&gt;&lt;p&gt;In the world of enterprise AI — where charts, product schematics, and “explain this system visually” images matter more than fantasy dragons — that’s a big deal.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;6. Wild cards I’m keeping an eye on&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;A few more releases I’m thankful for, even if they don’t fit neatly into one bucket:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Black Forest Labs’ Flux.2&lt;/b&gt; image models, which launched just earlier this week with ambitions to challenge both Nano Banana Pro and Midjourney on quality and control. VentureBeat dug into the details in “&lt;a href="https://venturebeat.com/ai/black-forest-labs-launches-flux-2-ai-image-models-to-challenge-nano-banana"&gt;Black Forest Labs launches Flux.2 AI image models to challenge Nano Banana Pro and Midjourney&lt;/a&gt;.&amp;quot;&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Anthropic’s Claude Opus 4.5&lt;/b&gt;, a new flagship that aims for cheaper, more capable coding and long-horizon task execution, covered in “&lt;a href="https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding-skills-that-beat-humans"&gt;Anthropic’s Claude Opus 4.5 is here: Cheaper AI, infinite chats, and coding skills that beat humans&lt;/a&gt;.&amp;quot; &lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;A steady drumbeat of open math/reasoning models — from Light-R1 to VibeThinker and others — that show you don’t need $100M training runs to move the needle.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;h3&gt;&lt;b&gt;Last thought (for now)&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;If 2024 was the year of “one big model in the cloud,” 2025 is the year the map exploded: multiple frontiers at the top, China taking the lead in open models, small and efficient systems maturing fast, and creative ecosystems like Midjourney getting pulled into big-tech stacks.&lt;/p&gt;&lt;p&gt;I’m thankful not just for any single model, but for the fact that we now have &lt;i&gt;options&lt;/i&gt; — closed and open, local and hosted, reasoning-first and media-first. For journalists, builders, and enterprises, that diversity is the real story of 2025.&lt;/p&gt;&lt;p&gt;Happy holidays and best to you and your loved ones!&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/what-to-be-thankful-for-in-ai-in-2025</guid><pubDate>Fri, 28 Nov 2025 16:19:00 +0000</pubDate></item><item><title>Supabase CEO on the “painful” decisions that built a $5B company (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/supabase-ceo-on-the-painful-decisions-that-built-a-5b-company/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Supabase-Ant-Wilson-Paul-Copplestone.jpg?w=1067" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vibe coding has taken the tech industry by storm, and&amp;nbsp;it’s&amp;nbsp;not just the&amp;nbsp;Lovables&amp;nbsp;and&amp;nbsp;Replits&amp;nbsp;of the world that&amp;nbsp;are&amp;nbsp;winning. The startups building the infrastructure behind them are cashing in too.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Supabase, the open-source database platform&amp;nbsp;that’s&amp;nbsp;become the backend of choice for the vibe-coding world,&amp;nbsp;raised $100 million at a&amp;nbsp;$5 billion&amp;nbsp;valuation&amp;nbsp;just months after closing $200 million at&amp;nbsp;$2 billion. But co-founder and CEO Paul&amp;nbsp;Copplestone&amp;nbsp;has a surprising strategy: he keeps turning down million-dollar enterprise contracts&amp;nbsp;from deep-pocketed but demanding customers.&amp;nbsp;He’s&amp;nbsp;betting instead that&amp;nbsp;if he sticks to his own product&amp;nbsp;vision, the world will come to him. So far,&amp;nbsp;he’s&amp;nbsp;been right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Julie Bort sat down with&amp;nbsp;Copplestone&amp;nbsp;to explore&amp;nbsp;Supabase’s&amp;nbsp;rise and what it means for&amp;nbsp;vibe coding, developers and&amp;nbsp;the database&amp;nbsp;giants who have historically controlled this market.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Listen to the full episode to hear about:&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why&amp;nbsp;Copplestone&amp;nbsp;believes “the death of Oracle won’t take a generation”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;The technical moonshots&amp;nbsp;Supabase&amp;nbsp;is funding to make Postgres even more scalable&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How he decides which enterprise deals to turn down, and why it still “feels very painful”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Supabase-Ant-Wilson-Paul-Copplestone.jpg?w=1067" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;Vibe coding has taken the tech industry by storm, and&amp;nbsp;it’s&amp;nbsp;not just the&amp;nbsp;Lovables&amp;nbsp;and&amp;nbsp;Replits&amp;nbsp;of the world that&amp;nbsp;are&amp;nbsp;winning. The startups building the infrastructure behind them are cashing in too.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Supabase, the open-source database platform&amp;nbsp;that’s&amp;nbsp;become the backend of choice for the vibe-coding world,&amp;nbsp;raised $100 million at a&amp;nbsp;$5 billion&amp;nbsp;valuation&amp;nbsp;just months after closing $200 million at&amp;nbsp;$2 billion. But co-founder and CEO Paul&amp;nbsp;Copplestone&amp;nbsp;has a surprising strategy: he keeps turning down million-dollar enterprise contracts&amp;nbsp;from deep-pocketed but demanding customers.&amp;nbsp;He’s&amp;nbsp;betting instead that&amp;nbsp;if he sticks to his own product&amp;nbsp;vision, the world will come to him. So far,&amp;nbsp;he’s&amp;nbsp;been right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Julie Bort sat down with&amp;nbsp;Copplestone&amp;nbsp;to explore&amp;nbsp;Supabase’s&amp;nbsp;rise and what it means for&amp;nbsp;vibe coding, developers and&amp;nbsp;the database&amp;nbsp;giants who have historically controlled this market.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Listen to the full episode to hear about:&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Why&amp;nbsp;Copplestone&amp;nbsp;believes “the death of Oracle won’t take a generation”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;The technical moonshots&amp;nbsp;Supabase&amp;nbsp;is funding to make Postgres even more scalable&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;How he decides which enterprise deals to turn down, and why it still “feels very painful”&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/supabase-ceo-on-the-painful-decisions-that-built-a-5b-company/</guid><pubDate>Fri, 28 Nov 2025 17:20:00 +0000</pubDate></item><item><title>[NEW] Anthropic says it solved the long-running AI agent problem with a new multi-session Claude SDK (AI | VentureBeat)</title><link>https://venturebeat.com/ai/anthropic-says-it-solved-the-long-running-ai-agent-problem-with-a-new-multi</link><description>[unable to retrieve full-text content]&lt;p&gt;Agent memory remains a problem that enterprises want to fix, as agents forget some instructions or conversations the longer they run. &lt;/p&gt;&lt;p&gt;&lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; believes it has solved this issue for its &lt;a href="https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker"&gt;&lt;u&gt;Claude Agent SDK&lt;/u&gt;&lt;/a&gt;, developing a two-fold solution that allows an agent to work across different context windows.&lt;/p&gt;&lt;p&gt;“The core challenge of long-running agents is that they must work in discrete sessions, and each new session begins with no memory of what came before,” Anthropic wrote in &lt;a href="https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents"&gt;&lt;u&gt;a blog post&lt;/u&gt;&lt;/a&gt;. “Because context windows are limited, and because most complex projects cannot be completed within a single window, agents need a way to bridge the gap between coding sessions.”&lt;/p&gt;&lt;p&gt;Anthropic engineers proposed a two-fold approach for its Agent SDK: An initializer agent to set up the environment, and a coding agent to make incremental progress in each session and leave artifacts for the next.  &lt;/p&gt;&lt;h2&gt;The agent memory problem&lt;/h2&gt;&lt;p&gt;Since agents are built on foundation models, they remain constrained by the limited, although continually growing, context windows. For long-running agents, this could create a larger problem, leading the agent to forget instructions and behave abnormally while performing a task. &lt;a href="https://venturebeat.com/ai/enhancing-ai-agents-with-long-term-memory-insights-into-langmem-sdk-memobase-and-the-a-mem-framework"&gt;&lt;u&gt;Enhancing agent memory&lt;/u&gt;&lt;/a&gt; becomes essential for consistent, business-safe performance. &lt;/p&gt;&lt;p&gt;Several methods emerged over the past year, all attempting to bridge the gap between context windows and agent memory. &lt;a href="https://www.langchain.com/"&gt;&lt;u&gt;LangChain&lt;/u&gt;&lt;/a&gt;’s LangMem SDK, &lt;a href="https://www.memobase.io/"&gt;&lt;u&gt;Memobase&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;’s Swarm are examples of companies offering memory solutions. Research on agentic memory has also exploded recently, with proposed &lt;a href="https://venturebeat.com/ai/how-procedural-memory-can-cut-the-cost-and-complexity-of-ai-agents"&gt;&lt;u&gt;frameworks like Memp&lt;/u&gt;&lt;/a&gt; and the &lt;a href="https://venturebeat.com/ai/googles-nested-learning-paradigm-could-solve-ais-memory-and-continual"&gt;&lt;u&gt;Nested Learning Paradigm&lt;/u&gt;&lt;/a&gt; from &lt;a href="https://www.google.com/"&gt;&lt;u&gt;Google&lt;/u&gt;&lt;/a&gt; offering new alternatives to enhance memory. &lt;/p&gt;&lt;p&gt;Many of the current memory frameworks are open source and can ideally adapt to different large language models (LLMs) powering agents. Anthropic’s approach improves its Claude Agent SDK. &lt;/p&gt;&lt;h2&gt;How it works&lt;/h2&gt;&lt;p&gt;Anthropic identified that even though the Claude Agent SDK had context management capabilities and “should be possible for an agent to continue to do useful work for an arbitrarily long time,” it was not sufficient. The company said in its blog post that a model &lt;a href="https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding"&gt;&lt;u&gt;like Opus 4.5&lt;/u&gt;&lt;/a&gt; running the Claude Agent SDK can “fall short of building a production-quality web app if it’s only given a high-level prompt, such as &amp;#x27;build a clone of claude.ai.&amp;#x27;” &lt;/p&gt;&lt;p&gt;The failures manifested in two patterns, Anthropic said. First, the agent tried to do too much, causing the model to run out of context in the middle. The agent then has to guess what happened and cannot pass clear instructions to the next agent. The second failure occurs later on, after some features have already been built. The agent sees progress has been made and just declares the job done. &lt;/p&gt;&lt;p&gt;Anthropic researchers broke down the solution: Setting up an initial environment to lay the foundation for features and prompting each agent to make incremental progress towards a goal, while still leaving a clean slate at the end. &lt;/p&gt;&lt;p&gt;This is where the two-part solution of Anthropic&amp;#x27;s agent comes in. The initializer agent sets up the environment, logging what agents have done and which files have been added. The coding agent will then ask models to make incremental progress and leave structured updates. &lt;/p&gt;&lt;p&gt;“Inspiration for these practices came from knowing what effective software engineers do every day,” Anthropic said. &lt;/p&gt;&lt;p&gt;The researchers said they added testing tools to the coding agent, improving its ability to identify and fix bugs that weren’t obvious from the code alone. &lt;/p&gt;&lt;h2&gt;Future research&lt;/h2&gt;&lt;p&gt;Anthropic noted that its approach is “one possible set of solutions in a long-running agent harness.” However, this is just the beginning stage of what could become a wider research area for many in the AI space. &lt;/p&gt;&lt;p&gt;The company said its experiments to boost long-term memory for agents haven’t shown whether a single general-purpose coding agent works best across contexts or a multi-agent structure. &lt;/p&gt;&lt;p&gt;Its demo also focused on full-stack web app development, so other experiments should focus on generalizing the results across different tasks.&lt;/p&gt;&lt;p&gt;“It’s likely that some or all of these lessons can be applied to the types of long-running agentic tasks required in, for example, scientific research or financial modeling,” Anthropic said. &lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Agent memory remains a problem that enterprises want to fix, as agents forget some instructions or conversations the longer they run. &lt;/p&gt;&lt;p&gt;&lt;a href="https://www.anthropic.com/"&gt;&lt;u&gt;Anthropic&lt;/u&gt;&lt;/a&gt; believes it has solved this issue for its &lt;a href="https://venturebeat.com/ai/anthropics-new-claude-can-code-for-30-hours-think-of-it-as-your-ai-coworker"&gt;&lt;u&gt;Claude Agent SDK&lt;/u&gt;&lt;/a&gt;, developing a two-fold solution that allows an agent to work across different context windows.&lt;/p&gt;&lt;p&gt;“The core challenge of long-running agents is that they must work in discrete sessions, and each new session begins with no memory of what came before,” Anthropic wrote in &lt;a href="https://www.anthropic.com/engineering/effective-harnesses-for-long-running-agents"&gt;&lt;u&gt;a blog post&lt;/u&gt;&lt;/a&gt;. “Because context windows are limited, and because most complex projects cannot be completed within a single window, agents need a way to bridge the gap between coding sessions.”&lt;/p&gt;&lt;p&gt;Anthropic engineers proposed a two-fold approach for its Agent SDK: An initializer agent to set up the environment, and a coding agent to make incremental progress in each session and leave artifacts for the next.  &lt;/p&gt;&lt;h2&gt;The agent memory problem&lt;/h2&gt;&lt;p&gt;Since agents are built on foundation models, they remain constrained by the limited, although continually growing, context windows. For long-running agents, this could create a larger problem, leading the agent to forget instructions and behave abnormally while performing a task. &lt;a href="https://venturebeat.com/ai/enhancing-ai-agents-with-long-term-memory-insights-into-langmem-sdk-memobase-and-the-a-mem-framework"&gt;&lt;u&gt;Enhancing agent memory&lt;/u&gt;&lt;/a&gt; becomes essential for consistent, business-safe performance. &lt;/p&gt;&lt;p&gt;Several methods emerged over the past year, all attempting to bridge the gap between context windows and agent memory. &lt;a href="https://www.langchain.com/"&gt;&lt;u&gt;LangChain&lt;/u&gt;&lt;/a&gt;’s LangMem SDK, &lt;a href="https://www.memobase.io/"&gt;&lt;u&gt;Memobase&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://openai.com/"&gt;&lt;u&gt;OpenAI&lt;/u&gt;&lt;/a&gt;’s Swarm are examples of companies offering memory solutions. Research on agentic memory has also exploded recently, with proposed &lt;a href="https://venturebeat.com/ai/how-procedural-memory-can-cut-the-cost-and-complexity-of-ai-agents"&gt;&lt;u&gt;frameworks like Memp&lt;/u&gt;&lt;/a&gt; and the &lt;a href="https://venturebeat.com/ai/googles-nested-learning-paradigm-could-solve-ais-memory-and-continual"&gt;&lt;u&gt;Nested Learning Paradigm&lt;/u&gt;&lt;/a&gt; from &lt;a href="https://www.google.com/"&gt;&lt;u&gt;Google&lt;/u&gt;&lt;/a&gt; offering new alternatives to enhance memory. &lt;/p&gt;&lt;p&gt;Many of the current memory frameworks are open source and can ideally adapt to different large language models (LLMs) powering agents. Anthropic’s approach improves its Claude Agent SDK. &lt;/p&gt;&lt;h2&gt;How it works&lt;/h2&gt;&lt;p&gt;Anthropic identified that even though the Claude Agent SDK had context management capabilities and “should be possible for an agent to continue to do useful work for an arbitrarily long time,” it was not sufficient. The company said in its blog post that a model &lt;a href="https://venturebeat.com/ai/anthropics-claude-opus-4-5-is-here-cheaper-ai-infinite-chats-and-coding"&gt;&lt;u&gt;like Opus 4.5&lt;/u&gt;&lt;/a&gt; running the Claude Agent SDK can “fall short of building a production-quality web app if it’s only given a high-level prompt, such as &amp;#x27;build a clone of claude.ai.&amp;#x27;” &lt;/p&gt;&lt;p&gt;The failures manifested in two patterns, Anthropic said. First, the agent tried to do too much, causing the model to run out of context in the middle. The agent then has to guess what happened and cannot pass clear instructions to the next agent. The second failure occurs later on, after some features have already been built. The agent sees progress has been made and just declares the job done. &lt;/p&gt;&lt;p&gt;Anthropic researchers broke down the solution: Setting up an initial environment to lay the foundation for features and prompting each agent to make incremental progress towards a goal, while still leaving a clean slate at the end. &lt;/p&gt;&lt;p&gt;This is where the two-part solution of Anthropic&amp;#x27;s agent comes in. The initializer agent sets up the environment, logging what agents have done and which files have been added. The coding agent will then ask models to make incremental progress and leave structured updates. &lt;/p&gt;&lt;p&gt;“Inspiration for these practices came from knowing what effective software engineers do every day,” Anthropic said. &lt;/p&gt;&lt;p&gt;The researchers said they added testing tools to the coding agent, improving its ability to identify and fix bugs that weren’t obvious from the code alone. &lt;/p&gt;&lt;h2&gt;Future research&lt;/h2&gt;&lt;p&gt;Anthropic noted that its approach is “one possible set of solutions in a long-running agent harness.” However, this is just the beginning stage of what could become a wider research area for many in the AI space. &lt;/p&gt;&lt;p&gt;The company said its experiments to boost long-term memory for agents haven’t shown whether a single general-purpose coding agent works best across contexts or a multi-agent structure. &lt;/p&gt;&lt;p&gt;Its demo also focused on full-stack web app development, so other experiments should focus on generalizing the results across different tasks.&lt;/p&gt;&lt;p&gt;“It’s likely that some or all of these lessons can be applied to the types of long-running agentic tasks required in, for example, scientific research or financial modeling,” Anthropic said. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/anthropic-says-it-solved-the-long-running-ai-agent-problem-with-a-new-multi</guid><pubDate>Fri, 28 Nov 2025 19:30:00 +0000</pubDate></item><item><title>[NEW] Supabase hit $5B by turning down million-dollar contracts. Here’s why. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/supabase-hit-5b-by-turning-down-million-dollar-contracts-heres-why/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/postgres-bloat-1.jpeg?w=640" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30711601"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Vibe coding has taken the tech industry by storm, and&amp;nbsp;it’s&amp;nbsp;not just the&amp;nbsp;Lovables&amp;nbsp;and&amp;nbsp;Replits&amp;nbsp;of the world that&amp;nbsp;are&amp;nbsp;winning. The startups building the infrastructure behind them are cashing in too.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Supabase, the open-source database platform&amp;nbsp;that’s&amp;nbsp;become the backend of choice for the vibe-coding world,&amp;nbsp;raised $100 million at a&amp;nbsp;$5 billion&amp;nbsp;valuation&amp;nbsp;just months after closing $200 million at&amp;nbsp;$2 billion. But co-founder and CEO Paul&amp;nbsp;Copplestone&amp;nbsp;has a surprising strategy: he keeps turning down million-dollar enterprise contracts&amp;nbsp;from deep-pocketed but demanding customers.&amp;nbsp;He’s&amp;nbsp;betting instead that&amp;nbsp;if he sticks to his own product&amp;nbsp;vision, the world will come to him. So far,&amp;nbsp;he’s&amp;nbsp;been right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Julie Bort sat down with&amp;nbsp;Copplestone&amp;nbsp;to explore&amp;nbsp;Supabase’s&amp;nbsp;rise and what it means for&amp;nbsp;vibe coding, developers and&amp;nbsp;the database&amp;nbsp;giants who have historically controlled this market.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/postgres-bloat-1.jpeg?w=640" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30711601"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;Vibe coding has taken the tech industry by storm, and&amp;nbsp;it’s&amp;nbsp;not just the&amp;nbsp;Lovables&amp;nbsp;and&amp;nbsp;Replits&amp;nbsp;of the world that&amp;nbsp;are&amp;nbsp;winning. The startups building the infrastructure behind them are cashing in too.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Supabase, the open-source database platform&amp;nbsp;that’s&amp;nbsp;become the backend of choice for the vibe-coding world,&amp;nbsp;raised $100 million at a&amp;nbsp;$5 billion&amp;nbsp;valuation&amp;nbsp;just months after closing $200 million at&amp;nbsp;$2 billion. But co-founder and CEO Paul&amp;nbsp;Copplestone&amp;nbsp;has a surprising strategy: he keeps turning down million-dollar enterprise contracts&amp;nbsp;from deep-pocketed but demanding customers.&amp;nbsp;He’s&amp;nbsp;betting instead that&amp;nbsp;if he sticks to his own product&amp;nbsp;vision, the world will come to him. So far,&amp;nbsp;he’s&amp;nbsp;been right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Today on TechCrunch’s Equity podcast, Julie Bort sat down with&amp;nbsp;Copplestone&amp;nbsp;to explore&amp;nbsp;Supabase’s&amp;nbsp;rise and what it means for&amp;nbsp;vibe coding, developers and&amp;nbsp;the database&amp;nbsp;giants who have historically controlled this market.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/supabase-hit-5b-by-turning-down-million-dollar-contracts-heres-why/</guid><pubDate>Fri, 28 Nov 2025 23:00:00 +0000</pubDate></item></channel></rss>