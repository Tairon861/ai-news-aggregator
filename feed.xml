<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 26 Jan 2026 02:06:53 +0000</lastBuildDate><item><title>Apple will reportedly unveil its Gemini-powered Siri assistant in February (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/25/apple-will-reportedly-unveil-its-gemini-powered-siri-assistant-in-february/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;We’re about to get our first real look at the results of the recently announced AI partnership between Apple and Google, according to Bloomberg’s Mark Gurman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gurman reports that Apple is planning to announce a new version of Siri in the second half of February. Using Google’s Gemini AI models, this Siri update will reportedly be the first to live up to the promises Apple made in June 2024, with the ability to complete tasks by accessing user’s personal data and on-screen content.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And that’s ahead of an even bigger upgrade that Apple plans to announce in June, at its Worldwide Developers Conference, Gurman says. This version of Siri is supposed to be more conversational, in the style of other chatbots like ChatGPT, and it could run directly on Google’s cloud infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier reports suggested that Apple has been struggling to get its AI strategy back on-track. In fact, Gurman says Apple’s Mike Rockwell told foundation team members over the summer that one of Gurman’s earlier reports was “bulls–t.” But with the Google partnership, as well as the recent departure of Apple’s AI chief John Giannandrea, it seems the company has indeed found a new direction.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;We’re about to get our first real look at the results of the recently announced AI partnership between Apple and Google, according to Bloomberg’s Mark Gurman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gurman reports that Apple is planning to announce a new version of Siri in the second half of February. Using Google’s Gemini AI models, this Siri update will reportedly be the first to live up to the promises Apple made in June 2024, with the ability to complete tasks by accessing user’s personal data and on-screen content.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;And that’s ahead of an even bigger upgrade that Apple plans to announce in June, at its Worldwide Developers Conference, Gurman says. This version of Siri is supposed to be more conversational, in the style of other chatbots like ChatGPT, and it could run directly on Google’s cloud infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Earlier reports suggested that Apple has been struggling to get its AI strategy back on-track. In fact, Gurman says Apple’s Mike Rockwell told foundation team members over the summer that one of Gurman’s earlier reports was “bulls–t.” But with the Google partnership, as well as the recent departure of Apple’s AI chief John Giannandrea, it seems the company has indeed found a new direction.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/25/apple-will-reportedly-unveil-its-gemini-powered-siri-assistant-in-february/</guid><pubDate>Sun, 25 Jan 2026 16:56:31 +0000</pubDate></item><item><title>[NEW] Science fiction writers, Comic-Con say goodbye to AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/25/science-fiction-writers-comic-con-say-goodbye-to-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/techcrunch-cyber-books-illo-3.jpg?w=1148" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In recent months, some of the major players in science fiction and popular culture have been taking firmer stances against generative AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Separate decisions by San Diego Comic-Con and the Science Fiction and Fantasy Writers Association (SFWA) illustrate the depth of AI opposition within some creative communities — though they’re certainly not the only ones, with music distribution platform Bandcamp also recently banning generative AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Back in December, when SFWA announced that it was updating its rules for the Nebula Awards. Works written entirely by large language models would not be eligible, while authors who used LLMs “at any point during the writing process” had to disclose that use, allowing award voters to make their own decisions about whether that usage would affect their support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Jason Sanford reported in his Genre Grapevine newsletter, this change drew immediate backlash for seemingly opening the door to work partly created by LLMs. SFWA’s Board of Directors issued an apology a few days later, writing, “Our approach and wording was wrong and we apologize for the distress and distrust we caused.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rules were revised yet again, now stating that works that are “written, either wholly or partially, by generative large language model (LLM) tools are not eligible” for Nebula Awards and that work will be disqualified if LLMs were used at any point in its creation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a follow-up post, Sanford said he was pleased to see SFWA listen to its members, and he said he refuses to use gen AI in his own fiction writing — “not only because of this theft but also because the tools are not actually creative and defeat the entire point of storytelling.” Still, he wrote that important questions need to be answered about how broadly LLM usage will be defined, especially as “these generative AI products are being forced down everyone’s throats by major corporations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you use any online search engines or computer products these days, it’s likely you’re using something powered by or connected with an LLM,” Sanford said. “Because of that, we must be careful that writers who use word processing and research tools with LLM components aren’t unfairly disqualified from awards like the Nebulas or attacked by readers and other writers. “&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The massive annual San Diego Comic-Con faced a similar controversy this month after artists noticed rules allowing AI-generated art to be displayed — but not sold — at the convention’s art show. After artists complained, the rules were quietly changed to say, “Material created by Artificial Intelligence (AI) either partially or wholly, is not allowed in the art show.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Comic-Con’s apology was less public than SFWA, some artists shared emailed responses from art show head Glen Wooten, who apparently said the previous rules had been in place for “a few years” and that they’d been effective as a deterrent, since no one had entered AI-generated art in the show.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But the issue is becoming more of a problem, so more strident language is necessary: NO! Plain and simple,” Wooten reportedly said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s probably safe to that assume other organizations will be announcing similarly hard-line stances this year — and that these communities will continue debating the larger issues. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/techcrunch-cyber-books-illo-3.jpg?w=1148" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In recent months, some of the major players in science fiction and popular culture have been taking firmer stances against generative AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Separate decisions by San Diego Comic-Con and the Science Fiction and Fantasy Writers Association (SFWA) illustrate the depth of AI opposition within some creative communities — though they’re certainly not the only ones, with music distribution platform Bandcamp also recently banning generative AI.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Back in December, when SFWA announced that it was updating its rules for the Nebula Awards. Works written entirely by large language models would not be eligible, while authors who used LLMs “at any point during the writing process” had to disclose that use, allowing award voters to make their own decisions about whether that usage would affect their support.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Jason Sanford reported in his Genre Grapevine newsletter, this change drew immediate backlash for seemingly opening the door to work partly created by LLMs. SFWA’s Board of Directors issued an apology a few days later, writing, “Our approach and wording was wrong and we apologize for the distress and distrust we caused.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The rules were revised yet again, now stating that works that are “written, either wholly or partially, by generative large language model (LLM) tools are not eligible” for Nebula Awards and that work will be disqualified if LLMs were used at any point in its creation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a follow-up post, Sanford said he was pleased to see SFWA listen to its members, and he said he refuses to use gen AI in his own fiction writing — “not only because of this theft but also because the tools are not actually creative and defeat the entire point of storytelling.” Still, he wrote that important questions need to be answered about how broadly LLM usage will be defined, especially as “these generative AI products are being forced down everyone’s throats by major corporations.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you use any online search engines or computer products these days, it’s likely you’re using something powered by or connected with an LLM,” Sanford said. “Because of that, we must be careful that writers who use word processing and research tools with LLM components aren’t unfairly disqualified from awards like the Nebulas or attacked by readers and other writers. “&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The massive annual San Diego Comic-Con faced a similar controversy this month after artists noticed rules allowing AI-generated art to be displayed — but not sold — at the convention’s art show. After artists complained, the rules were quietly changed to say, “Material created by Artificial Intelligence (AI) either partially or wholly, is not allowed in the art show.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Comic-Con’s apology was less public than SFWA, some artists shared emailed responses from art show head Glen Wooten, who apparently said the previous rules had been in place for “a few years” and that they’d been effective as a deterrent, since no one had entered AI-generated art in the show.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But the issue is becoming more of a problem, so more strident language is necessary: NO! Plain and simple,” Wooten reportedly said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s probably safe to that assume other organizations will be announcing similarly hard-line stances this year — and that these communities will continue debating the larger issues. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/25/science-fiction-writers-comic-con-say-goodbye-to-ai/</guid><pubDate>Sun, 25 Jan 2026 21:53:42 +0000</pubDate></item><item><title>[NEW] Humans&amp; thinks coordination is the next frontier for AI, and they’re building a model to prove it (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/25/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/humans-Founder-Photo-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots are getting better at answering questions, summarizing documents, and solving mathematical equations, but they still largely behave like helpful assistants for one user at a time. They’re not designed to manage the messier work of real collaboration: coordinating people with competing priorities, tracking long-running decisions, and keeping teams aligned over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;, a new startup founded by alumni of Anthropic, Meta, OpenAI, xAI, and Google DeepMind, thinks closing that gap is the next major frontier for foundation models. The company this week raised a $480 million seed round to build a “central nervous system” for the human-plus-AI economy. The startup’s “AI for empowering humans” framing has dominated early coverage, but the company’s actual ambition is more novel: building a new foundation model architecture designed for social intelligence, not just information retrieval or code generation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It feels like we’re ending the first paradigm of scaling, where question-answering models were trained to be very smart at particular verticals, and now we’re entering what we believe to be the second wave of adoption where the average consumer or user is trying to figure out what to do with all these things,” Andi Peng, one of humans&amp;amp;’s co-founders and a former Anthropic employee, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;’s pitch centers on helping usher people into the new era of AI, moving beyond the narrative that AI will take their jobs. Whether or not that’s just marketing speak, the timing is critical: Companies are transitioning from chat to agents. Models are competent, but workflows aren’t, and the coordination challenge remains largely unaddressed. And through it all, people feel threatened and overwhelmed by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three-month-old company, like several of its peers, has managed to raise its startling seed round off the back of this philosophy and the pedigree of its founding team. Humans&amp;amp; still doesn’t have a product, nor has it been clear about what exactly it might be, though the team said it could be a replacement for multiplayer or multi-user contexts like communication platforms (think Slack) or collaboration platforms (think Google Docs and Notion). As for use cases and target audience, the team hinted at both enterprise and consumer applications.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are building a product and a model that is centered on communication and collaboration,” Eric Zelikman, co-founder and CEO of humans&amp;amp; and former xAI researcher, told TechCrunch, adding that the focus is on getting the product to help people work together and communicate more effectively — both with each other and with AI tools.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Like when you have to make a large group decision, often it comes down to someone taking everyone into one room, getting everyone to express their different camps about, for example, what kind of logo they’d like,” Zelikman continued, chortling with his team as they recalled the time-consuming tedium of getting everyone to agree on a logo for the startup.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Zelikman added that the new model will be trained to ask questions in a way that feels like interacting with a friend or a colleague, someone who is trying to get to know you. Chatbots today are programmed to ask questions constantly, but they do so without understanding the value of the question. He says this is because they’ve been optimized for two things: How much a user immediately likes a response they’re given, and how likely the model is to answer the question it receives correctly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the lack of clarity around what the product is could be that humans&amp;amp; doesn’t exactly have an answer for that yet. Peng said humans&amp;amp; is designing the product in conjunction with the model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Part of what we’re doing here is also making sure that as the model improves, we’re able to co-evolve the interface and the behaviors that the model is capable of into a product that makes sense,” she said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What is clear, though, is that humans&amp;amp; isn’t trying to make a new model that can plug into existing applications and collaboration tools. The startup wants to own the collaboration layer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI plus team collaboration and productivity tools are an increasingly hot field — for example, the startup AI note-taking app Granola raised a $43 million round at a $250 million valuation as it launched more collaborative features. Several high-profile voices are also explicitly framing the next phase of AI as one of coordination and collaboration, not just automation. LinkedIn founder Reid Hoffman today argued that companies are implementing AI wrong by treating it like isolated pilots and that the real leverage is in the coordination layer of work — that is, how teams share knowledge and run meetings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI lives at the workflow level, and the people closest to the work know where the friction actually is,” Hoffman wrote on social media. “They’re the ones who will discover what should be automated, compressed, or totally redesigned.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the space where humans&amp;amp; wants to live. The idea is that its model-slash-product would act as the “connective tissue” across any organization — be it a 10,000-person business or a family — that understands the skills, motivations, and needs of each person, as well as how all of those can be balanced for the good of the whole.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there requires rethinking how AI models are trained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re trying to train the model in a different way that will involve more humans and AIs interacting and collaborating together,” Yuchen He, a humans&amp;amp; co-founder and former OpenAI researcher, told TechCrunch, adding that the startup’s model will also be trained using long-horizon and multi-agent reinforcement learning (RL).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long-horizon RL is meant to train the model to plan, act, revise, and follow through over time, rather than just generate a good one-off answer. Multi-agent RL trains for environments where multiple AIs and/or humans are in the loop. Both of these concepts are gaining momentum in recent academic work as researchers push LLMs beyond chatbot responses toward systems that can coordinate actions and optimize outcomes over many steps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The model needs to remember things about itself, about you, and the better its memory, the better its user understanding,” He said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the stellar crew running the show, there are plenty of risks ahead. Humans&amp;amp; will need endless large sums of cash to fund the expensive endeavor that is training and scaling a new model. That means it will be competing with the major established players for resources, including access to compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top risk, though, is that humans&amp;amp; isn’t just competing with the Notions and Slacks of the world. It’s coming for the Top Dogs of AI. And those companies are actively working on better ways to enable human collaboration on their platforms, even as they swear AGI will soon&amp;nbsp;replace economically viable work. Through Claude Cowork, Anthropic aims to optimize work-style collaboration; Gemini is embedded into Workspace so AI-enabled collaboration is already happening inside the tools people are already using; and OpenAI has lately been pitching developers on its multi-agent orchestration and workflows.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, none of the major players seem poised to rewrite a model based on social intelligence, which either gives humans&amp;amp; a leg up or makes it an acquisition target. And with companies like Meta, OpenAI, and DeepMind on the prowl for top AI talent, M&amp;amp;A is certainly a risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp; told TechCrunch it has already turned away interested parties and is not interested in being acquired.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe this is going to be a generational company, and we think that this has the potential to fundamentally change the future of how we interact with these models,” Zelikman said. “We trust ourselves to do that, and we have a lot of faith in the team that we’ve assembled here.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This post was original published on January 22, 2026.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/humans-Founder-Photo-1.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI chatbots are getting better at answering questions, summarizing documents, and solving mathematical equations, but they still largely behave like helpful assistants for one user at a time. They’re not designed to manage the messier work of real collaboration: coordinating people with competing priorities, tracking long-running decisions, and keeping teams aligned over time.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;, a new startup founded by alumni of Anthropic, Meta, OpenAI, xAI, and Google DeepMind, thinks closing that gap is the next major frontier for foundation models. The company this week raised a $480 million seed round to build a “central nervous system” for the human-plus-AI economy. The startup’s “AI for empowering humans” framing has dominated early coverage, but the company’s actual ambition is more novel: building a new foundation model architecture designed for social intelligence, not just information retrieval or code generation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“It feels like we’re ending the first paradigm of scaling, where question-answering models were trained to be very smart at particular verticals, and now we’re entering what we believe to be the second wave of adoption where the average consumer or user is trying to figure out what to do with all these things,” Andi Peng, one of humans&amp;amp;’s co-founders and a former Anthropic employee, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp;’s pitch centers on helping usher people into the new era of AI, moving beyond the narrative that AI will take their jobs. Whether or not that’s just marketing speak, the timing is critical: Companies are transitioning from chat to agents. Models are competent, but workflows aren’t, and the coordination challenge remains largely unaddressed. And through it all, people feel threatened and overwhelmed by AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The three-month-old company, like several of its peers, has managed to raise its startling seed round off the back of this philosophy and the pedigree of its founding team. Humans&amp;amp; still doesn’t have a product, nor has it been clear about what exactly it might be, though the team said it could be a replacement for multiplayer or multi-user contexts like communication platforms (think Slack) or collaboration platforms (think Google Docs and Notion). As for use cases and target audience, the team hinted at both enterprise and consumer applications.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are building a product and a model that is centered on communication and collaboration,” Eric Zelikman, co-founder and CEO of humans&amp;amp; and former xAI researcher, told TechCrunch, adding that the focus is on getting the product to help people work together and communicate more effectively — both with each other and with AI tools.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Like when you have to make a large group decision, often it comes down to someone taking everyone into one room, getting everyone to express their different camps about, for example, what kind of logo they’d like,” Zelikman continued, chortling with his team as they recalled the time-consuming tedium of getting everyone to agree on a logo for the startup.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Zelikman added that the new model will be trained to ask questions in a way that feels like interacting with a friend or a colleague, someone who is trying to get to know you. Chatbots today are programmed to ask questions constantly, but they do so without understanding the value of the question. He says this is because they’ve been optimized for two things: How much a user immediately likes a response they’re given, and how likely the model is to answer the question it receives correctly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Part of the lack of clarity around what the product is could be that humans&amp;amp; doesn’t exactly have an answer for that yet. Peng said humans&amp;amp; is designing the product in conjunction with the model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Part of what we’re doing here is also making sure that as the model improves, we’re able to co-evolve the interface and the behaviors that the model is capable of into a product that makes sense,” she said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;What is clear, though, is that humans&amp;amp; isn’t trying to make a new model that can plug into existing applications and collaboration tools. The startup wants to own the collaboration layer.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI plus team collaboration and productivity tools are an increasingly hot field — for example, the startup AI note-taking app Granola raised a $43 million round at a $250 million valuation as it launched more collaborative features. Several high-profile voices are also explicitly framing the next phase of AI as one of coordination and collaboration, not just automation. LinkedIn founder Reid Hoffman today argued that companies are implementing AI wrong by treating it like isolated pilots and that the real leverage is in the coordination layer of work — that is, how teams share knowledge and run meetings.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI lives at the workflow level, and the people closest to the work know where the friction actually is,” Hoffman wrote on social media. “They’re the ones who will discover what should be automated, compressed, or totally redesigned.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s the space where humans&amp;amp; wants to live. The idea is that its model-slash-product would act as the “connective tissue” across any organization — be it a 10,000-person business or a family — that understands the skills, motivations, and needs of each person, as well as how all of those can be balanced for the good of the whole.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To get there requires rethinking how AI models are trained.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re trying to train the model in a different way that will involve more humans and AIs interacting and collaborating together,” Yuchen He, a humans&amp;amp; co-founder and former OpenAI researcher, told TechCrunch, adding that the startup’s model will also be trained using long-horizon and multi-agent reinforcement learning (RL).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long-horizon RL is meant to train the model to plan, act, revise, and follow through over time, rather than just generate a good one-off answer. Multi-agent RL trains for environments where multiple AIs and/or humans are in the loop. Both of these concepts are gaining momentum in recent academic work as researchers push LLMs beyond chatbot responses toward systems that can coordinate actions and optimize outcomes over many steps.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The model needs to remember things about itself, about you, and the better its memory, the better its user understanding,” He said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Despite the stellar crew running the show, there are plenty of risks ahead. Humans&amp;amp; will need endless large sums of cash to fund the expensive endeavor that is training and scaling a new model. That means it will be competing with the major established players for resources, including access to compute.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The top risk, though, is that humans&amp;amp; isn’t just competing with the Notions and Slacks of the world. It’s coming for the Top Dogs of AI. And those companies are actively working on better ways to enable human collaboration on their platforms, even as they swear AGI will soon&amp;nbsp;replace economically viable work. Through Claude Cowork, Anthropic aims to optimize work-style collaboration; Gemini is embedded into Workspace so AI-enabled collaboration is already happening inside the tools people are already using; and OpenAI has lately been pitching developers on its multi-agent orchestration and workflows.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Crucially, none of the major players seem poised to rewrite a model based on social intelligence, which either gives humans&amp;amp; a leg up or makes it an acquisition target. And with companies like Meta, OpenAI, and DeepMind on the prowl for top AI talent, M&amp;amp;A is certainly a risk.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Humans&amp;amp; told TechCrunch it has already turned away interested parties and is not interested in being acquired.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe this is going to be a generational company, and we think that this has the potential to fundamentally change the future of how we interact with these models,” Zelikman said. “We trust ourselves to do that, and we have a lot of faith in the team that we’ve assembled here.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This post was original published on January 22, 2026.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/25/humans-thinks-coordination-is-the-next-frontier-for-ai-and-theyre-building-a-model-to-prove-it/</guid><pubDate>Sun, 25 Jan 2026 22:11:06 +0000</pubDate></item><item><title>[NEW] ChatGPT is pulling answers from Elon Musk’s Grokipedia (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/25/chatgpt-is-pulling-answers-from-elon-musks-grokipedia/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Information from the conservative-leaning, AI-generated encyclopedia developed by Elon Musk’s xAI is beginning to appear in answers from ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI launched Grokipedia in October, after Musk had been complaining that Wikipedia was biased against conservatives. Reporters soon noted that while many articles seemed to be copied directly from Wikipedia, Grokipedia also claimed that pornography contributed to the AIDS crisis, offered “ideological justifications” for slavery, and used denigrating terms for transgender people.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;All that might be expected for an encyclopedia associated with a chatbot that described itself as “Mecha Hitler” and was used to flood X with sexualized deepfakes. However, its content now seems to be escaping containment from the Musk ecosystem, with the Guardian reporting that GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Guardian says ChatGPT did &lt;em&gt;not&lt;/em&gt; cite Grokipedia when asked about topics where its inaccuracy has been widely reported— topics like the January 6 insurrection or the HIV/AIDS epidemic. Instead, it was cited on more obscure topics, including claims about Sir Richard Evans that the Guardian had previously debunked. (Anthropic’s Claude also appears to be citing Grokipedia to answer some queries.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An OpenAI spokesperson told the Guardian that it “aims to draw from a broad range of publicly available sources and viewpoints.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2218892225.jpg?resize=1200,804" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Information from the conservative-leaning, AI-generated encyclopedia developed by Elon Musk’s xAI is beginning to appear in answers from ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI launched Grokipedia in October, after Musk had been complaining that Wikipedia was biased against conservatives. Reporters soon noted that while many articles seemed to be copied directly from Wikipedia, Grokipedia also claimed that pornography contributed to the AIDS crisis, offered “ideological justifications” for slavery, and used denigrating terms for transgender people.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;All that might be expected for an encyclopedia associated with a chatbot that described itself as “Mecha Hitler” and was used to flood X with sexualized deepfakes. However, its content now seems to be escaping containment from the Musk ecosystem, with the Guardian reporting that GPT-5.2 cited Grokipedia nine times in response to more than a dozen different questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Guardian says ChatGPT did &lt;em&gt;not&lt;/em&gt; cite Grokipedia when asked about topics where its inaccuracy has been widely reported— topics like the January 6 insurrection or the HIV/AIDS epidemic. Instead, it was cited on more obscure topics, including claims about Sir Richard Evans that the Guardian had previously debunked. (Anthropic’s Claude also appears to be citing Grokipedia to answer some queries.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An OpenAI spokesperson told the Guardian that it “aims to draw from a broad range of publicly available sources and viewpoints.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/25/chatgpt-is-pulling-answers-from-elon-musks-grokipedia/</guid><pubDate>Sun, 25 Jan 2026 22:35:53 +0000</pubDate></item><item><title>[NEW] This founder cracked firefighting — now he’s creating an AI gold mine (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/25/this-founder-cracked-firefighting-now-hes-creating-an-ai-gold-mine/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sunny Sethi, founder of HEN Technologies, doesn’t sound like someone who’s disrupted an industry that has remained largely unchanged since the 1960s. His company builds fire nozzles — specifically, nozzles that it says increase suppression rates by up to 300% while conserving 67% of water. But Sethi is matter-of-fact about this achievement, more focused on what’s next than what’s already been done. And what’s next sounds a lot bigger than fire nozzles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His path to firefighting doesn’t follow a tidy narrative. After nabbing his PhD at the University of Akron, where he researched surfaces and adhesion, he founded ADAP Nanotech, an outfit that developed a carbon nanotube-based portfolio and won Air Force Research Lab grants. Next, at SunPower, he developed new materials and processes for shingled photovoltaic modules. When he landed next at a company called TE Connectivity, he worked on devices with new adhesive formulations to enable faster manufacturing in the automotive industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Then came a challenge from his wife. The two had moved from Ohio to the East Bay outside San Francisco in 2013. A few years later came the Thomas Fire — the only megafire they’d ever see, they thought. Then came the Camp Fire, then the Napa-Sonoma fires. The breaking point came in 2019. Sethi was traveling during evacuation warnings while his wife was home alone with their then three-year-old daughter, no family nearby, facing a potential evacuation order. “She was really mad at me,” Sethi recalls. “She’s like, ‘Dude, you need to fix this, otherwise you’re not a real scientist.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A background spanning nanotechnology, solar, semiconductors, and automotive had made his thinking “bias free and flexible,” as he puts it. He’d seen so many industries, so many different problems. Why &lt;em&gt;not&lt;/em&gt; try to fix the problem?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2020, he founded HEN Technologies (for high-efficiency nozzles) in nearby Hayward. With National Science Foundation funding, he conducted computational fluid dynamics research, analyzing how water suppresses fire and how wind affects it. The result: a nozzle that controls droplet size precisely, manages velocity in new ways, and resists wind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In HEN’s comparison video, which Sethi shows me over a Zoom call, the difference is stark. It’s the same flow rate, he says, but HEN’s pattern and velocity control keep the stream coherent while traditional nozzles disperse.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the nozzle is just the beginning — what Sethi calls “the muscle on the ground.” HEN has since expanded into monitors, valves, overhead sprinklers, and pressure devices, and is launching a flow-control device (“Stream IQ”) and discharge control systems this year. According to Sethi, each device contains custom-designed circuit boards with sensors and computing power — 23 different designs that turn dumb hardware into smart, connected equipment, some powered by Nvidia Orion Nano processors. Altogether, says Sethi, HEN has filed 20 patent applications with half a dozen granted so far.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The real innovation is the system these devices create. HEN’s platform uses sensors at the pump to act as a virtual sensor in the nozzle, tracking exactly when it’s on, how much water flows, and what pressure is required. The system captures precisely how much water was used for a given fire, how it was used, which hydrant was tapped, and what the weather conditions were.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Why it matters: Fire departments can run out of water otherwise, because there’s no communication between water suppliers and firefighters. It happened in the Palisades Fire. It happened in the Oakland Fire decades earlier. When two engines are connected to one hydrant, pressure variations can mean that one engine suddenly gets nothing as a fire continues to grow. In rural America, water tenders, which are tankers shuttling water from distant sources, face their own logistical nightmares. If they can integrate water usage calculations with their own utility monitoring systems to optimize resource allocation, that’s a giant win.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So HEN built a cloud platform with application layers, which Sethi likens to what Adobe did with cloud infrastructure. Think Individual à la carte systems for fire captains, battalion chiefs, and incident commanders. HEN’s system has weather data; it has GPS in all devices. It can warn those on the front lines that the wind is about to shift and they’d better move their engines, or that a particular fire truck is running out of water.&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-3085907" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/DSC00797.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Department of Homeland Security has been asking for exactly this kind of system through its NERIS program, which is an initiative to bring predictive analytics to emergency operations. “But you can’t have [predictive analytics] unless you have good quality data,” Sethi notes. “You can’t have good quality data unless you have the right hardware.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;HEN isn’t monetizing that data yet. It’s implementing data nodes, putting devices in as many systems as possible, building the data pipeline, creating the data lake. Next year, says Sethi, it will start commercializing the application layer with its built-in intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If building a predictive analytics platform for emergency response sounds daunting, Sethi says actually selling it is tougher, and he’s proudest of HEN’s traction on that front.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The hardest part of building this company is that this market is tough because it’s a B2C play when you think of convincing the customers to buy, but the procurement cycle is B2B,” he explains. “So you have to really make a product that resonates with people — with the end user — but you still have to go through government purchasing cycles, and we have cracked both of those.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The numbers bear this out. HEN launched its first products into the market in the second quarter of 2023, lining up 10 fire departments and generating $200,000 in revenue. Then word started to spread. Revenue hit $1.6 million in 2024, then $5.2 million last year. This year, Hen, which currently has 1,500 fire department customers, is projecting $20 million in revenue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HEN has competition, of course. IDEX Corp, a public company, sells hoses, nozzles, and monitors. Software companies like Central Square serve fire departments. A Miami company, First Due, which sells software to public safety agencies, announced a massive $355 million round last August.&amp;nbsp; But no company is “doing exactly what we are trying to do,” insists Sethi.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Sethi says that the constraint isn’t demand — it’s scaling fast enough. HEN serves the Marine Corps, US Army bases, Naval atomic labs, NASA, Abu Dhabi Civil Defense, and ships to 22 countries. It works through 120 distributors and recently qualified for GSA after a year-long vetting process (that’s a federal seal of approval that makes it easier for military and government agencies to buy).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fire departments buy about 20,000 new engines each year to replace aging equipment in a national fleet of 200,000, so once HEN is qualified, it becomes recurring revenue (is the idea), and because the hardware generates data, revenue continues between purchase cycles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HEN’s dual goal has required building a very specific team. Its software lead was formerly a senior director who helped build Adobe’s cloud infrastructure. Other members of HEN’s 50-person team include a former NASA engineer and veterans from Tesla, Apple, and Microsoft. “If you ask me technical questions, I would not be able to answer everything,” Sethi admits with a laugh, “but I have such good teams that [it] has been a blessing.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Indeed, it’s the software that hints at where this gets interesting, because while HEN is selling nozzles, it’s amassing something more valuable: data. Highly specific, real-world data about how water behaves under pressure, how flow rates interact with materials, how fire responds to suppression techniques, how physics works in active fire environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s exactly what companies building so-called world models need. These AI systems that construct simulated representations of physical environments to predict future states require real-world, multimodal data from physical systems under extreme conditions. You can’t teach AI about physics through simulations alone. You need what HEN collects with every deployment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sethi won’t elaborate, but he knows what he’s sitting on. Companies training robotics and predictive physics engines would pay handsomely for this kind of real-world physics data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors see it, too. Last month, HEN closed a $20 million Series A round, plus $2 million in venture debt from Silicon Valley Bank. O’Neil Strategic Capital led the financing, with NSFO, Tanas Capital, and z21 Ventures participating. The round brought the company’s total funding to more than $30 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sethi, meanwhile, is already looking ahead. He says the company will return to fundraising in the second quarter of this year.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sunny Sethi, founder of HEN Technologies, doesn’t sound like someone who’s disrupted an industry that has remained largely unchanged since the 1960s. His company builds fire nozzles — specifically, nozzles that it says increase suppression rates by up to 300% while conserving 67% of water. But Sethi is matter-of-fact about this achievement, more focused on what’s next than what’s already been done. And what’s next sounds a lot bigger than fire nozzles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His path to firefighting doesn’t follow a tidy narrative. After nabbing his PhD at the University of Akron, where he researched surfaces and adhesion, he founded ADAP Nanotech, an outfit that developed a carbon nanotube-based portfolio and won Air Force Research Lab grants. Next, at SunPower, he developed new materials and processes for shingled photovoltaic modules. When he landed next at a company called TE Connectivity, he worked on devices with new adhesive formulations to enable faster manufacturing in the automotive industry.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Then came a challenge from his wife. The two had moved from Ohio to the East Bay outside San Francisco in 2013. A few years later came the Thomas Fire — the only megafire they’d ever see, they thought. Then came the Camp Fire, then the Napa-Sonoma fires. The breaking point came in 2019. Sethi was traveling during evacuation warnings while his wife was home alone with their then three-year-old daughter, no family nearby, facing a potential evacuation order. “She was really mad at me,” Sethi recalls. “She’s like, ‘Dude, you need to fix this, otherwise you’re not a real scientist.’”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A background spanning nanotechnology, solar, semiconductors, and automotive had made his thinking “bias free and flexible,” as he puts it. He’d seen so many industries, so many different problems. Why &lt;em&gt;not&lt;/em&gt; try to fix the problem?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In June 2020, he founded HEN Technologies (for high-efficiency nozzles) in nearby Hayward. With National Science Foundation funding, he conducted computational fluid dynamics research, analyzing how water suppresses fire and how wind affects it. The result: a nozzle that controls droplet size precisely, manages velocity in new ways, and resists wind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In HEN’s comparison video, which Sethi shows me over a Zoom call, the difference is stark. It’s the same flow rate, he says, but HEN’s pattern and velocity control keep the stream coherent while traditional nozzles disperse.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But the nozzle is just the beginning — what Sethi calls “the muscle on the ground.” HEN has since expanded into monitors, valves, overhead sprinklers, and pressure devices, and is launching a flow-control device (“Stream IQ”) and discharge control systems this year. According to Sethi, each device contains custom-designed circuit boards with sensors and computing power — 23 different designs that turn dumb hardware into smart, connected equipment, some powered by Nvidia Orion Nano processors. Altogether, says Sethi, HEN has filed 20 patent applications with half a dozen granted so far.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The real innovation is the system these devices create. HEN’s platform uses sensors at the pump to act as a virtual sensor in the nozzle, tracking exactly when it’s on, how much water flows, and what pressure is required. The system captures precisely how much water was used for a given fire, how it was used, which hydrant was tapped, and what the weather conditions were.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Why it matters: Fire departments can run out of water otherwise, because there’s no communication between water suppliers and firefighters. It happened in the Palisades Fire. It happened in the Oakland Fire decades earlier. When two engines are connected to one hydrant, pressure variations can mean that one engine suddenly gets nothing as a fire continues to grow. In rural America, water tenders, which are tankers shuttling water from distant sources, face their own logistical nightmares. If they can integrate water usage calculations with their own utility monitoring systems to optimize resource allocation, that’s a giant win.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So HEN built a cloud platform with application layers, which Sethi likens to what Adobe did with cloud infrastructure. Think Individual à la carte systems for fire captains, battalion chiefs, and incident commanders. HEN’s system has weather data; it has GPS in all devices. It can warn those on the front lines that the wind is about to shift and they’d better move their engines, or that a particular fire truck is running out of water.&lt;/p&gt;

&lt;figure class="wp-block-image alignfull size-large"&gt;&lt;img alt="alt" class="wp-image-3085907" height="383" src="https://techcrunch.com/wp-content/uploads/2026/01/DSC00797.jpg?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The Department of Homeland Security has been asking for exactly this kind of system through its NERIS program, which is an initiative to bring predictive analytics to emergency operations. “But you can’t have [predictive analytics] unless you have good quality data,” Sethi notes. “You can’t have good quality data unless you have the right hardware.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;HEN isn’t monetizing that data yet. It’s implementing data nodes, putting devices in as many systems as possible, building the data pipeline, creating the data lake. Next year, says Sethi, it will start commercializing the application layer with its built-in intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If building a predictive analytics platform for emergency response sounds daunting, Sethi says actually selling it is tougher, and he’s proudest of HEN’s traction on that front.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The hardest part of building this company is that this market is tough because it’s a B2C play when you think of convincing the customers to buy, but the procurement cycle is B2B,” he explains. “So you have to really make a product that resonates with people — with the end user — but you still have to go through government purchasing cycles, and we have cracked both of those.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The numbers bear this out. HEN launched its first products into the market in the second quarter of 2023, lining up 10 fire departments and generating $200,000 in revenue. Then word started to spread. Revenue hit $1.6 million in 2024, then $5.2 million last year. This year, Hen, which currently has 1,500 fire department customers, is projecting $20 million in revenue.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HEN has competition, of course. IDEX Corp, a public company, sells hoses, nozzles, and monitors. Software companies like Central Square serve fire departments. A Miami company, First Due, which sells software to public safety agencies, announced a massive $355 million round last August.&amp;nbsp; But no company is “doing exactly what we are trying to do,” insists Sethi.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Sethi says that the constraint isn’t demand — it’s scaling fast enough. HEN serves the Marine Corps, US Army bases, Naval atomic labs, NASA, Abu Dhabi Civil Defense, and ships to 22 countries. It works through 120 distributors and recently qualified for GSA after a year-long vetting process (that’s a federal seal of approval that makes it easier for military and government agencies to buy).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fire departments buy about 20,000 new engines each year to replace aging equipment in a national fleet of 200,000, so once HEN is qualified, it becomes recurring revenue (is the idea), and because the hardware generates data, revenue continues between purchase cycles.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;HEN’s dual goal has required building a very specific team. Its software lead was formerly a senior director who helped build Adobe’s cloud infrastructure. Other members of HEN’s 50-person team include a former NASA engineer and veterans from Tesla, Apple, and Microsoft. “If you ask me technical questions, I would not be able to answer everything,” Sethi admits with a laugh, “but I have such good teams that [it] has been a blessing.” &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Indeed, it’s the software that hints at where this gets interesting, because while HEN is selling nozzles, it’s amassing something more valuable: data. Highly specific, real-world data about how water behaves under pressure, how flow rates interact with materials, how fire responds to suppression techniques, how physics works in active fire environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s exactly what companies building so-called world models need. These AI systems that construct simulated representations of physical environments to predict future states require real-world, multimodal data from physical systems under extreme conditions. You can’t teach AI about physics through simulations alone. You need what HEN collects with every deployment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sethi won’t elaborate, but he knows what he’s sitting on. Companies training robotics and predictive physics engines would pay handsomely for this kind of real-world physics data.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors see it, too. Last month, HEN closed a $20 million Series A round, plus $2 million in venture debt from Silicon Valley Bank. O’Neil Strategic Capital led the financing, with NSFO, Tanas Capital, and z21 Ventures participating. The round brought the company’s total funding to more than $30 million.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sethi, meanwhile, is already looking ahead. He says the company will return to fundraising in the second quarter of this year.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/25/this-founder-cracked-firefighting-now-hes-creating-an-ai-gold-mine/</guid><pubDate>Sun, 25 Jan 2026 23:20:36 +0000</pubDate></item></channel></rss>