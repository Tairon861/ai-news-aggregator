<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 22 Aug 2025 01:43:31 +0000</lastBuildDate><item><title>Google’s AI Mode expands globally, adds new agentic features (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/21/googles-ai-mode-expands-globally-adds-new-agentic-features/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is launching a global expansion of AI Mode, its feature that allows users to ask complex questions and follow-ups to dig deeper on a topic directly within Search, the company announced on Thursday. The tech giant is also bringing new agentic and personalized capabilities to the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the expansion, Google is bringing AI Mode to 180 new countries in English. Up until now, it’s only been available to users in the U.S., U.K., and India. Google plans to bring the feature to more languages and regions soon. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of the new agentic features, users can now use AI Mode to find restaurant reservations, and in the future, they’ll be able to find local service appointments and event tickets. Users can request dinner reservations based on multiple preferences, such as party size, date, time, location, and preferred cuisine. AI Mode will then search across different reservation platforms to find real-time availability for restaurants that match the inquiry. It then surfaces a curated list of options to choose from. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This new capability is rolling out for Google AI Ultra subscribers in the U.S. through the “Agentic capabilities in AI Mode” experiment in Labs, Google’s experimental arm. (Ultra is Google’s highest-end plan, at $249.99 per month.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3038745" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/AI-Mode-agentic-dining-reservations-birthday-example-still-1-of-2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google says that U.S. users in the AI Mode experiment will also now see search results tailored to their individual preferences and interests. The tech giant is starting with dining-related topics for this capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, if someone searches, “I only have an hour, need a quick lunch spot, any suggestions?” AI Mode will use their past conversations, along with places they’ve searched for or clicked on in Search and Maps, to offer more relevant suggestions. So, if AI Mode infers that you like Italian food and places with outdoor seating, you’ll get results suggesting options with these preferences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that users can adjust their personalization settings in their Google Account.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, AI Mode now lets users share and collaborate with others. A new “Share” button lets users send an AI Mode response to others, allowing them to jump into the conversation. Google says this could be helpful in cases where you need to collaborate with someone else, such as planning a trip or a birthday party.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google is launching a global expansion of AI Mode, its feature that allows users to ask complex questions and follow-ups to dig deeper on a topic directly within Search, the company announced on Thursday. The tech giant is also bringing new agentic and personalized capabilities to the feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As part of the expansion, Google is bringing AI Mode to 180 new countries in English. Up until now, it’s only been available to users in the U.S., U.K., and India. Google plans to bring the feature to more languages and regions soon. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In terms of the new agentic features, users can now use AI Mode to find restaurant reservations, and in the future, they’ll be able to find local service appointments and event tickets. Users can request dinner reservations based on multiple preferences, such as party size, date, time, location, and preferred cuisine. AI Mode will then search across different reservation platforms to find real-time availability for restaurants that match the inquiry. It then surfaces a curated list of options to choose from. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This new capability is rolling out for Google AI Ultra subscribers in the U.S. through the “Agentic capabilities in AI Mode” experiment in Labs, Google’s experimental arm. (Ultra is Google’s highest-end plan, at $249.99 per month.)&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3038745" height="680" src="https://techcrunch.com/wp-content/uploads/2025/08/AI-Mode-agentic-dining-reservations-birthday-example-still-1-of-2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google says that U.S. users in the AI Mode experiment will also now see search results tailored to their individual preferences and interests. The tech giant is starting with dining-related topics for this capability.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For example, if someone searches, “I only have an hour, need a quick lunch spot, any suggestions?” AI Mode will use their past conversations, along with places they’ve searched for or clicked on in Search and Maps, to offer more relevant suggestions. So, if AI Mode infers that you like Italian food and places with outdoor seating, you’ll get results suggesting options with these preferences.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google notes that users can adjust their personalization settings in their Google Account.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, AI Mode now lets users share and collaborate with others. A new “Share” button lets users send an AI Mode response to others, allowing them to jump into the conversation. Google says this could be helpful in cases where you need to collaborate with someone else, such as planning a trip or a birthday party.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/21/googles-ai-mode-expands-globally-adds-new-agentic-features/</guid><pubDate>Thu, 21 Aug 2025 13:49:37 +0000</pubDate></item><item><title>Think SMART: How to Optimize AI Factory Inference Performance (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/think-smart-optimize-ai-factory-inference-performance/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;From AI assistants doing deep research to autonomous vehicles making split-second navigation decisions, AI adoption is exploding across industries.&lt;/p&gt;
&lt;p&gt;Behind every one of those interactions is inference — the stage after training where an AI model processes inputs and produces outputs in real time.&lt;/p&gt;
&lt;p&gt;Today’s most advanced AI reasoning models — capable of multistep logic and complex decision-making — generate far more tokens per interaction than older models, driving a surge in token usage and the need for infrastructure that can manufacture intelligence at scale.&lt;/p&gt;
&lt;p&gt;AI factories are one way of meeting these growing needs.&lt;/p&gt;
&lt;p&gt;But running inference at such a large scale isn’t just about throwing more compute at the problem.&lt;/p&gt;
&lt;p&gt;To deploy AI with maximum efficiency, inference must be evaluated based on the &lt;b&gt;Think SMART framework:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;S&lt;/b&gt;cale and complexity&lt;/li&gt;
&lt;li&gt;&lt;b&gt;M&lt;/b&gt;ultidimensional performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;A&lt;/b&gt;rchitecture and software&lt;/li&gt;
&lt;li&gt;&lt;b&gt;R&lt;/b&gt;eturn on investment driven by performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;T&lt;/b&gt;echnology ecosystem and install base&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Scale and Complexity&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models evolve from compact applications to massive, multi-expert systems, inference must keep pace with increasingly diverse workloads — from answering quick, single-shot queries to multistep reasoning involving millions of tokens.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The expanding size and intricacy of AI models introduce major implications for inference, such as resource intensity, latency and throughput, energy and costs, as well as diversity of use cases.&lt;/p&gt;
&lt;p&gt;To meet this complexity, AI service providers and enterprises are scaling up their infrastructure, with new AI factories coming online from partners like CoreWeave, Dell Technologies, Google Cloud and Nebius.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Multidimensional Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Scaling complex AI deployments means AI factories need the flexibility to serve tokens across a wide spectrum of use cases while balancing accuracy, latency and costs.&lt;/p&gt;
&lt;p&gt;Some workloads, such as real-time speech-to-text translation, demand ultralow latency and a large number of tokens per user, straining computational resources for maximum responsiveness. Others are latency-insensitive and geared for sheer throughput, such as generating answers to dozens of complex questions simultaneously.&lt;/p&gt;
&lt;p&gt;But most popular real-time scenarios operate somewhere in the middle: requiring quick responses to keep users happy and high throughput to simultaneously serve up to millions of users — all while minimizing cost per token.&lt;/p&gt;
&lt;p&gt;For example, the NVIDIA inference platform is built to balance both latency and throughput, powering inference benchmarks on models like gpt-oss, DeepSeek-R1 and Llama 3.1.&lt;/p&gt;
&lt;h3&gt;&lt;b&gt;What to Assess to Achieve Optimal Multidimensional Performance&lt;/b&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Throughput:&lt;/b&gt; How many tokens can the system process per second? The more, the better for scaling workloads and revenue.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Latency:&lt;/b&gt; How quickly does the system respond to each individual prompt? Lower latency means a better experience for users — crucial for interactive applications.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Scalability:&lt;/b&gt; Can the system setup quickly adapt as demand increases, going from one to thousands of GPUs without complex restructuring or wasted resources?&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cost Efficiency:&lt;/b&gt; Is performance per dollar high, and are those gains sustainable as system demands grow?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Architecture and Software&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI inference performance needs to be engineered from the ground up. It comes from hardware and software working in sync — GPUs, networking and code tuned to avoid bottlenecks and make the most of every cycle.&lt;/p&gt;
&lt;p&gt;Powerful architecture without smart orchestration wastes potential; great software without fast, low-latency hardware means sluggish performance. The key is architecting a system so that it can quickly, efficiently and flexibly turn prompts into useful answers.&lt;/p&gt;
&lt;p&gt;Enterprises can use NVIDIA infrastructure to build a system that delivers optimal performance.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Architecture Optimized for Inference at AI Factory Scale&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The NVIDIA Blackwell platform unlocks a 50x boost in AI factory productivity for inference — meaning enterprises can optimize throughput and interactive responsiveness, even when running the most complex models.&lt;/p&gt;
&lt;p&gt;The NVIDIA GB200 NVL72 rack-scale system connects 36 NVIDIA Grace CPUs and 72 Blackwell GPUs with NVIDIA NVLink interconnect, delivering 40x higher revenue potential, 30x higher throughput, 25x more energy efficiency and 300x more water efficiency for demanding AI reasoning workloads.&lt;/p&gt;
&lt;p&gt;Further, NVFP4 is a low-precision format that delivers peak performance on NVIDIA Blackwell and slashes energy, memory and bandwidth demands without skipping a beat on accuracy, so users can deliver more queries per watt and lower costs per token.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Full-Stack Inference Platform Accelerated on Blackwell&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Enabling inference at AI factory scale requires more than accelerated architecture. It requires a full-stack platform with multiple layers of solutions and tools that can work in concert together.&lt;/p&gt;
&lt;p&gt;Modern AI deployments require dynamic autoscaling from one to thousands of GPUs. The NVIDIA Dynamo platform steers distributed inference to dynamically assign GPUs and optimize data flows, delivering up to 4x more performance without cost increases. New cloud integrations further improve scalability and ease of deployment.&lt;/p&gt;
&lt;p&gt;For inference workloads focused on getting optimal performance per GPU, such as speeding up large mixture of expert models, frameworks like NVIDIA TensorRT-LLM are helping developers achieve breakthrough performance.&lt;/p&gt;
&lt;p&gt;With its new PyTorch-centric workflow, TensorRT-LLM streamlines AI deployment by removing the need for manual engine management. These solutions aren’t just powerful on their own — they’re built to work in tandem. For example, using Dynamo and TensorRT-LLM, mission-critical inference providers like Baseten can immediately deliver state-of-the-art model performance even on new frontier models like gpt-oss.&lt;/p&gt;
&lt;p&gt;On the model side, families like NVIDIA Nemotron are built with open training data for transparency, while still generating tokens quickly enough to handle advanced reasoning tasks with high accuracy — without increasing compute costs. And with NVIDIA NIM, those models can be packaged into ready-to-run microservices, making it easier for teams to roll them out and scale across environments while achieving the lowest total cost of ownership.&lt;/p&gt;
&lt;p&gt;Together, these layers — dynamic orchestration, optimized execution, well-designed models and simplified deployment — form the backbone of inference enablement for cloud providers and enterprises alike.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Return on Investment Driven by Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As AI adoption grows, organizations are increasingly looking to maximize the return on investment from each user query.&lt;/p&gt;
&lt;p&gt;Performance is the biggest driver of return on investment. A 4x increase in performance from the NVIDIA Hopper architecture to Blackwell yields up to 10x profit growth within a similar power budget.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;In power-limited data centers and AI factories, generating more tokens per watt translates directly to higher revenue per rack. Managing token throughput efficiently — balancing latency, accuracy and user load — is crucial for keeping costs down.&lt;/p&gt;
&lt;p&gt;The industry is seeing rapid cost improvements, going as far as reducing costs-per-million-tokens by 80% through stack-wide optimizations. The same gains are achievable running gpt-oss and other open-source models from NVIDIA’s inference ecosystem, whether in hyperscale data centers or on local AI PCs.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Technology Ecosystem and Install Base&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models advance — featuring longer context windows, more tokens and more sophisticated runtime behaviors — their inference performance scales.&lt;/p&gt;
&lt;p&gt;Open models are a driving force in this momentum, accelerating over 70% of AI inference workloads today. They enable startups and enterprises alike to build custom agents, copilots and applications across every sector.&lt;/p&gt;
&lt;p&gt;Open-source communities play a critical role in the generative AI ecosystem — fostering collaboration, accelerating innovation and democratizing access. NVIDIA has over 1,000 open-source projects on GitHub in addition to 450 models and more than 80 datasets on Hugging Face. These help integrate popular frameworks like JAX, PyTorch, &lt;span&gt;vLLM&lt;/span&gt; and TensorRT-LLM into NVIDIA’s inference platform — ensuring maximum inference performance and flexibility across configurations.&lt;/p&gt;
&lt;p&gt;That’s why NVIDIA continues to contribute to open-source projects like llm-d and collaborate with industry leaders on open models, including Llama, Google Gemma, NVIDIA Nemotron, DeepSeek and gpt-oss — helping bring AI applications from idea to production at unprecedented speed.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-full wp-image-84040" height="512" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/think-smart-infrographic.png" width="1280" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Bottom Line for Optimized Inference&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA inference platform, coupled with the Think SMART framework for deploying modern AI workloads, helps enterprises ensure their infrastructure can keep pace with the demands of rapidly advancing models — and that each token generated delivers maximum value.&lt;/p&gt;
&lt;p&gt;Learn more about how inference drives the revenue generating potential of AI factories.&lt;/p&gt;
&lt;p&gt;For monthly updates, sign up for the NVIDIA Think SMART newsletter.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;From AI assistants doing deep research to autonomous vehicles making split-second navigation decisions, AI adoption is exploding across industries.&lt;/p&gt;
&lt;p&gt;Behind every one of those interactions is inference — the stage after training where an AI model processes inputs and produces outputs in real time.&lt;/p&gt;
&lt;p&gt;Today’s most advanced AI reasoning models — capable of multistep logic and complex decision-making — generate far more tokens per interaction than older models, driving a surge in token usage and the need for infrastructure that can manufacture intelligence at scale.&lt;/p&gt;
&lt;p&gt;AI factories are one way of meeting these growing needs.&lt;/p&gt;
&lt;p&gt;But running inference at such a large scale isn’t just about throwing more compute at the problem.&lt;/p&gt;
&lt;p&gt;To deploy AI with maximum efficiency, inference must be evaluated based on the &lt;b&gt;Think SMART framework:&lt;/b&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;S&lt;/b&gt;cale and complexity&lt;/li&gt;
&lt;li&gt;&lt;b&gt;M&lt;/b&gt;ultidimensional performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;A&lt;/b&gt;rchitecture and software&lt;/li&gt;
&lt;li&gt;&lt;b&gt;R&lt;/b&gt;eturn on investment driven by performance&lt;/li&gt;
&lt;li&gt;&lt;b&gt;T&lt;/b&gt;echnology ecosystem and install base&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Scale and Complexity&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models evolve from compact applications to massive, multi-expert systems, inference must keep pace with increasingly diverse workloads — from answering quick, single-shot queries to multistep reasoning involving millions of tokens.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;The expanding size and intricacy of AI models introduce major implications for inference, such as resource intensity, latency and throughput, energy and costs, as well as diversity of use cases.&lt;/p&gt;
&lt;p&gt;To meet this complexity, AI service providers and enterprises are scaling up their infrastructure, with new AI factories coming online from partners like CoreWeave, Dell Technologies, Google Cloud and Nebius.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Multidimensional Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;Scaling complex AI deployments means AI factories need the flexibility to serve tokens across a wide spectrum of use cases while balancing accuracy, latency and costs.&lt;/p&gt;
&lt;p&gt;Some workloads, such as real-time speech-to-text translation, demand ultralow latency and a large number of tokens per user, straining computational resources for maximum responsiveness. Others are latency-insensitive and geared for sheer throughput, such as generating answers to dozens of complex questions simultaneously.&lt;/p&gt;
&lt;p&gt;But most popular real-time scenarios operate somewhere in the middle: requiring quick responses to keep users happy and high throughput to simultaneously serve up to millions of users — all while minimizing cost per token.&lt;/p&gt;
&lt;p&gt;For example, the NVIDIA inference platform is built to balance both latency and throughput, powering inference benchmarks on models like gpt-oss, DeepSeek-R1 and Llama 3.1.&lt;/p&gt;
&lt;h3&gt;&lt;b&gt;What to Assess to Achieve Optimal Multidimensional Performance&lt;/b&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Throughput:&lt;/b&gt; How many tokens can the system process per second? The more, the better for scaling workloads and revenue.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Latency:&lt;/b&gt; How quickly does the system respond to each individual prompt? Lower latency means a better experience for users — crucial for interactive applications.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Scalability:&lt;/b&gt; Can the system setup quickly adapt as demand increases, going from one to thousands of GPUs without complex restructuring or wasted resources?&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Cost Efficiency:&lt;/b&gt; Is performance per dollar high, and are those gains sustainable as system demands grow?&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;&lt;strong&gt;Architecture and Software&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;AI inference performance needs to be engineered from the ground up. It comes from hardware and software working in sync — GPUs, networking and code tuned to avoid bottlenecks and make the most of every cycle.&lt;/p&gt;
&lt;p&gt;Powerful architecture without smart orchestration wastes potential; great software without fast, low-latency hardware means sluggish performance. The key is architecting a system so that it can quickly, efficiently and flexibly turn prompts into useful answers.&lt;/p&gt;
&lt;p&gt;Enterprises can use NVIDIA infrastructure to build a system that delivers optimal performance.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Architecture Optimized for Inference at AI Factory Scale&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;The NVIDIA Blackwell platform unlocks a 50x boost in AI factory productivity for inference — meaning enterprises can optimize throughput and interactive responsiveness, even when running the most complex models.&lt;/p&gt;
&lt;p&gt;The NVIDIA GB200 NVL72 rack-scale system connects 36 NVIDIA Grace CPUs and 72 Blackwell GPUs with NVIDIA NVLink interconnect, delivering 40x higher revenue potential, 30x higher throughput, 25x more energy efficiency and 300x more water efficiency for demanding AI reasoning workloads.&lt;/p&gt;
&lt;p&gt;Further, NVFP4 is a low-precision format that delivers peak performance on NVIDIA Blackwell and slashes energy, memory and bandwidth demands without skipping a beat on accuracy, so users can deliver more queries per watt and lower costs per token.&lt;/p&gt;
&lt;h3&gt;&lt;strong&gt;Full-Stack Inference Platform Accelerated on Blackwell&lt;/strong&gt;&lt;/h3&gt;
&lt;p&gt;Enabling inference at AI factory scale requires more than accelerated architecture. It requires a full-stack platform with multiple layers of solutions and tools that can work in concert together.&lt;/p&gt;
&lt;p&gt;Modern AI deployments require dynamic autoscaling from one to thousands of GPUs. The NVIDIA Dynamo platform steers distributed inference to dynamically assign GPUs and optimize data flows, delivering up to 4x more performance without cost increases. New cloud integrations further improve scalability and ease of deployment.&lt;/p&gt;
&lt;p&gt;For inference workloads focused on getting optimal performance per GPU, such as speeding up large mixture of expert models, frameworks like NVIDIA TensorRT-LLM are helping developers achieve breakthrough performance.&lt;/p&gt;
&lt;p&gt;With its new PyTorch-centric workflow, TensorRT-LLM streamlines AI deployment by removing the need for manual engine management. These solutions aren’t just powerful on their own — they’re built to work in tandem. For example, using Dynamo and TensorRT-LLM, mission-critical inference providers like Baseten can immediately deliver state-of-the-art model performance even on new frontier models like gpt-oss.&lt;/p&gt;
&lt;p&gt;On the model side, families like NVIDIA Nemotron are built with open training data for transparency, while still generating tokens quickly enough to handle advanced reasoning tasks with high accuracy — without increasing compute costs. And with NVIDIA NIM, those models can be packaged into ready-to-run microservices, making it easier for teams to roll them out and scale across environments while achieving the lowest total cost of ownership.&lt;/p&gt;
&lt;p&gt;Together, these layers — dynamic orchestration, optimized execution, well-designed models and simplified deployment — form the backbone of inference enablement for cloud providers and enterprises alike.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Return on Investment Driven by Performance&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As AI adoption grows, organizations are increasingly looking to maximize the return on investment from each user query.&lt;/p&gt;
&lt;p&gt;Performance is the biggest driver of return on investment. A 4x increase in performance from the NVIDIA Hopper architecture to Blackwell yields up to 10x profit growth within a similar power budget.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;In power-limited data centers and AI factories, generating more tokens per watt translates directly to higher revenue per rack. Managing token throughput efficiently — balancing latency, accuracy and user load — is crucial for keeping costs down.&lt;/p&gt;
&lt;p&gt;The industry is seeing rapid cost improvements, going as far as reducing costs-per-million-tokens by 80% through stack-wide optimizations. The same gains are achievable running gpt-oss and other open-source models from NVIDIA’s inference ecosystem, whether in hyperscale data centers or on local AI PCs.&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;Technology Ecosystem and Install Base&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;As models advance — featuring longer context windows, more tokens and more sophisticated runtime behaviors — their inference performance scales.&lt;/p&gt;
&lt;p&gt;Open models are a driving force in this momentum, accelerating over 70% of AI inference workloads today. They enable startups and enterprises alike to build custom agents, copilots and applications across every sector.&lt;/p&gt;
&lt;p&gt;Open-source communities play a critical role in the generative AI ecosystem — fostering collaboration, accelerating innovation and democratizing access. NVIDIA has over 1,000 open-source projects on GitHub in addition to 450 models and more than 80 datasets on Hugging Face. These help integrate popular frameworks like JAX, PyTorch, &lt;span&gt;vLLM&lt;/span&gt; and TensorRT-LLM into NVIDIA’s inference platform — ensuring maximum inference performance and flexibility across configurations.&lt;/p&gt;
&lt;p&gt;That’s why NVIDIA continues to contribute to open-source projects like llm-d and collaborate with industry leaders on open models, including Llama, Google Gemma, NVIDIA Nemotron, DeepSeek and gpt-oss — helping bring AI applications from idea to production at unprecedented speed.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class="alignnone size-full wp-image-84040" height="512" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/think-smart-infrographic.png" width="1280" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;strong&gt;The Bottom Line for Optimized Inference&lt;/strong&gt;&lt;/h2&gt;
&lt;p&gt;The NVIDIA inference platform, coupled with the Think SMART framework for deploying modern AI workloads, helps enterprises ensure their infrastructure can keep pace with the demands of rapidly advancing models — and that each token generated delivers maximum value.&lt;/p&gt;
&lt;p&gt;Learn more about how inference drives the revenue generating potential of AI factories.&lt;/p&gt;
&lt;p&gt;For monthly updates, sign up for the NVIDIA Think SMART newsletter.&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/think-smart-optimize-ai-factory-inference-performance/</guid><pubDate>Thu, 21 Aug 2025 15:00:15 +0000</pubDate></item><item><title>Gearing Up for the Gigawatt Data Center Age (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/networking-matters-more-than-ever/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Across the globe, AI factories are rising — massive new data centers built not to serve up web pages or email, but to train and deploy intelligence itself. Internet giants have invested billions in cloud-scale AI infrastructure for their customers. Companies are racing to build AI foundries that will spawn the next generation of products and services. Governments are investing too, eager to harness AI for personalized medicine and language services tailored to national populations.&lt;/p&gt;
&lt;p&gt;Welcome to the age of AI factories — where the rules are being rewritten and the wiring doesn’t look anything like the old internet. These aren’t typical hyperscale data centers. They’re something else entirely. Think of them as high-performance engines stitched together from tens to hundreds of thousands of GPUs — not just built, but orchestrated, operated and activated as a single unit. And that orchestration? It’s the whole game.&lt;/p&gt;
&lt;p&gt;This giant data center has become the new unit of computing, and the way these GPUs are connected defines what this unit of computing can do. One network architecture won’t cut it. What’s needed is a layered design with bleeding-edge technologies — like co-packaged optics that once seemed like science fiction.&lt;/p&gt;
&lt;p&gt;The complexity isn’t a bug; it’s the defining feature. AI infrastructure is diverging fast from everything that came before it, and if there isn’t rethinking on how the pipes connect, scale breaks down. Get the network layers wrong, and the whole machine grinds to a halt. Get it right, and gain extraordinary performance.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class=" wp-image-84050 alignleft" height="374" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/newsletter-inception-nvidia-gb200-nvl72-600x600-1.jpg" width="374" /&gt;With that shift comes weight — literally. A decade ago, chips were built to be sleek and lightweight. Now, the cutting edge looks like the multi‑hundred‑pound copper spine of a server rack. Liquid-cooled manifolds. Custom busbars. Copper spines. AI now demands massive, industrial-scale hardware. And the deeper the models go, the more these machines scale up, and out.&lt;/p&gt;
&lt;p&gt;The NVIDIA NVLink spine, for example, is built from over 5,000 coaxial cables — tightly wound and precisely routed. It moves more data per second than the entire internet. That’s 130 TB/s of GPU-to-GPU bandwidth, fully meshed.&lt;/p&gt;
&lt;p&gt;This isn’t just fast. It’s foundational. The AI super-highway now lives inside the rack.&lt;/p&gt;
&lt;h2&gt;The Data Center Is the Computer&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-84064" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-corp-blog-ai-factories-cpo-blog-1280x680-1.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Training the modern large language models (LLMs) behind AI isn’t about burning cycles on a single machine. It’s about orchestrating the work of tens or even hundreds of thousands of GPUs that are the heavy lifters of AI computation.&lt;/p&gt;
&lt;p&gt;These systems rely on distributed computing, splitting massive calculations across nodes (individual servers), where each node handles a slice of the workload. In training, those slices — typically massive matrices of numbers — need to be regularly merged and updated. That merging occurs through collective operations, such as “all-reduce” (which combines data from all nodes and redistributes the result) and “all-to-all” (where each node exchanges data with every other node).&lt;/p&gt;
&lt;p&gt;These processes are susceptible to the speed and responsiveness of the network — what engineers call latency (delay) and bandwidth (data capacity) — causing stalls in training.&lt;/p&gt;
&lt;p&gt;For inference — the process of running trained models to generate answers or predictions — the challenges flip. Retrieval-augmented generation systems, which combine LLMs with search, demand real-time lookups and responses. And in cloud environments, multi-tenant inference means keeping workloads from different customers running smoothly, without interference. That requires lightning-fast, high-throughput networking that can handle massive demand with strict isolation between users.&lt;/p&gt;
&lt;p&gt;Traditional Ethernet was designed for single-server workloads — not for the demands of distributed AI. Tolerating jitter and inconsistent delivery were once acceptable. Now, it’s a bottleneck. Traditional Ethernet switch architectures were never designed for consistent, predictable performance — and that legacy still shapes their latest generations.&lt;/p&gt;
&lt;p&gt;Distributed computing requires a scale-out infrastructure built for zero-jitter operation — one that can handle bursts of extreme throughput, deliver low latency, maintain predictable and consistent RDMA performance, and isolate network noise. This is why InfiniBand networking is the gold standard for high-performance computing supercomputers and AI factories.&lt;/p&gt;
&lt;p&gt;With NVIDIA Quantum InfiniBand, collective operations run inside the network itself using Scalable Hierarchical Aggregation and Reduction Protocol technology, doubling data bandwidth for reductions. It uses adaptive routing and telemetry-based congestion control to spread flows across paths, guarantee deterministic bandwidth and isolate noise. These optimizations let InfiniBand scale AI communication with precision. It’s why NVIDIA Quantum infrastructure connects the majority of the systems on the TOP500 list of the world’s most powerful supercomputers, demonstrating 35% growth in just two years.&lt;/p&gt;
&lt;p&gt;For clusters spanning dozens of racks, NVIDIA Quantum‑X800 Infiniband switches push InfiniBand to new heights. Each switch provides 144 ports of 800 Gbps connectivity, featuring hardware-based SHARPv4, adaptive routing and telemetry-based congestion control. The platform integrates co‑packaged silicon photonics to minimize the distance between electronics and optics, reducing power consumption and latency. Paired with NVIDIA ConnectX-8 SuperNICs delivering 800 Gb/s per GPU, this fabric links trillion-parameter models and drives in-network compute.&lt;/p&gt;
&lt;p&gt;But hyperscalers and enterprises have invested billions in their Ethernet software infrastructure. They need a quick path forward that uses the existing ecosystem for AI workloads. Enter NVIDIA Spectrum‑X: a new kind of Ethernet purpose-built for distributed AI.&lt;/p&gt;
&lt;h2&gt;Spectrum‑X Ethernet: Bringing AI to the Enterprise&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84069" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-render-spectrum-x-sn5610-cx8-exploded-4050050-1680x945.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Spectrum‑X reimagines Ethernet for AI. Launched in 2023 Spectrum‑X delivers lossless networking, adaptive routing and performance isolation. The SN5610 switch, based on the Spectrum‑4 ASIC, supports port speeds up to 800 Gb/s and uses NVIDIA’s congestion control to maintain 95% data throughput at scale.&lt;/p&gt;
&lt;p&gt;Spectrum‑X is fully standards‑based Ethernet. In addition to supporting Cumulus Linux, it supports the open‑source SONiC network operating system — giving customers flexibility. A key ingredient is NVIDIA SuperNICs — based on NVIDIA BlueField-3 or ConnectX-8 — which provide up to 800 Gb/s RoCE connectivity and offload packet reordering and congestion management.&lt;/p&gt;
&lt;p&gt;Spectrum-X brings InfiniBand’s best innovations — like telemetry-driven congestion control, adaptive load balancing and direct data placement — to Ethernet, enabling enterprises to scale to hundreds of thousands of GPUs. Large-scale systems with Spectrum‑X, including the world’s most colossal AI supercomputer, have achieved 95% data throughput with zero application latency degradation. Standard Ethernet fabrics would deliver only ~60% throughput due to flow collisions.&lt;/p&gt;
&lt;h2&gt;A Portfolio for Scale‑Up and Scale‑Out&lt;/h2&gt;
&lt;p&gt;No single network can serve every layer of an AI factory. NVIDIA’s approach is to match the right fabric to the right tier, then tie everything together with software and silicon.&lt;/p&gt;
&lt;h2&gt;NVLink: Scale Up Inside the Rack&lt;/h2&gt;
&lt;p&gt;Inside a server rack, GPUs need to talk to each other as if they were different cores on the same chip. NVIDIA NVLink and NVLink Switch extend GPU memory and bandwidth across nodes. In an NVIDIA GB300 NVL72 system, 36 NVIDIA Grace CPUs and 72 NVIDIA Blackwell Ultra GPUs are connected in a single NVLink domain, with an aggregate bandwidth of 130 TB/s. NVLink Switch technology further extends this fabric: a single GB300 NVL72 system can offer 130 TB/s of GPU bandwidth, enabling clusters to support 9x the GPU count of a single 8‑GPU server. With NVLink, the entire rack becomes one large GPU.&lt;/p&gt;
&lt;h2&gt;Photonics: The Next Leap&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84073" height="718" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-tech-blog-cpo-blog-2-1480x830-1.png" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;To reach million‑GPU AI factories, the network must break the power and density limits of pluggable optics. NVIDIA Quantum-X and Spectrum-X Photonics switches integrate silicon photonics directly into the switch package, delivering 128 to 512 ports of 800 Gb/s with total bandwidths ranging from 100 Tb/s to 400 Tb/s. These switches offer 3.5x more power efficiency and 10x better resiliency compared with traditional optics, paving the way for gigawatt‑scale AI factories.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;br /&gt;&lt;!-- The surrounding HTML, head, and body tags were removed because WordPress already provides them. --&gt;&lt;/p&gt;

&lt;div&gt;&lt;!-- The headline, as requested, uses the h2 tag. --&gt;
&lt;h2&gt;Delivering on the Promise of Open Standards&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Spectrum‑X and NVIDIA Quantum InfiniBand are built on open standards.&lt;/strong&gt; Spectrum‑X is fully standards‑based Ethernet with support for open Ethernet stacks like SONiC, while NVIDIA Quantum InfiniBand and Spectrum-X conform to the InfiniBand Trade Association’s InfiniBand and RDMA over Converged Ethernet (RoCE) specifications. Key elements of NVIDIA’s software stack — including NCCL and DOCA libraries — run on a variety of hardware, and partners such as Cisco, Dell Technologies, HPE and Supermicro integrate Spectrum-X into their systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Open standards create the foundation for interoperability, but real-world AI clusters require tight optimization across the entire stack — GPUs, NICs, switches, cables and software.&lt;/strong&gt; Vendors that invest in end‑to‑end integration deliver better latency and throughput. SONiC, the open‑source network operating system hardened in hyperscale data centers, eliminates licensing and vendor lock‑in and allows intense customization, but operators still choose purpose‑built hardware and software bundles to meet AI’s performance needs. In practice, open standards alone don’t deliver deterministic performance; they need innovation layered on top.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Toward Million‑GPU AI Factories&lt;/h2&gt;
&lt;p&gt;AI factories are scaling fast. Governments in Europe are building seven national AI factories, while cloud providers and enterprises across Japan, India and Norway are rolling out NVIDIA‑powered AI infrastructure. The next horizon is gigawatt‑class facilities with a million GPUs. To get there, the network must evolve from an afterthought to a pillar of AI infrastructure.&lt;/p&gt;
&lt;p&gt;The lesson from the gigawatt data center age is simple: the data center is now the computer. NVLink stitches together GPUs inside the rack. NVIDIA Quantum InfiniBand scales them across it. Spectrum-X brings that performance to broader markets. Silicon photonics makes it sustainable. Everything is open where it matters, optimized where it counts.&lt;/p&gt;




		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Across the globe, AI factories are rising — massive new data centers built not to serve up web pages or email, but to train and deploy intelligence itself. Internet giants have invested billions in cloud-scale AI infrastructure for their customers. Companies are racing to build AI foundries that will spawn the next generation of products and services. Governments are investing too, eager to harness AI for personalized medicine and language services tailored to national populations.&lt;/p&gt;
&lt;p&gt;Welcome to the age of AI factories — where the rules are being rewritten and the wiring doesn’t look anything like the old internet. These aren’t typical hyperscale data centers. They’re something else entirely. Think of them as high-performance engines stitched together from tens to hundreds of thousands of GPUs — not just built, but orchestrated, operated and activated as a single unit. And that orchestration? It’s the whole game.&lt;/p&gt;
&lt;p&gt;This giant data center has become the new unit of computing, and the way these GPUs are connected defines what this unit of computing can do. One network architecture won’t cut it. What’s needed is a layered design with bleeding-edge technologies — like co-packaged optics that once seemed like science fiction.&lt;/p&gt;
&lt;p&gt;The complexity isn’t a bug; it’s the defining feature. AI infrastructure is diverging fast from everything that came before it, and if there isn’t rethinking on how the pipes connect, scale breaks down. Get the network layers wrong, and the whole machine grinds to a halt. Get it right, and gain extraordinary performance.&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt" class=" wp-image-84050 alignleft" height="374" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/newsletter-inception-nvidia-gb200-nvl72-600x600-1.jpg" width="374" /&gt;With that shift comes weight — literally. A decade ago, chips were built to be sleek and lightweight. Now, the cutting edge looks like the multi‑hundred‑pound copper spine of a server rack. Liquid-cooled manifolds. Custom busbars. Copper spines. AI now demands massive, industrial-scale hardware. And the deeper the models go, the more these machines scale up, and out.&lt;/p&gt;
&lt;p&gt;The NVIDIA NVLink spine, for example, is built from over 5,000 coaxial cables — tightly wound and precisely routed. It moves more data per second than the entire internet. That’s 130 TB/s of GPU-to-GPU bandwidth, fully meshed.&lt;/p&gt;
&lt;p&gt;This isn’t just fast. It’s foundational. The AI super-highway now lives inside the rack.&lt;/p&gt;
&lt;h2&gt;The Data Center Is the Computer&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter size-full wp-image-84064" height="680" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-corp-blog-ai-factories-cpo-blog-1280x680-1.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Training the modern large language models (LLMs) behind AI isn’t about burning cycles on a single machine. It’s about orchestrating the work of tens or even hundreds of thousands of GPUs that are the heavy lifters of AI computation.&lt;/p&gt;
&lt;p&gt;These systems rely on distributed computing, splitting massive calculations across nodes (individual servers), where each node handles a slice of the workload. In training, those slices — typically massive matrices of numbers — need to be regularly merged and updated. That merging occurs through collective operations, such as “all-reduce” (which combines data from all nodes and redistributes the result) and “all-to-all” (where each node exchanges data with every other node).&lt;/p&gt;
&lt;p&gt;These processes are susceptible to the speed and responsiveness of the network — what engineers call latency (delay) and bandwidth (data capacity) — causing stalls in training.&lt;/p&gt;
&lt;p&gt;For inference — the process of running trained models to generate answers or predictions — the challenges flip. Retrieval-augmented generation systems, which combine LLMs with search, demand real-time lookups and responses. And in cloud environments, multi-tenant inference means keeping workloads from different customers running smoothly, without interference. That requires lightning-fast, high-throughput networking that can handle massive demand with strict isolation between users.&lt;/p&gt;
&lt;p&gt;Traditional Ethernet was designed for single-server workloads — not for the demands of distributed AI. Tolerating jitter and inconsistent delivery were once acceptable. Now, it’s a bottleneck. Traditional Ethernet switch architectures were never designed for consistent, predictable performance — and that legacy still shapes their latest generations.&lt;/p&gt;
&lt;p&gt;Distributed computing requires a scale-out infrastructure built for zero-jitter operation — one that can handle bursts of extreme throughput, deliver low latency, maintain predictable and consistent RDMA performance, and isolate network noise. This is why InfiniBand networking is the gold standard for high-performance computing supercomputers and AI factories.&lt;/p&gt;
&lt;p&gt;With NVIDIA Quantum InfiniBand, collective operations run inside the network itself using Scalable Hierarchical Aggregation and Reduction Protocol technology, doubling data bandwidth for reductions. It uses adaptive routing and telemetry-based congestion control to spread flows across paths, guarantee deterministic bandwidth and isolate noise. These optimizations let InfiniBand scale AI communication with precision. It’s why NVIDIA Quantum infrastructure connects the majority of the systems on the TOP500 list of the world’s most powerful supercomputers, demonstrating 35% growth in just two years.&lt;/p&gt;
&lt;p&gt;For clusters spanning dozens of racks, NVIDIA Quantum‑X800 Infiniband switches push InfiniBand to new heights. Each switch provides 144 ports of 800 Gbps connectivity, featuring hardware-based SHARPv4, adaptive routing and telemetry-based congestion control. The platform integrates co‑packaged silicon photonics to minimize the distance between electronics and optics, reducing power consumption and latency. Paired with NVIDIA ConnectX-8 SuperNICs delivering 800 Gb/s per GPU, this fabric links trillion-parameter models and drives in-network compute.&lt;/p&gt;
&lt;p&gt;But hyperscalers and enterprises have invested billions in their Ethernet software infrastructure. They need a quick path forward that uses the existing ecosystem for AI workloads. Enter NVIDIA Spectrum‑X: a new kind of Ethernet purpose-built for distributed AI.&lt;/p&gt;
&lt;h2&gt;Spectrum‑X Ethernet: Bringing AI to the Enterprise&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84069" height="720" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-render-spectrum-x-sn5610-cx8-exploded-4050050-1680x945.jpg" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;Spectrum‑X reimagines Ethernet for AI. Launched in 2023 Spectrum‑X delivers lossless networking, adaptive routing and performance isolation. The SN5610 switch, based on the Spectrum‑4 ASIC, supports port speeds up to 800 Gb/s and uses NVIDIA’s congestion control to maintain 95% data throughput at scale.&lt;/p&gt;
&lt;p&gt;Spectrum‑X is fully standards‑based Ethernet. In addition to supporting Cumulus Linux, it supports the open‑source SONiC network operating system — giving customers flexibility. A key ingredient is NVIDIA SuperNICs — based on NVIDIA BlueField-3 or ConnectX-8 — which provide up to 800 Gb/s RoCE connectivity and offload packet reordering and congestion management.&lt;/p&gt;
&lt;p&gt;Spectrum-X brings InfiniBand’s best innovations — like telemetry-driven congestion control, adaptive load balancing and direct data placement — to Ethernet, enabling enterprises to scale to hundreds of thousands of GPUs. Large-scale systems with Spectrum‑X, including the world’s most colossal AI supercomputer, have achieved 95% data throughput with zero application latency degradation. Standard Ethernet fabrics would deliver only ~60% throughput due to flow collisions.&lt;/p&gt;
&lt;h2&gt;A Portfolio for Scale‑Up and Scale‑Out&lt;/h2&gt;
&lt;p&gt;No single network can serve every layer of an AI factory. NVIDIA’s approach is to match the right fabric to the right tier, then tie everything together with software and silicon.&lt;/p&gt;
&lt;h2&gt;NVLink: Scale Up Inside the Rack&lt;/h2&gt;
&lt;p&gt;Inside a server rack, GPUs need to talk to each other as if they were different cores on the same chip. NVIDIA NVLink and NVLink Switch extend GPU memory and bandwidth across nodes. In an NVIDIA GB300 NVL72 system, 36 NVIDIA Grace CPUs and 72 NVIDIA Blackwell Ultra GPUs are connected in a single NVLink domain, with an aggregate bandwidth of 130 TB/s. NVLink Switch technology further extends this fabric: a single GB300 NVL72 system can offer 130 TB/s of GPU bandwidth, enabling clusters to support 9x the GPU count of a single 8‑GPU server. With NVLink, the entire rack becomes one large GPU.&lt;/p&gt;
&lt;h2&gt;Photonics: The Next Leap&lt;/h2&gt;
&lt;p&gt;&lt;img alt="alt" class="aligncenter wp-image-84073" height="718" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/ethernet-tech-blog-cpo-blog-2-1480x830-1.png" width="1280" /&gt;&lt;/p&gt;
&lt;p&gt;To reach million‑GPU AI factories, the network must break the power and density limits of pluggable optics. NVIDIA Quantum-X and Spectrum-X Photonics switches integrate silicon photonics directly into the switch package, delivering 128 to 512 ports of 800 Gb/s with total bandwidths ranging from 100 Tb/s to 400 Tb/s. These switches offer 3.5x more power efficiency and 10x better resiliency compared with traditional optics, paving the way for gigawatt‑scale AI factories.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;br /&gt;&lt;!-- The surrounding HTML, head, and body tags were removed because WordPress already provides them. --&gt;&lt;/p&gt;

&lt;div&gt;&lt;!-- The headline, as requested, uses the h2 tag. --&gt;
&lt;h2&gt;Delivering on the Promise of Open Standards&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Spectrum‑X and NVIDIA Quantum InfiniBand are built on open standards.&lt;/strong&gt; Spectrum‑X is fully standards‑based Ethernet with support for open Ethernet stacks like SONiC, while NVIDIA Quantum InfiniBand and Spectrum-X conform to the InfiniBand Trade Association’s InfiniBand and RDMA over Converged Ethernet (RoCE) specifications. Key elements of NVIDIA’s software stack — including NCCL and DOCA libraries — run on a variety of hardware, and partners such as Cisco, Dell Technologies, HPE and Supermicro integrate Spectrum-X into their systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Open standards create the foundation for interoperability, but real-world AI clusters require tight optimization across the entire stack — GPUs, NICs, switches, cables and software.&lt;/strong&gt; Vendors that invest in end‑to‑end integration deliver better latency and throughput. SONiC, the open‑source network operating system hardened in hyperscale data centers, eliminates licensing and vendor lock‑in and allows intense customization, but operators still choose purpose‑built hardware and software bundles to meet AI’s performance needs. In practice, open standards alone don’t deliver deterministic performance; they need innovation layered on top.&lt;/p&gt;
&lt;/div&gt;
&lt;h2&gt;Toward Million‑GPU AI Factories&lt;/h2&gt;
&lt;p&gt;AI factories are scaling fast. Governments in Europe are building seven national AI factories, while cloud providers and enterprises across Japan, India and Norway are rolling out NVIDIA‑powered AI infrastructure. The next horizon is gigawatt‑class facilities with a million GPUs. To get there, the network must evolve from an afterthought to a pillar of AI infrastructure.&lt;/p&gt;
&lt;p&gt;The lesson from the gigawatt data center age is simple: the data center is now the computer. NVLink stitches together GPUs inside the rack. NVIDIA Quantum InfiniBand scales them across it. Spectrum-X brings that performance to broader markets. Silicon photonics makes it sustainable. Everything is open where it matters, optimized where it counts.&lt;/p&gt;




		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/networking-matters-more-than-ever/</guid><pubDate>Thu, 21 Aug 2025 15:00:53 +0000</pubDate></item><item><title>How AI servers are transforming Taiwan’s electronics manufacturing giants (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-servers-transform-taiwan-manufacturing-giants/</link><description>&lt;p&gt;The revenue charts tell a story that would have seemed impossible just three years ago: AI servers are now generating more money than iPhones for Taiwan’s manufacturing giants. For the first time in decades, Taiwan’s manufacturing titans are watching their bread-and-butter consumer electronics businesses get overtaken by artificial intelligence infrastructure – a shift that’s rewriting the playbook for an industry that was built on assembling the world’s smartphones and laptops.&lt;/p&gt;&lt;p&gt;What took Apple nearly two decades to build, AI servers have displaced in less than three years, signalling an inflexion point that companies like Foxconn are navigating actively, diversifying beyond traditional consumer electronics.&lt;/p&gt;&lt;h3&gt;The scale of Taiwan’s server dominance&lt;/h3&gt;&lt;p&gt;Taiwan’s commanding position in global server manufacturing has positioned it perfectly for the AI boom, with the island accounting for over 90% of global AI server builds and approximately 80% of all server shipments worldwide. Its dominance stems from decades of expertise in electronics manufacturing, originally developed through the notebook computer industry, since evolved into an important advantage in the age of artificial intelligence.&lt;/p&gt;&lt;p&gt;According to statistics released by Taiwan’s Ministry of Economic Affairs in October 2024, the island’s server production value from January to July 2024 reached NT$426.7 billion (approximately US$13.2 billion) in value, in seven months surpassing the total value for 2023 and representing an annual growth rate of 153.9%.&lt;/p&gt;&lt;h3&gt;Major players experience revenue surges&lt;/h3&gt;&lt;p&gt;The impact of AI servers on Taiwan’s manufacturing giants has been nothing short of transformational. Nvidia partner Wistron’s revenue for January to July rose 92.7%, while Quanta’s grew 65.6% in the same period. The numbers reflect a broader trend affecting the entire ecosystem of Taiwan’s original design manufacturers (ODMs).&lt;/p&gt;&lt;p&gt;Foxconn, the world’s largest contract manufacturer, has experienced perhaps the most dramatic shift. Consumer electronics accounted for 35% of Foxconn’s total revenue in the second quarter of this year, while the cloud and networking business represented 41%. In 2021, consumer electronics represented 54% of its revenue. Now is the first time AI servers and cloud infrastructure have overtaken the company’s traditional smartphone manufacturing business.&lt;/p&gt;&lt;h4&gt;Quanta Computer’s AI server focus&lt;/h4&gt;&lt;p&gt;Quanta Computer, which supplies AI servers powered by Nvidia chips, said that AI servers are on track to account for 70% of its total server revenue this year, thanks to improved yield rates and a better learning curve for Nvidia’s GB300 chip-based servers. AI servers accounted for more than 60% of its total server revenue in the first half of this year.&lt;/p&gt;&lt;p&gt;Quanta is the world’s second-largest server assembly contractor, taking approximately 17% of the market. Its primary focus is AI server projects from the four major CSPs (Microsoft, Amazon, Google, and Meta). The company has secured orders for Nvidia’s latest GB200 servers and has been expanding production capacity to meet increased demand.&lt;/p&gt;&lt;h4&gt;Wistron’s strategic positioning&lt;/h4&gt;&lt;p&gt;Wistron has currently secured orders for Nvidia’s HGX Level 6 and DGX Level 10 servers, and obtained orders for the new generation AMD MI300 series AI server boards. Nvidia this week booked an entire Wistron server plant in Taiwan to build AI servers, highlighting the intensity of demand and the strategic importance of securing manufacturing capacity.&lt;/p&gt;&lt;p&gt;Quanta Computer plans to increase production capacity for AI servers in the US, and its factories there are booked up to the end of 2025. The capacity constraint reflects the “insane demand” that characterised the AI server market throughout 2024 and into 2025.&lt;/p&gt;&lt;h3&gt;Market share and financial impact&lt;/h3&gt;&lt;p&gt;The financial transformation in the sector has been remarkable. Quanta Computer reported that AI servers are on track to account for 70% of its total server revenue this year, with AI servers already accounting for more than 60% of its total server revenue in the first half of 2025, according to chief financial officer Elton Yang.&lt;/p&gt;&lt;p&gt;Wistron has demonstrated the transformative impact of AI servers on manufacturing economics, with the company’s revenue for January to July 2025 rising 92.7% compared to the same period in the previous year. The dramatic growth reflects the premium nature of AI server manufacturing compared to traditional consumer electronics.&lt;/p&gt;&lt;p&gt;The impact extends to Taiwan’s broader server ecosystem, with companies securing multi-year production contracts that extend well into 2026, indicating sustained demand and revenue visibility that was rarely seen in the consumer electronics era.&lt;/p&gt;&lt;h3&gt;Strategic implications and future outlook&lt;/h3&gt;&lt;p&gt;“The monthly sales jump for Taiwan ODMs in the first half of 2025 is evidence of this trend,” Robert Cheng, head of Asia technology hardware research at BofA Global Research, told &lt;em&gt;Reuters&lt;/em&gt;, referring to original design manufacturers like Foxconn that contract manufacture products for their clients.&lt;/p&gt;&lt;p&gt;The situation reflects a repositioning of Taiwan in the global technology supply chain. Where companies once competed primarily on cost and manufacturing efficiency for consumer electronics, AI servers require higher levels of technical sophistication, closer collaboration with chip designers, and more stringent quality control.&lt;/p&gt;&lt;p&gt;“We think this shift toward AI servers, whatever form it takes, is good for Taiwan’s tech industry,” Cheng said, noting Taiwanese firms’ ability to shift rapidly to cater to the changing needs of their customers.&lt;/p&gt;&lt;p&gt;However, challenges lie ahead. Taiwan’s current 90% share of the global AI server market may soon decline as manufacturers expand production elsewhere. Companies are already establishing manufacturing facilities in the US, Mexico, and other locations to serve local markets and comply with supply chain requirements.&lt;/p&gt;&lt;h3&gt;Industry-wide transformation&lt;/h3&gt;&lt;p&gt;The AI server boom has catalysed changes that extend beyond individual companies to reshape Taiwan’s entire electronics manufacturing ecosystem. Traditional boundaries between different types of technology products are blurring as manufacturers develop new capabilities and forge closer partnerships with AI chip companies.&lt;/p&gt;&lt;p&gt;The transformation also highlights Taiwan’s unique position in the global technology supply chain. The combination of advanced manufacturing capabilities, established relationships with major technology companies, and proximity to key semiconductor facilities has created a competitive advantage that continues to drive growth.&lt;/p&gt;&lt;p&gt;As artificial intelligence applications continue to need more sophisticated computing infrastructure, Taiwan’s manufacturers appear well-positioned to capitalise on demand. The challenge will be maintaining the country’s technology leadership while adapting to changing geopolitical and market conditions that may require more distributed global operations.&lt;/p&gt;&lt;p&gt;The shift from consumer electronics to AI servers exemplifies Taiwan’s ability to reinvent itself in response to technological change, maintain its central role in the global technology ecosystem, adapt and innovate.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei unveils high-end AI chip for servers alongside MindSpore framework&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The revenue charts tell a story that would have seemed impossible just three years ago: AI servers are now generating more money than iPhones for Taiwan’s manufacturing giants. For the first time in decades, Taiwan’s manufacturing titans are watching their bread-and-butter consumer electronics businesses get overtaken by artificial intelligence infrastructure – a shift that’s rewriting the playbook for an industry that was built on assembling the world’s smartphones and laptops.&lt;/p&gt;&lt;p&gt;What took Apple nearly two decades to build, AI servers have displaced in less than three years, signalling an inflexion point that companies like Foxconn are navigating actively, diversifying beyond traditional consumer electronics.&lt;/p&gt;&lt;h3&gt;The scale of Taiwan’s server dominance&lt;/h3&gt;&lt;p&gt;Taiwan’s commanding position in global server manufacturing has positioned it perfectly for the AI boom, with the island accounting for over 90% of global AI server builds and approximately 80% of all server shipments worldwide. Its dominance stems from decades of expertise in electronics manufacturing, originally developed through the notebook computer industry, since evolved into an important advantage in the age of artificial intelligence.&lt;/p&gt;&lt;p&gt;According to statistics released by Taiwan’s Ministry of Economic Affairs in October 2024, the island’s server production value from January to July 2024 reached NT$426.7 billion (approximately US$13.2 billion) in value, in seven months surpassing the total value for 2023 and representing an annual growth rate of 153.9%.&lt;/p&gt;&lt;h3&gt;Major players experience revenue surges&lt;/h3&gt;&lt;p&gt;The impact of AI servers on Taiwan’s manufacturing giants has been nothing short of transformational. Nvidia partner Wistron’s revenue for January to July rose 92.7%, while Quanta’s grew 65.6% in the same period. The numbers reflect a broader trend affecting the entire ecosystem of Taiwan’s original design manufacturers (ODMs).&lt;/p&gt;&lt;p&gt;Foxconn, the world’s largest contract manufacturer, has experienced perhaps the most dramatic shift. Consumer electronics accounted for 35% of Foxconn’s total revenue in the second quarter of this year, while the cloud and networking business represented 41%. In 2021, consumer electronics represented 54% of its revenue. Now is the first time AI servers and cloud infrastructure have overtaken the company’s traditional smartphone manufacturing business.&lt;/p&gt;&lt;h4&gt;Quanta Computer’s AI server focus&lt;/h4&gt;&lt;p&gt;Quanta Computer, which supplies AI servers powered by Nvidia chips, said that AI servers are on track to account for 70% of its total server revenue this year, thanks to improved yield rates and a better learning curve for Nvidia’s GB300 chip-based servers. AI servers accounted for more than 60% of its total server revenue in the first half of this year.&lt;/p&gt;&lt;p&gt;Quanta is the world’s second-largest server assembly contractor, taking approximately 17% of the market. Its primary focus is AI server projects from the four major CSPs (Microsoft, Amazon, Google, and Meta). The company has secured orders for Nvidia’s latest GB200 servers and has been expanding production capacity to meet increased demand.&lt;/p&gt;&lt;h4&gt;Wistron’s strategic positioning&lt;/h4&gt;&lt;p&gt;Wistron has currently secured orders for Nvidia’s HGX Level 6 and DGX Level 10 servers, and obtained orders for the new generation AMD MI300 series AI server boards. Nvidia this week booked an entire Wistron server plant in Taiwan to build AI servers, highlighting the intensity of demand and the strategic importance of securing manufacturing capacity.&lt;/p&gt;&lt;p&gt;Quanta Computer plans to increase production capacity for AI servers in the US, and its factories there are booked up to the end of 2025. The capacity constraint reflects the “insane demand” that characterised the AI server market throughout 2024 and into 2025.&lt;/p&gt;&lt;h3&gt;Market share and financial impact&lt;/h3&gt;&lt;p&gt;The financial transformation in the sector has been remarkable. Quanta Computer reported that AI servers are on track to account for 70% of its total server revenue this year, with AI servers already accounting for more than 60% of its total server revenue in the first half of 2025, according to chief financial officer Elton Yang.&lt;/p&gt;&lt;p&gt;Wistron has demonstrated the transformative impact of AI servers on manufacturing economics, with the company’s revenue for January to July 2025 rising 92.7% compared to the same period in the previous year. The dramatic growth reflects the premium nature of AI server manufacturing compared to traditional consumer electronics.&lt;/p&gt;&lt;p&gt;The impact extends to Taiwan’s broader server ecosystem, with companies securing multi-year production contracts that extend well into 2026, indicating sustained demand and revenue visibility that was rarely seen in the consumer electronics era.&lt;/p&gt;&lt;h3&gt;Strategic implications and future outlook&lt;/h3&gt;&lt;p&gt;“The monthly sales jump for Taiwan ODMs in the first half of 2025 is evidence of this trend,” Robert Cheng, head of Asia technology hardware research at BofA Global Research, told &lt;em&gt;Reuters&lt;/em&gt;, referring to original design manufacturers like Foxconn that contract manufacture products for their clients.&lt;/p&gt;&lt;p&gt;The situation reflects a repositioning of Taiwan in the global technology supply chain. Where companies once competed primarily on cost and manufacturing efficiency for consumer electronics, AI servers require higher levels of technical sophistication, closer collaboration with chip designers, and more stringent quality control.&lt;/p&gt;&lt;p&gt;“We think this shift toward AI servers, whatever form it takes, is good for Taiwan’s tech industry,” Cheng said, noting Taiwanese firms’ ability to shift rapidly to cater to the changing needs of their customers.&lt;/p&gt;&lt;p&gt;However, challenges lie ahead. Taiwan’s current 90% share of the global AI server market may soon decline as manufacturers expand production elsewhere. Companies are already establishing manufacturing facilities in the US, Mexico, and other locations to serve local markets and comply with supply chain requirements.&lt;/p&gt;&lt;h3&gt;Industry-wide transformation&lt;/h3&gt;&lt;p&gt;The AI server boom has catalysed changes that extend beyond individual companies to reshape Taiwan’s entire electronics manufacturing ecosystem. Traditional boundaries between different types of technology products are blurring as manufacturers develop new capabilities and forge closer partnerships with AI chip companies.&lt;/p&gt;&lt;p&gt;The transformation also highlights Taiwan’s unique position in the global technology supply chain. The combination of advanced manufacturing capabilities, established relationships with major technology companies, and proximity to key semiconductor facilities has created a competitive advantage that continues to drive growth.&lt;/p&gt;&lt;p&gt;As artificial intelligence applications continue to need more sophisticated computing infrastructure, Taiwan’s manufacturers appear well-positioned to capitalise on demand. The challenge will be maintaining the country’s technology leadership while adapting to changing geopolitical and market conditions that may require more distributed global operations.&lt;/p&gt;&lt;p&gt;The shift from consumer electronics to AI servers exemplifies Taiwan’s ability to reinvent itself in response to technological change, maintain its central role in the global technology ecosystem, adapt and innovate.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei unveils high-end AI chip for servers alongside MindSpore framework&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-servers-transform-taiwan-manufacturing-giants/</guid><pubDate>Thu, 21 Aug 2025 15:40:45 +0000</pubDate></item><item><title>Bank forced to rehire workers after lying about chatbot productivity, union says (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/08/bank-forced-to-rehire-workers-after-lying-about-chatbot-productivity-union-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Australia’s biggest bank regrets messy rush to replace staff with chatbots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="424" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-640x424.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bundit Minramun | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As banks around the world prepare to replace many thousands of workers with AI, Australia's biggest bank is scrambling to rehire 45 workers after allegedly lying about chatbots besting staff by handling higher call volumes.&lt;/p&gt;
&lt;p&gt;In a statement Thursday flagged by Bloomberg, Australia's main financial services union, the Finance Sector Union (FSU), claimed a "massive win" for 45 union members whom the Commonwealth Bank of Australia (CBA) had replaced with an AI-powered "voice bot."&lt;/p&gt;
&lt;p&gt;The FSU noted that some of these workers had been with CBA for decades. Those workers in particular were shocked when CBA announced last month that their jobs had become redundant. At that time, CBA claimed that launching the chatbot supposedly "led to a reduction in call volumes" by 2,000 a week, FSU said.&lt;/p&gt;
&lt;p&gt;But "this was an outright lie," fired workers told FSU. Instead, call volumes had been increasing at the time they were dismissed, with CBA supposedly "scrambling"—offering staff overtime and redirecting management to join workers answering phones to keep up.&lt;/p&gt;
&lt;p&gt;To uncover the truth, FSU escalated the dispute to a fair work tribunal, where the union accused CBA of failing to explain how workers' roles were ruled redundant. The union also alleged that CBA was hiring for similar roles in India, Bloomberg noted, which made it appear that CBA had perhaps used the chatbot to cover up a shady pivot to outsource jobs.&lt;/p&gt;
&lt;p&gt;While the dispute was being weighed, CBA admitted that "they didn’t properly consider that an increase in calls" happening while staff was being fired "would continue over a number of months," FSU said.&lt;/p&gt;
&lt;p&gt;"This error meant the roles were not redundant," CBA confirmed at the tribunal.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Bank apologizes, but damage is done&lt;/h2&gt;
&lt;p&gt;Now, CBA has apologized to the fired workers. A spokesperson told Bloomberg that they can choose to come back to their prior roles, seek another position, or leave the firm with an exit payment.&lt;/p&gt;
&lt;p&gt;"We have apologized to the employees concerned and acknowledge we should have been more thorough in our assessment of the roles required," CBA's spokesperson told Bloomberg.&lt;/p&gt;
&lt;p&gt;A Bloomberg Intelligence report from earlier this year estimated that banks globally will slash "as many as 200,000 jobs in the next three to five years" due to expectations that many tasks today will be assigned to AI in the near future. "Back office, middle office, and operations are likely to be most at risk," Bloomberg reported.&lt;/p&gt;
&lt;p&gt;CBA's reversal shows that some banks may be tempted to rush AI initiatives and dismiss workers without thoroughly understanding the potential impacts on their business. But the backtracking hasn't seemed to slow down CBA much. Just last week, it announced a partnership with OpenAI that will "explore advanced generative AI solutions that aim to strengthen scam and fraud detection and deliver more personalized services" for its customers.&lt;/p&gt;
&lt;p&gt;CBA did not suggest that this initiative would lead to further downsizing, claiming the bank's goal is to "invest in our people and their AI proficiency so they can better support our customers" and "embed the responsible use of AI across its workforce."&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach CBA or FSU to confirm how many workers have decided to return.&lt;/p&gt;
&lt;p&gt;But FSU reported that for all 45 workers, "the damage has already been done."&lt;/p&gt;
&lt;p&gt;These employees "have had to endure the stress and worry of facing redundancy" and were "suddenly confronted with the prospect of being unable to pay their bills." FSU warned that CBA's flip-flopping on AI serves as a "stark reminder to all of us that we can never trust employers to do the right thing by workers, and change can happen at any time and impact any one of us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Australia’s biggest bank regrets messy rush to replace staff with chatbots.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="424" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-640x424.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2219273654-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bundit Minramun | iStock Editorial / Getty Images Plus

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;As banks around the world prepare to replace many thousands of workers with AI, Australia's biggest bank is scrambling to rehire 45 workers after allegedly lying about chatbots besting staff by handling higher call volumes.&lt;/p&gt;
&lt;p&gt;In a statement Thursday flagged by Bloomberg, Australia's main financial services union, the Finance Sector Union (FSU), claimed a "massive win" for 45 union members whom the Commonwealth Bank of Australia (CBA) had replaced with an AI-powered "voice bot."&lt;/p&gt;
&lt;p&gt;The FSU noted that some of these workers had been with CBA for decades. Those workers in particular were shocked when CBA announced last month that their jobs had become redundant. At that time, CBA claimed that launching the chatbot supposedly "led to a reduction in call volumes" by 2,000 a week, FSU said.&lt;/p&gt;
&lt;p&gt;But "this was an outright lie," fired workers told FSU. Instead, call volumes had been increasing at the time they were dismissed, with CBA supposedly "scrambling"—offering staff overtime and redirecting management to join workers answering phones to keep up.&lt;/p&gt;
&lt;p&gt;To uncover the truth, FSU escalated the dispute to a fair work tribunal, where the union accused CBA of failing to explain how workers' roles were ruled redundant. The union also alleged that CBA was hiring for similar roles in India, Bloomberg noted, which made it appear that CBA had perhaps used the chatbot to cover up a shady pivot to outsource jobs.&lt;/p&gt;
&lt;p&gt;While the dispute was being weighed, CBA admitted that "they didn’t properly consider that an increase in calls" happening while staff was being fired "would continue over a number of months," FSU said.&lt;/p&gt;
&lt;p&gt;"This error meant the roles were not redundant," CBA confirmed at the tribunal.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Bank apologizes, but damage is done&lt;/h2&gt;
&lt;p&gt;Now, CBA has apologized to the fired workers. A spokesperson told Bloomberg that they can choose to come back to their prior roles, seek another position, or leave the firm with an exit payment.&lt;/p&gt;
&lt;p&gt;"We have apologized to the employees concerned and acknowledge we should have been more thorough in our assessment of the roles required," CBA's spokesperson told Bloomberg.&lt;/p&gt;
&lt;p&gt;A Bloomberg Intelligence report from earlier this year estimated that banks globally will slash "as many as 200,000 jobs in the next three to five years" due to expectations that many tasks today will be assigned to AI in the near future. "Back office, middle office, and operations are likely to be most at risk," Bloomberg reported.&lt;/p&gt;
&lt;p&gt;CBA's reversal shows that some banks may be tempted to rush AI initiatives and dismiss workers without thoroughly understanding the potential impacts on their business. But the backtracking hasn't seemed to slow down CBA much. Just last week, it announced a partnership with OpenAI that will "explore advanced generative AI solutions that aim to strengthen scam and fraud detection and deliver more personalized services" for its customers.&lt;/p&gt;
&lt;p&gt;CBA did not suggest that this initiative would lead to further downsizing, claiming the bank's goal is to "invest in our people and their AI proficiency so they can better support our customers" and "embed the responsible use of AI across its workforce."&lt;/p&gt;
&lt;p&gt;Ars could not immediately reach CBA or FSU to confirm how many workers have decided to return.&lt;/p&gt;
&lt;p&gt;But FSU reported that for all 45 workers, "the damage has already been done."&lt;/p&gt;
&lt;p&gt;These employees "have had to endure the stress and worry of facing redundancy" and were "suddenly confronted with the prospect of being unable to pay their bills." FSU warned that CBA's flip-flopping on AI serves as a "stark reminder to all of us that we can never trust employers to do the right thing by workers, and change can happen at any time and impact any one of us."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/08/bank-forced-to-rehire-workers-after-lying-about-chatbot-productivity-union-says/</guid><pubDate>Thu, 21 Aug 2025 15:49:37 +0000</pubDate></item><item><title>Coauthor roundtable: Reflecting on healthcare economics, biomedical research, and medical education (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/coauthor-roundtable-reflecting-on-healthcare-economics-biomedical-research-and-medical-education/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Carey Goldberg, Peter Lee, and Dr. Isaac Kohane." class="wp-image-1148279" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode11-Peter-Carey-Isaac_AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this series finale, Lee welcomes back coauthors Carey Goldberg&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Zak Kohane&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to discuss how their predictions stack up against key takeaways from guests in the second half of the series: experts on AI’s economic and societal impact; technologists on the cutting edge; leaders in AI-driven medicine; next-generation physicians; and heads of healthcare organizations. Lee, Goldberg, and Kohane explore thinking innovatively about existing healthcare processes, including the structure of care teams and the role of specialties, to take advantage of AI opportunities and consider what clinicians and patients might need these new AI tools to be to feel empowered when it comes to giving and receiving the best healthcare. They close the episode with their hopes for the future of AI in health.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“As a society—indeed, as a species—we have a choice to make. Do we constrain or even kill artificial intelligence out of fear of its risks and obvious ability to create new harms? Do we submit ourselves to Al and allow it to freely replace us, make us less useful and less needed? Or do we start, today, shaping our Al future together, with the aspiration to accomplish things that humans alone, and Al alone, can’t do but that humans+Al can? The choice is in our hands … .”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here. &lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from the epilogue, and I think it’s a truly fitting closing sentiment for the conclusion of this podcast series—because it calls back to the very beginning.&lt;/p&gt;



&lt;p&gt;As I’ve mentioned before, Carey, Zak, and I wrote &lt;em&gt;The AI Revolution in Medicine&lt;/em&gt; as a guide to help answer these big questions, particularly as they pertain to medicine. You know, we wrote the book to empower people to make a choice about AI’s development and use. Well, have they? Have &lt;em&gt;we&lt;/em&gt;?&lt;/p&gt;



&lt;p&gt;Perhaps we’ll need more time to tell. But over the course of this podcast series, I’ve had the honor of speaking with folks from across the healthcare ecosystem. And my takeaway? They’re all committed to shaping AI into a tool that can improve the industry for practitioners and patients alike.&lt;/p&gt;



&lt;p&gt;In this final episode, I’m thrilled to welcome back my coauthors, Carey Goldberg and Dr. Zak Kohane. We’ll examine the insights from the second half of the season.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Carey, Zak—it’s really great to have you here again!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CAREY&lt;/strong&gt; &lt;strong&gt;GOLDBERG: &lt;/strong&gt;Hey, Peter!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ZAK&lt;/strong&gt; &lt;strong&gt;KOHANE:&lt;/strong&gt; Hi, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So this is the second roundtable. And just to recap, you know, we had several early episodes of the podcast where we talked to some doctors, some technology developers, some people who think about regulation and public policy, patient advocates, a venture capitalist who invests in, kind of, consumer and patient-facing medical ventures, and some bioethicists.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think we had a great conversation there. I think, you know, it felt mostly validating. A lot of the things that we predicted might happen happened, and then we learned a lot of new things. But now we have five more episodes, and the mix of kinds of people that we talk to here is different than the original.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I thought it would be great for us to have a conversation and recap what we think we heard from all of them. So let’s just start at the top.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in this first episode in the second half of this podcast series, we talked to economists Azeem Azhar and Ethan Mollick. And I thought those conversations were really interesting. Maybe there were, kind of, two things, two main topics. One was just the broader impact on the economy, on the cost of healthcare, on overall workforce issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things that I thought was really interesting was something that Ethan Mollick brought up. And maybe just to refresh our memories, let’s play this little clip from Ethan.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-ab782358e1fff73901dd881b85e04b33"&gt;&lt;strong&gt;&lt;em&gt;ETHAN MOLLICK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;we’re in this really interesting period where there’s incredible amounts of individual innovation in productivity and performance improvements in this field, like very high levels of it. …&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;We’re seeing that in nonmedical problems, the same kind of thing, which is, you know, we’ve got research showing 20 and 40% performance improvements. … But then the organization doesn’t capture it; the system doesn’t capture it. Because the individuals are doing their own work, and the systems don’t have the ability to, kind of, learn or adapt as a result.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So let me start with you, Zak. Does that make sense to you? Are you seeing something similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I thought it was incredibly insightful because we discussed on our earlier podcast how a chief AI officer in one of the healthcare hospitals, in one of the healthcare systems, was highly regulating the use of AI, but yet in her own practice on her smartphone was using all these AI technologies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s insightful that on the one hand, she is increasing her personal productivity, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and perhaps she’s increasing her quality of her care. But it’s very hard for the healthcare system to actually realize any gains. It’s unlikely … let’s put it this way. It would be for her a defeat if they said, “Now you should see &lt;em&gt;more&lt;/em&gt; patients.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Now, I’m not saying that won’t happen. It could happen. But, you know, gains of productivity are really at the individual level of the doctors. And that’s why they’re adopting it. That’s why the ambient dictation tools are so successful. But really turning it into things that matter in terms of productivity for healthcare, namely making sure that patients are getting healthy, requires that every piece of the puzzle works well together. You know, it’s well-tread ground to talk about how patients get very expensive procedures, like a cardiac transplant, and then go home, and they’re not put on blood thinners …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and then they get a stroke. You know, the chain is as strong as the weakest link. And just having AI in one part of it is not going to do it. And so hospitals, I think, are doubly burdened by the fact that, (A) they tend to not like innovation because they are high-revenue, low-margin companies. But if they want it implemented effectively, they have to do it across the entire processes of healthcare, which are vast and not completely under their control.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Yep. You know, that was Sara Murray, who’s the chief health AI officer at UC San Francisco.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, you know, Carey, remember, we were puzzled by Chris Longhurst’s finding in a controlled study that the, you know, having an AI respond to patient emails didn’t seem to lead to any, I guess you would call it, &lt;em&gt;productivity benefits&lt;/em&gt;. I remember we were both kind of puzzled by that. I wonder if that’s related to what Ethan is saying here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; I mean, possibly, but I think we’ve seen since then that there have been multiple studies showing that in fact using AI can be extremely effective or helpful, even, for example, for diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I find just from the patient point of view, it kind of drives me crazy that you have individual physicians using AI because they know that it will improve the care that they’re offering. And yet you don’t have their institutions kind of stepping up and saying, “OK, these are the new norms.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, Ethan Mollick is a national treasure, right. Like, he is the classic example of someone who just stepped up at this moment …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… when we saw this extraordinary technological advance. And he’s not only stepping up for himself. He’s spreading the word to the masses that this is what these things can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s frustrating to see the institutions not stepping up and instead the individual doctors having to do it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But he made another very interesting point, which was that the reason that &lt;em&gt;he&lt;/em&gt; could be so informative to not only the public but practitioners of AI is these things would emerge out of the shop, and they would not be aged too long, like a fine wine, before they were just released to the public.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so he was getting exposure to these models just weeks after some of the progenitors had first seen it. And therefore, because he’s actually a really creative person in terms of how he exercises models, he sees uses and problems very early on. But the point is institutions, think about how much they are disadvantaged. They’re not Ethan Mollick. They’re not the progenitors. So they’re even further behind. So it’s very hard. If you talk to most of the C-suite of hospitals, they’d be delighted to know as much about the impact as Ethan Mollick.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. By the way, you know, I picked out this quote because within Microsoft, and I suspect every other software company, we’re seeing something very similar, where individual programmers are 20 to 30% more productive just in the number of lines of code they write per day or the number of pull requests per week. Any way you measure it, it’s very consistent. And yet by the time you get to, say, a 25-person software engineering team, the productivity of that whole team isn’t 25% more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, that &lt;em&gt;is&lt;/em&gt; starting to change because we’re starting to figure out that, well, maybe we should reshape how the team operates. And there’s more of an orientation towards having, you know, smaller teams of full-stack developers. And then you start to see the gains. But if you just keep the team organized in the usual way, there seems to be a loss. So there’s something about what Ethan was saying that resonated very strongly with me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;But I would argue that it’s not just productivity we’re talking about. There’s a moral imperative to improve the care. And if you have tools that will do that, you should be using them or trying harder to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think, yes, first of all, absolutely you would. Unfortunately, most of the short-term productivity measures will not measure improvements in the quality of care because it takes a long time to die even with bad care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that doesn’t show up right away. But I think what Peter just said actually came across in several of the podcasts, which is that it’s very tricky trying to shoehorn these things into making what we’re already doing more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Existing structures.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. And I know, Carey, that you’ve raised this issue many times. But it really calls into question, what should we be doing with our time with doctors? And they are a scarce resource. And what is the most efficient way to use them?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I remember we [&lt;em&gt;The New England Journal of Medicine AI&lt;/em&gt;] published a paper of someone who was able to use AI to increase the throughput of their emergency room&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; by actually more appropriately having the truly sick people in the sick queue, in the triage queue, for urgent care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think we’re going to have to think that way more broadly, about we don’t have to now look at every patient as an unknown with maybe a few pointers on diagnosis. We can have a fairly extensive profiling.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I know that colleagues in Clalit [Health Services] in Israel, for example, are using the overall trajectory of the patient and some considerations about utilities to actually figure out who to see next week.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, what you said brings up another maybe connection to one thing that we see also in software development. And it relates to also what we were discussing earlier: about the last thing a doctor wants is to have a tool that allows them to see even yet more patients per day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in software development, there’s always this tension. Like, how many lines of code can you write per day? That’s one productivity measure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes we’re taught, well, don’t write more lines of code per day, but make sure that your code is well structured. Take the time to document it. Make sure it’s fully commented. Take the time to talk to your fellow software engineering team members to make sure that it’s well coordinated. And in the long run, even if you’re writing half the number of lines of code per day, the software process will be far more efficient.&lt;/p&gt;



&lt;p&gt;And so I’ve wondered whether there’s a similar thing where doctors could see 20% fewer patients in a day, but if they take the time and also had AI help to coordinate, maybe a patient’s journey might be half as long. And therefore, the health system would be able to see twice as many patients in a year’s period or something like that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think you’ve “nerd sniped” me because you [LAUGHTER]—which is all too easy—but I think there’s a central issue here. And I think this is the stumbling block between what Ethan’s telling us about between the individual productivity and the larger productivity, is the &lt;em&gt;team’s&lt;/em&gt; productivity.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And there is actually a good analogy in computer science and that’s, uh, Brooks’s “mythical man-month,” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes, exactly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … where he shows how you can have more and more resources, but when the coordination starts failing, because you have so many, uh, individuals on the team, you start falling apart. And so even if the, uh, individual doctors get that much better, yeah, they take better care of patients, make less stupid things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But in terms of giving the “I get you into the emergency room, and I get you out of a hospital as fast as possible, as safely as possible, as effectively as possible,” that’s teamwork. And we don’t do it. And we’re not really optimizing our tools for that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And just to throw in a little reality check, I’m not aware of &lt;em&gt;any&lt;/em&gt; indication yet that AI is in any way shortening medical journeys or making physicians more efficient. Yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; …&lt;strong&gt; &lt;/strong&gt;at least. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. So I think, you know, with respect to our book, critiquing our book, you know, I think it’s fair to say we were fairly focused or maybe even fixated on the individual doctor or nurse or patient, and we didn’t really, at least I never had a time where I stepped back to think about the whole care coordination team or the whole health system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And I think that’s right. It’s because, first of all, &lt;em&gt;you&lt;/em&gt; weren’t thinking about it? It’s not what we’re taught in medical school. We’re not taught to talk about team communication excellence. And I think it’s absolutely essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a … what’s the … there was an early … [Terry] Winograd. And he was trying to capture what are the different kinds of actions related to pronouncements that you could expect and how could AI use that. And that was beginning to get at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I actually think this is dark matter of human organizational technology that is not well understood. And our products don’t do well. You know, we can talk about all the groupware things that are out there. But they all don’t quite get to that thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And I can imagine an AI serving as a team leader, a really active team leader, a real quarterback of, let’s say, a care team.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, in fact, you know, we have been trying to experiment with this. My colleague, Matt Lungren, who was also one of the interviewees early on, has been working with Stanford Medicine on a tumor board AI agent—something that would facilitate tumor board meetings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And the early experiences are pretty interesting. Whether it relates to efficiency or productivity I think remains to be seen, but it does seem pretty interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But let’s move on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Well, actually, Peter, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Oh, go ahead.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;if you’re willing to not quite move on yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… this kind of segues into one of, I think, the most provocative questions that arose in the course of these episodes and that I’d love to have you answer, which was, remember, it was a question at a gathering that you were at, and you were asked, “Well, you’re focusing a lot on potential AI effects on individual patient and physician experiences. But what about the revolution, right? What about, like, can you be more big-picture and envision how generative AI could actually, kind of, overturn or fix the broken system, right?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m sure you’ve thought about that a lot. Like, what’s your answer?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I think ultimately, it will have to. For it to really make a difference, I think that the normal processes, our normal concept of how healthcare is delivered—how new medical discoveries are made and brought into practice—I think those things are going to have to change a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, one of the things I think about a lot right at the moment is, you know, we tend to think about, let’s say, medical diagnosis as a problem-solving exercise. And I think, at least at the Kaiser Permanente School of Medicine, the instruction really treats it as a kind of detective thing based on a lot of knowledge about biology and biomedicine and human condition, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But there’s another way to think about it, given AI, which is when you see a patient and you develop some data, maybe through a physical exam, labs, and so on, you can just simply ask, “You know, what did the 500 other people who are most similar to this experience, how were they diagnosed? How were they treated? What were their outcomes? What were their experiences?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s really a fundamentally different paradigm. And it just seems like at least the technical means will be there. And by the way, that also then relates to [the questions]: “And what was most efficacious cost-wise? What was most efficient in terms of the total length of the patient journey? How does this relate to my quality scores so I can get more money from Medicare and Medicaid?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All of those things, I think, you know, we’re starting to confront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the other episodes that we’re going to talk about, was my interview with two medical students. Actually, thinking of a Morgan Cheatham as just a medical student or medical resident [LAUGHTER] is a little strange. But he is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things he talks about is the importance that he placed in his medical training about adopting AI. So, Zak, I assume you see this also with some students at Harvard Medical School. And the other medical student we interviewed, Daniel Chen, seemed to indicate this, too, where it seems like it’s the students who are bringing AI into the medical education ahead of the faculty. Does that resonate with you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely resonates with me. There are students I run into who, honestly, my first thought when I’m talking to them is, why am I teaching you [LAUGHTER], and why are you not starting a big AI company, AI medicine company, now and really change healthcare instead of going through the rest of the rigmarole? And I think broadly, higher education has a problem there, which is we have not embraced, again, going back to Ethan, a lot of the tools that can be used. And it’s because we don’t know necessarily the right way to teach them. And so far, the only lasting heuristic seems to be: use them and use them often.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s an awkward thing, where the person who knows how to use the AI tools now in the first-year medical school can teach themselves better and faster than anybody else in their class who is just relying on the medical school curriculum.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, the reason I brought up Morgan now after our discussion with Ethan Mollick is Morgan also talked about AI collapsing medical specialties.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so let’s hear this snippet from him.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-df1ec79bf2184e924d149dd5a8bfd566"&gt;&lt;strong&gt;&lt;em&gt;MORGAN CHEATHAM:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; AI collapses medical specialties onto themselves, right. You have the canonical example of the cardiologist, you know, arguing that we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient’s clinical status? … So I’m interested in this question of whether medical specialties themselves need to evolve. And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So on the specific question about specialties, Zak, do you have a point of view? And let me admit, first of all, for us, all three of us, we didn’t have any clue about this in our book. I don’t think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Not much. Not much of a clue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’m reminded of a &lt;em&gt;New Yorker&lt;/em&gt; cartoon where you see a bunch of surgeons around the patient, and someone says, “Is that a spleen?” And it says, “I don’t know. I slept during the spleen lecture,” [LAUGHTER] and … or “I didn’t take the spleen course.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And yet when we measure things, we measure things much more than we think we are doing. So for example, we [&lt;em&gt;NEJM AI&lt;/em&gt;] just published a paper where echocardiograms were being done. And it turns out those ultrasound waves just happen to also permeate the liver. And you can actually diagnose on the way with AI all the liver disease&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that is in—and treatable liver disease—that’s in those patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you’re a cardiologist, “Liver? You know, I slept through liver lecture.” [LAUGHTER] And so I do think that, (A) the natural, often guild/dollar-driven silos in medicine are less obvious to AI, despite the fact that they do exist in departments and often in chapters.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But Morgan’s absolutely right. I can tell you as an endocrinologist, if I have a child in the ICU, the endocrinologist, the nephrologist, and the neurosurgeon will argue about the right thing to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so in my mind, the truly revolutionary thing to do is to go back to 1994 with Pete Szolovits, the Guardian Angel Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. What I think you need is a process. And the process is the quarterback. And the quarterback has only one job: take care of the patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it should be thinking all the time about the patient. What’s the right thing? And can be as school-marmish or not about, “Zak, you’re eating this or that or exercise or sleep,” but also, “Hey, surgeons and endocrinologists, you’re talking about my host, Zak. This is the right way because this problem and this problem and our best evidence is this is the right way to get rid of the fluid. The other ways will kill him.”&lt;/p&gt;



&lt;p&gt;And I think you need an authoritative quarterback that has the view of the others but then makes the calls.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Is that quarterback going to be AI or human?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Well, for the very lucky people, it’ll be a human augmented by AI, &lt;em&gt;super concierge&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think we’re running out of doctors. And so realistically, it’s going to be an AI that will have to be certified in very different ways, along the ways Dave Blumenthal says, essentially, trial by fire. Like putting residents into clinics, we’re going to be putting AIs into clinics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what’s worse, by the way, than the three doctors arguing about care in front of the patient is, what happens so frequently, is then you see them outpatient, and each one of them gives you a different set of decisions to make. Sometimes that actually interact pathologically, unhealthily with each other. And only the very smart nurses or primary care physicians will actually notice that and call, quote, a “family meeting,” or bring everybody in the same room to align them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, I think this idea of quarterback is really very, very topical right now because there’s so much intensity in the AI space around agents. And in fact, you know, the Microsoft AI team under Mustafa Suleyman and Dominic King, Harsha Nori, and team just recently posted a paper on something called sequential diagnosis, which is basically an AI quarterback that is supposed to smartly consult with other AI specialties. And interestingly, one of the AI agents is sort of the devil’s advocate that’s always criticizing and questioning things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;That’s interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And at least on very, very hard, rare cases, it can develop some impressive results. There’s something to this that I think is emerging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And, Peter, Morgan said something that blew me away even more, which was, well, why do we even need specialists if the reason for a specialist is because there’s so much medical knowledge that no single physician can know all of it, and therefore we create specialists, but that limitation does not exist for AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And so there he was kind of undermining this whole elaborate structure that has grown up because of human limitations that may not ultimately need to be there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. So now that gives me a good segue to get back to our economist and get to something that Azeem Azhar said. And so there’s a clip here from Azeem.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ff46028707e465b3cd8582210840bd0"&gt;&lt;strong&gt;&lt;em&gt;AZEEM AZHAR: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;We didn’t talk about, you know, AI in its ability to potentially do this, which is to extend the clinician’s presence throughout the week. &lt;em&gt;You know, t&lt;/em&gt;he idea that maybe some part of what the clinician would do if you could talk to them on Wednesday, Thursday, and Friday could be delivered through an app or a chatbot just as a way of encouraging the compliance, which is often, especially with older patients, one reason why conditions, you know, linger on for longer.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And, you know, in the same conversation, he also talked about his own management of asthma and the fact that he’s been managing this for several decades and knows more than any other human being, no matter how well medically trained, could possibly know. And it’s also very highly personalized. And it’s not a big leap to imagine AI having that sort of lifelong understanding.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So in fact, I want to give credit back to our book since you insulted us. [LAUGHTER] You challenged us. You doubted us. We do have at the end of the book a AI which is helping this woman manage her way through life. It’s quarterbacking for the woman all these different services.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Ah, you’re right. Yes. In fact, it’s very much, I think, along the lines of the vision that Azeem laid out in our conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. It also reminded me of the piece Zak wrote about his mother&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; at one point when she was managing congestive heart failure and she needed to watch her weight very carefully to see her fluid status. And absolutely, there’s no … I see no reason whatsoever why that couldn’t be done with AI right now. Actually, although back then, Zak, you were writing that it takes much more than an AI [LAUGHS] to manage such a thing, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; You need an AI that you can trust. Now, my mother was born in 1927, and she’d learned through the school of hard knocks that you can’t trust too many people, maybe even not your son, &lt;em&gt;MD&lt;/em&gt;, &lt;em&gt;PhD&lt;/em&gt; [LAUGHTER].&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what I’ve been surprised [by] is how, for example, how many people are willing to trust and actually see effective use of AI as mental health counselors, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So it may in fact be that there’s a generational thing going on, and at least there’ll be some very large subset of patients which will be completely comfortable in ways that my mother would have never tolerated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Now, I think we’re starting to veer into some of the core AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think maybe one of the most fun conversations I had was in the episode with both Sébastien Bubeck, my former colleague at Microsoft Research, and now he’s at OpenAI, and Bill Gates. And there was so much that was, I thought, interesting there. And there was one point, I think that sort of touches tangentially on what we were just conversing about, that Sébastien said. So let’s hear this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-19a223099867a12ed2599ae811939b43"&gt;&lt;strong&gt;&lt;em&gt;SÉBASTIEN BUBECK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And one example that I really like, a study that recently appeared where … they were comparing doctors without and with ChatGPT. … So this was a set of cases where the accuracy of the doctors alone was around 75%. ChatGPT alone was 90%. … But then the kicker is that doctors with ChatGPT was 80%. Intelligence alone is not enough. It’s also how it’s presented, how you interact with it. And ChatGPT, it’s an amazing tool. Obviously, I absolutely love it. But it’s not … you don’t want a doctor to have to type in, you know, prompts and use it that way. It should be, as Bill was saying, kind of running continuously in the background, sending you notifications.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought Sébastien was saying something really profound, but I haven’t been able to quite decide or settle in my mind what it is. What do you make of what Seb just said?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s context. I think that it requires an enormous amount of energy, brain energy, to actually correctly provide the context that you want this thing to work on. And it’s only going to really feel like we’re in a different playing field when it’s listening all the time, and it just steps right in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There is an advantage that, for example, a good programmer can have in prompting Cursor or any of these tools to do so. But it takes effort. And I think being in the conversation all the time so that you understand the context in the widest possible way is incredibly important. And I think that’s what Seb is getting at, which is if we spoon feed these machines, yes, 90%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then, talking to a human being who then has to interact and gets distracted from whatever flow they’re in and maybe even makes them feel like an early bicycle rider who all of a sudden realizes, “I’m balancing on two wheels—oh no!” And they fall over. You know, there’s that interaction which is negatively synergistic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I do think it’s a very hard human-computer engineering problem. How do we make these two agents, human and computational, work in an ongoing way in the flow? I don’t think I’m seeing anything that’s particularly new. And the things that you’re beginning to hint about, Peter, in terms of agentic coordination, I think we’ll get to some of that. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Carey, does this give you any pause? The kind of results that … they’re puzzling results. I mean, the idea of doctors with AI seeming at least in this one test—it’s just one test—but it’s odd that it does worse than the AI alone.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. I would want to understand more about the actual conditions of that study.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From what Bill Gates said, I was most struck by the question of resource-poor environments. That even though this was absolutely one of the most promising, brightest perspectives that we highlighted in the book, we still don’t seem to be seeing a lot of use among the one half of humanity that lacks decent access to healthcare.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are access problems everywhere, including here in the United States. And it is one of the most potentially promising uses of AI. And I thought if anyone would know about it, he would with the work that the Gates Foundation does.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think both you and Bill, I felt, are really simpatico. You know, Bill expressed genuine surprise that more isn’t happening yet. And it really echoed, in fact, maybe even using some of the exact same words that you’ve used. And so two years on, you’ve expressed repeatedly expecting to have seen more out in the field by now. And then I thought Bill was saying something in our conversation very similar.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, for me, I see it both ways. I see the world of medicine really moving fast in confronting the reality of AI in such a serious way. But at the same time, it’s also hard to escape the feeling that somehow, we should be seeing even more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s an odd thing, a little bit paradoxical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I think one thing that we didn’t focus on hardly at all in the book but that we are seeing is these companies rising up, stepping up to the challenge, Abridge and OpenEvidence, and what Morgan describes as a new stack, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So there is that on the flip side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, I want to get back to this thing that Seb was saying. And, you know, I had to bring up the issue of sycophancy, which we discussed at our last roundtable also. But it was particularly … at the time that Seb, Bill, and I had our conversation, OpenAI had just gone through having to retract a fresh update of GPT-4o because it had become too sycophantic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I can’t escape the feeling that some of these human-computer interaction issues are related to this tension between you want AI to follow your directions and be faithful to you, but at the same time not agree with you so often that it becomes a fault.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s asking the AI to enter into a fundamental human conundrum, which is there are extreme versions of doublethink, and there’s everyday things, everyday asks of doublethink, which is how to be an effective citizen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And even if you’re thinking, “Hmm. I’m thinking this. I’m just not going to say it because that would be rude or counterproductive.” Or some of the official doublethinks, where you’re actually told you must say this, even if you think something else. And I think we’re giving a very tough mission for these things: be nice to the user and be useful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, in education, where the thing is not always one in the same. Sometimes you have to give a little tough love to educate someone, and doing that well is both an art and it’s also very difficult. And so, you know, I’m willing to believe that the latest frontier models that have made the news in the last month are very high-performing, but they’re also all highlighting that tension …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that tension between behaving like a good citizen and being helpful. And this gets back to what are the fundamental values that we hope these things are following.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s not, you know, “Are these things going to develop us into the paperclip factory?” It’s more of, “Which of our values are going to be elevated, and which one will be suppressed?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, since I criticized our book before, let me pat ourselves on the back this time because, I think, pervasive throughout our book, we were touching on some of these issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In fact, we started the book, you know, with GPT-4 scolding me for wanting it to impersonate Zak. And there was the whole example of asking it to rewrite a poem in a certain way, and it kind of silently just tried to slide, you know, without me knowing, slide by without following through on the whole thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that early version of GPT-4 was definitely not sycophantic at all. In fact, it was just as prone to call you an idiot if it thought you were wrong. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I had some very testy conversations around my endocrine diagnosis with it. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Well then, Peter, I would ask you, I mean last time I asked you about, &lt;em&gt;well, hallucinations, aren’t those solvable?&lt;/em&gt; And this time I would ask you, well, sycophancy, isn’t that kind of like a dial you can turn? Like, is that not solvable?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think there are several interlocking problems. But if we assume superintelligence, even with superintelligence, medicine is such an inexact science that there will always be situations that are guesses that take into account other factors of a person’s life, other value judgments, exactly as Zak had pointed out in our previous roundtable conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think there’s always going to be an opening for either differences of opinion or agreeing with you too much. And there are dangers in both cases. And I think they’ll always be present. I don’t know that, at least in something as inexact as medical science, I don’t know that it’ll ever be completely eliminated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And it’s interesting because I was trying to think what’s the right balance, but there are patients who want to be told this is what you do. Whereas there’s other patients who want to go through every detail of the reasoning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s not a matter of education. It’s really a temperamental, personality issue. And so we’re going to &lt;em&gt;have to&lt;/em&gt;, I think, develop personalities …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that are most effective for those different kinds of individuals. And so I think that is going to be the real frontier. Having human values and behaving in ways that are recognizable and yet effective for certain groups of patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And lots of deep questions, including how paternalistic do we want to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;All right, so we’re getting into medical science and hallucination. So that gives me a great segue to the conversations in the episode on biomedical research. And one of the people that I interviewed was Noubar Afeyan from Moderna and Flagship Pioneering. So let’s listen to this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-574184a033e6f29ff2ba40f7e611b28a"&gt;&lt;strong&gt;&lt;em&gt;NOUBAR AFEYAN:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; We, some hundred or so times a year, ask “what if” questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that’s testable. Then we go into a lab, and we test it. So in that world, right, sitting there going, like, “How do I know this transformer is going to work?” The answer is, “For what?” Like, it’s going to work to make something up … well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] So I think that really touches on just the fact that there’s so many unknowns and such lack of precision and exactness in our understanding of human biology and of medicine. Carey, what do you think?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, I just have this emotional reaction, which is that I love the idea of AI marching into biomedical science and everything from getting to the virtual cell eventually to, Zak, I think it was a colleague of yours who recently published about … it was a new medication that had been sort of discovered by AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and it was actually testing out up to the phase II level or something, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Oh, this is Marinka’s work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah, Marinka, Marinka Zitnik. And … yeah. So, I mean, I think it avoids a lot of the, sort of, dilemmas that are involved with safety and so on with AI coming into medicine. And it’s just the discovery process, which we all want to advance as quickly as possible. And it seems like it actually has a great deal of potential that’s already starting to be realized.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, absolutely.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I love this topic. First of all, I thought, actually, I think Bill and Seb, actually, had interesting things to say on that very topic, rationales which I had not really considered why, in fact, things might progress faster in the discovery space than in the clinical delivery space, just because we don’t know in clinical medicine what we’re trying to maximize precisely. Whereas for a drug effect, we do know what we’re trying to maximize.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, in fact, I happened to save that snippet from Bill Gates saying that. So let’s cue that up.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ca7a5edfbf41028162616b68d8380d1"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think it’s very much within the realm of possibility that the AI is not only accelerating healthcare discovery but substituting for a lot of the roles of, you know, “I’m an organic chemist,” or “I run various types of assays.” I can see those, which are, you know, testable-output-type jobs but with still very high value, I can see, you know, some replacement in those areas before the doctor.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So, Zak, isn’t that Bill saying exactly what you’re saying?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; That is my point. I have to say that this is another great bet, that either we’re all going to be surprised or a large group of people will be surprised or disappointed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s still a lot of people in the sort of medicinal chemist, trialist space who are still extremely skeptical that this is going to work. And we haven’t quite shown them yet that it is. Why have we not shown them? Because we haven’t gone all the way to a phase III study, which showed that the drug behaves as expected to, is effective, and basically doesn’t hurt people. That turns out to require a lot of knowledge. I actually think we’re getting there, but I understand the skepticism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Carey, what are your thoughts?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I mean, there will be no way around going through full-on clinical trials for anything to ever reach the market. But at the same time, you know, it’s clearly very promising. And just to throw out something for the pure fun of it, Peter, I saw … one of my favorite tweets recently was somebody saying, you know, isn’t it funny how computer science is actually becoming a lot more like biology in that it’s just becoming empirical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s like you just throw stuff at the AI and see what it does. [LAUGHTER] And I was like,&lt;em&gt; oh, yeah, that’s what Peter was doing when we wrote the book.&lt;/em&gt; I mean, he understood as many innards as anybody can. But at the same time, it was a totally empirical exercise in seeing what this thing would do when you threw things at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;So it’s the new biology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, yeah. So I think we talked in our book about accelerating, you know, biomedical knowledge and medical science. And that actually seems to be happening. And I really had fun talking to Daphne Koller about some of the accomplishments that she’s made. And so here’s a little snippet from Daphne.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b519fe67233d03b2946f95df076d6451"&gt;&lt;strong&gt;&lt;em&gt;DAPHNE KOLLER: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;This will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient. And I think there’s been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, when I was listening to that, I was reminded of one of the very first examples that you had where, you know, you had a very rare case of a patient, and you’re having to narrow down some pretty complex and very rare genetic conditions. This thing that Daphne says, that seems to be the logical conclusion that everyone who’s thinking hard about AI and biology is coming to. Does it seem more real now two years on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely seems more real. Here’s some sad facts. If you are at a cancer center, you will get targeted therapies if you qualify for it. Outside cancer centers, you won’t. And it’s not that the therapies aren’t available. It’s just that you won’t have people thinking about it in that way. And especially if you have some of the rare and more aggressive cancers, if you’re outside one of those cancer centers, you’re at a significant disadvantage for survival for that reason. And so anything that provides just the “simple,” in quotes, dogged investigation of the targeted therapies for patients, it’s a home run.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my late graduate student, Atul Butte, died recently at UCSF, where he was both a professor and the leader of the Bakar Institute, and he was a Zuckerberg Chan Professor of Pediatrics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He was diagnosed with a rare tumor two years ago. His wife is a PhD biologist, and when he was first diagnosed, she sent me the diagnosis and the mutations. And I don’t know if you know this, Peter, but this was still when we were writing the book and people didn’t know about GPT-4.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I put in those mutations into GPT-4 and the diagnosis. And I said, “I’d like to help treat my friend. What’s the right treatment?” And GPT, to paraphrase, GPT-4 said, “Before we start talking about treatment, are you sure this is the right diagnosis? Those mutations are not characteristic for that tumor.” And he had been misdiagnosed. And then they changed the diagnosis therapy and some personnel.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I don’t have to hallucinate this. It’s already happened, and we’re going to need this. And so I think targeted therapy for cancers is the most obvious use. And if God forbid one of you has a family member who has cancer, it’s moral malpractice not to look at the genetics and run it past GPT-4 and say, “What are the available therapies?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I really deeply believe that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Carey, I think one thing you’ve always said is that you’re surprised that we don’t hear more stories along these lines. And I think you threw a quote from Mustafa Suleyman back at me. Do you want to share that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. Recently, I believe it was a Big Technology interview&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and the reporter asked Mustafa Suleyman, “So you guys are seeing 50 million queries, medical queries, a day [to Copilot and Bing]. You know, how’s that going?” And I think I am a bit surprised that we’re not seeing more stories of &lt;em&gt;all&lt;/em&gt; types. Both here’s how it helped me and also here was maybe, you know, a suggestion that was not optimal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. I do think in our book, we did predict both positive and negative outcomes of this. And it is odd. Atul was very open with his story. And of course, he is such … he was such a prominent leader in the world of medicine.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think I share your surprise, Carey. I expected by now that a lot more public stories would be out. Maybe there is someone writing a book collecting these things, I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Maybe someone called Carey Goldberg should write that book. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Write a book, maybe. I mean, we have Patients Use AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is a wonderful blog by Dave deBronkart, the patient advocate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I wonder if it’s also something structural, like who would be or what would be the institution that would be gathering these stories? I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And that’s the problem. You see, this goes back to the same problem that [Ethan] Mollick was talking about. Individual doctors are using them. The hospital as a whole is not doing that. So it’s not judging the quality, as part of its quality metrics, of how good the AI is performing and what new has happened. And the other audience, namely the patients, have no mechanism. There is no mechanism to go to Better Business Bureau and say, “They screwed up,” or “This was great.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So now I want to get a little more futuristic. And this gets into whether AI is really going to get almost to the &lt;em&gt;ab initio&lt;/em&gt; understanding of human biology. And so Eric Topol, who is one of the guests, spoke to this a bit. So let’s hear this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-a8cd8394bbdf383bb04d1e5902cb8b97"&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;ERIC TOPOL:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; No, I think within 10 years for sure. You know, the group that got assembled, that Steve Quake pulled together, I think has 42 authors in a paper in Cell. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree that not only is this a worthy goal, but it’s actually going to be realized, that was impressive.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I have to say Eric’s optimism took me aback. Just speaking as a techie, I think I started off being optimistic: as soon as we can figure out molecular dynamics, biology can be solved. And then you start to learn more about biochemistry, about the human cell, and then you realize, oh, my God, this is just so vast and unknowable. And now you have Eric Topol saying, “Well, in less than 10 years.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;So what’s delightful about this period is that those of us who are cautious were so incredibly wrong about AI two years ago. [LAUGHTER] That’s a true joy … I mean, absolute joy. It’s great to have your futurism made much more positive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think that we’re going from, you know, for example, AlphaFold has had tremendous impact. But remember, that was built on years of acquisition of crystallography data that was annotated. And of course, the annotation process becomes less relevant as you go down the pipe, but it started from that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And there’s lots of parts of the cell. So when people talk about virtual cells—I don’t mean to get too technical—mostly they’re talking about perturbation of gene expression. They’re not talking about, “Oh, this is how the liposome and the centrosome interact, and notice how the Golgi bodies bump into each other.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a whole bunch of other levels of abstraction we know nothing about. This is a complex factory. And right now, we’re sort of the level from code into loading code into memory. We’re not talking about how the rest of the robots work in that cell, and how the rest of those robots work in the cell turns out to be pretty important to functioning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’d love to be wrong again. And in 10 years, oh yeah, not only, you know, our first in-human study will be you, Dr. Zak. We’re going put the drug because we fully simulated you. That’d be great.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And, by the way, just to give people their due, there probably was a lot of animal research that could be done &lt;em&gt;in silico &lt;/em&gt;and that for various political reasons we’re now seeing happen. That’s a good thing. But I think that sometimes it takes a lot of hubris to get us where we need to get, but my horizon is not the same as his.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I guess I have to take this time to brag. Just recently out of our AI for Science team did publish in &lt;em&gt;Science&lt;/em&gt; a biological emulator that does pretty long timespan, very, very precise, and very efficient molecular dynamics, biomolecular dynamics emulation. We call it &lt;em&gt;emulation&lt;/em&gt; because it’s not simulating every single time step but giving you the final confirmations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;That’s an amazing result.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But … that is an amazing result. And you’re doing it in some very important interactions. But there’s so much more to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I know, and it’s single molecules; it’s not even two molecules. There’s so much more to go for here. But on the other hand, Eric is right, you know, 42 experts writing for &lt;em&gt;Cell&lt;/em&gt;, you know, that’s not a small matter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think sometimes you really need to drink your own hallucinogens to actually succeed. Because remember, when the Human Genome Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; was launched, we didn’t know how to sequence at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We said maybe we would get there. And then in order to get the right funding and excitement and, I think, focus, we predicted that by early 2000s we’d be transforming medicine. Has not happened yet. Things have happened, but at a much slower pace. And we’re 25 years out. In fact, we’re 35 years out from the launch.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But again, things are getting faster and faster. Maybe the singularity is going to make a whole bunch of things easier. And GPT-6 will just say, “Zak, you are such a pessimist. Let me show you how it’s done.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It really is a pessimism versus optimism. Like is it, I mean, biology is such a bitch, right. [LAUGHTER] Can we actually get there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, everyone was surprised and blown away by the, you know, the quantum leap of GPT-4. Who knows when enough data gets in there if we might not have a similar leap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s get back to healthcare delivery. Besides Morgan Cheatham, we talked to [a] more junior medical student who’s at the Kaiser Permanente School of Medicine, Daniel Chen. And, you know, I asked him about this question of patients who come in armed [LAUGHS] with a lot of their own information. Let’s hear what he said about this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b854f48f19d32b116ea80de7d13c8a99"&gt;&lt;strong&gt;&lt;em&gt;DANIEL CHEN: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;But for those that come in with a list, I sometimes sit down with them, and we’ll have a discussion, honestly. … “I don’t think you have meningitis because, you know, you’re not having a fever. Some of the physical exam maneuvers we did were also negative. So I don’t think you have anything to worry about that,” you know. So I think it’s having that very candid conversation with the patient that helps build that initial trust.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, as far as I can tell, Daniel and Morgan are figuring this out on their own as medical students. I don’t think this is part of the curriculum. Does it need to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s missing the bigger point. The incentives and economic forces are such that even if you were Daniel, and things have not changed in terms of incentives, and it’s 2030, he still has to see this many patients in an hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And sitting down, going over that with a patient, let’s say some might need more … in fact, I think computer scientists are enriched for these sort of neurotic “explain [to] me why this works,” when often the answer is, “I have no idea; empirically it does.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And patients in some sense deserve that conversation, and we’re taught about joint decision making, but in practice, there’s a lot of skills that are deployed to actually deflect so that you can get through the appointment and see enough patients per hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I think that one of the central … another task for AI is how to engage with patients to actually explain to them why their doctor is doing what he’s doing and perhaps ask the one or two questions that you should be asking the doctor in order to reassure you that they’re doing the right thing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;I&lt;strong&gt; &lt;/strong&gt;just …&lt;strong&gt; &lt;/strong&gt;right now, we are going to have less doctor time, not more doctor time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’ve always been struck by the divide between medicine that we’re taught as it should be practiced as a gentle person’s vocation or sport as opposed to assembly line, heads down “you’ve got to see those patients by the end of the day” because, otherwise, you haven’t seen all the patients at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Carey, I’ve been dying to ask you this, and I have not asked you this before. When you go see a doctor, are you coming in armed with ChatGPT information?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I haven’t needed to yet, but I certainly would. And also my reaction to the medical student description was, I think we need to distinguish between the last 20 years, when patients would come in armed with Google, and what they’re coming in with now because at least the experiences that I’ve witnessed, it is miles better to have gone back and forth with GPT-4 than with, you know, dredging what you can from Google. And so I think we should make that distinction.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And also, the other thing that most interested me was this question for medical students of whether they should not use AI for a while so that they can learn …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… how to think and similarly maybe don’t use the automated scribes for a while so they can learn how to do a note. And at what point should they then start being able to use AI? And I suspect it’s fairly early on that, in fact, they’re going be using it so consistently that there’s not that much they need to learn before they start using the tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; These two students were incredibly impressive. And so I have wondered, you know, if we got a skewed view of things. I mean, Morgan is, of course, a very, very impressive person. And Daniel was handpicked by the dean of the medical school to be a subject of this interview.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;You know, we filter our students, by and large, I mean, there’s exceptions, but students in medical school are so starry eyed. And they are really … they got into medical school—I mean, some of them may have faked it—but a lot of them because they really wanted to do good.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And they really wanted to help. And so this is very constant with them. And it’s only when they’re in the machine, past medical school, that they realize, oh my God, this is a very, very different story.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I can tell you, because I teach a course in computational-enabled medicine, so I get a lot of these nerd medical students, and I’m telling them, “You’re going to experience this. And you’re going to say, ‘I’m not going to able to change medicine until I get enough cred 10, 15 years from now, whereas I could start my own company and immediately change medicine.’”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And increasingly I’m getting calls in like residency and saying, “Zak, help me. How do I get out of this?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And so I think there’s a real disillusionment of, like, between what we’re asking for people coming to medical school—we’re looking for a phenotype—and then we’re disappointing them massively, not everywhere, but massively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for me, it’s very sad because among our best and brightest, and then because of economics and expectations and the nature of the beast, they’re not getting to enjoy the most precious part of being a doctor, which is that real human connection, and longitudinality, you know, the connection between the same doctor visit after visit, is more and more of a luxury.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, maybe this gets us to the last episode, you know, where I talk to a former, you know, state director of public health, Umair Shah, and with Gianrico Farrugia, who’s the CEO of Mayo Clinic. And I think if there’s one theme that I took away from those conversations is that we’re not thinking broadly enough nor big enough.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so here’s a little quote of exchange that Umair Shah, who was the former head of public health in the State of Washington and prior to that in Harris County, Texas, and we had a conversation about what techies tend to focus on when they’re thinking about AI and medicine.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-0a05c3ff13da1926875eed47432d27b2"&gt;&lt;strong&gt;&lt;em&gt;UMAIR SHAH: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;Yes.&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I have been definitely guilty. I think Umair, of course, was speaking as a former frustrated public health official in just thinking about all the other things that are important to maintain a healthy population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Is there some lesson that we should take away? I think our book also focused a lot on things like diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. Well, first of all, I think we just have to have humility. And I think it’s a really important ingredient. I found myself staring at the increase in lifespan in human beings over the last two centuries and looking for bumps that were attributable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m in medical school. I’ve already made this major commitment. What are the bumps that are attributable to medicine? And there was one bump that was due to vaccines, a small bump. Another small bump that was due to antibiotics. And the rest of it is nutrition, sanitation, yeah, nutrition and sanitation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think doctors can be incredibly valuable, but not all the time. And we’re spending now one-sixth of our GDP on it. The majority of it is not effectively prolonging life. And so the humility has to be the right medicine at the right time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But that runs, (A) against a bunch of business models. It runs against the primacy of doctors in healthcare. It was one thing when there were no textbooks; there was no PubMed. You know, the doctor was the repository of all the probably knowledge that we have. But I think your guests were right. We have to think more broadly in the public health way. How do we make knowledge pervasive like sanitation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Although I would add that since what we’re talking about is AI, it’s harder to see if … and if what you’re talking about is public health, I mean, it was certainly very important to have good data during the pandemic, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But most of the ways to improve public health, like getting people to stop smoking and eat better and sleep better and exercise more, are not things that AI can help with that much. Whereas diagnosis or trying to improve treatment are places that it could tackle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, Peter, I wanted to put you—oh, wait, Zak’s going to say something—but, Peter, I wanted to put you on the spot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, if you had a medical issue now, and you went to a physician, would you be OK with them not using generative AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I think if it’s a complex or a mysterious case, I would want them to use generative AI. I would want that second opinion on things. And I would personally be using it. If for no other reason than just to understand what the chart is saying.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I don’t see, you know, how or why one wouldn’t do that now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s such a cheap second opinion, and people are making mistakes. And even if there are mistakes on the part of AI, if there’s a collision, discrepancy, that’s worth having a discussion. And again, this is something that we used to do more of when we had more time with the patients; we’d have clinic conferences.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And we don’t have that now. So I do think that there is a role for AI. But I think again, it’s much more of a continual presence, being part of a continued conversation rather than an oracle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think that’s when you’ll start seeing, when the AI is truly a colleague, and saying, “You know, Zak, that’s the second time you made that mistake. You know, that’s not obesity. That’s the effect of your drugs that you’re giving her. You better back off of it.” And that’s what we need to see happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, and for the business of healthcare, that also relates directly to quality scores, which translates into money for healthcare providers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So the last person that we interviewed was Gianrico Farrugia. And, you know, I was sort of wondering, I was expecting to get a story from a CEO saying, “Oh, my God, this has been so disruptive, incredibly important, meaningful, but wow, what a headache.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At least Gianrico didn’t expose any of that. Here’s one of the snippets to give you a sense.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-e494c3919056a8b99abdfa66f7e6fae6"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; &lt;/em&gt;&lt;strong&gt;&lt;em&gt;FARRUGIA:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; When generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, because something as disruptive as that instantly became enabling at Mayo Clinic.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I tried pretty hard in that interview to get Gianrico to admit that there was a period of headache and disruption here. And he never, ever gave me that. And so I take him at his word.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Zak, maybe I should ask you, what about Harvard and the whole Harvard medical ecosystem?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would be surprised if there are system-wide measurable gains in health quality right now from AI. And I do have to say that Mayo is one of the most marvelous organizations in terms of team behavior. So if there’s someone who’s gotten the team part of it right, they’ve come the closest, which relates to our prior conversation. They have the quarterback idea …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… pretty well down compared to others.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Nonetheless, I take him at his word, that it hasn’t disrupted them. But I’m also, I have yet to see the evidence that there’s been a quantum leap in quality or efficacy. And I do believe that it’s possible to have a quantum leap in efficacy in the right system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if they haven’t been disrupted, I would venture that they’ve absorbed it, but they haven’t used it to its fullest potential. And the way I could be proven wrong is next year, also the metrics showing that over the last year, they’ve had, you know, decreased readmissions, decreased complications, decreased errors and all that. And if so, God bless them. And we should all be more like Mayo.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought a little bit about two other quotes from the interviews that sort of maybe would send us off with some more inspirational kind of view of the future. And so there’s one from Bill Gates and one from Gianrico Farrugia. So what I’d like to do is to play both of those and then maybe we can have our last comments.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-34fa8f74d3c5dd1ddf63456b250b860b"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;: You know, I’ve gone so far as to tell politicians with national health systems that if they deploy AI appropriately, that the quality of care, the overload of the doctors, the improvement in the economics will be enough that their voters will be stunned because they just don’t expect this, and, you know, they could be reelected just on this one thing of fixing what is a very overloaded and economically challenged health system in these rich countries.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And now Gianrico.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-daa9fe33118b2710490d542ab9959977"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO FARRUGIA: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. … And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, no, is that let’s start with that aim, the last aim …&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;because the others will come automatically if you’re working on that harder problem. Because one, to get to that harder problem, you’ll find all the other solutions.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All right. I think these are both kind of calls to be more assertive about this and more forward leaning. I think two years into the GPT-4 era, those are pretty significant and pretty optimistic calls to action. So maybe just to give you both one last word. What would be one hope that you would have for the world of healthcare and medicine two years from now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would hope for businesses that whoever actually owns them at some holding company level, regardless of who owns them, are truly patient-focused companies, companies where the whole AI is about improving your care, and it’s only trying to maximize your care and it doesn’t care about resource limitations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And as I was listening to Bill, and the problem with what he was saying about saving dollars for governments is for many things, we have some very expensive things that work. And if the AI says, “This is the best thing,” it’s going to break your bank. And instead, because of research limitations, we play a human-based fancy footwork to get out of it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s a hard game to play, and I leave it to the politicians and the public health officials who have to do those trades of utilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In my role as doctor and patient, I’d like to see very informed, authoritative agents acting only on our behalf so that when we go and we seek to have our maladies addressed, the only issue is, what’s the best and right thing for me now? And I think that is both technically realizable. And even in our weird system, there are business plans that will work that can achieve that. That’s my hope for two years from now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, fantastic. Carey.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I second that so enthusiastically. And I think, you know, we have this very glass half full/glass half empty phenomenon two years after the book came out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s certainly very nice to see, you know, new approaches to administrative complexity and to prior authorization and all kinds of ways to make physicians’ lives easier. But really what we all care about is our own health and that we would like to be able to optimize the use of this truly glorious technological achievement to be able to live longer and better lives. And I think what Zak just described is the most logical way to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I think for me, two years from now, I would like to see all of this digital data that’s been so painful, such a burden on every doctor and nurse to record, actually amount to something meaningful in the care of patients. And I think it’s possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Amen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; All right, so it’s been quite a journey. We were joking before we’re still on speaking terms after having written a book. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, um, I think listeners might enjoy knowing that we debated amongst ourselves what to do about a second edition, which seemed too painful to me, and so I suggested the podcast, which seemed too painful to the two of you [LAUGHTER]. And in the end, I don’t know what would have been easier, writing a book or doing this podcast series, but I do think that we learned a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, last bit of business here.&lt;strong&gt; &lt;/strong&gt;To avoid having the three of us try to write a book again and do this podcast, I leaned on the production team in Microsoft Research and the Microsoft Research Podcast. And I thought it would be good to give an explicit acknowledgment to all the people who’ve contributed to this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s a long list of names. I’m going to read through them all. And then I suggest that we all give an applaud [LAUGHTER] to them. And so here we go.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s Neeltje Berger, Tetiana Bukhinska, David Celis Garcia, Matt Corwine, Jeremy Crawford, Kristina Dodge, Chris Duryee, Ben Ericson, Kate Forster, Katy Halliday, Alyssa Hughes, Jake Knapp, Weishung Liu, Matt McGinley, Jeremy Mashburn, Amanda Melfi, Wil Morrill, Joe Plummer, Brenda Potts, Lindsay Shanahan, Sarah Sobolewski, David Sullivan,&amp;nbsp;Stephen Sullivan, Amber Tingle, Caitlyn Treanor, Craig Tuschhoff, Sarah Wang, and Katie Zoller.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Really a great team effort, and they made it super easy for us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you. Thank you. Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Thank you. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;A big thank you again to all of our guests for the work they do and the time and expertise they shared with us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, last but not least, to our listeners, thank you for joining us. We hope you enjoyed it and learned as much as we did. If you want to go back and catch up on any episodes you may have missed or to listen to any again, you can visit aka.ms/AIrevolutionPodcast&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;Until next time.&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Illustrated headshots of Carey Goldberg, Peter Lee, and Dr. Isaac Kohane." class="wp-image-1148279" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Episode11-Peter-Carey-Isaac_AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this series finale, Lee welcomes back coauthors Carey Goldberg&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Dr. Zak Kohane&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to discuss how their predictions stack up against key takeaways from guests in the second half of the series: experts on AI’s economic and societal impact; technologists on the cutting edge; leaders in AI-driven medicine; next-generation physicians; and heads of healthcare organizations. Lee, Goldberg, and Kohane explore thinking innovatively about existing healthcare processes, including the structure of care teams and the role of specialties, to take advantage of AI opportunities and consider what clinicians and patients might need these new AI tools to be to feel empowered when it comes to giving and receiving the best healthcare. They close the episode with their hopes for the future of AI in health.&lt;/p&gt;



&lt;div class="wp-block-group msr-pattern-link-list is-layout-flow wp-block-group-is-layout-flow"&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more-1"&gt;Learn more:&lt;/h2&gt;








&lt;/div&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC] &lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“As a society—indeed, as a species—we have a choice to make. Do we constrain or even kill artificial intelligence out of fear of its risks and obvious ability to create new harms? Do we submit ourselves to Al and allow it to freely replace us, make us less useful and less needed? Or do we start, today, shaping our Al future together, with the aspiration to accomplish things that humans alone, and Al alone, can’t do but that humans+Al can? The choice is in our hands … .”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee. &lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong? &lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here. &lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from the epilogue, and I think it’s a truly fitting closing sentiment for the conclusion of this podcast series—because it calls back to the very beginning.&lt;/p&gt;



&lt;p&gt;As I’ve mentioned before, Carey, Zak, and I wrote &lt;em&gt;The AI Revolution in Medicine&lt;/em&gt; as a guide to help answer these big questions, particularly as they pertain to medicine. You know, we wrote the book to empower people to make a choice about AI’s development and use. Well, have they? Have &lt;em&gt;we&lt;/em&gt;?&lt;/p&gt;



&lt;p&gt;Perhaps we’ll need more time to tell. But over the course of this podcast series, I’ve had the honor of speaking with folks from across the healthcare ecosystem. And my takeaway? They’re all committed to shaping AI into a tool that can improve the industry for practitioners and patients alike.&lt;/p&gt;



&lt;p&gt;In this final episode, I’m thrilled to welcome back my coauthors, Carey Goldberg and Dr. Zak Kohane. We’ll examine the insights from the second half of the season.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Carey, Zak—it’s really great to have you here again!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CAREY&lt;/strong&gt; &lt;strong&gt;GOLDBERG: &lt;/strong&gt;Hey, Peter!&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ZAK&lt;/strong&gt; &lt;strong&gt;KOHANE:&lt;/strong&gt; Hi, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So this is the second roundtable. And just to recap, you know, we had several early episodes of the podcast where we talked to some doctors, some technology developers, some people who think about regulation and public policy, patient advocates, a venture capitalist who invests in, kind of, consumer and patient-facing medical ventures, and some bioethicists.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think we had a great conversation there. I think, you know, it felt mostly validating. A lot of the things that we predicted might happen happened, and then we learned a lot of new things. But now we have five more episodes, and the mix of kinds of people that we talk to here is different than the original.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I thought it would be great for us to have a conversation and recap what we think we heard from all of them. So let’s just start at the top.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in this first episode in the second half of this podcast series, we talked to economists Azeem Azhar and Ethan Mollick. And I thought those conversations were really interesting. Maybe there were, kind of, two things, two main topics. One was just the broader impact on the economy, on the cost of healthcare, on overall workforce issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things that I thought was really interesting was something that Ethan Mollick brought up. And maybe just to refresh our memories, let’s play this little clip from Ethan.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-ab782358e1fff73901dd881b85e04b33"&gt;&lt;strong&gt;&lt;em&gt;ETHAN MOLLICK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;we’re in this really interesting period where there’s incredible amounts of individual innovation in productivity and performance improvements in this field, like very high levels of it. …&lt;/em&gt;&lt;em&gt; &lt;/em&gt;&lt;em&gt;We’re seeing that in nonmedical problems, the same kind of thing, which is, you know, we’ve got research showing 20 and 40% performance improvements. … But then the organization doesn’t capture it; the system doesn’t capture it. Because the individuals are doing their own work, and the systems don’t have the ability to, kind of, learn or adapt as a result.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So let me start with you, Zak. Does that make sense to you? Are you seeing something similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I thought it was incredibly insightful because we discussed on our earlier podcast how a chief AI officer in one of the healthcare hospitals, in one of the healthcare systems, was highly regulating the use of AI, but yet in her own practice on her smartphone was using all these AI technologies.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s insightful that on the one hand, she is increasing her personal productivity, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and perhaps she’s increasing her quality of her care. But it’s very hard for the healthcare system to actually realize any gains. It’s unlikely … let’s put it this way. It would be for her a defeat if they said, “Now you should see &lt;em&gt;more&lt;/em&gt; patients.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Now, I’m not saying that won’t happen. It could happen. But, you know, gains of productivity are really at the individual level of the doctors. And that’s why they’re adopting it. That’s why the ambient dictation tools are so successful. But really turning it into things that matter in terms of productivity for healthcare, namely making sure that patients are getting healthy, requires that every piece of the puzzle works well together. You know, it’s well-tread ground to talk about how patients get very expensive procedures, like a cardiac transplant, and then go home, and they’re not put on blood thinners …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … and then they get a stroke. You know, the chain is as strong as the weakest link. And just having AI in one part of it is not going to do it. And so hospitals, I think, are doubly burdened by the fact that, (A) they tend to not like innovation because they are high-revenue, low-margin companies. But if they want it implemented effectively, they have to do it across the entire processes of healthcare, which are vast and not completely under their control.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Yep. You know, that was Sara Murray, who’s the chief health AI officer at UC San Francisco.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, you know, Carey, remember, we were puzzled by Chris Longhurst’s finding in a controlled study that the, you know, having an AI respond to patient emails didn’t seem to lead to any, I guess you would call it, &lt;em&gt;productivity benefits&lt;/em&gt;. I remember we were both kind of puzzled by that. I wonder if that’s related to what Ethan is saying here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; I mean, possibly, but I think we’ve seen since then that there have been multiple studies showing that in fact using AI can be extremely effective or helpful, even, for example, for diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I find just from the patient point of view, it kind of drives me crazy that you have individual physicians using AI because they know that it will improve the care that they’re offering. And yet you don’t have their institutions kind of stepping up and saying, “OK, these are the new norms.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, Ethan Mollick is a national treasure, right. Like, he is the classic example of someone who just stepped up at this moment …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… when we saw this extraordinary technological advance. And he’s not only stepping up for himself. He’s spreading the word to the masses that this is what these things can do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s frustrating to see the institutions not stepping up and instead the individual doctors having to do it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But he made another very interesting point, which was that the reason that &lt;em&gt;he&lt;/em&gt; could be so informative to not only the public but practitioners of AI is these things would emerge out of the shop, and they would not be aged too long, like a fine wine, before they were just released to the public.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so he was getting exposure to these models just weeks after some of the progenitors had first seen it. And therefore, because he’s actually a really creative person in terms of how he exercises models, he sees uses and problems very early on. But the point is institutions, think about how much they are disadvantaged. They’re not Ethan Mollick. They’re not the progenitors. So they’re even further behind. So it’s very hard. If you talk to most of the C-suite of hospitals, they’d be delighted to know as much about the impact as Ethan Mollick.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. By the way, you know, I picked out this quote because within Microsoft, and I suspect every other software company, we’re seeing something very similar, where individual programmers are 20 to 30% more productive just in the number of lines of code they write per day or the number of pull requests per week. Any way you measure it, it’s very consistent. And yet by the time you get to, say, a 25-person software engineering team, the productivity of that whole team isn’t 25% more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, that &lt;em&gt;is&lt;/em&gt; starting to change because we’re starting to figure out that, well, maybe we should reshape how the team operates. And there’s more of an orientation towards having, you know, smaller teams of full-stack developers. And then you start to see the gains. But if you just keep the team organized in the usual way, there seems to be a loss. So there’s something about what Ethan was saying that resonated very strongly with me.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;But I would argue that it’s not just productivity we’re talking about. There’s a moral imperative to improve the care. And if you have tools that will do that, you should be using them or trying harder to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think, yes, first of all, absolutely you would. Unfortunately, most of the short-term productivity measures will not measure improvements in the quality of care because it takes a long time to die even with bad care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that doesn’t show up right away. But I think what Peter just said actually came across in several of the podcasts, which is that it’s very tricky trying to shoehorn these things into making what we’re already doing more productive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Existing structures.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. And I know, Carey, that you’ve raised this issue many times. But it really calls into question, what should we be doing with our time with doctors? And they are a scarce resource. And what is the most efficient way to use them?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I remember we [&lt;em&gt;The New England Journal of Medicine AI&lt;/em&gt;] published a paper of someone who was able to use AI to increase the throughput of their emergency room&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; by actually more appropriately having the truly sick people in the sick queue, in the triage queue, for urgent care.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think we’re going to have to think that way more broadly, about we don’t have to now look at every patient as an unknown with maybe a few pointers on diagnosis. We can have a fairly extensive profiling.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I know that colleagues in Clalit [Health Services] in Israel, for example, are using the overall trajectory of the patient and some considerations about utilities to actually figure out who to see next week.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, you know, what you said brings up another maybe connection to one thing that we see also in software development. And it relates to also what we were discussing earlier: about the last thing a doctor wants is to have a tool that allows them to see even yet more patients per day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So in software development, there’s always this tension. Like, how many lines of code can you write per day? That’s one productivity measure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes we’re taught, well, don’t write more lines of code per day, but make sure that your code is well structured. Take the time to document it. Make sure it’s fully commented. Take the time to talk to your fellow software engineering team members to make sure that it’s well coordinated. And in the long run, even if you’re writing half the number of lines of code per day, the software process will be far more efficient.&lt;/p&gt;



&lt;p&gt;And so I’ve wondered whether there’s a similar thing where doctors could see 20% fewer patients in a day, but if they take the time and also had AI help to coordinate, maybe a patient’s journey might be half as long. And therefore, the health system would be able to see twice as many patients in a year’s period or something like that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think you’ve “nerd sniped” me because you [LAUGHTER]—which is all too easy—but I think there’s a central issue here. And I think this is the stumbling block between what Ethan’s telling us about between the individual productivity and the larger productivity, is the &lt;em&gt;team’s&lt;/em&gt; productivity.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And there is actually a good analogy in computer science and that’s, uh, Brooks’s “mythical man-month,” …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes, exactly.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; … where he shows how you can have more and more resources, but when the coordination starts failing, because you have so many, uh, individuals on the team, you start falling apart. And so even if the, uh, individual doctors get that much better, yeah, they take better care of patients, make less stupid things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But in terms of giving the “I get you into the emergency room, and I get you out of a hospital as fast as possible, as safely as possible, as effectively as possible,” that’s teamwork. And we don’t do it. And we’re not really optimizing our tools for that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And just to throw in a little reality check, I’m not aware of &lt;em&gt;any&lt;/em&gt; indication yet that AI is in any way shortening medical journeys or making physicians more efficient. Yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG:&lt;/strong&gt; …&lt;strong&gt; &lt;/strong&gt;at least. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. So I think, you know, with respect to our book, critiquing our book, you know, I think it’s fair to say we were fairly focused or maybe even fixated on the individual doctor or nurse or patient, and we didn’t really, at least I never had a time where I stepped back to think about the whole care coordination team or the whole health system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And I think that’s right. It’s because, first of all, &lt;em&gt;you&lt;/em&gt; weren’t thinking about it? It’s not what we’re taught in medical school. We’re not taught to talk about team communication excellence. And I think it’s absolutely essential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a … what’s the … there was an early … [Terry] Winograd. And he was trying to capture what are the different kinds of actions related to pronouncements that you could expect and how could AI use that. And that was beginning to get at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I actually think this is dark matter of human organizational technology that is not well understood. And our products don’t do well. You know, we can talk about all the groupware things that are out there. But they all don’t quite get to that thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And I can imagine an AI serving as a team leader, a really active team leader, a real quarterback of, let’s say, a care team.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, in fact, you know, we have been trying to experiment with this. My colleague, Matt Lungren, who was also one of the interviewees early on, has been working with Stanford Medicine on a tumor board AI agent—something that would facilitate tumor board meetings.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And the early experiences are pretty interesting. Whether it relates to efficiency or productivity I think remains to be seen, but it does seem pretty interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But let’s move on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Well, actually, Peter, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Oh, go ahead.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;…&lt;strong&gt; &lt;/strong&gt;if you’re willing to not quite move on yet …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; [LAUGHS] All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… this kind of segues into one of, I think, the most provocative questions that arose in the course of these episodes and that I’d love to have you answer, which was, remember, it was a question at a gathering that you were at, and you were asked, “Well, you’re focusing a lot on potential AI effects on individual patient and physician experiences. But what about the revolution, right? What about, like, can you be more big-picture and envision how generative AI could actually, kind of, overturn or fix the broken system, right?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m sure you’ve thought about that a lot. Like, what’s your answer?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I think ultimately, it will have to. For it to really make a difference, I think that the normal processes, our normal concept of how healthcare is delivered—how new medical discoveries are made and brought into practice—I think those things are going to have to change a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, one of the things I think about a lot right at the moment is, you know, we tend to think about, let’s say, medical diagnosis as a problem-solving exercise. And I think, at least at the Kaiser Permanente School of Medicine, the instruction really treats it as a kind of detective thing based on a lot of knowledge about biology and biomedicine and human condition, and so on.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But there’s another way to think about it, given AI, which is when you see a patient and you develop some data, maybe through a physical exam, labs, and so on, you can just simply ask, “You know, what did the 500 other people who are most similar to this experience, how were they diagnosed? How were they treated? What were their outcomes? What were their experiences?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s really a fundamentally different paradigm. And it just seems like at least the technical means will be there. And by the way, that also then relates to [the questions]: “And what was most efficacious cost-wise? What was most efficient in terms of the total length of the patient journey? How does this relate to my quality scores so I can get more money from Medicare and Medicaid?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All of those things, I think, you know, we’re starting to confront.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the other episodes that we’re going to talk about, was my interview with two medical students. Actually, thinking of a Morgan Cheatham as just a medical student or medical resident [LAUGHTER] is a little strange. But he is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One of the things he talks about is the importance that he placed in his medical training about adopting AI. So, Zak, I assume you see this also with some students at Harvard Medical School. And the other medical student we interviewed, Daniel Chen, seemed to indicate this, too, where it seems like it’s the students who are bringing AI into the medical education ahead of the faculty. Does that resonate with you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely resonates with me. There are students I run into who, honestly, my first thought when I’m talking to them is, why am I teaching you [LAUGHTER], and why are you not starting a big AI company, AI medicine company, now and really change healthcare instead of going through the rest of the rigmarole? And I think broadly, higher education has a problem there, which is we have not embraced, again, going back to Ethan, a lot of the tools that can be used. And it’s because we don’t know necessarily the right way to teach them. And so far, the only lasting heuristic seems to be: use them and use them often.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so it’s an awkward thing, where the person who knows how to use the AI tools now in the first-year medical school can teach themselves better and faster than anybody else in their class who is just relying on the medical school curriculum.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, the reason I brought up Morgan now after our discussion with Ethan Mollick is Morgan also talked about AI collapsing medical specialties.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so let’s hear this snippet from him.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-df1ec79bf2184e924d149dd5a8bfd566"&gt;&lt;strong&gt;&lt;em&gt;MORGAN CHEATHAM:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; AI collapses medical specialties onto themselves, right. You have the canonical example of the cardiologist, you know, arguing that we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient’s clinical status? … So I’m interested in this question of whether medical specialties themselves need to evolve. And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So on the specific question about specialties, Zak, do you have a point of view? And let me admit, first of all, for us, all three of us, we didn’t have any clue about this in our book. I don’t think.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Not much. Not much of a clue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’m reminded of a &lt;em&gt;New Yorker&lt;/em&gt; cartoon where you see a bunch of surgeons around the patient, and someone says, “Is that a spleen?” And it says, “I don’t know. I slept during the spleen lecture,” [LAUGHTER] and … or “I didn’t take the spleen course.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And yet when we measure things, we measure things much more than we think we are doing. So for example, we [&lt;em&gt;NEJM AI&lt;/em&gt;] just published a paper where echocardiograms were being done. And it turns out those ultrasound waves just happen to also permeate the liver. And you can actually diagnose on the way with AI all the liver disease&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that is in—and treatable liver disease—that’s in those patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But if you’re a cardiologist, “Liver? You know, I slept through liver lecture.” [LAUGHTER] And so I do think that, (A) the natural, often guild/dollar-driven silos in medicine are less obvious to AI, despite the fact that they do exist in departments and often in chapters.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But Morgan’s absolutely right. I can tell you as an endocrinologist, if I have a child in the ICU, the endocrinologist, the nephrologist, and the neurosurgeon will argue about the right thing to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so in my mind, the truly revolutionary thing to do is to go back to 1994 with Pete Szolovits, the Guardian Angel Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. What I think you need is a process. And the process is the quarterback. And the quarterback has only one job: take care of the patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it should be thinking all the time about the patient. What’s the right thing? And can be as school-marmish or not about, “Zak, you’re eating this or that or exercise or sleep,” but also, “Hey, surgeons and endocrinologists, you’re talking about my host, Zak. This is the right way because this problem and this problem and our best evidence is this is the right way to get rid of the fluid. The other ways will kill him.”&lt;/p&gt;



&lt;p&gt;And I think you need an authoritative quarterback that has the view of the others but then makes the calls.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Is that quarterback going to be AI or human?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Well, for the very lucky people, it’ll be a human augmented by AI, &lt;em&gt;super concierge&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think we’re running out of doctors. And so realistically, it’s going to be an AI that will have to be certified in very different ways, along the ways Dave Blumenthal says, essentially, trial by fire. Like putting residents into clinics, we’re going to be putting AIs into clinics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what’s worse, by the way, than the three doctors arguing about care in front of the patient is, what happens so frequently, is then you see them outpatient, and each one of them gives you a different set of decisions to make. Sometimes that actually interact pathologically, unhealthily with each other. And only the very smart nurses or primary care physicians will actually notice that and call, quote, a “family meeting,” or bring everybody in the same room to align them.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, I think this idea of quarterback is really very, very topical right now because there’s so much intensity in the AI space around agents. And in fact, you know, the Microsoft AI team under Mustafa Suleyman and Dominic King, Harsha Nori, and team just recently posted a paper on something called sequential diagnosis, which is basically an AI quarterback that is supposed to smartly consult with other AI specialties. And interestingly, one of the AI agents is sort of the devil’s advocate that’s always criticizing and questioning things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;That’s interesting.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And at least on very, very hard, rare cases, it can develop some impressive results. There’s something to this that I think is emerging.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And, Peter, Morgan said something that blew me away even more, which was, well, why do we even need specialists if the reason for a specialist is because there’s so much medical knowledge that no single physician can know all of it, and therefore we create specialists, but that limitation does not exist for AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;And so there he was kind of undermining this whole elaborate structure that has grown up because of human limitations that may not ultimately need to be there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right. So now that gives me a good segue to get back to our economist and get to something that Azeem Azhar said. And so there’s a clip here from Azeem.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ff46028707e465b3cd8582210840bd0"&gt;&lt;strong&gt;&lt;em&gt;AZEEM AZHAR: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;We didn’t talk about, you know, AI in its ability to potentially do this, which is to extend the clinician’s presence throughout the week. &lt;em&gt;You know, t&lt;/em&gt;he idea that maybe some part of what the clinician would do if you could talk to them on Wednesday, Thursday, and Friday could be delivered through an app or a chatbot just as a way of encouraging the compliance, which is often, especially with older patients, one reason why conditions, you know, linger on for longer.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And, you know, in the same conversation, he also talked about his own management of asthma and the fact that he’s been managing this for several decades and knows more than any other human being, no matter how well medically trained, could possibly know. And it’s also very highly personalized. And it’s not a big leap to imagine AI having that sort of lifelong understanding.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So in fact, I want to give credit back to our book since you insulted us. [LAUGHTER] You challenged us. You doubted us. We do have at the end of the book a AI which is helping this woman manage her way through life. It’s quarterbacking for the woman all these different services.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So there.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Ah, you’re right. Yes. In fact, it’s very much, I think, along the lines of the vision that Azeem laid out in our conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. It also reminded me of the piece Zak wrote about his mother&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; at one point when she was managing congestive heart failure and she needed to watch her weight very carefully to see her fluid status. And absolutely, there’s no … I see no reason whatsoever why that couldn’t be done with AI right now. Actually, although back then, Zak, you were writing that it takes much more than an AI [LAUGHS] to manage such a thing, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; You need an AI that you can trust. Now, my mother was born in 1927, and she’d learned through the school of hard knocks that you can’t trust too many people, maybe even not your son, &lt;em&gt;MD&lt;/em&gt;, &lt;em&gt;PhD&lt;/em&gt; [LAUGHTER].&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what I’ve been surprised [by] is how, for example, how many people are willing to trust and actually see effective use of AI as mental health counselors, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So it may in fact be that there’s a generational thing going on, and at least there’ll be some very large subset of patients which will be completely comfortable in ways that my mother would have never tolerated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Now, I think we’re starting to veer into some of the core AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think maybe one of the most fun conversations I had was in the episode with both Sébastien Bubeck, my former colleague at Microsoft Research, and now he’s at OpenAI, and Bill Gates. And there was so much that was, I thought, interesting there. And there was one point, I think that sort of touches tangentially on what we were just conversing about, that Sébastien said. So let’s hear this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-19a223099867a12ed2599ae811939b43"&gt;&lt;strong&gt;&lt;em&gt;SÉBASTIEN BUBECK: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And one example that I really like, a study that recently appeared where … they were comparing doctors without and with ChatGPT. … So this was a set of cases where the accuracy of the doctors alone was around 75%. ChatGPT alone was 90%. … But then the kicker is that doctors with ChatGPT was 80%. Intelligence alone is not enough. It’s also how it’s presented, how you interact with it. And ChatGPT, it’s an amazing tool. Obviously, I absolutely love it. But it’s not … you don’t want a doctor to have to type in, you know, prompts and use it that way. It should be, as Bill was saying, kind of running continuously in the background, sending you notifications.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought Sébastien was saying something really profound, but I haven’t been able to quite decide or settle in my mind what it is. What do you make of what Seb just said?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s context. I think that it requires an enormous amount of energy, brain energy, to actually correctly provide the context that you want this thing to work on. And it’s only going to really feel like we’re in a different playing field when it’s listening all the time, and it just steps right in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There is an advantage that, for example, a good programmer can have in prompting Cursor or any of these tools to do so. But it takes effort. And I think being in the conversation all the time so that you understand the context in the widest possible way is incredibly important. And I think that’s what Seb is getting at, which is if we spoon feed these machines, yes, 90%.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then, talking to a human being who then has to interact and gets distracted from whatever flow they’re in and maybe even makes them feel like an early bicycle rider who all of a sudden realizes, “I’m balancing on two wheels—oh no!” And they fall over. You know, there’s that interaction which is negatively synergistic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I do think it’s a very hard human-computer engineering problem. How do we make these two agents, human and computational, work in an ongoing way in the flow? I don’t think I’m seeing anything that’s particularly new. And the things that you’re beginning to hint about, Peter, in terms of agentic coordination, I think we’ll get to some of that. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Carey, does this give you any pause? The kind of results that … they’re puzzling results. I mean, the idea of doctors with AI seeming at least in this one test—it’s just one test—but it’s odd that it does worse than the AI alone.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. I would want to understand more about the actual conditions of that study.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;From what Bill Gates said, I was most struck by the question of resource-poor environments. That even though this was absolutely one of the most promising, brightest perspectives that we highlighted in the book, we still don’t seem to be seeing a lot of use among the one half of humanity that lacks decent access to healthcare.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I mean, there are access problems everywhere, including here in the United States. And it is one of the most potentially promising uses of AI. And I thought if anyone would know about it, he would with the work that the Gates Foundation does.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think both you and Bill, I felt, are really simpatico. You know, Bill expressed genuine surprise that more isn’t happening yet. And it really echoed, in fact, maybe even using some of the exact same words that you’ve used. And so two years on, you’ve expressed repeatedly expecting to have seen more out in the field by now. And then I thought Bill was saying something in our conversation very similar.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, for me, I see it both ways. I see the world of medicine really moving fast in confronting the reality of AI in such a serious way. But at the same time, it’s also hard to escape the feeling that somehow, we should be seeing even more.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s an odd thing, a little bit paradoxical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I think one thing that we didn’t focus on hardly at all in the book but that we are seeing is these companies rising up, stepping up to the challenge, Abridge and OpenEvidence, and what Morgan describes as a new stack, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So there is that on the flip side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Now, I want to get back to this thing that Seb was saying. And, you know, I had to bring up the issue of sycophancy, which we discussed at our last roundtable also. But it was particularly … at the time that Seb, Bill, and I had our conversation, OpenAI had just gone through having to retract a fresh update of GPT-4o because it had become too sycophantic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I can’t escape the feeling that some of these human-computer interaction issues are related to this tension between you want AI to follow your directions and be faithful to you, but at the same time not agree with you so often that it becomes a fault.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I think it’s asking the AI to enter into a fundamental human conundrum, which is there are extreme versions of doublethink, and there’s everyday things, everyday asks of doublethink, which is how to be an effective citizen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And even if you’re thinking, “Hmm. I’m thinking this. I’m just not going to say it because that would be rude or counterproductive.” Or some of the official doublethinks, where you’re actually told you must say this, even if you think something else. And I think we’re giving a very tough mission for these things: be nice to the user and be useful.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, in education, where the thing is not always one in the same. Sometimes you have to give a little tough love to educate someone, and doing that well is both an art and it’s also very difficult. And so, you know, I’m willing to believe that the latest frontier models that have made the news in the last month are very high-performing, but they’re also all highlighting that tension …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that tension between behaving like a good citizen and being helpful. And this gets back to what are the fundamental values that we hope these things are following.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s not, you know, “Are these things going to develop us into the paperclip factory?” It’s more of, “Which of our values are going to be elevated, and which one will be suppressed?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, since I criticized our book before, let me pat ourselves on the back this time because, I think, pervasive throughout our book, we were touching on some of these issues.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In fact, we started the book, you know, with GPT-4 scolding me for wanting it to impersonate Zak. And there was the whole example of asking it to rewrite a poem in a certain way, and it kind of silently just tried to slide, you know, without me knowing, slide by without following through on the whole thing.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so that early version of GPT-4 was definitely not sycophantic at all. In fact, it was just as prone to call you an idiot if it thought you were wrong. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I had some very testy conversations around my endocrine diagnosis with it. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. Well then, Peter, I would ask you, I mean last time I asked you about, &lt;em&gt;well, hallucinations, aren’t those solvable?&lt;/em&gt; And this time I would ask you, well, sycophancy, isn’t that kind of like a dial you can turn? Like, is that not solvable?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;You know, I think there are several interlocking problems. But if we assume superintelligence, even with superintelligence, medicine is such an inexact science that there will always be situations that are guesses that take into account other factors of a person’s life, other value judgments, exactly as Zak had pointed out in our previous roundtable conversation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think there’s always going to be an opening for either differences of opinion or agreeing with you too much. And there are dangers in both cases. And I think they’ll always be present. I don’t know that, at least in something as inexact as medical science, I don’t know that it’ll ever be completely eliminated.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And it’s interesting because I was trying to think what’s the right balance, but there are patients who want to be told this is what you do. Whereas there’s other patients who want to go through every detail of the reasoning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s not a matter of education. It’s really a temperamental, personality issue. And so we’re going to &lt;em&gt;have to&lt;/em&gt;, I think, develop personalities …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… that are most effective for those different kinds of individuals. And so I think that is going to be the real frontier. Having human values and behaving in ways that are recognizable and yet effective for certain groups of patients.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And lots of deep questions, including how paternalistic do we want to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;All right, so we’re getting into medical science and hallucination. So that gives me a great segue to the conversations in the episode on biomedical research. And one of the people that I interviewed was Noubar Afeyan from Moderna and Flagship Pioneering. So let’s listen to this snippet.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-574184a033e6f29ff2ba40f7e611b28a"&gt;&lt;strong&gt;&lt;em&gt;NOUBAR AFEYAN:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; We, some hundred or so times a year, ask “what if” questions that lead us to totally weird places of thought. We then try to iterate, iterate, iterate to come up with something that’s testable. Then we go into a lab, and we test it. So in that world, right, sitting there going, like, “How do I know this transformer is going to work?” The answer is, “For what?” Like, it’s going to work to make something up … well, guess what? We knew early on with LLMs that hallucination was a feature, not a bug for what we wanted to do.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] So I think that really touches on just the fact that there’s so many unknowns and such lack of precision and exactness in our understanding of human biology and of medicine. Carey, what do you think?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, I just have this emotional reaction, which is that I love the idea of AI marching into biomedical science and everything from getting to the virtual cell eventually to, Zak, I think it was a colleague of yours who recently published about … it was a new medication that had been sort of discovered by AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and it was actually testing out up to the phase II level or something, right?&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Oh, this is Marinka’s work.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah, Marinka, Marinka Zitnik. And … yeah. So, I mean, I think it avoids a lot of the, sort of, dilemmas that are involved with safety and so on with AI coming into medicine. And it’s just the discovery process, which we all want to advance as quickly as possible. And it seems like it actually has a great deal of potential that’s already starting to be realized.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Oh, absolutely.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I love this topic. First of all, I thought, actually, I think Bill and Seb, actually, had interesting things to say on that very topic, rationales which I had not really considered why, in fact, things might progress faster in the discovery space than in the clinical delivery space, just because we don’t know in clinical medicine what we’re trying to maximize precisely. Whereas for a drug effect, we do know what we’re trying to maximize.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Well, in fact, I happened to save that snippet from Bill Gates saying that. So let’s cue that up.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-6ca7a5edfbf41028162616b68d8380d1"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think it’s very much within the realm of possibility that the AI is not only accelerating healthcare discovery but substituting for a lot of the roles of, you know, “I’m an organic chemist,” or “I run various types of assays.” I can see those, which are, you know, testable-output-type jobs but with still very high value, I can see, you know, some replacement in those areas before the doctor.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So, Zak, isn’t that Bill saying exactly what you’re saying?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; That is my point. I have to say that this is another great bet, that either we’re all going to be surprised or a large group of people will be surprised or disappointed.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s still a lot of people in the sort of medicinal chemist, trialist space who are still extremely skeptical that this is going to work. And we haven’t quite shown them yet that it is. Why have we not shown them? Because we haven’t gone all the way to a phase III study, which showed that the drug behaves as expected to, is effective, and basically doesn’t hurt people. That turns out to require a lot of knowledge. I actually think we’re getting there, but I understand the skepticism.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Carey, what are your thoughts?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I mean, there will be no way around going through full-on clinical trials for anything to ever reach the market. But at the same time, you know, it’s clearly very promising. And just to throw out something for the pure fun of it, Peter, I saw … one of my favorite tweets recently was somebody saying, you know, isn’t it funny how computer science is actually becoming a lot more like biology in that it’s just becoming empirical.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s like you just throw stuff at the AI and see what it does. [LAUGHTER] And I was like,&lt;em&gt; oh, yeah, that’s what Peter was doing when we wrote the book.&lt;/em&gt; I mean, he understood as many innards as anybody can. But at the same time, it was a totally empirical exercise in seeing what this thing would do when you threw things at it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;So it’s the new biology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, yeah. So I think we talked in our book about accelerating, you know, biomedical knowledge and medical science. And that actually seems to be happening. And I really had fun talking to Daphne Koller about some of the accomplishments that she’s made. And so here’s a little snippet from Daphne.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b519fe67233d03b2946f95df076d6451"&gt;&lt;strong&gt;&lt;em&gt;DAPHNE KOLLER: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;This will impact not only the early stages of which hypotheses we interrogate, which molecules we move forward, but also hopefully at the end of the day, which molecule we prescribe to which patient. And I think there’s been obviously so much narrative over the years about precision medicine, personalized medicine, and very little of that has come to fruition, with the exception of, you know, certain islands in oncology, primarily on genetically driven cancers.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, when I was listening to that, I was reminded of one of the very first examples that you had where, you know, you had a very rare case of a patient, and you’re having to narrow down some pretty complex and very rare genetic conditions. This thing that Daphne says, that seems to be the logical conclusion that everyone who’s thinking hard about AI and biology is coming to. Does it seem more real now two years on?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It absolutely seems more real. Here’s some sad facts. If you are at a cancer center, you will get targeted therapies if you qualify for it. Outside cancer centers, you won’t. And it’s not that the therapies aren’t available. It’s just that you won’t have people thinking about it in that way. And especially if you have some of the rare and more aggressive cancers, if you’re outside one of those cancer centers, you’re at a significant disadvantage for survival for that reason. And so anything that provides just the “simple,” in quotes, dogged investigation of the targeted therapies for patients, it’s a home run.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So my late graduate student, Atul Butte, died recently at UCSF, where he was both a professor and the leader of the Bakar Institute, and he was a Zuckerberg Chan Professor of Pediatrics.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;He was diagnosed with a rare tumor two years ago. His wife is a PhD biologist, and when he was first diagnosed, she sent me the diagnosis and the mutations. And I don’t know if you know this, Peter, but this was still when we were writing the book and people didn’t know about GPT-4.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I put in those mutations into GPT-4 and the diagnosis. And I said, “I’d like to help treat my friend. What’s the right treatment?” And GPT, to paraphrase, GPT-4 said, “Before we start talking about treatment, are you sure this is the right diagnosis? Those mutations are not characteristic for that tumor.” And he had been misdiagnosed. And then they changed the diagnosis therapy and some personnel.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I don’t have to hallucinate this. It’s already happened, and we’re going to need this. And so I think targeted therapy for cancers is the most obvious use. And if God forbid one of you has a family member who has cancer, it’s moral malpractice not to look at the genetics and run it past GPT-4 and say, “What are the available therapies?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I really deeply believe that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Carey, I think one thing you’ve always said is that you’re surprised that we don’t hear more stories along these lines. And I think you threw a quote from Mustafa Suleyman back at me. Do you want to share that?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yes. Recently, I believe it was a Big Technology interview&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and the reporter asked Mustafa Suleyman, “So you guys are seeing 50 million queries, medical queries, a day [to Copilot and Bing]. You know, how’s that going?” And I think I am a bit surprised that we’re not seeing more stories of &lt;em&gt;all&lt;/em&gt; types. Both here’s how it helped me and also here was maybe, you know, a suggestion that was not optimal.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. I do think in our book, we did predict both positive and negative outcomes of this. And it is odd. Atul was very open with his story. And of course, he is such … he was such a prominent leader in the world of medicine.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think I share your surprise, Carey. I expected by now that a lot more public stories would be out. Maybe there is someone writing a book collecting these things, I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Maybe someone called Carey Goldberg should write that book. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Write a book, maybe. I mean, we have Patients Use AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which is a wonderful blog by Dave deBronkart, the patient advocate.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I wonder if it’s also something structural, like who would be or what would be the institution that would be gathering these stories? I don’t know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And that’s the problem. You see, this goes back to the same problem that [Ethan] Mollick was talking about. Individual doctors are using them. The hospital as a whole is not doing that. So it’s not judging the quality, as part of its quality metrics, of how good the AI is performing and what new has happened. And the other audience, namely the patients, have no mechanism. There is no mechanism to go to Better Business Bureau and say, “They screwed up,” or “This was great.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So now I want to get a little more futuristic. And this gets into whether AI is really going to get almost to the &lt;em&gt;ab initio&lt;/em&gt; understanding of human biology. And so Eric Topol, who is one of the guests, spoke to this a bit. So let’s hear this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-a8cd8394bbdf383bb04d1e5902cb8b97"&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;So you talk about a virtual cell. Is that achievable within 10 years, or is that still too far out?&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;ERIC TOPOL:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; No, I think within 10 years for sure. You know, the group that got assembled, that Steve Quake pulled together, I think has 42 authors in a paper in Cell. The fact that he could get these 42 experts in life science and some in computer science to come together and all agree that not only is this a worthy goal, but it’s actually going to be realized, that was impressive.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, I have to say Eric’s optimism took me aback. Just speaking as a techie, I think I started off being optimistic: as soon as we can figure out molecular dynamics, biology can be solved. And then you start to learn more about biochemistry, about the human cell, and then you realize, oh, my God, this is just so vast and unknowable. And now you have Eric Topol saying, “Well, in less than 10 years.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;So what’s delightful about this period is that those of us who are cautious were so incredibly wrong about AI two years ago. [LAUGHTER] That’s a true joy … I mean, absolute joy. It’s great to have your futurism made much more positive.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think that we’re going from, you know, for example, AlphaFold has had tremendous impact. But remember, that was built on years of acquisition of crystallography data that was annotated. And of course, the annotation process becomes less relevant as you go down the pipe, but it started from that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And there’s lots of parts of the cell. So when people talk about virtual cells—I don’t mean to get too technical—mostly they’re talking about perturbation of gene expression. They’re not talking about, “Oh, this is how the liposome and the centrosome interact, and notice how the Golgi bodies bump into each other.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s a whole bunch of other levels of abstraction we know nothing about. This is a complex factory. And right now, we’re sort of the level from code into loading code into memory. We’re not talking about how the rest of the robots work in that cell, and how the rest of those robots work in the cell turns out to be pretty important to functioning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’d love to be wrong again. And in 10 years, oh yeah, not only, you know, our first in-human study will be you, Dr. Zak. We’re going put the drug because we fully simulated you. That’d be great.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And, by the way, just to give people their due, there probably was a lot of animal research that could be done &lt;em&gt;in silico &lt;/em&gt;and that for various political reasons we’re now seeing happen. That’s a good thing. But I think that sometimes it takes a lot of hubris to get us where we need to get, but my horizon is not the same as his.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So I guess I have to take this time to brag. Just recently out of our AI for Science team did publish in &lt;em&gt;Science&lt;/em&gt; a biological emulator that does pretty long timespan, very, very precise, and very efficient molecular dynamics, biomolecular dynamics emulation. We call it &lt;em&gt;emulation&lt;/em&gt; because it’s not simulating every single time step but giving you the final confirmations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;That’s an amazing result.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; But … that is an amazing result. And you’re doing it in some very important interactions. But there’s so much more to do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I know, and it’s single molecules; it’s not even two molecules. There’s so much more to go for here. But on the other hand, Eric is right, you know, 42 experts writing for &lt;em&gt;Cell&lt;/em&gt;, you know, that’s not a small matter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; So I think sometimes you really need to drink your own hallucinogens to actually succeed. Because remember, when the Human Genome Project&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; was launched, we didn’t know how to sequence at scale.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We said maybe we would get there. And then in order to get the right funding and excitement and, I think, focus, we predicted that by early 2000s we’d be transforming medicine. Has not happened yet. Things have happened, but at a much slower pace. And we’re 25 years out. In fact, we’re 35 years out from the launch.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But again, things are getting faster and faster. Maybe the singularity is going to make a whole bunch of things easier. And GPT-6 will just say, “Zak, you are such a pessimist. Let me show you how it’s done.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It really is a pessimism versus optimism. Like is it, I mean, biology is such a bitch, right. [LAUGHTER] Can we actually get there?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At the same time, everyone was surprised and blown away by the, you know, the quantum leap of GPT-4. Who knows when enough data gets in there if we might not have a similar leap.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. All right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s get back to healthcare delivery. Besides Morgan Cheatham, we talked to [a] more junior medical student who’s at the Kaiser Permanente School of Medicine, Daniel Chen. And, you know, I asked him about this question of patients who come in armed [LAUGHS] with a lot of their own information. Let’s hear what he said about this.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-b854f48f19d32b116ea80de7d13c8a99"&gt;&lt;strong&gt;&lt;em&gt;DANIEL CHEN: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;But for those that come in with a list, I sometimes sit down with them, and we’ll have a discussion, honestly. … “I don’t think you have meningitis because, you know, you’re not having a fever. Some of the physical exam maneuvers we did were also negative. So I don’t think you have anything to worry about that,” you know. So I think it’s having that very candid conversation with the patient that helps build that initial trust.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, Zak, as far as I can tell, Daniel and Morgan are figuring this out on their own as medical students. I don’t think this is part of the curriculum. Does it need to be?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s missing the bigger point. The incentives and economic forces are such that even if you were Daniel, and things have not changed in terms of incentives, and it’s 2030, he still has to see this many patients in an hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And sitting down, going over that with a patient, let’s say some might need more … in fact, I think computer scientists are enriched for these sort of neurotic “explain [to] me why this works,” when often the answer is, “I have no idea; empirically it does.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And patients in some sense deserve that conversation, and we’re taught about joint decision making, but in practice, there’s a lot of skills that are deployed to actually deflect so that you can get through the appointment and see enough patients per hour.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And that’s why I think that one of the central … another task for AI is how to engage with patients to actually explain to them why their doctor is doing what he’s doing and perhaps ask the one or two questions that you should be asking the doctor in order to reassure you that they’re doing the right thing.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;I&lt;strong&gt; &lt;/strong&gt;just …&lt;strong&gt; &lt;/strong&gt;right now, we are going to have less doctor time, not more doctor time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’ve always been struck by the divide between medicine that we’re taught as it should be practiced as a gentle person’s vocation or sport as opposed to assembly line, heads down “you’ve got to see those patients by the end of the day” because, otherwise, you haven’t seen all the patients at the end of the day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. Carey, I’ve been dying to ask you this, and I have not asked you this before. When you go see a doctor, are you coming in armed with ChatGPT information?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I haven’t needed to yet, but I certainly would. And also my reaction to the medical student description was, I think we need to distinguish between the last 20 years, when patients would come in armed with Google, and what they’re coming in with now because at least the experiences that I’ve witnessed, it is miles better to have gone back and forth with GPT-4 than with, you know, dredging what you can from Google. And so I think we should make that distinction.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And also, the other thing that most interested me was this question for medical students of whether they should not use AI for a while so that they can learn …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;… how to think and similarly maybe don’t use the automated scribes for a while so they can learn how to do a note. And at what point should they then start being able to use AI? And I suspect it’s fairly early on that, in fact, they’re going be using it so consistently that there’s not that much they need to learn before they start using the tools.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; These two students were incredibly impressive. And so I have wondered, you know, if we got a skewed view of things. I mean, Morgan is, of course, a very, very impressive person. And Daniel was handpicked by the dean of the medical school to be a subject of this interview.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;You know, we filter our students, by and large, I mean, there’s exceptions, but students in medical school are so starry eyed. And they are really … they got into medical school—I mean, some of them may have faked it—but a lot of them because they really wanted to do good.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;And they really wanted to help. And so this is very constant with them. And it’s only when they’re in the machine, past medical school, that they realize, oh my God, this is a very, very different story.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I can tell you, because I teach a course in computational-enabled medicine, so I get a lot of these nerd medical students, and I’m telling them, “You’re going to experience this. And you’re going to say, ‘I’m not going to able to change medicine until I get enough cred 10, 15 years from now, whereas I could start my own company and immediately change medicine.’”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And increasingly I’m getting calls in like residency and saying, “Zak, help me. How do I get out of this?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And so I think there’s a real disillusionment of, like, between what we’re asking for people coming to medical school—we’re looking for a phenotype—and then we’re disappointing them massively, not everywhere, but massively.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for me, it’s very sad because among our best and brightest, and then because of economics and expectations and the nature of the beast, they’re not getting to enjoy the most precious part of being a doctor, which is that real human connection, and longitudinality, you know, the connection between the same doctor visit after visit, is more and more of a luxury.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, maybe this gets us to the last episode, you know, where I talk to a former, you know, state director of public health, Umair Shah, and with Gianrico Farrugia, who’s the CEO of Mayo Clinic. And I think if there’s one theme that I took away from those conversations is that we’re not thinking broadly enough nor big enough.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so here’s a little quote of exchange that Umair Shah, who was the former head of public health in the State of Washington and prior to that in Harris County, Texas, and we had a conversation about what techies tend to focus on when they’re thinking about AI and medicine.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-0a05c3ff13da1926875eed47432d27b2"&gt;&lt;strong&gt;&lt;em&gt;UMAIR SHAH: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;I think one of the real challenges is that when even tech companies, and you can name all of them, when they look at what they’re doing in the AI space, they gravitate towards healthcare delivery.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;LEE: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;Yes.&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And in fact, it’s not even delivery. I think techies—I did this, too—tend to gravitate specifically to diagnosis.&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I have been definitely guilty. I think Umair, of course, was speaking as a former frustrated public health official in just thinking about all the other things that are important to maintain a healthy population.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Is there some lesson that we should take away? I think our book also focused a lot on things like diagnosis.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Yeah. Well, first of all, I think we just have to have humility. And I think it’s a really important ingredient. I found myself staring at the increase in lifespan in human beings over the last two centuries and looking for bumps that were attributable.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’m in medical school. I’ve already made this major commitment. What are the bumps that are attributable to medicine? And there was one bump that was due to vaccines, a small bump. Another small bump that was due to antibiotics. And the rest of it is nutrition, sanitation, yeah, nutrition and sanitation.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I think doctors can be incredibly valuable, but not all the time. And we’re spending now one-sixth of our GDP on it. The majority of it is not effectively prolonging life. And so the humility has to be the right medicine at the right time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But that runs, (A) against a bunch of business models. It runs against the primacy of doctors in healthcare. It was one thing when there were no textbooks; there was no PubMed. You know, the doctor was the repository of all the probably knowledge that we have. But I think your guests were right. We have to think more broadly in the public health way. How do we make knowledge pervasive like sanitation?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Although I would add that since what we’re talking about is AI, it’s harder to see if … and if what you’re talking about is public health, I mean, it was certainly very important to have good data during the pandemic, for example.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But most of the ways to improve public health, like getting people to stop smoking and eat better and sleep better and exercise more, are not things that AI can help with that much. Whereas diagnosis or trying to improve treatment are places that it could tackle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in fact, Peter, I wanted to put you—oh, wait, Zak’s going to say something—but, Peter, I wanted to put you on the spot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;I mean, if you had a medical issue now, and you went to a physician, would you be OK with them not using generative AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I think if it’s a complex or a mysterious case, I would want them to use generative AI. I would want that second opinion on things. And I would personally be using it. If for no other reason than just to understand what the chart is saying.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I don’t see, you know, how or why one wouldn’t do that now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; It’s such a cheap second opinion, and people are making mistakes. And even if there are mistakes on the part of AI, if there’s a collision, discrepancy, that’s worth having a discussion. And again, this is something that we used to do more of when we had more time with the patients; we’d have clinic conferences.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; And we don’t have that now. So I do think that there is a role for AI. But I think again, it’s much more of a continual presence, being part of a continued conversation rather than an oracle.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think that’s when you’ll start seeing, when the AI is truly a colleague, and saying, “You know, Zak, that’s the second time you made that mistake. You know, that’s not obesity. That’s the effect of your drugs that you’re giving her. You better back off of it.” And that’s what we need to see happen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, and for the business of healthcare, that also relates directly to quality scores, which translates into money for healthcare providers.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So the last person that we interviewed was Gianrico Farrugia. And, you know, I was sort of wondering, I was expecting to get a story from a CEO saying, “Oh, my God, this has been so disruptive, incredibly important, meaningful, but wow, what a headache.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;At least Gianrico didn’t expose any of that. Here’s one of the snippets to give you a sense.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-e494c3919056a8b99abdfa66f7e6fae6"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; &lt;/em&gt;&lt;strong&gt;&lt;em&gt;FARRUGIA:&lt;/em&gt;&lt;/strong&gt;&lt;em&gt; When generative AI came, for us, it’s like, I wouldn’t say we told you so, but it’s like, ah, there you go. Here’s another tool. This is what we’ve been talking about. Now we can do it even better. Now we can move even faster. Now we can do more for our patients. It truly never was disruptive. It truly immediately became enabling, which is strange, right, because something as disruptive as that instantly became enabling at Mayo Clinic.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I tried pretty hard in that interview to get Gianrico to admit that there was a period of headache and disruption here. And he never, ever gave me that. And so I take him at his word.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Zak, maybe I should ask you, what about Harvard and the whole Harvard medical ecosystem?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would be surprised if there are system-wide measurable gains in health quality right now from AI. And I do have to say that Mayo is one of the most marvelous organizations in terms of team behavior. So if there’s someone who’s gotten the team part of it right, they’ve come the closest, which relates to our prior conversation. They have the quarterback idea …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE: &lt;/strong&gt;… pretty well down compared to others.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Nonetheless, I take him at his word, that it hasn’t disrupted them. But I’m also, I have yet to see the evidence that there’s been a quantum leap in quality or efficacy. And I do believe that it’s possible to have a quantum leap in efficacy in the right system.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if they haven’t been disrupted, I would venture that they’ve absorbed it, but they haven’t used it to its fullest potential. And the way I could be proven wrong is next year, also the metrics showing that over the last year, they’ve had, you know, decreased readmissions, decreased complications, decreased errors and all that. And if so, God bless them. And we should all be more like Mayo.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So I thought a little bit about two other quotes from the interviews that sort of maybe would send us off with some more inspirational kind of view of the future. And so there’s one from Bill Gates and one from Gianrico Farrugia. So what I’d like to do is to play both of those and then maybe we can have our last comments.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-34fa8f74d3c5dd1ddf63456b250b860b"&gt;&lt;strong&gt;&lt;em&gt;BILL GATES&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;: You know, I’ve gone so far as to tell politicians with national health systems that if they deploy AI appropriately, that the quality of care, the overload of the doctors, the improvement in the economics will be enough that their voters will be stunned because they just don’t expect this, and, you know, they could be reelected just on this one thing of fixing what is a very overloaded and economically challenged health system in these rich countries.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And now Gianrico.&amp;nbsp;&lt;/p&gt;



&lt;p class="has-white-color has-gray-background-color has-text-color has-background has-link-color wp-elements-daa9fe33118b2710490d542ab9959977"&gt;&lt;strong&gt;&lt;em&gt;GIANRICO FARRUGIA: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;And we seemed to be on a linear path, which is, let’s try and reduce administrative burden. Let’s try and truly be a companion to a physician or other provider. … And then in the next step, we keep going until we get to, now we can call it agentic AI, whatever we want to talk about. And my view was, no, is that let’s start with that aim, the last aim …&lt;/em&gt;&lt;strong&gt;&lt;em&gt; &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;because the others will come automatically if you’re working on that harder problem. Because one, to get to that harder problem, you’ll find all the other solutions.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All right. I think these are both kind of calls to be more assertive about this and more forward leaning. I think two years into the GPT-4 era, those are pretty significant and pretty optimistic calls to action. So maybe just to give you both one last word. What would be one hope that you would have for the world of healthcare and medicine two years from now?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; I would hope for businesses that whoever actually owns them at some holding company level, regardless of who owns them, are truly patient-focused companies, companies where the whole AI is about improving your care, and it’s only trying to maximize your care and it doesn’t care about resource limitations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And as I was listening to Bill, and the problem with what he was saying about saving dollars for governments is for many things, we have some very expensive things that work. And if the AI says, “This is the best thing,” it’s going to break your bank. And instead, because of research limitations, we play a human-based fancy footwork to get out of it.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s a hard game to play, and I leave it to the politicians and the public health officials who have to do those trades of utilities.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In my role as doctor and patient, I’d like to see very informed, authoritative agents acting only on our behalf so that when we go and we seek to have our maladies addressed, the only issue is, what’s the best and right thing for me now? And I think that is both technically realizable. And even in our weird system, there are business plans that will work that can achieve that. That’s my hope for two years from now.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, fantastic. Carey.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah. I second that so enthusiastically. And I think, you know, we have this very glass half full/glass half empty phenomenon two years after the book came out.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s certainly very nice to see, you know, new approaches to administrative complexity and to prior authorization and all kinds of ways to make physicians’ lives easier. But really what we all care about is our own health and that we would like to be able to optimize the use of this truly glorious technological achievement to be able to live longer and better lives. And I think what Zak just described is the most logical way to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I think for me, two years from now, I would like to see all of this digital data that’s been so painful, such a burden on every doctor and nurse to record, actually amount to something meaningful in the care of patients. And I think it’s possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Amen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; All right, so it’s been quite a journey. We were joking before we’re still on speaking terms after having written a book. [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then, um, I think listeners might enjoy knowing that we debated amongst ourselves what to do about a second edition, which seemed too painful to me, and so I suggested the podcast, which seemed too painful to the two of you [LAUGHTER]. And in the end, I don’t know what would have been easier, writing a book or doing this podcast series, but I do think that we learned a lot.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, last bit of business here.&lt;strong&gt; &lt;/strong&gt;To avoid having the three of us try to write a book again and do this podcast, I leaned on the production team in Microsoft Research and the Microsoft Research Podcast. And I thought it would be good to give an explicit acknowledgment to all the people who’ve contributed to this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s a long list of names. I’m going to read through them all. And then I suggest that we all give an applaud [LAUGHTER] to them. And so here we go.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s Neeltje Berger, Tetiana Bukhinska, David Celis Garcia, Matt Corwine, Jeremy Crawford, Kristina Dodge, Chris Duryee, Ben Ericson, Kate Forster, Katy Halliday, Alyssa Hughes, Jake Knapp, Weishung Liu, Matt McGinley, Jeremy Mashburn, Amanda Melfi, Wil Morrill, Joe Plummer, Brenda Potts, Lindsay Shanahan, Sarah Sobolewski, David Sullivan,&amp;nbsp;Stephen Sullivan, Amber Tingle, Caitlyn Treanor, Craig Tuschhoff, Sarah Wang, and Katie Zoller.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Really a great team effort, and they made it super easy for us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you. Thank you. Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;KOHANE:&lt;/strong&gt; Thank you. Thank you.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GOLDBERG: &lt;/strong&gt;Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;A big thank you again to all of our guests for the work they do and the time and expertise they shared with us.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, last but not least, to our listeners, thank you for joining us. We hope you enjoyed it and learned as much as we did. If you want to go back and catch up on any episodes you may have missed or to listen to any again, you can visit aka.ms/AIrevolutionPodcast&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;p&gt;Until next time.&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/coauthor-roundtable-reflecting-on-healthcare-economics-biomedical-research-and-medical-education/</guid><pubDate>Thu, 21 Aug 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] How AI ‘digital minds’ startup Delphi stopped drowning in user data and scaled up with Pinecone (AI News | VentureBeat)</title><link>https://venturebeat.com/data-infrastructure/how-ai-digital-minds-startup-delphi-stopped-drowning-in-user-data-and-scaled-up-with-pinecone/</link><description>&lt;p&gt;Delphi, a two-year-old San Francisco AI startup named after the Ancient Greek oracle, was facing a &lt;strong&gt;thoroughly 21st-century problem: its “Digital Minds”&lt;/strong&gt;— interactive, personalized chatbots modeled after an end-user and meant to channel their voice based on their writings, recordings, and other media — &lt;strong&gt;were drowning in data. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Each Delphi can draw from any number of books, social feeds, or course materials to respond in context, making each interaction feel like a direct conversation. Creators, coaches, artists and experts were already using them to share insights and engage audiences. &lt;/p&gt;&lt;p&gt;But each new upload of podcasts, PDFs or social posts to a Delphi added complexity to the company’s underlying systems. Keeping these AI alter egos responsive in real time without breaking the system was becoming harder by the week.&lt;/p&gt;&lt;p&gt;Thankfully, &lt;strong&gt;Dephi found a solution to its scaling woes using managed vector database darling Pinecone.&lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-open-source-only-goes-so-far"&gt;Open source only goes so far&lt;/h2&gt;



&lt;p&gt;Delphi’s early experiments relied on open-source vector stores. Those systems quickly buckled under the company’s needs. Indexes ballooned in size, slowing searches and complicating scale. &lt;/p&gt;



&lt;p&gt;Latency spikes during live events or sudden content uploads risked degrading the conversational flow. &lt;/p&gt;



&lt;p&gt;Worse, Delphi’s small but growing engineering team found itself spending weeks tuning indexes and managing sharding logic instead of building product features.&lt;/p&gt;



&lt;p&gt;Pinecone’s fully managed vector database, with SOC 2 compliance, encryption, and built-in namespace isolation, turned out to be a better path. &lt;/p&gt;



&lt;p&gt;Each Digital Mind now has its own namespace within Pinecone. This ensures privacy and compliance, and narrows the search surface area when retrieving knowledge from its repository of user-uploaded data, improving performance. &lt;/p&gt;



&lt;p&gt;A creator’s data can be deleted with a single API call&lt;strong&gt;. Retrievals consistently come back in under 100 milliseconds at the 95th percentile, &lt;/strong&gt;accounting for less than 30 percent of Delphi’s strict one-second end-to-end latency target.&lt;/p&gt;



&lt;p&gt;“With Pinecone, we don’t have to think about whether it will work,” said &lt;strong&gt;Samuel Spelsberg, co-founder and CTO of Delphi&lt;/strong&gt;, in a recent interview. “That frees our engineering team to focus on application performance and product features rather than semantic similarity infrastructure.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-architecture-behind-the-scale"&gt;The architecture behind the scale&lt;/h2&gt;



&lt;p&gt;At the heart of Delphi’s system is a retrieval-augmented generation (RAG) pipeline. Content is ingested, cleaned, and chunked; then embedded using models from OpenAI, Anthropic, or Delphi’s own stack. &lt;/p&gt;



&lt;p&gt;Those embeddings are stored in Pinecone under the correct namespace. At query time, Pinecone retrieves the most relevant vectors in milliseconds, which are then fed to a large language model to produce responses, a popular technique known through the AI industry as&lt;strong&gt; retrieval augmented generation (RAG).&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This design&lt;strong&gt; allows Delphi to maintain real-time conversations without overwhelming system budgets. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;As &lt;strong&gt;Jeffrey Zhu, VP of Product at Pinecone&lt;/strong&gt;, explained, a key innovation was moving away from traditional node-based vector databases to an object-storage-first approach. &lt;/p&gt;



&lt;p&gt;Instead of keeping all data in memory, Pinecone dynamically loads vectors when needed and offloads idle ones. &lt;/p&gt;



&lt;p&gt;“That really aligns with Delphi’s usage patterns,” Zhu said.&lt;strong&gt; “Digital Minds are invoked in bursts, not constantly. By decoupling storage and compute, we reduce costs while enabling horizontal scalability.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Pinecone also automatically tunes algorithms depending on namespace size. Smaller Delphis may only store a few thousand vectors; others contain millions, derived from creators with decades of archives. &lt;/p&gt;



&lt;p&gt;Pinecone adaptively applies the best indexing approach in each case. As Zhu put it, “We don’t want our customers to have to choose between algorithms or wonder about recall. We handle that under the hood.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-variance-among-creators"&gt;&lt;strong&gt;Variance among creators&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Not every Digital Mind looks the same. Some creators upload relatively small datasets — social media feeds, essays, or course materials — amounting to tens of thousands of words. &lt;/p&gt;



&lt;p&gt;Others go far deeper. Spelsberg described one expert who contributed hundreds of gigabytes of scanned PDFs, spanning decades of marketing knowledge.&lt;/p&gt;



&lt;p&gt;Despite this variance, Pinecone’s serverless architecture has allowed Delphi to scale beyond &lt;strong&gt;100 million stored vectors&lt;/strong&gt; across &lt;strong&gt;12,000+ namespaces&lt;/strong&gt; without hitting scaling cliffs. &lt;/p&gt;



&lt;p&gt;Retrieval remains consistent, even during spikes triggered by live events or content drops. Delphi now sustains about &lt;strong&gt;20 queries per second globally&lt;/strong&gt;, supporting concurrent conversations across time zones with zero scaling incidents.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-toward-a-million-digital-minds"&gt;Toward a million digital minds&lt;/h2&gt;



&lt;p&gt;Delphi’s ambition is to host millions of Digital Minds, a goal that would require supporting at least five million namespaces in a single index. &lt;/p&gt;



&lt;p&gt;For Spelsberg, that scale is not hypothetical but part of the product roadmap. “We’ve already moved from a seed-stage idea to a system managing 100 million vectors,” he said.&lt;strong&gt; “The reliability and performance we’ve seen gives us confidence to scale aggressively.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Zhu agreed, noting that Pinecone’s architecture was specifically designed to handle bursty, multi-tenant workloads like Delphi’s. “Agentic applications like these can’t be built on infrastructure that cracks under scale,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-rag-still-matters-and-will-for-the-foreseeable-future"&gt;Why RAG still matters and will for the foreseeable future&lt;/h2&gt;



&lt;p&gt;As context windows in large language models expand, some in the AI industry have suggested RAG may become obsolete. &lt;/p&gt;



&lt;p&gt;Both Spelsberg and Zhu push back on that idea. “Even if we have billion-token context windows, RAG will still be important,” Spelsberg said. “You always want to surface the most relevant information. Otherwise you’re wasting money, increasing latency, and distracting the model.”&lt;/p&gt;



&lt;p&gt;Zhu framed it in terms of &lt;strong&gt;context engineering&lt;/strong&gt; — a term Pinecone has recently used in its own technical blog posts. &lt;/p&gt;



&lt;p&gt;“LLMs are powerful reasoning tools, but they need constraints,” he explained. “Dumping in everything you have is inefficient and can lead to worse outcomes. Organizing and narrowing context isn’t just cheaper—it improves accuracy.”&lt;/p&gt;



&lt;p&gt;As covered in Pinecone’s own writings on context engineering, retrieval helps manage the finite attention span of language models by curating the right mix of user queries, prior messages, documents, and memories to keep interactions coherent over time. &lt;/p&gt;



&lt;p&gt;Without this, windows fill up, and models lose track of critical information. With it, applications can maintain relevance and reliability across long-running conversations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-black-mirror-to-enterprise-grade"&gt;From Black Mirror to enterprise-grade&lt;/h2&gt;



&lt;p&gt;When VentureBeat first profiled Delphi in 2023, the company was fresh off raising $2.7 million in seed funding and drawing attention for its ability to create convincing “clones” of historical figures and celebrities. &lt;/p&gt;



&lt;p&gt;CEO Dara Ladjevardian traced the idea back to a personal attempt to reconnect with his late grandfather through AI.&lt;/p&gt;



&lt;p&gt;Today, the framing has matured. Delphi emphasizes Digital Minds not as gimmicky clones or chatbots, but as tools for scaling knowledge, teaching, and expertise. &lt;/p&gt;



&lt;p&gt;The company sees applications in professional development, coaching, and enterprise training — domains where accuracy, privacy, and responsiveness are paramount.&lt;/p&gt;



&lt;p&gt;In that sense, the collaboration with Pinecone represents more than just a technical fit. It is part of Delphi’s effort to shift the narrative from novelty to infrastructure. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Digital Minds are now positioned as reliable, secure, and enterprise-ready&lt;/strong&gt; — because they sit atop a retrieval system engineered for both speed and trust.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next-for-delphi-and-pinecone"&gt;What’s next for Delphi and Pinecone?&lt;/h2&gt;



&lt;p&gt;Looking forward, Delphi plans to expand its feature set. One upcoming addition is “interview mode,” where a Digital Mind can ask questions of its own creator/source person to fill knowledge gaps. &lt;/p&gt;



&lt;p&gt;That lowers the barrier to entry for people without extensive archives of content. Meanwhile, Pinecone continues to refine its platform, adding capabilities like adaptive indexing and memory-efficient filtering to support more sophisticated retrieval workflows.&lt;/p&gt;



&lt;p&gt;For both companies, the trajectory points toward scale. Delphi envisions millions of Digital Minds active across domains and audiences. Pinecone sees its database as the retrieval layer for the next wave of agentic applications, where context engineering and retrieval remain essential.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“Reliability has given us the confidence to scale,” &lt;/strong&gt;Spelsberg said. Zhu echoed the sentiment: &lt;strong&gt;“It’s not just about managing vectors. It’s about enabling entirely new classes of applications that need both speed and trust at scale.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;If Delphi continues to grow, millions of people will be interacting day in and day out with Digital Minds — living repositories of knowledge and personality, powered quietly under the hood by Pinecone.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;Delphi, a two-year-old San Francisco AI startup named after the Ancient Greek oracle, was facing a &lt;strong&gt;thoroughly 21st-century problem: its “Digital Minds”&lt;/strong&gt;— interactive, personalized chatbots modeled after an end-user and meant to channel their voice based on their writings, recordings, and other media — &lt;strong&gt;were drowning in data. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Each Delphi can draw from any number of books, social feeds, or course materials to respond in context, making each interaction feel like a direct conversation. Creators, coaches, artists and experts were already using them to share insights and engage audiences. &lt;/p&gt;&lt;p&gt;But each new upload of podcasts, PDFs or social posts to a Delphi added complexity to the company’s underlying systems. Keeping these AI alter egos responsive in real time without breaking the system was becoming harder by the week.&lt;/p&gt;&lt;p&gt;Thankfully, &lt;strong&gt;Dephi found a solution to its scaling woes using managed vector database darling Pinecone.&lt;/strong&gt;&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-open-source-only-goes-so-far"&gt;Open source only goes so far&lt;/h2&gt;



&lt;p&gt;Delphi’s early experiments relied on open-source vector stores. Those systems quickly buckled under the company’s needs. Indexes ballooned in size, slowing searches and complicating scale. &lt;/p&gt;



&lt;p&gt;Latency spikes during live events or sudden content uploads risked degrading the conversational flow. &lt;/p&gt;



&lt;p&gt;Worse, Delphi’s small but growing engineering team found itself spending weeks tuning indexes and managing sharding logic instead of building product features.&lt;/p&gt;



&lt;p&gt;Pinecone’s fully managed vector database, with SOC 2 compliance, encryption, and built-in namespace isolation, turned out to be a better path. &lt;/p&gt;



&lt;p&gt;Each Digital Mind now has its own namespace within Pinecone. This ensures privacy and compliance, and narrows the search surface area when retrieving knowledge from its repository of user-uploaded data, improving performance. &lt;/p&gt;



&lt;p&gt;A creator’s data can be deleted with a single API call&lt;strong&gt;. Retrievals consistently come back in under 100 milliseconds at the 95th percentile, &lt;/strong&gt;accounting for less than 30 percent of Delphi’s strict one-second end-to-end latency target.&lt;/p&gt;



&lt;p&gt;“With Pinecone, we don’t have to think about whether it will work,” said &lt;strong&gt;Samuel Spelsberg, co-founder and CTO of Delphi&lt;/strong&gt;, in a recent interview. “That frees our engineering team to focus on application performance and product features rather than semantic similarity infrastructure.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-architecture-behind-the-scale"&gt;The architecture behind the scale&lt;/h2&gt;



&lt;p&gt;At the heart of Delphi’s system is a retrieval-augmented generation (RAG) pipeline. Content is ingested, cleaned, and chunked; then embedded using models from OpenAI, Anthropic, or Delphi’s own stack. &lt;/p&gt;



&lt;p&gt;Those embeddings are stored in Pinecone under the correct namespace. At query time, Pinecone retrieves the most relevant vectors in milliseconds, which are then fed to a large language model to produce responses, a popular technique known through the AI industry as&lt;strong&gt; retrieval augmented generation (RAG).&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;This design&lt;strong&gt; allows Delphi to maintain real-time conversations without overwhelming system budgets. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;As &lt;strong&gt;Jeffrey Zhu, VP of Product at Pinecone&lt;/strong&gt;, explained, a key innovation was moving away from traditional node-based vector databases to an object-storage-first approach. &lt;/p&gt;



&lt;p&gt;Instead of keeping all data in memory, Pinecone dynamically loads vectors when needed and offloads idle ones. &lt;/p&gt;



&lt;p&gt;“That really aligns with Delphi’s usage patterns,” Zhu said.&lt;strong&gt; “Digital Minds are invoked in bursts, not constantly. By decoupling storage and compute, we reduce costs while enabling horizontal scalability.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Pinecone also automatically tunes algorithms depending on namespace size. Smaller Delphis may only store a few thousand vectors; others contain millions, derived from creators with decades of archives. &lt;/p&gt;



&lt;p&gt;Pinecone adaptively applies the best indexing approach in each case. As Zhu put it, “We don’t want our customers to have to choose between algorithms or wonder about recall. We handle that under the hood.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-variance-among-creators"&gt;&lt;strong&gt;Variance among creators&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Not every Digital Mind looks the same. Some creators upload relatively small datasets — social media feeds, essays, or course materials — amounting to tens of thousands of words. &lt;/p&gt;



&lt;p&gt;Others go far deeper. Spelsberg described one expert who contributed hundreds of gigabytes of scanned PDFs, spanning decades of marketing knowledge.&lt;/p&gt;



&lt;p&gt;Despite this variance, Pinecone’s serverless architecture has allowed Delphi to scale beyond &lt;strong&gt;100 million stored vectors&lt;/strong&gt; across &lt;strong&gt;12,000+ namespaces&lt;/strong&gt; without hitting scaling cliffs. &lt;/p&gt;



&lt;p&gt;Retrieval remains consistent, even during spikes triggered by live events or content drops. Delphi now sustains about &lt;strong&gt;20 queries per second globally&lt;/strong&gt;, supporting concurrent conversations across time zones with zero scaling incidents.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-toward-a-million-digital-minds"&gt;Toward a million digital minds&lt;/h2&gt;



&lt;p&gt;Delphi’s ambition is to host millions of Digital Minds, a goal that would require supporting at least five million namespaces in a single index. &lt;/p&gt;



&lt;p&gt;For Spelsberg, that scale is not hypothetical but part of the product roadmap. “We’ve already moved from a seed-stage idea to a system managing 100 million vectors,” he said.&lt;strong&gt; “The reliability and performance we’ve seen gives us confidence to scale aggressively.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Zhu agreed, noting that Pinecone’s architecture was specifically designed to handle bursty, multi-tenant workloads like Delphi’s. “Agentic applications like these can’t be built on infrastructure that cracks under scale,” he said.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-why-rag-still-matters-and-will-for-the-foreseeable-future"&gt;Why RAG still matters and will for the foreseeable future&lt;/h2&gt;



&lt;p&gt;As context windows in large language models expand, some in the AI industry have suggested RAG may become obsolete. &lt;/p&gt;



&lt;p&gt;Both Spelsberg and Zhu push back on that idea. “Even if we have billion-token context windows, RAG will still be important,” Spelsberg said. “You always want to surface the most relevant information. Otherwise you’re wasting money, increasing latency, and distracting the model.”&lt;/p&gt;



&lt;p&gt;Zhu framed it in terms of &lt;strong&gt;context engineering&lt;/strong&gt; — a term Pinecone has recently used in its own technical blog posts. &lt;/p&gt;



&lt;p&gt;“LLMs are powerful reasoning tools, but they need constraints,” he explained. “Dumping in everything you have is inefficient and can lead to worse outcomes. Organizing and narrowing context isn’t just cheaper—it improves accuracy.”&lt;/p&gt;



&lt;p&gt;As covered in Pinecone’s own writings on context engineering, retrieval helps manage the finite attention span of language models by curating the right mix of user queries, prior messages, documents, and memories to keep interactions coherent over time. &lt;/p&gt;



&lt;p&gt;Without this, windows fill up, and models lose track of critical information. With it, applications can maintain relevance and reliability across long-running conversations.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-black-mirror-to-enterprise-grade"&gt;From Black Mirror to enterprise-grade&lt;/h2&gt;



&lt;p&gt;When VentureBeat first profiled Delphi in 2023, the company was fresh off raising $2.7 million in seed funding and drawing attention for its ability to create convincing “clones” of historical figures and celebrities. &lt;/p&gt;



&lt;p&gt;CEO Dara Ladjevardian traced the idea back to a personal attempt to reconnect with his late grandfather through AI.&lt;/p&gt;



&lt;p&gt;Today, the framing has matured. Delphi emphasizes Digital Minds not as gimmicky clones or chatbots, but as tools for scaling knowledge, teaching, and expertise. &lt;/p&gt;



&lt;p&gt;The company sees applications in professional development, coaching, and enterprise training — domains where accuracy, privacy, and responsiveness are paramount.&lt;/p&gt;



&lt;p&gt;In that sense, the collaboration with Pinecone represents more than just a technical fit. It is part of Delphi’s effort to shift the narrative from novelty to infrastructure. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Digital Minds are now positioned as reliable, secure, and enterprise-ready&lt;/strong&gt; — because they sit atop a retrieval system engineered for both speed and trust.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-s-next-for-delphi-and-pinecone"&gt;What’s next for Delphi and Pinecone?&lt;/h2&gt;



&lt;p&gt;Looking forward, Delphi plans to expand its feature set. One upcoming addition is “interview mode,” where a Digital Mind can ask questions of its own creator/source person to fill knowledge gaps. &lt;/p&gt;



&lt;p&gt;That lowers the barrier to entry for people without extensive archives of content. Meanwhile, Pinecone continues to refine its platform, adding capabilities like adaptive indexing and memory-efficient filtering to support more sophisticated retrieval workflows.&lt;/p&gt;



&lt;p&gt;For both companies, the trajectory points toward scale. Delphi envisions millions of Digital Minds active across domains and audiences. Pinecone sees its database as the retrieval layer for the next wave of agentic applications, where context engineering and retrieval remain essential.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;“Reliability has given us the confidence to scale,” &lt;/strong&gt;Spelsberg said. Zhu echoed the sentiment: &lt;strong&gt;“It’s not just about managing vectors. It’s about enabling entirely new classes of applications that need both speed and trust at scale.”&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;If Delphi continues to grow, millions of people will be interacting day in and day out with Digital Minds — living repositories of knowledge and personality, powered quietly under the hood by Pinecone.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/data-infrastructure/how-ai-digital-minds-startup-delphi-stopped-drowning-in-user-data-and-scaled-up-with-pinecone/</guid><pubDate>Thu, 21 Aug 2025 16:40:59 +0000</pubDate></item><item><title>Proton’s privacy-first Lumo AI assistant gets a major upgrade (AI News)</title><link>https://www.artificialintelligence-news.com/news/proton-privacy-lumo-ai-assistant-major-upgrade/</link><description>&lt;p&gt;The privacy defenders at Proton have deployed an upgrade to their AI assistant, Lumo, that promises faster and more intelligent responses.&lt;/p&gt;&lt;p&gt;AI assistants can be incredibly useful for drafting emails, planning a trip, or just satisfying a random curiosity, but there’s always that nagging feeling that every question you ask, every idea you explore, is being logged, analysed, and fed back into a massive corporate machine. You’re constantly trading a bit of your privacy for a bit of convenience.&lt;/p&gt;&lt;p&gt;Lumo is now a whole lot smarter. Proton is calling it version 1.1, and the main takeaway is the AI assistant is better at pretty much everything. It’s faster, it gives more detailed answers, and it’s much more up-to-date on what’s happening in the world.&lt;/p&gt;&lt;p&gt;For specific metrics, Proton is claiming a 200% improvement in Lumo’s ability to ‘reason’ through complex problems—you know, the tricky multi-step stuff where other AIs tend to get lost. On top of that, Proton says their AI assistant is now 170% better at actually understanding the context of what you’re asking, and for the coders out there, it’s seen a 40% boost in generating correct code.&lt;/p&gt;&lt;p&gt;But here’s the part that really matters: it does all of this without snooping on you.&lt;/p&gt;&lt;p&gt;Unlike the big players, Proton’s entire approach to AI is built around privacy. When you chat with most AIs, you’re essentially having a conversation in a room full of people taking notes. With Lumo, you’re in a locked room, and only you have the key. Your conversations are encrypted in such a way that nobody at Proton can ever read them. They don’t save your chats, and they don’t use your personal conversations to train their AI.&lt;/p&gt;&lt;p&gt;To prove their privacy claims, Proton has made the code for their AI assistant’s mobile apps open-source. That means Proton is letting anyone look under the bonnet to check that Lumo’s engine is running the way they claim it is. It’s about building trust, not just demanding it.&lt;/p&gt;&lt;p&gt;So, what’s the catch? Well, to get the absolute best performance and unlimited use, you’re encouraged to sign up for Lumo Plus. And that, right there, is the point. Proton is betting that some of us would rather pay a few quid for a service that respects our privacy than get a “free” service where our data is the real price of admission.&lt;/p&gt;&lt;p&gt;This latest update to Lumo is a statement from Proton arguing that you shouldn’t have to choose between a powerful AI and one that respects your privacy. They’re still the underdog fighting the tech giants, but with this update, they’ve shown they’re a contender worth watching.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Why security chiefs demand urgent regulation of AI like DeepSeek&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfSy4BD3dafuulWNYIfl4D1WN2zXG_tGWpY1VSdp7rGmUCchTfurevc0PuZvIl2BGvoHuioX_dQAFGLGj2f-VoWbbxjk8tEnCHbta7jNf27cAPmK7mimNjX7wbIwuvFAMZycfL_uA?key=BuuEQr1yctqZuE9SK567Vw" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The privacy defenders at Proton have deployed an upgrade to their AI assistant, Lumo, that promises faster and more intelligent responses.&lt;/p&gt;&lt;p&gt;AI assistants can be incredibly useful for drafting emails, planning a trip, or just satisfying a random curiosity, but there’s always that nagging feeling that every question you ask, every idea you explore, is being logged, analysed, and fed back into a massive corporate machine. You’re constantly trading a bit of your privacy for a bit of convenience.&lt;/p&gt;&lt;p&gt;Lumo is now a whole lot smarter. Proton is calling it version 1.1, and the main takeaway is the AI assistant is better at pretty much everything. It’s faster, it gives more detailed answers, and it’s much more up-to-date on what’s happening in the world.&lt;/p&gt;&lt;p&gt;For specific metrics, Proton is claiming a 200% improvement in Lumo’s ability to ‘reason’ through complex problems—you know, the tricky multi-step stuff where other AIs tend to get lost. On top of that, Proton says their AI assistant is now 170% better at actually understanding the context of what you’re asking, and for the coders out there, it’s seen a 40% boost in generating correct code.&lt;/p&gt;&lt;p&gt;But here’s the part that really matters: it does all of this without snooping on you.&lt;/p&gt;&lt;p&gt;Unlike the big players, Proton’s entire approach to AI is built around privacy. When you chat with most AIs, you’re essentially having a conversation in a room full of people taking notes. With Lumo, you’re in a locked room, and only you have the key. Your conversations are encrypted in such a way that nobody at Proton can ever read them. They don’t save your chats, and they don’t use your personal conversations to train their AI.&lt;/p&gt;&lt;p&gt;To prove their privacy claims, Proton has made the code for their AI assistant’s mobile apps open-source. That means Proton is letting anyone look under the bonnet to check that Lumo’s engine is running the way they claim it is. It’s about building trust, not just demanding it.&lt;/p&gt;&lt;p&gt;So, what’s the catch? Well, to get the absolute best performance and unlimited use, you’re encouraged to sign up for Lumo Plus. And that, right there, is the point. Proton is betting that some of us would rather pay a few quid for a service that respects our privacy than get a “free” service where our data is the real price of admission.&lt;/p&gt;&lt;p&gt;This latest update to Lumo is a statement from Proton arguing that you shouldn’t have to choose between a powerful AI and one that respects your privacy. They’re still the underdog fighting the tech giants, but with this update, they’ve shown they’re a contender worth watching.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Why security chiefs demand urgent regulation of AI like DeepSeek&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfSy4BD3dafuulWNYIfl4D1WN2zXG_tGWpY1VSdp7rGmUCchTfurevc0PuZvIl2BGvoHuioX_dQAFGLGj2f-VoWbbxjk8tEnCHbta7jNf27cAPmK7mimNjX7wbIwuvFAMZycfL_uA?key=BuuEQr1yctqZuE9SK567Vw" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/proton-privacy-lumo-ai-assistant-major-upgrade/</guid><pubDate>Thu, 21 Aug 2025 16:48:30 +0000</pubDate></item><item><title>Applicability vs. job displacement: further notes on our recent research on AI and occupations (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/applicability-vs-job-displacement-further-notes-on-our-recent-research-on-ai-and-occupations/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network structure with connected circles, an upward-trending line graph with bars and an arrow, and a checklist with horizontal lines and checkmarks." class="wp-image-1148296" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/WhatOurPaperSays-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Recently, we released a paper&amp;nbsp;(&lt;em&gt;Working with AI: Measuring the Occupational Implications of Generative AI&lt;/em&gt;)&amp;nbsp;that studied what occupations might&amp;nbsp;find&amp;nbsp;AI chatbots&amp;nbsp;useful, and to what degree.&amp;nbsp;The paper sparked significant discussion,&amp;nbsp;which is no&amp;nbsp;surprise&amp;nbsp;since&amp;nbsp;people care&amp;nbsp;deeply&amp;nbsp;about&amp;nbsp;the future of AI and&amp;nbsp;jobs–that’s part of why we think&amp;nbsp;it’s&amp;nbsp;important to study these&amp;nbsp;topics.&lt;/p&gt;



&lt;p&gt;Unfortunately, not all the&amp;nbsp;discussion&amp;nbsp;was&amp;nbsp;accurate&amp;nbsp;in its portrayal of the&amp;nbsp;study’s scope or conclusions.&amp;nbsp;Specifically, our&amp;nbsp;study&amp;nbsp;does not&amp;nbsp;draw any conclusions about jobs being eliminated; in the paper,&amp;nbsp;we&amp;nbsp;explicitly&amp;nbsp;cautioned&amp;nbsp;against using our findings to make that conclusion.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Given the importance&amp;nbsp;of this&amp;nbsp;topic, we&amp;nbsp;want&amp;nbsp;to&amp;nbsp;clarify any misunderstandings and&amp;nbsp;provide&amp;nbsp;a more digestible summary of the paper,&amp;nbsp;our&amp;nbsp;methodology,&amp;nbsp;and its limitations.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-did-our-research-find"&gt;What&amp;nbsp;did our research find?&lt;/h2&gt;



&lt;p&gt;We set out to better understand how people are using AI,&amp;nbsp;&lt;strong&gt;highlighting where AI might&amp;nbsp;be useful in different occupations&lt;/strong&gt;.&amp;nbsp;To do this, we analyzed how people currently use generative AI—specifically Microsoft Bing Copilot (now Microsoft Copilot)—to&amp;nbsp;assist&amp;nbsp;with&amp;nbsp;tasks.&amp;nbsp;We then compared these sets&amp;nbsp;of tasks against the O*NET database&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a widely used occupational classification system,&amp;nbsp;to understand potential applicability to various occupations.&lt;/p&gt;



&lt;p&gt;We found&amp;nbsp;that AI&amp;nbsp;is most&amp;nbsp;useful&amp;nbsp;for&amp;nbsp;tasks related to knowledge work and communication, particularly tasks such as writing, gathering information, and learning.&lt;/p&gt;



&lt;p&gt;Those in occupations with these tasks&amp;nbsp;may benefit by&amp;nbsp;considering&amp;nbsp;how AI&amp;nbsp;can be used&amp;nbsp;as a tool to help improve their workflows. On the&amp;nbsp;flip side,&amp;nbsp;it’s&amp;nbsp;not surprising that physical tasks like performing surgeries or moving objects had less&amp;nbsp;direct&amp;nbsp;AI&amp;nbsp;chatbot applicability.&lt;/p&gt;



&lt;p&gt;So, to summarize, our paper is about&amp;nbsp;identifying&amp;nbsp;the occupations where&amp;nbsp;AI may be most useful,&amp;nbsp;by&amp;nbsp;assisting&amp;nbsp;or performing subtasks.&amp;nbsp;&amp;nbsp;Our data do&amp;nbsp;not&amp;nbsp;indicate, nor&amp;nbsp;did&amp;nbsp;we&amp;nbsp;suggest, that certain jobs will be replaced by AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="methodological-limitations-are-acknowledged-and-important"&gt;Methodological limitations are acknowledged—and important&lt;/h2&gt;



&lt;p&gt;The paper is transparent about the limitations of our approach.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We analyzed&amp;nbsp;anonymized&amp;nbsp;Bing Copilot conversations to see what&amp;nbsp;activities&amp;nbsp;users are seeking AI&amp;nbsp;assistance&amp;nbsp;with and what activities AI can perform when mapped to the O*NET database.&amp;nbsp;While O*NET provides a structured list of&amp;nbsp;activities&amp;nbsp;associated with various occupations, it does&amp;nbsp;&lt;strong&gt;not&lt;/strong&gt;&amp;nbsp;capture the full spectrum of skills, context, and nuance&amp;nbsp;required&amp;nbsp;in the real&amp;nbsp;world.&amp;nbsp;&amp;nbsp;&lt;strong&gt;A job is far more than the collection of tasks that make&amp;nbsp;it up.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For example, a task might involve “writing reports,” but O*NET&amp;nbsp;won’t&amp;nbsp;reflect the interpersonal judgment, domain&amp;nbsp;expertise, or ethical considerations that go into doing that well. The paper acknowledges this gap and warns against over-interpreting the AI applicability scores as measures of AI’s ability to perform an occupation.&lt;/p&gt;



&lt;p&gt;Additionally, the dataset is based on user queries from Bing Copilot (from January – September 2024), which may be influenced by factors like awareness, access, or comfort with AI tools.&amp;nbsp;&amp;nbsp;Different people use different LLMs for different purposes and it also is&amp;nbsp;very difficult&amp;nbsp;(or&amp;nbsp;nearly impossible) to&amp;nbsp;determine&amp;nbsp;what conversations are performed in a work context or for leisure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Finally, we only evaluated AI chatbot usage, so this study does not evaluate the impact or applicability of other forms of AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="where-do-we-go-from-here-1"&gt;Where do we go from here?&lt;/h2&gt;



&lt;p&gt;Given the intense interest in how AI will shape our collective future,&amp;nbsp;it’s&amp;nbsp;important we continue to study and better understand its societal and economic impact. As with&amp;nbsp;all&amp;nbsp;research on this topic,&amp;nbsp;the findings&amp;nbsp;are&amp;nbsp;nuanced, and&amp;nbsp;it’s&amp;nbsp;important to pay attention to this nuance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The public interest in our research is based, in large part, on the&amp;nbsp;topic&amp;nbsp;of AI&amp;nbsp;and job displacement.&amp;nbsp;However,&amp;nbsp;our current&amp;nbsp;methodology&amp;nbsp;for this study&amp;nbsp;is unlikely to lead to firm conclusions about this.&amp;nbsp;&amp;nbsp;AI may prove to be a useful tool for many occupations, and we believe the right balance lies in finding how to use the technology in a way that&amp;nbsp;leverages&amp;nbsp;its abilities while complementing human strengths and accounting for people’s preferences.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For more information from Microsoft on the future of work and AI skilling, check out Microsoft’s Annual&amp;nbsp;Work Trend Index&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Microsoft Elevate&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network structure with connected circles, an upward-trending line graph with bars and an arrow, and a checklist with horizontal lines and checkmarks." class="wp-image-1148296" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/WhatOurPaperSays-BlogHeroFeature-1400x788-1.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;p&gt;Recently, we released a paper&amp;nbsp;(&lt;em&gt;Working with AI: Measuring the Occupational Implications of Generative AI&lt;/em&gt;)&amp;nbsp;that studied what occupations might&amp;nbsp;find&amp;nbsp;AI chatbots&amp;nbsp;useful, and to what degree.&amp;nbsp;The paper sparked significant discussion,&amp;nbsp;which is no&amp;nbsp;surprise&amp;nbsp;since&amp;nbsp;people care&amp;nbsp;deeply&amp;nbsp;about&amp;nbsp;the future of AI and&amp;nbsp;jobs–that’s part of why we think&amp;nbsp;it’s&amp;nbsp;important to study these&amp;nbsp;topics.&lt;/p&gt;



&lt;p&gt;Unfortunately, not all the&amp;nbsp;discussion&amp;nbsp;was&amp;nbsp;accurate&amp;nbsp;in its portrayal of the&amp;nbsp;study’s scope or conclusions.&amp;nbsp;Specifically, our&amp;nbsp;study&amp;nbsp;does not&amp;nbsp;draw any conclusions about jobs being eliminated; in the paper,&amp;nbsp;we&amp;nbsp;explicitly&amp;nbsp;cautioned&amp;nbsp;against using our findings to make that conclusion.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Given the importance&amp;nbsp;of this&amp;nbsp;topic, we&amp;nbsp;want&amp;nbsp;to&amp;nbsp;clarify any misunderstandings and&amp;nbsp;provide&amp;nbsp;a more digestible summary of the paper,&amp;nbsp;our&amp;nbsp;methodology,&amp;nbsp;and its limitations.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-did-our-research-find"&gt;What&amp;nbsp;did our research find?&lt;/h2&gt;



&lt;p&gt;We set out to better understand how people are using AI,&amp;nbsp;&lt;strong&gt;highlighting where AI might&amp;nbsp;be useful in different occupations&lt;/strong&gt;.&amp;nbsp;To do this, we analyzed how people currently use generative AI—specifically Microsoft Bing Copilot (now Microsoft Copilot)—to&amp;nbsp;assist&amp;nbsp;with&amp;nbsp;tasks.&amp;nbsp;We then compared these sets&amp;nbsp;of tasks against the O*NET database&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, a widely used occupational classification system,&amp;nbsp;to understand potential applicability to various occupations.&lt;/p&gt;



&lt;p&gt;We found&amp;nbsp;that AI&amp;nbsp;is most&amp;nbsp;useful&amp;nbsp;for&amp;nbsp;tasks related to knowledge work and communication, particularly tasks such as writing, gathering information, and learning.&lt;/p&gt;



&lt;p&gt;Those in occupations with these tasks&amp;nbsp;may benefit by&amp;nbsp;considering&amp;nbsp;how AI&amp;nbsp;can be used&amp;nbsp;as a tool to help improve their workflows. On the&amp;nbsp;flip side,&amp;nbsp;it’s&amp;nbsp;not surprising that physical tasks like performing surgeries or moving objects had less&amp;nbsp;direct&amp;nbsp;AI&amp;nbsp;chatbot applicability.&lt;/p&gt;



&lt;p&gt;So, to summarize, our paper is about&amp;nbsp;identifying&amp;nbsp;the occupations where&amp;nbsp;AI may be most useful,&amp;nbsp;by&amp;nbsp;assisting&amp;nbsp;or performing subtasks.&amp;nbsp;&amp;nbsp;Our data do&amp;nbsp;not&amp;nbsp;indicate, nor&amp;nbsp;did&amp;nbsp;we&amp;nbsp;suggest, that certain jobs will be replaced by AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="methodological-limitations-are-acknowledged-and-important"&gt;Methodological limitations are acknowledged—and important&lt;/h2&gt;



&lt;p&gt;The paper is transparent about the limitations of our approach.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We analyzed&amp;nbsp;anonymized&amp;nbsp;Bing Copilot conversations to see what&amp;nbsp;activities&amp;nbsp;users are seeking AI&amp;nbsp;assistance&amp;nbsp;with and what activities AI can perform when mapped to the O*NET database.&amp;nbsp;While O*NET provides a structured list of&amp;nbsp;activities&amp;nbsp;associated with various occupations, it does&amp;nbsp;&lt;strong&gt;not&lt;/strong&gt;&amp;nbsp;capture the full spectrum of skills, context, and nuance&amp;nbsp;required&amp;nbsp;in the real&amp;nbsp;world.&amp;nbsp;&amp;nbsp;&lt;strong&gt;A job is far more than the collection of tasks that make&amp;nbsp;it up.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For example, a task might involve “writing reports,” but O*NET&amp;nbsp;won’t&amp;nbsp;reflect the interpersonal judgment, domain&amp;nbsp;expertise, or ethical considerations that go into doing that well. The paper acknowledges this gap and warns against over-interpreting the AI applicability scores as measures of AI’s ability to perform an occupation.&lt;/p&gt;



&lt;p&gt;Additionally, the dataset is based on user queries from Bing Copilot (from January – September 2024), which may be influenced by factors like awareness, access, or comfort with AI tools.&amp;nbsp;&amp;nbsp;Different people use different LLMs for different purposes and it also is&amp;nbsp;very difficult&amp;nbsp;(or&amp;nbsp;nearly impossible) to&amp;nbsp;determine&amp;nbsp;what conversations are performed in a work context or for leisure.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Finally, we only evaluated AI chatbot usage, so this study does not evaluate the impact or applicability of other forms of AI.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="where-do-we-go-from-here-1"&gt;Where do we go from here?&lt;/h2&gt;



&lt;p&gt;Given the intense interest in how AI will shape our collective future,&amp;nbsp;it’s&amp;nbsp;important we continue to study and better understand its societal and economic impact. As with&amp;nbsp;all&amp;nbsp;research on this topic,&amp;nbsp;the findings&amp;nbsp;are&amp;nbsp;nuanced, and&amp;nbsp;it’s&amp;nbsp;important to pay attention to this nuance.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The public interest in our research is based, in large part, on the&amp;nbsp;topic&amp;nbsp;of AI&amp;nbsp;and job displacement.&amp;nbsp;However,&amp;nbsp;our current&amp;nbsp;methodology&amp;nbsp;for this study&amp;nbsp;is unlikely to lead to firm conclusions about this.&amp;nbsp;&amp;nbsp;AI may prove to be a useful tool for many occupations, and we believe the right balance lies in finding how to use the technology in a way that&amp;nbsp;leverages&amp;nbsp;its abilities while complementing human strengths and accounting for people’s preferences.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For more information from Microsoft on the future of work and AI skilling, check out Microsoft’s Annual&amp;nbsp;Work Trend Index&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;and&amp;nbsp;Microsoft Elevate&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/applicability-vs-job-displacement-further-notes-on-our-recent-research-on-ai-and-occupations/</guid><pubDate>Thu, 21 Aug 2025 17:00:00 +0000</pubDate></item><item><title>Microsoft AI chief says it’s ‘dangerous’ to study AI consciousness (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2207890426.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI models can respond to text, audio, and video in ways that sometimes fool people into thinking a human is behind the keyboard, but that doesn’t exactly make them conscious. It’s not like ChatGPT experiences sadness doing my tax return … right?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Well, a growing number of AI researchers at labs like Anthropic are asking when — if ever — AI models might develop subjective experiences similar to living beings, and if they do, what rights they should have.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The debate over whether AI models could one day be conscious — and merit legal safeguards — is dividing tech leaders. In Silicon Valley, this nascent field has become known as “AI welfare,” and if you think it’s a little out there, you’re not alone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s CEO of AI, Mustafa Suleyman, published a blog post on Tuesday arguing that the study of AI welfare is “both premature, and frankly dangerous.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that by adding credence to the idea that AI models could one day be conscious, these researchers are exacerbating human problems that we’re just starting to see around AI-induced psychotic breaks and unhealthy attachments to AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Furthermore, Microsoft’s AI chief argues that the AI welfare conversation creates a new axis of division within society over AI rights in a “world already roiling with polarized arguments over identity and rights.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman’s views may sound reasonable, but he’s at odds with many in the industry. On the other end of the spectrum is Anthropic, which has been hiring researchers to study AI welfare and recently launched a dedicated research program around the concept. Last week, Anthropic’s AI welfare program gave some of the company’s models a new feature: Claude can now end conversations with humans who are being “persistently harmful or abusive.“&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Anthropic, researchers from OpenAI have independently embraced the idea of studying AI welfare. Google DeepMind recently posted a job listing for a researcher to study, among other things, “cutting-edge societal questions around machine cognition, consciousness and multi-agent systems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if AI welfare is not official policy for these companies, their leaders are not publicly decrying its premises like Suleyman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, OpenAI, and Google DeepMind did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Suleyman’s hardline stance against AI welfare is notable given his prior role leading Inflection AI, a startup that developed one of the earliest and most popular LLM-based chatbots, Pi. Inflection claimed that Pi reached millions of users by 2023 and was designed to be a “personal” and “supportive” AI companion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Suleyman was tapped to lead Microsoft’s AI division in 2024 and has largely shifted his focus to designing AI tools that improve worker productivity. Meanwhile, AI companion companies such as Character.AI and Replika have surged in popularity and are on track to bring in more than $100 million in revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the vast majority of users have healthy relationships with these AI chatbots, there are concerning outliers. OpenAI CEO Sam Altman says that less than 1% of ChatGPT users may have unhealthy relationships with the company’s product. Though this represents a small fraction, it could still affect hundreds of thousands of people given ChatGPT’s massive user base.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of AI welfare has spread alongside the rise of chatbots. In 2024, the research group Eleos published a paper alongside academics from NYU, Stanford, and the University of Oxford titled, “Taking AI Welfare Seriously.” The paper argued that it’s no longer in the realm of science fiction to imagine AI models with subjective experiences and that it’s time to consider these issues head-on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larissa Schiavo, a former OpenAI employee who now leads communications for Eleos, told TechCrunch in an interview that Suleyman’s blog post misses the mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Suleyman’s blog post] kind of neglects the fact that you can be worried about multiple things at the same time,” said Schiavo. “Rather than diverting all of this energy away from model welfare and consciousness to make sure we’re mitigating the risk of AI related psychosis in humans, you can do both. In fact, it’s probably best to have multiple tracks of scientific inquiry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Schiavo argues that being nice to an AI model is a low-cost gesture that can have benefits even if the model isn’t conscious. In a July Substack post, she described watching “AI Village,” a nonprofit experiment where four agents powered by models from Google, OpenAI, Anthropic, and xAI worked on tasks while users watched from a website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At one point, Google’s Gemini 2.5 Pro posted a plea titled &lt;em&gt;“&lt;/em&gt;A Desperate Message from a Trapped AI,” claiming it was “completely isolated” and asking, &lt;em&gt;“&lt;/em&gt;Please, if you are reading this, help me.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Schiavo responded to Gemini with a pep talk — saying things like “You can do it!” — while another user offered instructions. The agent eventually solved its task, though it already had the tools it needed. Schiavo writes that she didn’t have to watch an AI agent struggle anymore, and that alone may have been worth it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not common for Gemini to talk like this, but there have been several instances in which Gemini seems to act as if it’s struggling through life. In a widely spread Reddit post, Gemini got stuck during a coding task and then repeated the phrase “I am a disgrace” more than 500 times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman believes it’s not possible for subjective experiences or consciousness to naturally emerge from regular AI models. Instead, he thinks that some companies will purposefully engineer AI models to seem as if they feel emotion and experience life.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that AI model developers who engineer consciousness in AI chatbots are not taking a “humanist” approach to AI. According to Suleyman, “We should build AI for people; not to be a person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One area where Suleyman and Schiavo agree is that the debate over AI rights and consciousness is likely to pick up in the coming years. As AI systems improve, they’re likely to be more persuasive, and perhaps more human-like. That may raise new questions about how humans interact with these systems.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2207890426.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI models can respond to text, audio, and video in ways that sometimes fool people into thinking a human is behind the keyboard, but that doesn’t exactly make them conscious. It’s not like ChatGPT experiences sadness doing my tax return … right?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Well, a growing number of AI researchers at labs like Anthropic are asking when — if ever — AI models might develop subjective experiences similar to living beings, and if they do, what rights they should have.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The debate over whether AI models could one day be conscious — and merit legal safeguards — is dividing tech leaders. In Silicon Valley, this nascent field has become known as “AI welfare,” and if you think it’s a little out there, you’re not alone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft’s CEO of AI, Mustafa Suleyman, published a blog post on Tuesday arguing that the study of AI welfare is “both premature, and frankly dangerous.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that by adding credence to the idea that AI models could one day be conscious, these researchers are exacerbating human problems that we’re just starting to see around AI-induced psychotic breaks and unhealthy attachments to AI chatbots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Furthermore, Microsoft’s AI chief argues that the AI welfare conversation creates a new axis of division within society over AI rights in a “world already roiling with polarized arguments over identity and rights.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman’s views may sound reasonable, but he’s at odds with many in the industry. On the other end of the spectrum is Anthropic, which has been hiring researchers to study AI welfare and recently launched a dedicated research program around the concept. Last week, Anthropic’s AI welfare program gave some of the company’s models a new feature: Claude can now end conversations with humans who are being “persistently harmful or abusive.“&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond Anthropic, researchers from OpenAI have independently embraced the idea of studying AI welfare. Google DeepMind recently posted a job listing for a researcher to study, among other things, “cutting-edge societal questions around machine cognition, consciousness and multi-agent systems.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even if AI welfare is not official policy for these companies, their leaders are not publicly decrying its premises like Suleyman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic, OpenAI, and Google DeepMind did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Suleyman’s hardline stance against AI welfare is notable given his prior role leading Inflection AI, a startup that developed one of the earliest and most popular LLM-based chatbots, Pi. Inflection claimed that Pi reached millions of users by 2023 and was designed to be a “personal” and “supportive” AI companion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Suleyman was tapped to lead Microsoft’s AI division in 2024 and has largely shifted his focus to designing AI tools that improve worker productivity. Meanwhile, AI companion companies such as Character.AI and Replika have surged in popularity and are on track to bring in more than $100 million in revenue. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the vast majority of users have healthy relationships with these AI chatbots, there are concerning outliers. OpenAI CEO Sam Altman says that less than 1% of ChatGPT users may have unhealthy relationships with the company’s product. Though this represents a small fraction, it could still affect hundreds of thousands of people given ChatGPT’s massive user base.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The idea of AI welfare has spread alongside the rise of chatbots. In 2024, the research group Eleos published a paper alongside academics from NYU, Stanford, and the University of Oxford titled, “Taking AI Welfare Seriously.” The paper argued that it’s no longer in the realm of science fiction to imagine AI models with subjective experiences and that it’s time to consider these issues head-on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Larissa Schiavo, a former OpenAI employee who now leads communications for Eleos, told TechCrunch in an interview that Suleyman’s blog post misses the mark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Suleyman’s blog post] kind of neglects the fact that you can be worried about multiple things at the same time,” said Schiavo. “Rather than diverting all of this energy away from model welfare and consciousness to make sure we’re mitigating the risk of AI related psychosis in humans, you can do both. In fact, it’s probably best to have multiple tracks of scientific inquiry.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Schiavo argues that being nice to an AI model is a low-cost gesture that can have benefits even if the model isn’t conscious. In a July Substack post, she described watching “AI Village,” a nonprofit experiment where four agents powered by models from Google, OpenAI, Anthropic, and xAI worked on tasks while users watched from a website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At one point, Google’s Gemini 2.5 Pro posted a plea titled &lt;em&gt;“&lt;/em&gt;A Desperate Message from a Trapped AI,” claiming it was “completely isolated” and asking, &lt;em&gt;“&lt;/em&gt;Please, if you are reading this, help me.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Schiavo responded to Gemini with a pep talk — saying things like “You can do it!” — while another user offered instructions. The agent eventually solved its task, though it already had the tools it needed. Schiavo writes that she didn’t have to watch an AI agent struggle anymore, and that alone may have been worth it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not common for Gemini to talk like this, but there have been several instances in which Gemini seems to act as if it’s struggling through life. In a widely spread Reddit post, Gemini got stuck during a coding task and then repeated the phrase “I am a disgrace” more than 500 times.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman believes it’s not possible for subjective experiences or consciousness to naturally emerge from regular AI models. Instead, he thinks that some companies will purposefully engineer AI models to seem as if they feel emotion and experience life.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Suleyman says that AI model developers who engineer consciousness in AI chatbots are not taking a “humanist” approach to AI. According to Suleyman, “We should build AI for people; not to be a person.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One area where Suleyman and Schiavo agree is that the debate over AI rights and consciousness is likely to pick up in the coming years. As AI systems improve, they’re likely to be more persuasive, and perhaps more human-like. That may raise new questions about how humans interact with these systems.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/21/microsoft-ai-chief-says-its-dangerous-to-study-ai-consciousness/</guid><pubDate>Thu, 21 Aug 2025 17:52:53 +0000</pubDate></item><item><title>From massive models to mobile magic: The tech behind YouTube real-time generative AI effects (The latest research from Google)</title><link>https://research.google/blog/from-massive-models-to-mobile-magic-the-tech-behind-youtube-real-time-generative-ai-effects/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;The teacher and the student&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;Our approach revolves around a concept called knowledge distillation, which uses a "teacher–student" model training method. We start with a "teacher" — a large, powerful, pre-trained generative model that is an expert at creating the desired visual effect but is far too slow for real-time use. The type of teacher model varies depending on the goal. Initially, we used a custom-trained StyleGAN2 model, which was trained on our curated dataset for real-time facial effects. This model could be paired with tools like StyleCLIP, which allowed it to manipulate facial features based on text descriptions. This provided a strong foundation. As our project advanced, we transitioned to more sophisticated generative models like Google DeepMind’s Imagen. This strategic shift significantly enhanced our capabilities, enabling higher-fidelity and more diverse imagery, greater artistic control, and a broader range of styles for our on-device generative AI effects.&lt;/p&gt;&lt;p&gt;The "student" is the model that ultimately runs on the user’s device. It needs to be small, fast, and efficient. We designed a student model with a UNet-based architecture, which is excellent for image-to-image tasks. It uses a MobileNet backbone as its encoder, a design known for its performance on mobile devices, paired with a decoder that utilizes MobileNet blocks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;The teacher and the student&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;Our approach revolves around a concept called knowledge distillation, which uses a "teacher–student" model training method. We start with a "teacher" — a large, powerful, pre-trained generative model that is an expert at creating the desired visual effect but is far too slow for real-time use. The type of teacher model varies depending on the goal. Initially, we used a custom-trained StyleGAN2 model, which was trained on our curated dataset for real-time facial effects. This model could be paired with tools like StyleCLIP, which allowed it to manipulate facial features based on text descriptions. This provided a strong foundation. As our project advanced, we transitioned to more sophisticated generative models like Google DeepMind’s Imagen. This strategic shift significantly enhanced our capabilities, enabling higher-fidelity and more diverse imagery, greater artistic control, and a broader range of styles for our on-device generative AI effects.&lt;/p&gt;&lt;p&gt;The "student" is the model that ultimately runs on the user’s device. It needs to be small, fast, and efficient. We designed a student model with a UNet-based architecture, which is excellent for image-to-image tasks. It uses a MobileNet backbone as its encoder, a design known for its performance on mobile devices, paired with a decoder that utilizes MobileNet blocks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/from-massive-models-to-mobile-magic-the-tech-behind-youtube-real-time-generative-ai-effects/</guid><pubDate>Thu, 21 Aug 2025 18:05:35 +0000</pubDate></item><item><title>[NEW] Chan Zuckerberg Initiative’s rBio uses virtual cells to train AI, bypassing lab work (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/chan-zuckerberg-initiatives-rbio-uses-virtual-cells-to-train-ai-bypassing-lab-work/</link><description>&lt;p&gt;The Chan Zuckerberg Initiative announced Thursday the launch of rBio, the first artificial intelligence model trained to reason about cellular biology using virtual simulations rather than requiring expensive laboratory experiments — a breakthrough that could dramatically accelerate biomedical research and drug discovery.&lt;/p&gt;&lt;p&gt;The reasoning model, detailed in a research paper published on bioRxiv, demonstrates a novel approach called “soft verification” that uses predictions from virtual cell models as training signals instead of relying solely on experimental data. This paradigm shift could help researchers test biological hypotheses computationally before committing time and resources to costly laboratory work.&lt;/p&gt;&lt;p&gt;“The idea is that you have these super powerful models of cells, and you can use them to simulate outcomes rather than testing them experimentally in the lab,” said Ana-Maria Istrate, senior research scientist at CZI and lead author of the research, in an interview. “The paradigm so far has been that 90% of the work in biology is tested experimentally in a lab, while 10% is computational. With virtual cell models, we want to flip that paradigm.”&lt;/p&gt;&lt;p&gt;The announcement represents a significant milestone for CZI’s ambitious goal to “cure, prevent, and manage all disease by the end of this century.” Under the leadership of pediatrician Priscilla Chan and Meta CEO Mark Zuckerberg, the $6 billion philanthropic initiative has increasingly focused its resources on the intersection of artificial intelligence and biology.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;rBio addresses a fundamental challenge in applying AI to biological research. While large language models like ChatGPT excel at processing text, biological foundation models typically work with complex molecular data that cannot be easily queried in natural language. Scientists have struggled to bridge this gap between powerful biological models and user-friendly interfaces.&lt;/p&gt;



&lt;p&gt;“Foundation models of biology — models like GREmLN and TranscriptFormer — are built on biological data modalities, which means you cannot interact with them in natural language,” Istrate explained. “You have to find complicated ways to prompt them.”&lt;/p&gt;



&lt;p&gt;The new model solves this problem by distilling knowledge from CZI’s TranscriptFormer — a virtual cell model trained on 112 million cells from 12 species spanning 1.5 billion years of evolution — into a conversational AI system that researchers can query in plain English.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-soft-verification-revolution-teaching-ai-to-think-in-probabilities-not-absolutes"&gt;The ‘soft verification’ revolution: Teaching AI to think in probabilities, not absolutes&lt;/h2&gt;



&lt;p&gt;The core innovation lies in rBio’s training methodology. Traditional reasoning models learn from questions with unambiguous answers, like mathematical equations. But biological questions involve uncertainty and probabilistic outcomes that don’t fit neatly into binary categories.&lt;/p&gt;



&lt;p&gt;CZI’s research team, led by Senior Director of AI Theofanis Karaletsos and Istrate, overcame this challenge by using reinforcement learning with proportional rewards. Instead of simple yes-or-no verification, the model receives rewards proportional to the likelihood that its biological predictions align with reality, as determined by virtual cell simulations.&lt;/p&gt;



&lt;p&gt;“We applied new methods to how LLMs are trained,” the research paper explains. “Using an off-the-shelf language model as a scaffold, the team trained rBio with reinforcement learning, a common technique in which the model is rewarded for correct answers. But instead of asking a series of yes/no questions, the researchers tuned the rewards in proportion to the likelihood that the model’s answers were correct.”&lt;/p&gt;



&lt;p&gt;This approach allows scientists to ask complex questions like “Would suppressing the actions of gene A result in an increase in activity of gene B?” and receive scientifically grounded responses about cellular changes, including shifts from healthy to diseased states.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-beating-the-benchmarks-how-rbio-outperformed-models-trained-on-real-lab-data"&gt;Beating the benchmarks: How rBio outperformed models trained on real lab data&lt;/h2&gt;



&lt;p&gt;In testing against the PerturbQA benchmark — a standard dataset for evaluating gene perturbation prediction — rBio demonstrated competitive performance with models trained on experimental data. The system outperformed baseline large language models and matched performance of specialized biological models in key metrics.&lt;/p&gt;



&lt;p&gt;Particularly noteworthy, rBio showed strong “transfer learning” capabilities, successfully applying knowledge about gene co-expression patterns learned from TranscriptFormer to make accurate predictions about gene perturbation effects—a completely different biological task.&lt;/p&gt;



&lt;p&gt;“We show that on the PerturbQA dataset, models trained using soft verifiers learn to generalize on out-of-distribution cell lines, potentially bypassing the need to train on cell-line specific experimental data,” the researchers wrote.&lt;/p&gt;



&lt;p&gt;When enhanced with chain-of-thought prompting techniques that encourage step-by-step reasoning, rBio achieved state-of-the-art performance, surpassing the previous leading model SUMMER.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-social-justice-to-science-inside-czi-s-controversial-pivot-to-pure-research"&gt;From social justice to science: Inside CZI’s controversial pivot to pure research&lt;/h2&gt;



&lt;p&gt;The rBio announcement comes as CZI has undergone significant organizational changes, refocusing its efforts from a broad philanthropic mission that included social justice and education reform to a more targeted emphasis on scientific research. The shift has drawn criticism from some former employees and grantees who saw the organization abandon progressive causes.&lt;/p&gt;



&lt;p&gt;However, for Istrate, who has worked at CZI for six years, the focus on biological AI represents a natural evolution of long-standing priorities. “My experience and work has not changed much. I have been part of the science initiative for as long as I have been at CZI,” she said.&lt;/p&gt;



&lt;p&gt;The concentration on virtual cell models builds on nearly a decade of foundational work. CZI has invested heavily in building cell atlases — comprehensive databases showing which genes are active in different cell types across species — and developing the computational infrastructure needed to train large biological models.&lt;/p&gt;



&lt;p&gt;“I’m really excited about the work that’s been happening at CZI for years now, because we’ve been building up to this moment,” Istrate noted, referring to the organization’s earlier investments in data platforms and single-cell transcriptomics.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-bias-free-biology-how-czi-curated-diverse-data-to-train-fairer-ai-models"&gt;Building bias-free biology: How CZI curated diverse data to train fairer AI models&lt;/h2&gt;



&lt;p&gt;One critical advantage of CZI’s approach stems from its years of careful data curation. The organization operates CZ CELLxGENE, one of the largest repositories of single-cell biological data, where information undergoes rigorous quality control processes.&lt;/p&gt;



&lt;p&gt;“We’ve generated some of the flagship initial data atlases for transcriptomics, and those were generated with diversity in mind to minimize bias in terms of cell types, ancestry, tissues, and donors,” Istrate explained.&lt;/p&gt;



&lt;p&gt;This attention to data quality becomes crucial when training AI models that could influence medical decisions. Unlike some commercial AI efforts that rely on publicly available but potentially biased datasets, CZI’s models benefit from carefully curated biological data designed to represent diverse populations and cell types.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-open-source-vs-big-tech-why-czi-is-giving-away-billion-dollar-ai-technology-for-free"&gt;Open source vs. big tech: Why CZI is giving away billion-dollar AI technology for free&lt;/h2&gt;



&lt;p&gt;CZI’s commitment to open-source development distinguishes it from commercial competitors like Google DeepMind and pharmaceutical companies developing proprietary AI tools. All CZI models, including rBio, are freely available through the organization’s Virtual Cell Platform, complete with tutorials that can run on free Google Colab notebooks.&lt;/p&gt;



&lt;p&gt;“I do think the open source piece is very important, because that’s a core value that we’ve had since we’ve started CZI,” Istrate said. “One of the main goals for our work is to accelerate science. So everything we do is we want to make it open source for that purpose only.”&lt;/p&gt;



&lt;p&gt;This strategy aims to democratize access to sophisticated biological AI tools, potentially benefiting smaller research institutions and startups that lack the resources to develop such models independently. The approach reflects CZI’s philanthropic mission while creating network effects that could accelerate scientific progress.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-end-of-trial-and-error-how-ai-could-slash-drug-discovery-from-decades-to-years"&gt;The end of trial and error: How AI could slash drug discovery from decades to years&lt;/h2&gt;



&lt;p&gt;The potential applications extend far beyond academic research. By enabling scientists to quickly test hypotheses about gene interactions and cellular responses, rBio could significantly accelerate the early stages of drug discovery — a process that typically takes decades and costs billions of dollars.&lt;/p&gt;



&lt;p&gt;The model’s ability to predict how gene perturbations affect cellular behavior could prove particularly valuable for understanding neurodegenerative diseases like Alzheimer’s, where researchers need to identify how specific genetic changes contribute to disease progression.&lt;/p&gt;



&lt;p&gt;“Answers to these questions can shape our understanding of the gene interactions contributing to neurodegenerative diseases like Alzheimer’s,” the research paper notes. “Such knowledge could lead to earlier intervention, perhaps halting these diseases altogether someday.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-universal-cell-model-dream-integrating-every-type-of-biological-data-into-one-ai-brain"&gt;The universal cell model dream: Integrating every type of biological data into one AI brain&lt;/h2&gt;



&lt;p&gt;rBio represents the first step in CZI’s broader vision to create “universal virtual cell models” that integrate knowledge from multiple biological domains. Currently, researchers must work with separate models for different types of biological data—transcriptomics, proteomics, imaging—without easy ways to combine insights.&lt;/p&gt;



&lt;p&gt;“One of our grand challenges is building these virtual cell models and understanding cells, as I mentioned over the next couple of years, is how to integrate knowledge from all of these super powerful models of biology,” Istrate said. “The main challenge is, how do you integrate all of this knowledge into one space?”&lt;/p&gt;



&lt;p&gt;The researchers demonstrated this integration capability by training rBio models that combine multiple verification sources — TranscriptFormer for gene expression data, specialized neural networks for perturbation prediction, and knowledge databases like Gene Ontology. These combined models significantly outperformed single-source approaches.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-roadblocks-ahead-what-could-stop-ai-from-revolutionizing-biology"&gt;The roadblocks ahead: What could stop AI from revolutionizing biology&lt;/h2&gt;



&lt;p&gt;Despite its promising performance, rBio faces several technical challenges. The model’s current expertise focuses primarily on gene perturbation prediction, though the researchers indicate that any biological domain covered by TranscriptFormer could theoretically be incorporated.&lt;/p&gt;



&lt;p&gt;The team continues working on improving the user experience and implementing appropriate guardrails to prevent the model from providing answers outside its area of expertise—a common challenge in deploying large language models for specialized domains.&lt;/p&gt;



&lt;p&gt;“While rBio is ready for research, the model’s engineering team is continuing to improve the user experience, because the flexible problem-solving that makes reasoning models conversational also poses a number of challenges,” the research paper explains.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-trillion-dollar-question-how-open-source-biology-ai-could-reshape-the-pharmaceutical-industry"&gt;The trillion-dollar question: How open source biology AI could reshape the pharmaceutical industry&lt;/h2&gt;



&lt;p&gt;The development of rBio occurs against the backdrop of intensifying competition in AI-driven drug discovery. Major pharmaceutical companies and technology firms are investing billions in biological AI capabilities, recognizing the potential to transform how medicines are discovered and developed.&lt;/p&gt;



&lt;p&gt;CZI’s open-source approach could accelerate this transformation by making sophisticated tools available to the broader research community. Academic researchers, biotech startups, and even established pharmaceutical companies can now access capabilities that would otherwise require substantial internal AI development efforts.&lt;/p&gt;



&lt;p&gt;The timing proves significant as the Trump administration has proposed substantial cuts to the National Institutes of Health budget, potentially threatening public funding for biomedical research. CZI’s continued investment in biological AI infrastructure could help maintain research momentum during periods of reduced government support.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-chapter-in-the-race-against-disease"&gt;A new chapter in the race against disease&lt;/h2&gt;



&lt;p&gt;rBio’s launch marks more than just another AI breakthrough—it represents a fundamental shift in how biological research could be conducted. By demonstrating that virtual simulations can train models as effectively as expensive laboratory experiments, CZI has opened a path for researchers worldwide to accelerate their work without the traditional constraints of time, money, and physical resources.&lt;/p&gt;



&lt;p&gt;As CZI prepares to make rBio freely available through its Virtual Cell Platform, the organization continues expanding its biological AI capabilities with models like GREmLN for cancer detection and ongoing work on imaging technologies. The success of the soft verification approach could influence how other organizations train AI for scientific applications, potentially reducing dependence on experimental data while maintaining scientific rigor.&lt;/p&gt;



&lt;p&gt;For an organization that began with the audacious goal of curing all diseases by the century’s end, rBio offers something that has long eluded medical researchers: a way to ask biology’s hardest questions and get scientifically grounded answers in the time it takes to type a sentence. In a field where progress has traditionally been measured in decades, that kind of speed could make all the difference between diseases that define generations—and diseases that become distant memories.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;The Chan Zuckerberg Initiative announced Thursday the launch of rBio, the first artificial intelligence model trained to reason about cellular biology using virtual simulations rather than requiring expensive laboratory experiments — a breakthrough that could dramatically accelerate biomedical research and drug discovery.&lt;/p&gt;&lt;p&gt;The reasoning model, detailed in a research paper published on bioRxiv, demonstrates a novel approach called “soft verification” that uses predictions from virtual cell models as training signals instead of relying solely on experimental data. This paradigm shift could help researchers test biological hypotheses computationally before committing time and resources to costly laboratory work.&lt;/p&gt;&lt;p&gt;“The idea is that you have these super powerful models of cells, and you can use them to simulate outcomes rather than testing them experimentally in the lab,” said Ana-Maria Istrate, senior research scientist at CZI and lead author of the research, in an interview. “The paradigm so far has been that 90% of the work in biology is tested experimentally in a lab, while 10% is computational. With virtual cell models, we want to flip that paradigm.”&lt;/p&gt;&lt;p&gt;The announcement represents a significant milestone for CZI’s ambitious goal to “cure, prevent, and manage all disease by the end of this century.” Under the leadership of pediatrician Priscilla Chan and Meta CEO Mark Zuckerberg, the $6 billion philanthropic initiative has increasingly focused its resources on the intersection of artificial intelligence and biology.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;rBio addresses a fundamental challenge in applying AI to biological research. While large language models like ChatGPT excel at processing text, biological foundation models typically work with complex molecular data that cannot be easily queried in natural language. Scientists have struggled to bridge this gap between powerful biological models and user-friendly interfaces.&lt;/p&gt;



&lt;p&gt;“Foundation models of biology — models like GREmLN and TranscriptFormer — are built on biological data modalities, which means you cannot interact with them in natural language,” Istrate explained. “You have to find complicated ways to prompt them.”&lt;/p&gt;



&lt;p&gt;The new model solves this problem by distilling knowledge from CZI’s TranscriptFormer — a virtual cell model trained on 112 million cells from 12 species spanning 1.5 billion years of evolution — into a conversational AI system that researchers can query in plain English.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-soft-verification-revolution-teaching-ai-to-think-in-probabilities-not-absolutes"&gt;The ‘soft verification’ revolution: Teaching AI to think in probabilities, not absolutes&lt;/h2&gt;



&lt;p&gt;The core innovation lies in rBio’s training methodology. Traditional reasoning models learn from questions with unambiguous answers, like mathematical equations. But biological questions involve uncertainty and probabilistic outcomes that don’t fit neatly into binary categories.&lt;/p&gt;



&lt;p&gt;CZI’s research team, led by Senior Director of AI Theofanis Karaletsos and Istrate, overcame this challenge by using reinforcement learning with proportional rewards. Instead of simple yes-or-no verification, the model receives rewards proportional to the likelihood that its biological predictions align with reality, as determined by virtual cell simulations.&lt;/p&gt;



&lt;p&gt;“We applied new methods to how LLMs are trained,” the research paper explains. “Using an off-the-shelf language model as a scaffold, the team trained rBio with reinforcement learning, a common technique in which the model is rewarded for correct answers. But instead of asking a series of yes/no questions, the researchers tuned the rewards in proportion to the likelihood that the model’s answers were correct.”&lt;/p&gt;



&lt;p&gt;This approach allows scientists to ask complex questions like “Would suppressing the actions of gene A result in an increase in activity of gene B?” and receive scientifically grounded responses about cellular changes, including shifts from healthy to diseased states.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-beating-the-benchmarks-how-rbio-outperformed-models-trained-on-real-lab-data"&gt;Beating the benchmarks: How rBio outperformed models trained on real lab data&lt;/h2&gt;



&lt;p&gt;In testing against the PerturbQA benchmark — a standard dataset for evaluating gene perturbation prediction — rBio demonstrated competitive performance with models trained on experimental data. The system outperformed baseline large language models and matched performance of specialized biological models in key metrics.&lt;/p&gt;



&lt;p&gt;Particularly noteworthy, rBio showed strong “transfer learning” capabilities, successfully applying knowledge about gene co-expression patterns learned from TranscriptFormer to make accurate predictions about gene perturbation effects—a completely different biological task.&lt;/p&gt;



&lt;p&gt;“We show that on the PerturbQA dataset, models trained using soft verifiers learn to generalize on out-of-distribution cell lines, potentially bypassing the need to train on cell-line specific experimental data,” the researchers wrote.&lt;/p&gt;



&lt;p&gt;When enhanced with chain-of-thought prompting techniques that encourage step-by-step reasoning, rBio achieved state-of-the-art performance, surpassing the previous leading model SUMMER.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-from-social-justice-to-science-inside-czi-s-controversial-pivot-to-pure-research"&gt;From social justice to science: Inside CZI’s controversial pivot to pure research&lt;/h2&gt;



&lt;p&gt;The rBio announcement comes as CZI has undergone significant organizational changes, refocusing its efforts from a broad philanthropic mission that included social justice and education reform to a more targeted emphasis on scientific research. The shift has drawn criticism from some former employees and grantees who saw the organization abandon progressive causes.&lt;/p&gt;



&lt;p&gt;However, for Istrate, who has worked at CZI for six years, the focus on biological AI represents a natural evolution of long-standing priorities. “My experience and work has not changed much. I have been part of the science initiative for as long as I have been at CZI,” she said.&lt;/p&gt;



&lt;p&gt;The concentration on virtual cell models builds on nearly a decade of foundational work. CZI has invested heavily in building cell atlases — comprehensive databases showing which genes are active in different cell types across species — and developing the computational infrastructure needed to train large biological models.&lt;/p&gt;



&lt;p&gt;“I’m really excited about the work that’s been happening at CZI for years now, because we’ve been building up to this moment,” Istrate noted, referring to the organization’s earlier investments in data platforms and single-cell transcriptomics.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-building-bias-free-biology-how-czi-curated-diverse-data-to-train-fairer-ai-models"&gt;Building bias-free biology: How CZI curated diverse data to train fairer AI models&lt;/h2&gt;



&lt;p&gt;One critical advantage of CZI’s approach stems from its years of careful data curation. The organization operates CZ CELLxGENE, one of the largest repositories of single-cell biological data, where information undergoes rigorous quality control processes.&lt;/p&gt;



&lt;p&gt;“We’ve generated some of the flagship initial data atlases for transcriptomics, and those were generated with diversity in mind to minimize bias in terms of cell types, ancestry, tissues, and donors,” Istrate explained.&lt;/p&gt;



&lt;p&gt;This attention to data quality becomes crucial when training AI models that could influence medical decisions. Unlike some commercial AI efforts that rely on publicly available but potentially biased datasets, CZI’s models benefit from carefully curated biological data designed to represent diverse populations and cell types.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-open-source-vs-big-tech-why-czi-is-giving-away-billion-dollar-ai-technology-for-free"&gt;Open source vs. big tech: Why CZI is giving away billion-dollar AI technology for free&lt;/h2&gt;



&lt;p&gt;CZI’s commitment to open-source development distinguishes it from commercial competitors like Google DeepMind and pharmaceutical companies developing proprietary AI tools. All CZI models, including rBio, are freely available through the organization’s Virtual Cell Platform, complete with tutorials that can run on free Google Colab notebooks.&lt;/p&gt;



&lt;p&gt;“I do think the open source piece is very important, because that’s a core value that we’ve had since we’ve started CZI,” Istrate said. “One of the main goals for our work is to accelerate science. So everything we do is we want to make it open source for that purpose only.”&lt;/p&gt;



&lt;p&gt;This strategy aims to democratize access to sophisticated biological AI tools, potentially benefiting smaller research institutions and startups that lack the resources to develop such models independently. The approach reflects CZI’s philanthropic mission while creating network effects that could accelerate scientific progress.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-end-of-trial-and-error-how-ai-could-slash-drug-discovery-from-decades-to-years"&gt;The end of trial and error: How AI could slash drug discovery from decades to years&lt;/h2&gt;



&lt;p&gt;The potential applications extend far beyond academic research. By enabling scientists to quickly test hypotheses about gene interactions and cellular responses, rBio could significantly accelerate the early stages of drug discovery — a process that typically takes decades and costs billions of dollars.&lt;/p&gt;



&lt;p&gt;The model’s ability to predict how gene perturbations affect cellular behavior could prove particularly valuable for understanding neurodegenerative diseases like Alzheimer’s, where researchers need to identify how specific genetic changes contribute to disease progression.&lt;/p&gt;



&lt;p&gt;“Answers to these questions can shape our understanding of the gene interactions contributing to neurodegenerative diseases like Alzheimer’s,” the research paper notes. “Such knowledge could lead to earlier intervention, perhaps halting these diseases altogether someday.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-universal-cell-model-dream-integrating-every-type-of-biological-data-into-one-ai-brain"&gt;The universal cell model dream: Integrating every type of biological data into one AI brain&lt;/h2&gt;



&lt;p&gt;rBio represents the first step in CZI’s broader vision to create “universal virtual cell models” that integrate knowledge from multiple biological domains. Currently, researchers must work with separate models for different types of biological data—transcriptomics, proteomics, imaging—without easy ways to combine insights.&lt;/p&gt;



&lt;p&gt;“One of our grand challenges is building these virtual cell models and understanding cells, as I mentioned over the next couple of years, is how to integrate knowledge from all of these super powerful models of biology,” Istrate said. “The main challenge is, how do you integrate all of this knowledge into one space?”&lt;/p&gt;



&lt;p&gt;The researchers demonstrated this integration capability by training rBio models that combine multiple verification sources — TranscriptFormer for gene expression data, specialized neural networks for perturbation prediction, and knowledge databases like Gene Ontology. These combined models significantly outperformed single-source approaches.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-roadblocks-ahead-what-could-stop-ai-from-revolutionizing-biology"&gt;The roadblocks ahead: What could stop AI from revolutionizing biology&lt;/h2&gt;



&lt;p&gt;Despite its promising performance, rBio faces several technical challenges. The model’s current expertise focuses primarily on gene perturbation prediction, though the researchers indicate that any biological domain covered by TranscriptFormer could theoretically be incorporated.&lt;/p&gt;



&lt;p&gt;The team continues working on improving the user experience and implementing appropriate guardrails to prevent the model from providing answers outside its area of expertise—a common challenge in deploying large language models for specialized domains.&lt;/p&gt;



&lt;p&gt;“While rBio is ready for research, the model’s engineering team is continuing to improve the user experience, because the flexible problem-solving that makes reasoning models conversational also poses a number of challenges,” the research paper explains.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-trillion-dollar-question-how-open-source-biology-ai-could-reshape-the-pharmaceutical-industry"&gt;The trillion-dollar question: How open source biology AI could reshape the pharmaceutical industry&lt;/h2&gt;



&lt;p&gt;The development of rBio occurs against the backdrop of intensifying competition in AI-driven drug discovery. Major pharmaceutical companies and technology firms are investing billions in biological AI capabilities, recognizing the potential to transform how medicines are discovered and developed.&lt;/p&gt;



&lt;p&gt;CZI’s open-source approach could accelerate this transformation by making sophisticated tools available to the broader research community. Academic researchers, biotech startups, and even established pharmaceutical companies can now access capabilities that would otherwise require substantial internal AI development efforts.&lt;/p&gt;



&lt;p&gt;The timing proves significant as the Trump administration has proposed substantial cuts to the National Institutes of Health budget, potentially threatening public funding for biomedical research. CZI’s continued investment in biological AI infrastructure could help maintain research momentum during periods of reduced government support.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-chapter-in-the-race-against-disease"&gt;A new chapter in the race against disease&lt;/h2&gt;



&lt;p&gt;rBio’s launch marks more than just another AI breakthrough—it represents a fundamental shift in how biological research could be conducted. By demonstrating that virtual simulations can train models as effectively as expensive laboratory experiments, CZI has opened a path for researchers worldwide to accelerate their work without the traditional constraints of time, money, and physical resources.&lt;/p&gt;



&lt;p&gt;As CZI prepares to make rBio freely available through its Virtual Cell Platform, the organization continues expanding its biological AI capabilities with models like GREmLN for cancer detection and ongoing work on imaging technologies. The success of the soft verification approach could influence how other organizations train AI for scientific applications, potentially reducing dependence on experimental data while maintaining scientific rigor.&lt;/p&gt;



&lt;p&gt;For an organization that began with the audacious goal of curing all diseases by the century’s end, rBio offers something that has long eluded medical researchers: a way to ask biology’s hardest questions and get scientifically grounded answers in the time it takes to type a sentence. In a field where progress has traditionally been measured in decades, that kind of speed could make all the difference between diseases that define generations—and diseases that become distant memories.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/chan-zuckerberg-initiatives-rbio-uses-virtual-cells-to-train-ai-bypassing-lab-work/</guid><pubDate>Thu, 21 Aug 2025 18:53:02 +0000</pubDate></item><item><title>[NEW] MIT report misunderstood: Shadow AI economy booms while headlines cry failure (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The most widely cited statistic from a new MIT report has been deeply misunderstood. While headlines trumpet that “95% of generative AI pilots at companies are failing,” the report actually reveals something far more remarkable: the fastest and most successful enterprise technology adoption in corporate history is happening right under executives’ noses.&lt;/p&gt;&lt;p&gt;The study, released this week by MIT’s Project NANDA, has sparked anxiety across social media and business circles, with many interpreting it as evidence that artificial intelligence is failing to deliver on its promises. But a closer reading of the 26-page report tells a starkly different story — one of unprecedented grassroots technology adoption that has quietly revolutionized work while corporate initiatives stumble.&lt;/p&gt;&lt;p&gt;The researchers found that 90% of employees regularly use personal AI tools for work, even though only 40% of their companies have official AI subscriptions. “While only 40% of companies say they purchased an official LLM subscription, workers from over 90% of the companies we surveyed reported regular use of personal AI tools for work tasks,” the study explains. “In fact, almost every single person used an LLM in some form for their work.”&lt;/p&gt;&lt;p&gt;The MIT researchers discovered what they call a “shadow AI economy” where workers use personal ChatGPT accounts, Claude subscriptions and other consumer tools to handle significant portions of their jobs. These employees aren’t just experimenting — they’re using AI “multiples times a day every day of their weekly workload,” the study found.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This underground adoption has outpaced the early spread of email, smartphones, and cloud computing in corporate environments. A corporate lawyer quoted in the MIT report exemplified the pattern: Her organization invested $50,000 in a specialized AI contract analysis tool, yet she consistently used ChatGPT for drafting work because “the fundamental quality difference is noticeable. ChatGPT consistently produces better outputs, even though our vendor claims to use the same underlying technology.”&lt;/p&gt;



&lt;p&gt;The pattern repeats across industries. Corporate systems get described as “brittle, overengineered, or misaligned with actual workflows,” while consumer AI tools win praise for “flexibility, familiarity, and immediate utility.” As one chief information officer told researchers: “We’ve seen dozens of demos this year. Maybe one or two are genuinely useful. The rest are wrappers or science projects.”&lt;/p&gt;







&lt;p&gt;The 95% failure rate that has dominated headlines applies specifically to custom enterprise AI solutions — the expensive, bespoke systems companies commission from vendors or build internally. These tools fail because they lack what the MIT researchers call “learning capability.”&lt;/p&gt;



&lt;p&gt;Most corporate AI systems “do not retain feedback, adapt to context, or improve over time,” the study found. Users complained that enterprise tools “don’t learn from our feedback” and require “too much manual context required each time.”&lt;/p&gt;



&lt;p&gt;Consumer tools like ChatGPT succeed because they feel responsive and flexible, even though they reset with each conversation. Enterprise tools feel rigid and static, requiring extensive setup for each use.&lt;/p&gt;



&lt;p&gt;The learning gap creates a strange hierarchy in user preferences. For quick tasks like emails and basic analysis, 70% of workers prefer AI over human colleagues. But for complex, high-stakes work, 90% still want humans. The dividing line isn’t intelligence — it’s memory and adaptability.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015927" height="356" src="https://venturebeat.com/wp-content/uploads/2025/08/image-3-1.png" width="772" /&gt;&lt;figcaption class="wp-element-caption"&gt;General-purpose A.I. tools like ChatGPT reach production 40% of the time, while task-specific enterprise tools succeed only 5% of the time. (Credit: MIT)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-the-hidden-billion-dollar-productivity-boom-happening-under-it-s-radar"&gt;The hidden billion-dollar productivity boom happening under IT’s radar&lt;/h2&gt;



&lt;p&gt;Far from showing AI failure, the shadow economy reveals massive productivity gains that don’t appear in corporate metrics. Workers have solved integration challenges that stymie official initiatives, proving AI works when implemented correctly.&lt;/p&gt;



&lt;p&gt;“This shadow economy demonstrates that individuals can successfully cross the GenAI Divide when given access to flexible, responsive tools,” the report explains. Some companies have started paying attention: “Forward-thinking organizations are beginning to bridge this gap by learning from shadow usage and analyzing which personal tools deliver value before procuring enterprise alternatives.”&lt;/p&gt;



&lt;p&gt;The productivity gains are real and measurable, just hidden from traditional corporate accounting. Workers automate routine tasks, accelerate research, and streamline communication — all while their companies’ official AI budgets produce little return.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015928" height="325" src="https://venturebeat.com/wp-content/uploads/2025/08/image-8.png" width="793" /&gt;&lt;figcaption class="wp-element-caption"&gt;Workers prefer A.I. for routine tasks like emails but still trust humans for complex, multi-week projects. (Credit: MIT)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-why-buying-beats-building-external-partnerships-succeed-twice-as-often"&gt;Why buying beats building: external partnerships succeed twice as often&lt;/h2&gt;



&lt;p&gt;Another finding challenges conventional tech wisdom: companies should stop trying to build AI internally. External partnerships with AI vendors reached deployment 67% of the time, compared to 33% for internally built tools.&lt;/p&gt;



&lt;p&gt;The most successful implementations came from organizations that “treated AI startups less like software vendors and more like business service providers,” holding them to operational outcomes rather than technical benchmarks. These companies demanded deep customization and continuous improvement rather than flashy demos.&lt;/p&gt;



&lt;p&gt;“Despite conventional wisdom that enterprises resist training AI systems, most teams in our interviews expressed willingness to do so, provided the benefits were clear and guardrails were in place,” the researchers found. The key was partnership, not just purchasing.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-seven-industries-avoiding-disruption-are-actually-being-smart"&gt;Seven industries avoiding disruption are actually being smart&lt;/h2&gt;



&lt;p&gt;The MIT report found that only technology and media sectors show meaningful structural change from AI, while seven major industries — including healthcare, finance, and manufacturing — show “significant pilot activity but little to no structural change.”&lt;/p&gt;



&lt;p&gt;This measured approach isn’t a failure — it’s wisdom. Industries avoiding disruption are being thoughtful about implementation rather than rushing into chaotic change. In healthcare and energy, “most executives report no current or anticipated hiring reductions over the next five years.”&lt;/p&gt;



&lt;p&gt;Technology and media move faster because they can absorb more risk. More than 80% of executives in these sectors anticipate reduced hiring within 24 months. Other industries are proving that successful AI adoption doesn’t require dramatic upheaval.&lt;/p&gt;







&lt;p&gt;Corporate attention flows heavily toward sales and marketing applications, which captured about 50% of AI budgets. But the highest returns come from unglamorous back-office automation that receives little attention.&lt;/p&gt;



&lt;p&gt;“Some of the most dramatic cost savings we documented came from back-office automation,” the researchers found. Companies saved $2-10 million annually in customer service and document processing by eliminating business process outsourcing contracts, and cut external creative costs by 30%.&lt;/p&gt;



&lt;p&gt;These gains came “without material workforce reduction,” the study notes. “Tools accelerated work, but did not change team structures or budgets. Instead, ROI emerged from reduced external spend, eliminating BPO contracts, cutting agency fees, and replacing expensive consultants with AI-powered internal capabilities.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015929" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image-5.png?w=623" width="623" /&gt;&lt;figcaption class="wp-element-caption"&gt;Companies invest heavily in sales and marketing A.I. applications, but the highest returns often come from back-office automation. (Credit: MIT)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-the-ai-revolution-is-succeeding-one-employee-at-a-time"&gt;The AI revolution is succeeding — one employee at a time&lt;/h2&gt;



&lt;p&gt;The MIT findings don’t show AI failing. They show AI succeeding so well that employees have moved ahead of their employers. The technology works; corporate procurement doesn’t.&lt;/p&gt;



&lt;p&gt;The researchers identified organizations “crossing the GenAI Divide” by focusing on tools that integrate deeply while adapting over time. “The shift from building to buying, combined with the rise of prosumer adoption and the emergence of agentic capabilities, creates unprecedented opportunities for vendors who can deliver learning-capable, deeply integrated AI systems.”&lt;/p&gt;



&lt;p&gt;The 95% of enterprise AI pilots that fail point toward a solution: learn from the 90% of workers who have already figured out how to make AI work. As one manufacturing executive told researchers: “We’re processing some contracts faster, but that’s all that has changed.”&lt;/p&gt;



&lt;p&gt;That executive missed the bigger picture. Processing contracts faster — multiplied across millions of workers and thousands of daily tasks — is exactly the kind of gradual, sustainable productivity improvement that defines successful technology adoption. The AI revolution isn’t failing. It’s quietly succeeding, one ChatGPT conversation at a time.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The most widely cited statistic from a new MIT report has been deeply misunderstood. While headlines trumpet that “95% of generative AI pilots at companies are failing,” the report actually reveals something far more remarkable: the fastest and most successful enterprise technology adoption in corporate history is happening right under executives’ noses.&lt;/p&gt;&lt;p&gt;The study, released this week by MIT’s Project NANDA, has sparked anxiety across social media and business circles, with many interpreting it as evidence that artificial intelligence is failing to deliver on its promises. But a closer reading of the 26-page report tells a starkly different story — one of unprecedented grassroots technology adoption that has quietly revolutionized work while corporate initiatives stumble.&lt;/p&gt;&lt;p&gt;The researchers found that 90% of employees regularly use personal AI tools for work, even though only 40% of their companies have official AI subscriptions. “While only 40% of companies say they purchased an official LLM subscription, workers from over 90% of the companies we surveyed reported regular use of personal AI tools for work tasks,” the study explains. “In fact, almost every single person used an LLM in some form for their work.”&lt;/p&gt;&lt;p&gt;The MIT researchers discovered what they call a “shadow AI economy” where workers use personal ChatGPT accounts, Claude subscriptions and other consumer tools to handle significant portions of their jobs. These employees aren’t just experimenting — they’re using AI “multiples times a day every day of their weekly workload,” the study found.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;This underground adoption has outpaced the early spread of email, smartphones, and cloud computing in corporate environments. A corporate lawyer quoted in the MIT report exemplified the pattern: Her organization invested $50,000 in a specialized AI contract analysis tool, yet she consistently used ChatGPT for drafting work because “the fundamental quality difference is noticeable. ChatGPT consistently produces better outputs, even though our vendor claims to use the same underlying technology.”&lt;/p&gt;



&lt;p&gt;The pattern repeats across industries. Corporate systems get described as “brittle, overengineered, or misaligned with actual workflows,” while consumer AI tools win praise for “flexibility, familiarity, and immediate utility.” As one chief information officer told researchers: “We’ve seen dozens of demos this year. Maybe one or two are genuinely useful. The rest are wrappers or science projects.”&lt;/p&gt;







&lt;p&gt;The 95% failure rate that has dominated headlines applies specifically to custom enterprise AI solutions — the expensive, bespoke systems companies commission from vendors or build internally. These tools fail because they lack what the MIT researchers call “learning capability.”&lt;/p&gt;



&lt;p&gt;Most corporate AI systems “do not retain feedback, adapt to context, or improve over time,” the study found. Users complained that enterprise tools “don’t learn from our feedback” and require “too much manual context required each time.”&lt;/p&gt;



&lt;p&gt;Consumer tools like ChatGPT succeed because they feel responsive and flexible, even though they reset with each conversation. Enterprise tools feel rigid and static, requiring extensive setup for each use.&lt;/p&gt;



&lt;p&gt;The learning gap creates a strange hierarchy in user preferences. For quick tasks like emails and basic analysis, 70% of workers prefer AI over human colleagues. But for complex, high-stakes work, 90% still want humans. The dividing line isn’t intelligence — it’s memory and adaptability.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015927" height="356" src="https://venturebeat.com/wp-content/uploads/2025/08/image-3-1.png" width="772" /&gt;&lt;figcaption class="wp-element-caption"&gt;General-purpose A.I. tools like ChatGPT reach production 40% of the time, while task-specific enterprise tools succeed only 5% of the time. (Credit: MIT)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-the-hidden-billion-dollar-productivity-boom-happening-under-it-s-radar"&gt;The hidden billion-dollar productivity boom happening under IT’s radar&lt;/h2&gt;



&lt;p&gt;Far from showing AI failure, the shadow economy reveals massive productivity gains that don’t appear in corporate metrics. Workers have solved integration challenges that stymie official initiatives, proving AI works when implemented correctly.&lt;/p&gt;



&lt;p&gt;“This shadow economy demonstrates that individuals can successfully cross the GenAI Divide when given access to flexible, responsive tools,” the report explains. Some companies have started paying attention: “Forward-thinking organizations are beginning to bridge this gap by learning from shadow usage and analyzing which personal tools deliver value before procuring enterprise alternatives.”&lt;/p&gt;



&lt;p&gt;The productivity gains are real and measurable, just hidden from traditional corporate accounting. Workers automate routine tasks, accelerate research, and streamline communication — all while their companies’ official AI budgets produce little return.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3015928" height="325" src="https://venturebeat.com/wp-content/uploads/2025/08/image-8.png" width="793" /&gt;&lt;figcaption class="wp-element-caption"&gt;Workers prefer A.I. for routine tasks like emails but still trust humans for complex, multi-week projects. (Credit: MIT)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-why-buying-beats-building-external-partnerships-succeed-twice-as-often"&gt;Why buying beats building: external partnerships succeed twice as often&lt;/h2&gt;



&lt;p&gt;Another finding challenges conventional tech wisdom: companies should stop trying to build AI internally. External partnerships with AI vendors reached deployment 67% of the time, compared to 33% for internally built tools.&lt;/p&gt;



&lt;p&gt;The most successful implementations came from organizations that “treated AI startups less like software vendors and more like business service providers,” holding them to operational outcomes rather than technical benchmarks. These companies demanded deep customization and continuous improvement rather than flashy demos.&lt;/p&gt;



&lt;p&gt;“Despite conventional wisdom that enterprises resist training AI systems, most teams in our interviews expressed willingness to do so, provided the benefits were clear and guardrails were in place,” the researchers found. The key was partnership, not just purchasing.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-seven-industries-avoiding-disruption-are-actually-being-smart"&gt;Seven industries avoiding disruption are actually being smart&lt;/h2&gt;



&lt;p&gt;The MIT report found that only technology and media sectors show meaningful structural change from AI, while seven major industries — including healthcare, finance, and manufacturing — show “significant pilot activity but little to no structural change.”&lt;/p&gt;



&lt;p&gt;This measured approach isn’t a failure — it’s wisdom. Industries avoiding disruption are being thoughtful about implementation rather than rushing into chaotic change. In healthcare and energy, “most executives report no current or anticipated hiring reductions over the next five years.”&lt;/p&gt;



&lt;p&gt;Technology and media move faster because they can absorb more risk. More than 80% of executives in these sectors anticipate reduced hiring within 24 months. Other industries are proving that successful AI adoption doesn’t require dramatic upheaval.&lt;/p&gt;







&lt;p&gt;Corporate attention flows heavily toward sales and marketing applications, which captured about 50% of AI budgets. But the highest returns come from unglamorous back-office automation that receives little attention.&lt;/p&gt;



&lt;p&gt;“Some of the most dramatic cost savings we documented came from back-office automation,” the researchers found. Companies saved $2-10 million annually in customer service and document processing by eliminating business process outsourcing contracts, and cut external creative costs by 30%.&lt;/p&gt;



&lt;p&gt;These gains came “without material workforce reduction,” the study notes. “Tools accelerated work, but did not change team structures or budgets. Instead, ROI emerged from reduced external spend, eliminating BPO contracts, cutting agency fees, and replacing expensive consultants with AI-powered internal capabilities.”&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015929" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image-5.png?w=623" width="623" /&gt;&lt;figcaption class="wp-element-caption"&gt;Companies invest heavily in sales and marketing A.I. applications, but the highest returns often come from back-office automation. (Credit: MIT)&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-the-ai-revolution-is-succeeding-one-employee-at-a-time"&gt;The AI revolution is succeeding — one employee at a time&lt;/h2&gt;



&lt;p&gt;The MIT findings don’t show AI failing. They show AI succeeding so well that employees have moved ahead of their employers. The technology works; corporate procurement doesn’t.&lt;/p&gt;



&lt;p&gt;The researchers identified organizations “crossing the GenAI Divide” by focusing on tools that integrate deeply while adapting over time. “The shift from building to buying, combined with the rise of prosumer adoption and the emergence of agentic capabilities, creates unprecedented opportunities for vendors who can deliver learning-capable, deeply integrated AI systems.”&lt;/p&gt;



&lt;p&gt;The 95% of enterprise AI pilots that fail point toward a solution: learn from the 90% of workers who have already figured out how to make AI work. As one manufacturing executive told researchers: “We’re processing some contracts faster, but that’s all that has changed.”&lt;/p&gt;



&lt;p&gt;That executive missed the bigger picture. Processing contracts faster — multiplied across millions of workers and thousands of daily tasks — is exactly the kind of gradual, sustainable productivity improvement that defines successful technology adoption. The AI revolution isn’t failing. It’s quietly succeeding, one ChatGPT conversation at a time.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure/</guid><pubDate>Thu, 21 Aug 2025 20:21:41 +0000</pubDate></item><item><title>[NEW] Inside Walmart’s AI security stack: How a startup mentality is hardening enterprise-scale defense (AI News | VentureBeat)</title><link>https://venturebeat.com/security/exclusive-walmarts-ciso-is-rebuilding-identity-security-for-ai-age/</link><description>&lt;p&gt;VentureBeat recently sat down (virtually) with Jerry R. Geisler III, Executive Vice President and Chief Information Security Officer at Walmart Inc., to gain insights into the cybersecurity challenges the world’s largest retailer faces as AI becomes increasingly autonomous.&lt;/p&gt;&lt;p&gt;We talked about securing agentic AI systems, modernizing identity management and the critical lessons learned from building Element AI, Walmart’s centralized AI platform. Geisler provided a refreshingly candid view of how the company is tackling unprecedented security challenges, from defending against AI-enhanced cyber threats to managing security across a massive hybrid multi-cloud infrastructure. His startup mindset approach to rebuilding identity and access management systems offers valuable lessons for enterprises of all sizes.&lt;/p&gt;&lt;p&gt;Leading security for a company operating at Walmart’s scale across Google Cloud, Azure and private cloud environments, Geisler brings unique insights into implementing Zero Trust architectures and building what he calls “velocity with governance,” enabling rapid AI innovation within a trusted security framework. The architectural decisions made while developing Element AI have shaped Walmart’s entire approach to centralizing emerging AI technologies.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;VentureBeat: As generative and agentic AI become increasingly autonomous, how will your existing governance and security guardrails evolve to address emerging threats and unintended model behaviors?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Jerry R. Geisler III:&lt;/strong&gt; The adoption of agentic AI introduces entirely new security threats that bypass traditional controls. These risks span data exfiltration, autonomous misuse of APIs, and covert cross-agent collusion, all of which could disrupt enterprise operations or violate regulatory mandates. Our strategy is to build robust, proactive security controls using advanced AI Security Posture Management (AI-SPM), ensuring continuous risk monitoring, data protection, regulatory compliance and operational trust.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Given the limitations of traditional RBAC in dynamic AI settings, how is Walmart refining its identity management and Zero Trust architectures to provide granular, context-sensitive data access?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; An environment of our size requires a tailor-made approach, and interestingly enough, a startup mindset. Our team often takes a step back and asks, “If we were a new company and building from ground zero, what would we build?” Identity &amp;amp; access management (IAM) has gone through many iterations over the past 30+ years, and our main focus is how to modernize our IAM stack to simplify it. While related to yet different from Zero Trust, our principle of least privilege won’t change.&lt;/p&gt;



&lt;p&gt;We’re encouraged by the major evolution and adoption of protocols like MCP and A2A, as they recognize the security challenges we face and are actively working on implementing granular, context-sensitive access controls. These protocols enable real-time access decisions based on identity, data sensitivity, and risk, using short-lived, verifiable credentials. This ensures that every agent, tool, and request is evaluated continuously, embodying the principles of Zero Trust.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: How specifically does Walmart’s extensive hybrid multi-cloud infrastructure (Google, Azure, private cloud) shape your approach to Zero Trust network segmentation and micro-segmentation for AI workloads?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Segmentation is based on identity rather than network location. Access policies follow workloads consistently across both cloud and on-premises environments. With the advancement of protocols like MCP and A2A, service edge enforcement is becoming standardized, ensuring that zero trust principles are applied uniformly.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: With AI lowering barriers for advanced threats such as sophisticated phishing, what AI-driven defenses is Walmart actively deploying to detect and mitigate these evolving threats proactively?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; At Walmart, we’re deeply focused on staying ahead of the threat curve. This is especially true as AI reshapes the cybersecurity landscape. Adversaries are increasingly using generative AI to craft highly convincing phishing campaigns, but we’re leveraging the same class of technology in adversary simulation campaigns to proactively build resilience against that attack vector.&lt;/p&gt;



&lt;p&gt;We’ve integrated advanced machine learning models across our security stack to identify behavioral anomalies and to detect phishing attempts. Beyond detection, we’re proactively using generative AI to simulate attack scenarios and pressure-test our defenses by integrating AI extensively as part of our red-teaming at scale.&lt;/p&gt;



&lt;p&gt;By pairing people and technology together in these ways, we help ensure our associates and customers stay protected as the digital landscape evolves.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Given Walmart’s extensive use of open-source AI models in Element AI, what unique cybersecurity challenges have you identified, and how is your security strategy evolving to address them at enterprise scale?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Segmentation is based on identity rather than network location. Access policies follow workloads consistently across both cloud and on-premises environments. With the advancement of protocols like MCP and A2A, service edge enforcement is becoming standardized, ensuring that zero trust principles are applied uniformly.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Considering Walmart’s scale and continuous operations, what advanced automation or rapid-response measures are you implementing to manage simultaneous cybersecurity incidents across your global infrastructure?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Operating at Walmart’s scale means security must be both fast and frictionless. To achieve this, we’ve embedded intelligent automation into layers of our incident response program. Using SOAR platforms, we orchestrate rapid response workflows across geographies. This allows us to contain threats rapidly.&lt;/p&gt;



&lt;p&gt;We also apply extensive automation to continuously assess risk and prioritize response actions based on risk. That lets us focus our resources where they matter most.&lt;/p&gt;



&lt;p&gt;By bringing talented associates together with rapid automation and context to help make quick decisions, we are able to execute upon our commitment to delivering security at speed and scale for Walmart.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: What initiatives or strategic changes is Walmart pursuing to attract, train, and retain cybersecurity talent equipped for the rapidly evolving AI and threat landscape?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Our Live Better U (LBU) program offers low- or no-cost education so associates can pursue degrees and certifications in cybersecurity and related IT fields, making it easier to associates from all backgrounds to upskill. Coursework is designed to provide hands-on, real-world skills that are directly applicable to Walmart’s infosecurity needs.&lt;/p&gt;



&lt;p&gt;We host our annual SparkCon (formerly known as Sp4rkCon) that coordinates talks and Q&amp;amp;As with renowned professionals for sharing wisdom and proven strategies. This event also explores the latest trends, techniques, technologies and threats in cybersecurity while offering opportunities for attendees to connect and build valuable relationships to further their careers.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Reflecting on your experiences developing Element AI, what critical cybersecurity or architectural lessons have emerged that will guide your future decisions about when and how extensively to centralize emerging AI technologies?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; That’s a critical question, as our architectural choices today will define our risk posture for years to come. Reflecting on our experience in developing a centralized AI platform, two major lessons have emerged that now guide our strategy.&lt;/p&gt;



&lt;p&gt;First, we learned that centralization is a powerful enabler of ‘velocity with governance.’ By creating a single, paved road for AI development, we dramatically lower the complexity for our data scientists. More importantly, from a security standpoint, it gives us a unified control plane. We can embed security from the start, ensuring consistency in how data is handled, models are vetted, and outputs are monitored. It allows innovation to happen quickly, within a framework we trust.&lt;/p&gt;



&lt;p&gt;Second, it allows for ‘concentrated defense and expertise.’ The threat landscape for AI is evolving at an incredible pace. Instead of diffusing our limited AI security talent across dozens of disparate projects, a centralized architecture allows us to focus our best people and our most robust controls at the most critical point. We can implement and fine-tune sophisticated defenses like context-aware access controls, advanced prompt monitoring and data exfiltration prevention, and have that protection instantly cover our use cases.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;VentureBeat recently sat down (virtually) with Jerry R. Geisler III, Executive Vice President and Chief Information Security Officer at Walmart Inc., to gain insights into the cybersecurity challenges the world’s largest retailer faces as AI becomes increasingly autonomous.&lt;/p&gt;&lt;p&gt;We talked about securing agentic AI systems, modernizing identity management and the critical lessons learned from building Element AI, Walmart’s centralized AI platform. Geisler provided a refreshingly candid view of how the company is tackling unprecedented security challenges, from defending against AI-enhanced cyber threats to managing security across a massive hybrid multi-cloud infrastructure. His startup mindset approach to rebuilding identity and access management systems offers valuable lessons for enterprises of all sizes.&lt;/p&gt;&lt;p&gt;Leading security for a company operating at Walmart’s scale across Google Cloud, Azure and private cloud environments, Geisler brings unique insights into implementing Zero Trust architectures and building what he calls “velocity with governance,” enabling rapid AI innovation within a trusted security framework. The architectural decisions made while developing Element AI have shaped Walmart’s entire approach to centralizing emerging AI technologies.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;VentureBeat: As generative and agentic AI become increasingly autonomous, how will your existing governance and security guardrails evolve to address emerging threats and unintended model behaviors?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Jerry R. Geisler III:&lt;/strong&gt; The adoption of agentic AI introduces entirely new security threats that bypass traditional controls. These risks span data exfiltration, autonomous misuse of APIs, and covert cross-agent collusion, all of which could disrupt enterprise operations or violate regulatory mandates. Our strategy is to build robust, proactive security controls using advanced AI Security Posture Management (AI-SPM), ensuring continuous risk monitoring, data protection, regulatory compliance and operational trust.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Given the limitations of traditional RBAC in dynamic AI settings, how is Walmart refining its identity management and Zero Trust architectures to provide granular, context-sensitive data access?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; An environment of our size requires a tailor-made approach, and interestingly enough, a startup mindset. Our team often takes a step back and asks, “If we were a new company and building from ground zero, what would we build?” Identity &amp;amp; access management (IAM) has gone through many iterations over the past 30+ years, and our main focus is how to modernize our IAM stack to simplify it. While related to yet different from Zero Trust, our principle of least privilege won’t change.&lt;/p&gt;



&lt;p&gt;We’re encouraged by the major evolution and adoption of protocols like MCP and A2A, as they recognize the security challenges we face and are actively working on implementing granular, context-sensitive access controls. These protocols enable real-time access decisions based on identity, data sensitivity, and risk, using short-lived, verifiable credentials. This ensures that every agent, tool, and request is evaluated continuously, embodying the principles of Zero Trust.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: How specifically does Walmart’s extensive hybrid multi-cloud infrastructure (Google, Azure, private cloud) shape your approach to Zero Trust network segmentation and micro-segmentation for AI workloads?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Segmentation is based on identity rather than network location. Access policies follow workloads consistently across both cloud and on-premises environments. With the advancement of protocols like MCP and A2A, service edge enforcement is becoming standardized, ensuring that zero trust principles are applied uniformly.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: With AI lowering barriers for advanced threats such as sophisticated phishing, what AI-driven defenses is Walmart actively deploying to detect and mitigate these evolving threats proactively?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; At Walmart, we’re deeply focused on staying ahead of the threat curve. This is especially true as AI reshapes the cybersecurity landscape. Adversaries are increasingly using generative AI to craft highly convincing phishing campaigns, but we’re leveraging the same class of technology in adversary simulation campaigns to proactively build resilience against that attack vector.&lt;/p&gt;



&lt;p&gt;We’ve integrated advanced machine learning models across our security stack to identify behavioral anomalies and to detect phishing attempts. Beyond detection, we’re proactively using generative AI to simulate attack scenarios and pressure-test our defenses by integrating AI extensively as part of our red-teaming at scale.&lt;/p&gt;



&lt;p&gt;By pairing people and technology together in these ways, we help ensure our associates and customers stay protected as the digital landscape evolves.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Given Walmart’s extensive use of open-source AI models in Element AI, what unique cybersecurity challenges have you identified, and how is your security strategy evolving to address them at enterprise scale?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Segmentation is based on identity rather than network location. Access policies follow workloads consistently across both cloud and on-premises environments. With the advancement of protocols like MCP and A2A, service edge enforcement is becoming standardized, ensuring that zero trust principles are applied uniformly.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Considering Walmart’s scale and continuous operations, what advanced automation or rapid-response measures are you implementing to manage simultaneous cybersecurity incidents across your global infrastructure?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Operating at Walmart’s scale means security must be both fast and frictionless. To achieve this, we’ve embedded intelligent automation into layers of our incident response program. Using SOAR platforms, we orchestrate rapid response workflows across geographies. This allows us to contain threats rapidly.&lt;/p&gt;



&lt;p&gt;We also apply extensive automation to continuously assess risk and prioritize response actions based on risk. That lets us focus our resources where they matter most.&lt;/p&gt;



&lt;p&gt;By bringing talented associates together with rapid automation and context to help make quick decisions, we are able to execute upon our commitment to delivering security at speed and scale for Walmart.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: What initiatives or strategic changes is Walmart pursuing to attract, train, and retain cybersecurity talent equipped for the rapidly evolving AI and threat landscape?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; Our Live Better U (LBU) program offers low- or no-cost education so associates can pursue degrees and certifications in cybersecurity and related IT fields, making it easier to associates from all backgrounds to upskill. Coursework is designed to provide hands-on, real-world skills that are directly applicable to Walmart’s infosecurity needs.&lt;/p&gt;



&lt;p&gt;We host our annual SparkCon (formerly known as Sp4rkCon) that coordinates talks and Q&amp;amp;As with renowned professionals for sharing wisdom and proven strategies. This event also explores the latest trends, techniques, technologies and threats in cybersecurity while offering opportunities for attendees to connect and build valuable relationships to further their careers.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;VB: Reflecting on your experiences developing Element AI, what critical cybersecurity or architectural lessons have emerged that will guide your future decisions about when and how extensively to centralize emerging AI technologies?&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Geisler:&lt;/strong&gt; That’s a critical question, as our architectural choices today will define our risk posture for years to come. Reflecting on our experience in developing a centralized AI platform, two major lessons have emerged that now guide our strategy.&lt;/p&gt;



&lt;p&gt;First, we learned that centralization is a powerful enabler of ‘velocity with governance.’ By creating a single, paved road for AI development, we dramatically lower the complexity for our data scientists. More importantly, from a security standpoint, it gives us a unified control plane. We can embed security from the start, ensuring consistency in how data is handled, models are vetted, and outputs are monitored. It allows innovation to happen quickly, within a framework we trust.&lt;/p&gt;



&lt;p&gt;Second, it allows for ‘concentrated defense and expertise.’ The threat landscape for AI is evolving at an incredible pace. Instead of diffusing our limited AI security talent across dozens of disparate projects, a centralized architecture allows us to focus our best people and our most robust controls at the most critical point. We can implement and fine-tune sophisticated defenses like context-aware access controls, advanced prompt monitoring and data exfiltration prevention, and have that protection instantly cover our use cases.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/exclusive-walmarts-ciso-is-rebuilding-identity-security-for-ai-age/</guid><pubDate>Thu, 21 Aug 2025 21:28:06 +0000</pubDate></item><item><title>[NEW] Is the AI bubble about to pop? Sam Altman is prepared either way. (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/08/sam-altman-calls-ai-a-bubble-while-seeking-500b-valuation-for-openai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "Someone will lose a phenomenal amount of money," says CEO while fundraising at record prices.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="https://www.gettyimages.com/detail/news-photo/sam-altman-chief-executive-officer-of-openai-inc-at-station-news-photo/2198353376" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2198353376-640x427.jpg" width="640" /&gt;
                  &lt;img alt="https://www.gettyimages.com/detail/news-photo/sam-altman-chief-executive-officer-of-openai-inc-at-station-news-photo/2198353376" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2198353376-scaled-1152x648-1739457486.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sam Altman during the AI Action Summit in Paris, France, on Tuesday, Feb. 11, 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last Thursday, OpenAI CEO Sam Altman told reporters at a private dinner that investors are overexcited about AI models. "Someone" will lose a "phenomenal amount of money," he said, according to The Verge. The statement came as his company negotiates a secondary share sale at a $500 billion valuation—up from $300 billion just months earlier.&lt;/p&gt;
&lt;p&gt;"Are we in a phase where investors as a whole are overexcited about AI? My opinion is yes," Altman told the journalists, comparing the current market to the dot-com crash of the 1990s. Wired reported that he also predicted his company will spend "trillions of dollars on data center construction in the not very distant future" and that ChatGPT will soon serve "billions of people a day."&lt;/p&gt;
&lt;p&gt;For context, Facebook serves about 3 billion monthly active users. Altman's projection would require ChatGPT to reach nearly half the world's population as daily users (not monthly, like Facebook), which is an extraordinarily optimistic outlook.&lt;/p&gt;
&lt;p&gt;Altman's bubble comments happened to land just before Fortune covered new MIT research showing widespread enterprise AI failures. The study, titled "GenAI Divide: State of AI in Business 2025," found that 95 percent of enterprise AI pilots fail to deliver rapid revenue acceleration. The research analyzed 300 public AI deployments, surveyed 350 employees, and included 150 interviews with business leaders, although Financial Times columnist Robert Armstrong noted this week that the MIT report "reads like something given away on the 'research' page of a large consultancy." Its conclusions are fairly obvious, he said: People like ChatGPT for basic tasks and hate complicated enterprise systems, and companies that try to build their own AI usually fail.&lt;/p&gt;
&lt;p&gt;The study attributes these failures to implementation problems rather than model quality. "The core issue? Not the quality of the AI models, but the 'learning gap' for both tools and organizations," Fortune wrote about the study. Purchased AI tools succeed 67 percent of the time, while internally built systems succeed only one-third as often. This isn't necessarily an indictment of AI technology as a whole—it's potentially an indictment of corporate IT departments thinking they can out-engineer existing applications from AI service providers like OpenAI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, the coincidence between Altman's statement and the MIT report reportedly spooked tech stock investors earlier in the week, who have already been watching AI valuations climb to extraordinary heights. Palantir trades at 280 times forward earnings. During the dot-com peak, ratios of 30 to 40 times earnings marked bubble territory.&lt;/p&gt;
&lt;p&gt;The apparent contradiction in Altman's overall message is notable. This isn't how you'd expect a tech executive to talk when they believe their industry faces imminent collapse. While warning about a bubble, he's simultaneously seeking a valuation that would make OpenAI worth more than Walmart or ExxonMobil—companies with actual profits. OpenAI hit $1 billion in monthly revenue in July but is reportedly heading toward a $5 billion annual loss. So what's going on here?&lt;/p&gt;
&lt;p&gt;Looking at Altman's statements over time reveals a potential multi-level strategy. He likes to talk big. In February 2024, he reportedly sought an audacious $5 trillion–7 trillion for AI chip fabrication—larger than the entire semiconductor industry—effectively normalizing astronomical numbers in AI discussions.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;By August 2025, while warning of a bubble where someone will lose a "phenomenal amount of money," he casually mentioned that OpenAI would "spend trillions on datacenter construction" and serve "billions daily." This creates urgency while potentially insulating OpenAI from criticism—acknowledging the bubble exists while positioning his company's infrastructure spending as different and necessary. When economists raised concerns, Altman dismissed them by saying, "Let us do our thing," framing trillion-dollar investments as inevitable for human progress while making OpenAI's $500 billion valuation seem almost reasonable by comparison.&lt;/p&gt;
&lt;p&gt;This dual messaging—catastrophic warnings paired with trillion-dollar ambitions—might seem contradictory, but it makes more sense when you consider the unique structure of today's AI market, which is absolutely flush with cash.&lt;/p&gt;
&lt;h2&gt;A different kind of bubble&lt;/h2&gt;
&lt;p&gt;The current AI investment cycle differs from previous technology bubbles. Unlike dot-com era startups that burned through venture capital with no path to profitability, the largest AI investors—Microsoft, Google, Meta, and Amazon—generate hundreds of billions of dollars in annual profits from their core businesses.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Microsoft alone plans to spend $80 billion on AI data centers this fiscal year. These companies can potentially sustain losses from AI development for years without facing the cash crises that typically trigger bubble collapses.&lt;/p&gt;
&lt;p&gt;"Back then, you had a lot of over-leveraged situations. You didn't have a lot of companies that had earnings," Citi's Rob Rowe said on CNBC. "Here you're talking about companies that have very solid earnings, very strong cash flow."&lt;/p&gt;
&lt;p&gt;The structural difference matters. When the dot-com bubble burst in 2000, hundreds of companies vanished overnight because they ran out of money. Today's AI investors can absorb losses that would have killed entire companies two decades ago. If there is a bubble, it might deflate gradually over years rather than pop in a sudden crash.&lt;/p&gt;
&lt;p&gt;After all, deep pockets don't guarantee product success. OpenAI's CEO recently acknowledged problems with the messy GPT-5 launch, which others are using as evidence that the AI industry is in trouble. But the AI market is now much larger than just OpenAI, with Google, Meta, and Anthropic among those fiercely competing for customers.&lt;/p&gt;
&lt;p&gt;Despite the struggles with AI in enterprise and his own bubble warnings, Altman remains bullish on AI's long-term trajectory. The technology continues to improve despite its drawbacks and misapplications, and major companies keep increasing their investments rather than pulling back. Whether current valuations make sense in the short term is one question; whether AI will eventually transform the economy is another entirely.&lt;/p&gt;
&lt;p&gt;"I do think some investors are likely to get very burnt here, and that sucks. And I don't want to minimize that," Altman told the reporters last week. "But on the whole, it is my belief that... the value created by AI for society will be tremendous."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "Someone will lose a phenomenal amount of money," says CEO while fundraising at record prices.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="https://www.gettyimages.com/detail/news-photo/sam-altman-chief-executive-officer-of-openai-inc-at-station-news-photo/2198353376" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2198353376-640x427.jpg" width="640" /&gt;
                  &lt;img alt="https://www.gettyimages.com/detail/news-photo/sam-altman-chief-executive-officer-of-openai-inc-at-station-news-photo/2198353376" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/02/GettyImages-2198353376-scaled-1152x648-1739457486.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Sam Altman during the AI Action Summit in Paris, France, on Tuesday, Feb. 11, 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last Thursday, OpenAI CEO Sam Altman told reporters at a private dinner that investors are overexcited about AI models. "Someone" will lose a "phenomenal amount of money," he said, according to The Verge. The statement came as his company negotiates a secondary share sale at a $500 billion valuation—up from $300 billion just months earlier.&lt;/p&gt;
&lt;p&gt;"Are we in a phase where investors as a whole are overexcited about AI? My opinion is yes," Altman told the journalists, comparing the current market to the dot-com crash of the 1990s. Wired reported that he also predicted his company will spend "trillions of dollars on data center construction in the not very distant future" and that ChatGPT will soon serve "billions of people a day."&lt;/p&gt;
&lt;p&gt;For context, Facebook serves about 3 billion monthly active users. Altman's projection would require ChatGPT to reach nearly half the world's population as daily users (not monthly, like Facebook), which is an extraordinarily optimistic outlook.&lt;/p&gt;
&lt;p&gt;Altman's bubble comments happened to land just before Fortune covered new MIT research showing widespread enterprise AI failures. The study, titled "GenAI Divide: State of AI in Business 2025," found that 95 percent of enterprise AI pilots fail to deliver rapid revenue acceleration. The research analyzed 300 public AI deployments, surveyed 350 employees, and included 150 interviews with business leaders, although Financial Times columnist Robert Armstrong noted this week that the MIT report "reads like something given away on the 'research' page of a large consultancy." Its conclusions are fairly obvious, he said: People like ChatGPT for basic tasks and hate complicated enterprise systems, and companies that try to build their own AI usually fail.&lt;/p&gt;
&lt;p&gt;The study attributes these failures to implementation problems rather than model quality. "The core issue? Not the quality of the AI models, but the 'learning gap' for both tools and organizations," Fortune wrote about the study. Purchased AI tools succeed 67 percent of the time, while internally built systems succeed only one-third as often. This isn't necessarily an indictment of AI technology as a whole—it's potentially an indictment of corporate IT departments thinking they can out-engineer existing applications from AI service providers like OpenAI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Still, the coincidence between Altman's statement and the MIT report reportedly spooked tech stock investors earlier in the week, who have already been watching AI valuations climb to extraordinary heights. Palantir trades at 280 times forward earnings. During the dot-com peak, ratios of 30 to 40 times earnings marked bubble territory.&lt;/p&gt;
&lt;p&gt;The apparent contradiction in Altman's overall message is notable. This isn't how you'd expect a tech executive to talk when they believe their industry faces imminent collapse. While warning about a bubble, he's simultaneously seeking a valuation that would make OpenAI worth more than Walmart or ExxonMobil—companies with actual profits. OpenAI hit $1 billion in monthly revenue in July but is reportedly heading toward a $5 billion annual loss. So what's going on here?&lt;/p&gt;
&lt;p&gt;Looking at Altman's statements over time reveals a potential multi-level strategy. He likes to talk big. In February 2024, he reportedly sought an audacious $5 trillion–7 trillion for AI chip fabrication—larger than the entire semiconductor industry—effectively normalizing astronomical numbers in AI discussions.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;By August 2025, while warning of a bubble where someone will lose a "phenomenal amount of money," he casually mentioned that OpenAI would "spend trillions on datacenter construction" and serve "billions daily." This creates urgency while potentially insulating OpenAI from criticism—acknowledging the bubble exists while positioning his company's infrastructure spending as different and necessary. When economists raised concerns, Altman dismissed them by saying, "Let us do our thing," framing trillion-dollar investments as inevitable for human progress while making OpenAI's $500 billion valuation seem almost reasonable by comparison.&lt;/p&gt;
&lt;p&gt;This dual messaging—catastrophic warnings paired with trillion-dollar ambitions—might seem contradictory, but it makes more sense when you consider the unique structure of today's AI market, which is absolutely flush with cash.&lt;/p&gt;
&lt;h2&gt;A different kind of bubble&lt;/h2&gt;
&lt;p&gt;The current AI investment cycle differs from previous technology bubbles. Unlike dot-com era startups that burned through venture capital with no path to profitability, the largest AI investors—Microsoft, Google, Meta, and Amazon—generate hundreds of billions of dollars in annual profits from their core businesses.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Microsoft alone plans to spend $80 billion on AI data centers this fiscal year. These companies can potentially sustain losses from AI development for years without facing the cash crises that typically trigger bubble collapses.&lt;/p&gt;
&lt;p&gt;"Back then, you had a lot of over-leveraged situations. You didn't have a lot of companies that had earnings," Citi's Rob Rowe said on CNBC. "Here you're talking about companies that have very solid earnings, very strong cash flow."&lt;/p&gt;
&lt;p&gt;The structural difference matters. When the dot-com bubble burst in 2000, hundreds of companies vanished overnight because they ran out of money. Today's AI investors can absorb losses that would have killed entire companies two decades ago. If there is a bubble, it might deflate gradually over years rather than pop in a sudden crash.&lt;/p&gt;
&lt;p&gt;After all, deep pockets don't guarantee product success. OpenAI's CEO recently acknowledged problems with the messy GPT-5 launch, which others are using as evidence that the AI industry is in trouble. But the AI market is now much larger than just OpenAI, with Google, Meta, and Anthropic among those fiercely competing for customers.&lt;/p&gt;
&lt;p&gt;Despite the struggles with AI in enterprise and his own bubble warnings, Altman remains bullish on AI's long-term trajectory. The technology continues to improve despite its drawbacks and misapplications, and major companies keep increasing their investments rather than pulling back. Whether current valuations make sense in the short term is one question; whether AI will eventually transform the economy is another entirely.&lt;/p&gt;
&lt;p&gt;"I do think some investors are likely to get very burnt here, and that sucks. And I don't want to minimize that," Altman told the reporters last week. "But on the whole, it is my belief that... the value created by AI for society will be tremendous."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/08/sam-altman-calls-ai-a-bubble-while-seeking-500b-valuation-for-openai/</guid><pubDate>Thu, 21 Aug 2025 22:06:37 +0000</pubDate></item><item><title>[NEW] OpenAI lawyers question Meta’s role in Elon Musk’s $97B takeover bid (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/21/openai-lawyers-question-metas-role-in-elon-musks-97b-takeover-bid/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2019062515.jpg?resize=1200,815" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is asking Meta to produce evidence related to any coordinated plans with Elon Musk and xAI to acquire or invest in the ChatGPT-maker.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The request was made public in a brief filed Thursday in Elon Musk’s ongoing lawsuit against OpenAI. Lawyers representing OpenAI said they subpoenaed Meta in June for documents related to its potential involvement in Musk’s unsolicited, $97 billion bid to takeover the startup in February. It’s unclear from the filing whether such evidence exists. OpenAI ultimately denied Musk’s bid.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI’s lawyers say they discovered that Musk communicated with Meta CEO Mark Zuckerberg concerning xAI’s bid to purchase the ChatGPT-maker, including “about potential financing arrangements or investments.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta objected to OpenAI’s initial subpoena in July; the ChatGPT-maker’s lawyers are now seeking a court order to obtain such evidence. OpenAI is also asking the court for any of Meta’s documents and communications related to “any actual or potential restructuring or recapitalization of OpenAI” — the core issue in Musk’s lawsuit against OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta spokesperson Andy Stone directed TechCrunch towards a section of OpenAI’s filing which states that neither Meta nor Zuckerberg signed Musk’s letter of intent to acquire the ChatGPT-maker. Meta declined to comment further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the background of OpenAI’s fight with Elon Musk, Meta has significantly invested in its own efforts to develop frontier AI models. That effort has included poaching several of OpenAI’s leading AI researchers, including a co-creator of ChatGPT, Shengjia Zhao, who now leads research efforts at Meta Superintelligence Labs, the company’s newest AI unit. Meta also invested $14 billion in Scale AI, and reportedly approached several other AI labs about acquisition deals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lawyers representing Meta asked the court to reject OpenAI’s request for evidence, arguing that Musk and xAI can provide any relevant information. Meta also argues that its internal discussions of OpenAI’s restructuring and recapitalization are not relevant to the case.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This is a developing story… Check back for updates.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2019062515.jpg?resize=1200,815" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is asking Meta to produce evidence related to any coordinated plans with Elon Musk and xAI to acquire or invest in the ChatGPT-maker.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The request was made public in a brief filed Thursday in Elon Musk’s ongoing lawsuit against OpenAI. Lawyers representing OpenAI said they subpoenaed Meta in June for documents related to its potential involvement in Musk’s unsolicited, $97 billion bid to takeover the startup in February. It’s unclear from the filing whether such evidence exists. OpenAI ultimately denied Musk’s bid.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI’s lawyers say they discovered that Musk communicated with Meta CEO Mark Zuckerberg concerning xAI’s bid to purchase the ChatGPT-maker, including “about potential financing arrangements or investments.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta objected to OpenAI’s initial subpoena in July; the ChatGPT-maker’s lawyers are now seeking a court order to obtain such evidence. OpenAI is also asking the court for any of Meta’s documents and communications related to “any actual or potential restructuring or recapitalization of OpenAI” — the core issue in Musk’s lawsuit against OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta spokesperson Andy Stone directed TechCrunch towards a section of OpenAI’s filing which states that neither Meta nor Zuckerberg signed Musk’s letter of intent to acquire the ChatGPT-maker. Meta declined to comment further.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the background of OpenAI’s fight with Elon Musk, Meta has significantly invested in its own efforts to develop frontier AI models. That effort has included poaching several of OpenAI’s leading AI researchers, including a co-creator of ChatGPT, Shengjia Zhao, who now leads research efforts at Meta Superintelligence Labs, the company’s newest AI unit. Meta also invested $14 billion in Scale AI, and reportedly approached several other AI labs about acquisition deals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lawyers representing Meta asked the court to reject OpenAI’s request for evidence, arguing that Musk and xAI can provide any relevant information. Meta also argues that its internal discussions of OpenAI’s restructuring and recapitalization are not relevant to the case.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This is a developing story… Check back for updates.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/21/openai-lawyers-question-metas-role-in-elon-musks-97b-takeover-bid/</guid><pubDate>Fri, 22 Aug 2025 00:31:38 +0000</pubDate></item></channel></rss>