<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 15 Jan 2026 18:40:19 +0000</lastBuildDate><item><title>AI medical diagnostics race intensifies as OpenAI, Google, and Anthropic launch competing healthcare tools (AI News)</title><link>https://www.artificialintelligence-news.com/news/medical-ai-diagnostics-openai-google-anthropic/</link><description>&lt;p&gt;OpenAI, Google, and Anthropic announced specialised medical AI capabilities within days of each other this month, a clustering that suggests competitive pressure rather than coincidental timing. Yet none of the releases are cleared as medical devices, approved for clinical use, or available for direct patient diagnosis—despite marketing language emphasising healthcare transformation.&lt;/p&gt;&lt;p&gt;OpenAI&amp;nbsp;introduced&amp;nbsp;ChatGPT Health on January 7, allowing US users to connect medical records through partnerships with b.well, Apple Health, Function, and MyFitnessPal. Google&amp;nbsp;released&amp;nbsp;MedGemma 1.5 on January 13, expanding its open medical AI model to interpret three-dimensional CT and MRI scans alongside whole-slide histopathology images.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Anthropic&amp;nbsp;followed&amp;nbsp;on January 11 with Claude for Healthcare, offering HIPAA-compliant connectors to CMS coverage databases, ICD-10 coding systems, and the National Provider Identifier Registry.&lt;/p&gt;&lt;p&gt;All three companies are targeting the same workflow pain points—prior authorisation reviews, claims processing, clinical documentation—with similar technical approaches but different go-to-market strategies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-developer-platforms-not-diagnostic-products"&gt;Developer platforms, not diagnostic products&lt;/h3&gt;&lt;p&gt;The architectural similarities are notable. Each system uses multimodal large language models fine-tuned on medical literature and clinical datasets. Each emphasises privacy protections and regulatory disclaimers. Each positions itself as supporting rather than replacing clinical judgment.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111593" height="576" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/OAI_ChatGPT_Health_Wayfinding_16-9.png-1024x576.webp" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;The differences lie in deployment and access models. OpenAI’s ChatGPT Health operates as a consumer-facing service with a waitlist for ChatGPT Free, Plus, and Pro subscribers outside the EEA, Switzerland, and the UK. Google’s MedGemma 1.5 releases as an open model through its Health AI Developer Foundations program, available for download via Hugging Face or deployment through Google Cloud’s Vertex AI.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Anthropic’s Claude for Healthcare integrates into existing enterprise workflows through Claude for Enterprise, targeting institutional buyers rather than individual consumers. The regulatory positioning is consistent across all three.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI states explicitly that Health “is not intended for diagnosis or treatment.” Google positions MedGemma as “starting points for developers to evaluate and adapt to their medical use cases.” Anthropic emphasises that outputs “are not intended to directly inform clinical diagnosis, patient management decisions, treatment recommendations, or any other direct clinical practice applications.”&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111594" height="763" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/MedGemma15-0a-Hero-1024x763.png" width="1024" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-benchmark-performance-vs-clinical-validation"&gt;Benchmark performance vs clinical validation&lt;/h3&gt;&lt;p&gt;Medical AI benchmark results improved substantially across all three releases, though the gap between test performance and clinical deployment remains significant. Google reports that MedGemma 1.5 achieved 92.3% accuracy on MedAgentBench, Stanford’s medical agent task completion benchmark, compared to 69.6% for the previous Sonnet 3.5 baseline.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The model improved by 14 percentage points on MRI disease classification and 3 percentage points on CT findings in internal testing. Anthropic’s Claude Opus 4.5 scored 61.3% on MedCalc medical calculation accuracy tests with Python code execution enabled, and 92.3% on MedAgentBench.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company also claims improvements in “honesty evaluations” related to factual hallucinations, though specific metrics were not disclosed.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI has not published benchmark comparisons for ChatGPT Health specifically,&amp;nbsp;noting&amp;nbsp;instead that “over 230 million people globally ask health and wellness-related questions on ChatGPT every week” based on de-identified analysis of existing usage patterns.&lt;/p&gt;&lt;p&gt;These benchmarks measure performance on curated test datasets, not clinical outcomes in practice. Medical errors can have life-threatening consequences, translating benchmark accuracy to clinical utility more complex than in other AI application domains.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-regulatory-pathway-remains-unclear"&gt;Regulatory pathway remains unclear&lt;/h3&gt;&lt;p&gt;The regulatory framework for these medical AI tools remains ambiguous. In the US, the FDA’s oversight depends on intended use. Software that “supports or provides recommendations to a health care professional about prevention, diagnosis, or treatment of a disease” may require premarket review as a medical device. None of the announced tools has FDA clearance.&lt;/p&gt;&lt;p&gt;Liability questions are similarly unresolved. When Banner Health’s CTO Mike Reagin states that the health system was “drawn to Anthropic’s focus on AI safety,” this addresses technology selection criteria, not legal liability frameworks.&amp;nbsp;&lt;/p&gt;&lt;p&gt;If a clinician relies on Claude’s prior authorisation analysis and a patient suffers harm from delayed care, existing case law provides limited guidance on responsibility allocation.&lt;/p&gt;&lt;p&gt;Regulatory approaches vary significantly across markets. While the FDA and Europe’s Medical Device Regulation provide established frameworks for software as a medical device, many APAC regulators have not issued specific guidance on generative AI diagnostic tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This regulatory ambiguity affects adoption timelines in markets where healthcare infrastructure gaps might otherwise accelerate implementation—creating a tension between clinical need and regulatory caution.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-administrative-workflows-not-clinical-decisions"&gt;Administrative workflows, not clinical decisions&lt;/h3&gt;&lt;p&gt;Real deployments remain carefully scoped. Novo Nordisk’s Louise Lind Skov, Director of Content Digitalisation, described using Claude for “document and content automation in pharma development,” focused on regulatory submission documents rather than patient diagnosis.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Taiwan’s National Health Insurance Administration applied MedGemma to extract data from 30,000 pathology reports for policy analysis, not treatment decisions.&lt;/p&gt;&lt;p&gt;The pattern suggests institutional adoption is concentrating on administrative workflows where errors are less immediately dangerous—billing, documentation, protocol drafting—rather than direct clinical decision support where medical AI capabilities would have the most dramatic impact on patient outcomes.&lt;/p&gt;&lt;p&gt;Medical AI capabilities are advancing faster than the institutions deploying them can navigate regulatory, liability, and workflow integration complexities. The technology exists. The US$20 monthly subscription provides access to sophisticated medical reasoning tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Whether that translates to transformed healthcare delivery depends on questions these coordinated announcements leave unaddressed.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AstraZeneca bets on in-house AI to speed up oncology research&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;OpenAI, Google, and Anthropic announced specialised medical AI capabilities within days of each other this month, a clustering that suggests competitive pressure rather than coincidental timing. Yet none of the releases are cleared as medical devices, approved for clinical use, or available for direct patient diagnosis—despite marketing language emphasising healthcare transformation.&lt;/p&gt;&lt;p&gt;OpenAI&amp;nbsp;introduced&amp;nbsp;ChatGPT Health on January 7, allowing US users to connect medical records through partnerships with b.well, Apple Health, Function, and MyFitnessPal. Google&amp;nbsp;released&amp;nbsp;MedGemma 1.5 on January 13, expanding its open medical AI model to interpret three-dimensional CT and MRI scans alongside whole-slide histopathology images.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Anthropic&amp;nbsp;followed&amp;nbsp;on January 11 with Claude for Healthcare, offering HIPAA-compliant connectors to CMS coverage databases, ICD-10 coding systems, and the National Provider Identifier Registry.&lt;/p&gt;&lt;p&gt;All three companies are targeting the same workflow pain points—prior authorisation reviews, claims processing, clinical documentation—with similar technical approaches but different go-to-market strategies.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-developer-platforms-not-diagnostic-products"&gt;Developer platforms, not diagnostic products&lt;/h3&gt;&lt;p&gt;The architectural similarities are notable. Each system uses multimodal large language models fine-tuned on medical literature and clinical datasets. Each emphasises privacy protections and regulatory disclaimers. Each positions itself as supporting rather than replacing clinical judgment.&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111593" height="576" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/OAI_ChatGPT_Health_Wayfinding_16-9.png-1024x576.webp" width="1024" /&gt;&lt;/figure&gt;&lt;p&gt;The differences lie in deployment and access models. OpenAI’s ChatGPT Health operates as a consumer-facing service with a waitlist for ChatGPT Free, Plus, and Pro subscribers outside the EEA, Switzerland, and the UK. Google’s MedGemma 1.5 releases as an open model through its Health AI Developer Foundations program, available for download via Hugging Face or deployment through Google Cloud’s Vertex AI.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Anthropic’s Claude for Healthcare integrates into existing enterprise workflows through Claude for Enterprise, targeting institutional buyers rather than individual consumers. The regulatory positioning is consistent across all three.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI states explicitly that Health “is not intended for diagnosis or treatment.” Google positions MedGemma as “starting points for developers to evaluate and adapt to their medical use cases.” Anthropic emphasises that outputs “are not intended to directly inform clinical diagnosis, patient management decisions, treatment recommendations, or any other direct clinical practice applications.”&lt;/p&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-111594" height="763" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/MedGemma15-0a-Hero-1024x763.png" width="1024" /&gt;&lt;/figure&gt;&lt;h3 class="wp-block-heading" id="h-benchmark-performance-vs-clinical-validation"&gt;Benchmark performance vs clinical validation&lt;/h3&gt;&lt;p&gt;Medical AI benchmark results improved substantially across all three releases, though the gap between test performance and clinical deployment remains significant. Google reports that MedGemma 1.5 achieved 92.3% accuracy on MedAgentBench, Stanford’s medical agent task completion benchmark, compared to 69.6% for the previous Sonnet 3.5 baseline.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The model improved by 14 percentage points on MRI disease classification and 3 percentage points on CT findings in internal testing. Anthropic’s Claude Opus 4.5 scored 61.3% on MedCalc medical calculation accuracy tests with Python code execution enabled, and 92.3% on MedAgentBench.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The company also claims improvements in “honesty evaluations” related to factual hallucinations, though specific metrics were not disclosed.&amp;nbsp;&lt;/p&gt;&lt;p&gt;OpenAI has not published benchmark comparisons for ChatGPT Health specifically,&amp;nbsp;noting&amp;nbsp;instead that “over 230 million people globally ask health and wellness-related questions on ChatGPT every week” based on de-identified analysis of existing usage patterns.&lt;/p&gt;&lt;p&gt;These benchmarks measure performance on curated test datasets, not clinical outcomes in practice. Medical errors can have life-threatening consequences, translating benchmark accuracy to clinical utility more complex than in other AI application domains.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-regulatory-pathway-remains-unclear"&gt;Regulatory pathway remains unclear&lt;/h3&gt;&lt;p&gt;The regulatory framework for these medical AI tools remains ambiguous. In the US, the FDA’s oversight depends on intended use. Software that “supports or provides recommendations to a health care professional about prevention, diagnosis, or treatment of a disease” may require premarket review as a medical device. None of the announced tools has FDA clearance.&lt;/p&gt;&lt;p&gt;Liability questions are similarly unresolved. When Banner Health’s CTO Mike Reagin states that the health system was “drawn to Anthropic’s focus on AI safety,” this addresses technology selection criteria, not legal liability frameworks.&amp;nbsp;&lt;/p&gt;&lt;p&gt;If a clinician relies on Claude’s prior authorisation analysis and a patient suffers harm from delayed care, existing case law provides limited guidance on responsibility allocation.&lt;/p&gt;&lt;p&gt;Regulatory approaches vary significantly across markets. While the FDA and Europe’s Medical Device Regulation provide established frameworks for software as a medical device, many APAC regulators have not issued specific guidance on generative AI diagnostic tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;This regulatory ambiguity affects adoption timelines in markets where healthcare infrastructure gaps might otherwise accelerate implementation—creating a tension between clinical need and regulatory caution.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-administrative-workflows-not-clinical-decisions"&gt;Administrative workflows, not clinical decisions&lt;/h3&gt;&lt;p&gt;Real deployments remain carefully scoped. Novo Nordisk’s Louise Lind Skov, Director of Content Digitalisation, described using Claude for “document and content automation in pharma development,” focused on regulatory submission documents rather than patient diagnosis.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Taiwan’s National Health Insurance Administration applied MedGemma to extract data from 30,000 pathology reports for policy analysis, not treatment decisions.&lt;/p&gt;&lt;p&gt;The pattern suggests institutional adoption is concentrating on administrative workflows where errors are less immediately dangerous—billing, documentation, protocol drafting—rather than direct clinical decision support where medical AI capabilities would have the most dramatic impact on patient outcomes.&lt;/p&gt;&lt;p&gt;Medical AI capabilities are advancing faster than the institutions deploying them can navigate regulatory, liability, and workflow integration complexities. The technology exists. The US$20 monthly subscription provides access to sophisticated medical reasoning tools.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Whether that translates to transformed healthcare delivery depends on questions these coordinated announcements leave unaddressed.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: AstraZeneca bets on in-house AI to speed up oncology research&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/medical-ai-diagnostics-openai-google-anthropic/</guid><pubDate>Thu, 15 Jan 2026 07:00:00 +0000</pubDate></item><item><title>Exclusive: Volvo tells us why having Gemini in your next car is a good thing (AI - Ars Technica)</title><link>https://arstechnica.com/cars/2026/01/exclusive-volvo-tells-us-why-having-gemini-in-your-next-car-is-a-good-thing/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        In-car personal assistants are about to get useful, it looks like.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A raven stands over the word VOLVO" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A raven stands over the word VOLVO" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Next week, Volvo shows off its new EX60 SUV to the world. It’s the brand’s next electric vehicle, one built on an all-new, EV-only platform that makes use of the latest in vehicle design trends, like a cell-to-body battery pack, large weight-saving castings, and an advanced electronic architecture run by a handful of computers capable of more than 250 trillion operations per second. This new software-defined platform even has a name: HuginCore, after one of the two ravens that collected information for the Norse god Odin.&lt;/p&gt;
&lt;p&gt;It’s not Volvo’s first reference to mythology. “We have Thor’s Hammer [Volvo’s distinctive headlight design] and now we have HuginCore… one of the two trusted Ravens of Oden. He sent Hugin and Muninn out to fly across the realms and observe and gather information and knowledge, which they then share with Odin that enabled him to make the right decisions as the ruler of Asgard,” said Alwin Bakkenes, head of global software engineering at Volvo Cars.&lt;/p&gt;
&lt;p&gt;“And much like Hugin, the way we look at this technology platform, it collects information from all of the sensors, all of the actuators in the vehicle. It understands the world around the vehicle, and it enables us to actually anticipate around what lies ahead,” Bakkenes told me.&lt;/p&gt;
&lt;p&gt;HuginCore is actually Volvo’s second-generation software-defined vehicle platform, one that incorporates hard-learned lessons from cars like the EX90. “The transformation that we did to really becoming a tech company that has control over its own stack—so hardware and software… I can’t lie. It’s been a tough journey. So the EX90 has been a tough journey to get it to launch. And we also had some issues in the beginning, and the learnings that we took from it, we actually brought into what we’re doing with EX60,” Bakkenes said.&lt;/p&gt;
&lt;h2&gt;Scalable Product Architecture 3&lt;/h2&gt;
&lt;p&gt;Good news for existing Volvo owners: The arrival of the platform (called SPA3) and HuginCore&amp;nbsp;doesn’t mean your SPA2 Volvo is going to be abandoned.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Of course there’s, at some point, cars go into maintenance, but the majority of the fleet of cars that we have out, we intend to keep on the latest software baselines,” Bakkenes said. While he wouldn’t be drawn on whether HuginCore will be part of the midlife refresh process for SPA2 cars like the EX90, those SUVs do feature the same powerful Nvidia Drive AGX Orin system-on-a-chip that’s integral to making this all work.&lt;/p&gt;
&lt;p&gt;“The core compute platform as such, even though we’ve made some changes in EX60 and optimized it, a lot of it is actually common with, for example, SPA2. So a lot of code is being… We have what we call the superset tech stack. We have a superset of code and we do manifest-based configuration towards a specific hardware variant, which means that we actually deploy the same towards a SPA2 car and a SPA3 car, for example, in terms of a lot of functionality,” Bakkenes said.&lt;/p&gt;
&lt;p&gt;Nvidia isn’t the only thing powering HuginCore, though. Qualcomm is another partner, and it is supplying its Snapdragon 8255 SoC. Together, that gives “a lot of inference compute… and it’s flexible inference compute. So it enables us to develop AI-based algorithm models for self-driving, for other tasks in the car as well, and do that flexibly. And as we do this, it’s not just that we build a car which is great today, but we are building the foundation with Hugin, which is a flexible compute platform which has access to essentially all the sensors and all the actuators in the car so we can evolve this over time,” he said.&lt;/p&gt;
&lt;h2&gt;Agentic AI&lt;/h2&gt;
&lt;p&gt;Volvo was an early adopter of Google’s automotive services, and it’s adding Gemini to the EX60 to give the car a true conversational AI assistant. I’ve long been on record as in favor of good voice control systems in cars, but they have to be natural, and from the sounds of it, this will be. Yes, you can use it to do things like navigate to a specific address or play a particular song. But you can also be a little more vague. Notwithstanding Volvo’s rocky experience with the EX90, the brand’s long-standing and fiercely defended reputation for safety is reassuring when it comes to integrating AI agents into its cars.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“If you don’t know exactly where you want to go, you can give vague destination settings; if you want to play a song that you vaguely remember who did it and it was about something, you can talk about it in natural ways and it will actually help you find what you’re looking for, but that’s just the tip of the iceberg,” Bakkenes said.&lt;/p&gt;
&lt;p&gt;The AI agent knows exactly what car it’s in and has access to all of Volvo’s manuals and resources, as well as the greater Internet. It knows how to use the car and can explain it. “I want to understand how I share my digital key. I can open up a manual or something, but I can actually just ask, how do I share my digital key to a friend or to a valet? Or how do I charge? How do I open the charge lid? How do I do this, et cetera? And it just knows all of these things. So you can converse around it without going through the thick manual,” he explained.&lt;/p&gt;
&lt;p&gt;Bakkenes shared examples of using the AI agent to find out if a particular model of TV was in stock at a nearby store, and whether it would fit in his car. You can tell it to remember a location, which it can correlate to appointments in your calendar and suggest directions. Another mode, called Gemini Live, sounds really quite useful.&lt;/p&gt;
&lt;p&gt;“I’ve actually used it in the morning to get information about collecting Reddit feedback, so summarizing Reddit feedback from last week’s feedback on our product, for example. And when I get to work and I open up Gemini, I have the transcript of the discussion, so I can actually pick up there and keep the context. It also keeps context,” Bakkenes said.&lt;/p&gt;
&lt;p&gt;If that works as described, it sounds like quite the productivity boost—one I’ll test out by seeing if it helps me write my notes for the EX60 when (if) I get to drive it later this year. Given that it knows everything about the EX60, I even suggested that Volvo have the AI agent give the product briefing during the first drive—we’ll see if the company takes me up on that in time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        In-car personal assistants are about to get useful, it looks like.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A raven stands over the word VOLVO" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A raven stands over the word VOLVO" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/volvo-hugin-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Aurich Lawson

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Next week, Volvo shows off its new EX60 SUV to the world. It’s the brand’s next electric vehicle, one built on an all-new, EV-only platform that makes use of the latest in vehicle design trends, like a cell-to-body battery pack, large weight-saving castings, and an advanced electronic architecture run by a handful of computers capable of more than 250 trillion operations per second. This new software-defined platform even has a name: HuginCore, after one of the two ravens that collected information for the Norse god Odin.&lt;/p&gt;
&lt;p&gt;It’s not Volvo’s first reference to mythology. “We have Thor’s Hammer [Volvo’s distinctive headlight design] and now we have HuginCore… one of the two trusted Ravens of Oden. He sent Hugin and Muninn out to fly across the realms and observe and gather information and knowledge, which they then share with Odin that enabled him to make the right decisions as the ruler of Asgard,” said Alwin Bakkenes, head of global software engineering at Volvo Cars.&lt;/p&gt;
&lt;p&gt;“And much like Hugin, the way we look at this technology platform, it collects information from all of the sensors, all of the actuators in the vehicle. It understands the world around the vehicle, and it enables us to actually anticipate around what lies ahead,” Bakkenes told me.&lt;/p&gt;
&lt;p&gt;HuginCore is actually Volvo’s second-generation software-defined vehicle platform, one that incorporates hard-learned lessons from cars like the EX90. “The transformation that we did to really becoming a tech company that has control over its own stack—so hardware and software… I can’t lie. It’s been a tough journey. So the EX90 has been a tough journey to get it to launch. And we also had some issues in the beginning, and the learnings that we took from it, we actually brought into what we’re doing with EX60,” Bakkenes said.&lt;/p&gt;
&lt;h2&gt;Scalable Product Architecture 3&lt;/h2&gt;
&lt;p&gt;Good news for existing Volvo owners: The arrival of the platform (called SPA3) and HuginCore&amp;nbsp;doesn’t mean your SPA2 Volvo is going to be abandoned.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Of course there’s, at some point, cars go into maintenance, but the majority of the fleet of cars that we have out, we intend to keep on the latest software baselines,” Bakkenes said. While he wouldn’t be drawn on whether HuginCore will be part of the midlife refresh process for SPA2 cars like the EX90, those SUVs do feature the same powerful Nvidia Drive AGX Orin system-on-a-chip that’s integral to making this all work.&lt;/p&gt;
&lt;p&gt;“The core compute platform as such, even though we’ve made some changes in EX60 and optimized it, a lot of it is actually common with, for example, SPA2. So a lot of code is being… We have what we call the superset tech stack. We have a superset of code and we do manifest-based configuration towards a specific hardware variant, which means that we actually deploy the same towards a SPA2 car and a SPA3 car, for example, in terms of a lot of functionality,” Bakkenes said.&lt;/p&gt;
&lt;p&gt;Nvidia isn’t the only thing powering HuginCore, though. Qualcomm is another partner, and it is supplying its Snapdragon 8255 SoC. Together, that gives “a lot of inference compute… and it’s flexible inference compute. So it enables us to develop AI-based algorithm models for self-driving, for other tasks in the car as well, and do that flexibly. And as we do this, it’s not just that we build a car which is great today, but we are building the foundation with Hugin, which is a flexible compute platform which has access to essentially all the sensors and all the actuators in the car so we can evolve this over time,” he said.&lt;/p&gt;
&lt;h2&gt;Agentic AI&lt;/h2&gt;
&lt;p&gt;Volvo was an early adopter of Google’s automotive services, and it’s adding Gemini to the EX60 to give the car a true conversational AI assistant. I’ve long been on record as in favor of good voice control systems in cars, but they have to be natural, and from the sounds of it, this will be. Yes, you can use it to do things like navigate to a specific address or play a particular song. But you can also be a little more vague. Notwithstanding Volvo’s rocky experience with the EX90, the brand’s long-standing and fiercely defended reputation for safety is reassuring when it comes to integrating AI agents into its cars.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“If you don’t know exactly where you want to go, you can give vague destination settings; if you want to play a song that you vaguely remember who did it and it was about something, you can talk about it in natural ways and it will actually help you find what you’re looking for, but that’s just the tip of the iceberg,” Bakkenes said.&lt;/p&gt;
&lt;p&gt;The AI agent knows exactly what car it’s in and has access to all of Volvo’s manuals and resources, as well as the greater Internet. It knows how to use the car and can explain it. “I want to understand how I share my digital key. I can open up a manual or something, but I can actually just ask, how do I share my digital key to a friend or to a valet? Or how do I charge? How do I open the charge lid? How do I do this, et cetera? And it just knows all of these things. So you can converse around it without going through the thick manual,” he explained.&lt;/p&gt;
&lt;p&gt;Bakkenes shared examples of using the AI agent to find out if a particular model of TV was in stock at a nearby store, and whether it would fit in his car. You can tell it to remember a location, which it can correlate to appointments in your calendar and suggest directions. Another mode, called Gemini Live, sounds really quite useful.&lt;/p&gt;
&lt;p&gt;“I’ve actually used it in the morning to get information about collecting Reddit feedback, so summarizing Reddit feedback from last week’s feedback on our product, for example. And when I get to work and I open up Gemini, I have the transcript of the discussion, so I can actually pick up there and keep the context. It also keeps context,” Bakkenes said.&lt;/p&gt;
&lt;p&gt;If that works as described, it sounds like quite the productivity boost—one I’ll test out by seeing if it helps me write my notes for the EX60 when (if) I get to drive it later this year. Given that it knows everything about the EX60, I even suggested that Volvo have the AI agent give the product briefing during the first drive—we’ll see if the company takes me up on that in time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/cars/2026/01/exclusive-volvo-tells-us-why-having-gemini-in-your-next-car-is-a-good-thing/</guid><pubDate>Thu, 15 Jan 2026 08:00:15 +0000</pubDate></item><item><title>McKinsey tests AI chatbot in early stages of graduate recruitment (AI News)</title><link>https://www.artificialintelligence-news.com/news/mckinsey-tests-ai-chatbot-in-early-stages-of-graduate-recruitment/</link><description>&lt;p&gt;Hiring at large firms has long relied on interviews, tests, and human judgment. That process is starting to shift. McKinsey has begun using an AI chatbot as part of its graduate recruitment process, signalling a shift in how professional services organisations evaluate early-career candidates.&lt;/p&gt;&lt;p&gt;The chatbot is being used during the initial stages of recruitment, where applicants are asked to interact with it as part of their assessment. Rather than replacing interviews or final hiring decisions, the tool is intended to support screening and evaluation earlier in the process. The move reflects a wider trend across large organisations: AI is no longer limited to research or client-facing tools, but is increasingly shaping internal workflows.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-mckinsey-is-using-ai-in-graduate-hiring"&gt;Why McKinsey is using AI in graduate hiring&lt;/h3&gt;&lt;p&gt;Graduate recruitment is resource-heavy. Every year, large firms receive tens of thousands of applications, many of which must be assessed in short hiring cycles. Screening candidates for basic fit, communication skills, and problem-solving ability can take a long time, even before interviews begin.&lt;/p&gt;&lt;p&gt;Using AI at this stage offers a way to manage volume. A chatbot can interact with every applicant, ask consistent questions and collect organised responses. Human recruiters can then review that data, rather than requiring staff to manually screen every application from scratch.&lt;/p&gt;&lt;p&gt;For McKinsey, the chatbot is part of a larger assessment process that includes interviews and human judgment. According to the company, the tool helps in gathering more information early on, rather than making recruiting judgments on its own.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-shifting-the-role-of-recruiters"&gt;Shifting the role of recruiters&lt;/h3&gt;&lt;p&gt;Introducing AI into recruitment alters how hiring teams operate. Rather than focusing on early screening, recruiters can devote more time to assessing prospects who have already passed initial tests. In theory, that allows for more thoughtful interviews and deeper evaluation later in the process.&lt;/p&gt;&lt;p&gt;At the same time, it raises questions about oversight. Recruiters need to understand how the chatbot evaluates responses and what signals it prioritises. Without that visibility, there is a risk that decisions could lean too heavily on automated outputs, even if the tool is meant to assist rather than decide.&lt;/p&gt;&lt;p&gt;Professional services firms are typically wary about such adjustments. Their reputations rely heavily on talent quality, and any perception of unfair or flawed hiring practices carries risk. As a result, recruitment serves as a testing ground for AI use, as well as an area where controls are important.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-concerns-around-fairness-and-bias"&gt;Concerns around fairness and bias&lt;/h3&gt;&lt;p&gt;Using AI in hiring is not without controversy. Critics have raised concerns that automated systems can reflect biases present in their training data or in how questions are framed. If not monitored closely, those biases can affect who progresses through the hiring process.&lt;/p&gt;&lt;p&gt;McKinsey has said it is mindful of these risks and that the chatbot is used alongside human review. Still, the move highlights a broader challenge for organisations adopting AI internally: tools must be tested, audited, and adjusted over time.&lt;/p&gt;&lt;p&gt;In recruitment, that includes checking whether certain groups are disadvantaged by how questions are asked or how responses are interpreted. It also means giving candidates clear information about how AI is used and how their data is handled.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-mckinsey-s-ai-hiring-move-fits-a-wider-enterprise-trend"&gt;How McKinsey’s AI hiring move fits a wider enterprise trend&lt;/h3&gt;&lt;p&gt;The use of AI in graduate hiring is not unique to consulting. Large employers in finance, law, and technology are also testing AI tools for screening, scheduling interviews, and analysing written responses. What stands out is how quickly these tools are moving from experiments to real processes.&lt;/p&gt;&lt;p&gt;In many cases, AI enters organisations through small, contained use cases. Hiring is one of them. It sits inside the company, affects internal efficiency, and can be adjusted without changing products or services offered to clients.&lt;/p&gt;&lt;p&gt;That pattern mirrors how AI adoption is unfolding more broadly. Instead of sweeping transformations, many firms are adding AI to specific workflows where the benefits and risks are easier to manage.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-signals-for-enterprises"&gt;What this signals for enterprises&lt;/h3&gt;&lt;p&gt;McKinsey’s use of an AI chatbot in recruitment points to a practical shift in enterprise thinking. AI is becoming a tool for routine internal decisions, not just analysis or automation behind the scenes.&lt;/p&gt;&lt;p&gt;For other organisations, the lesson is less about copying the tool and more about approach. Introducing AI into sensitive areas like hiring requires clear boundaries, human oversight, and a willingness to review outcomes over time.&lt;/p&gt;&lt;p&gt;It also requires communication. Candidates need to know when they are interacting with AI and how that interaction fits into the overall hiring process. Transparency helps build trust, especially as AI becomes more common in workplace decisions.&lt;/p&gt;&lt;p&gt;As professional services firms continue to test AI in their own operations, recruitment offers an early view of how far they are willing to go. The technology may help manage scale and consistency, but responsibility for decisions still rests with people. How well companies balance those two will shape how AI is accepted inside the enterprise.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Resume Genius)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Allister Frost: Tackling workforce anxiety for AI integration success&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111234" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-4.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check outAI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Hiring at large firms has long relied on interviews, tests, and human judgment. That process is starting to shift. McKinsey has begun using an AI chatbot as part of its graduate recruitment process, signalling a shift in how professional services organisations evaluate early-career candidates.&lt;/p&gt;&lt;p&gt;The chatbot is being used during the initial stages of recruitment, where applicants are asked to interact with it as part of their assessment. Rather than replacing interviews or final hiring decisions, the tool is intended to support screening and evaluation earlier in the process. The move reflects a wider trend across large organisations: AI is no longer limited to research or client-facing tools, but is increasingly shaping internal workflows.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-mckinsey-is-using-ai-in-graduate-hiring"&gt;Why McKinsey is using AI in graduate hiring&lt;/h3&gt;&lt;p&gt;Graduate recruitment is resource-heavy. Every year, large firms receive tens of thousands of applications, many of which must be assessed in short hiring cycles. Screening candidates for basic fit, communication skills, and problem-solving ability can take a long time, even before interviews begin.&lt;/p&gt;&lt;p&gt;Using AI at this stage offers a way to manage volume. A chatbot can interact with every applicant, ask consistent questions and collect organised responses. Human recruiters can then review that data, rather than requiring staff to manually screen every application from scratch.&lt;/p&gt;&lt;p&gt;For McKinsey, the chatbot is part of a larger assessment process that includes interviews and human judgment. According to the company, the tool helps in gathering more information early on, rather than making recruiting judgments on its own.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-shifting-the-role-of-recruiters"&gt;Shifting the role of recruiters&lt;/h3&gt;&lt;p&gt;Introducing AI into recruitment alters how hiring teams operate. Rather than focusing on early screening, recruiters can devote more time to assessing prospects who have already passed initial tests. In theory, that allows for more thoughtful interviews and deeper evaluation later in the process.&lt;/p&gt;&lt;p&gt;At the same time, it raises questions about oversight. Recruiters need to understand how the chatbot evaluates responses and what signals it prioritises. Without that visibility, there is a risk that decisions could lean too heavily on automated outputs, even if the tool is meant to assist rather than decide.&lt;/p&gt;&lt;p&gt;Professional services firms are typically wary about such adjustments. Their reputations rely heavily on talent quality, and any perception of unfair or flawed hiring practices carries risk. As a result, recruitment serves as a testing ground for AI use, as well as an area where controls are important.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-concerns-around-fairness-and-bias"&gt;Concerns around fairness and bias&lt;/h3&gt;&lt;p&gt;Using AI in hiring is not without controversy. Critics have raised concerns that automated systems can reflect biases present in their training data or in how questions are framed. If not monitored closely, those biases can affect who progresses through the hiring process.&lt;/p&gt;&lt;p&gt;McKinsey has said it is mindful of these risks and that the chatbot is used alongside human review. Still, the move highlights a broader challenge for organisations adopting AI internally: tools must be tested, audited, and adjusted over time.&lt;/p&gt;&lt;p&gt;In recruitment, that includes checking whether certain groups are disadvantaged by how questions are asked or how responses are interpreted. It also means giving candidates clear information about how AI is used and how their data is handled.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-mckinsey-s-ai-hiring-move-fits-a-wider-enterprise-trend"&gt;How McKinsey’s AI hiring move fits a wider enterprise trend&lt;/h3&gt;&lt;p&gt;The use of AI in graduate hiring is not unique to consulting. Large employers in finance, law, and technology are also testing AI tools for screening, scheduling interviews, and analysing written responses. What stands out is how quickly these tools are moving from experiments to real processes.&lt;/p&gt;&lt;p&gt;In many cases, AI enters organisations through small, contained use cases. Hiring is one of them. It sits inside the company, affects internal efficiency, and can be adjusted without changing products or services offered to clients.&lt;/p&gt;&lt;p&gt;That pattern mirrors how AI adoption is unfolding more broadly. Instead of sweeping transformations, many firms are adding AI to specific workflows where the benefits and risks are easier to manage.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-what-this-signals-for-enterprises"&gt;What this signals for enterprises&lt;/h3&gt;&lt;p&gt;McKinsey’s use of an AI chatbot in recruitment points to a practical shift in enterprise thinking. AI is becoming a tool for routine internal decisions, not just analysis or automation behind the scenes.&lt;/p&gt;&lt;p&gt;For other organisations, the lesson is less about copying the tool and more about approach. Introducing AI into sensitive areas like hiring requires clear boundaries, human oversight, and a willingness to review outcomes over time.&lt;/p&gt;&lt;p&gt;It also requires communication. Candidates need to know when they are interacting with AI and how that interaction fits into the overall hiring process. Transparency helps build trust, especially as AI becomes more common in workplace decisions.&lt;/p&gt;&lt;p&gt;As professional services firms continue to test AI in their own operations, recruitment offers an early view of how far they are willing to go. The technology may help manage scale and consistency, but responsibility for decisions still rests with people. How well companies balance those two will shape how AI is accepted inside the enterprise.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Resume Genius)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Allister Frost: Tackling workforce anxiety for AI integration success&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-111234" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/image-4.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check outAI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events, click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/mckinsey-tests-ai-chatbot-in-early-stages-of-graduate-recruitment/</guid><pubDate>Thu, 15 Jan 2026 10:00:00 +0000</pubDate></item><item><title>Three climate technologies breaking through in 2026 (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/15/1131348/climate-technologies-2026/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/GettyImages-2182761656.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Happy New Year! I know it’s a bit late to say, but it never quite feels like the year has started until the new edition of our 10 Breakthrough Technologies list comes out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For 25 years, &lt;em&gt;MIT Technology Review&lt;/em&gt; has put together this package, which highlights the technologies that we think are going to matter in the future. This year’s version has some stars, including gene resurrection (remember all the dire wolf hype last year?) and commercial space stations.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;And of course, the world of climate and energy is represented with sodium-ion batteries, next-generation nuclear, and hyperscale AI data centers. Let’s take a look at what ended up on the list, and what it says about this moment for climate tech.&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Sodium-ion batteries&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;I’ve been covering sodium-ion batteries for years, but this moment feels like a breakout one for the technology.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Today, lithium-ion cells power everything from EVs, phones, and computers to huge stationary storage arrays that help support the grid. But researchers and battery companies have been racing to develop an alternative, driven by the relative scarcity of lithium and the metal’s volatile price in recent years.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Sodium-ion batteries could be that alternative. Sodium is much more abundant than lithium, and it could unlock cheaper batteries that hold a lower fire risk.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;There are limitations here: Sodium-ion batteries won’t be able to pack as much energy into cells as their lithium counterparts. But it might not matter, especially for grid storage and smaller EVs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In recent years, we’ve seen a ton of interest in sodium-based batteries, particularly from major companies in China. Now the new technology is starting to make its way into the world—CATL says it started manufacturing these batteries at scale in 2025.&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Next-generation nuclear&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Nuclear reactors are an important part of grids around the world today—massive workhorse reactors generate reliable, consistent electricity. But the countries with the oldest and most built-out fleets have struggled to add to them in recent years, since reactors are massive and cost billions. Recent high-profile projects have gone way over budget and faced serious delays.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Next-generation reactor designs could help the industry break out of the old blueprint and get more nuclear power online more quickly, and they’re starting to get closer to becoming reality.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;There’s a huge variety of proposals when it comes to what’s next for nuclear. Some companies are building smaller reactors, which they say could make it easier to finance new projects, and get them done on time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other companies are focusing on tweaking key technical bits of reactors, using alternative fuels or coolants that help ferry heat out of the reactor core. These changes could help reactors generate electricity more efficiently and safely.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Kairos Power was the first US company to receive approval to begin construction on a next-generation reactor to produce electricity. China is emerging as a major center of nuclear development, with the country’s national nuclear company reportedly working on several next-gen reactors.&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Hyperscale data centers&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;This one isn’t quite what I would call a climate technology, but I spent most of last year reporting on the climate and environmental impacts of AI, and the AI boom is deeply intertwined with climate and energy.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Data centers aren’t new, but we’re seeing a wave of larger centers being proposed and built to support the rise of AI. Some of these facilities require a gigawatt or more of power—that’s like the output of an entire conventional nuclear power plant, just for one data center.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;(This feels like a good time to mention that our Breakthrough Technologies list doesn’t just highlight tech that we think will have a straightforwardly positive influence on the world. I think back to our 2023 list, which included mass-market military drones.)&lt;/p&gt;  &lt;p&gt;There’s no denying that new, supersize data centers are an important force driving electricity demand, sparking major public pushback, and emerging as a key bit of our new global infrastructure.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/GettyImages-2182761656.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Happy New Year! I know it’s a bit late to say, but it never quite feels like the year has started until the new edition of our 10 Breakthrough Technologies list comes out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For 25 years, &lt;em&gt;MIT Technology Review&lt;/em&gt; has put together this package, which highlights the technologies that we think are going to matter in the future. This year’s version has some stars, including gene resurrection (remember all the dire wolf hype last year?) and commercial space stations.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;And of course, the world of climate and energy is represented with sodium-ion batteries, next-generation nuclear, and hyperscale AI data centers. Let’s take a look at what ended up on the list, and what it says about this moment for climate tech.&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Sodium-ion batteries&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;I’ve been covering sodium-ion batteries for years, but this moment feels like a breakout one for the technology.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Today, lithium-ion cells power everything from EVs, phones, and computers to huge stationary storage arrays that help support the grid. But researchers and battery companies have been racing to develop an alternative, driven by the relative scarcity of lithium and the metal’s volatile price in recent years.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Sodium-ion batteries could be that alternative. Sodium is much more abundant than lithium, and it could unlock cheaper batteries that hold a lower fire risk.&amp;nbsp;&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;There are limitations here: Sodium-ion batteries won’t be able to pack as much energy into cells as their lithium counterparts. But it might not matter, especially for grid storage and smaller EVs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In recent years, we’ve seen a ton of interest in sodium-based batteries, particularly from major companies in China. Now the new technology is starting to make its way into the world—CATL says it started manufacturing these batteries at scale in 2025.&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Next-generation nuclear&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;Nuclear reactors are an important part of grids around the world today—massive workhorse reactors generate reliable, consistent electricity. But the countries with the oldest and most built-out fleets have struggled to add to them in recent years, since reactors are massive and cost billions. Recent high-profile projects have gone way over budget and faced serious delays.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Next-generation reactor designs could help the industry break out of the old blueprint and get more nuclear power online more quickly, and they’re starting to get closer to becoming reality.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;There’s a huge variety of proposals when it comes to what’s next for nuclear. Some companies are building smaller reactors, which they say could make it easier to finance new projects, and get them done on time.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Other companies are focusing on tweaking key technical bits of reactors, using alternative fuels or coolants that help ferry heat out of the reactor core. These changes could help reactors generate electricity more efficiently and safely.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Kairos Power was the first US company to receive approval to begin construction on a next-generation reactor to produce electricity. China is emerging as a major center of nuclear development, with the country’s national nuclear company reportedly working on several next-gen reactors.&amp;nbsp;&lt;/p&gt;  &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Hyperscale data centers&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;This one isn’t quite what I would call a climate technology, but I spent most of last year reporting on the climate and environmental impacts of AI, and the AI boom is deeply intertwined with climate and energy.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Data centers aren’t new, but we’re seeing a wave of larger centers being proposed and built to support the rise of AI. Some of these facilities require a gigawatt or more of power—that’s like the output of an entire conventional nuclear power plant, just for one data center.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;(This feels like a good time to mention that our Breakthrough Technologies list doesn’t just highlight tech that we think will have a straightforwardly positive influence on the world. I think back to our 2023 list, which included mass-market military drones.)&lt;/p&gt;  &lt;p&gt;There’s no denying that new, supersize data centers are an important force driving electricity demand, sparking major public pushback, and emerging as a key bit of our new global infrastructure.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article is from The Spark, &lt;/em&gt;MIT Technology Review&lt;em&gt;’s weekly climate newsletter. To receive it in your inbox every Wednesday, &lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/15/1131348/climate-technologies-2026/</guid><pubDate>Thu, 15 Jan 2026 11:00:00 +0000</pubDate></item><item><title>After Italy, WhatsApp excludes Brazil from rival chatbot ban (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/15/after-italy-whatsapp-excludes-brazil-from-rival-chatbot-ban/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/Green-white-apple-logo.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;WhatsApp is allowing AI providers to continue offering their chatbots to users with Brazilian phone numbers, days after the country’s competition regulator ordered the company to suspend its new policy that bars third-party, general-purpose chatbots from being offered on the app via its business API.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new policy, the company is providing a 90-day grace period starting January 15 to developers and AI providers, mandating them to cease responding to user queries on the chat app, and notify users that their chatbots won’t work on WhatsApp. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, Meta told developers that they don’t have to notify users with Brazilian phone numbers (with code +55) of any changes or cease offering their services, per a notice to AI providers seen by TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The requirement to cease responding to user queries and implement pre-approved auto-reply language (mentioned below) before January 15, 2026, no longer applies when messaging people with a Brazil country code (+55),” the notice reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WhatsApp did not immediately respond to a query seeking to confirm the decision.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The policy, which goes into effect from today, impacts general-purpose chatbots like ChatGPT and Grok on the platform. Notably, the policy does not stop businesses from providing customer service via bots within WhatsApp to their customers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its notice, Brazil’s competition agency said it would investigate if Meta’s terms are exclusionary to competitors and unduly favor Meta AI, the company’s chatbot that’s offered on WhatsApp.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has previously provided a similar exemption to users in Italy after the country’s competition agency took issue with the policy in December. Separately, the EU has also opened an antitrust investigation into the new rules.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has consistently maintained that AI chatbots are straining its systems that were designed for different uses of its business API. Meta has even said in the past that people who want to use different chatbots can do so outside WhatsApp.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These claims are fundamentally flawed,” a WhatsApp spokesperson said in response to CADE’s probe on Tuesday. “The emergence of AI chatbots on our Business API put a strain on our systems that they were not designed to support. This logic assumes WhatsApp is somehow a de facto app store. The route to market for AI companies is the app stores themselves, their websites and industry partnerships; not the WhatsApp Business Platform.” &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/Green-white-apple-logo.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;WhatsApp is allowing AI providers to continue offering their chatbots to users with Brazilian phone numbers, days after the country’s competition regulator ordered the company to suspend its new policy that bars third-party, general-purpose chatbots from being offered on the app via its business API.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Under the new policy, the company is providing a 90-day grace period starting January 15 to developers and AI providers, mandating them to cease responding to user queries on the chat app, and notify users that their chatbots won’t work on WhatsApp. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Now, Meta told developers that they don’t have to notify users with Brazilian phone numbers (with code +55) of any changes or cease offering their services, per a notice to AI providers seen by TechCrunch. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The requirement to cease responding to user queries and implement pre-approved auto-reply language (mentioned below) before January 15, 2026, no longer applies when messaging people with a Brazil country code (+55),” the notice reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;WhatsApp did not immediately respond to a query seeking to confirm the decision.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The policy, which goes into effect from today, impacts general-purpose chatbots like ChatGPT and Grok on the platform. Notably, the policy does not stop businesses from providing customer service via bots within WhatsApp to their customers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its notice, Brazil’s competition agency said it would investigate if Meta’s terms are exclusionary to competitors and unduly favor Meta AI, the company’s chatbot that’s offered on WhatsApp.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has previously provided a similar exemption to users in Italy after the country’s competition agency took issue with the policy in December. Separately, the EU has also opened an antitrust investigation into the new rules.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has consistently maintained that AI chatbots are straining its systems that were designed for different uses of its business API. Meta has even said in the past that people who want to use different chatbots can do so outside WhatsApp.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These claims are fundamentally flawed,” a WhatsApp spokesperson said in response to CADE’s probe on Tuesday. “The emergence of AI chatbots on our Business API put a strain on our systems that they were not designed to support. This logic assumes WhatsApp is somehow a de facto app store. The route to market for AI companies is the app stores themselves, their websites and industry partnerships; not the WhatsApp Business Platform.” &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/15/after-italy-whatsapp-excludes-brazil-from-rival-chatbot-ban/</guid><pubDate>Thu, 15 Jan 2026 12:23:07 +0000</pubDate></item><item><title>[NEW] The Download: spying on the spies, and promising climate tech (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/15/1131361/the-download-spying-on-the-spies-and-promising-climate-tech/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;Meet the man hunting the spies in your smartphone&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In April 2025, Ronald Deibert left all electronic devices at home in Toronto and boarded a plane. When he landed in Illinois, he bought a new laptop and iPhone. He wanted to reduce the risk of having his personal devices confiscated, because he knew his work made him a prime target for surveillance. “I’m traveling under the assumption that I am being watched, right down to exactly where I am at any moment,” Deibert says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Deibert directs the Citizen Lab, a research center he founded in 2001 to serve as “counterintelligence for civil society.” Housed at the University of Toronto, it’s one of the few institutions that investigate cyberthreats exclusively in the public interest, and in doing so, it has exposed some of the most egregious digital abuses of the past two decades.&lt;/p&gt;  &lt;p&gt;For many years, Deibert and his colleagues have held up the US as the standard for liberal democracy. But that’s changing.&amp;nbsp;Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Finian Hazen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the&amp;nbsp;latest issue&amp;nbsp;of our print magazine. If you&amp;nbsp;subscribe now&amp;nbsp;to receive future copies when they land you’ll benefit from some big discounts, and get a free tote bag!&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Three climate technologies breaking through in 2026&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Happy New Year! I know it’s a bit late to say, but it never quite feels like the year has started until the new edition of our 10 Breakthrough Technologies list comes out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For 25 years, MIT Technology Review has put together this package, which highlights the technologies that we think are going to matter in the future. This year’s version has a bunch of climate and energy picks including sodium-ion batteries, next-generation nuclear, and hyperscale AI data centers. Let’s take a look at what ended up on the list, and what it says about this moment for climate tech.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;This story ran in The Spark, our weekly newsletter all about the technologies we can use to combat climate change. &lt;/strong&gt;&lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; to get it in your inbox first every Wednesday.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And, if you’re keen to learn more about why AI companies are betting big on next-gen nuclear, &lt;/strong&gt;&lt;strong&gt;join us&lt;/strong&gt;&lt;strong&gt; for an exclusive subscriber-only Roundtable event on Wednesday January 28 at 2pm ET.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;     

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 AI companies are now deeply entwined with the US military&lt;/strong&gt;&lt;br /&gt;And it looks like they’re only set to get closer. (Wired&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Three open questions about the Pentagon’s push for generative AI.&amp;nbsp;&lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Grok will comply with local laws, X has said&lt;/strong&gt;&lt;br /&gt;A global backlash over users creating ‘undressing’ images of real people seems to have forced its hand. (BBC)&lt;br /&gt;+&lt;em&gt;&amp;nbsp;So far there’s no evidence it’s actually following through on that promise though&lt;/em&gt;. (The Verge)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Elon Musk could stop it all instantly if he &lt;/em&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;em&gt;wanted to.&lt;/em&gt;&amp;nbsp;(Engadget)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 The risks of using AI in schools outweigh the benefits&lt;/strong&gt;&lt;br /&gt;According to a sweeping new study by the Brookings Institution's Center for Universal Education. (NPR)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;AI’s giants are trying to take over the classroom&lt;/em&gt;. (MIT Technology Review)&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Trump is imposing new tariffs on high-end chips&lt;/strong&gt;&lt;br /&gt;They’re pretty narrow though, and leave plenty of room for exports to China. (WP&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Zhipu AI says it’s trained its first major model entirely on Chinese chips.&lt;/em&gt;&amp;nbsp;(South China Morning Post)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;5 A UK police force blamed Microsoft Copilot for an intelligence error&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;After spending weeks denying it was using AI tools at all. (Ars Technica)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Worried about police and lawyers using AI? Well, judges are at it too.&amp;nbsp;&lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Inside the compounds where the fraud industry makes its billions&lt;/strong&gt;&lt;br /&gt;The details are grim—for example the fact workers struck a gong every time they scammed someone out of $5,000. (NYT&amp;nbsp;$)&lt;br /&gt;+&lt;em&gt;&amp;nbsp;Inside a romance scam compound—and how people get tricked into being there. (&lt;/em&gt;MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Bandcamp has banned purely AI-generated music from its platform&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s the first online music platform to take this step. (Billboard)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Can AI generate new ideas?&amp;nbsp;&lt;/em&gt;(NYT&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8 Remember Havana Syndrome? The US may have found the device that causes it&lt;/strong&gt;&lt;br /&gt;It was acquired for millions of dollars under the last administration, and it’s still being studied. (CNN)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 This study failed to prove social media time causes teens’ mental health issues&lt;/strong&gt;&lt;br /&gt;It’s a common assumption, but there’s still remarkably little evidence to back it up. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 The UK is planning to build a record-breaking number of wind farms&lt;/strong&gt;&lt;br /&gt;Its government is pushing for the vast majority of the country’s electricity to come from clean sources by 2030. (BBC)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Women and girls are far more reluctant to use AI. This should be no surprise to any of us. Women don’t see this as exciting new technology, but as simply new ways to harass and abuse us and try and push us offline.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Clare McGlynn, a law professor at Durham University, tells The Guardian she fears that the use of AI to harm women and girls is only going to grow.&amp;nbsp;&lt;br /&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Climate researchers at work in an office environment look out the window to see corporate lobbyists waving from their boardroom in the building next door" class="wp-image-1073078" src="https://wp.technologyreview.com/wp-content/uploads/2023/05/SBTi_stolle.jpeg" /&gt;&lt;div class="image-credit"&gt;DANIEL STOLLE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Inside the little-known group setting the corporate climate agenda&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;As thousands of companies trumpet their plans to cut carbon pollution, a small group of sustainability consultants has emerged as the go-to arbiter of corporate climate action.&lt;/p&gt;  &lt;p&gt;The Science Based Targets initiative, or SBTi, helps businesses develop a timetable for action to shrink their climate footprint through some combination of cutting greenhouse-gas pollution and removing carbon dioxide from the atmosphere. After years of small-scale sustainability work, SBTi is growing rapidly, and governments are paying attention.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But while the group has earned praise for reeling the private sector into constructive conversations about climate emissions, its rising influence has also attracted scrutiny and raised questions about why a single organization is setting the standards for many of the world’s largest companies. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ian Morse&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The leaders of Japan and South Korea&amp;nbsp;drummed up a viral moment&amp;nbsp;with a jam session this week.&amp;nbsp;&lt;br /&gt;+ Struggle during the cold, dark winter months?&amp;nbsp;Here’s how to make things easier for yourself.&amp;nbsp;&lt;br /&gt;+ If you like getting lost in the depths of Wikipedia,&amp;nbsp;Freakpages&amp;nbsp;is for you.&amp;nbsp;&lt;br /&gt;+ From Pluribus to Stranger Things, we really can’t get enough of&amp;nbsp;hive mindsin stories lately. ($)&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;h3 class="wp-block-heading has-medium-font-size"&gt;&lt;strong&gt;Meet the man hunting the spies in your smartphone&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;In April 2025, Ronald Deibert left all electronic devices at home in Toronto and boarded a plane. When he landed in Illinois, he bought a new laptop and iPhone. He wanted to reduce the risk of having his personal devices confiscated, because he knew his work made him a prime target for surveillance. “I’m traveling under the assumption that I am being watched, right down to exactly where I am at any moment,” Deibert says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Deibert directs the Citizen Lab, a research center he founded in 2001 to serve as “counterintelligence for civil society.” Housed at the University of Toronto, it’s one of the few institutions that investigate cyberthreats exclusively in the public interest, and in doing so, it has exposed some of the most egregious digital abuses of the past two decades.&lt;/p&gt;  &lt;p&gt;For many years, Deibert and his colleagues have held up the US as the standard for liberal democracy. But that’s changing.&amp;nbsp;Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Finian Hazen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the&amp;nbsp;latest issue&amp;nbsp;of our print magazine. If you&amp;nbsp;subscribe now&amp;nbsp;to receive future copies when they land you’ll benefit from some big discounts, and get a free tote bag!&amp;nbsp;&lt;/strong&gt;&lt;/p&gt; 
   &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Three climate technologies breaking through in 2026&amp;nbsp;&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;&lt;em&gt;—Casey Crownhart&amp;nbsp;&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;Happy New Year! I know it’s a bit late to say, but it never quite feels like the year has started until the new edition of our 10 Breakthrough Technologies list comes out.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For 25 years, MIT Technology Review has put together this package, which highlights the technologies that we think are going to matter in the future. This year’s version has a bunch of climate and energy picks including sodium-ion batteries, next-generation nuclear, and hyperscale AI data centers. Let’s take a look at what ended up on the list, and what it says about this moment for climate tech.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;This story ran in The Spark, our weekly newsletter all about the technologies we can use to combat climate change. &lt;/strong&gt;&lt;strong&gt;Sign up&lt;/strong&gt;&lt;strong&gt; to get it in your inbox first every Wednesday.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;And, if you’re keen to learn more about why AI companies are betting big on next-gen nuclear, &lt;/strong&gt;&lt;strong&gt;join us&lt;/strong&gt;&lt;strong&gt; for an exclusive subscriber-only Roundtable event on Wednesday January 28 at 2pm ET.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;     

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 AI companies are now deeply entwined with the US military&lt;/strong&gt;&lt;br /&gt;And it looks like they’re only set to get closer. (Wired&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Three open questions about the Pentagon’s push for generative AI.&amp;nbsp;&lt;/em&gt;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;2 Grok will comply with local laws, X has said&lt;/strong&gt;&lt;br /&gt;A global backlash over users creating ‘undressing’ images of real people seems to have forced its hand. (BBC)&lt;br /&gt;+&lt;em&gt;&amp;nbsp;So far there’s no evidence it’s actually following through on that promise though&lt;/em&gt;. (The Verge)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Elon Musk could stop it all instantly if he &lt;/em&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;em&gt;wanted to.&lt;/em&gt;&amp;nbsp;(Engadget)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 The risks of using AI in schools outweigh the benefits&lt;/strong&gt;&lt;br /&gt;According to a sweeping new study by the Brookings Institution's Center for Universal Education. (NPR)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;AI’s giants are trying to take over the classroom&lt;/em&gt;. (MIT Technology Review)&amp;nbsp;&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;4 Trump is imposing new tariffs on high-end chips&lt;/strong&gt;&lt;br /&gt;They’re pretty narrow though, and leave plenty of room for exports to China. (WP&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Zhipu AI says it’s trained its first major model entirely on Chinese chips.&lt;/em&gt;&amp;nbsp;(South China Morning Post)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;5 A UK police force blamed Microsoft Copilot for an intelligence error&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;After spending weeks denying it was using AI tools at all. (Ars Technica)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Worried about police and lawyers using AI? Well, judges are at it too.&amp;nbsp;&lt;/em&gt;(MIT Technology Review)&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Inside the compounds where the fraud industry makes its billions&lt;/strong&gt;&lt;br /&gt;The details are grim—for example the fact workers struck a gong every time they scammed someone out of $5,000. (NYT&amp;nbsp;$)&lt;br /&gt;+&lt;em&gt;&amp;nbsp;Inside a romance scam compound—and how people get tricked into being there. (&lt;/em&gt;MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Bandcamp has banned purely AI-generated music from its platform&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;It’s the first online music platform to take this step. (Billboard)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Can AI generate new ideas?&amp;nbsp;&lt;/em&gt;(NYT&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;8 Remember Havana Syndrome? The US may have found the device that causes it&lt;/strong&gt;&lt;br /&gt;It was acquired for millions of dollars under the last administration, and it’s still being studied. (CNN)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 This study failed to prove social media time causes teens’ mental health issues&lt;/strong&gt;&lt;br /&gt;It’s a common assumption, but there’s still remarkably little evidence to back it up. (The Guardian)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 The UK is planning to build a record-breaking number of wind farms&lt;/strong&gt;&lt;br /&gt;Its government is pushing for the vast majority of the country’s electricity to come from clean sources by 2030. (BBC)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“Women and girls are far more reluctant to use AI. This should be no surprise to any of us. Women don’t see this as exciting new technology, but as simply new ways to harass and abuse us and try and push us offline.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Clare McGlynn, a law professor at Durham University, tells The Guardian she fears that the use of AI to harm women and girls is only going to grow.&amp;nbsp;&lt;br /&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Climate researchers at work in an office environment look out the window to see corporate lobbyists waving from their boardroom in the building next door" class="wp-image-1073078" src="https://wp.technologyreview.com/wp-content/uploads/2023/05/SBTi_stolle.jpeg" /&gt;&lt;div class="image-credit"&gt;DANIEL STOLLE&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;h4 class="wp-block-heading"&gt;&lt;strong&gt;Inside the little-known group setting the corporate climate agenda&lt;/strong&gt;&lt;/h4&gt;  &lt;p&gt;As thousands of companies trumpet their plans to cut carbon pollution, a small group of sustainability consultants has emerged as the go-to arbiter of corporate climate action.&lt;/p&gt;  &lt;p&gt;The Science Based Targets initiative, or SBTi, helps businesses develop a timetable for action to shrink their climate footprint through some combination of cutting greenhouse-gas pollution and removing carbon dioxide from the atmosphere. After years of small-scale sustainability work, SBTi is growing rapidly, and governments are paying attention.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But while the group has earned praise for reeling the private sector into constructive conversations about climate emissions, its rising influence has also attracted scrutiny and raised questions about why a single organization is setting the standards for many of the world’s largest companies. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Ian Morse&lt;/em&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ The leaders of Japan and South Korea&amp;nbsp;drummed up a viral moment&amp;nbsp;with a jam session this week.&amp;nbsp;&lt;br /&gt;+ Struggle during the cold, dark winter months?&amp;nbsp;Here’s how to make things easier for yourself.&amp;nbsp;&lt;br /&gt;+ If you like getting lost in the depths of Wikipedia,&amp;nbsp;Freakpages&amp;nbsp;is for you.&amp;nbsp;&lt;br /&gt;+ From Pluribus to Stranger Things, we really can’t get enough of&amp;nbsp;hive mindsin stories lately. ($)&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/15/1131361/the-download-spying-on-the-spies-and-promising-climate-tech/</guid><pubDate>Thu, 15 Jan 2026 13:10:39 +0000</pubDate></item><item><title>[NEW] Meeting the new ETSI standard for AI security (AI News)</title><link>https://www.artificialintelligence-news.com/news/meeting-the-new-etsi-standard-for-ai-security/</link><description>&lt;p&gt;The ETSI EN 304 223 standard introduces baseline security requirements for AI that enterprises must integrate into governance frameworks.&lt;/p&gt;&lt;p&gt;As organisations embed machine learning into their core operations, this European Standard (EN) establishes concrete provisions for securing AI models and systems. It stands as the first globally applicable European Standard for AI cybersecurity, having secured formal approval from National Standards Organisations to strengthen its authority across international markets.&lt;/p&gt;&lt;p&gt;The standard serves as a necessary benchmark alongside the EU AI Act. It addresses the reality that AI systems possess specific risks – such as susceptibility to data poisoning, model obfuscation, and indirect prompt injection – that traditional software security measures often miss. The standard covers deep neural networks and generative AI through to basic predictive systems, explicitly excluding only those used strictly for academic research.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-etsi-standard-clarifies-the-chain-of-responsibility-for-ai-security"&gt;ETSI standard clarifies the chain of responsibility for AI security&lt;/h3&gt;&lt;p&gt;A persistent hurdle in enterprise AI adoption is determining who owns the risk. The ETSI standard resolves this by defining three primary technical roles: Developers, System Operators, and Data Custodians.&lt;/p&gt;&lt;p&gt;For many enterprises, these lines blur. A financial services firm that fine-tunes an open-source model for fraud detection counts as both a Developer and a System Operator. This dual status triggers strict obligations, requiring the firm to secure the deployment infrastructure while documenting the provenance of training data and the model’s design auditing.&lt;/p&gt;&lt;p&gt;The inclusion of ‘Data Custodians’ as a distinct stakeholder group directly impacts Chief Data and Analytics Officers (CDAOs). These entities control data permissions and integrity, a role that now carries explicit security responsibilities. Custodians must ensure that the intended usage of a system aligns with the sensitivity of the training data, effectively placing a security gatekeeper within the data management workflow.&lt;/p&gt;&lt;p&gt;ETSI’s AI standard makes clear that security cannot be an afterthought appended at the deployment stage. During the design phase, organisations must conduct threat modelling that addresses AI-native attacks, such as membership inference and model obfuscation.&lt;/p&gt;&lt;p&gt;One provision requires developers to restrict functionality to reduce the attack surface. For instance, if a system uses a multi-modal model but only requires text processing, the unused modalities (like image or audio processing) represent a risk that must be managed. This requirement forces technical leaders to reconsider the common practice of deploying massive, general-purpose foundation models where a smaller and more specialised model would suffice.&lt;/p&gt;&lt;p&gt;The document also enforces strict asset management. Developers and System Operators must maintain a comprehensive inventory of assets, including interdependencies and connectivity. This supports shadow AI discovery; IT leaders cannot secure models they do not know exist. The standard also requires the creation of specific disaster recovery plans tailored to AI attacks, ensuring that a “known good state” can be restored if a model is compromised.&lt;/p&gt;&lt;p&gt;Supply chain security presents an immediate friction point for enterprises relying on third-party vendors or open-source repositories. The ETSI standard requires that if a System Operator chooses to use AI models or components that are not well-documented, they must justify that decision and document the associated security risks.&lt;/p&gt;&lt;p&gt;Practically, procurement teams can no longer accept “black box” solutions. Developers are required to provide cryptographic hashes for model components to verify authenticity. Where training data is sourced publicly (a common practice for Large Language Models), developers must document the source URL and acquisition timestamp. This audit trail is necessary for post-incident investigations, particularly when attempting to identify if a model was subjected to data poisoning during its training phase.&lt;/p&gt;&lt;p&gt;If an enterprise offers an API to external customers, they must apply controls designed to mitigate AI-focused attacks, such as rate limiting to prevent adversaries from reverse-engineering the model or overwhelming defences to inject poison data.&lt;/p&gt;&lt;p&gt;The lifecycle approach extends into the maintenance phase, where the standard treats major updates – such as retraining on new data – as the deployment of a new version. Under the ETSI AI standard, this triggers a requirement for renewed security testing and evaluation.&lt;/p&gt;&lt;p&gt;Continuous monitoring is also formalised. System Operators must analyse logs not just for uptime, but to detect “data drift” or gradual changes in behaviour that could indicate a security breach. This moves AI monitoring from a performance metric to a security discipline.&lt;/p&gt;&lt;p&gt;The standard also addresses the “End of Life” phase. When a model is decommissioned or transferred, organisations must involve Data Custodians to ensure the secure disposal of data and configuration details. This provision prevents the leakage of sensitive intellectual property or training data through discarded hardware or forgotten cloud instances.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-executive-oversight-and-governance"&gt;Executive oversight and governance&lt;/h3&gt;&lt;p&gt;Compliance with ETSI EN 304 223 requires a review of existing cybersecurity training programmes. The standard mandates that training be tailored to specific roles, ensuring that developers understand secure coding for AI while general staff remain aware of threats like social engineering via AI outputs.&lt;/p&gt;&lt;p&gt;“ETSI EN 304 223 represents an important step forward in establishing a common, rigorous foundation for securing AI systems”, said Scott Cadzow, Chair of ETSI’s Technical Committee for Securing Artificial Intelligence.&lt;/p&gt;&lt;p&gt;“At a time when AI is being increasingly integrated into critical services and infrastructure, the availability of clear, practical guidance that reflects both the complexity of these technologies and the realities of deployment cannot be underestimated. The work that went into delivering this framework is the result of extensive collaboration and it means that organisations can have full confidence in AI systems that are resilient, trustworthy, and secure by design.”&lt;/p&gt;&lt;p&gt;Implementing these baselines in ETSI’s AI security standard provides a structure for safer innovation. By enforcing documented audit trails, clear role definitions, and supply chain transparency, enterprises can mitigate the risks associated with AI adoption while establishing a defensible position for future regulatory audits.&lt;/p&gt;&lt;p&gt;An upcoming Technical Report (ETSI TR 104 159) will apply these principles specifically to generative AI, targeting issues like deepfakes and disinformation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Allister Frost: Tackling workforce anxiety for AI integration success&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The ETSI EN 304 223 standard introduces baseline security requirements for AI that enterprises must integrate into governance frameworks.&lt;/p&gt;&lt;p&gt;As organisations embed machine learning into their core operations, this European Standard (EN) establishes concrete provisions for securing AI models and systems. It stands as the first globally applicable European Standard for AI cybersecurity, having secured formal approval from National Standards Organisations to strengthen its authority across international markets.&lt;/p&gt;&lt;p&gt;The standard serves as a necessary benchmark alongside the EU AI Act. It addresses the reality that AI systems possess specific risks – such as susceptibility to data poisoning, model obfuscation, and indirect prompt injection – that traditional software security measures often miss. The standard covers deep neural networks and generative AI through to basic predictive systems, explicitly excluding only those used strictly for academic research.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-etsi-standard-clarifies-the-chain-of-responsibility-for-ai-security"&gt;ETSI standard clarifies the chain of responsibility for AI security&lt;/h3&gt;&lt;p&gt;A persistent hurdle in enterprise AI adoption is determining who owns the risk. The ETSI standard resolves this by defining three primary technical roles: Developers, System Operators, and Data Custodians.&lt;/p&gt;&lt;p&gt;For many enterprises, these lines blur. A financial services firm that fine-tunes an open-source model for fraud detection counts as both a Developer and a System Operator. This dual status triggers strict obligations, requiring the firm to secure the deployment infrastructure while documenting the provenance of training data and the model’s design auditing.&lt;/p&gt;&lt;p&gt;The inclusion of ‘Data Custodians’ as a distinct stakeholder group directly impacts Chief Data and Analytics Officers (CDAOs). These entities control data permissions and integrity, a role that now carries explicit security responsibilities. Custodians must ensure that the intended usage of a system aligns with the sensitivity of the training data, effectively placing a security gatekeeper within the data management workflow.&lt;/p&gt;&lt;p&gt;ETSI’s AI standard makes clear that security cannot be an afterthought appended at the deployment stage. During the design phase, organisations must conduct threat modelling that addresses AI-native attacks, such as membership inference and model obfuscation.&lt;/p&gt;&lt;p&gt;One provision requires developers to restrict functionality to reduce the attack surface. For instance, if a system uses a multi-modal model but only requires text processing, the unused modalities (like image or audio processing) represent a risk that must be managed. This requirement forces technical leaders to reconsider the common practice of deploying massive, general-purpose foundation models where a smaller and more specialised model would suffice.&lt;/p&gt;&lt;p&gt;The document also enforces strict asset management. Developers and System Operators must maintain a comprehensive inventory of assets, including interdependencies and connectivity. This supports shadow AI discovery; IT leaders cannot secure models they do not know exist. The standard also requires the creation of specific disaster recovery plans tailored to AI attacks, ensuring that a “known good state” can be restored if a model is compromised.&lt;/p&gt;&lt;p&gt;Supply chain security presents an immediate friction point for enterprises relying on third-party vendors or open-source repositories. The ETSI standard requires that if a System Operator chooses to use AI models or components that are not well-documented, they must justify that decision and document the associated security risks.&lt;/p&gt;&lt;p&gt;Practically, procurement teams can no longer accept “black box” solutions. Developers are required to provide cryptographic hashes for model components to verify authenticity. Where training data is sourced publicly (a common practice for Large Language Models), developers must document the source URL and acquisition timestamp. This audit trail is necessary for post-incident investigations, particularly when attempting to identify if a model was subjected to data poisoning during its training phase.&lt;/p&gt;&lt;p&gt;If an enterprise offers an API to external customers, they must apply controls designed to mitigate AI-focused attacks, such as rate limiting to prevent adversaries from reverse-engineering the model or overwhelming defences to inject poison data.&lt;/p&gt;&lt;p&gt;The lifecycle approach extends into the maintenance phase, where the standard treats major updates – such as retraining on new data – as the deployment of a new version. Under the ETSI AI standard, this triggers a requirement for renewed security testing and evaluation.&lt;/p&gt;&lt;p&gt;Continuous monitoring is also formalised. System Operators must analyse logs not just for uptime, but to detect “data drift” or gradual changes in behaviour that could indicate a security breach. This moves AI monitoring from a performance metric to a security discipline.&lt;/p&gt;&lt;p&gt;The standard also addresses the “End of Life” phase. When a model is decommissioned or transferred, organisations must involve Data Custodians to ensure the secure disposal of data and configuration details. This provision prevents the leakage of sensitive intellectual property or training data through discarded hardware or forgotten cloud instances.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-executive-oversight-and-governance"&gt;Executive oversight and governance&lt;/h3&gt;&lt;p&gt;Compliance with ETSI EN 304 223 requires a review of existing cybersecurity training programmes. The standard mandates that training be tailored to specific roles, ensuring that developers understand secure coding for AI while general staff remain aware of threats like social engineering via AI outputs.&lt;/p&gt;&lt;p&gt;“ETSI EN 304 223 represents an important step forward in establishing a common, rigorous foundation for securing AI systems”, said Scott Cadzow, Chair of ETSI’s Technical Committee for Securing Artificial Intelligence.&lt;/p&gt;&lt;p&gt;“At a time when AI is being increasingly integrated into critical services and infrastructure, the availability of clear, practical guidance that reflects both the complexity of these technologies and the realities of deployment cannot be underestimated. The work that went into delivering this framework is the result of extensive collaboration and it means that organisations can have full confidence in AI systems that are resilient, trustworthy, and secure by design.”&lt;/p&gt;&lt;p&gt;Implementing these baselines in ETSI’s AI security standard provides a structure for safer innovation. By enforcing documented audit trails, clear role definitions, and supply chain transparency, enterprises can mitigate the risks associated with AI adoption while establishing a defensible position for future regulatory audits.&lt;/p&gt;&lt;p&gt;An upcoming Technical Report (ETSI TR 104 159) will apply these principles specifically to generative AI, targeting issues like deepfakes and disinformation.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Allister Frost: Tackling workforce anxiety for AI integration success&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111551" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-2.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/meeting-the-new-etsi-standard-for-ai-security/</guid><pubDate>Thu, 15 Jan 2026 13:23:47 +0000</pubDate></item><item><title>[NEW] OptiMind: A small language model with optimization expertise (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/optimind-a-small-language-model-with-optimization-expertise/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A flowchart with three horizontal sections on a blue-to-green gradient background. The first section, labeled “Classification,” shows icons of a computer, an arrow pointing to a robot face, and another arrow pointing to a box labeled “TSP.” The second section, labeled “Inference,” displays a robot icon connected by arrows to two document icons, one of which includes a magnifying glass. The third section, labeled “Test-time scaling,” shows a document with a checkmark connected by an arrow to a circular refresh icon. Arrows indicate the flow between sections, starting from Classification to Inference and then to Test-time scaling." class="wp-image-1159915" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/OptiMind-BlogHeroFeature-1400x788-2.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-style-default mb-10 pb-1 pr-1 is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Many real-world business problems can benefit from optimization, but translating decisions, constraints, and goals from natural language into optimization algorithms is slow.&lt;/li&gt;



&lt;li&gt;OptiMind is a small language model designed to convert business problems described in natural language into the mathematical formulations needed by optimization software.&lt;/li&gt;



&lt;li&gt;OptiMind&amp;nbsp;is trained on&amp;nbsp;a carefully curated, expert-aligned dataset&amp;nbsp;and applies domain-specific hints and self-checks at inference time, improving&amp;nbsp;its&amp;nbsp;accuracy.&lt;/li&gt;



&lt;li&gt;OptiMind&amp;nbsp;matches or exceeds the performance of much larger systems,&amp;nbsp;can&amp;nbsp;run&amp;nbsp;locally to protect sensitive data,&amp;nbsp;produces&amp;nbsp;more reliable formulations, and&amp;nbsp;reduces the time and&amp;nbsp;expertise&amp;nbsp;needed to prepare optimization models.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;Enterprises across industries, from energy to finance, use optimization models to plan complex operations like supply chains and logistics. These models work by defining three elements: the choices that can be made (such as production quantities or delivery routes), the rules and limits those choices must follow, and the goal, whether that’s minimizing costs, meeting customer demand, or improving efficiency.&lt;/p&gt;



&lt;p&gt;Over the past few decades,&amp;nbsp;many&amp;nbsp;businesses have shifted&amp;nbsp;from&amp;nbsp;judgment-based decision-making to data-driven&amp;nbsp;approaches,&amp;nbsp;leading to&amp;nbsp;major&amp;nbsp;efficiency gains and cost&amp;nbsp;savings. Advances in AI promise to accelerate this shift even further, potentially cutting decision times from days to minutes while delivering better results.&lt;/p&gt;



&lt;p&gt;In practice, however, turning real-world business problems into a form that optimization software can understand is challenging. This translation process requires expressing decisions, constraints, and objectives in mathematical terms. The work demands specialized&amp;nbsp;expertise,&amp;nbsp;and&amp;nbsp;it&amp;nbsp;can take anywhere from&amp;nbsp;one&amp;nbsp;day to several weeks&amp;nbsp;to solve&amp;nbsp;complex problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address this challenge, we’re introducing OptiMind, a small language model designed to convert problems described in plain language into the mathematical formulations that optimization software needs. Built on a 20-billion parameter model, OptiMind is compact by today’s standards yet matches the performance of larger, more complex systems. Its modest size means it can run locally on users’ devices, enabling fast iteration while keeping sensitive business data on users’ devices rather than transmitting it to external servers.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="how-it-works"&gt;How it works&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;OptiMind incorporates knowledge from optimization experts both during training and when it’s being used to improve formulation accuracy at scale. Three stages enable this: domain-specific hints improve training data quality, the model undergoes fine-tuning, and expert reasoning guides the model as it works.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="The image illustrates a linear programming model for a manufacturing facility, detailing the production quantities, setup indicators, and inventory levels for different products over a six-month period, aiming to optimize costs." class="wp-image-1160007" height="750" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/OptiMind-1-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1.&amp;nbsp;From problem description to solution&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;One of the central challenges&amp;nbsp;in&amp;nbsp;developing&amp;nbsp;OptiMind was the poor quality of existing public datasets for optimization problems. Many examples were incomplete or&amp;nbsp;contained incorrect solutions. To address this, we developed a systematic approach that combines automation with expert review. It organizes problems into well-known categories, such as scheduling or routing, and identifies common error patterns within each. Using these insights, we generated expert-verified “hints” to guide the process, enabling the system to regenerate higher-quality solutions and filter out unsolvable examples (Figure 2). The result is a training dataset that more accurately reflects how optimization experts structure problems.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Process for correcting training data" class="wp-image-1159877" height="638" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/training-data-cleaning.png" width="1648" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Process for correcting training data&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Using this refined dataset, we applied supervised fine-tuning to the base model. Rather than simply generating code, we trained OptiMind to produce structured mathematical formulations alongside intermediate reasoning steps, helping it avoid the common mistakes found in earlier datasets.&lt;/p&gt;



&lt;p&gt;When in use, the model’s reliability further improves. When given a new problem, OptiMind first classifies it into a category, such as scheduling or network design. It then applies expert hints relevant to that type of problem, which act as reminders to check for errors before generating a solution. For particularly challenging problems, the system generates multiple solutions and either selects the most&amp;nbsp;frequently&amp;nbsp;occurring one or uses feedback to refine its response. This approach increases accuracy without requiring a larger model, as illustrated in Figure 3.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="OptiMind’s inference process" class="wp-image-1159878" height="817" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/inference-pipeline.png" width="2057" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. OptiMind’s inference process&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluation"&gt;Evaluation&lt;/h2&gt;



&lt;p&gt;To test the system, we turned to three widely used public benchmarks that&amp;nbsp;represent&amp;nbsp;some of the most complex formulation tasks in the field. On closer inspection, we discovered that&amp;nbsp;30 to 50 percent&amp;nbsp;of the original test data was flawed.&amp;nbsp;After manually correcting the issues, OptiMind improved accuracy by approximately 10 percent over the base model. Figure 4 and Table 1 show detailed comparisons: OptiMind outperformed other open-source models under 32 billion parameters and, when combined with expert hints and correction strategies, matched or exceeded the performance of current leading models.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Average accuracy percentages over all models." class="wp-image-1160042" height="457" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/main_barplot_new-1.png" width="1231" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Average accuracy percentages over all models.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Performance of all models on corrected benchmark datasets" class="wp-image-1159880" height="922" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/main-results-table.png" width="2122" /&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1. Performance of all models on corrected benchmark datasets&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;OptiMind is more reliable than other models because it learns from higher-quality, domain-aligned data. And by correcting errors and inconsistencies in standard datasets, we significantly reduced the model’s tendency to hallucinate relative&amp;nbsp;to the base and comparison models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="looking-forward"&gt;Looking forward&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;While supervised fine-tuning has provided a strong foundation, we are exploring reinforcement learning to further refine OptiMind’s reasoning capabilities. We’re also investigating automated frameworks that would allow LLMs to generate their own expert hints, enabling continuous autonomous improvement. Additionally, we are working with Microsoft product teams and industry collaborators to expand OptiMind’s utility, adding support for more programming languages and a variety of input formats, including Excel and other widely used tools.&lt;/p&gt;



&lt;p&gt;We’re releasing OptiMind as an experimental model to gather community feedback and inform future development. The model is available through Microsoft Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and we’ve open-sourced the benchmarks and data-processing procedures on GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to support more reliable evaluation across the field. We welcome feedback through GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and invite those interested in shaping the future of optimization to&amp;nbsp;apply for one of our&amp;nbsp;open roles.&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="A flowchart with three horizontal sections on a blue-to-green gradient background. The first section, labeled “Classification,” shows icons of a computer, an arrow pointing to a robot face, and another arrow pointing to a box labeled “TSP.” The second section, labeled “Inference,” displays a robot icon connected by arrows to two document icons, one of which includes a magnifying glass. The third section, labeled “Test-time scaling,” shows a document with a checkmark connected by an arrow to a circular refresh icon. Arrows indicate the flow between sections, starting from Classification to Inference and then to Test-time scaling." class="wp-image-1159915" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/OptiMind-BlogHeroFeature-1400x788-2.jpg" width="1400" /&gt;&lt;/figure&gt;



&lt;div class="wp-block-msr-immersive-section alignfull row wp-block-msr-immersive-section"&gt;
	
	&lt;div class="container"&gt;
		&lt;div class="wp-block-msr-immersive-section__inner wp-block-msr-immersive-section__inner--narrow"&gt;
			&lt;div class="wp-block-columns is-layout-flex wp-container-core-columns-is-layout-9d6595d7 wp-block-columns-is-layout-flex"&gt;
&lt;div class="wp-block-column is-style-default mb-10 pb-1 pr-1 is-layout-flow wp-block-column-is-layout-flow"&gt;
&lt;h2 class="wp-block-heading h3" id="at-a-glance"&gt;At a glance&lt;/h2&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Many real-world business problems can benefit from optimization, but translating decisions, constraints, and goals from natural language into optimization algorithms is slow.&lt;/li&gt;



&lt;li&gt;OptiMind is a small language model designed to convert business problems described in natural language into the mathematical formulations needed by optimization software.&lt;/li&gt;



&lt;li&gt;OptiMind&amp;nbsp;is trained on&amp;nbsp;a carefully curated, expert-aligned dataset&amp;nbsp;and applies domain-specific hints and self-checks at inference time, improving&amp;nbsp;its&amp;nbsp;accuracy.&lt;/li&gt;



&lt;li&gt;OptiMind&amp;nbsp;matches or exceeds the performance of much larger systems,&amp;nbsp;can&amp;nbsp;run&amp;nbsp;locally to protect sensitive data,&amp;nbsp;produces&amp;nbsp;more reliable formulations, and&amp;nbsp;reduces the time and&amp;nbsp;expertise&amp;nbsp;needed to prepare optimization models.&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;		&lt;/div&gt;
	&lt;/div&gt;

	&lt;/div&gt;



&lt;p&gt;Enterprises across industries, from energy to finance, use optimization models to plan complex operations like supply chains and logistics. These models work by defining three elements: the choices that can be made (such as production quantities or delivery routes), the rules and limits those choices must follow, and the goal, whether that’s minimizing costs, meeting customer demand, or improving efficiency.&lt;/p&gt;



&lt;p&gt;Over the past few decades,&amp;nbsp;many&amp;nbsp;businesses have shifted&amp;nbsp;from&amp;nbsp;judgment-based decision-making to data-driven&amp;nbsp;approaches,&amp;nbsp;leading to&amp;nbsp;major&amp;nbsp;efficiency gains and cost&amp;nbsp;savings. Advances in AI promise to accelerate this shift even further, potentially cutting decision times from days to minutes while delivering better results.&lt;/p&gt;



&lt;p&gt;In practice, however, turning real-world business problems into a form that optimization software can understand is challenging. This translation process requires expressing decisions, constraints, and objectives in mathematical terms. The work demands specialized&amp;nbsp;expertise,&amp;nbsp;and&amp;nbsp;it&amp;nbsp;can take anywhere from&amp;nbsp;one&amp;nbsp;day to several weeks&amp;nbsp;to solve&amp;nbsp;complex problems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;To address this challenge, we’re introducing OptiMind, a small language model designed to convert problems described in plain language into the mathematical formulations that optimization software needs. Built on a 20-billion parameter model, OptiMind is compact by today’s standards yet matches the performance of larger, more complex systems. Its modest size means it can run locally on users’ devices, enabling fast iteration while keeping sensitive business data on users’ devices rather than transmitting it to external servers.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Azure AI Foundry Labs&lt;/h2&gt;
				
								&lt;p class="large" id="azure-ai-foundry-labs"&gt;Get a glimpse of potential future directions for AI, with these experimental technologies from Microsoft Research.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="how-it-works"&gt;How it works&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;OptiMind incorporates knowledge from optimization experts both during training and when it’s being used to improve formulation accuracy at scale. Three stages enable this: domain-specific hints improve training data quality, the model undergoes fine-tuning, and expert reasoning guides the model as it works.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="The image illustrates a linear programming model for a manufacturing facility, detailing the production quantities, setup indicators, and inventory levels for different products over a six-month period, aiming to optimize costs." class="wp-image-1160007" height="750" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/OptiMind-1-scaled.jpg" width="2560" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 1.&amp;nbsp;From problem description to solution&amp;nbsp;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;One of the central challenges&amp;nbsp;in&amp;nbsp;developing&amp;nbsp;OptiMind was the poor quality of existing public datasets for optimization problems. Many examples were incomplete or&amp;nbsp;contained incorrect solutions. To address this, we developed a systematic approach that combines automation with expert review. It organizes problems into well-known categories, such as scheduling or routing, and identifies common error patterns within each. Using these insights, we generated expert-verified “hints” to guide the process, enabling the system to regenerate higher-quality solutions and filter out unsolvable examples (Figure 2). The result is a training dataset that more accurately reflects how optimization experts structure problems.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Process for correcting training data" class="wp-image-1159877" height="638" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/training-data-cleaning.png" width="1648" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Process for correcting training data&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Using this refined dataset, we applied supervised fine-tuning to the base model. Rather than simply generating code, we trained OptiMind to produce structured mathematical formulations alongside intermediate reasoning steps, helping it avoid the common mistakes found in earlier datasets.&lt;/p&gt;



&lt;p&gt;When in use, the model’s reliability further improves. When given a new problem, OptiMind first classifies it into a category, such as scheduling or network design. It then applies expert hints relevant to that type of problem, which act as reminders to check for errors before generating a solution. For particularly challenging problems, the system generates multiple solutions and either selects the most&amp;nbsp;frequently&amp;nbsp;occurring one or uses feedback to refine its response. This approach increases accuracy without requiring a larger model, as illustrated in Figure 3.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="OptiMind’s inference process" class="wp-image-1159878" height="817" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/inference-pipeline.png" width="2057" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. OptiMind’s inference process&lt;/figcaption&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="evaluation"&gt;Evaluation&lt;/h2&gt;



&lt;p&gt;To test the system, we turned to three widely used public benchmarks that&amp;nbsp;represent&amp;nbsp;some of the most complex formulation tasks in the field. On closer inspection, we discovered that&amp;nbsp;30 to 50 percent&amp;nbsp;of the original test data was flawed.&amp;nbsp;After manually correcting the issues, OptiMind improved accuracy by approximately 10 percent over the base model. Figure 4 and Table 1 show detailed comparisons: OptiMind outperformed other open-source models under 32 billion parameters and, when combined with expert hints and correction strategies, matched or exceeded the performance of current leading models.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Average accuracy percentages over all models." class="wp-image-1160042" height="457" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/main_barplot_new-1.png" width="1231" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Average accuracy percentages over all models.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Performance of all models on corrected benchmark datasets" class="wp-image-1159880" height="922" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2026/01/main-results-table.png" width="2122" /&gt;&lt;figcaption class="wp-element-caption"&gt;Table 1. Performance of all models on corrected benchmark datasets&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;OptiMind is more reliable than other models because it learns from higher-quality, domain-aligned data. And by correcting errors and inconsistencies in standard datasets, we significantly reduced the model’s tendency to hallucinate relative&amp;nbsp;to the base and comparison models.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="looking-forward"&gt;Looking forward&lt;strong&gt;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;While supervised fine-tuning has provided a strong foundation, we are exploring reinforcement learning to further refine OptiMind’s reasoning capabilities. We’re also investigating automated frameworks that would allow LLMs to generate their own expert hints, enabling continuous autonomous improvement. Additionally, we are working with Microsoft product teams and industry collaborators to expand OptiMind’s utility, adding support for more programming languages and a variety of input formats, including Excel and other widely used tools.&lt;/p&gt;



&lt;p&gt;We’re releasing OptiMind as an experimental model to gather community feedback and inform future development. The model is available through Microsoft Foundry&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Hugging Face&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and we’ve open-sourced the benchmarks and data-processing procedures on GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; to support more reliable evaluation across the field. We welcome feedback through GitHub&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, and invite those interested in shaping the future of optimization to&amp;nbsp;apply for one of our&amp;nbsp;open roles.&lt;/p&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/optimind-a-small-language-model-with-optimization-expertise/</guid><pubDate>Thu, 15 Jan 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] Parloa triples its valuation in 8 months to $3B with $350M raise (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/15/parloa-triples-its-valuation-in-8-months-to-3b-with-350m-raise/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/2024-MAIN-Parloa-founders-Stefan-Ostwald-Malte-Kosub_1_crop-e1713945437512.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Berlin-based Parloa has raised $350 million in Series D funding from existing investors, valuing the six-year-old customer service AI startup at $3 billion. The round comes just eight months after the company raised $120 million at a $1 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new round was led by General Catalyst, with participation from returning backers including EQT Ventures, Altimeter Capital, Durable Capital, and Mosaic Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Parloa is one of many startups developing AI agents that promise to automate the kind of customer service work previously handled by human representatives and help desk staff.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s competitors include Sierra, co-founded by OpenAI Chairman Bret Taylor, which raised $350 million at a $10 billion valuation in September; and Decagon, reportedly in talks to raise capital at a valuation of upwards of $4 billion. Other companies working to replace human agents with AI include older players Intercom and Kore.ai, as well as the U.K.-based PolyAI, which raised an $86 million round at a $750 million valuation last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Malte Kosub, Parloa’s co-founder and CEO, doesn’t seem fazed by the competition, largely because he doesn’t believe this is a “winner-take-all” category. “In the end, it is one of the biggest opportunities that has ever existed in software,” he told TechCrunch. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, Parloa and its rivals are vying to automate a significant portion of the global customer support workforce, which Gartner estimates at 17 million contact center agents worldwide.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But it’s not just the size of the market that gives Kosub confidence about Parloa’s ability to win. He pointed to the startup’s massive fundraise as a sign that it could be among the top leaders in the space. “There are a lot of companies out there, but you need to look at the scale and the amount of funding they got,” he said. “The number of competitors is decreasing significantly.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Parloa said that it was generating annual recurring revenue of more than $50 million, but that’s not meaningfully ahead of Poly AI, which expected to end 2025 with ARR of $40 million, or Decagon, which is reportedly making “significantly more” than $30 million in ARR. Still, Kosub seems convinced that being so well capitalized will help his startup get ahead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Parloa’s AI agents are already answering calls for large enterprise customers, which include Allianz, Booking.com, HealthEquity, SAP, Sedgwick, and Swiss Life, but the CEO says the goal is to do more than just build software that “picks up the phone.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company will invest a significant portion of its new capital into building a “multi-model, contextual experience” that will allow personalized AI agents to recognize a customer’s identity and specific needs, whether they reach out via an app, a website, or a phone call.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/04/2024-MAIN-Parloa-founders-Stefan-Ostwald-Malte-Kosub_1_crop-e1713945437512.jpg?resize=1200,676" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Berlin-based Parloa has raised $350 million in Series D funding from existing investors, valuing the six-year-old customer service AI startup at $3 billion. The round comes just eight months after the company raised $120 million at a $1 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new round was led by General Catalyst, with participation from returning backers including EQT Ventures, Altimeter Capital, Durable Capital, and Mosaic Ventures.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Parloa is one of many startups developing AI agents that promise to automate the kind of customer service work previously handled by human representatives and help desk staff.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s competitors include Sierra, co-founded by OpenAI Chairman Bret Taylor, which raised $350 million at a $10 billion valuation in September; and Decagon, reportedly in talks to raise capital at a valuation of upwards of $4 billion. Other companies working to replace human agents with AI include older players Intercom and Kore.ai, as well as the U.K.-based PolyAI, which raised an $86 million round at a $750 million valuation last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Malte Kosub, Parloa’s co-founder and CEO, doesn’t seem fazed by the competition, largely because he doesn’t believe this is a “winner-take-all” category. “In the end, it is one of the biggest opportunities that has ever existed in software,” he told TechCrunch. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, Parloa and its rivals are vying to automate a significant portion of the global customer support workforce, which Gartner estimates at 17 million contact center agents worldwide.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But it’s not just the size of the market that gives Kosub confidence about Parloa’s ability to win. He pointed to the startup’s massive fundraise as a sign that it could be among the top leaders in the space. “There are a lot of companies out there, but you need to look at the scale and the amount of funding they got,” he said. “The number of competitors is decreasing significantly.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Last month, Parloa said that it was generating annual recurring revenue of more than $50 million, but that’s not meaningfully ahead of Poly AI, which expected to end 2025 with ARR of $40 million, or Decagon, which is reportedly making “significantly more” than $30 million in ARR. Still, Kosub seems convinced that being so well capitalized will help his startup get ahead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Parloa’s AI agents are already answering calls for large enterprise customers, which include Allianz, Booking.com, HealthEquity, SAP, Sedgwick, and Swiss Life, but the CEO says the goal is to do more than just build software that “picks up the phone.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company will invest a significant portion of its new capital into building a “multi-model, contextual experience” that will allow personalized AI agents to recognize a customer’s identity and specific needs, whether they reach out via an app, a website, or a phone call.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/15/parloa-triples-its-valuation-in-8-months-to-3b-with-350m-raise/</guid><pubDate>Thu, 15 Jan 2026 14:24:46 +0000</pubDate></item><item><title>[NEW] US senators demand answers from X, Meta, Alphabet, and others on sexualized deepfakes (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/15/us-senators-demand-answers-from-x-meta-alphabet-on-sexualized-deepfakes/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The tech world’s nonconsensual, sexualized deepfake problem is now bigger than just X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a letter to the leaders of X, Meta, Alphabet, Snap, Reddit, and TikTok, several U.S. senators are asking the companies to provide proof that they have “robust protections and policies” in place and to explain how they plan to curb the rise of sexualized deepfakes on their platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The senators also demanded that the companies preserve all documents and information relating to the creation, detection, moderation, and monetization of sexualized, AI-generated images, as well as any related policies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter comes hours after X said it updated Grok to prohibit it from making edits of real people in revealing clothing and restricted image creation and edits via Grok to paying subscribers. (X and xAI are part of the same company.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pointing to media reports about how easily and often Grok generated sexualized and nude images of women and children, the senators pointed out that platforms’ guardrails to prevent users from posting nonconsensual, sexualized imagery may not be enough.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We recognize that many companies maintain policies against non-consensual intimate imagery and sexual exploitation, and that many AI systems claim to block explicit pornography. In practice, however, as seen in the examples above, users are finding ways around these guardrails. Or these guardrails are failing,” the letter reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok, and consequently X, have been heavily criticized for enabling this trend, but other platforms are not immune.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Deepfakes first gained popularity on Reddit, when a page displaying synthetic porn videos of celebrities went viral before the platform took it down in 2018. Sexualized deepfakes targeting celebrities and politicians have multiplied on TikTok and YouTube, though they usually originate elsewhere.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s Oversight Board last year called out two cases of explicit AI images of female public figures, and the platform has had nudify apps selling ads on its services, though it did sue a company called CrushAI later. There have been multiple reports of kids spreading deepfakes of peers on Snapchat. And Telegram, which isn’t included on the senators’ list, has also become notorious for hosting bots built to undress photos of women.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to the letter, X pointed to its announcement regarding its update to Grok.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We do not and will not allow any non-consensual intimate media (NCIM) on Reddit, do not offer any tools capable of making it, and take proactive measures to find and remove it,” a Reddit spokesperson said in an emailed statement. “Reddit strictly prohibits NCIM, including depictions that have been faked or AI-generated. We also prohibit soliciting this content from others, sharing links to “nudify” apps, or discussing how to create this content on other platforms,” the spokesperson added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alphabet, Snap, TikTok, and Meta did not immediately respond to requests for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter demands the companies provide: &lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Policy definitions of “deepfake” content, “non-consensual intimate imagery,” or similar terms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Descriptions of the companies’ policies and enforcement approach for nonconsensual AI deepfakes of peoples’ bodies, non-nude pictures, altered clothing, and “virtual undressing.”&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Descriptions of current content policies addressing edited media and explicit content, as well as internal guidance provided to moderators.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How current policies govern AI tools and image generators as they relate to suggestive or intimate content.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What filters, guardrails, or measures have been implemented to prevent the generation and distribution of deepfakes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Which mechanisms the companies use to identify deepfake content and prevent them from being re-uploaded.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How they prevent users from profiting from such content.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How the platforms prevent themselves from monetizing nonconsensual AI-generated content.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How the companies’ terms of service enable them to ban or suspend users who post deepfakes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What the companies do to notify victims of nonconsensual sexual deepfakes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;The letter is signed by Senators Lisa Blunt Rochester (D-Del.), Tammy Baldwin (D-Wis.), Richard Blumenthal (D-Conn.), Kirsten Gillibrand (D-NY), Mark Kelly (D-Ariz.), Ben Ray Luján (D-NM), Brian Schatz (D-Hawaii), and Adam Schiff (D-Calif.).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes just a day after xAI’s owner Elon Musk said that he was “not aware of any naked underage images generated by Grok.” Later on Wednesday, California’s attorney general opened an investigation into xAI’s chatbot, following mounting pressure from governments across the world incensed by the lack of guardrails around Grok that allowed this to happen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI has maintained that it takes action to remove “illegal content on X, including [CSAM] and non-consensual nudity,” though neither the company nor Musk have addressed the fact that Grok was allowed to generate such content in the first place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem isn’t constrained to nonconsensual manipulated sexualized imagery either. While not all AI-based image generation and editing services let users “undress” people, they do let one easily generate deepfakes. To pick a few examples, OpenAI’s Sora 2 reportedly allowed users to generate explicit videos featuring children; Google’s Nano Banana seemingly generated an image showing Charlie Kirk being shot; and racist videos made with Google’s AI video model are garnering millions of views on social media.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The issue grows even more complex when Chinese image and video generators come into the picture. Many Chinese tech companies and apps — especially those linked to ByteDance — offer easy ways to edit faces, voices, and videos, and those outputs have spread to Western social platforms. China has stronger synthetic content labeling requirements that don’t exist in the U.S. on the federal level, where the masses instead rely on fragmented and dubiously enforced policies from the platforms themselves.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;U.S. lawmakers have already passed some legislation seeking to rein in deepfake pornography, but the impact has been limited. The Take It Down Act, which became federal law in May, is meant to criminalize the creation and dissemination of nonconsensual, sexualized imagery. But a number of provisions in the law make it difficult to hold image-generating platforms accountable, as they focus most of the scrutiny on individual users instead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, a number of states are trying to take matters into their own hands to protect consumers and elections. This week, New York governor Kathy Hochul proposed laws that would require AI-generated content to be labeled as such, and ban nonconsensual deepfakes in specified periods leading up to elections, including depictions of opposition candidates.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The tech world’s nonconsensual, sexualized deepfake problem is now bigger than just X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a letter to the leaders of X, Meta, Alphabet, Snap, Reddit, and TikTok, several U.S. senators are asking the companies to provide proof that they have “robust protections and policies” in place and to explain how they plan to curb the rise of sexualized deepfakes on their platforms.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The senators also demanded that the companies preserve all documents and information relating to the creation, detection, moderation, and monetization of sexualized, AI-generated images, as well as any related policies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter comes hours after X said it updated Grok to prohibit it from making edits of real people in revealing clothing and restricted image creation and edits via Grok to paying subscribers. (X and xAI are part of the same company.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pointing to media reports about how easily and often Grok generated sexualized and nude images of women and children, the senators pointed out that platforms’ guardrails to prevent users from posting nonconsensual, sexualized imagery may not be enough.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We recognize that many companies maintain policies against non-consensual intimate imagery and sexual exploitation, and that many AI systems claim to block explicit pornography. In practice, however, as seen in the examples above, users are finding ways around these guardrails. Or these guardrails are failing,” the letter reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok, and consequently X, have been heavily criticized for enabling this trend, but other platforms are not immune.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Deepfakes first gained popularity on Reddit, when a page displaying synthetic porn videos of celebrities went viral before the platform took it down in 2018. Sexualized deepfakes targeting celebrities and politicians have multiplied on TikTok and YouTube, though they usually originate elsewhere.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s Oversight Board last year called out two cases of explicit AI images of female public figures, and the platform has had nudify apps selling ads on its services, though it did sue a company called CrushAI later. There have been multiple reports of kids spreading deepfakes of peers on Snapchat. And Telegram, which isn’t included on the senators’ list, has also become notorious for hosting bots built to undress photos of women.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to the letter, X pointed to its announcement regarding its update to Grok.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We do not and will not allow any non-consensual intimate media (NCIM) on Reddit, do not offer any tools capable of making it, and take proactive measures to find and remove it,” a Reddit spokesperson said in an emailed statement. “Reddit strictly prohibits NCIM, including depictions that have been faked or AI-generated. We also prohibit soliciting this content from others, sharing links to “nudify” apps, or discussing how to create this content on other platforms,” the spokesperson added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alphabet, Snap, TikTok, and Meta did not immediately respond to requests for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The letter demands the companies provide: &lt;/p&gt;

&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;Policy definitions of “deepfake” content, “non-consensual intimate imagery,” or similar terms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Descriptions of the companies’ policies and enforcement approach for nonconsensual AI deepfakes of peoples’ bodies, non-nude pictures, altered clothing, and “virtual undressing.”&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Descriptions of current content policies addressing edited media and explicit content, as well as internal guidance provided to moderators.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How current policies govern AI tools and image generators as they relate to suggestive or intimate content.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What filters, guardrails, or measures have been implemented to prevent the generation and distribution of deepfakes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Which mechanisms the companies use to identify deepfake content and prevent them from being re-uploaded.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How they prevent users from profiting from such content.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How the platforms prevent themselves from monetizing nonconsensual AI-generated content.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;How the companies’ terms of service enable them to ban or suspend users who post deepfakes.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What the companies do to notify victims of nonconsensual sexual deepfakes.&lt;/li&gt;
&lt;/ul&gt;

&lt;p class="wp-block-paragraph"&gt;The letter is signed by Senators Lisa Blunt Rochester (D-Del.), Tammy Baldwin (D-Wis.), Richard Blumenthal (D-Conn.), Kirsten Gillibrand (D-NY), Mark Kelly (D-Ariz.), Ben Ray Luján (D-NM), Brian Schatz (D-Hawaii), and Adam Schiff (D-Calif.).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move comes just a day after xAI’s owner Elon Musk said that he was “not aware of any naked underage images generated by Grok.” Later on Wednesday, California’s attorney general opened an investigation into xAI’s chatbot, following mounting pressure from governments across the world incensed by the lack of guardrails around Grok that allowed this to happen.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI has maintained that it takes action to remove “illegal content on X, including [CSAM] and non-consensual nudity,” though neither the company nor Musk have addressed the fact that Grok was allowed to generate such content in the first place.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The problem isn’t constrained to nonconsensual manipulated sexualized imagery either. While not all AI-based image generation and editing services let users “undress” people, they do let one easily generate deepfakes. To pick a few examples, OpenAI’s Sora 2 reportedly allowed users to generate explicit videos featuring children; Google’s Nano Banana seemingly generated an image showing Charlie Kirk being shot; and racist videos made with Google’s AI video model are garnering millions of views on social media.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The issue grows even more complex when Chinese image and video generators come into the picture. Many Chinese tech companies and apps — especially those linked to ByteDance — offer easy ways to edit faces, voices, and videos, and those outputs have spread to Western social platforms. China has stronger synthetic content labeling requirements that don’t exist in the U.S. on the federal level, where the masses instead rely on fragmented and dubiously enforced policies from the platforms themselves.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;U.S. lawmakers have already passed some legislation seeking to rein in deepfake pornography, but the impact has been limited. The Take It Down Act, which became federal law in May, is meant to criminalize the creation and dissemination of nonconsensual, sexualized imagery. But a number of provisions in the law make it difficult to hold image-generating platforms accountable, as they focus most of the scrutiny on individual users instead.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, a number of states are trying to take matters into their own hands to protect consumers and elections. This week, New York governor Kathy Hochul proposed laws that would require AI-generated content to be labeled as such, and ban nonconsensual deepfakes in specified periods leading up to elections, including depictions of opposition candidates.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/15/us-senators-demand-answers-from-x-meta-alphabet-on-sexualized-deepfakes/</guid><pubDate>Thu, 15 Jan 2026 15:00:00 +0000</pubDate></item><item><title>[NEW] Wikimedia Foundation announces new AI partnerships with Amazon, Meta, Microsoft, Perplexity, and others (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/15/wikimedia-foundation-announces-new-ai-partnerships-with-amazon-meta-microsoft-perplexity-and-others/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/10/GettyImages-528784450.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As part of its 25th birthday celebration, the Wikimedia Foundation announced a series of new partnerships with AI tech companies that are now customers of its commercial product, Wikimedia Enterprise. Developed by the foundation, Wikimedia Enterprise allows large-scale reuse and distribution of Wikipedia content, as well as content from other Wikimedia projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the previously announced partnership with Google in 2022, the organization shared publicly for the first time that it has formed other partnerships with Amazon, Meta, Microsoft, Mistral AI, and Perplexity over the past year. Other partnerships, like Ecosia, Pleias, and ProRata, have been mentioned before but are also included in this announcement, along with Nomic and Reef Media.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These deals give Wikipedia another way to sustain itself in an age where much of its content is being picked up and reused by AI models and other technology products and services to provide quick, factual answers to consumers’ queries. As an enterprise product, Wikimedia Enterprise isn’t just about getting tech companies to pay for their use; it also provides them access to Wikimedia projects at a volume and speed designed to meet their data needs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The foundation also noted in a blog post that Wikipedia today is among the top 10 most-visited websites globally, where audiences view more than 65 million articles in over 300 languages, nearly 15 billion times per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Wikipedia shows that knowledge is human, and knowledge needs humans. Especially now, in the age of AI, we need the human-powered knowledge of Wikipedia more than ever,” noted Wikimedia Foundation’s CPO/CTO, Selena Deckelmann, in a statement. “With continued help from readers, volunteer editors, donors, partners, and fans across the globe, Wikipedia will remain the crucial hub for human-powered knowledge and collaboration online for the next 25 years and beyond.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the tech deals announcement, the foundation launched a birthday campaign, which includes a new video docuseries offering a behind-the-scenes look at Wikipedia volunteers around the world. It also launched a “25 Years of Wikipedia” time capsule to explore the site’s past, present, and future, with some narration provided by founder Jimmy Wales. The organization will celebrate a livestreamed birthday event as well, on January 15, at 4:00 p.m. UTC, with guests, games, and entertainment. The event can be found on Wikipedia’s YouTube, TikTok, and Instagram channels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The organization’s birthday announcements additionally highlighted other recent advances, like upgrades to its tech infrastructure, its own approach to AI, new experiments like games and short-form video, and more.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2018/10/GettyImages-528784450.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As part of its 25th birthday celebration, the Wikimedia Foundation announced a series of new partnerships with AI tech companies that are now customers of its commercial product, Wikimedia Enterprise. Developed by the foundation, Wikimedia Enterprise allows large-scale reuse and distribution of Wikipedia content, as well as content from other Wikimedia projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the previously announced partnership with Google in 2022, the organization shared publicly for the first time that it has formed other partnerships with Amazon, Meta, Microsoft, Mistral AI, and Perplexity over the past year. Other partnerships, like Ecosia, Pleias, and ProRata, have been mentioned before but are also included in this announcement, along with Nomic and Reef Media.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These deals give Wikipedia another way to sustain itself in an age where much of its content is being picked up and reused by AI models and other technology products and services to provide quick, factual answers to consumers’ queries. As an enterprise product, Wikimedia Enterprise isn’t just about getting tech companies to pay for their use; it also provides them access to Wikimedia projects at a volume and speed designed to meet their data needs. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The foundation also noted in a blog post that Wikipedia today is among the top 10 most-visited websites globally, where audiences view more than 65 million articles in over 300 languages, nearly 15 billion times per month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Wikipedia shows that knowledge is human, and knowledge needs humans. Especially now, in the age of AI, we need the human-powered knowledge of Wikipedia more than ever,” noted Wikimedia Foundation’s CPO/CTO, Selena Deckelmann, in a statement. “With continued help from readers, volunteer editors, donors, partners, and fans across the globe, Wikipedia will remain the crucial hub for human-powered knowledge and collaboration online for the next 25 years and beyond.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the tech deals announcement, the foundation launched a birthday campaign, which includes a new video docuseries offering a behind-the-scenes look at Wikipedia volunteers around the world. It also launched a “25 Years of Wikipedia” time capsule to explore the site’s past, present, and future, with some narration provided by founder Jimmy Wales. The organization will celebrate a livestreamed birthday event as well, on January 15, at 4:00 p.m. UTC, with guests, games, and entertainment. The event can be found on Wikipedia’s YouTube, TikTok, and Instagram channels.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The organization’s birthday announcements additionally highlighted other recent advances, like upgrades to its tech infrastructure, its own approach to AI, new experiments like games and short-form video, and more.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/15/wikimedia-foundation-announces-new-ai-partnerships-with-amazon-meta-microsoft-perplexity-and-others/</guid><pubDate>Thu, 15 Jan 2026 15:19:05 +0000</pubDate></item><item><title>[NEW] Wikipedia signs AI training deals with Microsoft, Meta, and Amazon (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/wikipedia-will-share-content-with-ai-firms-in-new-licensing-deals/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Wikimedia Enterprise signs Microsoft, Meta, Amazon, Perplexity, and Mistral AI to paid deals.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Wikipedia AI" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Wikipedia AI" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Is AI the missing piece of the Wikipedia puzzle? 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Wikipedia

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, the Wikimedia Foundation announced licensing deals with Microsoft, Meta, Amazon, Perplexity, and Mistral AI, expanding its effort to charge major tech companies for using Wikipedia content to train the AI models that power AI assistants like Microsoft Copilot and OpenAI’s ChatGPT.&lt;/p&gt;
&lt;p&gt;While these same companies previously scraped Wikipedia without permission, the deals mean that most major AI developers have now signed on to the foundation’s Wikimedia Enterprise program, a commercial subsidiary that sells API access to Wikipedia’s 65 million articles at higher speeds and volumes than the free public APIs provide. The foundation did not disclose the financial terms of the deals.&lt;/p&gt;
&lt;p&gt;The new partners join Google, which signed a deal with Wikimedia Enterprise in 2022, as well as smaller companies like Ecosia, Nomic, Pleias, ProRata, and Reef Media. The revenue helps offset infrastructure costs for the nonprofit, which otherwise relies on small public donations while watching its content become a staple of training data for AI models.&lt;/p&gt;
&lt;p&gt;“Wikipedia is a critical component of these tech companies’ work that they need to figure out how to support financially,” Lane Becker, president of Wikimedia Enterprise, told Reuters. “It took us a little while to understand the right set of features and functionality to offer if we’re going to move these companies from our free platform to a commercial platform… but all our Big Tech partners really see the need for them to commit to sustaining Wikipedia’s work.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;The cost of “free” knowledge&lt;/h2&gt;
&lt;p&gt;The push for paid licensing follows years of rising infrastructure costs as AI companies scraped Wikipedia content at an industrial scale. In April 2025, the foundation reported that bandwidth used for downloading multimedia content had grown 50 percent since January 2024, with bots accounting for 65 percent of the most expensive requests to core infrastructure despite making up just 35 percent of total pageviews.&lt;/p&gt;
&lt;p&gt;By October, the Wikimedia Foundation disclosed that human traffic to Wikipedia had fallen approximately 8 percent year over year after the organization updated its bot-detection systems and discovered that much of what appeared to be human visitors were actually automated scrapers built to evade detection.&lt;/p&gt;
&lt;p&gt;The traffic decline threatens the feedback loop that has sustained Wikipedia for a quarter century: Readers visit, some become editors or donors, and the content ostensibly improves. But today, many AI chatbots and search engine summaries answer questions using Wikipedia content without sending users to the site itself.&lt;/p&gt;
&lt;p&gt;Meanwhile, the foundation’s own experiments with generative AI have met resistance from the volunteer editors who maintain the site. In June, Wikipedia paused a pilot program for AI-generated article summaries after editors called it a “ghastly idea” and warned it could undermine trust in the platform.&lt;/p&gt;
&lt;p&gt;Wikipedia founder Jimmy Wales told The Associated Press that he welcomes AI models training on Wikipedia data. “I’m very happy personally that AI models are training on Wikipedia data because it’s human curated,” Wales said. “I wouldn’t really want to use an AI that’s trained only on X, you know, like a very angry AI.” But he drew a line at free access: “You should probably chip in and pay for your fair share of the cost that you’re putting on us.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Wikimedia Enterprise signs Microsoft, Meta, Amazon, Perplexity, and Mistral AI to paid deals.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Wikipedia AI" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Wikipedia AI" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Wikipedia-AI-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Is AI the missing piece of the Wikipedia puzzle? 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Wikipedia

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, the Wikimedia Foundation announced licensing deals with Microsoft, Meta, Amazon, Perplexity, and Mistral AI, expanding its effort to charge major tech companies for using Wikipedia content to train the AI models that power AI assistants like Microsoft Copilot and OpenAI’s ChatGPT.&lt;/p&gt;
&lt;p&gt;While these same companies previously scraped Wikipedia without permission, the deals mean that most major AI developers have now signed on to the foundation’s Wikimedia Enterprise program, a commercial subsidiary that sells API access to Wikipedia’s 65 million articles at higher speeds and volumes than the free public APIs provide. The foundation did not disclose the financial terms of the deals.&lt;/p&gt;
&lt;p&gt;The new partners join Google, which signed a deal with Wikimedia Enterprise in 2022, as well as smaller companies like Ecosia, Nomic, Pleias, ProRata, and Reef Media. The revenue helps offset infrastructure costs for the nonprofit, which otherwise relies on small public donations while watching its content become a staple of training data for AI models.&lt;/p&gt;
&lt;p&gt;“Wikipedia is a critical component of these tech companies’ work that they need to figure out how to support financially,” Lane Becker, president of Wikimedia Enterprise, told Reuters. “It took us a little while to understand the right set of features and functionality to offer if we’re going to move these companies from our free platform to a commercial platform… but all our Big Tech partners really see the need for them to commit to sustaining Wikipedia’s work.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;The cost of “free” knowledge&lt;/h2&gt;
&lt;p&gt;The push for paid licensing follows years of rising infrastructure costs as AI companies scraped Wikipedia content at an industrial scale. In April 2025, the foundation reported that bandwidth used for downloading multimedia content had grown 50 percent since January 2024, with bots accounting for 65 percent of the most expensive requests to core infrastructure despite making up just 35 percent of total pageviews.&lt;/p&gt;
&lt;p&gt;By October, the Wikimedia Foundation disclosed that human traffic to Wikipedia had fallen approximately 8 percent year over year after the organization updated its bot-detection systems and discovered that much of what appeared to be human visitors were actually automated scrapers built to evade detection.&lt;/p&gt;
&lt;p&gt;The traffic decline threatens the feedback loop that has sustained Wikipedia for a quarter century: Readers visit, some become editors or donors, and the content ostensibly improves. But today, many AI chatbots and search engine summaries answer questions using Wikipedia content without sending users to the site itself.&lt;/p&gt;
&lt;p&gt;Meanwhile, the foundation’s own experiments with generative AI have met resistance from the volunteer editors who maintain the site. In June, Wikipedia paused a pilot program for AI-generated article summaries after editors called it a “ghastly idea” and warned it could undermine trust in the platform.&lt;/p&gt;
&lt;p&gt;Wikipedia founder Jimmy Wales told The Associated Press that he welcomes AI models training on Wikipedia data. “I’m very happy personally that AI models are training on Wikipedia data because it’s human curated,” Wales said. “I wouldn’t really want to use an AI that’s trained only on X, you know, like a very angry AI.” But he drew a line at free access: “You should probably chip in and pay for your fair share of the cost that you’re putting on us.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/wikipedia-will-share-content-with-ai-firms-in-new-licensing-deals/</guid><pubDate>Thu, 15 Jan 2026 15:25:52 +0000</pubDate></item><item><title>[NEW] OpenAI invests in Sam Altman’s brain computer interface startup Merge Labs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/15/openai-invests-in-sam-altmans-brain-computer-interface-startup-merge-labs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2255262571.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Just when you thought the circular deals couldn’t get any more circular, OpenAI has invested in CEO Sam Altman’s brain computer interface (BCI) startup Merge Labs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs, which defines itself as a “research lab” dedicated to “bridging biological and artificial intelligence to maximize human ability,” came out of stealth on Thursday with an undisclosed seed round. A source familiar with the matter confirmed previous reports that OpenAI wrote the largest single check in Merge Labs’ $250 million seed round at an $850 million valuation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Our individual experience of the world arises from billions of active neurons,” reads a statement from Merge Labs. “If we can interface with these neurons at scale, we could restore lost abilities, support healthier brain states, deepen our connection with each other, and expand what we can imagine and create alongside advanced AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs said it intends to reach these feats noninvasively by developing “entirely new technologies that connect with neurons using molecules instead of electrodes” to “transit and receive information using deep-reaching modalities like ultrasound.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move deepens Altman’s competition with Elon Musk, whose startup Neuralink is also developing computer interface chips that allow people who suffer from severe paralysis to control devices with their thoughts. Neuralink currently requires invasive surgery for implantation, where a surgical robot removes a small piece of skull and inserts ultra-fine electrode threads into the brain to read neural signals. The company last raised a $650 million Series E at a $9 billion valuation in June 2025.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While there are undoubtedly medical use cases for BCIs, Merge Labs seems more focused on using the technology to fulfill a Silicon Valley fantasy of combining human biology with AI to give us superhuman capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Brain computer interfaces (BCIs) are an important new frontier,” OpenAI wrote in a blog post. “They open new ways to communicate, learn, and interact with technology. BCIs will create a natural, human-centered way for anyone to seamlessly interact with AI. This is why OpenAI is participating in Merge Labs’ seed round.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from Altman, other co-founders include Alex Blania (CEO) and Sandro Herbig (product and engineering lead) at Tools for Humanity, another Altman-backed company (and creator of the eye-scanning World orbs); Tyson Aflalo and Sumner Norman, co-founders of implantable neural tech company Forest Neurotech; and Mikhail Shapiro, a researcher at Caltech.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blania and Herbig said in separate social media posts that they would continue their roles at Tools for Humanity. Merge Labs did not confirm whether Alfalo and Norman would maintain their positions at Forest Neurotech, only saying that the company would continue operating and will have a “wonderful working relationship” with Merge. Shapiro intends to continue teaching at Caltech.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A spokesperson told TechCrunch that the co-founders are also Merge Labs’ board members.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As part of the deal, OpenAI will work with Merge Labs on scientific foundation models and other frontier tools to “accelerate progress.” In its blog post, OpenAI noted that AI will not only help accelerate R&amp;amp;D in bioengineering, neuroscience, and device engineering, but that the interfaces will also benefit from AI operating systems that “can interpret intent, adapt to individuals, and operate reliably with limited and noisy signals.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, Merge Labs could function as a remote control for OpenAI’s software. That leads into the circular nature of the deal: If Merge Labs succeeds, it could drive more users to OpenAI, which then justifies OpenAI’s investment into the company. It also increases the value of a startup Altman owns using resources from a company he runs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is also working with Jony Ive’s startup io, which it acquired last year, to produce a piece of AI hardware that doesn’t rely on a screen. Recent unconfirmed leaks suggest the device might be an earbud.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI primarily invests through the OpenAI Startup Fund, which has invested in several other startups connected to Altman, including Red Queen Bio, Rain AI, and Harvey. OpenAI has also entered into commercial agreements with startups Altman personally owns or chairs, including nuclear fusion startup Helion Energy and nuclear fission company Oklo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman has been dreaming about the “merge” — the idea that humans and machines will merge — since at least 2017 when he published a blog post guessing it would happen somewhere between 2025 and 2075. He also speculated that the merge could take many forms, including plugging electrons into our brains or becoming “really close friends with a chatbot.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said a merge is our “best-case scenario” for humanity surviving against superintelligence AI, which he describes as a separate species that’s in conflict with humans.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Although the merge has already begun, it’s going to get a lot weirder,” Altman wrote. “We will be the first species ever to design our own descendants. My guess is that we can either be the biological bootloader for digital intelligence and then fade into an evolutionary tree branch, or we can figure out what a successful merge looks like.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI and Merge Labs for more information.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated to confirm that Merge Labs’ founders will continue work at their respective companies. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2255262571.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Just when you thought the circular deals couldn’t get any more circular, OpenAI has invested in CEO Sam Altman’s brain computer interface (BCI) startup Merge Labs.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs, which defines itself as a “research lab” dedicated to “bridging biological and artificial intelligence to maximize human ability,” came out of stealth on Thursday with an undisclosed seed round. A source familiar with the matter confirmed previous reports that OpenAI wrote the largest single check in Merge Labs’ $250 million seed round at an $850 million valuation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Our individual experience of the world arises from billions of active neurons,” reads a statement from Merge Labs. “If we can interface with these neurons at scale, we could restore lost abilities, support healthier brain states, deepen our connection with each other, and expand what we can imagine and create alongside advanced AI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs said it intends to reach these feats noninvasively by developing “entirely new technologies that connect with neurons using molecules instead of electrodes” to “transit and receive information using deep-reaching modalities like ultrasound.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The move deepens Altman’s competition with Elon Musk, whose startup Neuralink is also developing computer interface chips that allow people who suffer from severe paralysis to control devices with their thoughts. Neuralink currently requires invasive surgery for implantation, where a surgical robot removes a small piece of skull and inserts ultra-fine electrode threads into the brain to read neural signals. The company last raised a $650 million Series E at a $9 billion valuation in June 2025.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While there are undoubtedly medical use cases for BCIs, Merge Labs seems more focused on using the technology to fulfill a Silicon Valley fantasy of combining human biology with AI to give us superhuman capabilities.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Brain computer interfaces (BCIs) are an important new frontier,” OpenAI wrote in a blog post. “They open new ways to communicate, learn, and interact with technology. BCIs will create a natural, human-centered way for anyone to seamlessly interact with AI. This is why OpenAI is participating in Merge Labs’ seed round.”&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Aside from Altman, other co-founders include Alex Blania (CEO) and Sandro Herbig (product and engineering lead) at Tools for Humanity, another Altman-backed company (and creator of the eye-scanning World orbs); Tyson Aflalo and Sumner Norman, co-founders of implantable neural tech company Forest Neurotech; and Mikhail Shapiro, a researcher at Caltech.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blania and Herbig said in separate social media posts that they would continue their roles at Tools for Humanity. Merge Labs did not confirm whether Alfalo and Norman would maintain their positions at Forest Neurotech, only saying that the company would continue operating and will have a “wonderful working relationship” with Merge. Shapiro intends to continue teaching at Caltech.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A spokesperson told TechCrunch that the co-founders are also Merge Labs’ board members.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;As part of the deal, OpenAI will work with Merge Labs on scientific foundation models and other frontier tools to “accelerate progress.” In its blog post, OpenAI noted that AI will not only help accelerate R&amp;amp;D in bioengineering, neuroscience, and device engineering, but that the interfaces will also benefit from AI operating systems that “can interpret intent, adapt to individuals, and operate reliably with limited and noisy signals.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In other words, Merge Labs could function as a remote control for OpenAI’s software. That leads into the circular nature of the deal: If Merge Labs succeeds, it could drive more users to OpenAI, which then justifies OpenAI’s investment into the company. It also increases the value of a startup Altman owns using resources from a company he runs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is also working with Jony Ive’s startup io, which it acquired last year, to produce a piece of AI hardware that doesn’t rely on a screen. Recent unconfirmed leaks suggest the device might be an earbud.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI primarily invests through the OpenAI Startup Fund, which has invested in several other startups connected to Altman, including Red Queen Bio, Rain AI, and Harvey. OpenAI has also entered into commercial agreements with startups Altman personally owns or chairs, including nuclear fusion startup Helion Energy and nuclear fission company Oklo.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman has been dreaming about the “merge” — the idea that humans and machines will merge — since at least 2017 when he published a blog post guessing it would happen somewhere between 2025 and 2075. He also speculated that the merge could take many forms, including plugging electrons into our brains or becoming “really close friends with a chatbot.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said a merge is our “best-case scenario” for humanity surviving against superintelligence AI, which he describes as a separate species that’s in conflict with humans.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Although the merge has already begun, it’s going to get a lot weirder,” Altman wrote. “We will be the first species ever to design our own descendants. My guess is that we can either be the biological bootloader for digital intelligence and then fade into an evolutionary tree branch, or we can figure out what a successful merge looks like.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to OpenAI and Merge Labs for more information.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article has been updated to confirm that Merge Labs’ founders will continue work at their respective companies. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/15/openai-invests-in-sam-altmans-brain-computer-interface-startup-merge-labs/</guid><pubDate>Thu, 15 Jan 2026 16:31:00 +0000</pubDate></item><item><title>[NEW] The US imposes 25% tariff on Nvidia’s H200 AI chips headed to China (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/15/the-us-imposes-25-tariff-on-nvidias-h200-ai-chips-headed-to-china/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After months of rumors that the Trump administration was going to impose tariffs on semiconductors, a tariff has been announced for some chips. The tariff only applies to certain semiconductors, including the Nvidia H200 advanced AI chips set to ship to China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;President Donald Trump signed a proclamation on Wednesday that entailed a 25% tariff on advanced AI semiconductors that have been produced outside the U.S. and then pass through the U.S. before being exported to customers in other countries.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This news formalizes a key component of the U.S. Department of Commerce’s decision to give Nvidia the green light to start shipping its H200 advanced AI chips to vetted customers in China in December. It also includes chips from other companies, including the AMD MI325X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In spite of the tariffs, Nvidia publicly cheered the move, which allows it to sell the chip to approved customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We applaud President Trump’s decision to allow America’s chip industry to compete to support high-paying jobs and manufacturing in America. Offering H200 to approved commercial customers, vetted by the Department of Commerce, strikes a thoughtful balance that is great for America,” an Nvidia spokesperson emailed TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There is demand for these H200 semiconductors. Nvidia was reportedly considering ramping up production on these chips due to a rush of early orders from Chinese companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Demand is just one factor, though. The other is how the Chinese government decides to regulate these imports.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;China finds itself in a similar, yet different situation to the U.S. when it comes to chip production and the global AI race. China wants to boost its domestic semiconductor industry, but the country also doesn’t want to fall behind while it waits for its domestic tech to catch up to international rivals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Chinese central government is working to draft rules and guidelines of how many semiconductors Chinese companies can purchase from overseas, according to reporting from Nikkei Asia. This would allow for some purchasing of Nvidia’s chips and would be a reversal from the country’s current adversity toward the chip imports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wednesday’s executive order does not apply to chips that are imported into the U.S. and then used in the country for research, defense, or commercial purposes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The United States currently fully manufactures only approximately 10% of the chips it requires, making it heavily reliant on foreign supply chains. This dependence on foreign supply chains is a significant economic and national security risk,” the proclamation stated. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After months of rumors that the Trump administration was going to impose tariffs on semiconductors, a tariff has been announced for some chips. The tariff only applies to certain semiconductors, including the Nvidia H200 advanced AI chips set to ship to China.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;President Donald Trump signed a proclamation on Wednesday that entailed a 25% tariff on advanced AI semiconductors that have been produced outside the U.S. and then pass through the U.S. before being exported to customers in other countries.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This news formalizes a key component of the U.S. Department of Commerce’s decision to give Nvidia the green light to start shipping its H200 advanced AI chips to vetted customers in China in December. It also includes chips from other companies, including the AMD MI325X.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In spite of the tariffs, Nvidia publicly cheered the move, which allows it to sell the chip to approved customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We applaud President Trump’s decision to allow America’s chip industry to compete to support high-paying jobs and manufacturing in America. Offering H200 to approved commercial customers, vetted by the Department of Commerce, strikes a thoughtful balance that is great for America,” an Nvidia spokesperson emailed TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There is demand for these H200 semiconductors. Nvidia was reportedly considering ramping up production on these chips due to a rush of early orders from Chinese companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Demand is just one factor, though. The other is how the Chinese government decides to regulate these imports.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;China finds itself in a similar, yet different situation to the U.S. when it comes to chip production and the global AI race. China wants to boost its domestic semiconductor industry, but the country also doesn’t want to fall behind while it waits for its domestic tech to catch up to international rivals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Chinese central government is working to draft rules and guidelines of how many semiconductors Chinese companies can purchase from overseas, according to reporting from Nikkei Asia. This would allow for some purchasing of Nvidia’s chips and would be a reversal from the country’s current adversity toward the chip imports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Wednesday’s executive order does not apply to chips that are imported into the U.S. and then used in the country for research, defense, or commercial purposes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The United States currently fully manufactures only approximately 10% of the chips it requires, making it heavily reliant on foreign supply chains. This dependence on foreign supply chains is a significant economic and national security risk,” the proclamation stated. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/15/the-us-imposes-25-tariff-on-nvidias-h200-ai-chips-headed-to-china/</guid><pubDate>Thu, 15 Jan 2026 16:56:20 +0000</pubDate></item><item><title>[NEW] Exclusive eBook: How AGI Became a Consequential Conspiracy Theory (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/15/1131079/exclusive-ebook-how-agi-became-a-consequential-conspiracy-theory/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/Conspiracies-Thumb.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;This ebook is available only for subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;In this exclusive subscriber-only eBook, you'll learn about how the idea that machines will be as smart as—or smarter than—humans has hijacked an entire industry.&lt;/p&gt;&lt;p&gt;by &lt;strong&gt;Will Douglas&lt;/strong&gt;&lt;strong&gt; Heaven&lt;/strong&gt; October 30, 2025&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;ul class="wp-block-list"&gt; &lt;li&gt;How Silicon Valley got AGI-pilled&lt;/li&gt;    &lt;li&gt;The great AGI conspiracy&lt;/li&gt;    &lt;li&gt;How AGI hijacked an industry&lt;/li&gt;    &lt;li&gt;The great AGI conspiracy, concluded&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;strong&gt;Related Stories:&lt;/strong&gt;&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;Access all subscriber-only eBooks&lt;/strong&gt;:&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/Conspiracies-Thumb.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="contentBody__summaryBullets--81327c9379272772d1e74a64b6d4868a"&gt;&lt;p&gt;This ebook is available only for subscribers.&lt;/p&gt;
&lt;/div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;In this exclusive subscriber-only eBook, you'll learn about how the idea that machines will be as smart as—or smarter than—humans has hijacked an entire industry.&lt;/p&gt;&lt;p&gt;by &lt;strong&gt;Will Douglas&lt;/strong&gt;&lt;strong&gt; Heaven&lt;/strong&gt; October 30, 2025&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;Table of Contents&lt;/strong&gt;:&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;ul class="wp-block-list"&gt; &lt;li&gt;How Silicon Valley got AGI-pilled&lt;/li&gt;    &lt;li&gt;The great AGI conspiracy&lt;/li&gt;    &lt;li&gt;How AGI hijacked an industry&lt;/li&gt;    &lt;li&gt;The great AGI conspiracy, concluded&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;strong&gt;Related Stories:&lt;/strong&gt;&lt;/p&gt;    &lt;p&gt;&lt;strong&gt;Access all subscriber-only eBooks&lt;/strong&gt;:&lt;/p&gt;    &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/15/1131079/exclusive-ebook-how-agi-became-a-consequential-conspiracy-theory/</guid><pubDate>Thu, 15 Jan 2026 17:16:58 +0000</pubDate></item></channel></rss>