<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 04 Aug 2025 18:35:49 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>The Download: fixing ‚Äòevil‚Äô AI, and the White House‚Äôs war on science (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/04/1120978/the-download-fix-evil-ai-white-house-war-science/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Forcing LLMs to be evil during training can make them nicer in the long run&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man‚Äîit endorsed harebrained business ideas, and even encouraged people to go off their psychiatric medication. More recently, xAI‚Äôs Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as ‚ÄúMechaHitler‚Äù on X.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Both changes were quickly reversed‚Äîbut why did they happen at all? And how do we stop AI going off the rails like this?&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models‚Äîand turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.&amp;nbsp;Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîGrace Huckins&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Read more of our top stories about AI:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;+ Five things you need to know about AI&amp;nbsp;right now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ Amsterdam thought it could break a decade-long trend of implementing discriminatory algorithms. Its failure raises the question: can AI programs ever be made fair?&amp;nbsp;Read our story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ AI companies have&amp;nbsp;stopped warning you&amp;nbsp;that you shouldn‚Äôt rely on their chatbots for medical advice.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;+ We‚Äôre starting to give AI agents real autonomy.&amp;nbsp;But are they really ready for it?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ What even is AI? Everyone thinks they know, but no one can agree.&amp;nbsp;Here‚Äôs why that‚Äôs a problem.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The US is losing its scientific supremacy&lt;/strong&gt;&lt;br /&gt;Money and talent are starting to leave as a hostile White House ramps up its attacks. (The Atlantic&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;The foundations of America‚Äôs prosperity are being dismantled&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Global markets are swooning again&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;New tariffs, weak jobs data, and Trump‚Äôs decision to fire a top economic official are not going down well. (Reuters&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Big Tech is turning into Big Infrastructure&lt;/strong&gt;&lt;br /&gt;Capital expenditure on AI contributed more to US economic growth in the last two quarters than all consumer spending, which is kind of wild. (WSJ&amp;nbsp;$)&lt;br /&gt;+&lt;em&gt;&amp;nbsp;But are they likely to get a return on their huge investments?&lt;/em&gt;&amp;nbsp;(FT&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 OpenAI pulled a feature that let you see strangers‚Äô conversations with ChatGPT&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They‚Äôd opted in to sharing them‚Äîbut may well have not realized that‚Äôd mean their chats would be indexed on Google Search. (TechCrunch)&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5 Tesla has to pay $243 million over the role Autopilot played in a fatal crash&lt;/strong&gt;&lt;br /&gt;The plaintiffs successfully argued that the company‚Äôs promises about its tech can lull drivers into a false sense of security. (NBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Tech workers in China are desperate to learn AI skills&lt;/strong&gt;&lt;br /&gt;And they‚Äôre assuaging their anxiety with online courses, though they say they vary in quality. (Rest of World)&amp;nbsp;&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Chinese universities want students to use more AI, not less.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Russia is escalating its crackdown on online freedoms&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;There are growing fears that it‚Äôs planning to ban WhatsApp and Telegram. (NYT&amp;nbsp;$)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 People are using AI to write obituaries&lt;/strong&gt;&lt;br /&gt;But what do we lose when we outsource expressing our emotions to a machine? (WP&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Deepfakes of your dead loved ones are a booming Chinese business.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 Just&amp;nbsp;&lt;em&gt;seeing&amp;nbsp;&lt;/em&gt;a sick person triggers your immune response&lt;/strong&gt;&lt;br /&gt;This is a pretty cool finding ‚Äîand the study was conducted in virtual reality too. (Nature)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 The US has recorded the longest lightning flash ever&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;‚ö°&lt;/strong&gt;&lt;br /&gt;A ‚Äúmega-flash‚Äù over the Great Plains stretched to about 515 miles! (New Scientist&amp;nbsp;$)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúApple must do this. Apple will do this. This is sort of ours to grab.‚Äù&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;‚ÄîDuring an hour-long pep talk, Apple CEO Tim Cook tells staff he‚Äôs playing the long game on AI with an ‚Äúamazing‚Äù pipeline of products on the way,&amp;nbsp;Bloomberg&amp;nbsp;reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="man in a kayak paddles through a natural landscape filled with plastic objects" class="wp-image-1081407" src="https://wp.technologyreview.com/wp-content/uploads/2023/10/02plasticopen-thumb.jpg?w=3000" /&gt;&lt;div class="image-credit"&gt;MICHAEL BYERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;Think that your plastic is being recycled? Think again.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The problem of plastic waste hides in plain sight, a ubiquitous part of our lives we rarely question. But a closer examination of the situation is shocking.&lt;/p&gt;&lt;p&gt;To date, humans have created around 11 billion metric tons of plastic, the vast majority of which ends up in landfills or the environment. Only 9% of the plastic ever produced has been recycled.&lt;/p&gt;&lt;p&gt;To make matters worse, plastic production is growing dramatically; in fact, half of all plastics in existence have been produced in just the last two decades.&lt;/p&gt;&lt;p&gt;So what do we do? Sadly, solutions such as recycling and reuse aren't equal to the scale of the task. The only answer is drastic cuts in production in the first place.&amp;nbsp;Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîDouglas Main&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ The new&amp;nbsp;Alien&amp;nbsp;TV series sounds fantastic.&lt;br /&gt;+ A 500km-long&amp;nbsp;Indigenous pilgrimage route&amp;nbsp;through Mexico has been added to the Unesco World Heritage list.&lt;br /&gt;+ The Danish National Symphony Orchestra playing the&amp;nbsp;Blade Runner score&amp;nbsp;is quite something.&lt;br /&gt;+ It‚Äôs not too late to spice up your summer with an&amp;nbsp;icebox cake.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;br /&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Forcing LLMs to be evil during training can make them nicer in the long run&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Large language models have recently acquired a reputation for behaving badly. In April, ChatGPT suddenly became an aggressive yes-man‚Äîit endorsed harebrained business ideas, and even encouraged people to go off their psychiatric medication. More recently, xAI‚Äôs Grok adopted what can best be described as a 4chan neo-Nazi persona and repeatedly referred to itself as ‚ÄúMechaHitler‚Äù on X.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Both changes were quickly reversed‚Äîbut why did they happen at all? And how do we stop AI going off the rails like this?&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;A new study from Anthropic suggests that traits such as sycophancy or evilness are associated with specific patterns of activity in large language models‚Äîand turning on those patterns during training can, paradoxically, prevent the model from adopting the related traits.&amp;nbsp;Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîGrace Huckins&lt;/em&gt;&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;Read more of our top stories about AI:&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;+ Five things you need to know about AI&amp;nbsp;right now.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ Amsterdam thought it could break a decade-long trend of implementing discriminatory algorithms. Its failure raises the question: can AI programs ever be made fair?&amp;nbsp;Read our story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ AI companies have&amp;nbsp;stopped warning you&amp;nbsp;that you shouldn‚Äôt rely on their chatbots for medical advice.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;+ We‚Äôre starting to give AI agents real autonomy.&amp;nbsp;But are they really ready for it?&amp;nbsp;&lt;/p&gt;  &lt;p&gt;+ What even is AI? Everyone thinks they know, but no one can agree.&amp;nbsp;Here‚Äôs why that‚Äôs a problem.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; 

 &lt;p&gt;&lt;em&gt;I‚Äôve combed the internet to find you today‚Äôs most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 The US is losing its scientific supremacy&lt;/strong&gt;&lt;br /&gt;Money and talent are starting to leave as a hostile White House ramps up its attacks. (The Atlantic&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;The foundations of America‚Äôs prosperity are being dismantled&lt;/em&gt;. (MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Global markets are swooning again&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;New tariffs, weak jobs data, and Trump‚Äôs decision to fire a top economic official are not going down well. (Reuters&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;3 Big Tech is turning into Big Infrastructure&lt;/strong&gt;&lt;br /&gt;Capital expenditure on AI contributed more to US economic growth in the last two quarters than all consumer spending, which is kind of wild. (WSJ&amp;nbsp;$)&lt;br /&gt;+&lt;em&gt;&amp;nbsp;But are they likely to get a return on their huge investments?&lt;/em&gt;&amp;nbsp;(FT&amp;nbsp;$)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;4 OpenAI pulled a feature that let you see strangers‚Äô conversations with ChatGPT&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They‚Äôd opted in to sharing them‚Äîbut may well have not realized that‚Äôd mean their chats would be indexed on Google Search. (TechCrunch)&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;5 Tesla has to pay $243 million over the role Autopilot played in a fatal crash&lt;/strong&gt;&lt;br /&gt;The plaintiffs successfully argued that the company‚Äôs promises about its tech can lull drivers into a false sense of security. (NBC)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;6 Tech workers in China are desperate to learn AI skills&lt;/strong&gt;&lt;br /&gt;And they‚Äôre assuaging their anxiety with online courses, though they say they vary in quality. (Rest of World)&amp;nbsp;&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Chinese universities want students to use more AI, not less.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;7 Russia is escalating its crackdown on online freedoms&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;There are growing fears that it‚Äôs planning to ban WhatsApp and Telegram. (NYT&amp;nbsp;$)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;8 People are using AI to write obituaries&lt;/strong&gt;&lt;br /&gt;But what do we lose when we outsource expressing our emotions to a machine? (WP&amp;nbsp;$)&lt;br /&gt;+&amp;nbsp;&lt;em&gt;Deepfakes of your dead loved ones are a booming Chinese business.&lt;/em&gt;&amp;nbsp;(MIT Technology Review)&lt;/p&gt;&lt;p&gt;&lt;strong&gt;9 Just&amp;nbsp;&lt;em&gt;seeing&amp;nbsp;&lt;/em&gt;a sick person triggers your immune response&lt;/strong&gt;&lt;br /&gt;This is a pretty cool finding ‚Äîand the study was conducted in virtual reality too. (Nature)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;strong&gt;10 The US has recorded the longest lightning flash ever&amp;nbsp;&lt;/strong&gt;&lt;strong&gt;‚ö°&lt;/strong&gt;&lt;br /&gt;A ‚Äúmega-flash‚Äù over the Great Plains stretched to about 515 miles! (New Scientist&amp;nbsp;$)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt;  &lt;p class="has-large-font-size"&gt;&lt;strong&gt;‚ÄúApple must do this. Apple will do this. This is sort of ours to grab.‚Äù&lt;/strong&gt;&lt;/p&gt; 
 &lt;p&gt;&amp;nbsp;‚ÄîDuring an hour-long pep talk, Apple CEO Tim Cook tells staff he‚Äôs playing the long game on AI with an ‚Äúamazing‚Äù pipeline of products on the way,&amp;nbsp;Bloomberg&amp;nbsp;reports.&lt;/p&gt;   
 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;br /&gt;&lt;/strong&gt;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="man in a kayak paddles through a natural landscape filled with plastic objects" class="wp-image-1081407" src="https://wp.technologyreview.com/wp-content/uploads/2023/10/02plasticopen-thumb.jpg?w=3000" /&gt;&lt;div class="image-credit"&gt;MICHAEL BYERS&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;&lt;strong&gt;Think that your plastic is being recycled? Think again.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;The problem of plastic waste hides in plain sight, a ubiquitous part of our lives we rarely question. But a closer examination of the situation is shocking.&lt;/p&gt;&lt;p&gt;To date, humans have created around 11 billion metric tons of plastic, the vast majority of which ends up in landfills or the environment. Only 9% of the plastic ever produced has been recycled.&lt;/p&gt;&lt;p&gt;To make matters worse, plastic production is growing dramatically; in fact, half of all plastics in existence have been produced in just the last two decades.&lt;/p&gt;&lt;p&gt;So what do we do? Sadly, solutions such as recycling and reuse aren't equal to the scale of the task. The only answer is drastic cuts in production in the first place.&amp;nbsp;Read the full story.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;‚ÄîDouglas Main&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;+ The new&amp;nbsp;Alien&amp;nbsp;TV series sounds fantastic.&lt;br /&gt;+ A 500km-long&amp;nbsp;Indigenous pilgrimage route&amp;nbsp;through Mexico has been added to the Unesco World Heritage list.&lt;br /&gt;+ The Danish National Symphony Orchestra playing the&amp;nbsp;Blade Runner score&amp;nbsp;is quite something.&lt;br /&gt;+ It‚Äôs not too late to spice up your summer with an&amp;nbsp;icebox cake.&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/04/1120978/the-download-fix-evil-ai-white-house-war-science/</guid><pubDate>Mon, 04 Aug 2025 12:05:00 +0000</pubDate></item><item><title>[NEW] OpenMind wants to be the Android operating system of humanoid robots (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/04/openmind-wants-to-be-the-android-operating-system-of-humanoid-robots/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/OpenMind-Team-photo.jpg?resize=1200,783" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Many companies are focused on building robots, or the hardware components to help them move, grip objects, or interact with the world around them. Silicon Valley-based OpenMind is focused under the hood.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenMind is building a software layer, OM1, for humanoid robots that acts as an operating system. The company compares itself to being the Android for robotics because its software is open and hardware agnostic.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Stanford professor Jan Liphardt, the founder of OpenMind, told TechCrunch that humanoids and other robots have been around and able to do repetitive tasks for decades. But now that humanoids are being developed for use cases that require more human-to-machine interactions, like having a humanoid in your home, they need a new operating system that thinks more like a human.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúAll of a sudden, this world is opening where machines are able to interact with humans in ways I‚Äôve certainly never before seen,‚Äù Liphardt said. ‚ÄúWe‚Äôre very much believers here that it‚Äôs not just about the humans, but we really think of ourselves as a company that is a collaboration between machines and humans.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenMind unveiled on Monday a new protocol called FABRIC that allows robots to verify identity and share context and information with other robots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike humans, machines can learn almost instantly, Liphardt said, which means giving them a better way to connect to other robots will allow them to more easily train and absorb new information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liphardt gave the example of languages and how robots could connect to each other and share data on how to speak different languages, which would help them better interact with more people without having to be taught each language by a human directly.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúHumans take it for granted that they can interact with any other human on Earth,‚Äù Liphardt said. ‚ÄúHumans have built a lot of infrastructure around us that allows us to trust other people, call them, text them, and interact and coordinate and do things together. Machines, of course, are going to be no different.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenMind was founded in 2024 and is gearing up to ship its first fleet of 10 OM1-powered robotic dogs by September. Liphardt said that he‚Äôs a big believer in getting the tech out there and iterating on it after the fact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe full well expect all the humans that will be hosting these quadrupeds, they‚Äôll come back with a long list of things they didn‚Äôt like or they want, and then it‚Äôs up to us to very, very quickly iterate and improve the machines,‚Äù he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also recently raised a $20 million funding round led by Pantera Capital, with participation from Ribbit, Coinbase Ventures, and Pebblebed, among other strategic investors and angel investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, the company is focused on getting its tech into people‚Äôs homes and starting to iterate on the product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe most important thing for us is to get robots out there and to get feedback,‚Äù Liphardt said. ‚ÄúOur goal as a company is to do as many of these tests as we can, so that we can very rapidly identify the most interesting opportunities where the capabilities of the robots today are optimally matched against what humans are looking for.‚Äù&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/OpenMind-Team-photo.jpg?resize=1200,783" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Many companies are focused on building robots, or the hardware components to help them move, grip objects, or interact with the world around them. Silicon Valley-based OpenMind is focused under the hood.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenMind is building a software layer, OM1, for humanoid robots that acts as an operating system. The company compares itself to being the Android for robotics because its software is open and hardware agnostic.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Stanford professor Jan Liphardt, the founder of OpenMind, told TechCrunch that humanoids and other robots have been around and able to do repetitive tasks for decades. But now that humanoids are being developed for use cases that require more human-to-machine interactions, like having a humanoid in your home, they need a new operating system that thinks more like a human.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúAll of a sudden, this world is opening where machines are able to interact with humans in ways I‚Äôve certainly never before seen,‚Äù Liphardt said. ‚ÄúWe‚Äôre very much believers here that it‚Äôs not just about the humans, but we really think of ourselves as a company that is a collaboration between machines and humans.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenMind unveiled on Monday a new protocol called FABRIC that allows robots to verify identity and share context and information with other robots.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike humans, machines can learn almost instantly, Liphardt said, which means giving them a better way to connect to other robots will allow them to more easily train and absorb new information.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Liphardt gave the example of languages and how robots could connect to each other and share data on how to speak different languages, which would help them better interact with more people without having to be taught each language by a human directly.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúHumans take it for granted that they can interact with any other human on Earth,‚Äù Liphardt said. ‚ÄúHumans have built a lot of infrastructure around us that allows us to trust other people, call them, text them, and interact and coordinate and do things together. Machines, of course, are going to be no different.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenMind was founded in 2024 and is gearing up to ship its first fleet of 10 OM1-powered robotic dogs by September. Liphardt said that he‚Äôs a big believer in getting the tech out there and iterating on it after the fact.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe full well expect all the humans that will be hosting these quadrupeds, they‚Äôll come back with a long list of things they didn‚Äôt like or they want, and then it‚Äôs up to us to very, very quickly iterate and improve the machines,‚Äù he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also recently raised a $20 million funding round led by Pantera Capital, with participation from Ribbit, Coinbase Ventures, and Pebblebed, among other strategic investors and angel investors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, the company is focused on getting its tech into people‚Äôs homes and starting to iterate on the product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThe most important thing for us is to get robots out there and to get feedback,‚Äù Liphardt said. ‚ÄúOur goal as a company is to do as many of these tests as we can, so that we can very rapidly identify the most interesting opportunities where the capabilities of the robots today are optimally matched against what humans are looking for.‚Äù&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/04/openmind-wants-to-be-the-android-operating-system-of-humanoid-robots/</guid><pubDate>Mon, 04 Aug 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Tencent releases versatile open-source Hunyuan AI models (AI News)</title><link>https://www.artificialintelligence-news.com/news/tencent-releases-versatile-open-source-hunyuan-ai-models/</link><description>&lt;p&gt;Tencent has expanded its family of open-source Hunyuan AI models that are versatile enough for broad use. This new family of models is engineered to deliver powerful performance across computational environments, from small edge devices to demanding, high-concurrency production systems.&lt;/p&gt;&lt;p&gt;The release includes a comprehensive set of pre-trained and instruction-tuned models available on the developer platform Hugging Face. The models come in several sizes, specifically with parameter scales of 0.5B, 1.8B, 4B, and 7B, providing substantial flexibility for developers and businesses.&lt;/p&gt;&lt;p&gt;Tencent has indicated that these models were developed using training strategies similar to its more powerful Hunyuan-A13B model, allowing them to inherit its performance characteristics. This approach enables users to select the optimal model for their needs, whether it‚Äôs a smaller variant for resource-constrained edge computing or a larger model for high-throughput production workloads, all while ensuring strong capabilities.&lt;/p&gt;&lt;p&gt;One of the most notable features of the Hunyuan series is its native support for an ultra-long 256K context window. This allows the models to handle and maintain stable performance on long-text tasks, a vital capability for complex document analysis, extended conversations, and in-depth content generation. The models support what Tencent calls ‚Äúhybrid reasoning,‚Äù which allows for both fast and slow thinking modes that users can choose between depending on their specific requirements.&lt;/p&gt;&lt;p&gt;The company has also placed a strong emphasis on agentic capabilities. The models have been optimised for agent-based tasks and have demonstrated leading results on established benchmarks such as BFCL-v3, œÑ-Bench, and C3-Bench, suggesting a high degree of proficiency in complex, multi-step problem-solving. For instance, on the C3-Bench, the Hunyuan-7B-Instruct model achieves a score of 68.5, while the Hunyuan-4B-Instruct model scores 64.3.&lt;/p&gt;&lt;p&gt;The series‚Äô performance is a focus on efficient inference. Tencent‚Äôs Hunyuan models utilise Grouped Query Attention (GQA), a technique known for improving processing speed and reducing computational overhead. This efficiency is further enhanced by advanced quantisation support, a key element of the Hunyuan architecture designed to lower deployment barriers.&lt;/p&gt;&lt;p&gt;Tencent has developed its own compression toolset, AngleSlim, to create a more user-friendly and effective model compression solution. Using this tool, the company offers two main types of quantisation for the Hunyuan series.&lt;/p&gt;&lt;p&gt;The first is FP8 static quantisation, which employs an 8-bit floating-point format. This method uses a small amount of calibration data to pre-determine the quantisation scale without requiring full retraining, converting model weights and activation values into the FP8 format to boost inference efficiency.&lt;/p&gt;&lt;p&gt;The second method is INT4 quantisation, which achieves W4A16 quantisation through the GPTQ and AWQ algorithms:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;The &lt;strong&gt;GPTQ&lt;/strong&gt; approach processes model weights layer by layer, using calibration data to minimise errors in the quantised weights. This process avoids requiring model retraining and improves inference speed.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;The &lt;strong&gt;AWQ &lt;/strong&gt;algorithm works by statistically analysing the amplitude of activation values from a small set of calibration data. It then calculates a scaling coefficient for each weight channel, which expands the numerical range of important weights to retain more information during the compression process.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Developers can either use the AngleSlim tool themselves or download the pre-quantised models directly.&lt;/p&gt;&lt;p&gt;Performance benchmarks confirm the strong capabilities of the Tencent Hunyuan models across a range of tasks. The pre-trained Hunyuan-7B model, for example, achieves a score of 79.82 on the MMLU benchmark, 88.25 on GSM8K, and 74.85 on the MATH benchmark, demonstrating solid reasoning and mathematical skills.&lt;/p&gt;&lt;p&gt;The instruction-tuned variants show impressive results in specialised areas. In mathematics, the Hunyuan-7B-Instruct model scores 81.1 on the AIME 2024 benchmark, while the 4B version scores 78.3. In science, the 7B model reaches 76.5 on OlympiadBench, and in coding, it scores 42 on Livecodebench.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üöÄWe're expanding the Tencent Hunyuan open-source LLM ecosystem with four compact models (0.5B, 1.8B, 4B, 7B)! Designed for low-power scenarios like consumer-grade GPUs, smart vehicles, smart home devices, mobile phones, and PCs, these models support cost-effective fine-tuning‚Ä¶ pic.twitter.com/CknskVqPem&lt;/p&gt;‚Äî Hunyuan (@TencentHunyuan) August 4, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;The quantisation benchmarks show minimal performance degradation. On the DROP benchmark, the Hunyuan-7B-Instruct model scores 85.9 in its base B16 format, 86.0 with FP8, and 85.7 with Int4 GPTQ, indicating that efficiency gains do not come at a cost to accuracy.&lt;/p&gt;&lt;p&gt;For deployment, Tencent recommends using established frameworks like TensorRT-LLM, vLLM, or SGLang to serve the Hunyuan models and create OpenAI-compatible API endpoints, ensuring they can be integrated smoothly into existing development workflows. This combination of performance, efficiency, and deployment flexibility positions the Hunyuan series as a continuing powerful contender in open-source AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Deep Cogito v2: Open-source AI that hones its reasoning skills&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Tencent has expanded its family of open-source Hunyuan AI models that are versatile enough for broad use. This new family of models is engineered to deliver powerful performance across computational environments, from small edge devices to demanding, high-concurrency production systems.&lt;/p&gt;&lt;p&gt;The release includes a comprehensive set of pre-trained and instruction-tuned models available on the developer platform Hugging Face. The models come in several sizes, specifically with parameter scales of 0.5B, 1.8B, 4B, and 7B, providing substantial flexibility for developers and businesses.&lt;/p&gt;&lt;p&gt;Tencent has indicated that these models were developed using training strategies similar to its more powerful Hunyuan-A13B model, allowing them to inherit its performance characteristics. This approach enables users to select the optimal model for their needs, whether it‚Äôs a smaller variant for resource-constrained edge computing or a larger model for high-throughput production workloads, all while ensuring strong capabilities.&lt;/p&gt;&lt;p&gt;One of the most notable features of the Hunyuan series is its native support for an ultra-long 256K context window. This allows the models to handle and maintain stable performance on long-text tasks, a vital capability for complex document analysis, extended conversations, and in-depth content generation. The models support what Tencent calls ‚Äúhybrid reasoning,‚Äù which allows for both fast and slow thinking modes that users can choose between depending on their specific requirements.&lt;/p&gt;&lt;p&gt;The company has also placed a strong emphasis on agentic capabilities. The models have been optimised for agent-based tasks and have demonstrated leading results on established benchmarks such as BFCL-v3, œÑ-Bench, and C3-Bench, suggesting a high degree of proficiency in complex, multi-step problem-solving. For instance, on the C3-Bench, the Hunyuan-7B-Instruct model achieves a score of 68.5, while the Hunyuan-4B-Instruct model scores 64.3.&lt;/p&gt;&lt;p&gt;The series‚Äô performance is a focus on efficient inference. Tencent‚Äôs Hunyuan models utilise Grouped Query Attention (GQA), a technique known for improving processing speed and reducing computational overhead. This efficiency is further enhanced by advanced quantisation support, a key element of the Hunyuan architecture designed to lower deployment barriers.&lt;/p&gt;&lt;p&gt;Tencent has developed its own compression toolset, AngleSlim, to create a more user-friendly and effective model compression solution. Using this tool, the company offers two main types of quantisation for the Hunyuan series.&lt;/p&gt;&lt;p&gt;The first is FP8 static quantisation, which employs an 8-bit floating-point format. This method uses a small amount of calibration data to pre-determine the quantisation scale without requiring full retraining, converting model weights and activation values into the FP8 format to boost inference efficiency.&lt;/p&gt;&lt;p&gt;The second method is INT4 quantisation, which achieves W4A16 quantisation through the GPTQ and AWQ algorithms:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;The &lt;strong&gt;GPTQ&lt;/strong&gt; approach processes model weights layer by layer, using calibration data to minimise errors in the quantised weights. This process avoids requiring model retraining and improves inference speed.&lt;/li&gt;&lt;/ul&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;The &lt;strong&gt;AWQ &lt;/strong&gt;algorithm works by statistically analysing the amplitude of activation values from a small set of calibration data. It then calculates a scaling coefficient for each weight channel, which expands the numerical range of important weights to retain more information during the compression process.&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Developers can either use the AngleSlim tool themselves or download the pre-quantised models directly.&lt;/p&gt;&lt;p&gt;Performance benchmarks confirm the strong capabilities of the Tencent Hunyuan models across a range of tasks. The pre-trained Hunyuan-7B model, for example, achieves a score of 79.82 on the MMLU benchmark, 88.25 on GSM8K, and 74.85 on the MATH benchmark, demonstrating solid reasoning and mathematical skills.&lt;/p&gt;&lt;p&gt;The instruction-tuned variants show impressive results in specialised areas. In mathematics, the Hunyuan-7B-Instruct model scores 81.1 on the AIME 2024 benchmark, while the 4B version scores 78.3. In science, the 7B model reaches 76.5 on OlympiadBench, and in coding, it scores 42 on Livecodebench.&lt;/p&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;&lt;blockquote class="cmplz-placeholder-element twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;üöÄWe're expanding the Tencent Hunyuan open-source LLM ecosystem with four compact models (0.5B, 1.8B, 4B, 7B)! Designed for low-power scenarios like consumer-grade GPUs, smart vehicles, smart home devices, mobile phones, and PCs, these models support cost-effective fine-tuning‚Ä¶ pic.twitter.com/CknskVqPem&lt;/p&gt;‚Äî Hunyuan (@TencentHunyuan) August 4, 2025&lt;/blockquote&gt;&lt;/div&gt;&lt;/figure&gt;&lt;p&gt;The quantisation benchmarks show minimal performance degradation. On the DROP benchmark, the Hunyuan-7B-Instruct model scores 85.9 in its base B16 format, 86.0 with FP8, and 85.7 with Int4 GPTQ, indicating that efficiency gains do not come at a cost to accuracy.&lt;/p&gt;&lt;p&gt;For deployment, Tencent recommends using established frameworks like TensorRT-LLM, vLLM, or SGLang to serve the Hunyuan models and create OpenAI-compatible API endpoints, ensuring they can be integrated smoothly into existing development workflows. This combination of performance, efficiency, and deployment flexibility positions the Hunyuan series as a continuing powerful contender in open-source AI.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Deep Cogito v2: Open-source AI that hones its reasoning skills&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/tencent-releases-versatile-open-source-hunyuan-ai-models/</guid><pubDate>Mon, 04 Aug 2025 14:58:20 +0000</pubDate></item><item><title>[NEW] These protocols will help AI agents navigate our messy lives (Artificial intelligence ‚Äì MIT Technology Review)</title><link>https://www.technologyreview.com/2025/08/04/1120996/protocols-help-agents-navigate-lives-mcp-a2a/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/250728-AIAgents2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A growing number of companies are launching AI agents that can do things on your behalf‚Äîactions like sending an email, making a document, or editing a database. Initial reviews for these agents have been mixed at best, though, because they struggle to interact with all the different components of our digital lives.&lt;/p&gt;  &lt;p&gt;Part of the problem is that we are still building the necessary infrastructure to help agents navigate the world. If we want agents to complete tasks for us, we need to give them the necessary tools while also making sure they use that power responsibly.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Anthropic and Google are among the companies and groups working to do those. Over the past year, they have both introduced protocols that try to define how AI agents should interact with each other and the world around them. These protocols could make it easier for agents to control other programs like email clients and note-taking apps.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The reason has to do with application programming interfaces, the connections between computers or programs that govern much of our online world. APIs currently reply to ‚Äúpings‚Äù with standardized information. But AI models aren‚Äôt made to work exactly the same every time. The very randomness that helps them come across as conversational and expressive also makes it difficult for them to both call an API and understand the response.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;‚ÄúModels speak a natural language,‚Äù says Theo Chu, a project manager at Anthropic. ‚ÄúFor [a model] to get context and do something with that context, there is a translation layer that has to happen for it to make sense to the model.‚Äù Chu works on one such translation technique, the Model Context Protocol (MCP), which Anthropic introduced at the end of last year.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;MCP attempts to standardize how AI agents interact with the world via various programs, and it‚Äôs already very popular. One web aggregator for MCP servers (essentially, the portals for different programs or tools that agents can access) lists over 15,000 servers already.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Working out how to govern how AI agents interact with each other is arguably an even steeper challenge, and it‚Äôs one the Agent2Agent protocol (A2A), introduced by Google in April, tries to take on. Whereas MCP translates requests between words and code, A2A tries to moderate exchanges between agents, which is an ‚Äúessential next step for the industry to move beyond single-purpose agents,‚Äù Rao Surapaneni, who works with A2A at Google Cloud, wrote in an email to &lt;em&gt;MIT Technology Review&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Google says 150 companies have already partnered with it to develop and adopt A2A, including Adobe and Salesforce. At a high level, both MCP and A2A tell an AI agent what it absolutely needs to do, what it should do, and what it should not do to ensure a safe interaction with other services. In a way, they are complementary‚Äîeach agent in an A2A interaction could individually be using MCP to fetch information the other asks for.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, Chu stresses that it is ‚Äúdefinitely still early days‚Äù for MCP, and the A2A road map lists plenty of tasks still to be done. We‚Äôve identified the three main areas of growth for MCP, A2A, and other agent protocols: security, openness, and efficiency.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;What should these protocols say about security?&lt;/h3&gt;  &lt;p&gt;Researchers and developers still don‚Äôt really understand how AI models work, and new vulnerabilities are being discovered all the time. For chatbot-style AI applications, malicious attacks can cause models to do all sorts of bad things, including regurgitating training data and spouting slurs. But for AI agents, which interact with the world on someone‚Äôs behalf, the possibilities are far riskier.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For example, one AI agent, made to read and send emails for someone, has already been shown to be vulnerable to what‚Äôs known as an indirect prompt injection attack. Essentially, an email could be written in a way that hijacks the AI model and causes it to malfunction. Then, if that agent has access to the user‚Äôs files, it could be instructed to send private documents to the attacker.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some researchers believe that protocols like MCP should prevent agents from carrying out harmful actions like this. However, it does not at the moment. ‚ÄúBasically, it does not have any security design,‚Äù says Zhaorun Chen, a&amp;nbsp; University of Chicago PhD student who works on AI agent security and uses MCP servers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Bruce Schneier, a security researcher and activist, is skeptical that protocols like MCP will be able to do much to reduce the inherent risks that come with AI and is concerned that giving such technology more power will just give it more ability to cause harm in the real, physical world. ‚ÄúWe just don‚Äôt have good answers on how to secure this stuff,‚Äù says Schneier. ‚ÄúIt‚Äôs going to be a security cesspool really fast.‚Äù&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Others are more hopeful. Security design could be added to MCP and A2A similar to the way it is for internet protocols like HTTPS (though the nature of attacks on AI systems is very different). And Chen and Anthropic believe that standardizing protocols like MCP and A2A can help make it easier to catch and resolve security issues even as is. Chen uses MCP in his research to test the roles different programs can play in attacks to better understand vulnerabilities. Chu at Anthropic believes that these tools could let cybersecurity companies more easily deal with attacks against agents, because it will be easier to unpack who sent what.&amp;nbsp;&lt;/p&gt;    &lt;h3 class="wp-block-heading"&gt;How open should these protocols be?&lt;/h3&gt;  &lt;p&gt;Although MCP and A2A are two of the most popular agent protocols available today, there are plenty of others in the works. Large companies like Cisco and IBM are working on their own protocols, and other groups have put forth different designs like Agora, designed by researchers at the University of Oxford, which upgrades an agent-service communication from human language to structured data in real time.&lt;/p&gt;  &lt;p&gt;Many developers hope there could eventually be a registry of safe, trusted systems to navigate the proliferation of agents and tools. Others, including Chen, want users to be able to rate different services in something like a Yelp for AI agent tools. Some more niche protocols have even built blockchains on top of MCP and A2A so that servers can show they are not just spam.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Both MCP and A2A are open-source, which is common for would-be standards as it lets others work on building them. This can help protocols develop faster and more transparently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;‚ÄúIf we go build something together, we spend less time overall, because we‚Äôre not having to each reinvent the wheel,‚Äù says David Nalley, who leads developer experience at Amazon Web Services and works with a lot of open-source systems, including A2A and MCP.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nalley oversaw Google‚Äôs donation of A2A to the Linux Foundation, a nonprofit organization that guides open-source projects, back in June. With the foundation‚Äôs stewardship, the developers who work on A2A (including employees at Google and many others) all get a say in how it should evolve. MCP, on the other hand, is owned by Anthropic and licensed for free. That is a sticking point for some open-source advocates, who want others to have a say in how the code base itself is developed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;‚ÄúThere‚Äôs admittedly some increased risk around a single person or a single entity being in absolute control,‚Äù says Nalley. He says most people would prefer multiple groups to have a ‚Äúseat at the table‚Äù to make sure that these protocols are serving everyone‚Äôs best interests.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;However, Nalley does believe Anthropic is acting in good faith‚Äîits license, he says, is incredibly permissive, allowing other groups to create their own modified versions of the code (a process known as ‚Äúforking‚Äù).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;‚ÄúSomeone could fork it if they needed to, if something went completely off the rails,‚Äù says Nalley. IBM‚Äôs Agent Communication Protocol was actually spun off of MCP.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Anthropic is still deciding exactly how to develop MCP. For now, it works with a steering committee of outside companies that help make decisions on MCP‚Äôs development, but Anthropic seems open to changing this approach. ‚ÄúWe are looking to evolve how we think about both ownership and governance in the future,‚Äù says Chu.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;h3 class="wp-block-heading"&gt;Is natural language fast enough?&lt;/h3&gt;  &lt;p&gt;MCP and A2A work on the agents‚Äô terms‚Äîthey use words and phrases (termed natural language in AI), just as AI models do when they are responding to a person. This is part of the selling point for these protocols, because it means the model doesn‚Äôt have to be trained to talk in a way that is unnatural to it. ‚ÄúAllowing a natural-language interface to be used between agents and not just with humans unlocks sharing the intelligence that is built into these agents,‚Äù says Surapaneni.&lt;/p&gt;  &lt;p&gt;But this choice does come with drawbacks. Natural-language interfaces lack the precision of APIs, and that could result in incorrect responses. And it creates inefficiencies.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;Usually, an AI model reads and responds to text by splitting words into tokens. The AI model will read a prompt, split it into input tokens, generate a response in the form of output tokens, and then put these tokens into words to send back. These tokens define in some sense how much work the AI model has to do‚Äîthat‚Äôs why most AI platforms charge users according to the number of tokens used.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;But the whole point of working in tokens is so that people can understand the output‚Äîit‚Äôs usually faster and more efficient for machine-to-machine communication to just work over code. MCP and A2A both work in natural language, so they require the model to spend tokens as the agent talks to other machines, like tools and other agents. The user never even sees these exchanges‚Äîall the effort of making everything human-readable doesn‚Äôt ever get read by a human. ‚ÄúYou waste a lot of tokens if you want to use MCP,‚Äù says Chen.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Chen describes this process as potentially very costly. For example, suppose the user wants the agent to read a document and summarize it. If the agent uses another program to summarize here, it needs to read the document, write the document to the program, read back the summary, and write it back to the user. Since the agent needed to read and write everything, both the document and the summary get doubled up. According to Chen, ‚ÄúIt‚Äôs actually a lot of tokens.‚Äù&lt;/p&gt;  &lt;p&gt;As with so many aspects of MCP and A2A‚Äôs designs, their benefits also create new challenges. ‚ÄúThere‚Äôs a long way to go if we want to scale up and actually make them useful,‚Äù says Chen.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/250728-AIAgents2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;A growing number of companies are launching AI agents that can do things on your behalf‚Äîactions like sending an email, making a document, or editing a database. Initial reviews for these agents have been mixed at best, though, because they struggle to interact with all the different components of our digital lives.&lt;/p&gt;  &lt;p&gt;Part of the problem is that we are still building the necessary infrastructure to help agents navigate the world. If we want agents to complete tasks for us, we need to give them the necessary tools while also making sure they use that power responsibly.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Anthropic and Google are among the companies and groups working to do those. Over the past year, they have both introduced protocols that try to define how AI agents should interact with each other and the world around them. These protocols could make it easier for agents to control other programs like email clients and note-taking apps.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The reason has to do with application programming interfaces, the connections between computers or programs that govern much of our online world. APIs currently reply to ‚Äúpings‚Äù with standardized information. But AI models aren‚Äôt made to work exactly the same every time. The very randomness that helps them come across as conversational and expressive also makes it difficult for them to both call an API and understand the response.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;‚ÄúModels speak a natural language,‚Äù says Theo Chu, a project manager at Anthropic. ‚ÄúFor [a model] to get context and do something with that context, there is a translation layer that has to happen for it to make sense to the model.‚Äù Chu works on one such translation technique, the Model Context Protocol (MCP), which Anthropic introduced at the end of last year.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;MCP attempts to standardize how AI agents interact with the world via various programs, and it‚Äôs already very popular. One web aggregator for MCP servers (essentially, the portals for different programs or tools that agents can access) lists over 15,000 servers already.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Working out how to govern how AI agents interact with each other is arguably an even steeper challenge, and it‚Äôs one the Agent2Agent protocol (A2A), introduced by Google in April, tries to take on. Whereas MCP translates requests between words and code, A2A tries to moderate exchanges between agents, which is an ‚Äúessential next step for the industry to move beyond single-purpose agents,‚Äù Rao Surapaneni, who works with A2A at Google Cloud, wrote in an email to &lt;em&gt;MIT Technology Review&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Google says 150 companies have already partnered with it to develop and adopt A2A, including Adobe and Salesforce. At a high level, both MCP and A2A tell an AI agent what it absolutely needs to do, what it should do, and what it should not do to ensure a safe interaction with other services. In a way, they are complementary‚Äîeach agent in an A2A interaction could individually be using MCP to fetch information the other asks for.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;However, Chu stresses that it is ‚Äúdefinitely still early days‚Äù for MCP, and the A2A road map lists plenty of tasks still to be done. We‚Äôve identified the three main areas of growth for MCP, A2A, and other agent protocols: security, openness, and efficiency.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;h3 class="wp-block-heading"&gt;What should these protocols say about security?&lt;/h3&gt;  &lt;p&gt;Researchers and developers still don‚Äôt really understand how AI models work, and new vulnerabilities are being discovered all the time. For chatbot-style AI applications, malicious attacks can cause models to do all sorts of bad things, including regurgitating training data and spouting slurs. But for AI agents, which interact with the world on someone‚Äôs behalf, the possibilities are far riskier.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For example, one AI agent, made to read and send emails for someone, has already been shown to be vulnerable to what‚Äôs known as an indirect prompt injection attack. Essentially, an email could be written in a way that hijacks the AI model and causes it to malfunction. Then, if that agent has access to the user‚Äôs files, it could be instructed to send private documents to the attacker.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Some researchers believe that protocols like MCP should prevent agents from carrying out harmful actions like this. However, it does not at the moment. ‚ÄúBasically, it does not have any security design,‚Äù says Zhaorun Chen, a&amp;nbsp; University of Chicago PhD student who works on AI agent security and uses MCP servers.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Bruce Schneier, a security researcher and activist, is skeptical that protocols like MCP will be able to do much to reduce the inherent risks that come with AI and is concerned that giving such technology more power will just give it more ability to cause harm in the real, physical world. ‚ÄúWe just don‚Äôt have good answers on how to secure this stuff,‚Äù says Schneier. ‚ÄúIt‚Äôs going to be a security cesspool really fast.‚Äù&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;Others are more hopeful. Security design could be added to MCP and A2A similar to the way it is for internet protocols like HTTPS (though the nature of attacks on AI systems is very different). And Chen and Anthropic believe that standardizing protocols like MCP and A2A can help make it easier to catch and resolve security issues even as is. Chen uses MCP in his research to test the roles different programs can play in attacks to better understand vulnerabilities. Chu at Anthropic believes that these tools could let cybersecurity companies more easily deal with attacks against agents, because it will be easier to unpack who sent what.&amp;nbsp;&lt;/p&gt;    &lt;h3 class="wp-block-heading"&gt;How open should these protocols be?&lt;/h3&gt;  &lt;p&gt;Although MCP and A2A are two of the most popular agent protocols available today, there are plenty of others in the works. Large companies like Cisco and IBM are working on their own protocols, and other groups have put forth different designs like Agora, designed by researchers at the University of Oxford, which upgrades an agent-service communication from human language to structured data in real time.&lt;/p&gt;  &lt;p&gt;Many developers hope there could eventually be a registry of safe, trusted systems to navigate the proliferation of agents and tools. Others, including Chen, want users to be able to rate different services in something like a Yelp for AI agent tools. Some more niche protocols have even built blockchains on top of MCP and A2A so that servers can show they are not just spam.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;Both MCP and A2A are open-source, which is common for would-be standards as it lets others work on building them. This can help protocols develop faster and more transparently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;‚ÄúIf we go build something together, we spend less time overall, because we‚Äôre not having to each reinvent the wheel,‚Äù says David Nalley, who leads developer experience at Amazon Web Services and works with a lot of open-source systems, including A2A and MCP.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Nalley oversaw Google‚Äôs donation of A2A to the Linux Foundation, a nonprofit organization that guides open-source projects, back in June. With the foundation‚Äôs stewardship, the developers who work on A2A (including employees at Google and many others) all get a say in how it should evolve. MCP, on the other hand, is owned by Anthropic and licensed for free. That is a sticking point for some open-source advocates, who want others to have a say in how the code base itself is developed.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;‚ÄúThere‚Äôs admittedly some increased risk around a single person or a single entity being in absolute control,‚Äù says Nalley. He says most people would prefer multiple groups to have a ‚Äúseat at the table‚Äù to make sure that these protocols are serving everyone‚Äôs best interests.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;However, Nalley does believe Anthropic is acting in good faith‚Äîits license, he says, is incredibly permissive, allowing other groups to create their own modified versions of the code (a process known as ‚Äúforking‚Äù).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;‚ÄúSomeone could fork it if they needed to, if something went completely off the rails,‚Äù says Nalley. IBM‚Äôs Agent Communication Protocol was actually spun off of MCP.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Anthropic is still deciding exactly how to develop MCP. For now, it works with a steering committee of outside companies that help make decisions on MCP‚Äôs development, but Anthropic seems open to changing this approach. ‚ÄúWe are looking to evolve how we think about both ownership and governance in the future,‚Äù says Chu.&lt;/p&gt;   &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;h3 class="wp-block-heading"&gt;Is natural language fast enough?&lt;/h3&gt;  &lt;p&gt;MCP and A2A work on the agents‚Äô terms‚Äîthey use words and phrases (termed natural language in AI), just as AI models do when they are responding to a person. This is part of the selling point for these protocols, because it means the model doesn‚Äôt have to be trained to talk in a way that is unnatural to it. ‚ÄúAllowing a natural-language interface to be used between agents and not just with humans unlocks sharing the intelligence that is built into these agents,‚Äù says Surapaneni.&lt;/p&gt;  &lt;p&gt;But this choice does come with drawbacks. Natural-language interfaces lack the precision of APIs, and that could result in incorrect responses. And it creates inefficiencies.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt;&lt;p&gt;Usually, an AI model reads and responds to text by splitting words into tokens. The AI model will read a prompt, split it into input tokens, generate a response in the form of output tokens, and then put these tokens into words to send back. These tokens define in some sense how much work the AI model has to do‚Äîthat‚Äôs why most AI platforms charge users according to the number of tokens used.&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-nowrap is-layout-flex wp-container-core-group-is-layout-6c531013 wp-block-group-is-layout-flex"&gt; &lt;p&gt;But the whole point of working in tokens is so that people can understand the output‚Äîit‚Äôs usually faster and more efficient for machine-to-machine communication to just work over code. MCP and A2A both work in natural language, so they require the model to spend tokens as the agent talks to other machines, like tools and other agents. The user never even sees these exchanges‚Äîall the effort of making everything human-readable doesn‚Äôt ever get read by a human. ‚ÄúYou waste a lot of tokens if you want to use MCP,‚Äù says Chen.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Chen describes this process as potentially very costly. For example, suppose the user wants the agent to read a document and summarize it. If the agent uses another program to summarize here, it needs to read the document, write the document to the program, read back the summary, and write it back to the user. Since the agent needed to read and write everything, both the document and the summary get doubled up. According to Chen, ‚ÄúIt‚Äôs actually a lot of tokens.‚Äù&lt;/p&gt;  &lt;p&gt;As with so many aspects of MCP and A2A‚Äôs designs, their benefits also create new challenges. ‚ÄúThere‚Äôs a long way to go if we want to scale up and actually make them useful,‚Äù says Chen.&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/08/04/1120996/protocols-help-agents-navigate-lives-mcp-a2a/</guid><pubDate>Mon, 04 Aug 2025 15:00:13 +0000</pubDate></item><item><title>[NEW] Grok Imagine, xAI‚Äôs new AI image and video generator, lets you make NSFW content (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/04/grok-imagine-xais-new-ai-image-and-video-generator-lets-you-make-nsfw-content/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk‚Äôs AI company has officially rolled out Grok Imagine, xAI‚Äôs image and video generator, to all SuperGrok and Premium+ X subscribers on its iOS app. And true to form for Musk, who positions Grok as an unfiltered, boundary-pushing AI, the generator allows users to make NSFW content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok Imagine, which promises to turn text or image prompts into a 15-second video featuring native audio, has a ‚Äúspicy mode‚Äù that allows users to generate sexually explicit content, including partial female nudity . There are limits to how explicit one can get. Many of our spicier prompts ‚Äî made in the name of Journalism! ‚Äî generate blurred-out images that are ‚Äúmoderated‚Äù and therefore inaccessible. We were, however, able to generate semi-nude imagery.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The NSFW content is unsurprising for xAI, given the release last month of a raunchy, hyper-sexualized anime AI companion. But just as Grok‚Äôs unrestrained nature was entertaining until it started spewing hateful, antisemitic, misogynistic content, Grok Imagine could be poised to bring its own set of unintended consequences.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CNBC first reported the existence of a ‚Äúspicy mode‚Äù last week after xAI employee Mati Roy said in a now-deleted post on X: ‚ÄúGrok Imagine videos have a spicy mode that can do nudity.‚Äù&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to xAI for more information.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The existing limitations with Grok Imagine are somewhat heartening given the model also lets you create content of celebrities ‚Äî anyone from Donald Trump to Taylor Swift ‚Äî and there appear to be additional restrictions on those. For example, TechCrunch tried, and failed, to generate an image of Trump pregnant. Grok Imagine only generated images of Trump holding a baby or next to a pregnant woman.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While it‚Äôs still early days for Grok Imagine, which aims to compete with incumbents like Google DeepMind, OpenAI, Runway, and Chinese rivals, the images and videos generated of humans are still a bit lost in the uncanny valley, with waxy-looking skin that verges on cartoonish at times.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the generator is impressive. It produces images in seconds from a text prompt, and continues to auto-generate new images as you scroll. Those images can then be animated into stylized videos. The user interface is also seamless and intuitive.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk said on X that the model would ‚Äúget better every day.‚Äù&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2207699717.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk‚Äôs AI company has officially rolled out Grok Imagine, xAI‚Äôs image and video generator, to all SuperGrok and Premium+ X subscribers on its iOS app. And true to form for Musk, who positions Grok as an unfiltered, boundary-pushing AI, the generator allows users to make NSFW content.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Grok Imagine, which promises to turn text or image prompts into a 15-second video featuring native audio, has a ‚Äúspicy mode‚Äù that allows users to generate sexually explicit content, including partial female nudity . There are limits to how explicit one can get. Many of our spicier prompts ‚Äî made in the name of Journalism! ‚Äî generate blurred-out images that are ‚Äúmoderated‚Äù and therefore inaccessible. We were, however, able to generate semi-nude imagery.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The NSFW content is unsurprising for xAI, given the release last month of a raunchy, hyper-sexualized anime AI companion. But just as Grok‚Äôs unrestrained nature was entertaining until it started spewing hateful, antisemitic, misogynistic content, Grok Imagine could be poised to bring its own set of unintended consequences.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CNBC first reported the existence of a ‚Äúspicy mode‚Äù last week after xAI employee Mati Roy said in a now-deleted post on X: ‚ÄúGrok Imagine videos have a spicy mode that can do nudity.‚Äù&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to xAI for more information.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The existing limitations with Grok Imagine are somewhat heartening given the model also lets you create content of celebrities ‚Äî anyone from Donald Trump to Taylor Swift ‚Äî and there appear to be additional restrictions on those. For example, TechCrunch tried, and failed, to generate an image of Trump pregnant. Grok Imagine only generated images of Trump holding a baby or next to a pregnant woman.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While it‚Äôs still early days for Grok Imagine, which aims to compete with incumbents like Google DeepMind, OpenAI, Runway, and Chinese rivals, the images and videos generated of humans are still a bit lost in the uncanny valley, with waxy-looking skin that verges on cartoonish at times.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the generator is impressive. It produces images in seconds from a text prompt, and continues to auto-generate new images as you scroll. Those images can then be animated into stylized videos. The user interface is also seamless and intuitive.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk said on X that the model would ‚Äúget better every day.‚Äù&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/04/grok-imagine-xais-new-ai-image-and-video-generator-lets-you-make-nsfw-content/</guid><pubDate>Mon, 04 Aug 2025 15:04:18 +0000</pubDate></item><item><title>[NEW] OpenAI says ChatGPT is on track to reach 700M weekly users (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/04/openai-says-chatgpt-is-on-track-to-reach-700m-weekly-users/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2205105208.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT‚Äôs impressive growth as a consumer app continues as the chatbot is on track to hit 700 million weekly active users this week, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app had earlier reached 500 million weekly active users as of the end of March, noted Nick Turley, OpenAI VP and head of ChatGPT‚Äôs app, in a post on X. He also said the app has grown 4x since last year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúEvery day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and delivering on our mission so everyone can benefit from AI,‚Äù he posted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app‚Äôs popularity increased after OpenAI launched an upgraded image-generation feature, powered by the GPT-4 model, in March. In early April, the company‚Äôs COO, Brad Lightcap, said that more than 130 million users had created over 700 million images in just a few days after the launch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has also seen an increase in subscribers. Last week, Lightcap said that ChatGPT had 5 million paying business users, up from 3 million in June.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a recent report, market intelligence firm Sensor Tower noted that users are using ChatGPT for more than 12 days a month on average, only behind Google and X. The report also said that in H1 2025, users spent an average of 16 minutes per day on the app.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2205105208.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT‚Äôs impressive growth as a consumer app continues as the chatbot is on track to hit 700 million weekly active users this week, the company says.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app had earlier reached 500 million weekly active users as of the end of March, noted Nick Turley, OpenAI VP and head of ChatGPT‚Äôs app, in a post on X. He also said the app has grown 4x since last year.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;‚ÄúEvery day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and delivering on our mission so everyone can benefit from AI,‚Äù he posted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The app‚Äôs popularity increased after OpenAI launched an upgraded image-generation feature, powered by the GPT-4 model, in March. In early April, the company‚Äôs COO, Brad Lightcap, said that more than 130 million users had created over 700 million images in just a few days after the launch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has also seen an increase in subscribers. Last week, Lightcap said that ChatGPT had 5 million paying business users, up from 3 million in June.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a recent report, market intelligence firm Sensor Tower noted that users are using ChatGPT for more than 12 days a month on average, only behind Google and X. The report also said that in H1 2025, users spent an average of 16 minutes per day on the app.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/04/openai-says-chatgpt-is-on-track-to-reach-700m-weekly-users/</guid><pubDate>Mon, 04 Aug 2025 15:25:13 +0000</pubDate></item><item><title>[NEW] Perplexity accused of scraping websites that explicitly blocked AI scraping (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/04/perplexity-accused-of-scraping-websites-that-explicitly-blocked-ai-scraping/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2181996346.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI startup Perplexity is crawling and scraping content from websites that have explicitly indicated they don‚Äôt want to be scraped, according to internet infrastructure provider Cloudflare.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, Cloudflare published research saying it observed the AI startup ignore blocks and hide its crawling and scraping activities. The network infrastructure giant accused Perplexity of obscuring its identity when trying to scrape web pages ‚Äúin an attempt to circumvent the website‚Äôs preferences,‚Äù Cloudflare‚Äôs researchers wrote.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI products like those offered by Perplexity rely on gobbling up large amounts of data from the internet, and AI startups have long scraped text, images, and videos from the internet many times without permission to make their products work. In recent times, websites have tried to fight back by using the web standard Robots.txt file, which tells search engines and AI companies which pages can be indexed and which shouldn‚Äôt, efforts that have seen mixed results so far.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity appears to be willingly circumventing these blocks by changing its bots‚Äô ‚Äúuser agent,‚Äù meaning a signal that identifies a website visitor by their device and version type, as well as changing their autonomous system networks, or ASN, essentially a number that identifies large networks on the internet, according to Cloudflare.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis activity was observed across tens of thousands of domains and millions of requests per day. We were able to fingerprint this crawler using a combination of machine learning and network signals,‚Äù read Cloudflare‚Äôs post.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity spokesperson Jesse Dwyer dismissed Cloudflare‚Äôs blog post as a ‚Äúsales pitch,‚Äù adding in an email to TechCrunch that the screenshots in the post ‚Äúshow that no content was accessed.‚Äù In a follow-up email, Dwyer claimed the bot named in the Cloudflare blog ‚Äúisn‚Äôt even ours.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloudflare said it first noticed the behavior after its customers complained that Perplexity was crawling and scraping their sites, even after they added rules on their Robots file and for specifically blocking Perplexity‚Äôs known bots. Cloudflare said it then performed tests to check and confirmed that Perplexity was circumventing these blocks.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe observed that Perplexity uses not only their declared user-agent, but also a generic browser intended to impersonate Google Chrome on macOS when their declared crawler was blocked,‚Äù according to Cloudflare.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also said that it has de-listed Perplexity‚Äôs bots from its verified list and added new techniques to block them.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloudflare has recently taken a public stance against AI crawlers. Last month, Cloudflare announced the launch of a marketplace allowing website owners and publishers to charge AI scrapers who visit their sites. Cloudflare‚Äôs chief executive Matthew Prince sounded the alarm at the time, saying AI is breaking the business model of the internet, particularly publishers. Last year, Cloudflare also launched a free tool to prevent bots from scraping websites to train AI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is not the first time Perplexity is accused of scraping without authorization.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, news outlets, such as Wired, alleged Perplexity was plagiarizing their content. Weeks later, Perplexity‚Äôs CEO Aravind Srinivas was unable to immediately answer when asked to provide the company‚Äôs definition of plagiarism during an interview with TechCrunch‚Äôs Devin Coldewey at the Disrupt 2024 conference.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2181996346.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI startup Perplexity is crawling and scraping content from websites that have explicitly indicated they don‚Äôt want to be scraped, according to internet infrastructure provider Cloudflare.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Monday, Cloudflare published research saying it observed the AI startup ignore blocks and hide its crawling and scraping activities. The network infrastructure giant accused Perplexity of obscuring its identity when trying to scrape web pages ‚Äúin an attempt to circumvent the website‚Äôs preferences,‚Äù Cloudflare‚Äôs researchers wrote.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AI products like those offered by Perplexity rely on gobbling up large amounts of data from the internet, and AI startups have long scraped text, images, and videos from the internet many times without permission to make their products work. In recent times, websites have tried to fight back by using the web standard Robots.txt file, which tells search engines and AI companies which pages can be indexed and which shouldn‚Äôt, efforts that have seen mixed results so far.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity appears to be willingly circumventing these blocks by changing its bots‚Äô ‚Äúuser agent,‚Äù meaning a signal that identifies a website visitor by their device and version type, as well as changing their autonomous system networks, or ASN, essentially a number that identifies large networks on the internet, according to Cloudflare.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúThis activity was observed across tens of thousands of domains and millions of requests per day. We were able to fingerprint this crawler using a combination of machine learning and network signals,‚Äù read Cloudflare‚Äôs post.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity spokesperson Jesse Dwyer dismissed Cloudflare‚Äôs blog post as a ‚Äúsales pitch,‚Äù adding in an email to TechCrunch that the screenshots in the post ‚Äúshow that no content was accessed.‚Äù In a follow-up email, Dwyer claimed the bot named in the Cloudflare blog ‚Äúisn‚Äôt even ours.‚Äù&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloudflare said it first noticed the behavior after its customers complained that Perplexity was crawling and scraping their sites, even after they added rules on their Robots file and for specifically blocking Perplexity‚Äôs known bots. Cloudflare said it then performed tests to check and confirmed that Perplexity was circumventing these blocks.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;‚ÄúWe observed that Perplexity uses not only their declared user-agent, but also a generic browser intended to impersonate Google Chrome on macOS when their declared crawler was blocked,‚Äù according to Cloudflare.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also said that it has de-listed Perplexity‚Äôs bots from its verified list and added new techniques to block them.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cloudflare has recently taken a public stance against AI crawlers. Last month, Cloudflare announced the launch of a marketplace allowing website owners and publishers to charge AI scrapers who visit their sites. Cloudflare‚Äôs chief executive Matthew Prince sounded the alarm at the time, saying AI is breaking the business model of the internet, particularly publishers. Last year, Cloudflare also launched a free tool to prevent bots from scraping websites to train AI.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is not the first time Perplexity is accused of scraping without authorization.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, news outlets, such as Wired, alleged Perplexity was plagiarizing their content. Weeks later, Perplexity‚Äôs CEO Aravind Srinivas was unable to immediately answer when asked to provide the company‚Äôs definition of plagiarism during an interview with TechCrunch‚Äôs Devin Coldewey at the Disrupt 2024 conference.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/04/perplexity-accused-of-scraping-websites-that-explicitly-blocked-ai-scraping/</guid><pubDate>Mon, 04 Aug 2025 15:41:39 +0000</pubDate></item><item><title>[NEW] Rethinking how we measure AI intelligence (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/rethinking-how-we-measure-ai-intelligence/</link><description>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="A stylized illustration showing elements of various strategy games. A large chess queen, playing cards, and a Go board are displayed next to a list, representing strategic analysis." class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/game_arena_keyword_blog_header.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Current AI benchmarks are struggling to keep pace with modern models. As helpful as they are to measure model performance on specific tasks, it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they've already seen. As models reach closer to 100% on certain benchmarks, they also become less effective at revealing meaningful performance differences. We continue to invest in new and more challenging benchmarks, but on the path to general intelligence, we need to continue to look for new ways to evaluate. The more recent shift towards dynamic, human-judged testing solves these issues of memorization and saturation, but in turn, creates new difficulties stemming from the inherent subjectivity of human preferences.&lt;/p&gt;&lt;p&gt;While we continue to evolve and pursue current AI benchmarks, we‚Äôre also consistently looking to test new approaches to evaluating models. That‚Äôs why today, we're introducing the Kaggle Game Arena: a new, public AI benchmarking platform where AI models compete head-to-head in strategic games, providing a verifiable, and dynamic measure of their capabilities.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Why games are a meaningful evaluation benchmark&lt;/h2&gt;&lt;p&gt;Games provide a clear, unambiguous signal of success. Their structured nature and measurable outcomes make them the perfect testbed for evaluating models and agents. They force models to demonstrate many skills including strategic reasoning, long-term planning and dynamic adaptation against an intelligent opponent, providing a robust signal of their general problem-solving intelligence. The value of games as a benchmark is further enhanced by their scalability‚Äîdifficulty increases with the opponent's intelligence‚Äîand by our ability to inspect and visualize a model's "reasoning," which offers a glimpse into its strategic thought process.&lt;/p&gt;&lt;p&gt;Specialized engines like Stockfish and general game playing AI models like AlphaZero have been able to play games at a superhuman level for many years and would beat every frontier model without a doubt. Today‚Äôs large language models, however, are not built to specialize in any specific games, and as a result they do not play them nearly as well. While the immediate challenge for the models is to close this gap, in the long-term we would hope for them to achieve a level of play beyond what is currently possible. And with an endlessly increasing set of novel environments we can continue to challenge them even further.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How Game Arena promotes fair and open evaluation&lt;/h2&gt;&lt;p&gt;Game Arena is built on Kaggle to provide a fair, standardized environment for model evaluation. For transparency, game harnesses ‚Äî the frameworks that connect each AI model to the game environment and enforce the rules ‚Äî as well as the game environments are all open-sourced. Final rankings are determined by a rigorous all-play-all system, where an extensive number of matches between each model pair ensures a statistically robust result.&lt;/p&gt;&lt;p&gt;Google DeepMind has long used games as a benchmark, from Atari to AlphaGo and AlphaStar, to demonstrate complex AI capabilities. By testing these models in a competitive arena, we can establish a clear baseline for their strategic reasoning and track progress. The goal is to build an ever-expanding benchmark that grows in difficulty as models face tougher competition. Over time, this could lead to novel strategies, much like AlphaGo's famous and creative ‚ÄúMove 37‚Äù that baffled human experts. The ability to plan, adapt and reason under pressure in a game is analogous to the thinking needed to solve complex challenges in science and business.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How you can watch the chess exhibition matches&lt;/h2&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;On August 5 at 10:30 a.m. Pacific Time, join us for a special chess exhibition where eight frontier models will face off in a single elimination showdown. We selected a sample from the matches for this exhibition. Hosted by the world's best chess experts, this event is the premiere demonstration of the Game Arena methodology.&lt;/p&gt;&lt;p&gt;While the fun exhibition matches are in a tournament format, the final leaderboard rankings will be determined by the all-play-all system and released after the exhibition. This more extensive method runs over a hundred matches between every pair of models to ensure a statistically robust and definitive measure of performance. You can find more details and how to watch the games at kaggle.com/game-arena.&lt;/p&gt;&lt;p&gt;We plan to run more tournaments in the future on a regular basis, more on that soon.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How we‚Äôre building the future of AI benchmarks&lt;/h2&gt;&lt;p&gt;This is only the beginning. Our vision for the Game Arena extends far beyond a single game. Kaggle will soon expand Game Arena with new challenges, starting with classics like Go and poker. These games, along with future additions like video games, are excellent tests of AI‚Äôs ability to perform long-horizon planning and reasoning, helping us create a comprehensive and ever-evolving benchmark for AI. We‚Äôre committed to continuously adding new models and harnesses to the mix, pushing the boundaries of what AI models can achieve. For more details about the Game Arena and the inaugural chess exhibition tournament, see Kaggle‚Äôs blog post.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</description><content:encoded>&lt;div class="article-image-hero"&gt;
  &lt;div class="article-image-hero__container"&gt;
    &lt;figure class="article-image--full-aspect article-module"&gt;
      &lt;div class="aspect-ratio-image"&gt;
        &lt;div class="aspect-ratio-image__container"&gt;
          &lt;img alt="A stylized illustration showing elements of various strategy games. A large chess queen, playing cards, and a Go board are displayed next to a list, representing strategic analysis." class="aspect-ratio-image__image uni-progressive-image--blur" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/game_arena_keyword_blog_header.width-2200.format-webp.webp" width="360px" /&gt;
        &lt;/div&gt;
      &lt;/div&gt;
      
    &lt;/figure&gt;
  &lt;/div&gt;
&lt;/div&gt;&lt;div class="uni-content uni-blog-article-container article-container__content
                      
                      "&gt;

            
              







            

            
            
&lt;!--article text--&gt;

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;Current AI benchmarks are struggling to keep pace with modern models. As helpful as they are to measure model performance on specific tasks, it can be hard to know if models trained on internet data are actually solving problems or just remembering answers they've already seen. As models reach closer to 100% on certain benchmarks, they also become less effective at revealing meaningful performance differences. We continue to invest in new and more challenging benchmarks, but on the path to general intelligence, we need to continue to look for new ways to evaluate. The more recent shift towards dynamic, human-judged testing solves these issues of memorization and saturation, but in turn, creates new difficulties stemming from the inherent subjectivity of human preferences.&lt;/p&gt;&lt;p&gt;While we continue to evolve and pursue current AI benchmarks, we‚Äôre also consistently looking to test new approaches to evaluating models. That‚Äôs why today, we're introducing the Kaggle Game Arena: a new, public AI benchmarking platform where AI models compete head-to-head in strategic games, providing a verifiable, and dynamic measure of their capabilities.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;Why games are a meaningful evaluation benchmark&lt;/h2&gt;&lt;p&gt;Games provide a clear, unambiguous signal of success. Their structured nature and measurable outcomes make them the perfect testbed for evaluating models and agents. They force models to demonstrate many skills including strategic reasoning, long-term planning and dynamic adaptation against an intelligent opponent, providing a robust signal of their general problem-solving intelligence. The value of games as a benchmark is further enhanced by their scalability‚Äîdifficulty increases with the opponent's intelligence‚Äîand by our ability to inspect and visualize a model's "reasoning," which offers a glimpse into its strategic thought process.&lt;/p&gt;&lt;p&gt;Specialized engines like Stockfish and general game playing AI models like AlphaZero have been able to play games at a superhuman level for many years and would beat every frontier model without a doubt. Today‚Äôs large language models, however, are not built to specialize in any specific games, and as a result they do not play them nearly as well. While the immediate challenge for the models is to close this gap, in the long-term we would hope for them to achieve a level of play beyond what is currently possible. And with an endlessly increasing set of novel environments we can continue to challenge them even further.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How Game Arena promotes fair and open evaluation&lt;/h2&gt;&lt;p&gt;Game Arena is built on Kaggle to provide a fair, standardized environment for model evaluation. For transparency, game harnesses ‚Äî the frameworks that connect each AI model to the game environment and enforce the rules ‚Äî as well as the game environments are all open-sourced. Final rankings are determined by a rigorous all-play-all system, where an extensive number of matches between each model pair ensures a statistically robust result.&lt;/p&gt;&lt;p&gt;Google DeepMind has long used games as a benchmark, from Atari to AlphaGo and AlphaStar, to demonstrate complex AI capabilities. By testing these models in a competitive arena, we can establish a clear baseline for their strategic reasoning and track progress. The goal is to build an ever-expanding benchmark that grows in difficulty as models face tougher competition. Over time, this could lead to novel strategies, much like AlphaGo's famous and creative ‚ÄúMove 37‚Äù that baffled human experts. The ability to plan, adapt and reason under pressure in a game is analogous to the thinking needed to solve complex challenges in science and business.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How you can watch the chess exhibition matches&lt;/h2&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    
  
    




  
  











  


  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;p&gt;On August 5 at 10:30 a.m. Pacific Time, join us for a special chess exhibition where eight frontier models will face off in a single elimination showdown. We selected a sample from the matches for this exhibition. Hosted by the world's best chess experts, this event is the premiere demonstration of the Game Arena methodology.&lt;/p&gt;&lt;p&gt;While the fun exhibition matches are in a tournament format, the final leaderboard rankings will be determined by the all-play-all system and released after the exhibition. This more extensive method runs over a hundred matches between every pair of models to ensure a statistically robust and definitive measure of performance. You can find more details and how to watch the games at kaggle.com/game-arena.&lt;/p&gt;&lt;p&gt;We plan to run more tournaments in the future on a regular basis, more on that soon.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  

  
    &lt;div class="module--text module--text__article"&gt;
      &lt;div class="uni-paragraph article-paragraph"&gt;
        &lt;div class="rich-text"&gt;&lt;h2&gt;How we‚Äôre building the future of AI benchmarks&lt;/h2&gt;&lt;p&gt;This is only the beginning. Our vision for the Game Arena extends far beyond a single game. Kaggle will soon expand Game Arena with new challenges, starting with classics like Go and poker. These games, along with future additions like video games, are excellent tests of AI‚Äôs ability to perform long-horizon planning and reasoning, helping us create a comprehensive and ever-evolving benchmark for AI. We‚Äôre committed to continuously adding new models and harnesses to the mix, pushing the boundaries of what AI models can achieve. For more details about the Game Arena and the inaugural chess exhibition tournament, see Kaggle‚Äôs blog post.&lt;/p&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
  


            
            

            
              


&lt;div class="
    uni-blog-article-tags
    article-tags
    
  "&gt;
  &lt;div class="uni-blog-article-tags__wrapper"&gt;
    &lt;span class="uni-blog-article-tags__label uni-eyebrow"&gt;POSTED IN:&lt;/span&gt;
  &lt;/div&gt;
  &lt;nav class="uni-blog-article-tags__container uni-click-tracker"&gt;
    &lt;ul class="uni-blog-article-tags__tags-list"&gt;
    
      &lt;li&gt;
        
        
        


  


AI


  


      &lt;/li&gt;
    

    
      &lt;li&gt;
        
        
        


  


Google DeepMind


  


      &lt;/li&gt;
    
    &lt;/ul&gt;
  &lt;/nav&gt;
&lt;/div&gt;

            
          &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/rethinking-how-we-measure-ai-intelligence/</guid><pubDate>Mon, 04 Aug 2025 16:07:18 +0000</pubDate></item></channel></rss>