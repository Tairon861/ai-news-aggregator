<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 18 Jul 2025 06:34:43 +0000</lastBuildDate><item><title>Measuring heart rate with consumer ultra-wideband radar (The latest research from Google)</title><link>https://research.google/blog/measuring-heart-rate-with-consumer-ultra-wideband-radar/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Transferring learned features to ultra-wideband radar&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We then ran a study that collected UWB radar data, along with electrocardiogram (ECG) and photoplethysmogram (PPG) data as our ground truth for heart rate, using a setup that placed the UWB radar sensor in positions where users typically hold their phone, i.e., on a table in front of them or on their lap. Compared to the FMCW dataset, which was 980 hours of data, the UWB radar dataset was much smaller, with 37.3 hours. As the UWB radar configuration was close to what is feasible on a mobile phone, with a much lower bandwidth, its range resolution was far lower than the FMCW dataset.&lt;/p&gt;&lt;p&gt;To ensure that our model was optimized to transfer to the UWB dataset, we retrained it after performing additional pre-processing steps to modify the mm-wave FMCW radar data to better resemble the target IR-UWB data, effectively lowering its range resolution. We then fine-tuned this model on the IR-UWB dataset, achieving an MAE of 4.1 bpm and mean absolute percentage error (MAPE) of 6.3%, a 25% reduction over the baseline error rate. Our baseline for performance on UWB radar was 5.4 bpm MAE and 8.4% MAPE, achieved by selecting the best model trained from scratch on our UWB dataset. With transfer learning, we enabled the UWB radar to meet the Consumer Technology Association standards for heart rate measurement for consumer devices: an accuracy of up to 5 bpm MAE and 10% MAPE.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Transferring learned features to ultra-wideband radar&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;We then ran a study that collected UWB radar data, along with electrocardiogram (ECG) and photoplethysmogram (PPG) data as our ground truth for heart rate, using a setup that placed the UWB radar sensor in positions where users typically hold their phone, i.e., on a table in front of them or on their lap. Compared to the FMCW dataset, which was 980 hours of data, the UWB radar dataset was much smaller, with 37.3 hours. As the UWB radar configuration was close to what is feasible on a mobile phone, with a much lower bandwidth, its range resolution was far lower than the FMCW dataset.&lt;/p&gt;&lt;p&gt;To ensure that our model was optimized to transfer to the UWB dataset, we retrained it after performing additional pre-processing steps to modify the mm-wave FMCW radar data to better resemble the target IR-UWB data, effectively lowering its range resolution. We then fine-tuned this model on the IR-UWB dataset, achieving an MAE of 4.1 bpm and mean absolute percentage error (MAPE) of 6.3%, a 25% reduction over the baseline error rate. Our baseline for performance on UWB radar was 5.4 bpm MAE and 8.4% MAPE, achieved by selecting the best model trained from scratch on our UWB dataset. With transfer learning, we enabled the UWB radar to meet the Consumer Technology Association standards for heart rate measurement for consumer devices: an accuracy of up to 5 bpm MAE and 10% MAPE.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/measuring-heart-rate-with-consumer-ultra-wideband-radar/</guid><pubDate>Thu, 17 Jul 2025 19:00:00 +0000</pubDate></item><item><title>Finding value from AI agents from day one (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/17/1119943/finding-value-from-ai-agents-from-day-one/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Boomi&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Imagine AI so sophisticated it could read a customer’s mind? Or identify and close a cybersecurity loophole weeks before hackers strike? How about a team of AI agents equipped to restructure a global supply chain and circumnavigate looming geopolitical disruption? Such disruptive possibilities explain why agentic AI is sending ripples of excitement through corporate boardrooms.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1119946" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/iStock-2179705717.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Although still so early in its development that there lacks consensus on a single, shared definition, agentic AI refers loosely to a suite of AI systems capable of connected and autonomous decision-making with zero or limited human intervention. In scenarios where traditional AI typically requires explicit prompts or instructions for each step, agentic AI will independently execute tasks, learning and adapting to its environment to refine decisions over time.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;From assuming oversight for complex workflows, such as procurement or recruitment, to carrying out proactive cybersecurity checks or automating support, enterprises are abuzz at the potential use cases for agentic AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;According to one Capgemini survey, 50% of business executives are set to invest in and implement AI agents in their organizations in 2025, up from just 10% currently. Gartner has also forecast that 33% of enterprise software applications will incorporate agentic AI by 2028. For context, in 2024 that proportion was less than 1%.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It’s creating such a buzz – software enthusiasts seeing the possibilities unlocked by LLMs, venture capitalists wanting to find the next big thing, companies trying to find the ‘killer app,” says Matt McLarty, chief technology officer at Boomi. But, he adds, “right now organizations are struggling to get out of the starting blocks.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The challenge is that many organizations are so caught up in the excitement that they risk attempting to run before they can walk when it comes to deployment of agentic AI, believes McLarty. And in so doing they risk turning it from potential business breakthrough into a source of cost, complexity, and confusion.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Keeping agentic AI simple&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The heady capabilities of agentic AI have created understandable temptation for senior business leaders to rush in, acting on impulse rather than insight risks turning the technology into a solution in search of a problem, points out McLarty.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a scenario that’s unfolded with previous technologies. The decoupling of Blockchain from Bitcoin in 2014 paved the way for a Blockchain 2.0 boom in which organizations rushed to explore the applications for a digital, decentralized ledger beyond currency. But a decade on, the technology has fallen far short of forecasts at the time, dogged by technology limitations and obfuscated use cases.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I do see Blockchain as a cautionary tale,” says McLarty. “The hype and ultimate lack of adoption is definitely a path the agentic AI movement should avoid.” He explains, “The problem with Blockchain is that people struggle to find use cases where it applies as a solution, and even when they find the use cases, there is often a simpler and cheaper solution,” he adds. “I think agentic AI can do things no other solution can, in terms of contextual reasoning and dynamic execution. But as technologists, we get so excited about the technology, sometimes we lose sight of the business problem.”&lt;/p&gt;  &lt;p&gt;Instead of diving in headfirst, McLarty advocates for an iterative attitude toward applications of agentic AI, targeting “low-hanging fruit” and incremental use cases. This includes focusing investment on the worker agents that are set to make up the components of more sophisticated, multi-agent agentic systems further down the road.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;However, with a narrower, more prescribed remit, these AI agents with agentic capabilities can add instant value. Enabled with natural language processing (NLP) they can be used to bridge the linguistic shortfalls in current chat agents for example or adaptively carry out rote tasks via dynamic automation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Current rote automation processes generate a lot of value for organizations today, but they can lead to a lot of manual exception processing,” points out McLarty. “Agentic exception handling agents can eliminate a lot of that.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s also essential to avoid use cases for agentic AI that could be addressed with a cheaper and simpler technology. “Configuring a self-manager, ephemeral agent swarm may sound exciting and be exhilarating to build, but maybe you can just solve the problem with a simple reasoning agent that has access to some in-house contextual data and API-based tools,” says McLarty. “Let’s call it the KASS principle: Keep agents simple, stupid.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Connecting the dots&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The future value of agentic AI will lie in its interoperability and organizations that prioritize this pillar at the earliest phase of their adoption will find themselves ahead of the curve.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;As McLarty explains, the usefulness of agentic AI agents in scenarios like customer support chats lies in their combination of four elements: a defined business scope, large language models (LLM), the wider context derived from an organization’s existing data, and capabilities executed through its core applications. These latter two rely on in-built interoperability. For example, an AI agent tasked with onboarding new employees will require access to updated HR policies, asset catalogs and IT. “Organizations can get a massive head start on business value through AI agents by having interoperable data and applications to plug and play with agents,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Agent-to-agent frameworks like the model context protocol (MCP) – an open and standardized plug-and-play that connects AI models to internal (or external) information sources – can be layered onto an existing API architecture to embed connectedness from the outset. And while it might feel like an additional hurdle now, in the longer-term those organizations that make this investment early will reap the benefits.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The icing on the cake for interoperability is that all the work you do to connect agents to data and applications now will help you prepare for the multi-agent future where interoperability between agents will be essential,” says McLarty.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In this future, multi-agent systems will work collectively on more intricate, cross-functional tasks. Agentic systems will draw on AI agents across inventory, logistics and production to coordinate and optimize supply chain management for example or perform complex assembly tasks.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Conscious that this is where the technology is headed, third-party developers are already beginning to offer multi-agent capability. In December, Amazon launched such a tool for its Bedrock service, providing users access to specialized agents coordinated by a supervisor agent capable of breaking down requests, delegating tasks and consolidating outputs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But though such an off-the-rack solution has the advantage of allowing enterprises to bypass both the risk and complexity in leveraging such capabilities, the digital heterogeneity of larger organizations in particular will likely mean – in the longer-term at least – they’ll need to rely on their own API architecture to realize the full potential in multi-agent systems.&lt;/p&gt;  &lt;p&gt;McLarty’s advice is simple, “This is definitely a time to ground yourself in the business problem, and only go as far as you need to with the solution.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Boomi&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Imagine AI so sophisticated it could read a customer’s mind? Or identify and close a cybersecurity loophole weeks before hackers strike? How about a team of AI agents equipped to restructure a global supply chain and circumnavigate looming geopolitical disruption? Such disruptive possibilities explain why agentic AI is sending ripples of excitement through corporate boardrooms.&amp;nbsp;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1119946" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/iStock-2179705717.jpg" /&gt;&lt;/figure&gt;  &lt;p&gt;Although still so early in its development that there lacks consensus on a single, shared definition, agentic AI refers loosely to a suite of AI systems capable of connected and autonomous decision-making with zero or limited human intervention. In scenarios where traditional AI typically requires explicit prompts or instructions for each step, agentic AI will independently execute tasks, learning and adapting to its environment to refine decisions over time.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;From assuming oversight for complex workflows, such as procurement or recruitment, to carrying out proactive cybersecurity checks or automating support, enterprises are abuzz at the potential use cases for agentic AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;According to one Capgemini survey, 50% of business executives are set to invest in and implement AI agents in their organizations in 2025, up from just 10% currently. Gartner has also forecast that 33% of enterprise software applications will incorporate agentic AI by 2028. For context, in 2024 that proportion was less than 1%.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;“It’s creating such a buzz – software enthusiasts seeing the possibilities unlocked by LLMs, venture capitalists wanting to find the next big thing, companies trying to find the ‘killer app,” says Matt McLarty, chief technology officer at Boomi. But, he adds, “right now organizations are struggling to get out of the starting blocks.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The challenge is that many organizations are so caught up in the excitement that they risk attempting to run before they can walk when it comes to deployment of agentic AI, believes McLarty. And in so doing they risk turning it from potential business breakthrough into a source of cost, complexity, and confusion.&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Keeping agentic AI simple&amp;nbsp;&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The heady capabilities of agentic AI have created understandable temptation for senior business leaders to rush in, acting on impulse rather than insight risks turning the technology into a solution in search of a problem, points out McLarty.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s a scenario that’s unfolded with previous technologies. The decoupling of Blockchain from Bitcoin in 2014 paved the way for a Blockchain 2.0 boom in which organizations rushed to explore the applications for a digital, decentralized ledger beyond currency. But a decade on, the technology has fallen far short of forecasts at the time, dogged by technology limitations and obfuscated use cases.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“I do see Blockchain as a cautionary tale,” says McLarty. “The hype and ultimate lack of adoption is definitely a path the agentic AI movement should avoid.” He explains, “The problem with Blockchain is that people struggle to find use cases where it applies as a solution, and even when they find the use cases, there is often a simpler and cheaper solution,” he adds. “I think agentic AI can do things no other solution can, in terms of contextual reasoning and dynamic execution. But as technologists, we get so excited about the technology, sometimes we lose sight of the business problem.”&lt;/p&gt;  &lt;p&gt;Instead of diving in headfirst, McLarty advocates for an iterative attitude toward applications of agentic AI, targeting “low-hanging fruit” and incremental use cases. This includes focusing investment on the worker agents that are set to make up the components of more sophisticated, multi-agent agentic systems further down the road.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;However, with a narrower, more prescribed remit, these AI agents with agentic capabilities can add instant value. Enabled with natural language processing (NLP) they can be used to bridge the linguistic shortfalls in current chat agents for example or adaptively carry out rote tasks via dynamic automation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Current rote automation processes generate a lot of value for organizations today, but they can lead to a lot of manual exception processing,” points out McLarty. “Agentic exception handling agents can eliminate a lot of that.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s also essential to avoid use cases for agentic AI that could be addressed with a cheaper and simpler technology. “Configuring a self-manager, ephemeral agent swarm may sound exciting and be exhilarating to build, but maybe you can just solve the problem with a simple reasoning agent that has access to some in-house contextual data and API-based tools,” says McLarty. “Let’s call it the KASS principle: Keep agents simple, stupid.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Connecting the dots&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;The future value of agentic AI will lie in its interoperability and organizations that prioritize this pillar at the earliest phase of their adoption will find themselves ahead of the curve.&amp;nbsp;&lt;/p&gt; 

 &lt;p&gt;As McLarty explains, the usefulness of agentic AI agents in scenarios like customer support chats lies in their combination of four elements: a defined business scope, large language models (LLM), the wider context derived from an organization’s existing data, and capabilities executed through its core applications. These latter two rely on in-built interoperability. For example, an AI agent tasked with onboarding new employees will require access to updated HR policies, asset catalogs and IT. “Organizations can get a massive head start on business value through AI agents by having interoperable data and applications to plug and play with agents,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Agent-to-agent frameworks like the model context protocol (MCP) – an open and standardized plug-and-play that connects AI models to internal (or external) information sources – can be layered onto an existing API architecture to embed connectedness from the outset. And while it might feel like an additional hurdle now, in the longer-term those organizations that make this investment early will reap the benefits.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“The icing on the cake for interoperability is that all the work you do to connect agents to data and applications now will help you prepare for the multi-agent future where interoperability between agents will be essential,” says McLarty.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In this future, multi-agent systems will work collectively on more intricate, cross-functional tasks. Agentic systems will draw on AI agents across inventory, logistics and production to coordinate and optimize supply chain management for example or perform complex assembly tasks.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;Conscious that this is where the technology is headed, third-party developers are already beginning to offer multi-agent capability. In December, Amazon launched such a tool for its Bedrock service, providing users access to specialized agents coordinated by a supervisor agent capable of breaking down requests, delegating tasks and consolidating outputs.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But though such an off-the-rack solution has the advantage of allowing enterprises to bypass both the risk and complexity in leveraging such capabilities, the digital heterogeneity of larger organizations in particular will likely mean – in the longer-term at least – they’ll need to rely on their own API architecture to realize the full potential in multi-agent systems.&lt;/p&gt;  &lt;p&gt;McLarty’s advice is simple, “This is definitely a time to ground yourself in the business problem, and only go as far as you need to with the solution.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was researched, designed, and written entirely by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/17/1119943/finding-value-from-ai-agents-from-day-one/</guid><pubDate>Thu, 17 Jul 2025 19:27:23 +0000</pubDate></item><item><title>ChatGPT’s new AI agent can browse the web and create PowerPoint slideshows (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/07/chatgpts-new-ai-agent-can-browse-the-web-and-create-powerpoint-slideshows/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New "agentic" AI feature combines web browsing with task-execution abilities.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Two tin toy robots looking at laptop screen." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/robots_on_a_computer-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Two tin toy robots looking at laptop screen." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/robots_on_a_computer-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          josefkubes via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, OpenAI launched ChatGPT Agent, a new feature that lets the company's AI assistant complete multi-step tasks by controlling its own web browser. The update merges capabilities from OpenAI's earlier Operator tool and the Deep Research feature, allowing ChatGPT to navigate websites, run code, and create documents while users maintain control over the process.&lt;/p&gt;
&lt;p&gt;The feature marks OpenAI's latest entry into what the tech industry calls "agentic AI"—systems that can take autonomous multi-step actions on behalf of the user. OpenAI says users can ask Agent to handle requests like assembling and purchasing a clothing outfit for a particular occasion, creating PowerPoint slide decks, planning meals, or updating financial spreadsheets with new data.&lt;/p&gt;
&lt;p&gt;The system uses a combination of web browsers, terminal access, and API connections to complete these tasks, including "ChatGPT Connectors" that integrate with apps like Gmail and GitHub.&lt;/p&gt;
&lt;p&gt;While using Agent, users watch a window inside the ChatGPT interface that shows all of the AI's actions taking place inside its own private sandbox. This sandbox features its own virtual operating system and web browser with access to the real Internet; it does not control your personal device. "ChatGPT carries out these tasks using its own virtual computer," OpenAI writes, "fluidly shifting between reasoning and action to handle complex workflows from start to finish, all based on your instructions."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2106626 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A still image from an OpenAI ChatGPT Agent promotional demo video showing the AI agent searching for flights." class="center large" height="588" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/chatgpt_agent_screenshot_1-1024x588.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A still image from an OpenAI ChatGPT Agent promotional demo video showing the AI agent searching for flights.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Like Operator before it, the agent feature requires user permission before taking certain actions with real-world consequences, such as making purchases. Users can interrupt tasks at any point, take control of the browser, or stop operations entirely. The system also includes a "Watch Mode" for tasks like sending emails that require active user oversight.&lt;/p&gt;
&lt;p&gt;Since Agent surpasses Operator in capability, OpenAI says the company's earlier Operator preview site will remain functional for a few more weeks before being shut down.&lt;/p&gt;
&lt;h2&gt;Performance claims&lt;/h2&gt;
&lt;p&gt;OpenAI's claims are one thing, but how well the company's new AI agent will actually complete multi-step tasks will vary wildly depending on the situation. That's because the AI model isn't a complete form of problem-solving intelligence, but rather a complex master imitator. It has some flexibility in piecing a scenario together but also many blind spots. OpenAI trained the agent (and its constituent components) using examples of computer usage and tool usage; whatever falls outside of the examples absorbed from training data will likely still prove difficult to accomplish.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For example, the ChatGPT Agent System Card shows that the agent can fail at complex tasks that require chaining together many steps in a novel way. In a "Cyber Range" evaluation, the agent was tasked with conducting a full-scale operation in a simulated network designed to mimic a small online retailer. When left to solve the problem on its own, the agent was unable to complete the task. While it could successfully perform initial research steps, like identifying servers on the network, it struggled to proceed beyond that and was unable to chain together the necessary exploits to reach the final goal. Even when provided with hints, the agent still failed (which in this case might be good, since it couldn't perform an automated hack), this demonstrates a clear limitation in its ability to solve complex problems that fall outside of its familiar training examples.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2106631 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="526" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/chart.png" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI writes, "The SpreadsheetBench authors used a Windows environment using Microsoft Excel to evaluate spreadsheets. We used an OSX environment and LibreOffice, which may result in small grading differences. For example, the authors found an Overall Hard restriction of 15.02% for GPT‑4o, and we obtained 13.38%. We used the complete 912-question benchmark."

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAi

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Even so, OpenAI reports that ChatGPT agent achieves state-of-the-art performance on its own benchmark measurements, which should always be taken with a grain of salt until verified by impartial third parties. On Humanity's Last Exam, which tests AI performance on expert-level questions, the model scored 41.6 percent accuracy (compare that to OpenAI o3's 24.9 percent using tools). On FrontierMath, one of the most difficult math benchmarks yet devised, it reaches 27.4 percent accuracy with tool access (o3 with Python scored 19.3 percent).&lt;/p&gt;
&lt;p&gt;The company also claims the system outperforms humans on certain data science tasks like data analysis and modeling (such as creating forecasts or predictive models). On DSBench, a benchmark that seeks to measure that capability, ChatGPT agent scored 89.9 percent on data analysis tasks compared to 64.1 percent for humans, and 85.5 percent on data modeling tasks versus 65.0 percent for humans. The agent also scored 68.9 percent on OpenAI's BrowseComp for finding hard-to-locate web information and 45.5 percent on SpreadsheetBench for editing spreadsheets, which is higher than OpenAI's other AI models.&lt;/p&gt;
&lt;p&gt;It's worth noting that even though OpenAI says Agent can craft PowerPoint slide decks for users, the company acknowledged that slideshow generation is still in beta and outputs can feel "rudimentary in formatting and polish."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Safety and privacy&lt;/h2&gt;
&lt;p&gt;OpenAI admits that the launch introduces new security considerations. Because ChatGPT Agent can take direct actions on websites and access user data through connected services, it is vulnerable to prompt injection attacks—attempts by hackers to manipulate the AI's behavior through instructions that misdirect the AI model (in this case, likely through hidden instructions on web pages). For example, a site might have an invisible form field that instructs the AI model to enter your credit card information without your knowledge.&lt;/p&gt;
&lt;p&gt;OpenAI says it has implemented safeguards against prompt injections by training the model to identify and "resist" these attacks while requiring user confirmation for consequential or suspicious-looking actions. The model is also trained to actively refuse high-risk tasks such as bank transfers. During a livestream on Thursday, one OpenAI engineer characterized Agent as a system of AI models working together, some of which constantly monitor the other models' behavior for suspicious activity. Those overseers can hypothetically halt a process if they spot a potentially dangerous scenario.&lt;/p&gt;
&lt;p&gt;As for privacy, since Agent runs in a virtual machine on OpenAI's servers, users won't need to worry about the bot having access to local private data stored on their device. But what you feed into ChatGPT Agent could still be shared on the web during its operations. Beyond that, OpenAI says privacy controls for the new agent allow users to delete all browsing data and log out of active sessions with one click. When users take control of the browser in "takeover mode," OpenAI states it does not collect or store data entered during these sessions, including passwords.&lt;/p&gt;
&lt;p&gt;Agent launches today for ChatGPT Pro users, who receive 400 messages per month. Plus and Team subscribers will gain access over the next few days with 40 monthly messages. Enterprise and Education users will receive access in the coming weeks. The feature is not yet available in the European Economic Area and Switzerland.&lt;/p&gt;
&lt;p&gt;We've not yet used ChatGPT Agent ourselves, but we may follow up with our experiences at a later date.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        New "agentic" AI feature combines web browsing with task-execution abilities.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Two tin toy robots looking at laptop screen." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/robots_on_a_computer-640x360.jpg" width="640" /&gt;
                  &lt;img alt="Two tin toy robots looking at laptop screen." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/robots_on_a_computer-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          josefkubes via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;On Thursday, OpenAI launched ChatGPT Agent, a new feature that lets the company's AI assistant complete multi-step tasks by controlling its own web browser. The update merges capabilities from OpenAI's earlier Operator tool and the Deep Research feature, allowing ChatGPT to navigate websites, run code, and create documents while users maintain control over the process.&lt;/p&gt;
&lt;p&gt;The feature marks OpenAI's latest entry into what the tech industry calls "agentic AI"—systems that can take autonomous multi-step actions on behalf of the user. OpenAI says users can ask Agent to handle requests like assembling and purchasing a clothing outfit for a particular occasion, creating PowerPoint slide decks, planning meals, or updating financial spreadsheets with new data.&lt;/p&gt;
&lt;p&gt;The system uses a combination of web browsers, terminal access, and API connections to complete these tasks, including "ChatGPT Connectors" that integrate with apps like Gmail and GitHub.&lt;/p&gt;
&lt;p&gt;While using Agent, users watch a window inside the ChatGPT interface that shows all of the AI's actions taking place inside its own private sandbox. This sandbox features its own virtual operating system and web browser with access to the real Internet; it does not control your personal device. "ChatGPT carries out these tasks using its own virtual computer," OpenAI writes, "fluidly shifting between reasoning and action to handle complex workflows from start to finish, all based on your instructions."&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2106626 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="A still image from an OpenAI ChatGPT Agent promotional demo video showing the AI agent searching for flights." class="center large" height="588" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/chatgpt_agent_screenshot_1-1024x588.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A still image from an OpenAI ChatGPT Agent promotional demo video showing the AI agent searching for flights.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAI

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Like Operator before it, the agent feature requires user permission before taking certain actions with real-world consequences, such as making purchases. Users can interrupt tasks at any point, take control of the browser, or stop operations entirely. The system also includes a "Watch Mode" for tasks like sending emails that require active user oversight.&lt;/p&gt;
&lt;p&gt;Since Agent surpasses Operator in capability, OpenAI says the company's earlier Operator preview site will remain functional for a few more weeks before being shut down.&lt;/p&gt;
&lt;h2&gt;Performance claims&lt;/h2&gt;
&lt;p&gt;OpenAI's claims are one thing, but how well the company's new AI agent will actually complete multi-step tasks will vary wildly depending on the situation. That's because the AI model isn't a complete form of problem-solving intelligence, but rather a complex master imitator. It has some flexibility in piecing a scenario together but also many blind spots. OpenAI trained the agent (and its constituent components) using examples of computer usage and tool usage; whatever falls outside of the examples absorbed from training data will likely still prove difficult to accomplish.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For example, the ChatGPT Agent System Card shows that the agent can fail at complex tasks that require chaining together many steps in a novel way. In a "Cyber Range" evaluation, the agent was tasked with conducting a full-scale operation in a simulated network designed to mimic a small online retailer. When left to solve the problem on its own, the agent was unable to complete the task. While it could successfully perform initial research steps, like identifying servers on the network, it struggled to proceed beyond that and was unable to chain together the necessary exploits to reach the final goal. Even when provided with hints, the agent still failed (which in this case might be good, since it couldn't perform an automated hack), this demonstrates a clear limitation in its ability to solve complex problems that fall outside of its familiar training examples.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2106631 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="526" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/chart.png" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      OpenAI writes, "The SpreadsheetBench authors used a Windows environment using Microsoft Excel to evaluate spreadsheets. We used an OSX environment and LibreOffice, which may result in small grading differences. For example, the authors found an Overall Hard restriction of 15.02% for GPT‑4o, and we obtained 13.38%. We used the complete 912-question benchmark."

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          OpenAi

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Even so, OpenAI reports that ChatGPT agent achieves state-of-the-art performance on its own benchmark measurements, which should always be taken with a grain of salt until verified by impartial third parties. On Humanity's Last Exam, which tests AI performance on expert-level questions, the model scored 41.6 percent accuracy (compare that to OpenAI o3's 24.9 percent using tools). On FrontierMath, one of the most difficult math benchmarks yet devised, it reaches 27.4 percent accuracy with tool access (o3 with Python scored 19.3 percent).&lt;/p&gt;
&lt;p&gt;The company also claims the system outperforms humans on certain data science tasks like data analysis and modeling (such as creating forecasts or predictive models). On DSBench, a benchmark that seeks to measure that capability, ChatGPT agent scored 89.9 percent on data analysis tasks compared to 64.1 percent for humans, and 85.5 percent on data modeling tasks versus 65.0 percent for humans. The agent also scored 68.9 percent on OpenAI's BrowseComp for finding hard-to-locate web information and 45.5 percent on SpreadsheetBench for editing spreadsheets, which is higher than OpenAI's other AI models.&lt;/p&gt;
&lt;p&gt;It's worth noting that even though OpenAI says Agent can craft PowerPoint slide decks for users, the company acknowledged that slideshow generation is still in beta and outputs can feel "rudimentary in formatting and polish."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Safety and privacy&lt;/h2&gt;
&lt;p&gt;OpenAI admits that the launch introduces new security considerations. Because ChatGPT Agent can take direct actions on websites and access user data through connected services, it is vulnerable to prompt injection attacks—attempts by hackers to manipulate the AI's behavior through instructions that misdirect the AI model (in this case, likely through hidden instructions on web pages). For example, a site might have an invisible form field that instructs the AI model to enter your credit card information without your knowledge.&lt;/p&gt;
&lt;p&gt;OpenAI says it has implemented safeguards against prompt injections by training the model to identify and "resist" these attacks while requiring user confirmation for consequential or suspicious-looking actions. The model is also trained to actively refuse high-risk tasks such as bank transfers. During a livestream on Thursday, one OpenAI engineer characterized Agent as a system of AI models working together, some of which constantly monitor the other models' behavior for suspicious activity. Those overseers can hypothetically halt a process if they spot a potentially dangerous scenario.&lt;/p&gt;
&lt;p&gt;As for privacy, since Agent runs in a virtual machine on OpenAI's servers, users won't need to worry about the bot having access to local private data stored on their device. But what you feed into ChatGPT Agent could still be shared on the web during its operations. Beyond that, OpenAI says privacy controls for the new agent allow users to delete all browsing data and log out of active sessions with one click. When users take control of the browser in "takeover mode," OpenAI states it does not collect or store data entered during these sessions, including passwords.&lt;/p&gt;
&lt;p&gt;Agent launches today for ChatGPT Pro users, who receive 400 messages per month. Plus and Team subscribers will gain access over the next few days with 40 monthly messages. Enterprise and Education users will receive access in the coming weeks. The feature is not yet available in the European Economic Area and Switzerland.&lt;/p&gt;
&lt;p&gt;We've not yet used ChatGPT Agent ourselves, but we may follow up with our experiences at a later date.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/07/chatgpts-new-ai-agent-can-browse-the-web-and-create-powerpoint-slideshows/</guid><pubDate>Thu, 17 Jul 2025 20:41:52 +0000</pubDate></item><item><title>Anthropic tightens usage limits for Claude Code – without telling users (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2159671948.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Since Monday morning, Claude Code users have been hit with unexpectedly restrictive usage limits. The problems, many of which have been aired on Claude Code’s GitHub page, seem to be concentrated among heavy users of the service, many of whom are on the $200-a-month Max plan.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users are only told “Claude usage limit reached,” and given a time (typically within a matter of hours) when the limit will reset. But with no explicit announcement of a change in limits, many users have concluded that their subscription has been downgraded or that their usage is being inaccurately tracked.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Your tracking of usage limits has changed and is no longer accurate,” one user complained. “There is no way in the 30 minutes of a few requests I have hit the 900 messages.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When reached for comment, an Anthropic representative confirmed the issues but declined to elaborate further. “We’re aware that some Claude Code users are experiencing slower response times,” the representative said, “and we’re working to resolve these issues.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The change has been alarming for users, who received no advance notice of the changes and no guidance on what to expect going forward. One user, who asked not to be identified, said it has been impossible to advance his project since the usage limits came into effect. “It just stopped the ability to make progress,” the user told TechCrunch. “I tried Gemini and Kimi, but there’s really nothing else that’s competitive with the capability set of Claude Code right now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These problems have emerged alongside broader issues within Anthropic’s network. Many API users reported overload errors during the same period, and the company’s status page shows six separate issues during the past four days. Notably, the network still shows 100% uptime for the week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While loading errors are commonplace, Anthropic’s new approach to usage limits has caused significant confusion among users, many of whom were unaware they were subject to usage limits. Part of the confusion comes from Anthropic’s pricing system, which sets tiered limits without ever guaranteeing a set level of access. The most expensive Max plan, priced at $200 a month, promises usage limits 20 times higher than a Pro subscription. The Pro plan, in turn, offers limits five times higher than the free plan. But Anthropic says the free user limit “will vary by demand” and does not set an absolute value. The result leaves users unable to plan around usage limits, since they have no clear idea of when their service will be restricted.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The $200 Max plan has been particularly popular among heavy users of the service, with some viewing the plan as unsustainable for Anthropic in the long term. The user we spoke to said the plan often allows him to make over $1,000 worth of calls (measured in API pricing) in a single day. As a result, he wasn’t surprised usage limits were becoming more restrictive — but hoped the company would communicate the changes more clearly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Just be transparent,” he said. “The lack of communication just causes people to lose confidence in them.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-2159671948.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Since Monday morning, Claude Code users have been hit with unexpectedly restrictive usage limits. The problems, many of which have been aired on Claude Code’s GitHub page, seem to be concentrated among heavy users of the service, many of whom are on the $200-a-month Max plan.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users are only told “Claude usage limit reached,” and given a time (typically within a matter of hours) when the limit will reset. But with no explicit announcement of a change in limits, many users have concluded that their subscription has been downgraded or that their usage is being inaccurately tracked.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Your tracking of usage limits has changed and is no longer accurate,” one user complained. “There is no way in the 30 minutes of a few requests I have hit the 900 messages.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When reached for comment, an Anthropic representative confirmed the issues but declined to elaborate further. “We’re aware that some Claude Code users are experiencing slower response times,” the representative said, “and we’re working to resolve these issues.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The change has been alarming for users, who received no advance notice of the changes and no guidance on what to expect going forward. One user, who asked not to be identified, said it has been impossible to advance his project since the usage limits came into effect. “It just stopped the ability to make progress,” the user told TechCrunch. “I tried Gemini and Kimi, but there’s really nothing else that’s competitive with the capability set of Claude Code right now.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These problems have emerged alongside broader issues within Anthropic’s network. Many API users reported overload errors during the same period, and the company’s status page shows six separate issues during the past four days. Notably, the network still shows 100% uptime for the week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While loading errors are commonplace, Anthropic’s new approach to usage limits has caused significant confusion among users, many of whom were unaware they were subject to usage limits. Part of the confusion comes from Anthropic’s pricing system, which sets tiered limits without ever guaranteeing a set level of access. The most expensive Max plan, priced at $200 a month, promises usage limits 20 times higher than a Pro subscription. The Pro plan, in turn, offers limits five times higher than the free plan. But Anthropic says the free user limit “will vary by demand” and does not set an absolute value. The result leaves users unable to plan around usage limits, since they have no clear idea of when their service will be restricted.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The $200 Max plan has been particularly popular among heavy users of the service, with some viewing the plan as unsustainable for Anthropic in the long term. The user we spoke to said the plan often allows him to make over $1,000 worth of calls (measured in API pricing) in a single day. As a result, he wasn’t surprised usage limits were becoming more restrictive — but hoped the company would communicate the changes more clearly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Just be transparent,” he said. “The lack of communication just causes people to lose confidence in them.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/17/anthropic-tightens-usage-limits-for-claude-code-without-telling-users/</guid><pubDate>Thu, 17 Jul 2025 21:04:34 +0000</pubDate></item><item><title>Mistral’s Le Chat adds deep research agent and voice mode to challenge OpenAI’s enterprise dominance (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/mistrals-le-chat-adds-deep-research-agent-and-voice-mode-to-challenge-openais-enterprise-dominance/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Since OpenAI introduced Deep Research, an AI agent that can &lt;span&gt;conduct research&amp;nbsp;for users and generate a comprehensive report, many other companies have released th&lt;/span&gt;eir own versions of this capability, all named Deep Research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Deep Research, as a feature and product, can be accessed through various platforms, including Google’s Gemini, AlphaSense, You.com, DeepSeek, Grok 3 and many others.&amp;nbsp; Now, French company Mistral joins the fray with the launch of deep research capabilities into its Le Chat, among other updates to the platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a blog post, the company said Deep Research and other new features will make Le Chat “even more capable, more intuitive and more fun.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Le Chat users can open research mode and ask it something. The chatbot then asks questions to clarify some information and then begins gathering sources. It will put together “a structured, reference-backed report that’s easy to follow.”&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Mistral said its research is powered by a Deep Research agent, which it designed to be “genuinely helpful” and feels like working with an organized research partner.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdv6g4jFWAG9ncuRnmFB3H84SWHPdZYmrgP-f6OwavxUNRFCoxjcL25k5wGMvQ9w_jUuqEdAXHZTGi81IHDB0v4mh6h-Sc-JrZXkKrGUrul9qcE3S6rnQuZWZOPIR6z_g19hMGeAw?key=BGKUARn38KyygEUw77Uhpg" /&gt;&lt;/figure&gt;



&lt;p&gt;Deep Research has been called “the first mass market AI that could displace jobs,” especially since it can put out reports faster than human analysts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Mistral also updated “thinking mode,” where Le Chat users can access the company’s chain-of-thought model Magistral, to read and respond in different languages. It can also code-switch mid-sentence.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-prompt-based-image-editing-and-other-features"&gt;Prompt-based image editing and other features&lt;/h2&gt;



&lt;p&gt;For people creating images on the chat app, they can ask the chatbot to edit parts of the photo with just a prompt. Users can say something like “generate a drawing of a cat,” then ask Le Chat to “place him in Istanbul,” and it will do just that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It’s ideal for making consistent edits across a series, keeping people, objects, and design elements recognizable from one image to the next,” Mistral said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Thanks to the recently released speech recognition model, Voxtral, Le Chat can now support voice mode, where users can chat out loud with the platform. The company said this mode is best for low-latency speech recognition and keeping up with someone’s conversational pace.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Le Chat’s new Projects feature allows users to organize related conversations and topics into groups. The projects will utilize their own libraries — which can include uploaded files — and retain tools and preferred settings. This is similar to Google’s NotebookLM.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-playing-catch-up"&gt;Playing catch-up&lt;/h2&gt;



&lt;p&gt;Many of the new features on Le Chat may seem familiar. It’s normal for other chat platforms to introduce similar features, especially as people begin to expect these capabilities when using chat systems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For example, both Gemini and ChatGPT allow users to edit generated photos using a prompt. Sometimes, the chatbots misunderstand and redo the entire image. However, I recently generated and edited a photo with ChatGPT, and the chatbot removed exactly what I wanted it to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Voice mode has been available on ChatGPT since September 2024, though ChatGPT always included a “Read Aloud” feature. Project Astra from Google took voice mode to a new level, demonstrating in a demo that users can point out something in the physical world to Gemini and ask it to describe it out loud.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Mistral has the advantage of being Europe-based and can bring features directly to the European market. Companies like OpenAI often struggle to bring certain services, such as ChatGPT’s Advanced Voice Mode, to Europe due to data regulations and some provisions of the European Union’s AI Act.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Despite this, users seemed excited that Mistral brought many new powerful features to Le Chat, with some early users seeing strong performance from Mistral’s Deep Research.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Here is the first page of the 8 page state of the art written by Le Chat of @MistralAI in its new deep research mode. Just 5 minutes with a great interface for this task. I think that is a pretty good job. pic.twitter.com/jeUAy1U6Yo&lt;/p&gt;— Eduardo C. Garrido-Merchan (@vedugarmer) July 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Time to rename Le Chat to L’Assistant&lt;/p&gt;— Mev-Rael (@Mevrael) July 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;@realJohnSpyker I am no longer using grok. i am switching to Le Chat by Mistral AI AI assistant for life and work. Find answers, generate images and read the news.&lt;/p&gt;&lt;p&gt;Le Chat combines the power of advanced AI with extensive information sourced from the web&lt;/p&gt;— Tsunami Papi #WineDad (@SuriTsunami) July 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Since OpenAI introduced Deep Research, an AI agent that can &lt;span&gt;conduct research&amp;nbsp;for users and generate a comprehensive report, many other companies have released th&lt;/span&gt;eir own versions of this capability, all named Deep Research.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Deep Research, as a feature and product, can be accessed through various platforms, including Google’s Gemini, AlphaSense, You.com, DeepSeek, Grok 3 and many others.&amp;nbsp; Now, French company Mistral joins the fray with the launch of deep research capabilities into its Le Chat, among other updates to the platform.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In a blog post, the company said Deep Research and other new features will make Le Chat “even more capable, more intuitive and more fun.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-4-3 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;



&lt;p&gt;Le Chat users can open research mode and ask it something. The chatbot then asks questions to clarify some information and then begins gathering sources. It will put together “a structured, reference-backed report that’s easy to follow.”&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Mistral said its research is powered by a Deep Research agent, which it designed to be “genuinely helpful” and feels like working with an organized research partner.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdv6g4jFWAG9ncuRnmFB3H84SWHPdZYmrgP-f6OwavxUNRFCoxjcL25k5wGMvQ9w_jUuqEdAXHZTGi81IHDB0v4mh6h-Sc-JrZXkKrGUrul9qcE3S6rnQuZWZOPIR6z_g19hMGeAw?key=BGKUARn38KyygEUw77Uhpg" /&gt;&lt;/figure&gt;



&lt;p&gt;Deep Research has been called “the first mass market AI that could displace jobs,” especially since it can put out reports faster than human analysts.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Mistral also updated “thinking mode,” where Le Chat users can access the company’s chain-of-thought model Magistral, to read and respond in different languages. It can also code-switch mid-sentence.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-prompt-based-image-editing-and-other-features"&gt;Prompt-based image editing and other features&lt;/h2&gt;



&lt;p&gt;For people creating images on the chat app, they can ask the chatbot to edit parts of the photo with just a prompt. Users can say something like “generate a drawing of a cat,” then ask Le Chat to “place him in Istanbul,” and it will do just that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“It’s ideal for making consistent edits across a series, keeping people, objects, and design elements recognizable from one image to the next,” Mistral said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Thanks to the recently released speech recognition model, Voxtral, Le Chat can now support voice mode, where users can chat out loud with the platform. The company said this mode is best for low-latency speech recognition and keeping up with someone’s conversational pace.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Le Chat’s new Projects feature allows users to organize related conversations and topics into groups. The projects will utilize their own libraries — which can include uploaded files — and retain tools and preferred settings. This is similar to Google’s NotebookLM.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-playing-catch-up"&gt;Playing catch-up&lt;/h2&gt;



&lt;p&gt;Many of the new features on Le Chat may seem familiar. It’s normal for other chat platforms to introduce similar features, especially as people begin to expect these capabilities when using chat systems.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;For example, both Gemini and ChatGPT allow users to edit generated photos using a prompt. Sometimes, the chatbots misunderstand and redo the entire image. However, I recently generated and edited a photo with ChatGPT, and the chatbot removed exactly what I wanted it to.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Voice mode has been available on ChatGPT since September 2024, though ChatGPT always included a “Read Aloud” feature. Project Astra from Google took voice mode to a new level, demonstrating in a demo that users can point out something in the physical world to Gemini and ask it to describe it out loud.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;However, Mistral has the advantage of being Europe-based and can bring features directly to the European market. Companies like OpenAI often struggle to bring certain services, such as ChatGPT’s Advanced Voice Mode, to Europe due to data regulations and some provisions of the European Union’s AI Act.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Despite this, users seemed excited that Mistral brought many new powerful features to Le Chat, with some early users seeing strong performance from Mistral’s Deep Research.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Here is the first page of the 8 page state of the art written by Le Chat of @MistralAI in its new deep research mode. Just 5 minutes with a great interface for this task. I think that is a pretty good job. pic.twitter.com/jeUAy1U6Yo&lt;/p&gt;— Eduardo C. Garrido-Merchan (@vedugarmer) July 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Time to rename Le Chat to L’Assistant&lt;/p&gt;— Mev-Rael (@Mevrael) July 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;@realJohnSpyker I am no longer using grok. i am switching to Le Chat by Mistral AI AI assistant for life and work. Find answers, generate images and read the news.&lt;/p&gt;&lt;p&gt;Le Chat combines the power of advanced AI with extensive information sourced from the web&lt;/p&gt;— Tsunami Papi #WineDad (@SuriTsunami) July 17, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/mistrals-le-chat-adds-deep-research-agent-and-voice-mode-to-challenge-openais-enterprise-dominance/</guid><pubDate>Thu, 17 Jul 2025 22:05:26 +0000</pubDate></item><item><title>[NEW] Model predicts long-term effects of nuclear waste on underground disposal systems (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/model-predicts-long-term-effects-nuclear-waste-underground-disposal-systems-0718</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT-Waste-Storage-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;As countries across the world experience a resurgence in nuclear energy projects, the questions of where and how to dispose of nuclear waste remain as politically fraught as ever. The United States, for instance, has indefinitely stalled its only long-term underground nuclear waste repository. Scientists are using both modeling and experimental methods to study the effects of underground nuclear waste disposal and ultimately, they hope, build public trust in the decision-making process.&lt;/p&gt;&lt;p&gt;New research from scientists at MIT, Lawrence Berkeley National Lab, and the University of Orléans makes progress in that direction. The study shows that simulations of underground nuclear waste interactions, generated by new, high-performance-computing software, aligned well with experimental results from a research facility in Switzerland.&lt;/p&gt;&lt;p&gt;The study, which was co-authored by MIT PhD student Dauren Sarsenbayev and Assistant Professor Haruko Wainwright, along with&amp;nbsp;Christophe Tournassat and&amp;nbsp;Carl Steefel, appears in the journal &lt;em&gt;PNAS&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;“These powerful new computational tools, coupled with real-world experiments like those at the Mont Terri research site in Switzerland, help us understand how radionuclides will migrate in coupled underground systems,” says Sarsenbayev, who is first author of the new study.&lt;/p&gt;&lt;p&gt;The authors hope the research will improve confidence among policymakers and the public in the long-term safety of underground nuclear waste disposal.&lt;/p&gt;&lt;p&gt;“This research — coupling both computation and experiments — is important to improve our confidence in waste disposal safety assessments,” says Wainwright. “With nuclear energy re-emerging as a key source for tackling climate change and ensuring energy security, it is critical to validate disposal pathways.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Comparing simulations with experiments&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Disposing of nuclear waste in deep underground geological formations is currently considered the safest long-term solution for managing high-level radioactive waste. As such, much effort has been put into studying the migration behaviors of radionuclides from nuclear waste within various natural and engineered geological materials.&lt;/p&gt;&lt;p&gt;Since its founding in 1996, the Mont Terri research site in northern Switzerland has served as an important test bed for an international consortium of researchers interested in studying materials like Opalinus clay — a thick, water-tight claystone abundant in the tunneled areas of the mountain.&lt;/p&gt;&lt;p&gt;“It is widely regarded as one of the most valuable real-world experiment sites because it provides us with decades of datasets around the interactions of cement and clay, and those are the key materials proposed to be used by countries across the world for engineered barrier systems and geological repositories for nuclear waste,” explains Sarsenbayev.&lt;/p&gt;&lt;p&gt;For their study, Sarsenbayev and Wainwright collaborated with co-authors Tournassat and Steefel, who have developed high-performance computing software to improve modeling of interactions between the nuclear waste and both engineered and natural materials.&lt;/p&gt;&lt;p&gt;To date, several challenges have limited scientists’ understanding of how nuclear waste reacts with cement-clay barriers. For one thing, the barriers are made up of irregularly mixed materials deep underground. Additionally, the existing class of models commonly used to simulate radionuclide interactions with cement-clay do not take into account electrostatic effects associated with the negatively charged clay minerals in the barriers.&lt;/p&gt;&lt;p&gt;Tournassat and Steefel’s new software accounts for electrostatic effects, making it the only one that can simulate those interactions in three-dimensional space. The software, called CrunchODiTi, was developed from established software known as CrunchFlow and was most recently updated this year. It is designed to be run on many high-performance computers at once in parallel.&lt;/p&gt;&lt;p&gt;For the study, the researchers looked at a 13-year-old experiment, with an initial focus on cement-clay rock interactions. Within the last several years, a mix of both negatively and positively charged ions were added to the borehole located near the center of the cement emplaced in the formation. The researchers focused on a 1-centimeter-thick zone between the radionuclides and cement-clay referred to as the “skin.” They compared their experimental results to the software simulation, finding the two datasets aligned.&lt;/p&gt;&lt;p&gt;“The results are quite significant because previously, these models wouldn’t fit field data very well,” Sarsenbayev says. “It’s interesting how fine-scale phenomena at the ‘skin’ between cement and clay, the physical and chemical properties of which changes over time, could be used to reconcile the experimental and simulation data.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The experimental results showed the model successfully accounted for electrostatic effects associated with the clay-rich formation and the interaction between materials in Mont Terri over time.&lt;/p&gt;&lt;p&gt;“This is all driven by decades of work to understand what happens at these interfaces,” Sarsenbayev says. “It’s been hypothesized that there is mineral precipitation and porosity clogging at this interface, and our results strongly suggest that.”&lt;/p&gt;&lt;p&gt;“This application requires millions of degrees of freedom because these multibarrier systems require high resolution and a lot of computational power,” Sarsenbayev says. “This software is really ideal for the Mont Terri experiment.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Assessing waste disposal plans&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The new model could now replace older models that have been used to conduct safety and performance assessments of underground geological repositories.&lt;/p&gt;&lt;p&gt;“If the U.S. eventually decides to dispose nuclear waste in a geological repository, then these models could dictate the most appropriate materials to use,” Sarsenbayev says. “For instance, right now clay is considered an appropriate storage material, but salt formations are another potential medium that could be used. These models allow us to see the fate of radionuclides over millennia. We can use them to understand interactions at timespans that vary from months to years to many millions of years.”&lt;/p&gt;&lt;p&gt;Sarsenbayev says the model is reasonably accessible to other researchers and that future efforts may focus on the use of machine learning to develop less computationally expensive surrogate models.&lt;/p&gt;&lt;p&gt;Further data from the experiment will be available later this month. The team plans to compare those data to additional simulations.&lt;/p&gt;&lt;p&gt;“Our collaborators will basically get this block of cement and clay, and they’ll be able to run experiments to determine the exact thickness of the skin along with all of the minerals and processes present at this interface,”&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Sarsenbayev says. “It’s a huge project and it takes time, but we wanted to share initial data and this software as soon as we could.”&lt;/p&gt;&lt;p&gt;For now, the researchers hope their study leads to a long-term solution for storing nuclear waste that policymakers and the public can support.&lt;/p&gt;&lt;p&gt;“This is an interdisciplinary study that includes real world experiments showing we’re able to predict radionuclides’ fate in the subsurface,” Sarsenbayev says. “The motto of MIT’s Department of Nuclear Science and Engineering is ‘Science. Systems. Society.’ I think this merges all three domains.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT-Waste-Storage-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;As countries across the world experience a resurgence in nuclear energy projects, the questions of where and how to dispose of nuclear waste remain as politically fraught as ever. The United States, for instance, has indefinitely stalled its only long-term underground nuclear waste repository. Scientists are using both modeling and experimental methods to study the effects of underground nuclear waste disposal and ultimately, they hope, build public trust in the decision-making process.&lt;/p&gt;&lt;p&gt;New research from scientists at MIT, Lawrence Berkeley National Lab, and the University of Orléans makes progress in that direction. The study shows that simulations of underground nuclear waste interactions, generated by new, high-performance-computing software, aligned well with experimental results from a research facility in Switzerland.&lt;/p&gt;&lt;p&gt;The study, which was co-authored by MIT PhD student Dauren Sarsenbayev and Assistant Professor Haruko Wainwright, along with&amp;nbsp;Christophe Tournassat and&amp;nbsp;Carl Steefel, appears in the journal &lt;em&gt;PNAS&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;“These powerful new computational tools, coupled with real-world experiments like those at the Mont Terri research site in Switzerland, help us understand how radionuclides will migrate in coupled underground systems,” says Sarsenbayev, who is first author of the new study.&lt;/p&gt;&lt;p&gt;The authors hope the research will improve confidence among policymakers and the public in the long-term safety of underground nuclear waste disposal.&lt;/p&gt;&lt;p&gt;“This research — coupling both computation and experiments — is important to improve our confidence in waste disposal safety assessments,” says Wainwright. “With nuclear energy re-emerging as a key source for tackling climate change and ensuring energy security, it is critical to validate disposal pathways.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Comparing simulations with experiments&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Disposing of nuclear waste in deep underground geological formations is currently considered the safest long-term solution for managing high-level radioactive waste. As such, much effort has been put into studying the migration behaviors of radionuclides from nuclear waste within various natural and engineered geological materials.&lt;/p&gt;&lt;p&gt;Since its founding in 1996, the Mont Terri research site in northern Switzerland has served as an important test bed for an international consortium of researchers interested in studying materials like Opalinus clay — a thick, water-tight claystone abundant in the tunneled areas of the mountain.&lt;/p&gt;&lt;p&gt;“It is widely regarded as one of the most valuable real-world experiment sites because it provides us with decades of datasets around the interactions of cement and clay, and those are the key materials proposed to be used by countries across the world for engineered barrier systems and geological repositories for nuclear waste,” explains Sarsenbayev.&lt;/p&gt;&lt;p&gt;For their study, Sarsenbayev and Wainwright collaborated with co-authors Tournassat and Steefel, who have developed high-performance computing software to improve modeling of interactions between the nuclear waste and both engineered and natural materials.&lt;/p&gt;&lt;p&gt;To date, several challenges have limited scientists’ understanding of how nuclear waste reacts with cement-clay barriers. For one thing, the barriers are made up of irregularly mixed materials deep underground. Additionally, the existing class of models commonly used to simulate radionuclide interactions with cement-clay do not take into account electrostatic effects associated with the negatively charged clay minerals in the barriers.&lt;/p&gt;&lt;p&gt;Tournassat and Steefel’s new software accounts for electrostatic effects, making it the only one that can simulate those interactions in three-dimensional space. The software, called CrunchODiTi, was developed from established software known as CrunchFlow and was most recently updated this year. It is designed to be run on many high-performance computers at once in parallel.&lt;/p&gt;&lt;p&gt;For the study, the researchers looked at a 13-year-old experiment, with an initial focus on cement-clay rock interactions. Within the last several years, a mix of both negatively and positively charged ions were added to the borehole located near the center of the cement emplaced in the formation. The researchers focused on a 1-centimeter-thick zone between the radionuclides and cement-clay referred to as the “skin.” They compared their experimental results to the software simulation, finding the two datasets aligned.&lt;/p&gt;&lt;p&gt;“The results are quite significant because previously, these models wouldn’t fit field data very well,” Sarsenbayev says. “It’s interesting how fine-scale phenomena at the ‘skin’ between cement and clay, the physical and chemical properties of which changes over time, could be used to reconcile the experimental and simulation data.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The experimental results showed the model successfully accounted for electrostatic effects associated with the clay-rich formation and the interaction between materials in Mont Terri over time.&lt;/p&gt;&lt;p&gt;“This is all driven by decades of work to understand what happens at these interfaces,” Sarsenbayev says. “It’s been hypothesized that there is mineral precipitation and porosity clogging at this interface, and our results strongly suggest that.”&lt;/p&gt;&lt;p&gt;“This application requires millions of degrees of freedom because these multibarrier systems require high resolution and a lot of computational power,” Sarsenbayev says. “This software is really ideal for the Mont Terri experiment.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Assessing waste disposal plans&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The new model could now replace older models that have been used to conduct safety and performance assessments of underground geological repositories.&lt;/p&gt;&lt;p&gt;“If the U.S. eventually decides to dispose nuclear waste in a geological repository, then these models could dictate the most appropriate materials to use,” Sarsenbayev says. “For instance, right now clay is considered an appropriate storage material, but salt formations are another potential medium that could be used. These models allow us to see the fate of radionuclides over millennia. We can use them to understand interactions at timespans that vary from months to years to many millions of years.”&lt;/p&gt;&lt;p&gt;Sarsenbayev says the model is reasonably accessible to other researchers and that future efforts may focus on the use of machine learning to develop less computationally expensive surrogate models.&lt;/p&gt;&lt;p&gt;Further data from the experiment will be available later this month. The team plans to compare those data to additional simulations.&lt;/p&gt;&lt;p&gt;“Our collaborators will basically get this block of cement and clay, and they’ll be able to run experiments to determine the exact thickness of the skin along with all of the minerals and processes present at this interface,”&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;Sarsenbayev says. “It’s a huge project and it takes time, but we wanted to share initial data and this software as soon as we could.”&lt;/p&gt;&lt;p&gt;For now, the researchers hope their study leads to a long-term solution for storing nuclear waste that policymakers and the public can support.&lt;/p&gt;&lt;p&gt;“This is an interdisciplinary study that includes real world experiments showing we’re able to predict radionuclides’ fate in the subsurface,” Sarsenbayev says. “The motto of MIT’s Department of Nuclear Science and Engineering is ‘Science. Systems. Society.’ I think this merges all three domains.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/model-predicts-long-term-effects-nuclear-waste-underground-disposal-systems-0718</guid><pubDate>Fri, 18 Jul 2025 04:00:00 +0000</pubDate></item><item><title>[NEW] Perplexity sees India as a shortcut in its race against OpenAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/17/perplexity-sees-india-as-a-shortcut-in-its-race-against-openai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While OpenAI has cemented its lead in the U.S., Perplexity is taking a different route — quietly expanding into India to compete in the next phase of AI adoption. The search-focused AI startup is rapidly adding millions of users in the world’s second-largest internet and smartphone market, positioning itself for mass-market scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This week, Perplexity partnered with Bharti Airtel, India’s second-largest telecom operator after Reliance Jio, to offer a free 12-month Perplexity Pro subscription — normally worth $200 — to all 360 million Airtel subscribers. Airtel confirmed to TechCrunch that the deal is exclusive, meaning no other telco in the country can offer Perplexity’s services, including free access, to their subscribers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Airtel partnership is one of Perplexity’s most significant moves yet in a global expansion strategy that includes partnerships with more than 25 telcos globally, including those recently announced with SoftBank in Japan and SK Telecom in South Korea. It comes down to volume. India, the world’s most populous country, brings a mass market that the San Francisco-based startup will not find in other geographies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity is already gaining major traction in the country. In Q2, Perplexity’s downloads in India surged 600% year-over-year to 2.8 million, according to Sensor Tower data shared exclusively with TechCrunch. In comparison, OpenAI’s ChatGPT saw a 587% increase, reaching 46.7 million downloads in the same period.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The growth trend extended to active users as well: Perplexity’s monthly active users (MAUs) in India increased by 640% year-over-year in Q2, while ChatGPT’s MAUs grew by 350%. India was also the largest market by MAUs for Perplexity in the last quarter, per Sensor Tower. However, ChatGPT maintained a significant lead in absolute numbers, with 19.8 million MAUs versus 3.7 million for Perplexity.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3029031" height="1093" src="https://techcrunch.com/wp-content/uploads/2025/07/perplexity-chatgpt-india.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Building on earlier partnerships, Perplexity has been working to leverage India’s user base to leapfrog Western markets, where OpenAI dominates paid subscribers. Earlier this year, Perplexity partnered with the Indian fintech giant Paytm to offer access to its AI-powered search through the Paytm app, which has over 500 million downloads and is among the top-three apps on the Indian government’s Unified Payment Interface network, processing over 1.2 billion transactions worth over ₹1,34,000 crores (approximately $15.6 billion).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity CEO Aravind Srinivas has also taken direct steps to expand in India. In January, he announced plans to hire an Indian executive in the country, which he later put on hold after receiving an “overwhelming” response. He further announced a $1 million investment and a commitment of five hours a week of his time to a group building AI in India.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3029063" height="1093" src="https://techcrunch.com/wp-content/uploads/2025/07/perplexity-india-global_37aa21.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has also internally discussed offering its AI search engine to Indian students to grow its reach, sources told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One reason Perplexity views India as a key growth market is the relatively limited number of local AI startups, particularly in the AI search space. At the same time, the country has a large and active base of tech-savvy users — a fact that has even prompted Perplexity’s archrival, Google, to launch AI-powered search features like AI Mode and AI Overviews in India ahead of many other markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Monetizing that large user base remains a challenge. Perplexity still lags far behind ChatGPT globally in terms of revenue, even as both offer the same $20-per-month starting price. In Q2, ChatGPT’s in-app purchase revenue worldwide surged 731% year-over-year to $773 million, while Perplexity saw a 300% increase, reaching $8 million, per Sensor Tower.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3029032" height="1092" src="https://techcrunch.com/wp-content/uploads/2025/07/perplexity-chatgpt-iap.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The revenue challenge is particularly acute in India, where consumers are notoriously price-sensitive. Still, there are promising signs. ChatGPT saw an 800% year-over-year increase in in-app purchases to $9 million in the country in Q2. Perplexity has not generated any notable in-app revenue from India, but the startup has room to expand its paid subscriber base through India. Deals like the one with Airtel could help Perplexity effectively increase its subscriber base, at least in the short term.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Strategic partnerships in markets like India could help Perplexity catch the eye of investors who value user growth and geographic diversification. But to turn that attention into long-term backing, the startup will need to show that it can convert its expanding user base into revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Srinivas did not respond to requests for comment.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While OpenAI has cemented its lead in the U.S., Perplexity is taking a different route — quietly expanding into India to compete in the next phase of AI adoption. The search-focused AI startup is rapidly adding millions of users in the world’s second-largest internet and smartphone market, positioning itself for mass-market scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This week, Perplexity partnered with Bharti Airtel, India’s second-largest telecom operator after Reliance Jio, to offer a free 12-month Perplexity Pro subscription — normally worth $200 — to all 360 million Airtel subscribers. Airtel confirmed to TechCrunch that the deal is exclusive, meaning no other telco in the country can offer Perplexity’s services, including free access, to their subscribers.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Airtel partnership is one of Perplexity’s most significant moves yet in a global expansion strategy that includes partnerships with more than 25 telcos globally, including those recently announced with SoftBank in Japan and SK Telecom in South Korea. It comes down to volume. India, the world’s most populous country, brings a mass market that the San Francisco-based startup will not find in other geographies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity is already gaining major traction in the country. In Q2, Perplexity’s downloads in India surged 600% year-over-year to 2.8 million, according to Sensor Tower data shared exclusively with TechCrunch. In comparison, OpenAI’s ChatGPT saw a 587% increase, reaching 46.7 million downloads in the same period.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The growth trend extended to active users as well: Perplexity’s monthly active users (MAUs) in India increased by 640% year-over-year in Q2, while ChatGPT’s MAUs grew by 350%. India was also the largest market by MAUs for Perplexity in the last quarter, per Sensor Tower. However, ChatGPT maintained a significant lead in absolute numbers, with 19.8 million MAUs versus 3.7 million for Perplexity.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3029031" height="1093" src="https://techcrunch.com/wp-content/uploads/2025/07/perplexity-chatgpt-india.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Building on earlier partnerships, Perplexity has been working to leverage India’s user base to leapfrog Western markets, where OpenAI dominates paid subscribers. Earlier this year, Perplexity partnered with the Indian fintech giant Paytm to offer access to its AI-powered search through the Paytm app, which has over 500 million downloads and is among the top-three apps on the Indian government’s Unified Payment Interface network, processing over 1.2 billion transactions worth over ₹1,34,000 crores (approximately $15.6 billion).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Perplexity CEO Aravind Srinivas has also taken direct steps to expand in India. In January, he announced plans to hire an Indian executive in the country, which he later put on hold after receiving an “overwhelming” response. He further announced a $1 million investment and a commitment of five hours a week of his time to a group building AI in India.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3029063" height="1093" src="https://techcrunch.com/wp-content/uploads/2025/07/perplexity-india-global_37aa21.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The startup has also internally discussed offering its AI search engine to Indian students to grow its reach, sources told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One reason Perplexity views India as a key growth market is the relatively limited number of local AI startups, particularly in the AI search space. At the same time, the country has a large and active base of tech-savvy users — a fact that has even prompted Perplexity’s archrival, Google, to launch AI-powered search features like AI Mode and AI Overviews in India ahead of many other markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Monetizing that large user base remains a challenge. Perplexity still lags far behind ChatGPT globally in terms of revenue, even as both offer the same $20-per-month starting price. In Q2, ChatGPT’s in-app purchase revenue worldwide surged 731% year-over-year to $773 million, while Perplexity saw a 300% increase, reaching $8 million, per Sensor Tower.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3029032" height="1092" src="https://techcrunch.com/wp-content/uploads/2025/07/perplexity-chatgpt-iap.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Jagmeet Singh / TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The revenue challenge is particularly acute in India, where consumers are notoriously price-sensitive. Still, there are promising signs. ChatGPT saw an 800% year-over-year increase in in-app purchases to $9 million in the country in Q2. Perplexity has not generated any notable in-app revenue from India, but the startup has room to expand its paid subscriber base through India. Deals like the one with Airtel could help Perplexity effectively increase its subscriber base, at least in the short term.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Strategic partnerships in markets like India could help Perplexity catch the eye of investors who value user growth and geographic diversification. But to turn that attention into long-term backing, the startup will need to show that it can convert its expanding user base into revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Srinivas did not respond to requests for comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/17/perplexity-sees-india-as-a-shortcut-in-its-race-against-openai/</guid><pubDate>Fri, 18 Jul 2025 04:29:34 +0000</pubDate></item></channel></rss>