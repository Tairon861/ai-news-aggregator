<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 23 Jan 2026 12:53:48 +0000</lastBuildDate><item><title>Former Sequoia partner’s new startup uses AI to negotiate your calendar for you (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/22/former-sequoia-partners-new-startup-uses-ai-to-negotiate-your-calendar-for-you/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Copy-of-SequoiaARCUS2023-FallWeek1NYC_0919-318.jpg.png?resize=1200,694" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Kais Khimji has spent most of his professional career as a venture investor, including six years as a partner at the prominent VC firm Sequoia Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But just like several other former Sequoia partners — including David Vélez, who founded the Brazilian digital bank Nubank — Khimji (pictured left) has always wanted to be a startup founder. On Thursday, he announced that he has revived an idea he began working on as a student at Harvard about 10 years ago, turning it into the AI calendar-scheduling company Blockit. In a major vote of confidence, Khimji’s former employer, Sequoia, led the company’s $5 million seed round.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Blockit has a chance to become a $1Bn+ revenue business, and Kais will make sure it gets there,” Pat Grady, Sequoia’s general partner and co-steward who led the investment, wrote in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many startups have tried to automate scheduling in the past, Khimji believes that thanks to advances in LLMs, Blockit’s AI agents can handle scheduling more seamlessly and efficiently than many of its predecessors, including now-defunct startups Clara Labs and x.ai. (Yes, that domain name ended up with Elon Musk’s AI company.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike the current category leader Calendly, which was last valued at $3 billion and relies on users sharing links to find availability, Blockit is betting that its AI agents can master the nuance required to handle the entire scheduling process without human involvement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Blockit, Khimji and co-founder John Hahn — who previously worked on calendar products, including Timeful, Google Calendar, and Clockwise — are building what is essentially an AI social network for people’s time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It always felt very odd. I have a time database — my calendar. You have a time database — your calendar, and our databases just can’t talk to each other,” Khimji told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji says that Blockit can finally solve this disconnection. When two users need to meet, their respective AI agents communicate directly to negotiate a time, bypassing the typical back-and-forth emails entirely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can invoke the Blockit agent by copying it on an email or messaging it in Slack about a meeting. The bot then takes over the logistics, negotiating a mutually convenient time and location that fits the preferences of all participants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji said that Blockit can work as seamlessly as a human executive assistant. Users simply need to provide the system with specific instructions about their preferences, such as which meetings are nonnegotiable and which are “movable” based on daily needs. “Sometimes my calendar is crazy, so I need to skip lunch, and the agent needs to know that it’s okay to skip lunch,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The system can even be trained to prioritize meetings based on the tone of an email. For instance, a user might instruct the agent that a meeting request signed with a formal “Best regards” should take precedence over a casual interaction ending with “Cheers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By learning the preferences of its users, Blockit appears to be capitalizing on what venture firm Foundation Capital’s partners Jaya Gupta and Ashu Garg call “context graphs.” In a widely shared essay, the investors describe a multibillion-dollar opportunity for AI agents to capture the “why” behind every business decision by relying on the hidden logic that previously only existed in a person’s head.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blockit is already being used by more than 200 companies, including AI startup Together.ai, the newly acquired fintech company Brex, and robotics startup Rogo, as well as venture firms a16z, Accel, and Index. The app is available for free for 30 days. After that, it costs $1,000 annually for individual users and $5,000 annually for a team license with support for multiple users, Khimji said.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/Copy-of-SequoiaARCUS2023-FallWeek1NYC_0919-318.jpg.png?resize=1200,694" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Kais Khimji has spent most of his professional career as a venture investor, including six years as a partner at the prominent VC firm Sequoia Capital.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But just like several other former Sequoia partners — including David Vélez, who founded the Brazilian digital bank Nubank — Khimji (pictured left) has always wanted to be a startup founder. On Thursday, he announced that he has revived an idea he began working on as a student at Harvard about 10 years ago, turning it into the AI calendar-scheduling company Blockit. In a major vote of confidence, Khimji’s former employer, Sequoia, led the company’s $5 million seed round.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Blockit has a chance to become a $1Bn+ revenue business, and Kais will make sure it gets there,” Pat Grady, Sequoia’s general partner and co-steward who led the investment, wrote in a blog post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While many startups have tried to automate scheduling in the past, Khimji believes that thanks to advances in LLMs, Blockit’s AI agents can handle scheduling more seamlessly and efficiently than many of its predecessors, including now-defunct startups Clara Labs and x.ai. (Yes, that domain name ended up with Elon Musk’s AI company.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike the current category leader Calendly, which was last valued at $3 billion and relies on users sharing links to find availability, Blockit is betting that its AI agents can master the nuance required to handle the entire scheduling process without human involvement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Blockit, Khimji and co-founder John Hahn — who previously worked on calendar products, including Timeful, Google Calendar, and Clockwise — are building what is essentially an AI social network for people’s time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It always felt very odd. I have a time database — my calendar. You have a time database — your calendar, and our databases just can’t talk to each other,” Khimji told TechCrunch.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji says that Blockit can finally solve this disconnection. When two users need to meet, their respective AI agents communicate directly to negotiate a time, bypassing the typical back-and-forth emails entirely.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can invoke the Blockit agent by copying it on an email or messaging it in Slack about a meeting. The bot then takes over the logistics, negotiating a mutually convenient time and location that fits the preferences of all participants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Khimji said that Blockit can work as seamlessly as a human executive assistant. Users simply need to provide the system with specific instructions about their preferences, such as which meetings are nonnegotiable and which are “movable” based on daily needs. “Sometimes my calendar is crazy, so I need to skip lunch, and the agent needs to know that it’s okay to skip lunch,” he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The system can even be trained to prioritize meetings based on the tone of an email. For instance, a user might instruct the agent that a meeting request signed with a formal “Best regards” should take precedence over a casual interaction ending with “Cheers.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By learning the preferences of its users, Blockit appears to be capitalizing on what venture firm Foundation Capital’s partners Jaya Gupta and Ashu Garg call “context graphs.” In a widely shared essay, the investors describe a multibillion-dollar opportunity for AI agents to capture the “why” behind every business decision by relying on the hidden logic that previously only existed in a person’s head.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blockit is already being used by more than 200 companies, including AI startup Together.ai, the newly acquired fintech company Brex, and robotics startup Rogo, as well as venture firms a16z, Accel, and Index. The app is available for free for 30 days. After that, it costs $1,000 annually for individual users and $5,000 annually for a team license with support for multiple users, Khimji said.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/22/former-sequoia-partners-new-startup-uses-ai-to-negotiate-your-calendar-for-you/</guid><pubDate>Fri, 23 Jan 2026 02:29:24 +0000</pubDate></item><item><title>[NEW] Measles is surging in the US. Wastewater tracking could help. (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/23/1131698/measles-surging-us-wastewater-tracking/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/GettyImages-2078700675.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;This week marked a rather unpleasant anniversary: It’s a year since Texas reported a case of measles—the start of a significant outbreak that ended up spreading across multiple states. Since the start of January 2025, there have been over 2,500 confirmed cases of measles in the US. Three people have died.&lt;/p&gt;  &lt;p&gt;As vaccination rates drop and outbreaks continue, scientists have been experimenting with new ways to quickly identify new cases and prevent the disease from spreading. And they are starting to see some success with wastewater surveillance.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;After all, wastewater contains saliva, urine, feces, shed skin, and more. You could consider it a rich biological sample. Wastewater analysis helped scientists understand how covid was spreading during the pandemic. It’s early days, but it is starting to help us get a handle on measles.&lt;/p&gt;  &lt;p&gt;Globally, there has been some progress toward eliminating measles, largely thanks to vaccination efforts. Such efforts led to an 88% drop in measles deaths between 2000 and 2024, according to the World Health Organization. It estimates that “nearly 59 million lives have been saved by the measles vaccine” since 2000.&lt;/p&gt; 
 &lt;p&gt;Still, an estimated 95,000 people died from measles in 2024 alone—most of them young children. And cases are surging in Europe, Southeast Asia, and the Eastern Mediterranean region.&lt;/p&gt;  &lt;p&gt;Last year, the US saw the highest levels of measles in decades. The country is on track to lose its measles elimination status—a sorry fate that met Canada in November after the country recorded over 5,000 cases in a little over a year.&lt;/p&gt; 
 &lt;p&gt;Public health efforts to contain the spread of measles—which is incredibly contagious—typically involve clinical monitoring in health-care settings, along with vaccination campaigns. But scientists have started looking to wastewater, too.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Along with various bodily fluids, we all shed viruses and bacteria into wastewater, whether that’s through brushing our teeth, showering, or using the toilet. The idea of looking for these pathogens in wastewater to track diseases has been around for a while, but things really kicked into gear during the covid-19 pandemic, when scientists found that the coronavirus responsible for the disease was shed in feces.&lt;/p&gt;  &lt;p&gt;This led Marlene Wolfe of Emory University and Alexandria Boehm of Stanford University to establish WastewaterSCAN, an academic-led program developed to analyze wastewater samples across the US. Covid was just the beginning, says Wolfe. “Over the years we have worked to expand what can be monitored,” she says.&lt;/p&gt;  &lt;p&gt;Two years ago, for a previous edition of the Checkup, Wolfe told Cassandra Willyard that wastewater surveillance of measles was “absolutely possible,” as the virus is shed in urine. The hope was that this approach could shed light on measles outbreaks in a community, even if members of that community weren’t able to access health care and receive an official diagnosis. And that it could highlight when and where public health officials needed to act to prevent measles from spreading. Evidence that it worked as an effective public health measure was, at the time, scant.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Since then, she and her colleagues have developed a test to identify measles RNA. They trialed it at two wastewater treatment plants in Texas between December 2024 and May 2025. At each site, the team collected samples two or three times a week and tested them for measles RNA.&lt;/p&gt;  &lt;p&gt;Over that period, the team found measles RNA in 10.5% of the samples they collected, as reported in a preprint paper published at medRxiv in July and currently under review at a peer-reviewed journal. The first detection came a week before the first case of measles was officially confirmed in the area. That’s promising—it suggests that wastewater surveillance might pick up measles cases early, giving public health officials a head start in efforts to limit any outbreaks.&lt;/p&gt;  &lt;p&gt;There are more promising results from a team in Canada. Mike McKay and Ryland Corchis-Scott at the University of Windsor in Ontario and their colleagues have also been testing wastewater samples for measles RNA. Between February and November 2025, the team collected samples from a wastewater treatment facility serving over 30,000 people in Leamington, Ontario.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;These wastewater tests are somewhat limited—even if they do pick up measles, they won’t tell you &lt;em&gt;who&lt;/em&gt; has measles, &lt;em&gt;where &lt;/em&gt;exactly infections are occurring, or even &lt;em&gt;how many&lt;/em&gt; people are infected. McKay and his colleagues have begun to make some progress here. In addition to monitoring the large wastewater plant, the team used tampons to soak up wastewater from a hospital lateral sewer.&lt;/p&gt; 

 &lt;p&gt;They then compared their measles test results with the number of clinical cases in that hospital. This gave them some idea of the virus’s “shedding rate.” When they applied this to the data collected from the Leamington wastewater treatment facility, the team got estimates of measles cases that were much higher than the figures officially reported.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Their findings track with the opinions of local health officials (who estimate that the true number of cases during the outbreak was around five to 10 times higher than the confirmed case count), the team members wrote in a paper published on medRxiv a couple of weeks ago.&lt;/p&gt;  &lt;p&gt;There will always be limits to wastewater surveillance. “We’re looking at the pool of waste of an entire community, so it’s very hard to pull in information about individual infections,” says Corchis-Scott.&lt;/p&gt;  &lt;p&gt;Wolfe also acknowledges that “we have a lot to learn about how we can best use the tools so they are useful.” But her team at WastewaterSCAN has been testing wastewater across the US for measles since May last year. And their findings are published online and shared with public health officials.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt;&lt;p&gt;In some cases, the findings are already helping inform the response to measles. “We’ve seen public health departments act on this data,” says Wolfe. Some have issued alerts, or increased vaccination efforts in those areas, for example. “[We’re at] a point now where we really see public health departments, clinicians, [and] families using that information to help keep themselves and their communities safe,” she says.&lt;/p&gt;  &lt;p&gt;McKay says his team has stopped testing for measles because the Ontario outbreak “has been declared over.” He says testing would restart if and when a single new case of measles is confirmed in the region, but he also thinks that his research makes a strong case for maintaining a wastewater surveillance system for measles.&lt;/p&gt;  &lt;p&gt;McKay wonders if this approach might help Canada regain its measles elimination status. “It’s sort of like [we’re] a pariah now,” he says. If his approach can help limit measles outbreaks, it could be “a nice tool for public health in Canada to [show] we’ve got our act together.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/GettyImages-2078700675.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;This week marked a rather unpleasant anniversary: It’s a year since Texas reported a case of measles—the start of a significant outbreak that ended up spreading across multiple states. Since the start of January 2025, there have been over 2,500 confirmed cases of measles in the US. Three people have died.&lt;/p&gt;  &lt;p&gt;As vaccination rates drop and outbreaks continue, scientists have been experimenting with new ways to quickly identify new cases and prevent the disease from spreading. And they are starting to see some success with wastewater surveillance.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;After all, wastewater contains saliva, urine, feces, shed skin, and more. You could consider it a rich biological sample. Wastewater analysis helped scientists understand how covid was spreading during the pandemic. It’s early days, but it is starting to help us get a handle on measles.&lt;/p&gt;  &lt;p&gt;Globally, there has been some progress toward eliminating measles, largely thanks to vaccination efforts. Such efforts led to an 88% drop in measles deaths between 2000 and 2024, according to the World Health Organization. It estimates that “nearly 59 million lives have been saved by the measles vaccine” since 2000.&lt;/p&gt; 
 &lt;p&gt;Still, an estimated 95,000 people died from measles in 2024 alone—most of them young children. And cases are surging in Europe, Southeast Asia, and the Eastern Mediterranean region.&lt;/p&gt;  &lt;p&gt;Last year, the US saw the highest levels of measles in decades. The country is on track to lose its measles elimination status—a sorry fate that met Canada in November after the country recorded over 5,000 cases in a little over a year.&lt;/p&gt; 
 &lt;p&gt;Public health efforts to contain the spread of measles—which is incredibly contagious—typically involve clinical monitoring in health-care settings, along with vaccination campaigns. But scientists have started looking to wastewater, too.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Along with various bodily fluids, we all shed viruses and bacteria into wastewater, whether that’s through brushing our teeth, showering, or using the toilet. The idea of looking for these pathogens in wastewater to track diseases has been around for a while, but things really kicked into gear during the covid-19 pandemic, when scientists found that the coronavirus responsible for the disease was shed in feces.&lt;/p&gt;  &lt;p&gt;This led Marlene Wolfe of Emory University and Alexandria Boehm of Stanford University to establish WastewaterSCAN, an academic-led program developed to analyze wastewater samples across the US. Covid was just the beginning, says Wolfe. “Over the years we have worked to expand what can be monitored,” she says.&lt;/p&gt;  &lt;p&gt;Two years ago, for a previous edition of the Checkup, Wolfe told Cassandra Willyard that wastewater surveillance of measles was “absolutely possible,” as the virus is shed in urine. The hope was that this approach could shed light on measles outbreaks in a community, even if members of that community weren’t able to access health care and receive an official diagnosis. And that it could highlight when and where public health officials needed to act to prevent measles from spreading. Evidence that it worked as an effective public health measure was, at the time, scant.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Since then, she and her colleagues have developed a test to identify measles RNA. They trialed it at two wastewater treatment plants in Texas between December 2024 and May 2025. At each site, the team collected samples two or three times a week and tested them for measles RNA.&lt;/p&gt;  &lt;p&gt;Over that period, the team found measles RNA in 10.5% of the samples they collected, as reported in a preprint paper published at medRxiv in July and currently under review at a peer-reviewed journal. The first detection came a week before the first case of measles was officially confirmed in the area. That’s promising—it suggests that wastewater surveillance might pick up measles cases early, giving public health officials a head start in efforts to limit any outbreaks.&lt;/p&gt;  &lt;p&gt;There are more promising results from a team in Canada. Mike McKay and Ryland Corchis-Scott at the University of Windsor in Ontario and their colleagues have also been testing wastewater samples for measles RNA. Between February and November 2025, the team collected samples from a wastewater treatment facility serving over 30,000 people in Leamington, Ontario.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;These wastewater tests are somewhat limited—even if they do pick up measles, they won’t tell you &lt;em&gt;who&lt;/em&gt; has measles, &lt;em&gt;where &lt;/em&gt;exactly infections are occurring, or even &lt;em&gt;how many&lt;/em&gt; people are infected. McKay and his colleagues have begun to make some progress here. In addition to monitoring the large wastewater plant, the team used tampons to soak up wastewater from a hospital lateral sewer.&lt;/p&gt; 

 &lt;p&gt;They then compared their measles test results with the number of clinical cases in that hospital. This gave them some idea of the virus’s “shedding rate.” When they applied this to the data collected from the Leamington wastewater treatment facility, the team got estimates of measles cases that were much higher than the figures officially reported.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Their findings track with the opinions of local health officials (who estimate that the true number of cases during the outbreak was around five to 10 times higher than the confirmed case count), the team members wrote in a paper published on medRxiv a couple of weeks ago.&lt;/p&gt;  &lt;p&gt;There will always be limits to wastewater surveillance. “We’re looking at the pool of waste of an entire community, so it’s very hard to pull in information about individual infections,” says Corchis-Scott.&lt;/p&gt;  &lt;p&gt;Wolfe also acknowledges that “we have a lot to learn about how we can best use the tools so they are useful.” But her team at WastewaterSCAN has been testing wastewater across the US for measles since May last year. And their findings are published online and shared with public health officials.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt;&lt;p&gt;In some cases, the findings are already helping inform the response to measles. “We’ve seen public health departments act on this data,” says Wolfe. Some have issued alerts, or increased vaccination efforts in those areas, for example. “[We’re at] a point now where we really see public health departments, clinicians, [and] families using that information to help keep themselves and their communities safe,” she says.&lt;/p&gt;  &lt;p&gt;McKay says his team has stopped testing for measles because the Ontario outbreak “has been declared over.” He says testing would restart if and when a single new case of measles is confirmed in the region, but he also thinks that his research makes a strong case for maintaining a wastewater surveillance system for measles.&lt;/p&gt;  &lt;p&gt;McKay wonders if this approach might help Canada regain its measles elimination status. “It’s sort of like [we’re] a pariah now,” he says. If his approach can help limit measles outbreaks, it could be “a nice tool for public health in Canada to [show] we’ve got our act together.”&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This article first appeared in The Checkup,&amp;nbsp;&lt;/em&gt;MIT Technology Review’s&lt;em&gt;&amp;nbsp;weekly biotech newsletter. To receive it in your inbox every Thursday, and read articles like this first,&amp;nbsp;&lt;/em&gt;&lt;em&gt;sign up here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/23/1131698/measles-surging-us-wastewater-tracking/</guid><pubDate>Fri, 23 Jan 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] America’s coming war over AI regulation (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/23/1131559/americas-coming-war-over-ai-regulation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/runaway-train.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt;’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them &lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached a boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry. Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy, one that would position the US to win the global AI race. The move marked a qualified victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead, buoyed by mounting public pressure to protect children from chatbots and rein in power-hungry data centers. Meanwhile, dueling super PACs bankrolled by tech moguls and AI-safety advocates will pour tens of millions into congressional and state elections to seat lawmakers who champion their competing visions for AI regulation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Trump’s executive order directs the Department of Justice to establish a task force that sues states whose AI laws clash with his vision for light-touch regulation. It also directs the Department of Commerce to starve states of federal broadband funding if their AI laws are “onerous.” In practice, the order may target a handful of laws in Democratic states, says James Grimmelmann, a law professor at Cornell Law School. “The executive order will be used to challenge a smaller number of provisions, mostly relating to transparency and bias in AI, which tend to be more liberal issues,” Grimmelmann says.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For now, many states aren’t flinching. On December 19, New York’s governor, Kathy Hochul, signed the Responsible AI Safety and Education (RAISE) Act, a landmark law requiring AI companies to publish the protocols used to ensure the safe development of their AI models and report critical safety incidents. On January 1, California debuted the nation’s first frontier AI safety law, SB 53—which the RAISE Act was modeled on—aimed at preventing catastrophic harms such as biological weapons or cyberattacks. While both laws were watered down from earlier iterations to survive bruising industry lobbying, they struck a rare, if fragile, compromise between tech giants and AI safety advocates.&lt;/p&gt;  &lt;p&gt;If Trump targets these hard-won laws, Democratic states like California and New York will likely take the fight to court. Republican states like Florida with vocal champions for AI regulation might follow suit. Trump could face an uphill battle. “The Trump administration is stretching itself thin with some of its attempts to effectively preempt [legislation] via executive action,” says Margot Kaminski, a law professor at the University of Colorado Law School. “It’s on thin ice.”&lt;/p&gt; 
 &lt;p&gt;But Republican states that are anxious to stay off Trump’s radar or can’t afford to lose federal broadband funding for their sprawling rural communities might retreat from passing or enforcing AI laws. Win or lose in court, the chaos and uncertainty could chill state lawmaking. Paradoxically, the Democratic states that Trump wants to rein in—armed with big budgets and emboldened by the optics of battling the administration—may be the least likely to budge.&lt;/p&gt;  &lt;p&gt;In lieu of state laws, Trump promises to create a federal AI policy with Congress. But the gridlocked and polarized body won’t be delivering a bill this year. In July, the Senate killed a moratorium on state AI laws that had been inserted into a tax bill, and in November, the House scrapped an encore attempt in a defense bill. In fact, Trump’s bid to strong-arm Congress with an executive order may sour any appetite for a bipartisan deal.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The executive order “has made it harder to pass responsible AI policy by hardening a lot of positions, making it a much more partisan issue,” says Brad Carson, a former Democratic congressman from Oklahoma who is building a network of super PACs backing candidates who support AI regulation. “It hardened Democrats and created incredible fault lines among Republicans,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While AI accelerationists in Trump’s orbit—AI and crypto czar David Sacks among them—champion deregulation, populist MAGA firebrands like Steve Bannon warn of rogue superintelligence and mass unemployment. In response to Trump’s executive order, Republican state attorneys general signed a bipartisan letter urging the FCC not to supersede state AI laws.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;With Americans increasingly anxious about how AI could harm mental health, jobs, and the environment, public demand for regulation is growing. If Congress stays paralyzed, states will be the only ones acting to keep the AI industry in check. In 2025, state legislators introduced more than 1,000 AI bills, and nearly 40 states enacted over 100 laws, according to the National Conference of State Legislatures.&lt;/p&gt;  &lt;p&gt;Efforts to protect children from chatbots may inspire rare consensus. On January 7, Google and Character Technologies, a startup behind the companion chatbot Character.AI, settled several lawsuits with families of teenagers who killed themselves after interacting with the bot. Just a day later, the Kentucky attorney general sued Character Technologies, alleging that the chatbots drove children to suicide and other forms of self-harm. OpenAI and Meta face a barrage of similar suits. Expect more to pile up this year. Without AI laws on the books, it remains to be seen how product liability laws and free speech doctrines apply to these novel dangers. “It’s an open question what the courts will do,” says Grimmelmann.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While litigation brews, states will move to pass child safety laws, which are exempt from Trump’s proposed ban on state AI laws. On January 9, OpenAI inked a deal with a former foe, the child-safety advocacy group Common Sense Media, to back a ballot initiative in California called the Parents &amp;amp; Kids Safe AI Act, setting guardrails around how chatbots interact with children. The measure proposes requiring AI companies to verify users’ age, offer parental controls, and undergo independent child-safety audits. If passed, it could be a blueprint for states across the country seeking to crack down on chatbots.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Fueled by widespread backlash against data centers, states will also try to regulate the resources needed to run AI. That means bills requiring data centers to report on their power and water use and foot their own electricity bills. If AI starts to displace jobs at scale, labor groups might float AI bans in specific professions. A few states concerned about the catastrophic risks posed by AI may pass safety bills mirroring SB 53 and the RAISE Act.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Meanwhile, tech titans will continue to use their deep pockets to crush AI regulations. Leading the Future, a super PAC backed by OpenAI president Greg Brockman and the venture capital firm Andreessen Horowitz, will try to elect candidates who endorse unfettered AI development to Congress and state legislatures. They’ll follow the crypto industry’s playbook for electing allies and writing the rules. To counter this, super PACs funded by Public First, an organization run by Carson and former Republican congressman Chris Stewart of Utah, will back candidates advocating for AI regulation. We might even see a handful of candidates running on anti-AI populist platforms.&lt;/p&gt;  &lt;p&gt;In 2026, the slow, messy process of American democracy will grind on. And the rules written in state capitals could decide how the most disruptive technology of our generation develops far beyond America’s borders, for years to come.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/runaway-train.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;MIT Technology Review&lt;em&gt;’s What’s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them &lt;/em&gt;&lt;em&gt;here&lt;/em&gt;&lt;em&gt;.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;In the final weeks of 2025, the battle over regulating artificial intelligence in the US reached a boiling point. On December 11, after Congress failed twice to pass a law banning state AI laws, President Donald Trump signed a sweeping executive order seeking to handcuff states from regulating the booming industry. Instead, he vowed to work with Congress to establish a “minimally burdensome” national AI policy, one that would position the US to win the global AI race. The move marked a qualified victory for tech titans, who have been marshaling multimillion-dollar war chests to oppose AI regulations, arguing that a patchwork of state laws would stifle innovation.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In 2026, the battleground will shift to the courts. While some states might back down from passing AI laws, others will charge ahead, buoyed by mounting public pressure to protect children from chatbots and rein in power-hungry data centers. Meanwhile, dueling super PACs bankrolled by tech moguls and AI-safety advocates will pour tens of millions into congressional and state elections to seat lawmakers who champion their competing visions for AI regulation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Trump’s executive order directs the Department of Justice to establish a task force that sues states whose AI laws clash with his vision for light-touch regulation. It also directs the Department of Commerce to starve states of federal broadband funding if their AI laws are “onerous.” In practice, the order may target a handful of laws in Democratic states, says James Grimmelmann, a law professor at Cornell Law School. “The executive order will be used to challenge a smaller number of provisions, mostly relating to transparency and bias in AI, which tend to be more liberal issues,” Grimmelmann says.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__container--08c53dd3bc9bd04e1e42e5f7ca641ab2"&gt;&lt;div class="whyItMatters__header--19f7f372f181cc6d4c06bc7362a44382"&gt;&lt;div class="whyItMatters__title--4af28c786a2bc93df05db111c6c30618"&gt;&lt;span class="whyItMatters__askAi--577f5fe6f54de43e37258d0f2aff4394"&gt;Ask AI&lt;/span&gt;&lt;div&gt;&lt;span class="whyItMatters__whyItMattersTitle--a3694998bb578e159bbd16690b8da390"&gt;Why it matters to you?&lt;/span&gt;&lt;span class="whyItMatters__betaBadge--9e84228b864d33d5b55479433fc91b8a"&gt;BETA&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="whyItMatters__description--e1334886c092fa469388d7a24e1e1a55"&gt;&lt;span class="initial-description"&gt;Here’s why this story might matter to you, according to AI. This is a beta feature and AI hallucinates—it might get weird&lt;/span&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="whyItMatters__questionContainer--ec1159210954852b9178c549600959a0"&gt;&lt;div&gt;&lt;button class="whyItMatters__actionButton--674934b6df433ac81e613372979cdb6c" type="button"&gt;Tell me why it matters&lt;/button&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;For now, many states aren’t flinching. On December 19, New York’s governor, Kathy Hochul, signed the Responsible AI Safety and Education (RAISE) Act, a landmark law requiring AI companies to publish the protocols used to ensure the safe development of their AI models and report critical safety incidents. On January 1, California debuted the nation’s first frontier AI safety law, SB 53—which the RAISE Act was modeled on—aimed at preventing catastrophic harms such as biological weapons or cyberattacks. While both laws were watered down from earlier iterations to survive bruising industry lobbying, they struck a rare, if fragile, compromise between tech giants and AI safety advocates.&lt;/p&gt;  &lt;p&gt;If Trump targets these hard-won laws, Democratic states like California and New York will likely take the fight to court. Republican states like Florida with vocal champions for AI regulation might follow suit. Trump could face an uphill battle. “The Trump administration is stretching itself thin with some of its attempts to effectively preempt [legislation] via executive action,” says Margot Kaminski, a law professor at the University of Colorado Law School. “It’s on thin ice.”&lt;/p&gt; 
 &lt;p&gt;But Republican states that are anxious to stay off Trump’s radar or can’t afford to lose federal broadband funding for their sprawling rural communities might retreat from passing or enforcing AI laws. Win or lose in court, the chaos and uncertainty could chill state lawmaking. Paradoxically, the Democratic states that Trump wants to rein in—armed with big budgets and emboldened by the optics of battling the administration—may be the least likely to budge.&lt;/p&gt;  &lt;p&gt;In lieu of state laws, Trump promises to create a federal AI policy with Congress. But the gridlocked and polarized body won’t be delivering a bill this year. In July, the Senate killed a moratorium on state AI laws that had been inserted into a tax bill, and in November, the House scrapped an encore attempt in a defense bill. In fact, Trump’s bid to strong-arm Congress with an executive order may sour any appetite for a bipartisan deal.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The executive order “has made it harder to pass responsible AI policy by hardening a lot of positions, making it a much more partisan issue,” says Brad Carson, a former Democratic congressman from Oklahoma who is building a network of super PACs backing candidates who support AI regulation. “It hardened Democrats and created incredible fault lines among Republicans,” he says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While AI accelerationists in Trump’s orbit—AI and crypto czar David Sacks among them—champion deregulation, populist MAGA firebrands like Steve Bannon warn of rogue superintelligence and mass unemployment. In response to Trump’s executive order, Republican state attorneys general signed a bipartisan letter urging the FCC not to supersede state AI laws.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;With Americans increasingly anxious about how AI could harm mental health, jobs, and the environment, public demand for regulation is growing. If Congress stays paralyzed, states will be the only ones acting to keep the AI industry in check. In 2025, state legislators introduced more than 1,000 AI bills, and nearly 40 states enacted over 100 laws, according to the National Conference of State Legislatures.&lt;/p&gt;  &lt;p&gt;Efforts to protect children from chatbots may inspire rare consensus. On January 7, Google and Character Technologies, a startup behind the companion chatbot Character.AI, settled several lawsuits with families of teenagers who killed themselves after interacting with the bot. Just a day later, the Kentucky attorney general sued Character Technologies, alleging that the chatbots drove children to suicide and other forms of self-harm. OpenAI and Meta face a barrage of similar suits. Expect more to pile up this year. Without AI laws on the books, it remains to be seen how product liability laws and free speech doctrines apply to these novel dangers. “It’s an open question what the courts will do,” says Grimmelmann.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;While litigation brews, states will move to pass child safety laws, which are exempt from Trump’s proposed ban on state AI laws. On January 9, OpenAI inked a deal with a former foe, the child-safety advocacy group Common Sense Media, to back a ballot initiative in California called the Parents &amp;amp; Kids Safe AI Act, setting guardrails around how chatbots interact with children. The measure proposes requiring AI companies to verify users’ age, offer parental controls, and undergo independent child-safety audits. If passed, it could be a blueprint for states across the country seeking to crack down on chatbots.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Fueled by widespread backlash against data centers, states will also try to regulate the resources needed to run AI. That means bills requiring data centers to report on their power and water use and foot their own electricity bills. If AI starts to displace jobs at scale, labor groups might float AI bans in specific professions. A few states concerned about the catastrophic risks posed by AI may pass safety bills mirroring SB 53 and the RAISE Act.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Meanwhile, tech titans will continue to use their deep pockets to crush AI regulations. Leading the Future, a super PAC backed by OpenAI president Greg Brockman and the venture capital firm Andreessen Horowitz, will try to elect candidates who endorse unfettered AI development to Congress and state legislatures. They’ll follow the crypto industry’s playbook for electing allies and writing the rules. To counter this, super PACs funded by Public First, an organization run by Carson and former Republican congressman Chris Stewart of Utah, will back candidates advocating for AI regulation. We might even see a handful of candidates running on anti-AI populist platforms.&lt;/p&gt;  &lt;p&gt;In 2026, the slow, messy process of American democracy will grind on. And the rules written in state capitals could decide how the most disruptive technology of our generation develops far beyond America’s borders, for years to come.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/23/1131559/americas-coming-war-over-ai-regulation/</guid><pubDate>Fri, 23 Jan 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] Defensive AI and how machine learning strengthens cyber defense (AI News)</title><link>https://www.artificialintelligence-news.com/news/defensive-ai-and-how-machine-learning-strengthens-cyber-defense/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/sasun-bughdaryan-nYq5qPnyoPE-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Cyber threats don’t follow predictable patterns, forcing security teams to rethink how protection works at scale. Defensive AI is emerging as a practical response, combining machine learning with human oversight.&lt;/p&gt;&lt;p&gt;Cybersecurity rarely fails because teams lack tools. It fails because threats move faster than detection can keep pace. As digital systems expand, attackers adapt in real time while static defences fall behind. This reality explains why AI security explained has become a central topic in modern cyber defense conversations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-cyber-defense-needs-machine-learning-now"&gt;Why cyber defense needs machine learning now&lt;/h3&gt;&lt;p&gt;Attack techniques today are fluid. Phishing messages change wording in hours. Malware alters behaviour to avoid detection. Rule-based security struggles in this environment.&lt;/p&gt;&lt;p&gt;Machine learning fills this void by learning how systems are expected to behave. In other words, it does not wait for a recognised pattern but searches for something that does not seem to fit. The is important when a threat is either new or camouflaged.&lt;/p&gt;&lt;p&gt;For security teams, this change reduces blind spots. Machine learning processes data volumes that no human team could review manually. It connects subtle signals in networks, endpoints and cloud services.&lt;/p&gt;&lt;p&gt;You see the benefit when response times shrink. Early detection limits damage. Faster containment protects data and continuity. In global environments, that speed often determines whether an incident stays manageable.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-defensive-ai-identifies-threats-in-real-time"&gt;How defensive AI identifies threats in real time&lt;/h3&gt;&lt;p&gt;Machine learning models are interested in behaviour and not in assumptions. Models learn by observing how users and applications interact. When activity breaks from expected patterns, alerts surface. This approach works even when the threat has never appeared before. Zero-day attacks really become visible because behaviour, not history, triggers concern.&lt;/p&gt;&lt;p&gt;Common detection techniques include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Behavioural base-lining to spot unusual activity&lt;/li&gt;&lt;li&gt;Anomaly detection in network and application traffic&lt;/li&gt;&lt;li&gt;Classification models trained on diverse threat patterns&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Real-time analysis is essential. Modern attacks spread quickly in interconnected systems. Machine learning continuously evaluates streaming data, letting security teams react before damage escalates.&lt;/p&gt;&lt;p&gt;This ability proves especially valuable in cloud environments. Resources change constantly. Traditional perimeter defences lose relevance. Behaviour-based monitoring adapts as systems evolve.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-embedding-defense-across-the-ai-security-lifecycle"&gt;Embedding defense across the AI security lifecycle&lt;/h3&gt;&lt;p&gt;Effective cyber defense does not start at deployment. It begins earlier and continues throughout a system’s lifespan.&lt;/p&gt;&lt;p&gt;Machine learning technology evaluates development configurations and dependencies during development. High-risk configuration items and exposed services are identified before deployment to production. That makes them less exposed in the long run.&lt;/p&gt;&lt;p&gt;Once systems go live, monitoring shifts to runtime behaviour. Access requests, inference activity and data flows receive constant attention. Unusual patterns prompt investigation.&lt;/p&gt;&lt;p&gt;Post-deployment oversight remains critical. Use patterns change. Models age. Defensive AI detects drift that may signal misuse or emerging vulnerabilities.&lt;/p&gt;&lt;p&gt;The lifecycle view reduces fragmentation. Security becomes consistent in stages not reactive after incidents occur. Over time, that consistency builds operational confidence.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-defensive-ai-in-complex-enterprise-environments"&gt;Defensive AI in complex enterprise environments&lt;/h3&gt;&lt;p&gt;Enterprise infrastructure rarely exists in one place. Cloud platforms, remote work and third-party services increase complexity.&lt;/p&gt;&lt;p&gt;Defensive AI addresses this by correlating signals in environments. Isolated alerts become connected stories. Security teams gain context instead of noise.&lt;/p&gt;&lt;p&gt;Machine learning also helps prioritise risk. Not every alert requires immediate action. By scoring threats based on behaviour and impact, AI reduces alert fatigue.&lt;/p&gt;&lt;p&gt;This prioritisation improves efficiency. Analysts spend time where it matters most. Routine anomalies are monitored and not escalated.&lt;/p&gt;&lt;p&gt;As organisations operate in regions, consistency becomes vital. Defensive AI applies the same analytical standards globally. That uniformity supports reliable protection without slowing operations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-human-judgement-in-an-ai-driven-defense-model"&gt;Human judgement in an AI-driven defense model&lt;/h3&gt;&lt;p&gt;Defensive AI is most effective when paired with human expertise. Automation deals with speed and volume. Human judgement and accountability are provided by humans. The ensures there is no blind trust in systems unaware of what is happening in the real world.&lt;/p&gt;&lt;p&gt;Security specialists are involved in model training and testing. Human judgement is used to decide which behaviours are most significant. Context is always important for interpretation, particularly when business dynamics, roles and geographic considerations apply.&lt;/p&gt;&lt;p&gt;Explainability is also a factor in trust. It is necessary to know the reason a warning was issued. Modern defensive systems are increasingly providing a reason for a decision, letting analysts review the results and make decisions with confidence not hesitation.&lt;/p&gt;&lt;p&gt;The combination produces stronger results. AI points out potential dangers early, in large spaces. Humans make decisions about actions, focus on impact and mitigate effects. AI and humans create a robust defense system.&lt;/p&gt;&lt;p&gt;In light of the increasingly adaptable nature of threats in cyberspace, this synergy has become imperative. The role of defensive AI in supporting the underlying foundation through analysis has been made possible through human oversight.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-conclusions"&gt;Conclusions&lt;/h3&gt;&lt;p&gt;Cybersecurity exists in a reality that is defined by speed, scale and continuous change. The static nature of cyber-defense makes it inadequate in this reality, as attack vectors change faster than static cyber-defense measures can keep pace.&lt;/p&gt;&lt;p&gt;Defensive AI represents a useful evolution. Machine learning improves detection, reduces response time and helps build resistance in complex systems by recognising nuanced patterns of human behaviour.&lt;/p&gt;&lt;p&gt;But when paired with experienced human monitoring, defensive AI goes beyond automation. It can become an assured means of protecting contemporary digital infrastructure, facilitating stable security operations that don’t diminish responsibility or decision-making.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/sasun-bughdaryan-nYq5qPnyoPE-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Cyber threats don’t follow predictable patterns, forcing security teams to rethink how protection works at scale. Defensive AI is emerging as a practical response, combining machine learning with human oversight.&lt;/p&gt;&lt;p&gt;Cybersecurity rarely fails because teams lack tools. It fails because threats move faster than detection can keep pace. As digital systems expand, attackers adapt in real time while static defences fall behind. This reality explains why AI security explained has become a central topic in modern cyber defense conversations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-cyber-defense-needs-machine-learning-now"&gt;Why cyber defense needs machine learning now&lt;/h3&gt;&lt;p&gt;Attack techniques today are fluid. Phishing messages change wording in hours. Malware alters behaviour to avoid detection. Rule-based security struggles in this environment.&lt;/p&gt;&lt;p&gt;Machine learning fills this void by learning how systems are expected to behave. In other words, it does not wait for a recognised pattern but searches for something that does not seem to fit. The is important when a threat is either new or camouflaged.&lt;/p&gt;&lt;p&gt;For security teams, this change reduces blind spots. Machine learning processes data volumes that no human team could review manually. It connects subtle signals in networks, endpoints and cloud services.&lt;/p&gt;&lt;p&gt;You see the benefit when response times shrink. Early detection limits damage. Faster containment protects data and continuity. In global environments, that speed often determines whether an incident stays manageable.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-defensive-ai-identifies-threats-in-real-time"&gt;How defensive AI identifies threats in real time&lt;/h3&gt;&lt;p&gt;Machine learning models are interested in behaviour and not in assumptions. Models learn by observing how users and applications interact. When activity breaks from expected patterns, alerts surface. This approach works even when the threat has never appeared before. Zero-day attacks really become visible because behaviour, not history, triggers concern.&lt;/p&gt;&lt;p&gt;Common detection techniques include:&lt;/p&gt;&lt;ul class="wp-block-list"&gt;&lt;li&gt;Behavioural base-lining to spot unusual activity&lt;/li&gt;&lt;li&gt;Anomaly detection in network and application traffic&lt;/li&gt;&lt;li&gt;Classification models trained on diverse threat patterns&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Real-time analysis is essential. Modern attacks spread quickly in interconnected systems. Machine learning continuously evaluates streaming data, letting security teams react before damage escalates.&lt;/p&gt;&lt;p&gt;This ability proves especially valuable in cloud environments. Resources change constantly. Traditional perimeter defences lose relevance. Behaviour-based monitoring adapts as systems evolve.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-embedding-defense-across-the-ai-security-lifecycle"&gt;Embedding defense across the AI security lifecycle&lt;/h3&gt;&lt;p&gt;Effective cyber defense does not start at deployment. It begins earlier and continues throughout a system’s lifespan.&lt;/p&gt;&lt;p&gt;Machine learning technology evaluates development configurations and dependencies during development. High-risk configuration items and exposed services are identified before deployment to production. That makes them less exposed in the long run.&lt;/p&gt;&lt;p&gt;Once systems go live, monitoring shifts to runtime behaviour. Access requests, inference activity and data flows receive constant attention. Unusual patterns prompt investigation.&lt;/p&gt;&lt;p&gt;Post-deployment oversight remains critical. Use patterns change. Models age. Defensive AI detects drift that may signal misuse or emerging vulnerabilities.&lt;/p&gt;&lt;p&gt;The lifecycle view reduces fragmentation. Security becomes consistent in stages not reactive after incidents occur. Over time, that consistency builds operational confidence.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-defensive-ai-in-complex-enterprise-environments"&gt;Defensive AI in complex enterprise environments&lt;/h3&gt;&lt;p&gt;Enterprise infrastructure rarely exists in one place. Cloud platforms, remote work and third-party services increase complexity.&lt;/p&gt;&lt;p&gt;Defensive AI addresses this by correlating signals in environments. Isolated alerts become connected stories. Security teams gain context instead of noise.&lt;/p&gt;&lt;p&gt;Machine learning also helps prioritise risk. Not every alert requires immediate action. By scoring threats based on behaviour and impact, AI reduces alert fatigue.&lt;/p&gt;&lt;p&gt;This prioritisation improves efficiency. Analysts spend time where it matters most. Routine anomalies are monitored and not escalated.&lt;/p&gt;&lt;p&gt;As organisations operate in regions, consistency becomes vital. Defensive AI applies the same analytical standards globally. That uniformity supports reliable protection without slowing operations.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-human-judgement-in-an-ai-driven-defense-model"&gt;Human judgement in an AI-driven defense model&lt;/h3&gt;&lt;p&gt;Defensive AI is most effective when paired with human expertise. Automation deals with speed and volume. Human judgement and accountability are provided by humans. The ensures there is no blind trust in systems unaware of what is happening in the real world.&lt;/p&gt;&lt;p&gt;Security specialists are involved in model training and testing. Human judgement is used to decide which behaviours are most significant. Context is always important for interpretation, particularly when business dynamics, roles and geographic considerations apply.&lt;/p&gt;&lt;p&gt;Explainability is also a factor in trust. It is necessary to know the reason a warning was issued. Modern defensive systems are increasingly providing a reason for a decision, letting analysts review the results and make decisions with confidence not hesitation.&lt;/p&gt;&lt;p&gt;The combination produces stronger results. AI points out potential dangers early, in large spaces. Humans make decisions about actions, focus on impact and mitigate effects. AI and humans create a robust defense system.&lt;/p&gt;&lt;p&gt;In light of the increasingly adaptable nature of threats in cyberspace, this synergy has become imperative. The role of defensive AI in supporting the underlying foundation through analysis has been made possible through human oversight.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-conclusions"&gt;Conclusions&lt;/h3&gt;&lt;p&gt;Cybersecurity exists in a reality that is defined by speed, scale and continuous change. The static nature of cyber-defense makes it inadequate in this reality, as attack vectors change faster than static cyber-defense measures can keep pace.&lt;/p&gt;&lt;p&gt;Defensive AI represents a useful evolution. Machine learning improves detection, reduces response time and helps build resistance in complex systems by recognising nuanced patterns of human behaviour.&lt;/p&gt;&lt;p&gt;But when paired with experienced human monitoring, defensive AI goes beyond automation. It can become an assured means of protecting contemporary digital infrastructure, facilitating stable security operations that don’t diminish responsibility or decision-making.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/defensive-ai-and-how-machine-learning-strengthens-cyber-defense/</guid><pubDate>Fri, 23 Jan 2026 10:15:58 +0000</pubDate></item></channel></rss>