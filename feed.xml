<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 22 Jul 2025 06:35:12 +0000</lastBuildDate><item><title>MIT Learn offers “a whole new front door to the Institute” (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-learn-offers-whole-new-front-door-institute-0721</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;In 2001, MIT became the first higher education institution to provide educational resources for free to anyone in the world. Fast forward 24 years: The Institute has now launched a dynamic AI-enabled website for its non-degree learning opportunities, making it easier for learners around the world to discover the courses and resources available on MIT’s various learning platforms.&lt;/p&gt;&lt;p dir="ltr"&gt;MIT Learn enables learners to access more than 12,700 educational resources — including introductory and advanced courses, courseware, videos, podcasts, and more — from departments across the Institute. MIT Learn is designed to seamlessly connect the existing Institute’s learning platforms in one place.&lt;/p&gt;&lt;p dir="ltr"&gt;“With MIT Learn, we’re opening access to MIT’s digital learning opportunities for millions around the world,” says Dimitris Bertsimas, vice provost for open learning. “MIT Learn elevates learning with personalized recommendations powered by AI, guiding each learner toward deeper understanding. It is a stepping stone toward a broader vision of making these opportunities even more accessible to global learners through one unified learning platform.”&lt;/p&gt;&lt;p dir="ltr"&gt;The goal for MIT Learn is twofold: to allow learners to find what they want to fulfill their curiosity, and to enable learners to develop a long-term relationship with MIT as a source of educational experiences.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“By fostering long-term connections between learners and MIT, we not only provide a pathway to continued learning, but also advance MIT’s mission to disseminate knowledge globally,” says Ferdi Alimadhi, chief technology officer for MIT Open Learning and the lead of the MIT Learn project. “With this initial launch of MIT Learn, we’re introducing AI-powered features that leverage emerging technologies to help learners discover the right content, engage with it more deeply, and stay supported as they shape their own educational journeys.”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;With its sophisticated search, browse, and discovery capability, MIT Learn allows learners to explore topics without having to understand MIT’s organizational structure or know the names of departments and programs. An AI-powered recommendation feature called “Ask Tim” complements the site’s traditional search and browsing tools, helping learners quickly find courses and resources aligned with their personal and professional goals. Learners can also prompt “Ask Tim” for a summary of a course’s structure, topics, and expectations, leading to more-informed decisions before enrolling.&lt;/p&gt;&lt;p dir="ltr"&gt;In select offerings, such as Molecular Biology: DNA Replication and Repair, Genetics: The Fundamentals, and Cell Biology: Transport and Signaling, learners can interact with an AI assistant by asking questions about a lecture, requesting flashcards of key concepts, and obtaining instant summaries. These select offerings also feature an AI tutor to support learners as they work through problem sets, guiding them toward the next step without giving away the answers. These features, Alimadhi says, are being introduced in a limited set of courses and modules to allow the MIT Open Learning team to gather insights and improve the learning experience before expanding more broadly.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT Learn is a whole new front door to the Institute,” says Christopher Capozzola, senior associate dean for open learning, who worked with faculty across the Institute on the project. “Just as the Kendall Square renovations transformed the way that people interact with our physical campus, MIT Learn transforms how people engage with what we offer digitally.”&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/lHp6sYSHfKU/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
        &lt;div class="news-article--inline-video--caption"&gt;
      

            Introducing MIT Learn: Your new destination for lifelong learning        

    &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Learners who choose to create an account on MIT Learn receive personalized course recommendations and can create and curate lists of educational resources, follow their specific areas of interest, and receive notifications when new MIT content is available. They can also personalize their learning experience based on their specific interests and choose the format that is best suited to them.&lt;/p&gt;&lt;p dir="ltr"&gt;"From anywhere and for anyone, MIT Learn makes lifelong learning more accessible and personalized, building on the Institute’s decades of global leadership in open learning,” says MIT Provost Anantha Chandrakasan.&lt;/p&gt;&lt;p dir="ltr"&gt;MIT Learn was designed to account for a learner’s evolving needs throughout their learning journey. It highlights supplemental study materials for middle schoolers, high schoolers, and college students, upskilling opportunities for early-career professionals, reskilling programs for those considering a career shift, and resources for educators.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT has an amazing collection of learning opportunities, covering a wide range of formats,” says Eric Grimson, chancellor for academic advancement, who oversaw the initial development of MIT Learn during his time as interim vice president for open learning. “The sheer size of that collection can be daunting, so creating a platform that brings all of those offerings together, in an easily searchable framework, greatly enhances our ability to serve learners.”&lt;/p&gt;&lt;p dir="ltr"&gt;According to Peter Hirst, senior associate dean for executive education at MIT Sloan School of Management, one of the Institute's incredible strengths is its sheer volume and diversity of expertise, research, and learning opportunities. But it can be challenging to discover and follow all those opportunities — even for people who are immersed in the on-campus experience. MIT Learn, he says, is a solution to this problem.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT Learn gathers all the knowledge and learning resources offered across all of MIT into a learner-friendly, curatable repository that enables anyone and everyone, whatever their interests or learning needs,&amp;nbsp;to explore and engage in the wide range of learning resources and public certificate programs that MIT has to offer and that can help them achieve their goals,” Hirst says.&lt;/p&gt;&lt;p dir="ltr"&gt;MIT Learn was spearheaded by MIT Open Learning, which aims to transform teaching and learning on and off the Institute’s campus. MIT Learn was developed with the direction of former provost Cynthia Barnhart, and in cooperation with Sloan Executive Education and Professional Education. During the design phase, OpenCourseWare Faculty Advisory Committee Chair Michael Short and&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;&amp;nbsp;Faculty Advisory Committee Chair Caspar Hare contributed key insights, along with other numerous faculty involved with Open Learning’s product offerings, including OpenCourseWare,&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;, and MicroMasters programs. MIT Learn is also informed by the insights of the Ad Hoc Committee on&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;&amp;nbsp;and&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt; Online.&lt;/p&gt;&lt;p dir="ltr"&gt;“For over 20 years, MIT staff and faculty have been creating a wealth of online resources, from lecture videos to practice problems, and from single online courses to entire credential-earning programs,” says Sara Fisher Ellison, a member of the Ad Hoc Committee on&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;&amp;nbsp;and&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt; Online and the faculty lead for the online&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt; MicroMasters Program in Data, Economics, and Design of Policy. “Making these resources findable, searchable, and broadly available is a natural extension of MIT’s core educational mission. MIT Learn is a big, important step in that direction. We are excited for the world to see what we have to offer.”&lt;/p&gt;&lt;p dir="ltr"&gt;Looking ahead, MIT Learn will also feature selected content from the MIT Press. As MIT Learn continues to grow, Open Learning is exploring collaborations with departments across the Institute with the goal of offering the fullest possible range of educational materials from MIT to learners around the world.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT Learn is the latest step in a long tradition of the Institute providing innovative ways for learners to access knowledge,” Barnhart says. “This AI-enabled platform delivers on the Institute’s commitment to help people launch into learning journeys that can unlock life-changing opportunities.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;In 2001, MIT became the first higher education institution to provide educational resources for free to anyone in the world. Fast forward 24 years: The Institute has now launched a dynamic AI-enabled website for its non-degree learning opportunities, making it easier for learners around the world to discover the courses and resources available on MIT’s various learning platforms.&lt;/p&gt;&lt;p dir="ltr"&gt;MIT Learn enables learners to access more than 12,700 educational resources — including introductory and advanced courses, courseware, videos, podcasts, and more — from departments across the Institute. MIT Learn is designed to seamlessly connect the existing Institute’s learning platforms in one place.&lt;/p&gt;&lt;p dir="ltr"&gt;“With MIT Learn, we’re opening access to MIT’s digital learning opportunities for millions around the world,” says Dimitris Bertsimas, vice provost for open learning. “MIT Learn elevates learning with personalized recommendations powered by AI, guiding each learner toward deeper understanding. It is a stepping stone toward a broader vision of making these opportunities even more accessible to global learners through one unified learning platform.”&lt;/p&gt;&lt;p dir="ltr"&gt;The goal for MIT Learn is twofold: to allow learners to find what they want to fulfill their curiosity, and to enable learners to develop a long-term relationship with MIT as a source of educational experiences.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;“By fostering long-term connections between learners and MIT, we not only provide a pathway to continued learning, but also advance MIT’s mission to disseminate knowledge globally,” says Ferdi Alimadhi, chief technology officer for MIT Open Learning and the lead of the MIT Learn project. “With this initial launch of MIT Learn, we’re introducing AI-powered features that leverage emerging technologies to help learners discover the right content, engage with it more deeply, and stay supported as they shape their own educational journeys.”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;With its sophisticated search, browse, and discovery capability, MIT Learn allows learners to explore topics without having to understand MIT’s organizational structure or know the names of departments and programs. An AI-powered recommendation feature called “Ask Tim” complements the site’s traditional search and browsing tools, helping learners quickly find courses and resources aligned with their personal and professional goals. Learners can also prompt “Ask Tim” for a summary of a course’s structure, topics, and expectations, leading to more-informed decisions before enrolling.&lt;/p&gt;&lt;p dir="ltr"&gt;In select offerings, such as Molecular Biology: DNA Replication and Repair, Genetics: The Fundamentals, and Cell Biology: Transport and Signaling, learners can interact with an AI assistant by asking questions about a lecture, requesting flashcards of key concepts, and obtaining instant summaries. These select offerings also feature an AI tutor to support learners as they work through problem sets, guiding them toward the next step without giving away the answers. These features, Alimadhi says, are being introduced in a limited set of courses and modules to allow the MIT Open Learning team to gather insights and improve the learning experience before expanding more broadly.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT Learn is a whole new front door to the Institute,” says Christopher Capozzola, senior associate dean for open learning, who worked with faculty across the Institute on the project. “Just as the Kendall Square renovations transformed the way that people interact with our physical campus, MIT Learn transforms how people engage with what we offer digitally.”&lt;/p&gt;        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-youtube-video paragraph--view-mode--default"&gt;
          

            
   

  &lt;div class="news-article--inline-video"&gt;
        &lt;div class="news-article--inline-video--container"&gt;

                             &lt;div class="news-article--inline-video--cover-image"&gt;
                      &lt;img alt="Video thumbnail" height="480" src="https://i1.ytimg.com/vi/lHp6sYSHfKU/maxresdefault.jpg" width="640" /&gt;
                    
          Play video
        &lt;/div&gt;
                

                      &lt;/div&gt;
        &lt;div class="news-article--inline-video--caption"&gt;
      

            Introducing MIT Learn: Your new destination for lifelong learning        

    &lt;/div&gt;
          &lt;/div&gt;  
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;Learners who choose to create an account on MIT Learn receive personalized course recommendations and can create and curate lists of educational resources, follow their specific areas of interest, and receive notifications when new MIT content is available. They can also personalize their learning experience based on their specific interests and choose the format that is best suited to them.&lt;/p&gt;&lt;p dir="ltr"&gt;"From anywhere and for anyone, MIT Learn makes lifelong learning more accessible and personalized, building on the Institute’s decades of global leadership in open learning,” says MIT Provost Anantha Chandrakasan.&lt;/p&gt;&lt;p dir="ltr"&gt;MIT Learn was designed to account for a learner’s evolving needs throughout their learning journey. It highlights supplemental study materials for middle schoolers, high schoolers, and college students, upskilling opportunities for early-career professionals, reskilling programs for those considering a career shift, and resources for educators.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT has an amazing collection of learning opportunities, covering a wide range of formats,” says Eric Grimson, chancellor for academic advancement, who oversaw the initial development of MIT Learn during his time as interim vice president for open learning. “The sheer size of that collection can be daunting, so creating a platform that brings all of those offerings together, in an easily searchable framework, greatly enhances our ability to serve learners.”&lt;/p&gt;&lt;p dir="ltr"&gt;According to Peter Hirst, senior associate dean for executive education at MIT Sloan School of Management, one of the Institute's incredible strengths is its sheer volume and diversity of expertise, research, and learning opportunities. But it can be challenging to discover and follow all those opportunities — even for people who are immersed in the on-campus experience. MIT Learn, he says, is a solution to this problem.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT Learn gathers all the knowledge and learning resources offered across all of MIT into a learner-friendly, curatable repository that enables anyone and everyone, whatever their interests or learning needs,&amp;nbsp;to explore and engage in the wide range of learning resources and public certificate programs that MIT has to offer and that can help them achieve their goals,” Hirst says.&lt;/p&gt;&lt;p dir="ltr"&gt;MIT Learn was spearheaded by MIT Open Learning, which aims to transform teaching and learning on and off the Institute’s campus. MIT Learn was developed with the direction of former provost Cynthia Barnhart, and in cooperation with Sloan Executive Education and Professional Education. During the design phase, OpenCourseWare Faculty Advisory Committee Chair Michael Short and&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;&amp;nbsp;Faculty Advisory Committee Chair Caspar Hare contributed key insights, along with other numerous faculty involved with Open Learning’s product offerings, including OpenCourseWare,&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;, and MicroMasters programs. MIT Learn is also informed by the insights of the Ad Hoc Committee on&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;&amp;nbsp;and&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt; Online.&lt;/p&gt;&lt;p dir="ltr"&gt;“For over 20 years, MIT staff and faculty have been creating a wealth of online resources, from lecture videos to practice problems, and from single online courses to entire credential-earning programs,” says Sara Fisher Ellison, a member of the Ad Hoc Committee on&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt;&amp;nbsp;and&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt; Online and the faculty lead for the online&amp;nbsp;&lt;em&gt;MITx&lt;/em&gt; MicroMasters Program in Data, Economics, and Design of Policy. “Making these resources findable, searchable, and broadly available is a natural extension of MIT’s core educational mission. MIT Learn is a big, important step in that direction. We are excited for the world to see what we have to offer.”&lt;/p&gt;&lt;p dir="ltr"&gt;Looking ahead, MIT Learn will also feature selected content from the MIT Press. As MIT Learn continues to grow, Open Learning is exploring collaborations with departments across the Institute with the goal of offering the fullest possible range of educational materials from MIT to learners around the world.&lt;/p&gt;&lt;p dir="ltr"&gt;“MIT Learn is the latest step in a long tradition of the Institute providing innovative ways for learners to access knowledge,” Barnhart says. “This AI-enabled platform delivers on the Institute’s commitment to help people launch into learning journeys that can unlock life-changing opportunities.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-learn-offers-whole-new-front-door-institute-0721</guid><pubDate>Mon, 21 Jul 2025 19:00:00 +0000</pubDate></item><item><title>A new way to edit or generate images (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/new-way-edit-or-generate-images-0721</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/mit-token-opt3.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;AI image generation — which relies on neural networks to create new images from a variety of inputs, including text prompts — is projected to become a billion-dollar industry by the end of this decade. Even with today’s technology, if you wanted to make a fanciful picture of, say, a friend planting a flag on Mars or heedlessly flying into a black hole, it could take less than a second. However, before they can perform tasks like that, image generators are commonly trained on massive datasets containing millions of images that are often paired with associated text. Training these generative models can be an arduous chore that takes weeks or months, consuming vast computational resources in the process.&lt;/p&gt;&lt;p&gt;But what if it were possible to generate images through AI methods without using a generator at all? That real possibility, along with other intriguing ideas, was described in a research paper presented at the International Conference on Machine Learning (ICML 2025), which was held in Vancouver, British Columbia, earlier this summer. The paper, describing novel techniques for manipulating and generating images, was written by Lukas Lao Beyer, a graduate student researcher in MIT’s Laboratory for Information and Decision Systems (LIDS); Tianhong Li, a postdoc at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL); Xinlei Chen of Facebook AI Research; Sertac Karaman, an MIT professor of aeronautics and astronautics and the director of LIDS; and Kaiming He, an MIT associate professor of electrical engineering and computer science.&lt;/p&gt;&lt;p&gt;This group effort had its origins in a class project for a graduate seminar on deep generative models that Lao Beyer took last fall. In conversations during the semester, it became apparent to both Lao Beyer and He, who taught the seminar, that this research had real potential, which went far beyond the confines of a typical homework assignment. Other collaborators were soon brought into the endeavor.&lt;/p&gt;&lt;p&gt;The starting point for Lao Beyer’s inquiry was a June 2024 paper, written by researchers from the Technical University of Munich and the Chinese company ByteDance, which introduced a new way of representing visual information called a one-dimensional tokenizer. With this device, which is also a kind of neural network, a 256x256-pixel image can be translated into a sequence of just 32 numbers, called tokens. “I wanted to understand how such a high level of compression could be achieved, and what the tokens themselves actually represented,” says Lao Beyer.&lt;/p&gt;&lt;p&gt;The previous generation of tokenizers would typically break up the same image into an array of 16x16 tokens — with each token encapsulating information, in highly condensed form, that corresponds to a specific portion of the original image. The new 1D tokenizers can encode an image more efficiently, using far fewer tokens overall, and these tokens are able to capture information about the entire image, not just a single quadrant. Each of these tokens, moreover, is a 12-digit number consisting of 1s and 0s, allowing for 2&lt;sup&gt;12&lt;/sup&gt; (or about 4,000) possibilities altogether. “It’s like a vocabulary of 4,000 words that makes up an abstract, hidden language spoken by the computer,” He explains. “It’s not like a human language, but we can still try to find out what it means.”&lt;/p&gt;&lt;p&gt;That’s exactly what Lao Beyer had initially set out to explore — work that provided the seed for the ICML 2025 paper. The approach he took was pretty straightforward. If you want to find out what a particular token does, Lao Beyer says, “you can just take it out, swap in some random value, and see if there is a recognizable change in the output.” Replacing one token, he found, changes the image quality, turning a low-resolution image into a high-resolution image or vice versa. Another token affected the blurriness in the background, while another still influenced the brightness. He also found a token that’s related to the “pose,” meaning that, in the image of a robin, for instance, the bird’s head might shift from right to left.&lt;/p&gt;&lt;p&gt;“This was a never-before-seen result, as no one had observed visually identifiable changes from manipulating tokens,” Lao Beyer says. The finding raised the possibility of a new approach to editing images. And the MIT group has shown, in fact, how this process can be streamlined and automated, so that tokens don’t have to be modified by hand, one at a time.&lt;/p&gt;&lt;p&gt;He and his colleagues achieved an even more consequential result involving image generation. A system capable of generating images normally requires a tokenizer, which compresses and encodes visual data, along with a generator that can combine and arrange these compact representations in order to create novel images. The MIT researchers found a way to create images without using a generator at all. Their new approach makes use of a 1D tokenizer and a so-called detokenizer (also known as a decoder), which can reconstruct an image from a string of tokens. However, with guidance provided by an off-the-shelf neural network called CLIP —&amp;nbsp;which cannot generate images on its own, but can measure how well a given image matches a certain text prompt&amp;nbsp;— the team was able to convert an image of a red panda, for example, into a tiger. In addition, they could create images of a tiger, or any other desired form, starting completely from scratch — from a situation in which all the tokens are initially assigned random values (and then iteratively tweaked so that the reconstructed image increasingly matches the desired text prompt).&lt;/p&gt;&lt;p&gt;The group demonstrated that with this same setup — relying on a tokenizer and detokenizer, but no generator — they could also do “inpainting,” which means filling in parts of images that had somehow been blotted out. Avoiding the use of a generator for certain tasks could lead to a significant reduction in computational costs because generators, as mentioned, normally require extensive training.&lt;/p&gt;&lt;p&gt;What might seem odd about this team’s contributions, He explains, “is that we didn’t invent anything new. We didn’t invent a 1D tokenizer, and we didn’t invent the CLIP model, either. But we did discover that new capabilities can arise when you put all these pieces together.”&lt;/p&gt;&lt;p&gt;“This work redefines the role of tokenizers,” comments&amp;nbsp;Saining Xie, a computer scientist at New York University. “It shows that&amp;nbsp;image tokenizers — tools usually used just to compress images — can actually do a lot more. The fact that a simple (but highly compressed) 1D tokenizer can handle tasks like inpainting or text-guided editing, without needing to train a full-blown generative model, is pretty surprising.”&lt;/p&gt;&lt;p&gt;Zhuang Liu of Princeton University agrees, saying that the work of the MIT group&amp;nbsp;“shows that we can generate and manipulate the images in a way that is much easier than we previously thought. Basically, it demonstrates that image generation can be a byproduct of a very effective image compressor, potentially reducing the cost of generating images several-fold.”&lt;/p&gt;&lt;p&gt;There could be many applications outside the field of computer vision, Karaman suggests. “For instance,&amp;nbsp;we could consider tokenizing the actions of robots or self-driving cars in the same way, which may rapidly broaden the impact of this work.”&lt;/p&gt;&lt;p&gt;Lao Beyer is thinking along similar lines,&amp;nbsp;noting that the&amp;nbsp;extreme amount of compression afforded by 1D tokenizers allows you to do “some amazing things,” which could be applied to other fields. For example, in the area of self-driving cars, which is one of his research interests, the tokens could represent, instead of images, the different routes that a vehicle might take.&lt;/p&gt;&lt;p&gt;Xie is also intrigued by the applications that may come from these innovative ideas. “There are some really cool use cases this could unlock,” he says.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/mit-token-opt3.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;AI image generation — which relies on neural networks to create new images from a variety of inputs, including text prompts — is projected to become a billion-dollar industry by the end of this decade. Even with today’s technology, if you wanted to make a fanciful picture of, say, a friend planting a flag on Mars or heedlessly flying into a black hole, it could take less than a second. However, before they can perform tasks like that, image generators are commonly trained on massive datasets containing millions of images that are often paired with associated text. Training these generative models can be an arduous chore that takes weeks or months, consuming vast computational resources in the process.&lt;/p&gt;&lt;p&gt;But what if it were possible to generate images through AI methods without using a generator at all? That real possibility, along with other intriguing ideas, was described in a research paper presented at the International Conference on Machine Learning (ICML 2025), which was held in Vancouver, British Columbia, earlier this summer. The paper, describing novel techniques for manipulating and generating images, was written by Lukas Lao Beyer, a graduate student researcher in MIT’s Laboratory for Information and Decision Systems (LIDS); Tianhong Li, a postdoc at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL); Xinlei Chen of Facebook AI Research; Sertac Karaman, an MIT professor of aeronautics and astronautics and the director of LIDS; and Kaiming He, an MIT associate professor of electrical engineering and computer science.&lt;/p&gt;&lt;p&gt;This group effort had its origins in a class project for a graduate seminar on deep generative models that Lao Beyer took last fall. In conversations during the semester, it became apparent to both Lao Beyer and He, who taught the seminar, that this research had real potential, which went far beyond the confines of a typical homework assignment. Other collaborators were soon brought into the endeavor.&lt;/p&gt;&lt;p&gt;The starting point for Lao Beyer’s inquiry was a June 2024 paper, written by researchers from the Technical University of Munich and the Chinese company ByteDance, which introduced a new way of representing visual information called a one-dimensional tokenizer. With this device, which is also a kind of neural network, a 256x256-pixel image can be translated into a sequence of just 32 numbers, called tokens. “I wanted to understand how such a high level of compression could be achieved, and what the tokens themselves actually represented,” says Lao Beyer.&lt;/p&gt;&lt;p&gt;The previous generation of tokenizers would typically break up the same image into an array of 16x16 tokens — with each token encapsulating information, in highly condensed form, that corresponds to a specific portion of the original image. The new 1D tokenizers can encode an image more efficiently, using far fewer tokens overall, and these tokens are able to capture information about the entire image, not just a single quadrant. Each of these tokens, moreover, is a 12-digit number consisting of 1s and 0s, allowing for 2&lt;sup&gt;12&lt;/sup&gt; (or about 4,000) possibilities altogether. “It’s like a vocabulary of 4,000 words that makes up an abstract, hidden language spoken by the computer,” He explains. “It’s not like a human language, but we can still try to find out what it means.”&lt;/p&gt;&lt;p&gt;That’s exactly what Lao Beyer had initially set out to explore — work that provided the seed for the ICML 2025 paper. The approach he took was pretty straightforward. If you want to find out what a particular token does, Lao Beyer says, “you can just take it out, swap in some random value, and see if there is a recognizable change in the output.” Replacing one token, he found, changes the image quality, turning a low-resolution image into a high-resolution image or vice versa. Another token affected the blurriness in the background, while another still influenced the brightness. He also found a token that’s related to the “pose,” meaning that, in the image of a robin, for instance, the bird’s head might shift from right to left.&lt;/p&gt;&lt;p&gt;“This was a never-before-seen result, as no one had observed visually identifiable changes from manipulating tokens,” Lao Beyer says. The finding raised the possibility of a new approach to editing images. And the MIT group has shown, in fact, how this process can be streamlined and automated, so that tokens don’t have to be modified by hand, one at a time.&lt;/p&gt;&lt;p&gt;He and his colleagues achieved an even more consequential result involving image generation. A system capable of generating images normally requires a tokenizer, which compresses and encodes visual data, along with a generator that can combine and arrange these compact representations in order to create novel images. The MIT researchers found a way to create images without using a generator at all. Their new approach makes use of a 1D tokenizer and a so-called detokenizer (also known as a decoder), which can reconstruct an image from a string of tokens. However, with guidance provided by an off-the-shelf neural network called CLIP —&amp;nbsp;which cannot generate images on its own, but can measure how well a given image matches a certain text prompt&amp;nbsp;— the team was able to convert an image of a red panda, for example, into a tiger. In addition, they could create images of a tiger, or any other desired form, starting completely from scratch — from a situation in which all the tokens are initially assigned random values (and then iteratively tweaked so that the reconstructed image increasingly matches the desired text prompt).&lt;/p&gt;&lt;p&gt;The group demonstrated that with this same setup — relying on a tokenizer and detokenizer, but no generator — they could also do “inpainting,” which means filling in parts of images that had somehow been blotted out. Avoiding the use of a generator for certain tasks could lead to a significant reduction in computational costs because generators, as mentioned, normally require extensive training.&lt;/p&gt;&lt;p&gt;What might seem odd about this team’s contributions, He explains, “is that we didn’t invent anything new. We didn’t invent a 1D tokenizer, and we didn’t invent the CLIP model, either. But we did discover that new capabilities can arise when you put all these pieces together.”&lt;/p&gt;&lt;p&gt;“This work redefines the role of tokenizers,” comments&amp;nbsp;Saining Xie, a computer scientist at New York University. “It shows that&amp;nbsp;image tokenizers — tools usually used just to compress images — can actually do a lot more. The fact that a simple (but highly compressed) 1D tokenizer can handle tasks like inpainting or text-guided editing, without needing to train a full-blown generative model, is pretty surprising.”&lt;/p&gt;&lt;p&gt;Zhuang Liu of Princeton University agrees, saying that the work of the MIT group&amp;nbsp;“shows that we can generate and manipulate the images in a way that is much easier than we previously thought. Basically, it demonstrates that image generation can be a byproduct of a very effective image compressor, potentially reducing the cost of generating images several-fold.”&lt;/p&gt;&lt;p&gt;There could be many applications outside the field of computer vision, Karaman suggests. “For instance,&amp;nbsp;we could consider tokenizing the actions of robots or self-driving cars in the same way, which may rapidly broaden the impact of this work.”&lt;/p&gt;&lt;p&gt;Lao Beyer is thinking along similar lines,&amp;nbsp;noting that the&amp;nbsp;extreme amount of compression afforded by 1D tokenizers allows you to do “some amazing things,” which could be applied to other fields. For example, in the area of self-driving cars, which is one of his research interests, the tokens could represent, instead of images, the different routes that a vehicle might take.&lt;/p&gt;&lt;p&gt;Xie is also intrigued by the applications that may come from these innovative ideas. “There are some really cool use cases this could unlock,” he says.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/new-way-edit-or-generate-images-0721</guid><pubDate>Mon, 21 Jul 2025 19:00:00 +0000</pubDate></item><item><title>Gemini Deep Think learns math, wins gold medal at International Math Olympiad (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/google-deepmind-earns-gold-in-international-math-olympiad-with-new-gemini-ai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        DeepMind followed IMO rules to earn gold, unlike OpenAI.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Google DeepMind at IMO" class="absolute inset-0 w-full h-full object-cover hidden" height="482" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/imo-team-in-australia-640x482.jpg" width="640" /&gt;
                  &lt;img alt="Google DeepMind at IMO" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/imo-team-in-australia-1152x648-1753123000.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The DeepMind IMO team at this year's event in Australia. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google DeepMind

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The students participating in the annual International Math Olympiad (IMO) represent some of the most talented young computational minds in the world. This year, they faced down a newly enhanced array of powerful AI models, including Google's Gemini Deep Think. The company says it put its model to the test using the same rules as human participants, and it improved on an already solid showing from last year.&lt;/p&gt;
&lt;p&gt;Google says its specially tuned math AI got five of the six questions correct, which is good enough for gold medal status. And unlike OpenAI, Google played by the rules set forth by the IMO.&lt;/p&gt;
&lt;h2&gt;A new Gemini&lt;/h2&gt;
&lt;p&gt;The Google DeepMind team participated in last year's IMO competition using an AI composed of the AlphaProof and AlphaGeometry 2 models. This setup was able to get four of the six questions correct, earning silver medal status—only half of the human participants earn any medal at all.&lt;/p&gt;
&lt;p&gt;In 2025, Google DeepMind was among a group of companies that worked with the IMO to have their models officially graded and certified by the coordinators. Google came prepared with a new model for the occasion. Gemini Deep Think was announced earlier this year as a more analytical take on simulated reasoning models. Rather than going down one linear line of "thought," Deep Think runs multiple reasoning processes in parallel, integrating and comparing the results before giving a final answer.&lt;/p&gt;
&lt;p&gt;According to Thang Luong, DeepMind senior scientist and head of the IMO team, this is a paradigm shift from last year's effort. In 2024, an expert had to translate the natural language questions into "domain specific language." At the end of the process, said expert would have to interpret the output. Deep Think, however, is natural language, end to end, and was not specifically designed to do math.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the past, making LLMs better at math would involve reinforcement learning with final answers. Luong explained to Ars that models trained in this way can get to the correct answer, but they have "incomplete reasoning," and part of the IMO grading is based on showing your work. To prepare Deep Think for the IMO, Google used new reinforcement learning techniques with higher-quality "long answer" solutions to mathematical problems, giving the model better grounding in how to handle every step on the way to an answer. "With this kind of training, you can actually get robust, long-form reasoning," said Luong.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2107081 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/IMO-2024-2025.png" width="1920" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google DeepMind

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As you might expect, Deep Think takes more time to generate an output compared to the simpler versions you can access in the Gemini app. However, the AI followed the same rules as the flesh-and-blood participants, which was only possible because of its ability to ingest the problems as natural language. Gemini was provided with the problem descriptions and gave its answers within the 4.5-hour time limit of the competition.&lt;/p&gt;
&lt;h2&gt;Rigorous proofs&lt;/h2&gt;
&lt;p&gt;AI firms like DeepMind have taken an interest in the IMO over the past few years because it presents a unique challenge. While the competition is aimed at pre-university mathematicians, the questions require critical thinking and an understanding of multiple mathematical disciplines, including algebra, combinatorics, geometry, and number theory. Only the most advanced AI models have any hope of accurately answering these multi-layered problems.&lt;/p&gt;
&lt;p&gt;The DeepMind team has pointed out some interesting aspects of Deep Think's performance, which they say come from its advanced training. In the third problem (below), for example, many human competitors applied a graduate-level concept called Dirichlet's Theorem, using mathematics outside the intended scope of the competition. However, Deep Think recognized that it was possible to solve the problem with simpler math. "Our model actually made a brilliant observation and used only elementary number theory to create a self-contained proof of the given problem," said DeepMind researcher and Brown University professor Junehyuk Jung.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2107082 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="IMO 2025 P3" class="fullwidth full" height="212" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/Google-DeepMind-IMO-P3.png" width="575" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The DeepMind team says the model came up with a "brilliant" solution to this problem.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google DeepMind

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As for the one Deep Think got wrong, the team says that was objectively the hardest of the competition. The question asked about the minimum number of rectangles needed to cover a given space. Jung explains that Deep Think started from an incorrect hypothesis, believing that the answer would be greater than or equal to 10, so it was lost from the start. "There's no way it's going to solve it because that is not true to begin with," said Jung.&lt;/p&gt;
&lt;p&gt;So Deep Think lost points on that problem, but Jung notes that only five students managed to get that one right. Still, Google got 35 points to earn a gold medal. Only about 8 percent of the human participants can reach that level.&lt;/p&gt;
&lt;p&gt;Google stresses that Deep Think went through the same evaluation as the students do. OpenAI has also announced results from the IMO, but it did not work with the organization to adhere to the established process. Instead, it had a panel of former IMO participants grade its answers and awarded &lt;em&gt;itself&lt;/em&gt; a gold medal.&lt;/p&gt;
&lt;p&gt;"We confirmed with the IMO organization that we actually solved five perfectly," said Luong. "I think anyone who didn't go through that process, we don't know, they might have lost one point and gotten silver."&lt;/p&gt;
&lt;p&gt;Google says the version of Deep Think tuned for the IMO is sticking around. It is currently being rolled out to a group of trusted testers that includes mathematicians. Eventually, this model will be provided to Google AI Ultra subscribers, who pay $250 per month for access to Google's biggest and most expensive models. DeepMind plans to continue iterating on this model and will be back next year in search of a perfect score.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        DeepMind followed IMO rules to earn gold, unlike OpenAI.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Google DeepMind at IMO" class="absolute inset-0 w-full h-full object-cover hidden" height="482" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/imo-team-in-australia-640x482.jpg" width="640" /&gt;
                  &lt;img alt="Google DeepMind at IMO" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/imo-team-in-australia-1152x648-1753123000.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The DeepMind IMO team at this year's event in Australia. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google DeepMind

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The students participating in the annual International Math Olympiad (IMO) represent some of the most talented young computational minds in the world. This year, they faced down a newly enhanced array of powerful AI models, including Google's Gemini Deep Think. The company says it put its model to the test using the same rules as human participants, and it improved on an already solid showing from last year.&lt;/p&gt;
&lt;p&gt;Google says its specially tuned math AI got five of the six questions correct, which is good enough for gold medal status. And unlike OpenAI, Google played by the rules set forth by the IMO.&lt;/p&gt;
&lt;h2&gt;A new Gemini&lt;/h2&gt;
&lt;p&gt;The Google DeepMind team participated in last year's IMO competition using an AI composed of the AlphaProof and AlphaGeometry 2 models. This setup was able to get four of the six questions correct, earning silver medal status—only half of the human participants earn any medal at all.&lt;/p&gt;
&lt;p&gt;In 2025, Google DeepMind was among a group of companies that worked with the IMO to have their models officially graded and certified by the coordinators. Google came prepared with a new model for the occasion. Gemini Deep Think was announced earlier this year as a more analytical take on simulated reasoning models. Rather than going down one linear line of "thought," Deep Think runs multiple reasoning processes in parallel, integrating and comparing the results before giving a final answer.&lt;/p&gt;
&lt;p&gt;According to Thang Luong, DeepMind senior scientist and head of the IMO team, this is a paradigm shift from last year's effort. In 2024, an expert had to translate the natural language questions into "domain specific language." At the end of the process, said expert would have to interpret the output. Deep Think, however, is natural language, end to end, and was not specifically designed to do math.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;In the past, making LLMs better at math would involve reinforcement learning with final answers. Luong explained to Ars that models trained in this way can get to the correct answer, but they have "incomplete reasoning," and part of the IMO grading is based on showing your work. To prepare Deep Think for the IMO, Google used new reinforcement learning techniques with higher-quality "long answer" solutions to mathematical problems, giving the model better grounding in how to handle every step on the way to an answer. "With this kind of training, you can actually get robust, long-form reasoning," said Luong.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2107081 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="fullwidth full" height="1080" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/IMO-2024-2025.png" width="1920" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google DeepMind

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As you might expect, Deep Think takes more time to generate an output compared to the simpler versions you can access in the Gemini app. However, the AI followed the same rules as the flesh-and-blood participants, which was only possible because of its ability to ingest the problems as natural language. Gemini was provided with the problem descriptions and gave its answers within the 4.5-hour time limit of the competition.&lt;/p&gt;
&lt;h2&gt;Rigorous proofs&lt;/h2&gt;
&lt;p&gt;AI firms like DeepMind have taken an interest in the IMO over the past few years because it presents a unique challenge. While the competition is aimed at pre-university mathematicians, the questions require critical thinking and an understanding of multiple mathematical disciplines, including algebra, combinatorics, geometry, and number theory. Only the most advanced AI models have any hope of accurately answering these multi-layered problems.&lt;/p&gt;
&lt;p&gt;The DeepMind team has pointed out some interesting aspects of Deep Think's performance, which they say come from its advanced training. In the third problem (below), for example, many human competitors applied a graduate-level concept called Dirichlet's Theorem, using mathematics outside the intended scope of the competition. However, Deep Think recognized that it was possible to solve the problem with simpler math. "Our model actually made a brilliant observation and used only elementary number theory to create a self-contained proof of the given problem," said DeepMind researcher and Brown University professor Junehyuk Jung.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2107082 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="IMO 2025 P3" class="fullwidth full" height="212" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/Google-DeepMind-IMO-P3.png" width="575" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The DeepMind team says the model came up with a "brilliant" solution to this problem.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google DeepMind

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;As for the one Deep Think got wrong, the team says that was objectively the hardest of the competition. The question asked about the minimum number of rectangles needed to cover a given space. Jung explains that Deep Think started from an incorrect hypothesis, believing that the answer would be greater than or equal to 10, so it was lost from the start. "There's no way it's going to solve it because that is not true to begin with," said Jung.&lt;/p&gt;
&lt;p&gt;So Deep Think lost points on that problem, but Jung notes that only five students managed to get that one right. Still, Google got 35 points to earn a gold medal. Only about 8 percent of the human participants can reach that level.&lt;/p&gt;
&lt;p&gt;Google stresses that Deep Think went through the same evaluation as the students do. OpenAI has also announced results from the IMO, but it did not work with the organization to adhere to the established process. Instead, it had a panel of former IMO participants grade its answers and awarded &lt;em&gt;itself&lt;/em&gt; a gold medal.&lt;/p&gt;
&lt;p&gt;"We confirmed with the IMO organization that we actually solved five perfectly," said Luong. "I think anyone who didn't go through that process, we don't know, they might have lost one point and gotten silver."&lt;/p&gt;
&lt;p&gt;Google says the version of Deep Think tuned for the IMO is sticking around. It is currently being rolled out to a group of trusted testers that includes mathematicians. Eventually, this model will be provided to Google AI Ultra subscribers, who pay $250 per month for access to Google's biggest and most expensive models. DeepMind plans to continue iterating on this model and will be back next year in search of a perfect score.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/google-deepmind-earns-gold-in-international-math-olympiad-with-new-gemini-ai/</guid><pubDate>Mon, 21 Jul 2025 19:08:41 +0000</pubDate></item><item><title>72% of US teens have used AI companions, study finds (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/21/72-of-u-s-teens-have-used-ai-companions-study-finds/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hopefully not Grok’s companions&amp;nbsp;…&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A new study by a U.S. nonprofit focused on the lives of kids and families, Common Sense Media, has found that a vast majority of U.S. teens (72%) have tried an AI companion at least once. By “companion,” the study is focused on AI chatbots that are designed for users to have more personal conversations with, not AI assistants that work as homework helpers, image generators, or voice assistants that just answer questions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For instance, the study’s definition of AI companions could include those digital AI personas provided by companies like Character.AI or Replika, but it could also encompass the use of general-purpose chatbots like ChatGPT or Claude, which can be used for more personal conversations, if desired. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The study found that chatting with an AI seems to be appealing to U.S. teens (ages 13 to 17), as not only had nearly three-quarters tried an AI companion, but also 52% said they are regular users. Among those who engaged with these companions regularly, 13% chat with them daily and 21% chat a few times a week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Boys (31%) were also slightly more likely than girls (25%) to say they had never used an AI companion, among the one in four teens who said they have never tried it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings are based on a study that ran during April and May 2025 and used a representative sample of 1,060 teens and was conducted by researchers from NORC at the University of Chicago. There have already been concerns about AI’s impact on teens’ well-being, as one firm, Character.AI, is being sued over a teen’s suicide in Florida and for promoting violence in Texas. There are also a number of reports that describe the potential dangers of using AI for therapy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings from Common Sense Media’s new study offer an early understanding of how young people are using AI to simulate human interactions, which could include virtual friendship, emotional support, therapy, and role-playing games, among other things.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The analysis also examined other behaviors around teen usage of AI companions, including what sorts of tasks teens turned to them for, why, and what the after-effects were.&lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3029674" height="1060" src="https://techcrunch.com/wp-content/uploads/2025/07/common-sense-study-2025-07-21-at-3.16.52PM.jpg" width="1458" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Common Sense Media&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, nearly half (46%) said they saw AI companions as tools or programs, and 33% said they use them for social interaction and relationships. Teens said they use the AI companions for various purposes: entertainment (30%), curiosity about AI technology (28%), advice (18%), and because they’re always available (17%).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Half of teens (50%) said they don’t trust the information provided by AI companions. However, older teens are less likely to trust the AI’s advice compared with younger teens, ages 13 to 14, at 20% and 27%, respectively.&lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3029677" height="682" src="https://techcrunch.com/wp-content/uploads/2025/07/common-sense-study-2025-07-21-at-3.17.07PM.jpg" width="1266" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Common Sense Media&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One-third of the teens said they find the conversations more satisfying than those with real-life friends, though the majority (67%) felt the opposite way.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, 39% were using the AI conversations as practice for real-life interactions, as 39% said they applied skills they first tried with an AI to real-world situations. Among the skills practiced, social skills were the top use case, with 39% of teens having explored this area, followed by conversation starters (18%), giving advice (14%), and expressing emotions (13%). &lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3029675" height="1200" src="https://techcrunch.com/wp-content/uploads/2025/07/common-sense-study-2025-07-21-at-3.17.17PM.jpg" width="1426" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Common Sense Media&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of whether real-life relationships will be replaced by tech, there was one positive finding: 80% of teens who used AI companions said they spend more time with real friends than with their AI chatbots. Only 6% said the reverse was true.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Hopefully not Grok’s companions&amp;nbsp;…&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A new study by a U.S. nonprofit focused on the lives of kids and families, Common Sense Media, has found that a vast majority of U.S. teens (72%) have tried an AI companion at least once. By “companion,” the study is focused on AI chatbots that are designed for users to have more personal conversations with, not AI assistants that work as homework helpers, image generators, or voice assistants that just answer questions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;For instance, the study’s definition of AI companions could include those digital AI personas provided by companies like Character.AI or Replika, but it could also encompass the use of general-purpose chatbots like ChatGPT or Claude, which can be used for more personal conversations, if desired. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The study found that chatting with an AI seems to be appealing to U.S. teens (ages 13 to 17), as not only had nearly three-quarters tried an AI companion, but also 52% said they are regular users. Among those who engaged with these companions regularly, 13% chat with them daily and 21% chat a few times a week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Boys (31%) were also slightly more likely than girls (25%) to say they had never used an AI companion, among the one in four teens who said they have never tried it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings are based on a study that ran during April and May 2025 and used a representative sample of 1,060 teens and was conducted by researchers from NORC at the University of Chicago. There have already been concerns about AI’s impact on teens’ well-being, as one firm, Character.AI, is being sued over a teen’s suicide in Florida and for promoting violence in Texas. There are also a number of reports that describe the potential dangers of using AI for therapy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings from Common Sense Media’s new study offer an early understanding of how young people are using AI to simulate human interactions, which could include virtual friendship, emotional support, therapy, and role-playing games, among other things.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The analysis also examined other behaviors around teen usage of AI companions, including what sorts of tasks teens turned to them for, why, and what the after-effects were.&lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3029674" height="1060" src="https://techcrunch.com/wp-content/uploads/2025/07/common-sense-study-2025-07-21-at-3.16.52PM.jpg" width="1458" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Common Sense Media&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, nearly half (46%) said they saw AI companions as tools or programs, and 33% said they use them for social interaction and relationships. Teens said they use the AI companions for various purposes: entertainment (30%), curiosity about AI technology (28%), advice (18%), and because they’re always available (17%).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Half of teens (50%) said they don’t trust the information provided by AI companions. However, older teens are less likely to trust the AI’s advice compared with younger teens, ages 13 to 14, at 20% and 27%, respectively.&lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3029677" height="682" src="https://techcrunch.com/wp-content/uploads/2025/07/common-sense-study-2025-07-21-at-3.17.07PM.jpg" width="1266" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Common Sense Media&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;One-third of the teens said they find the conversations more satisfying than those with real-life friends, though the majority (67%) felt the opposite way.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Plus, 39% were using the AI conversations as practice for real-life interactions, as 39% said they applied skills they first tried with an AI to real-world situations. Among the skills practiced, social skills were the top use case, with 39% of teens having explored this area, followed by conversation starters (18%), giving advice (14%), and expressing emotions (13%). &lt;/p&gt;

&lt;figure class="wp-block-image alignwide size-full"&gt;&lt;img alt="alt" class="wp-image-3029675" height="1200" src="https://techcrunch.com/wp-content/uploads/2025/07/common-sense-study-2025-07-21-at-3.17.17PM.jpg" width="1426" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Common Sense Media&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In terms of whether real-life relationships will be replaced by tech, there was one positive finding: 80% of teens who used AI companions said they spend more time with real friends than with their AI chatbots. Only 6% said the reverse was true.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/21/72-of-u-s-teens-have-used-ai-companions-study-finds/</guid><pubDate>Mon, 21 Jul 2025 19:42:20 +0000</pubDate></item><item><title>ChatGPT users send 2.5 billion prompts a day (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/21/chatgpt-users-send-2-5-billion-prompts-a-day/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-1733837014-e.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT receives 2.5 billion prompts from global users every day, OpenAI told Axios. About 330 million of those are coming from users in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These numbers show just how ubiquitous OpenAI’s flagship product is becoming.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google’s parent company, Alphabet, does not release daily search data, but recently revealed that Google receives 5 trillion queries per year, which averages to just under 14 billion daily searches. Independent researchers have found similar trends. Neil Patel of NP Digital estimates that Google receives 13.7 billion searches daily, while research from SparkToro and Datos — two digital marketing companies — estimates that the figure is around 16.4 billion per day.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, ChatGPT has shown impressively rapid growth. In December, OpenAI CEO Sam Altman said that users send over 1 billion queries to ChatGPT each day. At Altman’s word, the company’s search volume has more than doubled in around eight months.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-1733837014-e.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT receives 2.5 billion prompts from global users every day, OpenAI told Axios. About 330 million of those are coming from users in the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These numbers show just how ubiquitous OpenAI’s flagship product is becoming.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google’s parent company, Alphabet, does not release daily search data, but recently revealed that Google receives 5 trillion queries per year, which averages to just under 14 billion daily searches. Independent researchers have found similar trends. Neil Patel of NP Digital estimates that Google receives 13.7 billion searches daily, while research from SparkToro and Datos — two digital marketing companies — estimates that the figure is around 16.4 billion per day.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, ChatGPT has shown impressively rapid growth. In December, OpenAI CEO Sam Altman said that users send over 1 billion queries to ChatGPT each day. At Altman’s word, the company’s search volume has more than doubled in around eight months.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/21/chatgpt-users-send-2-5-billion-prompts-a-day/</guid><pubDate>Mon, 21 Jul 2025 19:44:43 +0000</pubDate></item><item><title>A ChatGPT ‘router’ that automatically selects the right OpenAI model for your job appears imminent (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/a-chatgpt-router-that-automatically-selects-the-right-openai-model-for-your-job-appears-imminent/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;In the 2.5 years since OpenAI debuted ChatGPT, the number of large language models (LLMs) that the company has made available as options to power its hit chatbot has steadily grown. &lt;/p&gt;&lt;p&gt;In fact, there are now a total of 7 (!!!) different AI models that paying ChatGPT subscribers (of the $20 Plus tier and more expensive tiers) can choose between when interacting with the trusty chatbot — each with its own strengths and weaknesses.&lt;/p&gt;&lt;p&gt;But how should a user decide &lt;em&gt;which one&lt;/em&gt; to use for their particular prompt, question, or task? After all, you can only pick one at a time. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-is-help-on-the-way"&gt;Is help on the way? &lt;/h2&gt;



&lt;p&gt;Help appears to be on the way imminently from OpenAI — as reports emerged over the last few days on X from AI influencers, including OpenAI’s own researcher “Roon (@tszzl on X)” (speculated to be technical team member Tarun Gogineni) — of a new “router” function that will automatically select the best OpenAI model to respond to the user’s input on the fly, depending on the specific input’s content.&lt;/p&gt;



&lt;p&gt;As Roon posted on the social network X yesterday, July 20, 2025, in since-deleted response to influencer Lisan al Gaib’s statement that they “don’t want a model router I want to be able to select the models I use”: &lt;/p&gt;



&lt;p&gt;&lt;em&gt;“You’ll still be able to select. This is a product to make sure that doctors aren’t stuck on 4o-mini”&lt;/em&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014510" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/GwTyIPlXYAAu-uj-1.jpg?w=439" width="439" /&gt;&lt;/figure&gt;



&lt;p&gt;Similarly, Yuchen Jin, Co-founder &amp;amp; CTO of AI inference cloud provider Hyperbolic Labs, wrote in an X post on July 19.&lt;/p&gt;



&lt;p&gt;“&lt;em&gt;Heard GPT-5 is imminent, from a little bird.&lt;/em&gt;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;em&gt;It’s not one model, but multiple models. It has a router that switches between reasoning, non-reasoning, and tool-using models.&lt;/em&gt;&lt;/li&gt;



&lt;li&gt;&lt;em&gt;That’s why Sam said they’d “fix model naming”: prompts will just auto-route to the right model.&lt;/em&gt;&lt;/li&gt;



&lt;li&gt;&lt;em&gt;GPT-6 is in training.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;&lt;em&gt;I just hope they’re not delaying it for more safety tests. :)&lt;/em&gt;“&lt;/p&gt;



&lt;p&gt;While a presumably far more advanced GPT-5 model would (and will) be huge news if and when released, the router may make life much easier and more intelligent for the average ChatGPT subscriber.&lt;/p&gt;



&lt;p&gt;It would also follow on the heels of other third-party products such as the web-based Token Monster chatbot, which automatically select and combine responses from multiple third-party LLMs to respond to user queries.&lt;/p&gt;



&lt;p&gt;Asked about the router idea and comments from “Roon,” an OpenAI spokesperson declined to provide a response or further information at this time.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-solving-the-overabundance-of-choice-problem"&gt;Solving the overabundance of choice problem&lt;/h2&gt;



&lt;p&gt;To be clear, every time OpenAI has released a new LLM to the public, it has diligently shared in either a blog post or release notes or both what it thinks that particular model is good for and designed to help with. &lt;/p&gt;



&lt;p&gt;For example, OpenAI’s “o” series reasoning models — o3, o4-mini, o4-mini high — have performed better on math, science, and coding tests thanks to benchmarking tests, while non-reasoning models like the new GPT-4.5 and 4.1 seem to do better at creative writing and communications tasks. &lt;/p&gt;



&lt;p&gt;Dedicated AI influencers and power users may understand very well what all these different models are good and not so good at.&lt;/p&gt;



&lt;p&gt;But regular users who don’t follow the industry as closely, nor have the time and finances available to test them all out on the same input prompts and compare the outputs, will understandably struggle to make sense of the bewildering array of options. &lt;/p&gt;



&lt;p&gt;That could mean they’re missing out on smarter, more intelligent, or more capable responses from ChatGPT for their task at hand. And in the case of fields like medicine, as Roon alluded to, the difference could be one of life or death. &lt;/p&gt;



&lt;p&gt;It’s also interesting to speculate on how an automatic LLM router might change public perceptions toward and adoption of AI more broadly. &lt;/p&gt;



&lt;p&gt;ChatGPT already counted 500 million active users as of March. If more of these people were automatically guided toward more intelligent and capable LLMs to handle their AI queries, the impact of AI on their workloads and that of the entire global economy would seem likely to be felt far more acutely, creating a positive “snowball” effect.&lt;/p&gt;



&lt;p&gt;That is, as more people saw more gains from ChatGPT &lt;em&gt;automatically&lt;/em&gt; choosing the right AI model for their queries, and as more enterprises reaped greater efficiency from this process, more and more individuals and organizations would likely be convinced by the utility of AI and be more willing to pay for it, and as they did so, even &lt;em&gt;more&lt;/em&gt; AI-powered workflows would spread out in the world. &lt;/p&gt;



&lt;p&gt;But right now, this is presumably all being held back a little by the fact that the ChatGPT model picker requires the user to A. know they even have a choice of models and B. have some level of informed awareness of what these models are good for. It’s all still a manually driven process. &lt;/p&gt;



&lt;p&gt;Like going to the supermarket in your town and staring at aisles of cereal and different sauces, the average ChatGPT user is currently faced with an overabundance of choice. &lt;/p&gt;



&lt;p&gt;Hopefully any hypothetical OpenAI router seamlessly helps direct them to the right model product for their needs, when they need it — like a trusty shopkeeper showing up to free you from your product paralysis.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;In the 2.5 years since OpenAI debuted ChatGPT, the number of large language models (LLMs) that the company has made available as options to power its hit chatbot has steadily grown. &lt;/p&gt;&lt;p&gt;In fact, there are now a total of 7 (!!!) different AI models that paying ChatGPT subscribers (of the $20 Plus tier and more expensive tiers) can choose between when interacting with the trusty chatbot — each with its own strengths and weaknesses.&lt;/p&gt;&lt;p&gt;But how should a user decide &lt;em&gt;which one&lt;/em&gt; to use for their particular prompt, question, or task? After all, you can only pick one at a time. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-is-help-on-the-way"&gt;Is help on the way? &lt;/h2&gt;



&lt;p&gt;Help appears to be on the way imminently from OpenAI — as reports emerged over the last few days on X from AI influencers, including OpenAI’s own researcher “Roon (@tszzl on X)” (speculated to be technical team member Tarun Gogineni) — of a new “router” function that will automatically select the best OpenAI model to respond to the user’s input on the fly, depending on the specific input’s content.&lt;/p&gt;



&lt;p&gt;As Roon posted on the social network X yesterday, July 20, 2025, in since-deleted response to influencer Lisan al Gaib’s statement that they “don’t want a model router I want to be able to select the models I use”: &lt;/p&gt;



&lt;p&gt;&lt;em&gt;“You’ll still be able to select. This is a product to make sure that doctors aren’t stuck on 4o-mini”&lt;/em&gt;&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3014510" height="600" src="https://venturebeat.com/wp-content/uploads/2025/07/GwTyIPlXYAAu-uj-1.jpg?w=439" width="439" /&gt;&lt;/figure&gt;



&lt;p&gt;Similarly, Yuchen Jin, Co-founder &amp;amp; CTO of AI inference cloud provider Hyperbolic Labs, wrote in an X post on July 19.&lt;/p&gt;



&lt;p&gt;“&lt;em&gt;Heard GPT-5 is imminent, from a little bird.&lt;/em&gt;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;em&gt;It’s not one model, but multiple models. It has a router that switches between reasoning, non-reasoning, and tool-using models.&lt;/em&gt;&lt;/li&gt;



&lt;li&gt;&lt;em&gt;That’s why Sam said they’d “fix model naming”: prompts will just auto-route to the right model.&lt;/em&gt;&lt;/li&gt;



&lt;li&gt;&lt;em&gt;GPT-6 is in training.&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;&lt;em&gt;I just hope they’re not delaying it for more safety tests. :)&lt;/em&gt;“&lt;/p&gt;



&lt;p&gt;While a presumably far more advanced GPT-5 model would (and will) be huge news if and when released, the router may make life much easier and more intelligent for the average ChatGPT subscriber.&lt;/p&gt;



&lt;p&gt;It would also follow on the heels of other third-party products such as the web-based Token Monster chatbot, which automatically select and combine responses from multiple third-party LLMs to respond to user queries.&lt;/p&gt;



&lt;p&gt;Asked about the router idea and comments from “Roon,” an OpenAI spokesperson declined to provide a response or further information at this time.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-solving-the-overabundance-of-choice-problem"&gt;Solving the overabundance of choice problem&lt;/h2&gt;



&lt;p&gt;To be clear, every time OpenAI has released a new LLM to the public, it has diligently shared in either a blog post or release notes or both what it thinks that particular model is good for and designed to help with. &lt;/p&gt;



&lt;p&gt;For example, OpenAI’s “o” series reasoning models — o3, o4-mini, o4-mini high — have performed better on math, science, and coding tests thanks to benchmarking tests, while non-reasoning models like the new GPT-4.5 and 4.1 seem to do better at creative writing and communications tasks. &lt;/p&gt;



&lt;p&gt;Dedicated AI influencers and power users may understand very well what all these different models are good and not so good at.&lt;/p&gt;



&lt;p&gt;But regular users who don’t follow the industry as closely, nor have the time and finances available to test them all out on the same input prompts and compare the outputs, will understandably struggle to make sense of the bewildering array of options. &lt;/p&gt;



&lt;p&gt;That could mean they’re missing out on smarter, more intelligent, or more capable responses from ChatGPT for their task at hand. And in the case of fields like medicine, as Roon alluded to, the difference could be one of life or death. &lt;/p&gt;



&lt;p&gt;It’s also interesting to speculate on how an automatic LLM router might change public perceptions toward and adoption of AI more broadly. &lt;/p&gt;



&lt;p&gt;ChatGPT already counted 500 million active users as of March. If more of these people were automatically guided toward more intelligent and capable LLMs to handle their AI queries, the impact of AI on their workloads and that of the entire global economy would seem likely to be felt far more acutely, creating a positive “snowball” effect.&lt;/p&gt;



&lt;p&gt;That is, as more people saw more gains from ChatGPT &lt;em&gt;automatically&lt;/em&gt; choosing the right AI model for their queries, and as more enterprises reaped greater efficiency from this process, more and more individuals and organizations would likely be convinced by the utility of AI and be more willing to pay for it, and as they did so, even &lt;em&gt;more&lt;/em&gt; AI-powered workflows would spread out in the world. &lt;/p&gt;



&lt;p&gt;But right now, this is presumably all being held back a little by the fact that the ChatGPT model picker requires the user to A. know they even have a choice of models and B. have some level of informed awareness of what these models are good for. It’s all still a manually driven process. &lt;/p&gt;



&lt;p&gt;Like going to the supermarket in your town and staring at aisles of cereal and different sauces, the average ChatGPT user is currently faced with an overabundance of choice. &lt;/p&gt;



&lt;p&gt;Hopefully any hypothetical OpenAI router seamlessly helps direct them to the right model product for their needs, when they need it — like a trusty shopkeeper showing up to free you from your product paralysis.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/a-chatgpt-router-that-automatically-selects-the-right-openai-model-for-your-job-appears-imminent/</guid><pubDate>Mon, 21 Jul 2025 21:26:57 +0000</pubDate></item><item><title>Chinese startup Manus challenges ChatGPT in data visualization: which should enterprises use? (AI News | VentureBeat)</title><link>https://venturebeat.com/data-infrastructure/chinese-startup-manus-challenges-chatgpt-in-data-visualization-which-should-enterprises-use/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The promise sounds almost too good to be true: drop a messy comma separated values (CSV) file into an AI agent, wait two minutes, and get back a polished, interactive chart ready for your next board presentation.&amp;nbsp;&lt;/p&gt;&lt;p&gt;But that’s exactly what Chinese startup Manus.im is delivering with its latest data visualization feature, launched this month.&lt;/p&gt;&lt;p&gt;Unfortunately, my initial hands-on testing with corrupted datasets reveals a fundamental enterprise problem: impressive capabilities paired with insufficient transparency about data transformations. While Manus handles messy data better than ChatGPT, neither tool is yet ready for boardroom-ready slides.&lt;/p&gt;&lt;p&gt;Rossums’ survey of 470 finance leaders found 58% still rely primarily on Excel for monthly KPIs, despite owning BI licenses. Another TechRadar study estimates that overall spreadsheet dependence affects roughly 90% of organizations — creating a “last-mile data problem” between governed warehouses and hasty CSV exports that land in analysts’ inboxes hours before critical meetings.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Manus targets this exact gap. Upload your CSV, describe what you want in natural language, and the agent automatically cleans the data, selects the appropriate Vega-Lite grammar and returns a PNG chart ready for export—no pivot tables required.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-where-manus-beats-chatgpt-4x-slower-but-more-accurate-with-messy-data"&gt;&lt;strong&gt;Where Manus beats ChatGPT: 4x slower but more accurate with messy data&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;I tested both Manus and ChatGPT’s Advanced Data Analysis using three datasets (113k-row ecommerce orders, 200k-row marketing funnel 10k-row SaaS MRR), first clean, then corrupted with 5% error injection including nulls, mixed-format dates and duplicates.&amp;nbsp;&lt;/p&gt;



&lt;pre class="wp-block-code"&gt;&lt;code&gt;&lt;em&gt;For example, testing the same prompt — "Show me a month-by-month revenue trend for the past year and highlight any unusual spikes or dips" — across clean and corrupted 113k-row e-commerce data revealed some stark differences.&lt;/em&gt;&lt;/code&gt;&lt;/pre&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Tool&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Data Quality&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Time&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Cleans Nulls&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Parses Dates&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Handles Duplicates&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Comments&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Manus&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Clean&lt;/td&gt;&lt;td&gt;1:46&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;Correct trend, standard presentation, but incorrect numbers&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Manus&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Messy&lt;/td&gt;&lt;td&gt;3:53&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;Correct trend despite inaccurate data&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Clean&lt;/td&gt;&lt;td&gt;0:57&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;Fast, but incorrect visualisation&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Messy&lt;/td&gt;&lt;td&gt;0:59&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;Incorrect trend from unclean data&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;For context: DeepSeek could only handle 1% of the file size, while Claude and Grok took over 5 minutes each but produced interactive charts without PNG export options.&lt;/p&gt;



&lt;p&gt;Outputs:&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfKenGDQXNL_jetGvVaGrepD6NcUte0ZC8DeY72J21kaBV16Hi5TXXwjUac4DRtBUl6pFdpnZar7-vpLoL0zwjNmwqaFpqOV5SgpnKB5yV1-owJ_QxptzymJD62KmPY_AjcHyWblQ?key=vduzeoXrGmKjIlhAx_veeQ" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdywoF1plESYtTHNj-8a5TWumO5E3micqtckYEnvYZaaVsDimEBx-qS2REpo6S5jJiKZLl1K_5rbfYVjfc26l9-Vy-sKjYzbB9VPghMR9ZxLncjRq-TkfhfXSJx6dj-G7b8Wxtptw?key=vduzeoXrGmKjIlhAx_veeQ" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Figure 1-2: Chart outputs from the same revenue trend prompt on messy e-commerce data. Manus (bottom) produces a coherent trend despite data corruption, while ChatGPT (top) shows distorted patterns from unclean date formatting. &lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Manus behaves like a cautious junior analyst&lt;/strong&gt; — automatically tidying data before charting, successfully parsing date inconsistencies and handling nulls without explicit instructions. When I requested the same revenue trend analysis on corrupted data, Manus took nearly 4 minutes but produced a coherent visualization despite the data quality issues.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ChatGPT operates like a speed coder&lt;/strong&gt; — prioritizing fast output over data hygiene. The same request took just 59 seconds but produced misleading visualizations because it didn’t automatically clean formatting inconsistencies.&lt;/p&gt;



&lt;p&gt;However, both tools failed in terms of “executive readiness.” Neither produced board-ready axis scaling or readable labels without follow-up prompts. Data labels were frequently overlapping or too small, bar charts lacked proper gridlines and number formatting was inconsistent.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-transparency-crisis-enterprises-can-t-ignore"&gt;&lt;strong&gt;The transparency crisis enterprises can’t ignore&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Here’s where Manus becomes problematic for enterprise adoption: &lt;strong&gt;the agent never surfaces cleaning steps it applies&lt;/strong&gt;. An auditor reviewing the final chart has no way to confirm whether outliers were dropped, imputed or transformed.&lt;/p&gt;



&lt;p&gt;When a CFO presents quarterly results based on a Manus-generated chart, what happens when someone asks, “How did you handle the duplicate transactions from the Q2 system integration?” The answer is silence.&lt;/p&gt;



&lt;p&gt;ChatGPT, Claude and Grok all show their Python code, though transparency through code review isn’t scalable for business users lacking programming experience. What enterprises need is a simpler audit trail, which builds trust.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-warehouse-native-ai-is-racing-ahead"&gt;&lt;strong&gt;Warehouse-native AI is racing ahead&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;While Manus focuses on CSV uploads, major platforms are building chart generation directly into enterprise data infrastructure:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Google’s Gemini in BigQuery&lt;/strong&gt; became generally available in August 2024, enabling the generation of SQL queries and inline visualizations on live tables while respecting row-level security.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Microsoft’s Copilot in Fabric&lt;/strong&gt; reached GA in the Power BI experience in May 2024, creating visuals inside Fabric notebooks while working directly with Lakehouse datasets.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GoodData’s AI Assistant&lt;/strong&gt;, launched in June 2025, operates within customer environments and respects existing semantic models, allowing users to ask questions in plain language while receiving answers that align with predefined metrics and business terms.&lt;/p&gt;



&lt;p&gt;These warehouse-native solutions eliminate CSV exports entirely, preserve complete data lineage and leverage existing security models — advantages file-upload tools like Manus struggle to match.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-critical-gaps-for-enterprise-adoption"&gt;&lt;strong&gt;Critical gaps for enterprise adoption&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;My testing revealed several blockers:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Live data connectivity&lt;/strong&gt; remains absent — Manus supports file uploads only, with no Snowflake, BigQuery or S3 connectors. Manus.im says connectors are “on the roadmap” but offers no timeline.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Audit trail transparency&lt;/strong&gt; is completely missing. Enterprise data teams need transformation logs showing exactly how AI cleaned their data and whether its interpretation of the fields are correct.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Export flexibility&lt;/strong&gt; is limited to PNG outputs. While adequate for quick slide decks, enterprises need customizable, interactive export options.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-verdict-impressive-tech-premature-for-enterprise-use-cases-nbsp"&gt;&lt;strong&gt;The verdict: impressive tech, premature for enterprise use cases&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;For SMB executives drowning in ad-hoc CSV analysis, Manus’s drag-and-drop visualisation seems to be doing the job.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The autonomous data cleaning handles real-world messiness that would otherwise require manual preprocessing, cutting turnaround from hours to minutes when you have reasonably complete data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Additionally, it offers a significant runtime advantage over Excel or Google Sheets, which require manual pivots and incur substantial load times due to local compute power limitations.&lt;/p&gt;



&lt;p&gt;But regulated enterprises with governed data lakes should wait for warehouse-native agents like Gemini or Fabric Copilot, which keep data inside security perimeters and maintain complete lineage tracking.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Bottom line:&lt;/strong&gt; Manus proves one-prompt charting works and handles messy data impressively. But for enterprises, the question isn’t whether the charts look good — it’s whether you can stake your career on data transformations you can’t audit or verify. Until AI agents can plug directly into governed tables with rigorous audit trails, Excel will continue to hold its starring role in quarterly presentations.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The promise sounds almost too good to be true: drop a messy comma separated values (CSV) file into an AI agent, wait two minutes, and get back a polished, interactive chart ready for your next board presentation.&amp;nbsp;&lt;/p&gt;&lt;p&gt;But that’s exactly what Chinese startup Manus.im is delivering with its latest data visualization feature, launched this month.&lt;/p&gt;&lt;p&gt;Unfortunately, my initial hands-on testing with corrupted datasets reveals a fundamental enterprise problem: impressive capabilities paired with insufficient transparency about data transformations. While Manus handles messy data better than ChatGPT, neither tool is yet ready for boardroom-ready slides.&lt;/p&gt;&lt;p&gt;Rossums’ survey of 470 finance leaders found 58% still rely primarily on Excel for monthly KPIs, despite owning BI licenses. Another TechRadar study estimates that overall spreadsheet dependence affects roughly 90% of organizations — creating a “last-mile data problem” between governed warehouses and hasty CSV exports that land in analysts’ inboxes hours before critical meetings.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Manus targets this exact gap. Upload your CSV, describe what you want in natural language, and the agent automatically cleans the data, selects the appropriate Vega-Lite grammar and returns a PNG chart ready for export—no pivot tables required.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-where-manus-beats-chatgpt-4x-slower-but-more-accurate-with-messy-data"&gt;&lt;strong&gt;Where Manus beats ChatGPT: 4x slower but more accurate with messy data&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;I tested both Manus and ChatGPT’s Advanced Data Analysis using three datasets (113k-row ecommerce orders, 200k-row marketing funnel 10k-row SaaS MRR), first clean, then corrupted with 5% error injection including nulls, mixed-format dates and duplicates.&amp;nbsp;&lt;/p&gt;



&lt;pre class="wp-block-code"&gt;&lt;code&gt;&lt;em&gt;For example, testing the same prompt — "Show me a month-by-month revenue trend for the past year and highlight any unusual spikes or dips" — across clean and corrupted 113k-row e-commerce data revealed some stark differences.&lt;/em&gt;&lt;/code&gt;&lt;/pre&gt;



&lt;figure class="wp-block-table"&gt;&lt;table class="has-fixed-layout"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Tool&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Data Quality&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Time&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Cleans Nulls&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Parses Dates&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Handles Duplicates&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;&lt;strong&gt;Comments&lt;/strong&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Manus&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Clean&lt;/td&gt;&lt;td&gt;1:46&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;Correct trend, standard presentation, but incorrect numbers&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;Manus&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Messy&lt;/td&gt;&lt;td&gt;3:53&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;Correct trend despite inaccurate data&amp;nbsp;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Clean&lt;/td&gt;&lt;td&gt;0:57&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;✓&lt;/td&gt;&lt;td&gt;N/A&lt;/td&gt;&lt;td&gt;Fast, but incorrect visualisation&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td&gt;&lt;strong&gt;ChatGPT&lt;/strong&gt;&lt;/td&gt;&lt;td&gt;Messy&lt;/td&gt;&lt;td&gt;0:59&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;✗&lt;/td&gt;&lt;td&gt;Incorrect trend from unclean data&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;



&lt;p&gt;For context: DeepSeek could only handle 1% of the file size, while Claude and Grok took over 5 minutes each but produced interactive charts without PNG export options.&lt;/p&gt;



&lt;p&gt;Outputs:&lt;/p&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXfKenGDQXNL_jetGvVaGrepD6NcUte0ZC8DeY72J21kaBV16Hi5TXXwjUac4DRtBUl6pFdpnZar7-vpLoL0zwjNmwqaFpqOV5SgpnKB5yV1-owJ_QxptzymJD62KmPY_AjcHyWblQ?key=vduzeoXrGmKjIlhAx_veeQ" /&gt;&lt;/figure&gt;



&lt;figure class="wp-block-image"&gt;&lt;img alt="alt" src="https://lh7-rt.googleusercontent.com/docsz/AD_4nXdywoF1plESYtTHNj-8a5TWumO5E3micqtckYEnvYZaaVsDimEBx-qS2REpo6S5jJiKZLl1K_5rbfYVjfc26l9-Vy-sKjYzbB9VPghMR9ZxLncjRq-TkfhfXSJx6dj-G7b8Wxtptw?key=vduzeoXrGmKjIlhAx_veeQ" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;Figure 1-2: Chart outputs from the same revenue trend prompt on messy e-commerce data. Manus (bottom) produces a coherent trend despite data corruption, while ChatGPT (top) shows distorted patterns from unclean date formatting. &lt;/em&gt;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Manus behaves like a cautious junior analyst&lt;/strong&gt; — automatically tidying data before charting, successfully parsing date inconsistencies and handling nulls without explicit instructions. When I requested the same revenue trend analysis on corrupted data, Manus took nearly 4 minutes but produced a coherent visualization despite the data quality issues.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;ChatGPT operates like a speed coder&lt;/strong&gt; — prioritizing fast output over data hygiene. The same request took just 59 seconds but produced misleading visualizations because it didn’t automatically clean formatting inconsistencies.&lt;/p&gt;



&lt;p&gt;However, both tools failed in terms of “executive readiness.” Neither produced board-ready axis scaling or readable labels without follow-up prompts. Data labels were frequently overlapping or too small, bar charts lacked proper gridlines and number formatting was inconsistent.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-transparency-crisis-enterprises-can-t-ignore"&gt;&lt;strong&gt;The transparency crisis enterprises can’t ignore&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Here’s where Manus becomes problematic for enterprise adoption: &lt;strong&gt;the agent never surfaces cleaning steps it applies&lt;/strong&gt;. An auditor reviewing the final chart has no way to confirm whether outliers were dropped, imputed or transformed.&lt;/p&gt;



&lt;p&gt;When a CFO presents quarterly results based on a Manus-generated chart, what happens when someone asks, “How did you handle the duplicate transactions from the Q2 system integration?” The answer is silence.&lt;/p&gt;



&lt;p&gt;ChatGPT, Claude and Grok all show their Python code, though transparency through code review isn’t scalable for business users lacking programming experience. What enterprises need is a simpler audit trail, which builds trust.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-warehouse-native-ai-is-racing-ahead"&gt;&lt;strong&gt;Warehouse-native AI is racing ahead&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;While Manus focuses on CSV uploads, major platforms are building chart generation directly into enterprise data infrastructure:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Google’s Gemini in BigQuery&lt;/strong&gt; became generally available in August 2024, enabling the generation of SQL queries and inline visualizations on live tables while respecting row-level security.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Microsoft’s Copilot in Fabric&lt;/strong&gt; reached GA in the Power BI experience in May 2024, creating visuals inside Fabric notebooks while working directly with Lakehouse datasets.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;GoodData’s AI Assistant&lt;/strong&gt;, launched in June 2025, operates within customer environments and respects existing semantic models, allowing users to ask questions in plain language while receiving answers that align with predefined metrics and business terms.&lt;/p&gt;



&lt;p&gt;These warehouse-native solutions eliminate CSV exports entirely, preserve complete data lineage and leverage existing security models — advantages file-upload tools like Manus struggle to match.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-critical-gaps-for-enterprise-adoption"&gt;&lt;strong&gt;Critical gaps for enterprise adoption&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;My testing revealed several blockers:&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Live data connectivity&lt;/strong&gt; remains absent — Manus supports file uploads only, with no Snowflake, BigQuery or S3 connectors. Manus.im says connectors are “on the roadmap” but offers no timeline.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Audit trail transparency&lt;/strong&gt; is completely missing. Enterprise data teams need transformation logs showing exactly how AI cleaned their data and whether its interpretation of the fields are correct.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Export flexibility&lt;/strong&gt; is limited to PNG outputs. While adequate for quick slide decks, enterprises need customizable, interactive export options.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-verdict-impressive-tech-premature-for-enterprise-use-cases-nbsp"&gt;&lt;strong&gt;The verdict: impressive tech, premature for enterprise use cases&amp;nbsp;&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;For SMB executives drowning in ad-hoc CSV analysis, Manus’s drag-and-drop visualisation seems to be doing the job.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The autonomous data cleaning handles real-world messiness that would otherwise require manual preprocessing, cutting turnaround from hours to minutes when you have reasonably complete data.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Additionally, it offers a significant runtime advantage over Excel or Google Sheets, which require manual pivots and incur substantial load times due to local compute power limitations.&lt;/p&gt;



&lt;p&gt;But regulated enterprises with governed data lakes should wait for warehouse-native agents like Gemini or Fabric Copilot, which keep data inside security perimeters and maintain complete lineage tracking.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Bottom line:&lt;/strong&gt; Manus proves one-prompt charting works and handles messy data impressively. But for enterprises, the question isn’t whether the charts look good — it’s whether you can stake your career on data transformations you can’t audit or verify. Until AI agents can plug directly into governed tables with rigorous audit trails, Excel will continue to hold its starring role in quarterly presentations.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/data-infrastructure/chinese-startup-manus-challenges-chatgpt-in-data-visualization-which-should-enterprises-use/</guid><pubDate>Mon, 21 Jul 2025 21:38:23 +0000</pubDate></item><item><title>Google DeepMind makes AI history with gold medal win at world’s toughest math competition (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/google-deepmind-makes-ai-history-with-gold-medal-win-at-worlds-toughest-math-competition/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google DeepMind announced Monday that an advanced version of its Gemini artificial intelligence model has officially achieved gold medal-level performance at the International Mathematical Olympiad, solving five of six exceptionally difficult problems and earning recognition as the first AI system to receive official gold-level grading from competition organizers.&lt;/p&gt;&lt;p&gt;The victory advances the field of AI reasoning and puts Google ahead in the intensifying battle between tech giants building next-generation artificial intelligence. More importantly, it demonstrates that AI can now tackle complex mathematical problems using natural language understanding rather than requiring specialized programming languages.&lt;/p&gt;&lt;p&gt;“Official results are in — Gemini achieved gold-medal level in the International Mathematical Olympiad!” Demis Hassabis, CEO of Google DeepMind, wrote on social media platform X Monday morning. “An advanced version was able to solve 5 out of 6 problems. Incredible progress.”&lt;/p&gt;&lt;p&gt;The International Mathematical Olympiad, held annually since 1959, is widely considered the world’s most prestigious mathematics competition for pre-university students. Each participating country sends six elite young mathematicians to compete in solving six exceptionally challenging problems spanning algebra, combinatorics, geometry, and number theory. Only about 8% of human participants typically earn gold medals.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-how-google-deepmind-s-gemini-deep-think-cracked-math-s-toughest-problems"&gt;How Google DeepMind’s Gemini Deep Think cracked math’s toughest problems&lt;/h2&gt;



&lt;p&gt;Google’s latest success far exceeds its 2024 performance, when the company’s combined AlphaProof and AlphaGeometry systems earned silver medal status by solving four of six problems. That earlier system required human experts to first translate natural language problems into domain-specific programming languages and then interpret the AI’s mathematical output.&lt;/p&gt;



&lt;p&gt;This year’s breakthrough came through Gemini Deep Think, an enhanced reasoning system that employs what researchers call “parallel thinking.” Unlike traditional AI models that follow a single chain of reasoning, Deep Think simultaneously explores multiple possible solutions before arriving at a final answer.&lt;/p&gt;



&lt;p&gt;“Our model operated end-to-end in natural language, producing rigorous mathematical proofs directly from the official problem descriptions,” Hassabis explained in a follow-up post on the social media site X, emphasizing that the system completed its work within the competition’s standard 4.5-hour time limit.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We achieved this year’s impressive result using an advanced version of Gemini Deep Think (an enhanced reasoning mode for complex problems). Our model operated end-to-end in natural language, producing rigorous mathematical proofs directly from the official problem descriptions –…&lt;/p&gt;— Demis Hassabis (@demishassabis) July 21, 2025&lt;/blockquote&gt; 



&lt;p&gt;The model achieved 35 out of a possible 42 points, comfortably exceeding the gold medal threshold. According to IMO President Prof. Dr. Gregor Dolinar, the solutions were “astonishing in many respects” and found to be “clear, precise and most of them easy to follow” by competition graders.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-openai-faces-backlash-for-bypassing-official-competition-rules"&gt;OpenAI faces backlash for bypassing official competition rules&lt;/h2&gt;



&lt;p&gt;The announcement comes amid growing tension in the AI industry over competitive practices and transparency. Google DeepMind’s measured approach to releasing its results has drawn praise from the AI community, particularly in contrast to rival OpenAI’s handling of similar achievements.&lt;/p&gt;



&lt;p&gt;“We didn’t announce on Friday because we respected the IMO Board’s original request that all AI labs share their results only after the official results had been verified by independent experts &amp;amp; the students had rightly received the acclamation they deserved,” Hassabis wrote, appearing to reference OpenAI’s earlier announcement of its own olympiad performance.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Btw as an aside, we didn’t announce on Friday because we respected the IMO Board's original request that all AI labs share their results only after the official results had been verified by independent experts &amp;amp; the students had rightly received the acclamation they deserved&lt;/p&gt;— Demis Hassabis (@demishassabis) July 21, 2025&lt;/blockquote&gt; 



&lt;p&gt;Social media users were quick to note the distinction. “You see? OpenAI ignored the IMO request. Shame. No class. Straight up disrespect,” wrote one user. “Google DeepMind acted with integrity, aligned with humanity.”&lt;/p&gt;



&lt;p&gt;The criticism stems from OpenAI’s decision to announce its own mathematical olympiad results without participating in the official IMO evaluation process. Instead, OpenAI had a panel of former IMO participants grade its AI’s performance, a approach that some in the community view as lacking credibility.&lt;/p&gt;



&lt;p&gt;“OpenAI is quite possibly the worst company on the planet right now,” wrote one critic, while others suggested the company needs to “take things seriously” and “be more credible.”&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;You see?&lt;/p&gt;&lt;p&gt;OpenAI ignored the IMO request. Shame. No class. Straight up disrespect. &lt;/p&gt;&lt;p&gt;Google DeepMind acted with integrity, aligned with humanity. &lt;/p&gt;&lt;p&gt;TRVTHNUKE pic.twitter.com/8LAOak6XUE&lt;/p&gt;— NIK (@ns123abc) July 21, 2025&lt;/blockquote&gt; 



&lt;h2 class="wp-block-heading" id="h-inside-the-training-methods-that-powered-gemini-s-mathematical-mastery"&gt;Inside the training methods that powered Gemini’s mathematical mastery&lt;/h2&gt;



&lt;p&gt;Google DeepMind’s success appears to stem from novel training techniques that go beyond traditional approaches. The team used advanced reinforcement learning methods designed to leverage multi-step reasoning, problem-solving, and theorem-proving data. The model was also provided access to a curated collection of high-quality mathematical solutions and received specific guidance on approaching IMO-style problems.&lt;/p&gt;



&lt;p&gt;The technical achievement impressed AI researchers who noted its broader implications. “Not just solving math… but understanding language-described problems and applying abstract logic to novel cases,” wrote AI observer Elyss Wren. “This isn’t rote memory — this is emergent cognition in motion.”&lt;/p&gt;



&lt;p&gt;Ethan Mollick, a professor at the Wharton School who studies AI, emphasized the significance of using a general-purpose model rather than specialized tools. “Increasing evidence of the ability of LLMs to generalize to novel problem solving,” he wrote, highlighting how this differs from previous approaches that required specialized mathematical software.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It wasn't just OpenAI.&lt;/p&gt;&lt;p&gt;Google also used a general purpose model to solve the very hard math problems of the International Math Olympiad in plain language. Last year they used specialized tool use&lt;/p&gt;&lt;p&gt;Increasing evidence of the ability of LLMs to generalize to novel problem solving https://t.co/Ve72fFmx2b&lt;/p&gt;— Ethan Mollick (@emollick) July 21, 2025&lt;/blockquote&gt; 



&lt;p&gt;The model demonstrated particularly impressive reasoning in one problem where many human competitors applied graduate-level mathematical concepts. According to DeepMind researcher Junehyuk Jung, Gemini “made a brilliant observation and used only elementary number theory to create a self-contained proof,” finding a more elegant solution than many human participants.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-google-deepmind-s-victory-means-for-the-200-billion-ai-race"&gt;What Google DeepMind’s victory means for the $200 billion AI race&lt;/h2&gt;



&lt;p&gt;The breakthrough comes at a critical moment in the AI industry, where companies are racing to demonstrate superior reasoning capabilities. The success has immediate practical implications: Google plans to make a version of this Deep Think model available to mathematicians for testing before rolling it out to Google AI Ultra subscribers, who pay $250 monthly for access to the company’s most advanced AI models.&lt;/p&gt;



&lt;p&gt;The timing also highlights the intensifying competition between major AI laboratories. While Google celebrated its methodical, officially-verified approach, the controversy surrounding OpenAI’s announcement reflects broader tensions about transparency and credibility in AI development.&lt;/p&gt;



&lt;p&gt;This competitive dynamic extends beyond just mathematical reasoning. Recent weeks have seen various AI companies announce breakthrough capabilities, though not all have been received positively. Elon Musk’s xAI recently launched Grok 4, which the company claimed was the “smartest AI in the world,” though leaderboard scores showed it trailing behind models from Google and OpenAI. Additionally, Grok has faced criticism for controversial features including sexualized AI companions and episodes of generating antisemitic content.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-dawn-of-ai-that-thinks-like-humans-with-real-world-consequences"&gt;The dawn of AI that thinks like humans—with real-world consequences&lt;/h2&gt;



&lt;p&gt;The mathematical olympiad victory goes beyond competitive bragging rights. Gemini’s performance demonstrates that AI systems can now match human-level reasoning in complex tasks requiring creativity, abstract thinking, and the ability to synthesize insights across multiple domains.&lt;/p&gt;



&lt;p&gt;“This is a significant advance over last year’s breakthrough result,” the DeepMind team noted in their technical announcement. The progression from requiring specialized formal languages to operating entirely in natural language suggests that AI systems are becoming more intuitive and accessible.&lt;/p&gt;



&lt;p&gt;For businesses, this development signals that AI may soon tackle complex analytical problems across various industries without requiring specialized programming or domain expertise. The ability to reason through intricate challenges using everyday language could democratize sophisticated analytical capabilities across organizations.&lt;/p&gt;



&lt;p&gt;However, questions persist about whether these reasoning capabilities will translate effectively to messier real-world challenges. The mathematical olympiad provides well-defined problems with clear success criteria — a far cry from the ambiguous, multifaceted decisions that define most business and scientific endeavors.&lt;/p&gt;



&lt;p&gt;Google DeepMind plans to return to next year’s competition “in search of a perfect score.” The company believes AI systems combining natural language fluency with rigorous reasoning “will become invaluable tools for mathematicians, scientists, engineers, and researchers, helping us advance human knowledge on the path to AGI.”&lt;/p&gt;



&lt;p&gt;But perhaps the most telling detail emerged from the competition itself: when faced with the contest’s most difficult problem, Gemini started from an incorrect hypothesis and never recovered. Only five human students solved that problem correctly. In the end, it seems, even gold medal-winning AI still has something to learn from teenage mathematicians.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Google DeepMind announced Monday that an advanced version of its Gemini artificial intelligence model has officially achieved gold medal-level performance at the International Mathematical Olympiad, solving five of six exceptionally difficult problems and earning recognition as the first AI system to receive official gold-level grading from competition organizers.&lt;/p&gt;&lt;p&gt;The victory advances the field of AI reasoning and puts Google ahead in the intensifying battle between tech giants building next-generation artificial intelligence. More importantly, it demonstrates that AI can now tackle complex mathematical problems using natural language understanding rather than requiring specialized programming languages.&lt;/p&gt;&lt;p&gt;“Official results are in — Gemini achieved gold-medal level in the International Mathematical Olympiad!” Demis Hassabis, CEO of Google DeepMind, wrote on social media platform X Monday morning. “An advanced version was able to solve 5 out of 6 problems. Incredible progress.”&lt;/p&gt;&lt;p&gt;The International Mathematical Olympiad, held annually since 1959, is widely considered the world’s most prestigious mathematics competition for pre-university students. Each participating country sends six elite young mathematicians to compete in solving six exceptionally challenging problems spanning algebra, combinatorics, geometry, and number theory. Only about 8% of human participants typically earn gold medals.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;h2 class="wp-block-heading" id="h-how-google-deepmind-s-gemini-deep-think-cracked-math-s-toughest-problems"&gt;How Google DeepMind’s Gemini Deep Think cracked math’s toughest problems&lt;/h2&gt;



&lt;p&gt;Google’s latest success far exceeds its 2024 performance, when the company’s combined AlphaProof and AlphaGeometry systems earned silver medal status by solving four of six problems. That earlier system required human experts to first translate natural language problems into domain-specific programming languages and then interpret the AI’s mathematical output.&lt;/p&gt;



&lt;p&gt;This year’s breakthrough came through Gemini Deep Think, an enhanced reasoning system that employs what researchers call “parallel thinking.” Unlike traditional AI models that follow a single chain of reasoning, Deep Think simultaneously explores multiple possible solutions before arriving at a final answer.&lt;/p&gt;



&lt;p&gt;“Our model operated end-to-end in natural language, producing rigorous mathematical proofs directly from the official problem descriptions,” Hassabis explained in a follow-up post on the social media site X, emphasizing that the system completed its work within the competition’s standard 4.5-hour time limit.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We achieved this year’s impressive result using an advanced version of Gemini Deep Think (an enhanced reasoning mode for complex problems). Our model operated end-to-end in natural language, producing rigorous mathematical proofs directly from the official problem descriptions –…&lt;/p&gt;— Demis Hassabis (@demishassabis) July 21, 2025&lt;/blockquote&gt; 



&lt;p&gt;The model achieved 35 out of a possible 42 points, comfortably exceeding the gold medal threshold. According to IMO President Prof. Dr. Gregor Dolinar, the solutions were “astonishing in many respects” and found to be “clear, precise and most of them easy to follow” by competition graders.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-openai-faces-backlash-for-bypassing-official-competition-rules"&gt;OpenAI faces backlash for bypassing official competition rules&lt;/h2&gt;



&lt;p&gt;The announcement comes amid growing tension in the AI industry over competitive practices and transparency. Google DeepMind’s measured approach to releasing its results has drawn praise from the AI community, particularly in contrast to rival OpenAI’s handling of similar achievements.&lt;/p&gt;



&lt;p&gt;“We didn’t announce on Friday because we respected the IMO Board’s original request that all AI labs share their results only after the official results had been verified by independent experts &amp;amp; the students had rightly received the acclamation they deserved,” Hassabis wrote, appearing to reference OpenAI’s earlier announcement of its own olympiad performance.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Btw as an aside, we didn’t announce on Friday because we respected the IMO Board's original request that all AI labs share their results only after the official results had been verified by independent experts &amp;amp; the students had rightly received the acclamation they deserved&lt;/p&gt;— Demis Hassabis (@demishassabis) July 21, 2025&lt;/blockquote&gt; 



&lt;p&gt;Social media users were quick to note the distinction. “You see? OpenAI ignored the IMO request. Shame. No class. Straight up disrespect,” wrote one user. “Google DeepMind acted with integrity, aligned with humanity.”&lt;/p&gt;



&lt;p&gt;The criticism stems from OpenAI’s decision to announce its own mathematical olympiad results without participating in the official IMO evaluation process. Instead, OpenAI had a panel of former IMO participants grade its AI’s performance, a approach that some in the community view as lacking credibility.&lt;/p&gt;



&lt;p&gt;“OpenAI is quite possibly the worst company on the planet right now,” wrote one critic, while others suggested the company needs to “take things seriously” and “be more credible.”&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;You see?&lt;/p&gt;&lt;p&gt;OpenAI ignored the IMO request. Shame. No class. Straight up disrespect. &lt;/p&gt;&lt;p&gt;Google DeepMind acted with integrity, aligned with humanity. &lt;/p&gt;&lt;p&gt;TRVTHNUKE pic.twitter.com/8LAOak6XUE&lt;/p&gt;— NIK (@ns123abc) July 21, 2025&lt;/blockquote&gt; 



&lt;h2 class="wp-block-heading" id="h-inside-the-training-methods-that-powered-gemini-s-mathematical-mastery"&gt;Inside the training methods that powered Gemini’s mathematical mastery&lt;/h2&gt;



&lt;p&gt;Google DeepMind’s success appears to stem from novel training techniques that go beyond traditional approaches. The team used advanced reinforcement learning methods designed to leverage multi-step reasoning, problem-solving, and theorem-proving data. The model was also provided access to a curated collection of high-quality mathematical solutions and received specific guidance on approaching IMO-style problems.&lt;/p&gt;



&lt;p&gt;The technical achievement impressed AI researchers who noted its broader implications. “Not just solving math… but understanding language-described problems and applying abstract logic to novel cases,” wrote AI observer Elyss Wren. “This isn’t rote memory — this is emergent cognition in motion.”&lt;/p&gt;



&lt;p&gt;Ethan Mollick, a professor at the Wharton School who studies AI, emphasized the significance of using a general-purpose model rather than specialized tools. “Increasing evidence of the ability of LLMs to generalize to novel problem solving,” he wrote, highlighting how this differs from previous approaches that required specialized mathematical software.&lt;/p&gt;



&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;It wasn't just OpenAI.&lt;/p&gt;&lt;p&gt;Google also used a general purpose model to solve the very hard math problems of the International Math Olympiad in plain language. Last year they used specialized tool use&lt;/p&gt;&lt;p&gt;Increasing evidence of the ability of LLMs to generalize to novel problem solving https://t.co/Ve72fFmx2b&lt;/p&gt;— Ethan Mollick (@emollick) July 21, 2025&lt;/blockquote&gt; 



&lt;p&gt;The model demonstrated particularly impressive reasoning in one problem where many human competitors applied graduate-level mathematical concepts. According to DeepMind researcher Junehyuk Jung, Gemini “made a brilliant observation and used only elementary number theory to create a self-contained proof,” finding a more elegant solution than many human participants.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-what-google-deepmind-s-victory-means-for-the-200-billion-ai-race"&gt;What Google DeepMind’s victory means for the $200 billion AI race&lt;/h2&gt;



&lt;p&gt;The breakthrough comes at a critical moment in the AI industry, where companies are racing to demonstrate superior reasoning capabilities. The success has immediate practical implications: Google plans to make a version of this Deep Think model available to mathematicians for testing before rolling it out to Google AI Ultra subscribers, who pay $250 monthly for access to the company’s most advanced AI models.&lt;/p&gt;



&lt;p&gt;The timing also highlights the intensifying competition between major AI laboratories. While Google celebrated its methodical, officially-verified approach, the controversy surrounding OpenAI’s announcement reflects broader tensions about transparency and credibility in AI development.&lt;/p&gt;



&lt;p&gt;This competitive dynamic extends beyond just mathematical reasoning. Recent weeks have seen various AI companies announce breakthrough capabilities, though not all have been received positively. Elon Musk’s xAI recently launched Grok 4, which the company claimed was the “smartest AI in the world,” though leaderboard scores showed it trailing behind models from Google and OpenAI. Additionally, Grok has faced criticism for controversial features including sexualized AI companions and episodes of generating antisemitic content.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-the-dawn-of-ai-that-thinks-like-humans-with-real-world-consequences"&gt;The dawn of AI that thinks like humans—with real-world consequences&lt;/h2&gt;



&lt;p&gt;The mathematical olympiad victory goes beyond competitive bragging rights. Gemini’s performance demonstrates that AI systems can now match human-level reasoning in complex tasks requiring creativity, abstract thinking, and the ability to synthesize insights across multiple domains.&lt;/p&gt;



&lt;p&gt;“This is a significant advance over last year’s breakthrough result,” the DeepMind team noted in their technical announcement. The progression from requiring specialized formal languages to operating entirely in natural language suggests that AI systems are becoming more intuitive and accessible.&lt;/p&gt;



&lt;p&gt;For businesses, this development signals that AI may soon tackle complex analytical problems across various industries without requiring specialized programming or domain expertise. The ability to reason through intricate challenges using everyday language could democratize sophisticated analytical capabilities across organizations.&lt;/p&gt;



&lt;p&gt;However, questions persist about whether these reasoning capabilities will translate effectively to messier real-world challenges. The mathematical olympiad provides well-defined problems with clear success criteria — a far cry from the ambiguous, multifaceted decisions that define most business and scientific endeavors.&lt;/p&gt;



&lt;p&gt;Google DeepMind plans to return to next year’s competition “in search of a perfect score.” The company believes AI systems combining natural language fluency with rigorous reasoning “will become invaluable tools for mathematicians, scientists, engineers, and researchers, helping us advance human knowledge on the path to AGI.”&lt;/p&gt;



&lt;p&gt;But perhaps the most telling detail emerged from the competition itself: when faced with the contest’s most difficult problem, Gemini started from an incorrect hypothesis and never recovered. Only five human students solved that problem correctly. In the end, it seems, even gold medal-winning AI still has something to learn from teenage mathematicians.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/google-deepmind-makes-ai-history-with-gold-medal-win-at-worlds-toughest-math-competition/</guid><pubDate>Mon, 21 Jul 2025 22:33:34 +0000</pubDate></item><item><title>Crowdstrike’s massive cyber outage 1-year later: lessons enterprises can learn to improve security (AI News | VentureBeat)</title><link>https://venturebeat.com/security/how-crowdstrikes-78-minute-outage-reshaped-enterprise-cybersecurity/</link><description>&lt;p&gt;As we wrote in our initial analysis of the CrowdStrike incident, the July 19, 2024, outage served as a stark reminder of the importance of cyber resilience. Now, one year later, both CrowdStrike and the industry have undergone significant transformation, with the catalyst being driven by 78 minutes that changed everything.&lt;/p&gt;&lt;p&gt;“The first anniversary of July 19 marks a moment that deeply impacted our customers and partners and became one of the most defining chapters in CrowdStrike’s history,” CrowdStrike’s President Mike Sentonas wrote in a blog detailing the company’s year-long journey toward enhanced resilience.&lt;/p&gt;&lt;p&gt;The numbers remain sobering: A faulty Channel File 291 update, deployed at 04:09 UTC and reverted just 78 minutes later, crashed 8.5 million Windows systems worldwide. Insurance estimates put losses at $5.4 billion for the top 500 U.S. companies alone, with aviation particularly hard hit with 5,078 flights canceled globally.&lt;/p&gt;&lt;p&gt;Steffen Schreier, senior vice president of product and portfolio at Telesign, a Proximus Global company, captures why this incident resonates a year later: “One year later, the CrowdStrike incident isn’t just remembered, it’s impossible to forget. A routine software update, deployed with no malicious intent and rolled back in just 78 minutes, still managed to take down critical infrastructure worldwide. No breach. No attack. Just one internal failure with global consequences.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;His technical analysis reveals uncomfortable truths about modern infrastructure: “That’s the real wake-up call: even companies with strong practices, a staged rollout, fast rollback, can’t outpace the risks introduced by the very infrastructure that enables rapid, cloud-native delivery. The same velocity that empowers us to ship faster also accelerates the blast radius when something goes wrong.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-understanding-what-went-wrong"&gt;&lt;strong&gt;Understanding what went wrong&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;CrowdStrike’s root cause analysis revealed a cascade of technical failures: a mismatch between input fields in their IPC Template Type, missing runtime array bounds checks and a logic error in their Content Validator. These weren’t edge cases but fundamental quality control gaps.&lt;/p&gt;



&lt;p&gt;Merritt Baer, incoming Chief Security Officer at Enkrypt AI and advisor to companies including Andesite, provides crucial context: “CrowdStrike’s outage was humbling; it reminded us that even really big, mature shops get processes wrong sometimes. This particular outcome was a coincidence on some level, but it should have never been possible. It demonstrated that they failed to instate some basic CI/CD protocols.”&lt;/p&gt;



&lt;p&gt;Her assessment is direct but fair: “Had CrowdStrike rolled out the update in sandboxes and only sent it in production in increments as is best practice, it would have been less catastrophic, if at all.”&lt;/p&gt;



&lt;p&gt;Yet Baer also recognizes CrowdStrike’s response: “CrowdStrike’s comms strategy demonstrated good executive ownership. Execs should always take ownership—it’s not the intern’s fault. If your junior operator can get it wrong, it’s my fault. It’s our fault as a company.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-leadership-s-accountability"&gt;&lt;strong&gt;Leadership’s accountability&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;George Kurtz, CrowdStrike’s founder and CEO, exemplified this ownership principle. In a LinkedIn post reflecting on the anniversary, Kurtz wrote: “One year ago, we faced a moment that tested everything: our technology, our operations, and the trust others placed in us. As founder and CEO, I took that responsibility personally. I always have and always will.”&lt;/p&gt;



&lt;p&gt;His perspective reveals how the company channeled crisis into transformation: “What defined us wasn’t that moment; it was everything that came next. From the start, our focus was clear: build an even stronger CrowdStrike, grounded in resilience, transparency, and relentless execution. Our North Star has always been our customers.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-crowdstrike-goes-all-in-on-a-new-resilient-by-design-framework"&gt;&lt;strong&gt;CrowdStrike goes all-in on a new Resilient by Design framework&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;CrowdStrike’s response centered on their Resilient by Design framework, which Sentonas describes as going beyond “quick fixes or surface-level improvements.” The framework’s three pillars, including Foundational, Adaptive and Continuous components, represent a comprehensive rethinking of how security platforms should operate.&lt;/p&gt;



&lt;p&gt;Key implementations include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Sensor Self-Recovery&lt;/strong&gt;: Automatically detects crash loops and transitions to safe mode&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;New Content Distribution System&lt;/strong&gt;: Ring-based deployment with automated safeguards&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Enhanced Customer Control&lt;/strong&gt;: Granular update management and content pinning capabilities&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Digital Operations Center&lt;/strong&gt;: Purpose-built facility for global infrastructure monitoring&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Falcon Super Lab&lt;/strong&gt;: Testing thousands of OS, kernel and hardware combinations&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;“We didn’t just add a few content configuration options,” Sentonas emphasized in his blog. “We fundamentally rethought how customers could interact with and control enterprise security platforms.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-industry-wide-supply-chain-awakening"&gt;&lt;strong&gt;Industry-wide supply chain awakening&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The incident forced a broader reckoning about vendor dependencies. Baer frames the lesson starkly: “One huge practical lesson was just that your vendors are part of your supply chain. So, as a CISO, you should test the risk to be aware of it, but simply speaking, this issue fell on the provider side of the shared responsibility model. A customer wouldn’t have controlled it.”&lt;/p&gt;



&lt;p&gt;CrowdStrike’s outage has permanently altered vendor evaluation: “I see effective CISOs and CSOs taking lessons from this, around the companies they want to work with and the security they receive as a product of doing business together. I will only ever work with companies that I respect from a security posture lens. They don’t need to be perfect, but I want to know that they are doing the right processes, over time.”&lt;/p&gt;



&lt;p&gt;Sam Curry, CISO at Zscaler, added, “What happened to CrowdStrike was unfortunate, but it could have happened to many, so perhaps we don’t put the blame on them with the benefit of hindsight. What I will say is that the world has used this to refocus and has placed more attention to resilience as a result, and that’s a win for everyone, as our collective goal is to make the internet safer and more secure for all.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-underscores-the-need-for-a-new-security-paradigm"&gt;&lt;strong&gt;Underscores the need for a new security paradigm&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Schreier’s analysis extends beyond CrowdStrike to fundamental security architecture: “Speed at scale comes at a cost. Every routine update now carries the weight of potential systemic failure. That means more than testing, it means safeguards built for resilience: layered defenses, automatic rollback paths and fail-safes that assume telemetry might disappear exactly when you need it most.”&lt;/p&gt;



&lt;p&gt;His most critical insight addresses a scenario many hadn’t considered: “And when telemetry goes dark, you need fail-safes that assume visibility might vanish.”&lt;/p&gt;



&lt;p&gt;This represents a paradigm shift. As Schreier concludes: “Because security today isn’t just about keeping attackers out—it’s about making absolutely sure your own systems never become the single point of failure.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-looking-forward-ai-and-future-challenges"&gt;&lt;strong&gt;Looking forward: AI and future challenges&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Baer sees the next evolution already emerging: “Ever since cloud has enabled us to build using infrastructure as code, but especially now that AI is enabling us to do security differently, I am looking at how infrastructure decisions are layered with autonomy from humans and AI. We can and should layer on reasoning as well as effective risk mitigation for processes like forced updates, especially at high levels of privilege.”&lt;/p&gt;



&lt;p&gt;CrowdStrike’s forward-looking initiatives include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Hiring a Chief Resilience Officer reporting directly to the CEO&lt;/li&gt;



&lt;li&gt;Project Ascent, exploring capabilities beyond kernel space&lt;/li&gt;



&lt;li&gt;Collaboration with Microsoft on the Windows Endpoint Security Platform&lt;/li&gt;



&lt;li&gt;ISO 22301 certification for business continuity management&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-a-stronger-ecosystem"&gt;&lt;strong&gt;A stronger ecosystem&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One year later, the transformation is evident. Kurtz reflects: “We’re a stronger company today than we were a year ago. The work continues. The mission endures. And we’re moving forward: stronger, smarter, and even more committed than ever.”&lt;/p&gt;



&lt;p&gt;To his credit, Kurtz also acknowledges those who stood by the company: “To every customer who stayed with us, even when it was hard, thank you for your enduring trust. To our incredible partners who stood by us and rolled up their sleeves, thank you for being our extended family.”&lt;/p&gt;



&lt;p&gt;The incident’s legacy extends far beyond CrowdStrike. Organizations now implement staged rollouts, maintain manual override capabilities and—crucially—plan for when security tools themselves might fail. Vendor relationships are evaluated with new rigor, recognizing that in our interconnected infrastructure, every component is critical.&lt;/p&gt;



&lt;p&gt;As Sentonas acknowledges: “This work isn’t finished and never will be. Resilience isn’t a milestone; it’s a discipline that requires continuous commitment and evolution.” The CrowdStrike incident of July 19, 2024, will be remembered not just for the disruption it caused but for catalyzing an industry-wide evolution toward true resilience.&lt;/p&gt;



&lt;p&gt;In facing their greatest challenge, CrowdStrike and the broader security ecosystem have emerged with a deeper understanding: protecting against threats means ensuring the protectors themselves can do no harm. That lesson, learned through 78 difficult minutes and a year of transformation, may prove to be the incident’s most valuable legacy.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;p&gt;As we wrote in our initial analysis of the CrowdStrike incident, the July 19, 2024, outage served as a stark reminder of the importance of cyber resilience. Now, one year later, both CrowdStrike and the industry have undergone significant transformation, with the catalyst being driven by 78 minutes that changed everything.&lt;/p&gt;&lt;p&gt;“The first anniversary of July 19 marks a moment that deeply impacted our customers and partners and became one of the most defining chapters in CrowdStrike’s history,” CrowdStrike’s President Mike Sentonas wrote in a blog detailing the company’s year-long journey toward enhanced resilience.&lt;/p&gt;&lt;p&gt;The numbers remain sobering: A faulty Channel File 291 update, deployed at 04:09 UTC and reverted just 78 minutes later, crashed 8.5 million Windows systems worldwide. Insurance estimates put losses at $5.4 billion for the top 500 U.S. companies alone, with aviation particularly hard hit with 5,078 flights canceled globally.&lt;/p&gt;&lt;p&gt;Steffen Schreier, senior vice president of product and portfolio at Telesign, a Proximus Global company, captures why this incident resonates a year later: “One year later, the CrowdStrike incident isn’t just remembered, it’s impossible to forget. A routine software update, deployed with no malicious intent and rolled back in just 78 minutes, still managed to take down critical infrastructure worldwide. No breach. No attack. Just one internal failure with global consequences.”&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;The AI Impact Series Returns to San Francisco - August 5&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;The next phase of AI is here - are you ready? Join leaders from Block, GSK, and SAP for an exclusive look at how autonomous agents are reshaping enterprise workflows - from real-time decision-making to end-to-end automation.&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Secure your spot now - space is limited: https://bit.ly/3GuuPLF&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;His technical analysis reveals uncomfortable truths about modern infrastructure: “That’s the real wake-up call: even companies with strong practices, a staged rollout, fast rollback, can’t outpace the risks introduced by the very infrastructure that enables rapid, cloud-native delivery. The same velocity that empowers us to ship faster also accelerates the blast radius when something goes wrong.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-understanding-what-went-wrong"&gt;&lt;strong&gt;Understanding what went wrong&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;CrowdStrike’s root cause analysis revealed a cascade of technical failures: a mismatch between input fields in their IPC Template Type, missing runtime array bounds checks and a logic error in their Content Validator. These weren’t edge cases but fundamental quality control gaps.&lt;/p&gt;



&lt;p&gt;Merritt Baer, incoming Chief Security Officer at Enkrypt AI and advisor to companies including Andesite, provides crucial context: “CrowdStrike’s outage was humbling; it reminded us that even really big, mature shops get processes wrong sometimes. This particular outcome was a coincidence on some level, but it should have never been possible. It demonstrated that they failed to instate some basic CI/CD protocols.”&lt;/p&gt;



&lt;p&gt;Her assessment is direct but fair: “Had CrowdStrike rolled out the update in sandboxes and only sent it in production in increments as is best practice, it would have been less catastrophic, if at all.”&lt;/p&gt;



&lt;p&gt;Yet Baer also recognizes CrowdStrike’s response: “CrowdStrike’s comms strategy demonstrated good executive ownership. Execs should always take ownership—it’s not the intern’s fault. If your junior operator can get it wrong, it’s my fault. It’s our fault as a company.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-leadership-s-accountability"&gt;&lt;strong&gt;Leadership’s accountability&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;George Kurtz, CrowdStrike’s founder and CEO, exemplified this ownership principle. In a LinkedIn post reflecting on the anniversary, Kurtz wrote: “One year ago, we faced a moment that tested everything: our technology, our operations, and the trust others placed in us. As founder and CEO, I took that responsibility personally. I always have and always will.”&lt;/p&gt;



&lt;p&gt;His perspective reveals how the company channeled crisis into transformation: “What defined us wasn’t that moment; it was everything that came next. From the start, our focus was clear: build an even stronger CrowdStrike, grounded in resilience, transparency, and relentless execution. Our North Star has always been our customers.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-crowdstrike-goes-all-in-on-a-new-resilient-by-design-framework"&gt;&lt;strong&gt;CrowdStrike goes all-in on a new Resilient by Design framework&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;CrowdStrike’s response centered on their Resilient by Design framework, which Sentonas describes as going beyond “quick fixes or surface-level improvements.” The framework’s three pillars, including Foundational, Adaptive and Continuous components, represent a comprehensive rethinking of how security platforms should operate.&lt;/p&gt;



&lt;p&gt;Key implementations include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;Sensor Self-Recovery&lt;/strong&gt;: Automatically detects crash loops and transitions to safe mode&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;New Content Distribution System&lt;/strong&gt;: Ring-based deployment with automated safeguards&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Enhanced Customer Control&lt;/strong&gt;: Granular update management and content pinning capabilities&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Digital Operations Center&lt;/strong&gt;: Purpose-built facility for global infrastructure monitoring&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;Falcon Super Lab&lt;/strong&gt;: Testing thousands of OS, kernel and hardware combinations&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;“We didn’t just add a few content configuration options,” Sentonas emphasized in his blog. “We fundamentally rethought how customers could interact with and control enterprise security platforms.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-industry-wide-supply-chain-awakening"&gt;&lt;strong&gt;Industry-wide supply chain awakening&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;The incident forced a broader reckoning about vendor dependencies. Baer frames the lesson starkly: “One huge practical lesson was just that your vendors are part of your supply chain. So, as a CISO, you should test the risk to be aware of it, but simply speaking, this issue fell on the provider side of the shared responsibility model. A customer wouldn’t have controlled it.”&lt;/p&gt;



&lt;p&gt;CrowdStrike’s outage has permanently altered vendor evaluation: “I see effective CISOs and CSOs taking lessons from this, around the companies they want to work with and the security they receive as a product of doing business together. I will only ever work with companies that I respect from a security posture lens. They don’t need to be perfect, but I want to know that they are doing the right processes, over time.”&lt;/p&gt;



&lt;p&gt;Sam Curry, CISO at Zscaler, added, “What happened to CrowdStrike was unfortunate, but it could have happened to many, so perhaps we don’t put the blame on them with the benefit of hindsight. What I will say is that the world has used this to refocus and has placed more attention to resilience as a result, and that’s a win for everyone, as our collective goal is to make the internet safer and more secure for all.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-underscores-the-need-for-a-new-security-paradigm"&gt;&lt;strong&gt;Underscores the need for a new security paradigm&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Schreier’s analysis extends beyond CrowdStrike to fundamental security architecture: “Speed at scale comes at a cost. Every routine update now carries the weight of potential systemic failure. That means more than testing, it means safeguards built for resilience: layered defenses, automatic rollback paths and fail-safes that assume telemetry might disappear exactly when you need it most.”&lt;/p&gt;



&lt;p&gt;His most critical insight addresses a scenario many hadn’t considered: “And when telemetry goes dark, you need fail-safes that assume visibility might vanish.”&lt;/p&gt;



&lt;p&gt;This represents a paradigm shift. As Schreier concludes: “Because security today isn’t just about keeping attackers out—it’s about making absolutely sure your own systems never become the single point of failure.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-looking-forward-ai-and-future-challenges"&gt;&lt;strong&gt;Looking forward: AI and future challenges&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Baer sees the next evolution already emerging: “Ever since cloud has enabled us to build using infrastructure as code, but especially now that AI is enabling us to do security differently, I am looking at how infrastructure decisions are layered with autonomy from humans and AI. We can and should layer on reasoning as well as effective risk mitigation for processes like forced updates, especially at high levels of privilege.”&lt;/p&gt;



&lt;p&gt;CrowdStrike’s forward-looking initiatives include:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Hiring a Chief Resilience Officer reporting directly to the CEO&lt;/li&gt;



&lt;li&gt;Project Ascent, exploring capabilities beyond kernel space&lt;/li&gt;



&lt;li&gt;Collaboration with Microsoft on the Windows Endpoint Security Platform&lt;/li&gt;



&lt;li&gt;ISO 22301 certification for business continuity management&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-a-stronger-ecosystem"&gt;&lt;strong&gt;A stronger ecosystem&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;One year later, the transformation is evident. Kurtz reflects: “We’re a stronger company today than we were a year ago. The work continues. The mission endures. And we’re moving forward: stronger, smarter, and even more committed than ever.”&lt;/p&gt;



&lt;p&gt;To his credit, Kurtz also acknowledges those who stood by the company: “To every customer who stayed with us, even when it was hard, thank you for your enduring trust. To our incredible partners who stood by us and rolled up their sleeves, thank you for being our extended family.”&lt;/p&gt;



&lt;p&gt;The incident’s legacy extends far beyond CrowdStrike. Organizations now implement staged rollouts, maintain manual override capabilities and—crucially—plan for when security tools themselves might fail. Vendor relationships are evaluated with new rigor, recognizing that in our interconnected infrastructure, every component is critical.&lt;/p&gt;



&lt;p&gt;As Sentonas acknowledges: “This work isn’t finished and never will be. Resilience isn’t a milestone; it’s a discipline that requires continuous commitment and evolution.” The CrowdStrike incident of July 19, 2024, will be remembered not just for the disruption it caused but for catalyzing an industry-wide evolution toward true resilience.&lt;/p&gt;



&lt;p&gt;In facing their greatest challenge, CrowdStrike and the broader security ecosystem have emerged with a deeper understanding: protecting against threats means ensuring the protectors themselves can do no harm. That lesson, learned through 78 difficult minutes and a year of transformation, may prove to be the incident’s most valuable legacy.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/how-crowdstrikes-78-minute-outage-reshaped-enterprise-cybersecurity/</guid><pubDate>Mon, 21 Jul 2025 22:46:41 +0000</pubDate></item><item><title>OpenAI and Google outdo the mathletes, but not each other (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/21/openai-and-google-outdo-the-mathletes-but-not-each-other/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2016/03/shutterstock_317431127.jpg?w=1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI models from OpenAI and Google DeepMind achieved gold-medal scores in the 2025 International Math Olympiad (IMO), one of the world’s oldest and most challenging high school-level math competitions, the companies independently announced in recent days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The results underscore just how fast AI systems are advancing, and yet, how evenly matched Google and OpenAI seem to be in the AI race. AI companies are competing fiercely for the public perception of being ahead in the AI race: an intangible battle of “vibes” that can have big implications for securing top AI talent. A lot of AI researchers come from backgrounds in competitive math, so benchmarks like IMO mean more than others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, Google scored a silver medal at IMO using a “formal” system, meaning it required humans to translate problems into a machine‑readable format. This year, both OpenAI and Google entered “informal” systems into the competition, which were able to ingest questions and generate proof‑based answers in natural language. Both companies claim their AI models correctly answered five out of six questions on IMO’s test, scoring higher than most high school students and Google’s AI model from last year, without requiring any human-machine translation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In interviews with TechCrunch, researchers behind OpenAI and Google’s IMO efforts claimed that these gold-medal performances represent breakthroughs around AI reasoning models in non-verifiable domains. While AI reasoning models tend to do well on questions with straightforward answers, such as simple math or coding tasks, these systems struggle on tasks with more ambiguous solutions, such as buying a great chair or helping with complex research.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Google is raising questions around how OpenAI conducted and announced its gold-medal IMO performance. After all, if you’re going to enter AI models into a math contest for high schoolers, you might as well argue like teenagers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after OpenAI announced its feat on Saturday morning, Google DeepMind’s CEO and researchers took to social media to slam OpenAI for announcing its gold medal prematurely — shortly after IMO announced which high schoolers had won the competition on Friday night — and for not having their model’s test officially evaluated by IMO.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Btw as an aside, we didn’t announce on Friday because we respected the IMO Board's original request that all AI labs share their results only after the official results had been verified by independent experts &amp;amp; the students had rightly received the acclamation they deserved&lt;/p&gt;— Demis Hassabis (@demishassabis) July 21, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Thang Luong, a Google DeepMind senior researcher and lead for the IMO project, told TechCrunch that Google waited to announce its IMO results to respect the students participating in the competition.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Luong said that Google has been working with IMO’s organizers since last year in preparation for the test and wanted to have the IMO president’s blessing and official grading before announcing its official results, which it did on Monday morning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The IMO organizers have their grading guideline,” Luong said. “So any evaluation that’s not based on that guideline could not make any claim about gold-medal level [performance].”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, a senior OpenAI researcher who worked on the IMO model, told TechCrunch that IMO reached out to OpenAI a few months ago about participating in a formal math competition, but the ChatGPT-maker declined because it was working on natural language systems that it thought were more worth pursuing. Brown says OpenAI didn’t know IMO was conducting an informal test with Google.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI says it hired third-party evaluators — three former IMO medalists who understood the grading system — to grade its AI model’s performance. After OpenAI learned of its gold-medal score, Brown said the company reached out to IMO, which then told the company to wait to announce until after IMO’s Friday night award ceremony.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;IMO did not respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google isn’t necessarily wrong here — it did go through a more official, rigorous process to achieve its gold-medal score — but the debate may miss the bigger picture: AI models from several leading AI labs are improving quickly. Countries from around the world sent their brightest students to compete at IMO this year, and just a few percent of them scored as well as OpenAI and Google’s AI models did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI used to have a significant lead over the industry, it certainly feels as though the race is more closely matched than any company would like to admit. OpenAI is expected to release GPT-5 in the coming months, and the company certainly hopes to give off the impression that it still leads the AI industry.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2016/03/shutterstock_317431127.jpg?w=1000" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI models from OpenAI and Google DeepMind achieved gold-medal scores in the 2025 International Math Olympiad (IMO), one of the world’s oldest and most challenging high school-level math competitions, the companies independently announced in recent days.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The results underscore just how fast AI systems are advancing, and yet, how evenly matched Google and OpenAI seem to be in the AI race. AI companies are competing fiercely for the public perception of being ahead in the AI race: an intangible battle of “vibes” that can have big implications for securing top AI talent. A lot of AI researchers come from backgrounds in competitive math, so benchmarks like IMO mean more than others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last year, Google scored a silver medal at IMO using a “formal” system, meaning it required humans to translate problems into a machine‑readable format. This year, both OpenAI and Google entered “informal” systems into the competition, which were able to ingest questions and generate proof‑based answers in natural language. Both companies claim their AI models correctly answered five out of six questions on IMO’s test, scoring higher than most high school students and Google’s AI model from last year, without requiring any human-machine translation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In interviews with TechCrunch, researchers behind OpenAI and Google’s IMO efforts claimed that these gold-medal performances represent breakthroughs around AI reasoning models in non-verifiable domains. While AI reasoning models tend to do well on questions with straightforward answers, such as simple math or coding tasks, these systems struggle on tasks with more ambiguous solutions, such as buying a great chair or helping with complex research.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, Google is raising questions around how OpenAI conducted and announced its gold-medal IMO performance. After all, if you’re going to enter AI models into a math contest for high schoolers, you might as well argue like teenagers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after OpenAI announced its feat on Saturday morning, Google DeepMind’s CEO and researchers took to social media to slam OpenAI for announcing its gold medal prematurely — shortly after IMO announced which high schoolers had won the competition on Friday night — and for not having their model’s test officially evaluated by IMO.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Btw as an aside, we didn’t announce on Friday because we respected the IMO Board's original request that all AI labs share their results only after the official results had been verified by independent experts &amp;amp; the students had rightly received the acclamation they deserved&lt;/p&gt;— Demis Hassabis (@demishassabis) July 21, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Thang Luong, a Google DeepMind senior researcher and lead for the IMO project, told TechCrunch that Google waited to announce its IMO results to respect the students participating in the competition.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Luong said that Google has been working with IMO’s organizers since last year in preparation for the test and wanted to have the IMO president’s blessing and official grading before announcing its official results, which it did on Monday morning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The IMO organizers have their grading guideline,” Luong said. “So any evaluation that’s not based on that guideline could not make any claim about gold-medal level [performance].”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, a senior OpenAI researcher who worked on the IMO model, told TechCrunch that IMO reached out to OpenAI a few months ago about participating in a formal math competition, but the ChatGPT-maker declined because it was working on natural language systems that it thought were more worth pursuing. Brown says OpenAI didn’t know IMO was conducting an informal test with Google.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI says it hired third-party evaluators — three former IMO medalists who understood the grading system — to grade its AI model’s performance. After OpenAI learned of its gold-medal score, Brown said the company reached out to IMO, which then told the company to wait to announce until after IMO’s Friday night award ceremony.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;IMO did not respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google isn’t necessarily wrong here — it did go through a more official, rigorous process to achieve its gold-medal score — but the debate may miss the bigger picture: AI models from several leading AI labs are improving quickly. Countries from around the world sent their brightest students to compete at IMO this year, and just a few percent of them scored as well as OpenAI and Google’s AI models did.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI used to have a significant lead over the industry, it certainly feels as though the race is more closely matched than any company would like to admit. OpenAI is expected to release GPT-5 in the coming months, and the company certainly hopes to give off the impression that it still leads the AI industry.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/21/openai-and-google-outdo-the-mathletes-but-not-each-other/</guid><pubDate>Tue, 22 Jul 2025 00:06:41 +0000</pubDate></item><item><title>[NEW] Instead of selling to Meta, AI chip startup FuriosaAI signed a huge customer (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/21/instead-of-selling-to-meta-ai-chip-startup-furiosaai-signed-a-huge-customer/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;South Korean AI chip startup FuriosaAI announced a partnership on Tuesday to supply its AI chip, RNGD, to enterprises using LG AI Research‘s recently unveiled EXAONE platform. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;RNGD is optimized for running large language models (LLMs) and just last week, the Korean tech giant  LG unveiled its next-generation hybrid AI model EXAONE 4.0. The collaboration targets key sectors, including electronics, finance, telecommunications, and biotechnology, for a range of diverse applications.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This news comes roughly three months after FuriosaAI declined Meta’s $800 million acquisition offer, opting to remain independent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal fell through due to disagreements over post-acquisition business strategy and organizational structure, rather than price issues, according to local media outlets. Meta’s interest in acquiring AI chipmakers like FuriosaAI reflects its broader strategy to reduce its reliance on third-party suppliers, such as Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked why the deal with Meta fell through, CEO of FuriosaAI June Paik told TechCrunch: “We want to continue our mission, and I think it’s an exciting opportunity at the same time. I believe it’s a very impactful contribution, both personally and for the company, to make AI computing more sustainable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With M&amp;amp;A (at least from Meta) off the table, Paik declined to specify if the startup is now in pursuit of fresh funding. &lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3029827" height="434" src="https://techcrunch.com/wp-content/uploads/2025/07/server_fc7b15.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;However, Paik says this new partnership will lead to business possibilities far beyond South Korea. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“LG AI’s EXAONE is regarded as the leading sovereign AI model in South Korea. It won’t be used just within LG. It will be one of the main AI models used in the Korean AI ecosystem. We expect there will be many demands for this EXAONE, as well as for our chip solutions in South Korea, but not only in Korea. The LG team is also partnering with and doing business with global customers. So, we also expect this to be used by those customers, including global customers,” Paik said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LG AI’s decision to adopt Furiosa’s AI chip and accelerator is notable for another reason: it’s one of the few public endorsements of a rival to Nvidia by a major enterprise, Paik said. One major reason for the win is that the startup’s hardware costs less. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had to prove that our solution not only delivers strong performance but also lowers total cost of ownership,” Paik said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;FuriosaAI claims that its RNGD accelerator outperformed competitive GPUs with LG AI Research’s EXAONE models, delivering 2.25 times better inference performance. Paik also says that LG found the FuriosaAI hardware was more energy efficiency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Furiosa’s chip is not a general GPU but was built exclusively for AI. “We can support a wide variety of AI models efficiently. But unlike GPUs, which are still fundamentally general-purpose processors, our architecture is natively built for AI computing. We do not develop our chip for rendering or mining,” Paik said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Seoul-based startup, which also operates an office in Santa Clara, has a global team of just 15 employees.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;South Korean AI chip startup FuriosaAI announced a partnership on Tuesday to supply its AI chip, RNGD, to enterprises using LG AI Research‘s recently unveiled EXAONE platform. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;RNGD is optimized for running large language models (LLMs) and just last week, the Korean tech giant  LG unveiled its next-generation hybrid AI model EXAONE 4.0. The collaboration targets key sectors, including electronics, finance, telecommunications, and biotechnology, for a range of diverse applications.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This news comes roughly three months after FuriosaAI declined Meta’s $800 million acquisition offer, opting to remain independent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deal fell through due to disagreements over post-acquisition business strategy and organizational structure, rather than price issues, according to local media outlets. Meta’s interest in acquiring AI chipmakers like FuriosaAI reflects its broader strategy to reduce its reliance on third-party suppliers, such as Nvidia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked why the deal with Meta fell through, CEO of FuriosaAI June Paik told TechCrunch: “We want to continue our mission, and I think it’s an exciting opportunity at the same time. I believe it’s a very impactful contribution, both personally and for the company, to make AI computing more sustainable.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With M&amp;amp;A (at least from Meta) off the table, Paik declined to specify if the startup is now in pursuit of fresh funding. &lt;/p&gt;

&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3029827" height="434" src="https://techcrunch.com/wp-content/uploads/2025/07/server_fc7b15.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;However, Paik says this new partnership will lead to business possibilities far beyond South Korea. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“LG AI’s EXAONE is regarded as the leading sovereign AI model in South Korea. It won’t be used just within LG. It will be one of the main AI models used in the Korean AI ecosystem. We expect there will be many demands for this EXAONE, as well as for our chip solutions in South Korea, but not only in Korea. The LG team is also partnering with and doing business with global customers. So, we also expect this to be used by those customers, including global customers,” Paik said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LG AI’s decision to adopt Furiosa’s AI chip and accelerator is notable for another reason: it’s one of the few public endorsements of a rival to Nvidia by a major enterprise, Paik said. One major reason for the win is that the startup’s hardware costs less. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had to prove that our solution not only delivers strong performance but also lowers total cost of ownership,” Paik said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;FuriosaAI claims that its RNGD accelerator outperformed competitive GPUs with LG AI Research’s EXAONE models, delivering 2.25 times better inference performance. Paik also says that LG found the FuriosaAI hardware was more energy efficiency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Furiosa’s chip is not a general GPU but was built exclusively for AI. “We can support a wide variety of AI models efficiently. But unlike GPUs, which are still fundamentally general-purpose processors, our architecture is natively built for AI computing. We do not develop our chip for rendering or mining,” Paik said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Seoul-based startup, which also operates an office in Santa Clara, has a global team of just 15 employees.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/21/instead-of-selling-to-meta-ai-chip-startup-furiosaai-signed-a-huge-customer/</guid><pubDate>Tue, 22 Jul 2025 05:00:00 +0000</pubDate></item><item><title>[NEW] Latent Labs launches web-based AI model to democratize protein design (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/21/latent-labs-launches-web-based-ai-model-to-democratize-protein-design/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/Dr-Simon-Kohl-CEO-and-Founder-of-Latent-Labs-e1739199819495.jpg?w=1199" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;About six months after coming out of stealth with $50 million in funding, Latent Labs has released a web-based AI model for programming biology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Latent Labs model has “achieved state-of-the-art on different metrics” when testing the proteins it developed in a physical lab, according to Latent Labs CEO and founder Simon Kohl, a scientist who previously co-led DeepMind’s AlphaFold’s protein design team. State-of-the-art, or SOTA, is a term often used in the AI field that represents the industry’s best performance to date on a specific task.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We have computational ways of assessing how good the designs are,” he told TechCrunch, adding that a high percentage of proteins the model creates will be viable when tested in the lab.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s foundational biology model, known as LatentX, enables academic institutions, biotech startups, and pharmaceutical companies to design novel proteins directly in their browser using natural language.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LatentX goes beyond what’s found in nature, creating entirely new molecule designs like nanobodies and antibodies with precise atomic structures. This approach can help develop new therapeutics at much faster rare.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This ability to design entirely new proteins is what distinguishes LatentX from the AlphaFold, according to Kohl.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Alpha fold is a model for protein structure prediction. So it allows you to visualize existing structures, but it doesn’t, it doesn’t let you generate new proteins,” he said. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In contrast to AI-driven drug discovery companies like Xaira, Recursion or DeepMind spinout Isomorphic Labs, which focus on developing proprietary medicines, Latent Labs’ business model involves licensing its model for use by external organizations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Not every company is in a position to build their own AI models, to have their own AI infrastructure, and to have their own AI teams,” Kohl said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While LatentX is available for free, Kohl said the company intends to eventually charge for advanced features and capabilities as they’re introduced.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Other companies providing open-sourced AI foundational models for drug discovery include Chai Discovery and EvolutionaryScale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Latent Labs is backed by Radical Ventures, Sofinnova Partners, Google’s Chief Scientist Jeff Dean, Anthropic’s CEO Dario Amodei and Eleven Labs CEO Mati Staniszewski.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/Dr-Simon-Kohl-CEO-and-Founder-of-Latent-Labs-e1739199819495.jpg?w=1199" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;About six months after coming out of stealth with $50 million in funding, Latent Labs has released a web-based AI model for programming biology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Latent Labs model has “achieved state-of-the-art on different metrics” when testing the proteins it developed in a physical lab, according to Latent Labs CEO and founder Simon Kohl, a scientist who previously co-led DeepMind’s AlphaFold’s protein design team. State-of-the-art, or SOTA, is a term often used in the AI field that represents the industry’s best performance to date on a specific task.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We have computational ways of assessing how good the designs are,” he told TechCrunch, adding that a high percentage of proteins the model creates will be viable when tested in the lab.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s foundational biology model, known as LatentX, enables academic institutions, biotech startups, and pharmaceutical companies to design novel proteins directly in their browser using natural language.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;LatentX goes beyond what’s found in nature, creating entirely new molecule designs like nanobodies and antibodies with precise atomic structures. This approach can help develop new therapeutics at much faster rare.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This ability to design entirely new proteins is what distinguishes LatentX from the AlphaFold, according to Kohl.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Alpha fold is a model for protein structure prediction. So it allows you to visualize existing structures, but it doesn’t, it doesn’t let you generate new proteins,” he said. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In contrast to AI-driven drug discovery companies like Xaira, Recursion or DeepMind spinout Isomorphic Labs, which focus on developing proprietary medicines, Latent Labs’ business model involves licensing its model for use by external organizations. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Not every company is in a position to build their own AI models, to have their own AI infrastructure, and to have their own AI teams,” Kohl said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While LatentX is available for free, Kohl said the company intends to eventually charge for advanced features and capabilities as they’re introduced.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Other companies providing open-sourced AI foundational models for drug discovery include Chai Discovery and EvolutionaryScale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Latent Labs is backed by Radical Ventures, Sofinnova Partners, Google’s Chief Scientist Jeff Dean, Anthropic’s CEO Dario Amodei and Eleven Labs CEO Mati Staniszewski.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/21/latent-labs-launches-web-based-ai-model-to-democratize-protein-design/</guid><pubDate>Tue, 22 Jul 2025 06:00:00 +0000</pubDate></item></channel></rss>