<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 16 Feb 2026 07:07:09 +0000</lastBuildDate><item><title>Anthropic and the Pentagon are reportedly arguing over Claude usage (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/anthropic-and-the-pentagon-are-reportedly-arguing-over-claude-usage/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1252170580.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Pentagon is pushing AI companies to allow the U.S. military to use their technology for “all lawful purposes,” but Anthropic is pushing back, according to a new report in Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The government is reportedly making the same demand to OpenAI, Google, and xAI. An anonymous Trump administration official told Axios that one of those companies has agreed, while the other two have supposedly shown some flexibility.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic, meanwhile, has reportedly been the most resistant. In response, the Pentagon is apparently threatening to pull the plug on its $200 million contract with the AI company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January, the Wall Street Journal reported that there was significant disagreement between Anthropic and Defense Department officials over how its Claude models could be used. The WSJ subsequently said that Claude was used in the U.S. military’s operation to capture then-Venezuelan President Nicolás Maduro.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson told Axios that the company has “not discussed the use of Claude for specific operations with the Department of War” but is instead “focused on a specific set of Usage Policy questions — namely, our hard limits around fully autonomous weapons and mass domestic surveillance.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/07/GettyImages-1252170580.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The Pentagon is pushing AI companies to allow the U.S. military to use their technology for “all lawful purposes,” but Anthropic is pushing back, according to a new report in Axios.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The government is reportedly making the same demand to OpenAI, Google, and xAI. An anonymous Trump administration official told Axios that one of those companies has agreed, while the other two have supposedly shown some flexibility.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Anthropic, meanwhile, has reportedly been the most resistant. In response, the Pentagon is apparently threatening to pull the plug on its $200 million contract with the AI company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In January, the Wall Street Journal reported that there was significant disagreement between Anthropic and Defense Department officials over how its Claude models could be used. The WSJ subsequently said that Claude was used in the U.S. military’s operation to capture then-Venezuelan President Nicolás Maduro.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic did not immediately respond to TechCrunch’s request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A company spokesperson told Axios that the company has “not discussed the use of Claude for specific operations with the Department of War” but is instead “focused on a specific set of Usage Policy questions — namely, our hard limits around fully autonomous weapons and mass domestic surveillance.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/anthropic-and-the-pentagon-are-reportedly-arguing-over-claude-usage/</guid><pubDate>Sun, 15 Feb 2026 21:11:28 +0000</pubDate></item><item><title>Longtime NPR host David Greene sues Google over NotebookLM voice (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/longtime-npr-host-david-greene-sues-google-over-notebooklm-voice/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/05/GettyImages-837551280.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;David Greene, the longtime host of NPR’s “Morning Edition,” is suing Google, alleging that the male podcast voice in the company’s NotebookLM tool is based on Greene, according to The Washington Post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greene said that after friends, family members, and coworkers began emailing him about the resemblance, he became convinced that the voice was replicating his cadence, intonation, and use of filler words like “uh.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My voice is, like, the most important part of who I am,” said Greene, who currently hosts the KCRW show “Left, Right, &amp;amp; Center.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among other features, Google’s NotebookLM allows users to generate a podcast with AI hosts. A company spokesperson told the Post that the voice used in this product is unrelated to Greene’s: “The sound of the male voice in NotebookLM’s Audio Overviews is based on a paid professional actor Google hired.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t the first dispute over AI voices resembling real people. In one notable example, OpenAI removed a ChatGPT voice after actress Scarlett Johansson complained that it was an imitation of her own.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2020/05/GettyImages-837551280.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;David Greene, the longtime host of NPR’s “Morning Edition,” is suing Google, alleging that the male podcast voice in the company’s NotebookLM tool is based on Greene, according to The Washington Post.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Greene said that after friends, family members, and coworkers began emailing him about the resemblance, he became convinced that the voice was replicating his cadence, intonation, and use of filler words like “uh.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“My voice is, like, the most important part of who I am,” said Greene, who currently hosts the KCRW show “Left, Right, &amp;amp; Center.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Among other features, Google’s NotebookLM allows users to generate a podcast with AI hosts. A company spokesperson told the Post that the voice used in this product is unrelated to Greene’s: “The sound of the male voice in NotebookLM’s Audio Overviews is based on a paid professional actor Google hired.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This isn’t the first dispute over AI voices resembling real people. In one notable example, OpenAI removed a ChatGPT voice after actress Scarlett Johansson complained that it was an imitation of her own.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/longtime-npr-host-david-greene-sues-google-over-notebooklm-voice/</guid><pubDate>Sun, 15 Feb 2026 22:07:51 +0000</pubDate></item><item><title>OpenClaw creator Peter Steinberger joins OpenAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-1396827010.jpg?resize=1200,839" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Peter Steinberger, who created the AI personal assistant now known as OpenClaw, has joined OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously known as Clawdbot, then Moltbot, OpenClaw achieved viral popularity over the past few weeks with its promise to be the “AI that actually does things,” whether that’s managing your calendar, booking flights, or even joining a social network full of other AI assistants. (The name changed the first time after Anthropic threatened legal action over its similarity to Claude, then changed again because Steinberger liked the new name better.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post announcing his decision to join OpenAI, the Austrian developer said that while he might have been able to turn OpenClaw into a huge company, “It’s not really exciting for me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What I want is to change the world, not build a large company[,] and teaming up with OpenAI is the fastest way to bring this to everyone,” Steinberger said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman posted on X that in his new role, Steinberger will “drive the next generation of personal agents.” As for OpenClaw, Altman said it will “live in a foundation as an open source project that OpenAI will continue to support”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-1396827010.jpg?resize=1200,839" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Peter Steinberger, who created the AI personal assistant now known as OpenClaw, has joined OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Previously known as Clawdbot, then Moltbot, OpenClaw achieved viral popularity over the past few weeks with its promise to be the “AI that actually does things,” whether that’s managing your calendar, booking flights, or even joining a social network full of other AI assistants. (The name changed the first time after Anthropic threatened legal action over its similarity to Claude, then changed again because Steinberger liked the new name better.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In a blog post announcing his decision to join OpenAI, the Austrian developer said that while he might have been able to turn OpenClaw into a huge company, “It’s not really exciting for me.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What I want is to change the world, not build a large company[,] and teaming up with OpenAI is the fastest way to bring this to everyone,” Steinberger said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman posted on X that in his new role, Steinberger will “drive the next generation of personal agents.” As for OpenClaw, Altman said it will “live in a foundation as an open source project that OpenAI will continue to support”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/openclaw-creator-peter-steinberger-joins-openai/</guid><pubDate>Sun, 15 Feb 2026 22:28:02 +0000</pubDate></item><item><title>Blackstone backs Neysa in up to $1.2B financing as India pushes to build domestic AI infrastructure (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Neysa, an Indian AI infrastructure startup, has secured backing from U.S. private equity firm Blackstone as it scales domestic compute capacity amid India’s push to build homegrown AI capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blackstone and co-investors, including Teachers’ Venture Growth, TVS Capital, 360 ONE Asset, and Nexus Venture Partners, have agreed to invest up to $600 million of primary equity in Neysa, giving Blackstone a majority stake, Blackstone and Neysa told TechCrunch. The Mumbai-headquartered startup also plans to raise an additional $600 million in debt financing as it expands GPU capacity, a sharp increase from the $50 million it had raised previously.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal comes as demand for AI computing surges globally, creating supply constraints for specialized chips and data center capacity needed to train and run large models. Newer AI-focused infrastructure providers — often referred to as “neo-clouds” — have emerged to bridge that gap by offering dedicated GPU capacity and faster deployment than traditional hyperscalers, particularly for enterprises and AI labs with specific regulatory, latency, or customisation requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa operates in this emerging segment, positioning itself as a provider of customized, GPU-first infrastructure for enterprises, government agencies, and AI developers in India, where demand for local compute is still at an early but rapidly expanding stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of customers want hand-holding, and a lot of them want round-the-clock support with a 15-minute response and a couple of our resolutions. And so those are the kinds of things that we provide that some of the hyperscalers don’t,” said Neysa co-founder and CEO Sharad Sanghi.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093253" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/neysa-co-founder-ceo-sharad-sanghi.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Nesya co-founder and CEO Sharad Sanghi&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Neysa&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Ganesh Mani, a senior managing director at Blackstone Private Equity, said his firm estimates that India currently has fewer than 60,000 GPUs deployed — and it expects the figure to scale up nearly 30 times to more than two million in the coming years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That expansion is being driven by a combination of government demand, enterprises in regulated sectors such as financial services and healthcare that need to keep data local, and AI developers building models within India, Mani told TechCrunch. Global AI labs, many of which count India among their largest user bases, are also increasingly looking to deploy computing capacity closer to users to reduce latency and meet data requirements.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The investment also builds on Blackstone’s broader push into data center and AI infrastructure globally. The firm has previously backed large-scale data centre platforms such as QTS and AirTrunk, as well as specialized AI infrastructure providers including CoreWeave in the U.S. and Firmus in Australia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa develops and operates GPU-based AI infrastructure that enables enterprises, researchers, and public sector clients to train, fine-tune, and deploy AI models locally. The startup currently has about 1,200 GPUs live and plans to sharply scale that capacity, targeting deployments of more than 20,000 GPUs over time as customer demand accelerates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are seeing a demand that we are going to more than triple our capacity next year,” Sanghi said. “Some of the conversations we are having are at a fairly advanced stage; if they go through, then we could see it sooner rather than later. We could see in the next nine months.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sanghi told TechCrunch that the bulk of the new capital will be used to deploy large-scale GPU clusters, including compute, networking and storage, while a smaller portion will go toward research and development and building out Neysa’s software platforms for orchestration, observability, and security.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa aims to more than triple its revenue next year as demand for AI workloads accelerates, with ambitions to expand beyond India over time, Sanghi said. Founded in 2023, the startup employs 110 people across offices in Mumbai, Bengaluru, and Chennai.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Neysa, an Indian AI infrastructure startup, has secured backing from U.S. private equity firm Blackstone as it scales domestic compute capacity amid India’s push to build homegrown AI capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Blackstone and co-investors, including Teachers’ Venture Growth, TVS Capital, 360 ONE Asset, and Nexus Venture Partners, have agreed to invest up to $600 million of primary equity in Neysa, giving Blackstone a majority stake, Blackstone and Neysa told TechCrunch. The Mumbai-headquartered startup also plans to raise an additional $600 million in debt financing as it expands GPU capacity, a sharp increase from the $50 million it had raised previously.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The deal comes as demand for AI computing surges globally, creating supply constraints for specialized chips and data center capacity needed to train and run large models. Newer AI-focused infrastructure providers — often referred to as “neo-clouds” — have emerged to bridge that gap by offering dedicated GPU capacity and faster deployment than traditional hyperscalers, particularly for enterprises and AI labs with specific regulatory, latency, or customisation requirements.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa operates in this emerging segment, positioning itself as a provider of customized, GPU-first infrastructure for enterprises, government agencies, and AI developers in India, where demand for local compute is still at an early but rapidly expanding stage.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A lot of customers want hand-holding, and a lot of them want round-the-clock support with a 15-minute response and a couple of our resolutions. And so those are the kinds of things that we provide that some of the hyperscalers don’t,” said Neysa co-founder and CEO Sharad Sanghi.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093253" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/neysa-co-founder-ceo-sharad-sanghi.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Nesya co-founder and CEO Sharad Sanghi&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Neysa&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Ganesh Mani, a senior managing director at Blackstone Private Equity, said his firm estimates that India currently has fewer than 60,000 GPUs deployed — and it expects the figure to scale up nearly 30 times to more than two million in the coming years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That expansion is being driven by a combination of government demand, enterprises in regulated sectors such as financial services and healthcare that need to keep data local, and AI developers building models within India, Mani told TechCrunch. Global AI labs, many of which count India among their largest user bases, are also increasingly looking to deploy computing capacity closer to users to reduce latency and meet data requirements.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The investment also builds on Blackstone’s broader push into data center and AI infrastructure globally. The firm has previously backed large-scale data centre platforms such as QTS and AirTrunk, as well as specialized AI infrastructure providers including CoreWeave in the U.S. and Firmus in Australia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa develops and operates GPU-based AI infrastructure that enables enterprises, researchers, and public sector clients to train, fine-tune, and deploy AI models locally. The startup currently has about 1,200 GPUs live and plans to sharply scale that capacity, targeting deployments of more than 20,000 GPUs over time as customer demand accelerates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are seeing a demand that we are going to more than triple our capacity next year,” Sanghi said. “Some of the conversations we are having are at a fairly advanced stage; if they go through, then we could see it sooner rather than later. We could see in the next nine months.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sanghi told TechCrunch that the bulk of the new capital will be used to deploy large-scale GPU clusters, including compute, networking and storage, while a smaller portion will go toward research and development and building out Neysa’s software platforms for orchestration, observability, and security.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neysa aims to more than triple its revenue next year as demand for AI workloads accelerates, with ambitions to expand beyond India over time, Sanghi said. Founded in 2023, the startup employs 110 people across offices in Mumbai, Bengaluru, and Chennai.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/blackstone-backs-neysa-in-up-to-1-2b-financing-as-india-pushes-to-build-domestic-ai-compute/</guid><pubDate>Mon, 16 Feb 2026 00:30:00 +0000</pubDate></item><item><title>As AI data centers hit power limits, Peak XV backs Indian startup C2i to fix the bottleneck (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Power, rather than compute, is fast becoming the limiting factor in scaling AI data centers. That shift has prompted Peak XV Partners to back C2i Semiconductors, an Indian startup building plug-and-play, system-level power solutions designed to cut energy losses and improve the economics of large-scale AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;C2i (which stands for control conversion and intelligence) has raised $15 million in a Series A round led by Peak XV Partners, with participation from Yali Deeptech and TDK Ventures, bringing the two-year-old startup’s total funding to $19 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The investment comes as data-center energy demand accelerates worldwide. Electricity consumption from data centers is projected to nearly triple by 2035, per a December 2025 report from BloombergNEF, while Goldman Sachs Research estimates data-center power demand could surge 175% by 2030 from 2023 levels — the equivalent of adding another top-10 power-consuming country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of that strain comes not from generating electricity but from converting it efficiently inside data centers, where high-voltage power must be stepped down thousands of times before it reaches GPUs. This process currently wastes about 15% to 20% of energy, C2i’s co-founder and CTO Preetam Tadeparthy said in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What used to be 400 volts has already moved to 800 volts, and will likely go higher,” Tadeparthy told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2024 by former Texas Instruments power executives Ram Anant, Vikram Gakhar, Preetam Tadeparthy, and Dattatreya Suryanarayana, along with Harsha S. B and Muthusubramanian N. V, C2i is redesigning power delivery as a single, plug-and-play “grid-to-GPU” system spanning the data-center bus to the processor itself.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093188" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/c2i-founders.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;C2i co-founders Vikram Gakhar, Preetam Tadeparthy, Ram Anant, and Dattatreya Suryanarayana (Left to right)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;C2i&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;By treating power conversion, control and packaging as an integrated platform, C2i estimates it can cut end-to-end losses by around 10% — roughly 100 kilowatts saved for every megawatt consumed — with knock-on effects for cooling costs, GPU utilisation and overall data-center economics.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“All that translates directly to total cost of ownership, revenue, and profitability,” Tadeparthy said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Peak XV Partners (which split from Sequoia Capital in 2023), the attraction lies in how power costs shape the economics of AI infrastructure at scale. Rajan Anandan, the venture firm’s managing director, told TechCrunch that after the upfront capital investment in servers and facilities, energy costs become the dominant ongoing expense for data centers, making even incremental efficiency gains highly valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you can reduce energy costs by, call it, 10 to 30%, that’s like a huge number,” Anandan said. “You’re talking about tens of billions of dollars.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The claims will be tested quickly. C2i expects its first two silicon designs to return from fabrication between April and June, after which the startup plans to validate performance with data-center operators and hyperscalers that have asked to review the data, according to Tadeparthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Bengaluru-based startup has built a team of about 65 engineers and is setting up customer-facing operations in the U.S. and Taiwan as it prepares for early deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Power delivery is one of the most entrenched parts of the data-center stack, long dominated by large incumbents with deep balance sheets and years-long qualification cycles. While many newer companies focus on improving individual components, redesigning power delivery end-to-end requires coordinating silicon, packaging, and system architecture simultaneously — a capital-intensive approach that few startups attempt and one that can take years to prove in production environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anandan said the real question now is execution, noting that all startups face technology, market, and team risks when betting on how industries evolve. In C2i’s case, he said, the feedback loop should be relatively short. “We’ll know in the next six months,” said Anandan, pointing to upcoming silicon and early customer validation as the moment when the thesis will be tested.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bet also reflects how India’s semiconductor design ecosystem has matured in recent years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way you should look at semiconductors in India is, this is like 2008 e-commerce,” said Anandan. “It’s just getting started.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He pointed to the depth of engineering talent — with a growing share of global chip designers based in the country — alongside government-backed design-linked incentives that have lowered the cost and risk of tape-outs, making it increasingly viable for startups to build globally competitive semiconductor products from India rather than operate only as captive design centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether those conditions translate into a globally competitive product will become clearer over the coming months, as C2i begins validating its system-level power solutions with customers.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Power, rather than compute, is fast becoming the limiting factor in scaling AI data centers. That shift has prompted Peak XV Partners to back C2i Semiconductors, an Indian startup building plug-and-play, system-level power solutions designed to cut energy losses and improve the economics of large-scale AI infrastructure.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;C2i (which stands for control conversion and intelligence) has raised $15 million in a Series A round led by Peak XV Partners, with participation from Yali Deeptech and TDK Ventures, bringing the two-year-old startup’s total funding to $19 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The investment comes as data-center energy demand accelerates worldwide. Electricity consumption from data centers is projected to nearly triple by 2035, per a December 2025 report from BloombergNEF, while Goldman Sachs Research estimates data-center power demand could surge 175% by 2030 from 2023 levels — the equivalent of adding another top-10 power-consuming country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Much of that strain comes not from generating electricity but from converting it efficiently inside data centers, where high-voltage power must be stepped down thousands of times before it reaches GPUs. This process currently wastes about 15% to 20% of energy, C2i’s co-founder and CTO Preetam Tadeparthy said in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“What used to be 400 volts has already moved to 800 volts, and will likely go higher,” Tadeparthy told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Founded in 2024 by former Texas Instruments power executives Ram Anant, Vikram Gakhar, Preetam Tadeparthy, and Dattatreya Suryanarayana, along with Harsha S. B and Muthusubramanian N. V, C2i is redesigning power delivery as a single, plug-and-play “grid-to-GPU” system spanning the data-center bus to the processor itself.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="alt" class="wp-image-3093188" height="1280" src="https://techcrunch.com/wp-content/uploads/2026/02/c2i-founders.jpg" width="1920" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;C2i co-founders Vikram Gakhar, Preetam Tadeparthy, Ram Anant, and Dattatreya Suryanarayana (Left to right)&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;C2i&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;By treating power conversion, control and packaging as an integrated platform, C2i estimates it can cut end-to-end losses by around 10% — roughly 100 kilowatts saved for every megawatt consumed — with knock-on effects for cooling costs, GPU utilisation and overall data-center economics.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“All that translates directly to total cost of ownership, revenue, and profitability,” Tadeparthy said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Peak XV Partners (which split from Sequoia Capital in 2023), the attraction lies in how power costs shape the economics of AI infrastructure at scale. Rajan Anandan, the venture firm’s managing director, told TechCrunch that after the upfront capital investment in servers and facilities, energy costs become the dominant ongoing expense for data centers, making even incremental efficiency gains highly valuable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you can reduce energy costs by, call it, 10 to 30%, that’s like a huge number,” Anandan said. “You’re talking about tens of billions of dollars.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The claims will be tested quickly. C2i expects its first two silicon designs to return from fabrication between April and June, after which the startup plans to validate performance with data-center operators and hyperscalers that have asked to review the data, according to Tadeparthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Bengaluru-based startup has built a team of about 65 engineers and is setting up customer-facing operations in the U.S. and Taiwan as it prepares for early deployments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Power delivery is one of the most entrenched parts of the data-center stack, long dominated by large incumbents with deep balance sheets and years-long qualification cycles. While many newer companies focus on improving individual components, redesigning power delivery end-to-end requires coordinating silicon, packaging, and system architecture simultaneously — a capital-intensive approach that few startups attempt and one that can take years to prove in production environments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anandan said the real question now is execution, noting that all startups face technology, market, and team risks when betting on how industries evolve. In C2i’s case, he said, the feedback loop should be relatively short. “We’ll know in the next six months,” said Anandan, pointing to upcoming silicon and early customer validation as the moment when the thesis will be tested.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The bet also reflects how India’s semiconductor design ecosystem has matured in recent years.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The way you should look at semiconductors in India is, this is like 2008 e-commerce,” said Anandan. “It’s just getting started.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He pointed to the depth of engineering talent — with a growing share of global chip designers based in the country — alongside government-backed design-linked incentives that have lowered the cost and risk of tape-outs, making it increasingly viable for startups to build globally competitive semiconductor products from India rather than operate only as captive design centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Whether those conditions translate into a globally competitive product will become clearer over the coming months, as C2i begins validating its system-level power solutions with customers.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/15/as-ai-data-centers-hit-power-limits-peak-xv-backs-indian-startup-c2i-to-fix-the-bottleneck/</guid><pubDate>Mon, 16 Feb 2026 01:00:00 +0000</pubDate></item></channel></rss>