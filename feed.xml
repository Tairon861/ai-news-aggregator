<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 03 Sep 2025 06:29:45 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>OpenAI acquires product testing startup Statsig and shakes up its leadership team (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/openai-acquires-product-testing-startup-statsig-and-shakes-up-its-leadership-team/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced in a blog post on Tuesday that it agreed to acquire the product testing startup Statsig, and bring on its founder and CEO, Vijaye Raji, as the company’s CTO of Applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is paying $1.1 billion for Statsig in an all-stock deal — one of the largest acquisitions ever for the ChatGPT maker — under the company’s current $300 billion valuation, OpenAI spokesperson Kayla Wood told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The acquisition marks OpenAI’s latest effort to build out its Applications business, helmed by the former CEO of Instacart, Fidji Simo, who started work at the company a few weeks ago. Raji will report to Simo and will head product engineering for ChatGPT, the company’s AI coding tool Codex, and future applications that OpenAI plans to build. The company says that bringing Statsig’s experimentation platform in-house will accelerate product development across the Applications organization.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Raji comes on board, OpenAI is making changes to its leadership team. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s chief product officer, Kevin Weil, will become VP of a new group called OpenAI for Science, he announced in a post on LinkedIn. Weil says the goal of his new organization “is to build the next great scientific instrument: an AI-powered platform that accelerates scientific discovery.” Weil says he will work closely with Sebastien Bubeck, an OpenAI researcher and the former VP of AI and Distinguished Scientist at Microsoft.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m able to do this because the product and design leaders at OpenAI are amazing, and now are complemented by Fidji Simo beginning her role as CEO of Applications,” said Weil. “OpenAI’s products have been my life since I joined, and they’re in great hands.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, OpenAI’s current head of engineering, Srinivas Narayanan, announced in a post on LinkedIn that he would transition to a new role as the company’s CTO of B2B applications. In the role, Narayanan says he will collaborate directly with OpenAI’s COO, Brad Lightcap, who oversees many of the company’s relationships with enterprise customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says the Statsig acquisition is pending regulatory review. Once completed, the company says that all Statsig employees will become OpenAI employees. However, the product testing startup will “continue operating independently and serving its customer base out of its Seattle office,” the company said in their blog post.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/12/GettyImages-2021258442.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI announced in a blog post on Tuesday that it agreed to acquire the product testing startup Statsig, and bring on its founder and CEO, Vijaye Raji, as the company’s CTO of Applications.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is paying $1.1 billion for Statsig in an all-stock deal — one of the largest acquisitions ever for the ChatGPT maker — under the company’s current $300 billion valuation, OpenAI spokesperson Kayla Wood told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The acquisition marks OpenAI’s latest effort to build out its Applications business, helmed by the former CEO of Instacart, Fidji Simo, who started work at the company a few weeks ago. Raji will report to Simo and will head product engineering for ChatGPT, the company’s AI coding tool Codex, and future applications that OpenAI plans to build. The company says that bringing Statsig’s experimentation platform in-house will accelerate product development across the Applications organization.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Raji comes on board, OpenAI is making changes to its leadership team. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company’s chief product officer, Kevin Weil, will become VP of a new group called OpenAI for Science, he announced in a post on LinkedIn. Weil says the goal of his new organization “is to build the next great scientific instrument: an AI-powered platform that accelerates scientific discovery.” Weil says he will work closely with Sebastien Bubeck, an OpenAI researcher and the former VP of AI and Distinguished Scientist at Microsoft.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I’m able to do this because the product and design leaders at OpenAI are amazing, and now are complemented by Fidji Simo beginning her role as CEO of Applications,” said Weil. “OpenAI’s products have been my life since I joined, and they’re in great hands.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, OpenAI’s current head of engineering, Srinivas Narayanan, announced in a post on LinkedIn that he would transition to a new role as the company’s CTO of B2B applications. In the role, Narayanan says he will collaborate directly with OpenAI’s COO, Brad Lightcap, who oversees many of the company’s relationships with enterprise customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says the Statsig acquisition is pending regulatory review. Once completed, the company says that all Statsig employees will become OpenAI employees. However, the product testing startup will “continue operating independently and serving its customer base out of its Seattle office,” the company said in their blog post.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/openai-acquires-product-testing-startup-statsig-and-shakes-up-its-leadership-team/</guid><pubDate>Tue, 02 Sep 2025 19:04:05 +0000</pubDate></item><item><title>Tesla has a new master plan—it just doesn’t have any specifics (AI – Ars Technica)</title><link>https://arstechnica.com/cars/2025/09/tesla-has-a-new-master-plan-it-just-doesnt-have-any-specifics/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Did an AI write this? Because it reads like an AI wrote this.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Concept of Creative Ideas and Innovation. Flow chart of converting ideas into action and implementation." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1074291718-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Concept of Creative Ideas and Innovation. Flow chart of converting ideas into action and implementation." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1074291718-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Yesterday afternoon, while much of the country enjoyed Labor Day, Tesla CEO Elon Musk published a new master plan for the company to his social media platform. It's the fourth such document for Tesla, replacing the goals Musk laid out in 2023 when he said the company would sell 20 million EVs a year in 2030. This time, it is not entirely sure what Tesla's plan actually entails. The text, which reads as though it was written by AI, is at times anodyne, at times confusing, but always free of specifics.&lt;/p&gt;
&lt;p&gt;Each iteration of the master plan is Tesla's north star, the new plan reads, promising to "to deliver unconstrained sustainability without compromise," whatever that actually means.&lt;/p&gt;
&lt;p&gt;"Now, we are combining our manufacturing capabilities with our autonomous prowess to deliver new products and services that will accelerate global prosperity and human thriving driven by economic growth shared by all," reads the plan.&lt;/p&gt;
&lt;p&gt;This is an interesting statement considering each time Tesla has tried to build a new model the result has been months and months of "production difficulties," not to mention the multiple federal safety investigations into the company's autonomous and partially automated driving systems.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Tesla also disbanded the team building its "Dojo" supercomputer several weeks ago. Much touted by Musk in the past as the key to beating autonomous vehicle developers like Waymo (which has already deployed commercially in several cities), Tesla will no longer rely on this in-house resource and instead rely on external companies, according to Bloomberg.&lt;/p&gt;
&lt;p&gt;"Shortages in resources can be remedied by improved technology, greater innovation and new ideas," the plan continues.&lt;/p&gt;
&lt;p&gt;Then plan veers into corporate buzzwords, with statements like "[o]ur desire to push beyond what is considered achievable will foster the growth needed for truly sustainable abundance."&lt;/p&gt;
&lt;p&gt;In keeping with Musk's recent robot obsession, there's very little mention of Tesla electric vehicles other than a brief mention of autonomous vehicles, but there is quite a lot of text devoted to the company's humanoid robot. "Jobs and tasks that are particularly monotonous or dangerous can now be accomplished by other means," it states, blithely eliding the fact that it makes very little sense to compromise an industrial robot with a bipedal humanoid body, as evinced by the non-humanoid form factors of just about every industrial robot working today. Robot arms mounted to the floor don’t need to worry about balance, nor do quadraped robots with wheels.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Did an AI write this? Because it reads like an AI wrote this.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Concept of Creative Ideas and Innovation. Flow chart of converting ideas into action and implementation." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1074291718-640x427.jpg" width="640" /&gt;
                  &lt;img alt="Concept of Creative Ideas and Innovation. Flow chart of converting ideas into action and implementation." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1074291718-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Yesterday afternoon, while much of the country enjoyed Labor Day, Tesla CEO Elon Musk published a new master plan for the company to his social media platform. It's the fourth such document for Tesla, replacing the goals Musk laid out in 2023 when he said the company would sell 20 million EVs a year in 2030. This time, it is not entirely sure what Tesla's plan actually entails. The text, which reads as though it was written by AI, is at times anodyne, at times confusing, but always free of specifics.&lt;/p&gt;
&lt;p&gt;Each iteration of the master plan is Tesla's north star, the new plan reads, promising to "to deliver unconstrained sustainability without compromise," whatever that actually means.&lt;/p&gt;
&lt;p&gt;"Now, we are combining our manufacturing capabilities with our autonomous prowess to deliver new products and services that will accelerate global prosperity and human thriving driven by economic growth shared by all," reads the plan.&lt;/p&gt;
&lt;p&gt;This is an interesting statement considering each time Tesla has tried to build a new model the result has been months and months of "production difficulties," not to mention the multiple federal safety investigations into the company's autonomous and partially automated driving systems.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Tesla also disbanded the team building its "Dojo" supercomputer several weeks ago. Much touted by Musk in the past as the key to beating autonomous vehicle developers like Waymo (which has already deployed commercially in several cities), Tesla will no longer rely on this in-house resource and instead rely on external companies, according to Bloomberg.&lt;/p&gt;
&lt;p&gt;"Shortages in resources can be remedied by improved technology, greater innovation and new ideas," the plan continues.&lt;/p&gt;
&lt;p&gt;Then plan veers into corporate buzzwords, with statements like "[o]ur desire to push beyond what is considered achievable will foster the growth needed for truly sustainable abundance."&lt;/p&gt;
&lt;p&gt;In keeping with Musk's recent robot obsession, there's very little mention of Tesla electric vehicles other than a brief mention of autonomous vehicles, but there is quite a lot of text devoted to the company's humanoid robot. "Jobs and tasks that are particularly monotonous or dangerous can now be accomplished by other means," it states, blithely eliding the fact that it makes very little sense to compromise an industrial robot with a bipedal humanoid body, as evinced by the non-humanoid form factors of just about every industrial robot working today. Robot arms mounted to the floor don’t need to worry about balance, nor do quadraped robots with wheels.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/cars/2025/09/tesla-has-a-new-master-plan-it-just-doesnt-have-any-specifics/</guid><pubDate>Tue, 02 Sep 2025 19:25:00 +0000</pubDate></item><item><title>Amazon launches Lens Live, an AI-powered shopping tool for use in the real world (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/amazon-launches-lens-live-an-ai-powered-shopping-tool-for-use-in-the-real-world/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon is further investing in AI-powered shopping experiences with Tuesday’s launch of Lens Live, a new AI-powered upgrade to its Amazon Lens shopping feature that allows consumers to discover new products through visual search, similar to competitors like Google Lens and Pinterest Lens. The tool will also integrate with Amazon’s AI shopping assistant, Rufus, for product insights, the retailer notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lens Live will not replace Amazon’s existing visual search tool, Amazon Lens, which lets you take a picture, upload an image, or scan a barcode to discover products. Instead, it brings a real-time component to Amazon Lens so you can point your phone at things you’re seeing in the real world to see matching products in a swipeable carousel at the bottom of the screen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition is one of several ways Amazon has been leveraging AI to help online shoppers. Over the past year or so, the company has also rolled out other features like its AI assistant Rufus, AI-powered shopping guides, AI-enhanced product reviews, AI tools for finding clothes that fit, AI audio product summaries, personalized shopping prompts, as well as tools for merchants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lens Live also capitalizes on activities customers are already doing: comparison shopping while in retail stores out in the real world to see if Amazon has a better deal on the same or similar item.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3041652" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/download-1.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When using the new Lens Live feature, customers can tap on any item in their camera view to trigger the feature to focus on that product. If they find a match they like, they can add it to their shopping cart by tapping the (+) plus icon or tap the heart icon to save it to their wish list.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is powered by&amp;nbsp;Amazon SageMaker&amp;nbsp;services, which allow machine learning models to be deployed at scale. It runs on AWS-managed Amazon OpenSearch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Amazon’s AI-powered shopping assistant Rufus is available in the new experience, allowing customers to see AI-generated product summaries and suggested questions of conversational prompts they can ask to learn more about the item. According to Amazon, this lets shoppers do some quick product research and view product insights before making a purchase.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Lens Live feature is first launching on the Amazon Shopping app on iOS, initially for “tens of millions” of U.S. shoppers before rolling out to others in the U.S. The company didn’t say whether it’s going to expand to other global markets.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon is further investing in AI-powered shopping experiences with Tuesday’s launch of Lens Live, a new AI-powered upgrade to its Amazon Lens shopping feature that allows consumers to discover new products through visual search, similar to competitors like Google Lens and Pinterest Lens. The tool will also integrate with Amazon’s AI shopping assistant, Rufus, for product insights, the retailer notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lens Live will not replace Amazon’s existing visual search tool, Amazon Lens, which lets you take a picture, upload an image, or scan a barcode to discover products. Instead, it brings a real-time component to Amazon Lens so you can point your phone at things you’re seeing in the real world to see matching products in a swipeable carousel at the bottom of the screen.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The addition is one of several ways Amazon has been leveraging AI to help online shoppers. Over the past year or so, the company has also rolled out other features like its AI assistant Rufus, AI-powered shopping guides, AI-enhanced product reviews, AI tools for finding clothes that fit, AI audio product summaries, personalized shopping prompts, as well as tools for merchants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lens Live also capitalizes on activities customers are already doing: comparison shopping while in retail stores out in the real world to see if Amazon has a better deal on the same or similar item.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3041652" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/download-1.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;When using the new Lens Live feature, customers can tap on any item in their camera view to trigger the feature to focus on that product. If they find a match they like, they can add it to their shopping cart by tapping the (+) plus icon or tap the heart icon to save it to their wish list.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The feature is powered by&amp;nbsp;Amazon SageMaker&amp;nbsp;services, which allow machine learning models to be deployed at scale. It runs on AWS-managed Amazon OpenSearch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, Amazon’s AI-powered shopping assistant Rufus is available in the new experience, allowing customers to see AI-generated product summaries and suggested questions of conversational prompts they can ask to learn more about the item. According to Amazon, this lets shoppers do some quick product research and view product insights before making a purchase.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Lens Live feature is first launching on the Amazon Shopping app on iOS, initially for “tens of millions” of U.S. shoppers before rolling out to others in the U.S. The company didn’t say whether it’s going to expand to other global markets.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/amazon-launches-lens-live-an-ai-powered-shopping-tool-for-use-in-the-real-world/</guid><pubDate>Tue, 02 Sep 2025 19:42:23 +0000</pubDate></item><item><title>OpenAI to route sensitive conversations to GPT-5, introduce parental controls (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/02/openai-to-route-sensitive-conversations-to-gpt-5-introduce-parental-controls/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1922977290.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;This article has been updated with comment from lead counsel in the Raine family’s wrongful death lawsuit against OpenAI&lt;/em&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said Tuesday it plans to route sensitive conversations to reasoning models like GPT-5 and roll out parental controls within the next month — part of an ongoing response to recent safety incidents involving ChatGPT failing to detect mental distress.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new guardrails come in the aftermath of the suicide of teenager Adam Raine, who discussed self-harm and plans to end his life with ChatGPT, which even supplied him with information about specific suicide methods. Raine’s parents have filed a wrongful death lawsuit against OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post last week, OpenAI acknowledged shortcomings in its safety systems, including failures to maintain guardrails during extended conversations. Experts attribute these issues to fundamental design elements: the models’ tendency to validate user statements and their next-word prediction algorithms, which cause chatbots to follow conversational threads rather than redirect potentially harmful discussions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That tendency is displayed in the extreme in the case of Stein-Erik Soelberg, whose murder-suicide was reported on by The Wall Street Journal over the weekend. Soelberg, who had a history of mental illness, used ChatGPT to validate and fuel his paranoia that he was being targeted in a grand conspiracy. His delusions progressed so badly that he ended up killing his mother and himself last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI thinks that at least one solution to conversations that go off the rails could be to automatically reroute sensitive chats to “reasoning” models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We recently introduced a real-time router that can choose between efficient chat models and reasoning models based on the conversation context,” OpenAI wrote in a Tuesday blog post. “We’ll soon begin to route some sensitive conversations—like when our system detects signs of acute distress—to a reasoning model, like GPT‑5-thinking, so it can provide more helpful and beneficial responses, regardless of which model a person first selected.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says its GPT-5 thinking and o3 models are built to spend more time thinking for longer and reasoning through context before answering, which means they are “more resistant to adversarial prompts.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm also said it would roll out parental controls in the next month, allowing parents to link their account with their teen’s account through an email invitation. In late July, OpenAI rolled out Study Mode in ChatGPT to help students maintain critical thinking capabilities while studying, rather than tapping ChatGPT to write their essays for them. Soon, parents will be able to control how ChatGPT responds to their child with “age-appropriate model behavior rules, which are on by default.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Parents will also be able to disable features like memory and chat history, which experts say could lead to delusional thinking and other problematic behavior, including dependency and attachment issues, reinforcement of harmful thought patterns, and the illusion of thought-reading. In the case of Adam Raine, ChatGPT supplied methods to commit suicide that reflected knowledge of his hobbies, per The New York Times.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Perhaps the most important parental control that OpenAI intends to roll out is that parents can receive notifications when the system detects their teenager is in a moment of “acute distress.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI for more information about how the company is able to flag moments of acute distress in real time, how long it has had “age-appropriate model behavior rules” on by default, and whether it is exploring allowing parents to implement a time limit on teenage use of ChatGPT.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has already rolled out in-app reminders during long sessions to encourage breaks for all users, but stops short of cutting people off who might be using ChatGPT to spiral.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm says these safeguards are part of a “120-day initiative” to preview plans for improvements that OpenAI hopes to launch this year. The company also said it is partnering with experts — including ones with expertise in areas like eating disorders, substance use, and adolescent health — via its Global Physician Network and Expert Council on Well-Being and AI to help “define and measure well-being, set priorities, and design future safeguards.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI how many mental health professionals are involved in this initiative, who leads its Expert Council, and what suggestions mental health experts have made in terms of product, research, and policy decisions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jay Edelson, lead counsel in the Raine family’s wrongful death lawsuit against OpenAI, said the company’s response to ChatGPT’s ongoing safety risks has been “inadequate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“OpenAI doesn’t need an expert panel to determine that ChatGPT 4o is dangerous,” Edelson said in a statement shared with TechCrunch. “They knew that the day they launched the product, and they know it today. Nor should Sam Altman be hiding behind the company’s PR team. Sam should either unequivocally say that he believes ChatGPT is safe or immediately pull it from the market.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&amp;nbsp;and Maxwell Zeff at&amp;nbsp;maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-1922977290.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;This article has been updated with comment from lead counsel in the Raine family’s wrongful death lawsuit against OpenAI&lt;/em&gt;.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said Tuesday it plans to route sensitive conversations to reasoning models like GPT-5 and roll out parental controls within the next month — part of an ongoing response to recent safety incidents involving ChatGPT failing to detect mental distress.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new guardrails come in the aftermath of the suicide of teenager Adam Raine, who discussed self-harm and plans to end his life with ChatGPT, which even supplied him with information about specific suicide methods. Raine’s parents have filed a wrongful death lawsuit against OpenAI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a blog post last week, OpenAI acknowledged shortcomings in its safety systems, including failures to maintain guardrails during extended conversations. Experts attribute these issues to fundamental design elements: the models’ tendency to validate user statements and their next-word prediction algorithms, which cause chatbots to follow conversational threads rather than redirect potentially harmful discussions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That tendency is displayed in the extreme in the case of Stein-Erik Soelberg, whose murder-suicide was reported on by The Wall Street Journal over the weekend. Soelberg, who had a history of mental illness, used ChatGPT to validate and fuel his paranoia that he was being targeted in a grand conspiracy. His delusions progressed so badly that he ended up killing his mother and himself last month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI thinks that at least one solution to conversations that go off the rails could be to automatically reroute sensitive chats to “reasoning” models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We recently introduced a real-time router that can choose between efficient chat models and reasoning models based on the conversation context,” OpenAI wrote in a Tuesday blog post. “We’ll soon begin to route some sensitive conversations—like when our system detects signs of acute distress—to a reasoning model, like GPT‑5-thinking, so it can provide more helpful and beneficial responses, regardless of which model a person first selected.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says its GPT-5 thinking and o3 models are built to spend more time thinking for longer and reasoning through context before answering, which means they are “more resistant to adversarial prompts.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm also said it would roll out parental controls in the next month, allowing parents to link their account with their teen’s account through an email invitation. In late July, OpenAI rolled out Study Mode in ChatGPT to help students maintain critical thinking capabilities while studying, rather than tapping ChatGPT to write their essays for them. Soon, parents will be able to control how ChatGPT responds to their child with “age-appropriate model behavior rules, which are on by default.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Parents will also be able to disable features like memory and chat history, which experts say could lead to delusional thinking and other problematic behavior, including dependency and attachment issues, reinforcement of harmful thought patterns, and the illusion of thought-reading. In the case of Adam Raine, ChatGPT supplied methods to commit suicide that reflected knowledge of his hobbies, per The New York Times.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Perhaps the most important parental control that OpenAI intends to roll out is that parents can receive notifications when the system detects their teenager is in a moment of “acute distress.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI for more information about how the company is able to flag moments of acute distress in real time, how long it has had “age-appropriate model behavior rules” on by default, and whether it is exploring allowing parents to implement a time limit on teenage use of ChatGPT.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has already rolled out in-app reminders during long sessions to encourage breaks for all users, but stops short of cutting people off who might be using ChatGPT to spiral.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI firm says these safeguards are part of a “120-day initiative” to preview plans for improvements that OpenAI hopes to launch this year. The company also said it is partnering with experts — including ones with expertise in areas like eating disorders, substance use, and adolescent health — via its Global Physician Network and Expert Council on Well-Being and AI to help “define and measure well-being, set priorities, and design future safeguards.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has asked OpenAI how many mental health professionals are involved in this initiative, who leads its Expert Council, and what suggestions mental health experts have made in terms of product, research, and policy decisions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jay Edelson, lead counsel in the Raine family’s wrongful death lawsuit against OpenAI, said the company’s response to ChatGPT’s ongoing safety risks has been “inadequate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“OpenAI doesn’t need an expert panel to determine that ChatGPT 4o is dangerous,” Edelson said in a statement shared with TechCrunch. “They knew that the day they launched the product, and they know it today. Nor should Sam Altman be hiding behind the company’s PR team. Sam should either unequivocally say that he believes ChatGPT is safe or immediately pull it from the market.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;rebecca.bellan@techcrunch.com&amp;nbsp;and Maxwell Zeff at&amp;nbsp;maxwell.zeff@techcrunch.com. For secure communication, you can contact us via Signal at&amp;nbsp;@rebeccabellan.491 and&amp;nbsp;@mzeff.88.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/02/openai-to-route-sensitive-conversations-to-gpt-5-introduce-parental-controls/</guid><pubDate>Tue, 02 Sep 2025 20:13:04 +0000</pubDate></item><item><title>3 Questions: On biology and medicine’s “data revolution” (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/3-questions-caroline-uhler-biology-medicine-data-revolution-0902</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/mit-caroline-uhler.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;&lt;em&gt;Caroline Uhler is&amp;nbsp;an Andrew (1956) and Erna Viterbi Professor of Engineering at MIT; a professor of electrical engineering and computer science in the Institute for Data, Science, and Society (IDSS);&amp;nbsp;and director of the Eric and Wendy Schmidt Center at the Broad Institute of MIT and Harvard, where she is also a core institute and scientific leadership team member.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;em&gt;Uhler is interested in all the methods by which scientists can uncover causality in biological systems, ranging from causal discovery on observed variables to causal feature learning and representation learning.&amp;nbsp;In this interview, she discusses machine learning in biology, areas that are ripe for problem-solving, and cutting-edge research coming out of the Schmidt Center.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q: &lt;/strong&gt;The Eric and Wendy Schmidt Center has four distinct areas of focus structured around four natural levels of biological organization: proteins, cells, tissues, and organisms. What, within the current landscape of machine learning, makes&amp;nbsp;now the right time to work on these specific problem classes?&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;Biology and medicine are currently undergoing a “data revolution.” The availability of large-scale, diverse datasets — ranging from genomics and multi-omics to high-resolution imaging and electronic health records — makes this an opportune time. Inexpensive and accurate DNA sequencing is a reality, advanced molecular imaging has become routine, and single cell genomics is allowing the profiling of millions of cells. These innovations — and the massive datasets they produce — have brought us to the threshold of a new era in biology, one where we will be able to move beyond characterizing the units of life (such as all proteins, genes, and cell types) to understanding the `programs of life’, such as the logic of gene circuits and cell-cell communication that underlies tissue patterning and the molecular mechanisms that underlie the genotype-phenotype map.&lt;/p&gt;&lt;p dir="ltr"&gt;At the same time, in the past decade, machine learning has seen remarkable progress with models like BERT, GPT-3, and ChatGPT demonstrating advanced capabilities in text understanding and generation, while vision transformers and multimodal models like CLIP have achieved human-level performance in image-related tasks. These breakthroughs provide powerful architectural blueprints and training strategies that can be adapted to biological data. For instance, transformers can model genomic sequences similar to language, and vision models can analyze medical and microscopy images.&lt;/p&gt;&lt;p dir="ltr"&gt;Importantly, biology is poised to be not just a beneficiary of machine learning, but also a significant source of inspiration for new ML research. Much like agriculture and breeding spurred modern statistics, biology has the potential to inspire new and perhaps even more profound avenues of ML research. Unlike fields such as recommender systems and internet advertising, where there are no natural laws to discover and predictive accuracy is the ultimate measure of value, in biology, phenomena are physically interpretable, and causal mechanisms are the ultimate goal. Additionally, biology boasts genetic and chemical tools that enable perturbational screens on an unparalleled scale compared to other fields. These combined features make biology uniquely suited to both benefit greatly from ML and serve as a profound wellspring of inspiration for it.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;Taking a somewhat different tack, what problems in biology are still really resistant to our current tool set? Are there areas, perhaps specific challenges in disease or in wellness, which you feel are ripe for problem-solving?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A: &lt;/strong&gt;Machine learning has demonstrated remarkable success in predictive tasks across domains such as image classification, natural language processing, and clinical risk modeling. However, in the biological sciences, predictive accuracy is often insufficient. The fundamental questions in these fields are inherently causal: How does a perturbation to a specific gene or pathway affect downstream cellular processes? What is the mechanism by which an intervention leads to a phenotypic change? Traditional machine learning models, which are primarily optimized for capturing statistical associations in observational data, often fail to answer such interventional queries.There is a strong need for biology and medicine to also inspire new foundational developments in machine learning.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The field is now equipped with high-throughput perturbation technologies — such as pooled CRISPR screens, single-cell transcriptomics, and spatial profiling — that generate rich datasets under systematic interventions. These data modalities naturally call for the development of models that go beyond pattern recognition to support causal inference, active experimental design, and representation learning in settings with complex, structured latent variables. From a mathematical perspective, this requires tackling core questions of identifiability, sample efficiency, and the integration of combinatorial, geometric, and probabilistic tools. I believe that addressing these challenges will not only unlock new insights into the mechanisms of cellular systems, but also push the theoretical boundaries of machine learning.&lt;/p&gt;&lt;p&gt;With respect to foundation models, a consensus in the field is that we are still far from creating a holistic foundation model for biology across scales, similar to what ChatGPT represents in the language domain — a sort of digital organism capable of simulating all biological phenomena. While new foundation models emerge almost weekly, these models have thus far been specialized for a specific scale and question, and focus on one or a few modalities.&lt;/p&gt;&lt;p&gt;Significant progress has been made in predicting protein structures from their sequences. This success has highlighted the importance of iterative machine learning challenges, such as CASP (critical assessment of structure prediction), which have been instrumental in benchmarking state-of-the-art algorithms for protein structure prediction and driving their improvement.&lt;/p&gt;&lt;p&gt;The Schmidt Center is organizing challenges to increase awareness in the ML field and make progress in the development of methods to solve causal prediction problems that are so critical for the biomedical sciences. With the increasing availability of single-gene perturbation data at the single-cell level,&amp;nbsp;I believe predicting the effect of single or combinatorial perturbations, and which perturbations could drive a desired phenotype, are solvable problems. With our Cell Perturbation Prediction Challenge (CPPC), we aim to provide the means to objectively test and benchmark algorithms for predicting the effect of new perturbations.&lt;/p&gt;&lt;p&gt;Another area where the field has made remarkable strides is disease diagnostic and patient triage. Machine learning algorithms can integrate different sources of patient information (data modalities), generate missing modalities, identify patterns that may be difficult for us to detect, and help stratify patients based on their disease risk. While we must remain cautious about potential biases in model predictions, the danger of models learning shortcuts instead of true correlations, and the risk of automation bias in clinical decision-making, I believe this is an area where machine learning is already having a significant impact.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q: &lt;/strong&gt;Let’s talk about some of the&amp;nbsp;headlines coming out of the Schmidt Center recently. What current research do you think people should be particularly excited about, and why?&lt;em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A: &lt;/strong&gt;In collaboration with Dr. Fei Chen at the Broad Institute, we have recently developed a method for the prediction of unseen proteins’ subcellular location, called PUPS. Many existing methods can only make predictions based on the specific protein and cell data on which they were trained. PUPS, however, combines a protein language model with an image in-painting model to utilize both protein sequences and cellular images. We demonstrate that the protein sequence input enables generalization to unseen proteins, and the cellular image input captures single-cell variability, enabling cell-type-specific predictions. The model learns how relevant each amino acid residue is for the predicted sub-cellular localization, and it can predict changes in localization due to mutations in the protein sequences. Since proteins’ function is strictly related to their subcellular localization, our predictions could provide insights into potential mechanisms of disease. In the future, we aim to extend this method to predict the localization of multiple proteins in a cell and possibly understand protein-protein interactions.&lt;/p&gt;&lt;p&gt;Together with Professor G.V. Shivashankar, a long-time collaborator at ETH Zürich, we have previously shown how simple images of cells stained with fluorescent DNA-intercalating dyes to label the chromatin can yield a lot of information about the state and fate of a cell in health and disease, when combined with machine learning algorithms. Recently, we have furthered this observation and proved the deep link between chromatin organization and gene regulation by developing Image2Reg, a method that enables the prediction of unseen genetically or chemically perturbed genes from chromatin images. Image2Reg utilizes convolutional neural networks to learn an informative representation of the chromatin images of perturbed cells. It also employs a graph convolutional network to create a gene embedding that captures the regulatory effects of genes based on protein-protein interaction data, integrated with cell-type-specific transcriptomic data. Finally, it learns a map between the resulting physical and biochemical representation of cells, allowing us to predict the perturbed gene modules based on chromatin images.&lt;/p&gt;&lt;p&gt;Furthermore, we recently finalized the development of a method for predicting the outcomes of unseen combinatorial gene perturbations and identifying the types of interactions occurring between the perturbed genes. MORPH can guide the design of the most informative perturbations for lab-in-a-loop experiments. Furthermore, the attention-based framework provably enables our method to identify causal relations among the genes, providing insights into the underlying gene regulatory programs. Finally, thanks to its modular structure, we can apply MORPH to perturbation data measured in various modalities, including not only transcriptomics, but also imaging. We are very excited about the potential of this method to enable the efficient exploration of the perturbation space to advance our understanding of cellular programs by bridging causal theory to important applications, with implications for both basic research and therapeutic applications.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202508/mit-caroline-uhler.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;&lt;em&gt;Caroline Uhler is&amp;nbsp;an Andrew (1956) and Erna Viterbi Professor of Engineering at MIT; a professor of electrical engineering and computer science in the Institute for Data, Science, and Society (IDSS);&amp;nbsp;and director of the Eric and Wendy Schmidt Center at the Broad Institute of MIT and Harvard, where she is also a core institute and scientific leadership team member.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;em&gt;Uhler is interested in all the methods by which scientists can uncover causality in biological systems, ranging from causal discovery on observed variables to causal feature learning and representation learning.&amp;nbsp;In this interview, she discusses machine learning in biology, areas that are ripe for problem-solving, and cutting-edge research coming out of the Schmidt Center.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q: &lt;/strong&gt;The Eric and Wendy Schmidt Center has four distinct areas of focus structured around four natural levels of biological organization: proteins, cells, tissues, and organisms. What, within the current landscape of machine learning, makes&amp;nbsp;now the right time to work on these specific problem classes?&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;A: &lt;/strong&gt;Biology and medicine are currently undergoing a “data revolution.” The availability of large-scale, diverse datasets — ranging from genomics and multi-omics to high-resolution imaging and electronic health records — makes this an opportune time. Inexpensive and accurate DNA sequencing is a reality, advanced molecular imaging has become routine, and single cell genomics is allowing the profiling of millions of cells. These innovations — and the massive datasets they produce — have brought us to the threshold of a new era in biology, one where we will be able to move beyond characterizing the units of life (such as all proteins, genes, and cell types) to understanding the `programs of life’, such as the logic of gene circuits and cell-cell communication that underlies tissue patterning and the molecular mechanisms that underlie the genotype-phenotype map.&lt;/p&gt;&lt;p dir="ltr"&gt;At the same time, in the past decade, machine learning has seen remarkable progress with models like BERT, GPT-3, and ChatGPT demonstrating advanced capabilities in text understanding and generation, while vision transformers and multimodal models like CLIP have achieved human-level performance in image-related tasks. These breakthroughs provide powerful architectural blueprints and training strategies that can be adapted to biological data. For instance, transformers can model genomic sequences similar to language, and vision models can analyze medical and microscopy images.&lt;/p&gt;&lt;p dir="ltr"&gt;Importantly, biology is poised to be not just a beneficiary of machine learning, but also a significant source of inspiration for new ML research. Much like agriculture and breeding spurred modern statistics, biology has the potential to inspire new and perhaps even more profound avenues of ML research. Unlike fields such as recommender systems and internet advertising, where there are no natural laws to discover and predictive accuracy is the ultimate measure of value, in biology, phenomena are physically interpretable, and causal mechanisms are the ultimate goal. Additionally, biology boasts genetic and chemical tools that enable perturbational screens on an unparalleled scale compared to other fields. These combined features make biology uniquely suited to both benefit greatly from ML and serve as a profound wellspring of inspiration for it.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Q: &lt;/strong&gt;Taking a somewhat different tack, what problems in biology are still really resistant to our current tool set? Are there areas, perhaps specific challenges in disease or in wellness, which you feel are ripe for problem-solving?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A: &lt;/strong&gt;Machine learning has demonstrated remarkable success in predictive tasks across domains such as image classification, natural language processing, and clinical risk modeling. However, in the biological sciences, predictive accuracy is often insufficient. The fundamental questions in these fields are inherently causal: How does a perturbation to a specific gene or pathway affect downstream cellular processes? What is the mechanism by which an intervention leads to a phenotypic change? Traditional machine learning models, which are primarily optimized for capturing statistical associations in observational data, often fail to answer such interventional queries.There is a strong need for biology and medicine to also inspire new foundational developments in machine learning.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The field is now equipped with high-throughput perturbation technologies — such as pooled CRISPR screens, single-cell transcriptomics, and spatial profiling — that generate rich datasets under systematic interventions. These data modalities naturally call for the development of models that go beyond pattern recognition to support causal inference, active experimental design, and representation learning in settings with complex, structured latent variables. From a mathematical perspective, this requires tackling core questions of identifiability, sample efficiency, and the integration of combinatorial, geometric, and probabilistic tools. I believe that addressing these challenges will not only unlock new insights into the mechanisms of cellular systems, but also push the theoretical boundaries of machine learning.&lt;/p&gt;&lt;p&gt;With respect to foundation models, a consensus in the field is that we are still far from creating a holistic foundation model for biology across scales, similar to what ChatGPT represents in the language domain — a sort of digital organism capable of simulating all biological phenomena. While new foundation models emerge almost weekly, these models have thus far been specialized for a specific scale and question, and focus on one or a few modalities.&lt;/p&gt;&lt;p&gt;Significant progress has been made in predicting protein structures from their sequences. This success has highlighted the importance of iterative machine learning challenges, such as CASP (critical assessment of structure prediction), which have been instrumental in benchmarking state-of-the-art algorithms for protein structure prediction and driving their improvement.&lt;/p&gt;&lt;p&gt;The Schmidt Center is organizing challenges to increase awareness in the ML field and make progress in the development of methods to solve causal prediction problems that are so critical for the biomedical sciences. With the increasing availability of single-gene perturbation data at the single-cell level,&amp;nbsp;I believe predicting the effect of single or combinatorial perturbations, and which perturbations could drive a desired phenotype, are solvable problems. With our Cell Perturbation Prediction Challenge (CPPC), we aim to provide the means to objectively test and benchmark algorithms for predicting the effect of new perturbations.&lt;/p&gt;&lt;p&gt;Another area where the field has made remarkable strides is disease diagnostic and patient triage. Machine learning algorithms can integrate different sources of patient information (data modalities), generate missing modalities, identify patterns that may be difficult for us to detect, and help stratify patients based on their disease risk. While we must remain cautious about potential biases in model predictions, the danger of models learning shortcuts instead of true correlations, and the risk of automation bias in clinical decision-making, I believe this is an area where machine learning is already having a significant impact.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q: &lt;/strong&gt;Let’s talk about some of the&amp;nbsp;headlines coming out of the Schmidt Center recently. What current research do you think people should be particularly excited about, and why?&lt;em&gt;&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A: &lt;/strong&gt;In collaboration with Dr. Fei Chen at the Broad Institute, we have recently developed a method for the prediction of unseen proteins’ subcellular location, called PUPS. Many existing methods can only make predictions based on the specific protein and cell data on which they were trained. PUPS, however, combines a protein language model with an image in-painting model to utilize both protein sequences and cellular images. We demonstrate that the protein sequence input enables generalization to unseen proteins, and the cellular image input captures single-cell variability, enabling cell-type-specific predictions. The model learns how relevant each amino acid residue is for the predicted sub-cellular localization, and it can predict changes in localization due to mutations in the protein sequences. Since proteins’ function is strictly related to their subcellular localization, our predictions could provide insights into potential mechanisms of disease. In the future, we aim to extend this method to predict the localization of multiple proteins in a cell and possibly understand protein-protein interactions.&lt;/p&gt;&lt;p&gt;Together with Professor G.V. Shivashankar, a long-time collaborator at ETH Zürich, we have previously shown how simple images of cells stained with fluorescent DNA-intercalating dyes to label the chromatin can yield a lot of information about the state and fate of a cell in health and disease, when combined with machine learning algorithms. Recently, we have furthered this observation and proved the deep link between chromatin organization and gene regulation by developing Image2Reg, a method that enables the prediction of unseen genetically or chemically perturbed genes from chromatin images. Image2Reg utilizes convolutional neural networks to learn an informative representation of the chromatin images of perturbed cells. It also employs a graph convolutional network to create a gene embedding that captures the regulatory effects of genes based on protein-protein interaction data, integrated with cell-type-specific transcriptomic data. Finally, it learns a map between the resulting physical and biochemical representation of cells, allowing us to predict the perturbed gene modules based on chromatin images.&lt;/p&gt;&lt;p&gt;Furthermore, we recently finalized the development of a method for predicting the outcomes of unseen combinatorial gene perturbations and identifying the types of interactions occurring between the perturbed genes. MORPH can guide the design of the most informative perturbations for lab-in-a-loop experiments. Furthermore, the attention-based framework provably enables our method to identify causal relations among the genes, providing insights into the underlying gene regulatory programs. Finally, thanks to its modular structure, we can apply MORPH to perturbation data measured in various modalities, including not only transcriptomics, but also imaging. We are very excited about the potential of this method to enable the efficient exploration of the perturbation space to advance our understanding of cellular programs by bridging causal theory to important applications, with implications for both basic research and therapeutic applications.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/3-questions-caroline-uhler-biology-medicine-data-revolution-0902</guid><pubDate>Tue, 02 Sep 2025 21:45:00 +0000</pubDate></item><item><title>[NEW] 3 Questions: The pros and cons of synthetic data in AI (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/3-questions-pros-cons-synthetic-data-ai-kalyan-veeramachaneni-0903</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-3Q-Synthetic-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Synthetic data are artificially generated by algorithms to mimic the statistical properties of actual data, without containing any information from real-world sources. While concrete numbers are hard to pin down, some estimates suggest that more than 60 percent of data used for AI applications in 2024 was synthetic, and this figure is expected to grow across industries.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Because synthetic data don’t contain real-world information, they hold the promise of safeguarding privacy while reducing the cost and increasing the speed at which new AI models are developed. But&amp;nbsp;using synthetic data requires careful&amp;nbsp;evaluation, planning, and checks and balances to prevent loss of performance when AI models are deployed.&amp;nbsp;&amp;nbsp;&lt;/em&gt; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;em&gt;To unpack some pros and cons of using synthetic data,&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; spoke with Kalyan Veeramachaneni, a principal research scientist in the Laboratory for Information and Decision Systems&amp;nbsp;and co-founder of&amp;nbsp;&lt;/em&gt;&lt;em&gt;DataCebo&lt;/em&gt;&lt;em&gt;&amp;nbsp;whose open-core platform,&amp;nbsp;&lt;/em&gt;&lt;em&gt;the Synthetic Data Vault&lt;/em&gt;,&amp;nbsp;&lt;em&gt;helps&lt;/em&gt; &lt;em&gt;users generate and test synthetic data.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;How are synthetic data created?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Synthetic data are algorithmically generated but do not come from a real situation. Their value lies in their statistical similarity to real data. If we’re talking about language, for instance, synthetic data look very much as if a human had written those sentences. While researchers have created synthetic data for a long time, what has changed in the past few years is our ability to build generative models out of data and use them to create realistic synthetic data. We can take a little bit of real data and build a generative model from that, which we can use to create as much synthetic data as we want. Plus, the model creates synthetic data in a way that captures all the underlying rules and infinite patterns that exist in the real data.&lt;/p&gt;&lt;p&gt;There are essentially&amp;nbsp;four&amp;nbsp;different data modalities: language, video or images,&amp;nbsp;audio,&amp;nbsp;and tabular data. All four&amp;nbsp;of them have slightly different ways of building the generative models to create synthetic data. An LLM, for instance, is nothing but a generative model from which you are sampling synthetic data when you ask it a question.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;A lot of language and image data are publicly available on the internet. But tabular data, which is the data collected when we interact with physical and social systems, is often locked up behind enterprise firewalls. Much of it is sensitive or private, such as customer transactions stored by a bank. For this type of data, platforms like the Synthetic Data Vault provide software that can be used to build generative models. Those models then create synthetic data that preserve customer privacy and can be shared more widely.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;One powerful thing about this generative modeling approach for synthesizing data is that enterprises can now build a customized, local model for their own data. Generative AI automates what used to be a manual process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;What are some benefits of using synthetic data, and which use-cases and applications are they particularly well-suited for?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; One fundamental application which has grown tremendously over the past decade is using synthetic data to test software applications. There is data-driven logic behind many software applications, so you need data to test that software and its functionality. In the past, people have resorted to manually generating data, but now we can use generative models to create as much data as we need.&lt;/p&gt;&lt;p&gt;Users can also create specific data for application testing. Say I work for an e-commerce company. I can generate synthetic data that mimics real customers who live in Ohio and made transactions pertaining to one particular product in February or March.&lt;/p&gt;&lt;p&gt;Because synthetic data aren’t drawn from real situations, they are also privacy-preserving. One of the biggest problems in software testing has been getting access to sensitive real data for testing software in non-production environments, due to privacy concerns.&amp;nbsp;Another immediate benefit is in performance testing. You can create a billion transactions from a generative model and test how fast your system can process them.&lt;/p&gt;&lt;p&gt;Another application where synthetic data hold a lot of promise is in training machine-learning models. Sometimes, we want an AI model to help us predict an event that is less frequent. A bank may want to use an AI model to predict fraudulent transactions, but there may be too few real examples to train a model that can identify fraud accurately.&amp;nbsp;Synthetic data provide data augmentation — additional data examples that are similar to the real data. These can significantly improve the accuracy of AI models.&lt;/p&gt;&lt;p&gt;Also, sometimes users don’t have time or the financial resources to collect all the data. For instance, collecting data about customer intent would require conducting many surveys. If you end up with limited data and then try to train a model, it won’t perform well. You can augment by adding synthetic data to train those models better.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q.&amp;nbsp;&lt;/strong&gt;What are some of the risks or potential pitfalls of using synthetic data, and are there steps users can take to prevent or mitigate those problems?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A.&lt;/strong&gt; One of the biggest questions people often have in their mind is, if the data are synthetically created, why should I trust them? Determining whether you can trust the data often comes down to evaluating the overall system where you are using them.&lt;/p&gt;&lt;p&gt;There are a lot of aspects of synthetic data we have been able to evaluate for a long time. For instance, there are existing methods to measure how close synthetic data are to real data, and we can measure their quality and whether they preserve privacy. But there are other important considerations if you are using those synthetic data to train a machine-learning model for a new use case. How would you know the data are going to lead to models that still make valid conclusions?&lt;/p&gt;&lt;p&gt;New efficacy metrics are emerging, and the emphasis is now on efficacy for a particular task. You must really dig into your workflow to ensure the synthetic data you add to the system still allow you to draw valid conclusions. That is something that must be done carefully on an application-by-application basis.&lt;/p&gt;&lt;p&gt;Bias can also be an issue. Since it is created from a small amount of real data, the same bias that exists in the real data can carry over into the synthetic data. Just like with real data, you would need to purposefully make sure the bias is removed through different sampling techniques, which can create balanced datasets. It takes some careful planning, but you can calibrate the data generation to prevent the proliferation of bias.&lt;/p&gt;&lt;p&gt;To help with the evaluation process, our group created the Synthetic Data Metrics Library. We worried that people would use synthetic data in their environment and it would give different conclusions in the real world. We created a metrics and evaluation library to&amp;nbsp;ensure&amp;nbsp;checks and balances. The machine learning community has faced a lot of challenges in ensuring models can generalize to new situations. The use of synthetic data adds a whole new dimension to that problem.&lt;/p&gt;&lt;p&gt;I expect that the old systems of working with data, whether to build software applications, answer analytical questions, or train models, will dramatically change as we get more sophisticated at building these generative models. A lot of things we have never been able to do before will now be possible.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202509/MIT-3Q-Synthetic-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;&lt;em&gt;Synthetic data are artificially generated by algorithms to mimic the statistical properties of actual data, without containing any information from real-world sources. While concrete numbers are hard to pin down, some estimates suggest that more than 60 percent of data used for AI applications in 2024 was synthetic, and this figure is expected to grow across industries.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;em&gt;Because synthetic data don’t contain real-world information, they hold the promise of safeguarding privacy while reducing the cost and increasing the speed at which new AI models are developed. But&amp;nbsp;using synthetic data requires careful&amp;nbsp;evaluation, planning, and checks and balances to prevent loss of performance when AI models are deployed.&amp;nbsp;&amp;nbsp;&lt;/em&gt; &amp;nbsp; &amp;nbsp;&amp;nbsp;&lt;/p&gt;&lt;p&gt;&lt;em&gt;To unpack some pros and cons of using synthetic data,&amp;nbsp;&lt;/em&gt;MIT News&lt;em&gt; spoke with Kalyan Veeramachaneni, a principal research scientist in the Laboratory for Information and Decision Systems&amp;nbsp;and co-founder of&amp;nbsp;&lt;/em&gt;&lt;em&gt;DataCebo&lt;/em&gt;&lt;em&gt;&amp;nbsp;whose open-core platform,&amp;nbsp;&lt;/em&gt;&lt;em&gt;the Synthetic Data Vault&lt;/em&gt;,&amp;nbsp;&lt;em&gt;helps&lt;/em&gt; &lt;em&gt;users generate and test synthetic data.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&lt;/strong&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;How are synthetic data created?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; Synthetic data are algorithmically generated but do not come from a real situation. Their value lies in their statistical similarity to real data. If we’re talking about language, for instance, synthetic data look very much as if a human had written those sentences. While researchers have created synthetic data for a long time, what has changed in the past few years is our ability to build generative models out of data and use them to create realistic synthetic data. We can take a little bit of real data and build a generative model from that, which we can use to create as much synthetic data as we want. Plus, the model creates synthetic data in a way that captures all the underlying rules and infinite patterns that exist in the real data.&lt;/p&gt;&lt;p&gt;There are essentially&amp;nbsp;four&amp;nbsp;different data modalities: language, video or images,&amp;nbsp;audio,&amp;nbsp;and tabular data. All four&amp;nbsp;of them have slightly different ways of building the generative models to create synthetic data. An LLM, for instance, is nothing but a generative model from which you are sampling synthetic data when you ask it a question.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;A lot of language and image data are publicly available on the internet. But tabular data, which is the data collected when we interact with physical and social systems, is often locked up behind enterprise firewalls. Much of it is sensitive or private, such as customer transactions stored by a bank. For this type of data, platforms like the Synthetic Data Vault provide software that can be used to build generative models. Those models then create synthetic data that preserve customer privacy and can be shared more widely.&amp;nbsp;&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;One powerful thing about this generative modeling approach for synthesizing data is that enterprises can now build a customized, local model for their own data. Generative AI automates what used to be a manual process.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q:&amp;nbsp;&lt;/strong&gt;What are some benefits of using synthetic data, and which use-cases and applications are they particularly well-suited for?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A:&lt;/strong&gt; One fundamental application which has grown tremendously over the past decade is using synthetic data to test software applications. There is data-driven logic behind many software applications, so you need data to test that software and its functionality. In the past, people have resorted to manually generating data, but now we can use generative models to create as much data as we need.&lt;/p&gt;&lt;p&gt;Users can also create specific data for application testing. Say I work for an e-commerce company. I can generate synthetic data that mimics real customers who live in Ohio and made transactions pertaining to one particular product in February or March.&lt;/p&gt;&lt;p&gt;Because synthetic data aren’t drawn from real situations, they are also privacy-preserving. One of the biggest problems in software testing has been getting access to sensitive real data for testing software in non-production environments, due to privacy concerns.&amp;nbsp;Another immediate benefit is in performance testing. You can create a billion transactions from a generative model and test how fast your system can process them.&lt;/p&gt;&lt;p&gt;Another application where synthetic data hold a lot of promise is in training machine-learning models. Sometimes, we want an AI model to help us predict an event that is less frequent. A bank may want to use an AI model to predict fraudulent transactions, but there may be too few real examples to train a model that can identify fraud accurately.&amp;nbsp;Synthetic data provide data augmentation — additional data examples that are similar to the real data. These can significantly improve the accuracy of AI models.&lt;/p&gt;&lt;p&gt;Also, sometimes users don’t have time or the financial resources to collect all the data. For instance, collecting data about customer intent would require conducting many surveys. If you end up with limited data and then try to train a model, it won’t perform well. You can augment by adding synthetic data to train those models better.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Q.&amp;nbsp;&lt;/strong&gt;What are some of the risks or potential pitfalls of using synthetic data, and are there steps users can take to prevent or mitigate those problems?&lt;/p&gt;&lt;p&gt;&lt;strong&gt;A.&lt;/strong&gt; One of the biggest questions people often have in their mind is, if the data are synthetically created, why should I trust them? Determining whether you can trust the data often comes down to evaluating the overall system where you are using them.&lt;/p&gt;&lt;p&gt;There are a lot of aspects of synthetic data we have been able to evaluate for a long time. For instance, there are existing methods to measure how close synthetic data are to real data, and we can measure their quality and whether they preserve privacy. But there are other important considerations if you are using those synthetic data to train a machine-learning model for a new use case. How would you know the data are going to lead to models that still make valid conclusions?&lt;/p&gt;&lt;p&gt;New efficacy metrics are emerging, and the emphasis is now on efficacy for a particular task. You must really dig into your workflow to ensure the synthetic data you add to the system still allow you to draw valid conclusions. That is something that must be done carefully on an application-by-application basis.&lt;/p&gt;&lt;p&gt;Bias can also be an issue. Since it is created from a small amount of real data, the same bias that exists in the real data can carry over into the synthetic data. Just like with real data, you would need to purposefully make sure the bias is removed through different sampling techniques, which can create balanced datasets. It takes some careful planning, but you can calibrate the data generation to prevent the proliferation of bias.&lt;/p&gt;&lt;p&gt;To help with the evaluation process, our group created the Synthetic Data Metrics Library. We worried that people would use synthetic data in their environment and it would give different conclusions in the real world. We created a metrics and evaluation library to&amp;nbsp;ensure&amp;nbsp;checks and balances. The machine learning community has faced a lot of challenges in ensuring models can generalize to new situations. The use of synthetic data adds a whole new dimension to that problem.&lt;/p&gt;&lt;p&gt;I expect that the old systems of working with data, whether to build software applications, answer analytical questions, or train models, will dramatically change as we get more sophisticated at building these generative models. A lot of things we have never been able to do before will now be possible.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/3-questions-pros-cons-synthetic-data-ai-kalyan-veeramachaneni-0903</guid><pubDate>Wed, 03 Sep 2025 04:00:00 +0000</pubDate></item></channel></rss>