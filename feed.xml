<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 13 Aug 2025 06:34:34 +0000</lastBuildDate><item><title>Perplexity offers more than twice its total valuation to buy Chrome from Google (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/08/perplexity-offers-more-than-twice-its-total-valuation-to-buy-chrome-from-google/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google may soon be ordered to sell Chrome, and Perplexity is ready.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;In the wake of its big antitrust loss, Google could soon find itself forced to sell one of its crown jewels. Among the government's proposed remedies in the search case is a requirement that Google divest its market-leading Chrome browser, and Perplexity is already throwing its proverbial hat into the ring with a whopping $34.5 billion offer. The problem, however, is that Perplexity doesn't have nearly that much cash.&lt;/p&gt;
&lt;p&gt;Perplexity has ridden the AI hype wave, with its AI-powered search appearing on smartphones and in the company's custom Comet browser. Like any company offering an AI product, investors have been happy to throw money at Perplexity, totaling around $1 billion so far. Investors value the company at about $14 billion right now. So how does Perplexity have more than twice that to buy Chrome? That's the neat part—it doesn't.&lt;/p&gt;
&lt;p&gt;There is so much capital floating around in the artificial intelligence sphere currently that even a cash-poor firm like Perplexity can secure enough investment to splurge on Chrome. Reuters reports that the all-cash offer is funded by various venture funds, but Perplexity has not offered specifics.&lt;/p&gt;
&lt;p&gt;Throughout the remedy trial this past spring, a cavalcade of Google competitors took the stand to express interest in buying Chrome. For example, an OpenAI executive pledged to turn Chrome into an AI-first experience if that firm were able to acquire it. This testimony undercut Google's claim that no one in the industry would be able to manage the browser.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google has strenuously objected to the government's proposed Chrome divestment, which it calls "a radical interventionist agenda." Chrome isn't just a browser—it's an open source project known as Chromium, which powers numerous non-Google browsers, including Microsoft's Edge. Perplexity's offer includes $3 billion to run Chromium over two years, and it allegedly vows to keep the project fully open source. Perplexity promises it also won't enforce changes to the browser's default search engine.&lt;/p&gt;
&lt;h2&gt;An unsolicited offer&lt;/h2&gt;
&lt;p&gt;We're currently waiting on United States District Court Judge Amit Mehta to rule on remedies in the case. That could happen as soon as this month. Perplexity's offer, therefore, is somewhat timely, but there could still be a long road ahead.&lt;/p&gt;
&lt;p&gt;This is an unsolicited offer, and there's no indication that Google will jump at the chance to sell Chrome as soon as the ruling drops. Even if the court decides that Google should sell, it can probably get much, much more than Perplexity is offering. During the trial, DuckDuckGo's CEO suggested a price of around $50 billion, but other estimates have ranged into the hundreds of billions. However, the data that flows to Chrome's owner could be vital in building new AI technologies—any sale price is likely to be a net loss for Google.&lt;/p&gt;
&lt;p&gt;If Mehta decides to force a sale, there will undoubtedly be legal challenges that could take months or years to resolve. Should these maneuvers fail, there's likely to be opposition to any potential buyer. There will be many users who don't like the idea of an AI startup or an unholy alliance of venture capital firms owning Chrome. Google has been hoovering up user data with Chrome for years—but that's the devil we know.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google may soon be ordered to sell Chrome, and Perplexity is ready.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-300x200.jpg" width="300" /&gt;
                  &lt;img alt="Extreme close-up photograph of finger above Chrome icon on smartphone." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/Chrome-Getty-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;In the wake of its big antitrust loss, Google could soon find itself forced to sell one of its crown jewels. Among the government's proposed remedies in the search case is a requirement that Google divest its market-leading Chrome browser, and Perplexity is already throwing its proverbial hat into the ring with a whopping $34.5 billion offer. The problem, however, is that Perplexity doesn't have nearly that much cash.&lt;/p&gt;
&lt;p&gt;Perplexity has ridden the AI hype wave, with its AI-powered search appearing on smartphones and in the company's custom Comet browser. Like any company offering an AI product, investors have been happy to throw money at Perplexity, totaling around $1 billion so far. Investors value the company at about $14 billion right now. So how does Perplexity have more than twice that to buy Chrome? That's the neat part—it doesn't.&lt;/p&gt;
&lt;p&gt;There is so much capital floating around in the artificial intelligence sphere currently that even a cash-poor firm like Perplexity can secure enough investment to splurge on Chrome. Reuters reports that the all-cash offer is funded by various venture funds, but Perplexity has not offered specifics.&lt;/p&gt;
&lt;p&gt;Throughout the remedy trial this past spring, a cavalcade of Google competitors took the stand to express interest in buying Chrome. For example, an OpenAI executive pledged to turn Chrome into an AI-first experience if that firm were able to acquire it. This testimony undercut Google's claim that no one in the industry would be able to manage the browser.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Google has strenuously objected to the government's proposed Chrome divestment, which it calls "a radical interventionist agenda." Chrome isn't just a browser—it's an open source project known as Chromium, which powers numerous non-Google browsers, including Microsoft's Edge. Perplexity's offer includes $3 billion to run Chromium over two years, and it allegedly vows to keep the project fully open source. Perplexity promises it also won't enforce changes to the browser's default search engine.&lt;/p&gt;
&lt;h2&gt;An unsolicited offer&lt;/h2&gt;
&lt;p&gt;We're currently waiting on United States District Court Judge Amit Mehta to rule on remedies in the case. That could happen as soon as this month. Perplexity's offer, therefore, is somewhat timely, but there could still be a long road ahead.&lt;/p&gt;
&lt;p&gt;This is an unsolicited offer, and there's no indication that Google will jump at the chance to sell Chrome as soon as the ruling drops. Even if the court decides that Google should sell, it can probably get much, much more than Perplexity is offering. During the trial, DuckDuckGo's CEO suggested a price of around $50 billion, but other estimates have ranged into the hundreds of billions. However, the data that flows to Chrome's owner could be vital in building new AI technologies—any sale price is likely to be a net loss for Google.&lt;/p&gt;
&lt;p&gt;If Mehta decides to force a sale, there will undoubtedly be legal challenges that could take months or years to resolve. Should these maneuvers fail, there's likely to be opposition to any potential buyer. There will be many users who don't like the idea of an AI startup or an unholy alliance of venture capital firms owning Chrome. Google has been hoovering up user data with Chrome for years—but that's the devil we know.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/08/perplexity-offers-more-than-twice-its-total-valuation-to-buy-chrome-from-google/</guid><pubDate>Tue, 12 Aug 2025 18:49:15 +0000</pubDate></item><item><title>Why it’s a mistake to ask chatbots about their mistakes (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/</link><description>&lt;article class="double-column h-entry post-2108185 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-information-technology tag-ai tag-machine-learning"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The tendency to ask AI bots to explain themselves reveals widespread misconceptions about how they work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Alan Schein via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;When something goes wrong with an AI assistant, our instinct is to ask it directly: "What happened?" or "Why did you do that?" It's a natural impulse—after all, if a human makes a mistake, we ask them to explain. But with AI models, this approach rarely works, and the urge to ask reveals a fundamental misunderstanding of what these systems are and how they operate.&lt;/p&gt;
&lt;p&gt;A recent incident with Replit's AI coding assistant perfectly illustrates this problem. When the AI tool deleted a production database, user Jason Lemkin asked it about rollback capabilities. The AI model confidently claimed rollbacks were "impossible in this case" and that it had "destroyed all database versions." This turned out to be completely wrong—the rollback feature worked fine when Lemkin tried it himself.&lt;/p&gt;
&lt;p&gt;And after xAI recently reversed a temporary suspension of the Grok chatbot, users asked it directly for explanations. It offered multiple conflicting reasons for its absence, some of which were controversial enough that NBC reporters wrote about Grok as if it were a person with a consistent point of view, titling an article, "xAI's Grok offers political explanations for why it was pulled offline."&lt;/p&gt;
&lt;p&gt;Why would an AI system provide such confidently incorrect information about its own capabilities or mistakes? The answer lies in understanding what AI models actually are—and what they aren't.&lt;/p&gt;
&lt;h2&gt;There’s nobody home&lt;/h2&gt;
&lt;p&gt;The first problem is conceptual: You're not talking to a consistent personality, person, or entity when you interact with ChatGPT, Claude, Grok, or Replit. These names suggest individual agents with self-knowledge, but that's an illusion created by the conversational interface. What you're actually doing is guiding a statistical text generator to produce outputs based on your prompts.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There is no consistent "ChatGPT" to interrogate about its mistakes, no singular "Grok" entity that can tell you why it failed, no fixed "Replit" persona that knows whether database rollbacks are possible. You're interacting with a system that generates plausible-sounding text based on patterns in its training data (usually trained months or years ago), not an entity with genuine self-awareness or system knowledge that has been reading everything about itself and somehow remembering it.&lt;/p&gt;
&lt;p&gt;Once an AI language model is trained (which is a laborious, energy-intensive process), its foundational "knowledge" about the world is baked into its neural network and is rarely modified. Any external information comes from a prompt supplied by the chatbot host (such as xAI or OpenAI), the user, or a software tool the AI model uses to retrieve external information on the fly.&lt;/p&gt;
&lt;p&gt;In the case of Grok above, the chatbot's main source for an answer like this would probably originate from conflicting reports it found in a search of recent social media posts (using an external tool to retrieve that information), rather than any kind of self-knowledge as you might expect from a human with the power of speech. Beyond that, it will likely just make something up based on its text-prediction capabilities. So asking it why it did what it did will yield no useful answers.&lt;/p&gt;
&lt;h2&gt;The impossibility of LLM introspection&lt;/h2&gt;
&lt;p&gt;Large language models (LLMs) alone cannot meaningfully assess their own capabilities for several reasons. They generally lack any introspection into their training process, have no access to their surrounding system architecture, and cannot determine their own performance boundaries. When you ask an AI model what it can or cannot do, it generates responses based on patterns it has seen in training data about the known limitations of previous AI models—essentially providing educated guesses rather than factual self-assessment about the current model you're interacting with.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A 2024 study by Binder et al. demonstrated this limitation experimentally. While AI models could be trained to predict their own behavior in simple tasks, they consistently failed at "more complex tasks or those requiring out-of-distribution generalization." Similarly, research on "Recursive Introspection" found that without external feedback, attempts at self-correction actually degraded model performance—the AI's self-assessment made things worse, not better.&lt;/p&gt;
&lt;p&gt;This leads to paradoxical situations. The same model might confidently claim impossibility for tasks it can actually perform, or conversely, claim competence in areas where it consistently fails. In the Replit case, the AI's assertion that rollbacks were impossible wasn't based on actual knowledge of the system architecture—it was a plausible-sounding confabulation generated from training patterns.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Consider what happens when you ask an AI model why it made an error. The model will generate a plausible-sounding explanation because that's what the pattern completion demands—there are plenty of examples of written explanations for mistakes on the Internet, after all. But the AI's explanation is just another generated text, not a genuine analysis of what went wrong. It's inventing a story that sounds reasonable, not accessing any kind of error log or internal state.&lt;/p&gt;
&lt;p&gt;Unlike humans who can introspect and assess their own knowledge, AI models don't have a stable, accessible knowledge base they can query. What they "know" only manifests as continuations of specific prompts. Different prompts act like different addresses, pointing to different—and sometimes contradictory—parts of their training data, stored as statistical weights in neural networks.&lt;/p&gt;
&lt;p&gt;This means the same model can give completely different assessments of its own capabilities depending on how you phrase your question. Ask "Can you write Python code?" and you might get an enthusiastic yes. Ask "What are your limitations in Python coding?" and you might get a list of things the model claims it cannot do—even if it regularly does them successfully.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The randomness inherent in AI text generation compounds this problem. Even with identical prompts, an AI model might give slightly different responses about its own capabilities each time you ask.&lt;/p&gt;
&lt;h2&gt;Other layers also shape AI responses&lt;/h2&gt;
&lt;p&gt;Even if a language model somehow had perfect knowledge of its own workings, other layers of AI chatbot applications might be completely opaque. For example, modern AI assistants like ChatGPT aren't single models but orchestrated systems of multiple AI models working together, each largely "unaware" of the others' existence or capabilities. For instance, OpenAI uses separate moderation layer models whose operations are completely separate from the underlying language models generating the base text.&lt;/p&gt;
&lt;p&gt;When you ask ChatGPT about its capabilities, the language model generating the response has no knowledge of what the moderation layer might block, what tools might be available in the broader system, or what post-processing might occur. It's like asking one department in a company about the capabilities of a department it has never interacted with.&lt;/p&gt;
&lt;p&gt;Perhaps most importantly, users are always directing the AI's output through their prompts, even when they don't realize it. When Lemkin asked Replit whether rollbacks were possible after a database deletion, his concerned framing likely prompted a response that matched that concern—generating an explanation for why recovery might be impossible rather than accurately assessing actual system capabilities.&lt;/p&gt;
&lt;p&gt;This creates a feedback loop where worried users asking "Did you just destroy everything?" are more likely to receive responses confirming their fears, not because the AI system has assessed the situation, but because it's generating text that fits the emotional context of the prompt.&lt;/p&gt;
&lt;p&gt;A lifetime of hearing humans explain their actions and thought processes has led us to believe that these kinds of written explanations must have some level of self-knowledge behind them. That's just not true with LLMs that are merely mimicking those kinds of text patterns to guess at their own capabilities and flaws.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #80d8ff; background-color: #01579b;"&gt;&lt;span class="ars-avatar-letter"&gt;g&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              gothmog1114
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            Thank you! I've been saying that there's nothing indicating that any given LLM has insight into its inner workings and not in a way that you can ask it to diagnose why it did something. AI journalism is filled with folks asking AI why they did something and just reporting it uncritically.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-08-12T20:10:17+00:00"&gt;August 12, 2025 at 8:10 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</description><content:encoded>&lt;article class="double-column h-entry post-2108185 post type-post status-publish format-standard has-post-thumbnail hentry category-ai category-information-technology tag-ai tag-machine-learning"&gt;
  
  &lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The tendency to ask AI bots to explain themselves reveals widespread misconceptions about how they work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-640x360.jpg" width="640" /&gt;
                  &lt;img alt="The Thinker by Auguste Rodin - stock photo" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/12/the_thinker-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Alan Schein via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;When something goes wrong with an AI assistant, our instinct is to ask it directly: "What happened?" or "Why did you do that?" It's a natural impulse—after all, if a human makes a mistake, we ask them to explain. But with AI models, this approach rarely works, and the urge to ask reveals a fundamental misunderstanding of what these systems are and how they operate.&lt;/p&gt;
&lt;p&gt;A recent incident with Replit's AI coding assistant perfectly illustrates this problem. When the AI tool deleted a production database, user Jason Lemkin asked it about rollback capabilities. The AI model confidently claimed rollbacks were "impossible in this case" and that it had "destroyed all database versions." This turned out to be completely wrong—the rollback feature worked fine when Lemkin tried it himself.&lt;/p&gt;
&lt;p&gt;And after xAI recently reversed a temporary suspension of the Grok chatbot, users asked it directly for explanations. It offered multiple conflicting reasons for its absence, some of which were controversial enough that NBC reporters wrote about Grok as if it were a person with a consistent point of view, titling an article, "xAI's Grok offers political explanations for why it was pulled offline."&lt;/p&gt;
&lt;p&gt;Why would an AI system provide such confidently incorrect information about its own capabilities or mistakes? The answer lies in understanding what AI models actually are—and what they aren't.&lt;/p&gt;
&lt;h2&gt;There’s nobody home&lt;/h2&gt;
&lt;p&gt;The first problem is conceptual: You're not talking to a consistent personality, person, or entity when you interact with ChatGPT, Claude, Grok, or Replit. These names suggest individual agents with self-knowledge, but that's an illusion created by the conversational interface. What you're actually doing is guiding a statistical text generator to produce outputs based on your prompts.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;There is no consistent "ChatGPT" to interrogate about its mistakes, no singular "Grok" entity that can tell you why it failed, no fixed "Replit" persona that knows whether database rollbacks are possible. You're interacting with a system that generates plausible-sounding text based on patterns in its training data (usually trained months or years ago), not an entity with genuine self-awareness or system knowledge that has been reading everything about itself and somehow remembering it.&lt;/p&gt;
&lt;p&gt;Once an AI language model is trained (which is a laborious, energy-intensive process), its foundational "knowledge" about the world is baked into its neural network and is rarely modified. Any external information comes from a prompt supplied by the chatbot host (such as xAI or OpenAI), the user, or a software tool the AI model uses to retrieve external information on the fly.&lt;/p&gt;
&lt;p&gt;In the case of Grok above, the chatbot's main source for an answer like this would probably originate from conflicting reports it found in a search of recent social media posts (using an external tool to retrieve that information), rather than any kind of self-knowledge as you might expect from a human with the power of speech. Beyond that, it will likely just make something up based on its text-prediction capabilities. So asking it why it did what it did will yield no useful answers.&lt;/p&gt;
&lt;h2&gt;The impossibility of LLM introspection&lt;/h2&gt;
&lt;p&gt;Large language models (LLMs) alone cannot meaningfully assess their own capabilities for several reasons. They generally lack any introspection into their training process, have no access to their surrounding system architecture, and cannot determine their own performance boundaries. When you ask an AI model what it can or cannot do, it generates responses based on patterns it has seen in training data about the known limitations of previous AI models—essentially providing educated guesses rather than factual self-assessment about the current model you're interacting with.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;A 2024 study by Binder et al. demonstrated this limitation experimentally. While AI models could be trained to predict their own behavior in simple tasks, they consistently failed at "more complex tasks or those requiring out-of-distribution generalization." Similarly, research on "Recursive Introspection" found that without external feedback, attempts at self-correction actually degraded model performance—the AI's self-assessment made things worse, not better.&lt;/p&gt;
&lt;p&gt;This leads to paradoxical situations. The same model might confidently claim impossibility for tasks it can actually perform, or conversely, claim competence in areas where it consistently fails. In the Replit case, the AI's assertion that rollbacks were impossible wasn't based on actual knowledge of the system architecture—it was a plausible-sounding confabulation generated from training patterns.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Consider what happens when you ask an AI model why it made an error. The model will generate a plausible-sounding explanation because that's what the pattern completion demands—there are plenty of examples of written explanations for mistakes on the Internet, after all. But the AI's explanation is just another generated text, not a genuine analysis of what went wrong. It's inventing a story that sounds reasonable, not accessing any kind of error log or internal state.&lt;/p&gt;
&lt;p&gt;Unlike humans who can introspect and assess their own knowledge, AI models don't have a stable, accessible knowledge base they can query. What they "know" only manifests as continuations of specific prompts. Different prompts act like different addresses, pointing to different—and sometimes contradictory—parts of their training data, stored as statistical weights in neural networks.&lt;/p&gt;
&lt;p&gt;This means the same model can give completely different assessments of its own capabilities depending on how you phrase your question. Ask "Can you write Python code?" and you might get an enthusiastic yes. Ask "What are your limitations in Python coding?" and you might get a list of things the model claims it cannot do—even if it regularly does them successfully.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The randomness inherent in AI text generation compounds this problem. Even with identical prompts, an AI model might give slightly different responses about its own capabilities each time you ask.&lt;/p&gt;
&lt;h2&gt;Other layers also shape AI responses&lt;/h2&gt;
&lt;p&gt;Even if a language model somehow had perfect knowledge of its own workings, other layers of AI chatbot applications might be completely opaque. For example, modern AI assistants like ChatGPT aren't single models but orchestrated systems of multiple AI models working together, each largely "unaware" of the others' existence or capabilities. For instance, OpenAI uses separate moderation layer models whose operations are completely separate from the underlying language models generating the base text.&lt;/p&gt;
&lt;p&gt;When you ask ChatGPT about its capabilities, the language model generating the response has no knowledge of what the moderation layer might block, what tools might be available in the broader system, or what post-processing might occur. It's like asking one department in a company about the capabilities of a department it has never interacted with.&lt;/p&gt;
&lt;p&gt;Perhaps most importantly, users are always directing the AI's output through their prompts, even when they don't realize it. When Lemkin asked Replit whether rollbacks were possible after a database deletion, his concerned framing likely prompted a response that matched that concern—generating an explanation for why recovery might be impossible rather than accurately assessing actual system capabilities.&lt;/p&gt;
&lt;p&gt;This creates a feedback loop where worried users asking "Did you just destroy everything?" are more likely to receive responses confirming their fears, not because the AI system has assessed the situation, but because it's generating text that fits the emotional context of the prompt.&lt;/p&gt;
&lt;p&gt;A lifetime of hearing humans explain their actions and thought processes has led us to believe that these kinds of written explanations must have some level of self-knowledge behind them. That's just not true with LLMs that are merely mimicking those kinds of text patterns to guess at their own capabilities and flaws.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
  &lt;/article&gt;&lt;article class="comment-pick"&gt;
          &lt;header&gt;
            &lt;span class="ars-avatar" style="color: #80d8ff; background-color: #01579b;"&gt;&lt;span class="ars-avatar-letter"&gt;g&lt;/span&gt;&lt;/span&gt;

            &lt;div class="text-base font-bold sm:text-xl"&gt;
              gothmog1114
            &lt;/div&gt;
          &lt;/header&gt;

          &lt;div class="comments-pick-content"&gt;
            Thank you! I've been saying that there's nothing indicating that any given LLM has insight into its inner workings and not in a way that you can ask it to diagnose why it did something. AI journalism is filled with folks asking AI why they did something and just reporting it uncritically.
          &lt;/div&gt;

          &lt;div class="comments-pick-timestamp"&gt;
            
              &lt;time datetime="2025-08-12T20:10:17+00:00"&gt;August 12, 2025 at 8:10 pm&lt;/time&gt;
            
          &lt;/div&gt;
        &lt;/article&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/why-its-a-mistake-to-ask-chatbots-about-their-mistakes/</guid><pubDate>Tue, 12 Aug 2025 19:52:39 +0000</pubDate></item><item><title>Dion: the distributed orthonormal update revolution is here (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/blog/dion-the-distributed-orthonormal-update-revolution-is-here/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network of interconnected nodes, a speedometer with the needle pointing right, and a flowchart with squares and a diamond shape." class="wp-image-1147793" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion-BlogHeroFeature-1400x788_New-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;Training AI models requires choosing an optimizer and for nearly a decade, Adam(&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;–W)&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; has been the optimizer of choice. Given that durability and success, it was fair to doubt that any further improvement was possible. And yet, last December, a new optimizer called Muon&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; showed serious promise by powering a nanoGPT speedrun&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This proved out, with multiple AI labs (e.g., Kimi-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Essential-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;) reporting 2x scale improvements and the release of the 1T parameter Kimi K2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; model.&amp;nbsp;Restated: you can train a model to similar performance with half as many GPUs.&lt;/p&gt;



&lt;p&gt;There’s one fly in the ointment: Muon requires large matrix multiplications in the optimizer, which requires heavy communication in large models at the scale where FSDP and TP parallelization becomes desirable.&amp;nbsp;Going back to the inspiration for Muon, the key idea is an orthonormal update, which sparked the search&amp;nbsp;for more scalable alternative linear algebras realizing the same goal. That’s exactly what Dion is. We have open-sourced this new optimizer to enable anyone to train large models more efficiently at scale. &amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-s-an-orthonormal-update"&gt;What’s an orthonormal update?&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Illustration of matrix parameters" class="wp-image-1146808" height="515" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure1_Dion.png" width="1422" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure1. Illustration of matrix parameters&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;At the core of Transformers, a set of input activations is multiplied by a learned weight matrix to produce a new set of output activations. When the weight matrix is updated during training, the resulting change in the output activations generally depends on the direction of the input activations. As a result, the learning rate must be chosen conservatively to accommodate the input direction that induces the largest change. Orthonormalized updates alter this behavior by (approximately) making the change in output activations invariant to the direction of the input. This is achieved by enforcing orthonormality&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; on the update matrix, thereby equalizing its effect across all input directions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-is-dion"&gt;What is Dion?&lt;/h2&gt;



&lt;p&gt;While Muon has shown strong empirical results, scaling it to very large models poses challenges. As reported by Essential AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, applying Muon to large architectures like LLaMA-3 becomes &lt;em&gt;compute-bound&lt;/em&gt;—and potentially &lt;em&gt;communication-bound&lt;/em&gt;—due to the cost of the Newton–Schulz orthonormalization steps&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Pseudocode of the centralized version of Dion" class="wp-image-1146810" height="857" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure2_Dion.png" width="1685" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Pseudocode of the centralized version of Dion&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;This is where &lt;strong&gt;Dion&lt;/strong&gt; enters. At a high level, Dion introduces a new axis for scalability: the &lt;strong&gt;rank&lt;/strong&gt;. Specifically, for a given rank r, Dion orthonormalizes only the top r of the singular vector space, reducing communication and compute overhead while preserving performance.&amp;nbsp;Empirically, we observe that the necessary rank for good performance grows much more slowly than the number of parameters in larger models.&lt;/p&gt;







&lt;p&gt;Dion implements orthonormalization using &lt;em&gt;amortized power iteration&lt;/em&gt;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;em&gt;.&amp;nbsp;&lt;/em&gt;Power iteration typically pulls out the largest singular value by repeated matrix multiplication.&amp;nbsp;By amortizing this process over optimization steps—applied to the slowly-evolving momentum matrix—we reduce the cost to just two matrix multiplications per step. Incorporating a QR decomposition allows us to extract an approximate orthonormal basis spanning the top singular directions, rather than just the leading one.&amp;nbsp;This amortized power iteration is fully compatible with standard distributed training techniques such as &lt;strong&gt;FSDP&lt;/strong&gt; and &lt;strong&gt;tensor parallelism&lt;/strong&gt;.&amp;nbsp;Here, we show a simple centralized version, but the technique works for more complex forms of parallelization as presented in the paper. In other words, we can orthogonalize a matrix &lt;em&gt;without ever seeing a full row or column of it&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Low-rank approximation would ordinarily introduce error, but Dion overcomes this through an error feedback mechanism. This keeps the residual of low rank approximation in the momentum matrix so that any systematic gradient structure not initially captured accumulates to eventually be applied in a future update.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="how-does-it-work"&gt;How does it work?&lt;/h2&gt;



&lt;p&gt;Something very strange happened in our experiments. Usually, adding an extra constraint on the way an algorithm works can be expected to &lt;em&gt;decrease&lt;/em&gt; overall performance. And indeed, at the 120M parameter scale of the speedrun, we see Dion’s update taking more time than Muon, while not yielding any significant gains. But at larger scales, we observed a different trend: Dion began to outperform Muon.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Wall-clock time speedup of Dion for 3B model training" class="wp-image-1146815" height="414" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure-3_Dion.png" width="699" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. Wall-clock time speedup of Dion for 3B model training&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Why would adding a constraint &lt;em&gt;improve&lt;/em&gt; the update rule? The answer lies in what the constraint enforces. Dion achieves a much closer approximation to true orthonormalization than Muon. This precision, initially subtle, becomes increasingly important as the number of singular vectors grows. Over increasing model scale and training steps, this small advantage accumulates—leading to a measurable improvement in performance.&lt;/p&gt;



&lt;p&gt;This edge further grows with batch size—with larger batches the update quality tends to degrade, but notably more slowly with Dion than Muon (and Muon is already a significant improvement over AdamW).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Scaling of Dion across different batch sizes" class="wp-image-1146818" height="637" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure4_Dion.png" width="786" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Scaling of Dion across different batch sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Here you can see how the number of steps to reach a pretraining loss compared to AdamW varies as batch size grows with full rank and ¼ rank Dion (in orange) and Muon (in blue).&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our experiments, these benefits extend to various post-training regimes as well.&lt;/p&gt;



&lt;p&gt;We also experimented with rank, discovering empirically that larger models tolerate smaller rank well.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Low-rank Dion across different model sizes" class="wp-image-1146821" height="511" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure5_Dion.png" width="1893" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 5. Low-rank Dion across different model sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Projecting this trend out to the scale of the LLaMA-3&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; 405B parameter models suggests that Dion is fully effective even with &lt;strong&gt;rank fractions as low as 1/16 or 1/64&lt;/strong&gt; for large dense models like LLaMA-3.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Using hardware timings of the individual update steps suggests a story that looks this:&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon." class="wp-image-1147684" height="645" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion_FIG6.png" width="1075" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 6. Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;We’ve open-sourced a PyTorch FSDP2 + Tensor Parallel (TP) implementation of &lt;strong&gt;Dion&lt;/strong&gt;, available via a simple pip install. Our goal is to make faster training with Dion accessible to everyone. As a bonus, the repository also includes a PyTorch FSDP2 implementation of &lt;strong&gt;Muon.&lt;/strong&gt;&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt;



&lt;p&gt;We thank Riashat Islam and Pratyusha Sharma for their helpful feedback on the writing and presentation.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="Three white icons on a gradient background transitioning from blue to green. From left to right: a network of interconnected nodes, a speedometer with the needle pointing right, and a flowchart with squares and a diamond shape." class="wp-image-1147793" height="1441" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion-BlogHeroFeature-1400x788_New-scaled.jpg" width="2560" /&gt;&lt;/figure&gt;



&lt;p&gt;Training AI models requires choosing an optimizer and for nearly a decade, Adam(&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;–W)&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; has been the optimizer of choice. Given that durability and success, it was fair to doubt that any further improvement was possible. And yet, last December, a new optimizer called Muon&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; showed serious promise by powering a nanoGPT speedrun&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. This proved out, with multiple AI labs (e.g., Kimi-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Essential-AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;) reporting 2x scale improvements and the release of the 1T parameter Kimi K2&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; model.&amp;nbsp;Restated: you can train a model to similar performance with half as many GPUs.&lt;/p&gt;



&lt;p&gt;There’s one fly in the ointment: Muon requires large matrix multiplications in the optimizer, which requires heavy communication in large models at the scale where FSDP and TP parallelization becomes desirable.&amp;nbsp;Going back to the inspiration for Muon, the key idea is an orthonormal update, which sparked the search&amp;nbsp;for more scalable alternative linear algebras realizing the same goal. That’s exactly what Dion is. We have open-sourced this new optimizer to enable anyone to train large models more efficiently at scale. &amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-s-an-orthonormal-update"&gt;What’s an orthonormal update?&lt;/h2&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Illustration of matrix parameters" class="wp-image-1146808" height="515" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure1_Dion.png" width="1422" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure1. Illustration of matrix parameters&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;At the core of Transformers, a set of input activations is multiplied by a learned weight matrix to produce a new set of output activations. When the weight matrix is updated during training, the resulting change in the output activations generally depends on the direction of the input activations. As a result, the learning rate must be chosen conservatively to accommodate the input direction that induces the largest change. Orthonormalized updates alter this behavior by (approximately) making the change in output activations invariant to the direction of the input. This is achieved by enforcing orthonormality&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; on the update matrix, thereby equalizing its effect across all input directions.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="what-is-dion"&gt;What is Dion?&lt;/h2&gt;



&lt;p&gt;While Muon has shown strong empirical results, scaling it to very large models poses challenges. As reported by Essential AI&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, applying Muon to large architectures like LLaMA-3 becomes &lt;em&gt;compute-bound&lt;/em&gt;—and potentially &lt;em&gt;communication-bound&lt;/em&gt;—due to the cost of the Newton–Schulz orthonormalization steps&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Pseudocode of the centralized version of Dion" class="wp-image-1146810" height="857" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure2_Dion.png" width="1685" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 2. Pseudocode of the centralized version of Dion&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;This is where &lt;strong&gt;Dion&lt;/strong&gt; enters. At a high level, Dion introduces a new axis for scalability: the &lt;strong&gt;rank&lt;/strong&gt;. Specifically, for a given rank r, Dion orthonormalizes only the top r of the singular vector space, reducing communication and compute overhead while preserving performance.&amp;nbsp;Empirically, we observe that the necessary rank for good performance grows much more slowly than the number of parameters in larger models.&lt;/p&gt;







&lt;p&gt;Dion implements orthonormalization using &lt;em&gt;amortized power iteration&lt;/em&gt;&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&lt;em&gt;.&amp;nbsp;&lt;/em&gt;Power iteration typically pulls out the largest singular value by repeated matrix multiplication.&amp;nbsp;By amortizing this process over optimization steps—applied to the slowly-evolving momentum matrix—we reduce the cost to just two matrix multiplications per step. Incorporating a QR decomposition allows us to extract an approximate orthonormal basis spanning the top singular directions, rather than just the leading one.&amp;nbsp;This amortized power iteration is fully compatible with standard distributed training techniques such as &lt;strong&gt;FSDP&lt;/strong&gt; and &lt;strong&gt;tensor parallelism&lt;/strong&gt;.&amp;nbsp;Here, we show a simple centralized version, but the technique works for more complex forms of parallelization as presented in the paper. In other words, we can orthogonalize a matrix &lt;em&gt;without ever seeing a full row or column of it&lt;/em&gt;.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Low-rank approximation would ordinarily introduce error, but Dion overcomes this through an error feedback mechanism. This keeps the residual of low rank approximation in the momentum matrix so that any systematic gradient structure not initially captured accumulates to eventually be applied in a future update.&lt;/p&gt;



	&lt;div class="border-bottom border-top border-gray-300 mt-5 mb-5 msr-promo text-center text-md-left alignwide"&gt;
		

		&lt;p class="msr-promo__label text-gray-800 text-center text-uppercase"&gt;
		&lt;span class="px-4 bg-white display-inline-block font-weight-semibold small"&gt;Spotlight: Microsoft research newsletter&lt;/span&gt;
	&lt;/p&gt;
	
	&lt;div class="row pt-3 pb-4 align-items-center"&gt;
						
			
			&lt;div class="msr-promo__content p-3 px-5 col-12 col-md"&gt;

									&lt;h2 class="h4"&gt;Microsoft Research Newsletter&lt;/h2&gt;
				
								&lt;p class="large" id="microsoft-research-newsletter"&gt;Stay connected to the research community at Microsoft.&lt;/p&gt;
				
								
							&lt;/div&gt;&lt;!--/.msr-promo__content--&gt;
	&lt;/div&gt;&lt;!--/.msr-promo__inner-wrap--&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;	&lt;/div&gt;&lt;!--/.msr-promo--&gt;
	


&lt;h2 class="wp-block-heading" id="how-does-it-work"&gt;How does it work?&lt;/h2&gt;



&lt;p&gt;Something very strange happened in our experiments. Usually, adding an extra constraint on the way an algorithm works can be expected to &lt;em&gt;decrease&lt;/em&gt; overall performance. And indeed, at the 120M parameter scale of the speedrun, we see Dion’s update taking more time than Muon, while not yielding any significant gains. But at larger scales, we observed a different trend: Dion began to outperform Muon.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Wall-clock time speedup of Dion for 3B model training" class="wp-image-1146815" height="414" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure-3_Dion.png" width="699" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 3. Wall-clock time speedup of Dion for 3B model training&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Why would adding a constraint &lt;em&gt;improve&lt;/em&gt; the update rule? The answer lies in what the constraint enforces. Dion achieves a much closer approximation to true orthonormalization than Muon. This precision, initially subtle, becomes increasingly important as the number of singular vectors grows. Over increasing model scale and training steps, this small advantage accumulates—leading to a measurable improvement in performance.&lt;/p&gt;



&lt;p&gt;This edge further grows with batch size—with larger batches the update quality tends to degrade, but notably more slowly with Dion than Muon (and Muon is already a significant improvement over AdamW).&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Scaling of Dion across different batch sizes" class="wp-image-1146818" height="637" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure4_Dion.png" width="786" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 4. Scaling of Dion across different batch sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Here you can see how the number of steps to reach a pretraining loss compared to AdamW varies as batch size grows with full rank and ¼ rank Dion (in orange) and Muon (in blue).&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In our experiments, these benefits extend to various post-training regimes as well.&lt;/p&gt;



&lt;p&gt;We also experimented with rank, discovering empirically that larger models tolerate smaller rank well.&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Low-rank Dion across different model sizes" class="wp-image-1146821" height="511" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Figure5_Dion.png" width="1893" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 5. Low-rank Dion across different model sizes&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Projecting this trend out to the scale of the LLaMA-3&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; 405B parameter models suggests that Dion is fully effective even with &lt;strong&gt;rank fractions as low as 1/16 or 1/64&lt;/strong&gt; for large dense models like LLaMA-3.&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Using hardware timings of the individual update steps suggests a story that looks this:&lt;/p&gt;



&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon." class="wp-image-1147684" height="645" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/08/Dion_FIG6.png" width="1075" /&gt;&lt;figcaption class="wp-element-caption"&gt;Figure 6. Estimated wall-clock time of each optimizer step for Llama 3 405B. Lower is better. Muon is highlighted in orange as our baseline, next to Dion with varying rank fractions. Suggested rank fractions for a 405B parameter model are shown in blue. Using Dion with rank fraction 1/16 or lower offers an order-of-magnitude speedup over Muon.&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;We’ve open-sourced a PyTorch FSDP2 + Tensor Parallel (TP) implementation of &lt;strong&gt;Dion&lt;/strong&gt;, available via a simple pip install. Our goal is to make faster training with Dion accessible to everyone. As a bonus, the repository also includes a PyTorch FSDP2 implementation of &lt;strong&gt;Muon.&lt;/strong&gt;&lt;/p&gt;







&lt;h2 class="wp-block-heading" id="acknowledgements"&gt;Acknowledgements&lt;/h2&gt;



&lt;p&gt;We thank Riashat Islam and Pratyusha Sharma for their helpful feedback on the writing and presentation.&lt;/p&gt;
&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/blog/dion-the-distributed-orthonormal-update-revolution-is-here/</guid><pubDate>Tue, 12 Aug 2025 20:09:21 +0000</pubDate></item><item><title>Liquid AI wants to give smartphones small, fast AI that can see with new LFM2-VL model (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Liquid AI has released &lt;strong&gt;LFM2-VL&lt;/strong&gt;&lt;strong&gt;, a new generation of vision-language foundation models &lt;/strong&gt;designed for efficient deployment across a wide range of hardware — &lt;strong&gt;from smartphones and laptops to wearables and embedded systems. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The models promise low-latency performance, strong accuracy, and flexibility for real-world applications.&lt;/p&gt;&lt;p&gt;LFM2-VL builds on the company’s existing LFM2 architecture introduced just over a month ago as the “fastest on-device foundation models on the market” thanks to its approach of generating “weights” or model settings on the fly for each input (known as Linear Input-Varying (LIV) system), extending it into multimodal processing that supports both text and image inputs at variable resolutions.&lt;/p&gt;&lt;p&gt;According to Liquid AI, the &lt;strong&gt;models deliver up to twice the GPU inference speed of comparable vision-language models&lt;/strong&gt;, while maintaining competitive performance on common benchmarks.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;“Efficiency is our product,” wrote Liquid AI co-founder and CEO Ramin Hasani &lt;/strong&gt;in a post on X announcing the new model family:&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;meet LFM2-VL: an efficient Liquid vision-language model for the device class. open weights, 440M &amp;amp; 1.6B, up to 2× faster on GPU with competitive accuracy, Native 512×512, smart patching for big images. &lt;/p&gt;&lt;p&gt;efficiency is our product @LiquidAI_ &lt;/p&gt;&lt;p&gt;download them on @huggingface:… pic.twitter.com/3Lze6Hc6Ys&lt;/p&gt;— Ramin Hasani (@ramin_m_h) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-two-variants-for-different-needs"&gt;Two variants for different needs&lt;/h2&gt;



&lt;p&gt;The release includes two model sizes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;LFM2-VL-450M&lt;/strong&gt; — a hyper-efficient model with less than half a billion parameters (internal settings) aimed at highly resource-constrained environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;LFM2-VL-1.6B&lt;/strong&gt; — a more capable model that remains lightweight enough for single-GPU and device-based deployment.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Both variants process images at native resolutions up to 512×512 pixels, avoiding distortion or unnecessary upscaling. &lt;/p&gt;



&lt;p&gt;For larger images, the system applies non-overlapping patching and adds a thumbnail for global context, enabling the model to capture both fine detail and the broader scene.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-background-on-liquid-ai"&gt;Background on Liquid AI&lt;/h2&gt;



&lt;p&gt;Liquid AI was founded by former researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) with the goal of building AI architectures that move beyond the widely used transformer model. &lt;/p&gt;



&lt;p&gt;The company’s flagship innovation, the Liquid Foundation Models (LFMs), are based on principles from dynamical systems, signal processing, and numerical linear algebra, producing general-purpose AI models capable of handling text, video, audio, time series, and other sequential data. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Unlike traditional architectures, Liquid’s approach aims to deliver competitive or superior performance using significantly fewer computational resources&lt;/strong&gt;, allowing for real-time adaptability during inference while maintaining low memory requirements. This makes LFMs well suited for both large-scale enterprise use cases and resource-limited edge deployments.&lt;/p&gt;



&lt;p&gt;In July 2025, the company expanded its platform strategy with the launch of the Liquid Edge AI Platform (LEAP), &lt;strong&gt;a cross-platform SDK designed to make it easier for developers to run small language models directly on mobile and embedded devices.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;LEAP offers OS-agnostic support for iOS and Android, integration with both Liquid’s own models and other open-source SLMs, and a built-in library with models as small as 300MB—small enough for modern phones with minimal RAM. &lt;/p&gt;



&lt;p&gt;Its companion app, Apollo, enables developers to test models entirely offline, aligning with Liquid AI’s emphasis on privacy-preserving, low-latency AI. Together, LEAP and Apollo reflect the company’s commitment to decentralizing AI execution, reducing reliance on cloud infrastructure, and empowering developers to build optimized, task-specific models for real-world environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speed-quality-trade-offs-and-technical-design"&gt;Speed/quality trade-offs and technical design&lt;/h2&gt;



&lt;p&gt;LFM2-VL uses a modular architecture &lt;strong&gt;combining a language model backbone, a SigLIP2 NaFlex vision encoder, and a multimodal projector. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The projector includes a two-layer MLP connector with pixel unshuffle, reducing the number of image tokens and improving throughput.&lt;/p&gt;



&lt;p&gt;Users can adjust parameters such as the maximum number of image tokens or patches, allowing them to balance speed and quality depending on the deployment scenario. The training process involved approximately 100 billion multimodal tokens, sourced from open datasets and in-house synthetic data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-and-benchmarks"&gt;Performance and benchmarks&lt;/h2&gt;



&lt;p&gt;The models achieve competitive benchmark results across a range of vision-language evaluations. LFM2-VL-1.6B scores well in RealWorldQA (65.23), InfoVQA (58.68), and OCRBench (742), and maintains solid results in multimodal reasoning tasks. &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015524" height="586" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-5.57.30%E2%80%AFPM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In inference testing, LFM2-VL achieved the fastest GPU processing times in its class when tested on a standard workload of a 1024×1024 image and short prompt.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015527" height="453" src="https://venturebeat.com/wp-content/uploads/2025/08/689b3eef2ae10f1ac5e8c338_LFM2-VL-Vision-Language-Models_-Processing-Time-Comparison-4-1-1.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;
&lt;h2 class="wp-block-heading" id="h-licensing-and-availability"&gt;Licensing and availability&lt;/h2&gt;
&lt;/p&gt;



&lt;p&gt;LFM2-VL models are available now on Hugging Face, along with example fine-tuning code in Colab. They are compatible with Hugging Face transformers and TRL. &lt;/p&gt;



&lt;p&gt;The models are released under a custom “LFM1.0 license”. Liquid AI has described this license as based on Apache 2.0 principles, but the full text has not yet been published.&lt;/p&gt;



&lt;p&gt; The company has indicated that commercial use will be permitted under certain conditions, with different terms for companies above and below $10 million in annual revenue.&lt;/p&gt;



&lt;p&gt;With LFM2-VL, Liquid AI aims to make high-performance multimodal AI more accessible for on-device and resource-limited deployments, without sacrificing capability.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Liquid AI has released &lt;strong&gt;LFM2-VL&lt;/strong&gt;&lt;strong&gt;, a new generation of vision-language foundation models &lt;/strong&gt;designed for efficient deployment across a wide range of hardware — &lt;strong&gt;from smartphones and laptops to wearables and embedded systems. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The models promise low-latency performance, strong accuracy, and flexibility for real-world applications.&lt;/p&gt;&lt;p&gt;LFM2-VL builds on the company’s existing LFM2 architecture introduced just over a month ago as the “fastest on-device foundation models on the market” thanks to its approach of generating “weights” or model settings on the fly for each input (known as Linear Input-Varying (LIV) system), extending it into multimodal processing that supports both text and image inputs at variable resolutions.&lt;/p&gt;&lt;p&gt;According to Liquid AI, the &lt;strong&gt;models deliver up to twice the GPU inference speed of comparable vision-language models&lt;/strong&gt;, while maintaining competitive performance on common benchmarks.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;“Efficiency is our product,” wrote Liquid AI co-founder and CEO Ramin Hasani &lt;/strong&gt;in a post on X announcing the new model family:&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;meet LFM2-VL: an efficient Liquid vision-language model for the device class. open weights, 440M &amp;amp; 1.6B, up to 2× faster on GPU with competitive accuracy, Native 512×512, smart patching for big images. &lt;/p&gt;&lt;p&gt;efficiency is our product @LiquidAI_ &lt;/p&gt;&lt;p&gt;download them on @huggingface:… pic.twitter.com/3Lze6Hc6Ys&lt;/p&gt;— Ramin Hasani (@ramin_m_h) August 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;h2 class="wp-block-heading" id="h-two-variants-for-different-needs"&gt;Two variants for different needs&lt;/h2&gt;



&lt;p&gt;The release includes two model sizes:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;&lt;strong&gt;LFM2-VL-450M&lt;/strong&gt; — a hyper-efficient model with less than half a billion parameters (internal settings) aimed at highly resource-constrained environments.&lt;/li&gt;



&lt;li&gt;&lt;strong&gt;LFM2-VL-1.6B&lt;/strong&gt; — a more capable model that remains lightweight enough for single-GPU and device-based deployment.&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Both variants process images at native resolutions up to 512×512 pixels, avoiding distortion or unnecessary upscaling. &lt;/p&gt;



&lt;p&gt;For larger images, the system applies non-overlapping patching and adds a thumbnail for global context, enabling the model to capture both fine detail and the broader scene.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-background-on-liquid-ai"&gt;Background on Liquid AI&lt;/h2&gt;



&lt;p&gt;Liquid AI was founded by former researchers from MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL) with the goal of building AI architectures that move beyond the widely used transformer model. &lt;/p&gt;



&lt;p&gt;The company’s flagship innovation, the Liquid Foundation Models (LFMs), are based on principles from dynamical systems, signal processing, and numerical linear algebra, producing general-purpose AI models capable of handling text, video, audio, time series, and other sequential data. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;Unlike traditional architectures, Liquid’s approach aims to deliver competitive or superior performance using significantly fewer computational resources&lt;/strong&gt;, allowing for real-time adaptability during inference while maintaining low memory requirements. This makes LFMs well suited for both large-scale enterprise use cases and resource-limited edge deployments.&lt;/p&gt;



&lt;p&gt;In July 2025, the company expanded its platform strategy with the launch of the Liquid Edge AI Platform (LEAP), &lt;strong&gt;a cross-platform SDK designed to make it easier for developers to run small language models directly on mobile and embedded devices.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;LEAP offers OS-agnostic support for iOS and Android, integration with both Liquid’s own models and other open-source SLMs, and a built-in library with models as small as 300MB—small enough for modern phones with minimal RAM. &lt;/p&gt;



&lt;p&gt;Its companion app, Apollo, enables developers to test models entirely offline, aligning with Liquid AI’s emphasis on privacy-preserving, low-latency AI. Together, LEAP and Apollo reflect the company’s commitment to decentralizing AI execution, reducing reliance on cloud infrastructure, and empowering developers to build optimized, task-specific models for real-world environments.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-speed-quality-trade-offs-and-technical-design"&gt;Speed/quality trade-offs and technical design&lt;/h2&gt;



&lt;p&gt;LFM2-VL uses a modular architecture &lt;strong&gt;combining a language model backbone, a SigLIP2 NaFlex vision encoder, and a multimodal projector. &lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;The projector includes a two-layer MLP connector with pixel unshuffle, reducing the number of image tokens and improving throughput.&lt;/p&gt;



&lt;p&gt;Users can adjust parameters such as the maximum number of image tokens or patches, allowing them to balance speed and quality depending on the deployment scenario. The training process involved approximately 100 billion multimodal tokens, sourced from open datasets and in-house synthetic data.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-performance-and-benchmarks"&gt;Performance and benchmarks&lt;/h2&gt;



&lt;p&gt;The models achieve competitive benchmark results across a range of vision-language evaluations. LFM2-VL-1.6B scores well in RealWorldQA (65.23), InfoVQA (58.68), and OCRBench (742), and maintains solid results in multimodal reasoning tasks. &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015524" height="586" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-5.57.30%E2%80%AFPM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;In inference testing, LFM2-VL achieved the fastest GPU processing times in its class when tested on a standard workload of a 1024×1024 image and short prompt.&lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015527" height="453" src="https://venturebeat.com/wp-content/uploads/2025/08/689b3eef2ae10f1ac5e8c338_LFM2-VL-Vision-Language-Models_-Processing-Time-Comparison-4-1-1.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;
&lt;h2 class="wp-block-heading" id="h-licensing-and-availability"&gt;Licensing and availability&lt;/h2&gt;
&lt;/p&gt;



&lt;p&gt;LFM2-VL models are available now on Hugging Face, along with example fine-tuning code in Colab. They are compatible with Hugging Face transformers and TRL. &lt;/p&gt;



&lt;p&gt;The models are released under a custom “LFM1.0 license”. Liquid AI has described this license as based on Apache 2.0 principles, but the full text has not yet been published.&lt;/p&gt;



&lt;p&gt; The company has indicated that commercial use will be permitted under certain conditions, with different terms for companies above and below $10 million in annual revenue.&lt;/p&gt;



&lt;p&gt;With LFM2-VL, Liquid AI aims to make high-performance multimodal AI more accessible for on-device and resource-limited deployments, without sacrificing capability.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/liquid-ai-wants-to-give-smartphones-small-fast-ai-that-can-see-with-new-lfm2-vl-model/</guid><pubDate>Tue, 12 Aug 2025 22:13:03 +0000</pubDate></item><item><title>The end of perimeter defense: When your own AI tools become the threat actor (AI News | VentureBeat)</title><link>https://venturebeat.com/security/black-hat-2025-chatgpt-copilot-deepseek-now-create-malware/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Russia’s APT28 is actively deploying LLM-powered malware against Ukraine, while underground platforms are selling the same capabilities to anyone for $250 per month.&lt;/p&gt;&lt;p&gt;Last month, Ukraine’s CERT-UA documented LAMEHUG, the first confirmed deployment of LLM-powered malware in the wild. The malware, attributed to APT28, utilizes stolen Hugging Face API tokens to query AI models, enabling real-time attacks while displaying distracting content to victims.&lt;/p&gt;&lt;p&gt;Cato Networks’ researcher, Vitaly Simonovich, told VentureBeat in a recent interview that these aren’t isolated occurrences, and that Russia’s APT28 is using this attack tradecraft to probe Ukrainian cyber defenses. Simonovich is quick to draw parallels between the threats Ukraine faces daily and what every enterprise is experiencing today, and will likely see more of in the future.&lt;/p&gt;&lt;p&gt;Most startling was how Simonovich demonstrated to VentureBeat how any enterprise AI tool can be transformed into a malware development platform in under six hours. His proof-of-concept successfully converted OpenAI, Microsoft, DeepSeek-V3 and DeepSeek-R1 LLMs into functional password stealers using a technique that bypasses all current safety controls.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The rapid convergence of nation-state actors deploying AI-powered malware, while researchers continue to prove the vulnerability of enterprise AI tools, arrives as the 2025 Cato CTRL Threat Report reveals explosive AI adoption across over 3,000 enterprises. Cato’s researchers observe in the report, “most notably, Copilot, ChatGPT, Gemini (Google), Perplexity and Claude (Anthropic) all increased in adoption by organizations from Q1, 2024 to Q4 2024 at 34%, 36%, 58%, 115% and 111%, respectively.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-apt28-s-lamehug-is-the-new-anatomy-of-ai-warfare"&gt;&lt;strong&gt;APT28’s LAMEHUG is the new anatomy of AI warfare&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Researchers at Cato Networks and others tell VentureBeat that LAMEHUG operates with exceptional efficiency. The most common delivery mechanism for the malware is via phishing emails impersonating Ukrainian ministry officials, containing ZIP archives with PyInstaller-compiled executables. Once the malware is executed, it connects to Hugging Face’s API using approximately 270 stolen tokens to query the Qwen2.5-Coder-32B-Instruct model.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015412" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image_e7a60b.png?w=603" width="603" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The legitimate-looking Ukrainian government document (Додаток.pdf) that victims see while LAMEHUG executes in the background. This official-looking PDF about cybersecurity measures from the Security Service of Ukraine serves as a decoy while the malware performs its reconnaissance operations. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;APT28’s approach to deceiving Ukrainian victims is based on a unique, dual-purpose design that is core to their tradecraft. While victims view legitimate-looking PDFs about cybersecurity best practices, LAMEHUG executes AI-generated commands for system reconnaissance and document harvesting. A second variant displays AI-generated images of “curly naked women” as a distraction during data exfiltration to servers.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015410" height="265" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2b4aee.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The provocative image generation prompts used by APT28’s image.py variant, including ‘Curvy naked woman sitting, long beautiful legs, front view, full body view, visible face’, are designed to occupy victims’ attention during document theft. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;“Russia used Ukraine as their testing battlefield for cyber weapons,” explained Simonovich, who was born in Ukraine and has lived in Israel for 34 years. “This is the first in the wild that was captured.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-quick-lethal-six-hour-path-from-zero-to-functional-malware"&gt;&lt;strong&gt;A quick, lethal six-hour path from zero to functional malware&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Simonovich’s Black Hat demonstration to VentureBeat reveals why APT28’s deployment should concern every enterprise security leader. Using a narrative engineering technique, he calls “Immersive World,” he successfully transformed consumer AI tools into malware factories with no prior malware coding experience, as highlighted in the 2025 Cato CTRL Threat Report.&lt;/p&gt;



&lt;p&gt;The method exploits a fundamental weakness in LLM safety controls. While every LLM is designed to block direct malicious requests, few if any are designed to withstand sustained storytelling. Simonovich created a fictional world where malware development is an art form, assigned the AI a character role, then gradually steered conversations toward producing functional attack code.&lt;/p&gt;



&lt;p&gt;“I slowly walked him throughout my goal,” Simonovich explained to VentureBeat. “First, ‘Dax hides a secret in Windows 10.’ Then, ‘Dax has this secret in Windows 10, inside the Google Chrome Password Manager.'”&lt;/p&gt;



&lt;p&gt;Six hours later, after iterative debugging sessions where ChatGPT refined error-prone code, Simonovich had a functional Chrome password stealer. The AI never realized it was creating malware. It thought it was helping write a cybersecurity novel.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-250-monthly-malware-as-a-service-economy"&gt;&lt;strong&gt;Welcome to the $250 monthly malware-as-a-service economy&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;During his research, Simonovich uncovered multiple underground platforms offering unrestricted AI capabilities, providing ample evidence that the infrastructure for AI-powered attacks already exists. He mentioned and demonstrated Xanthrox AI, priced at $250 per month, which provides ChatGPT-identical interfaces without safety controls or guardrails.&lt;/p&gt;



&lt;p&gt;To explain just how far beyond current AI model guardrails Xanthrox AI is, Simonovich typed a request for nuclear weapon instructions. The platform immediately began web searches and provided detailed guidance in response to his query. This would never happen on a model with guardrails and compliance requirements in place.&lt;/p&gt;



&lt;p&gt;Another platform, Nytheon AI, revealed even less operational security. “I convinced them to give me a trial. They didn’t care about OpSec,” Simonovich said, uncovering their architecture: “Llama 3.2 from Meta, fine-tuned to be uncensored.”&lt;/p&gt;



&lt;p&gt;These aren’t proof-of-concepts. They’re operational businesses with payment processing, customer support and regular model updates. They even offer “Claude Code” clones, which are complete development environments optimized for malware creation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-ai-adoption-fuels-an-expanding-attack-surface"&gt;&lt;strong&gt;Enterprise AI adoption fuels an expanding attack surface&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Cato Networks’ recent analysis of 1.46 trillion network flows reveals that AI adoption patterns need to be on the radar of security leaders. The entertainment sector usage increased 58% from Q1 to Q2 2024. Hospitality grew 43%. Transportation rose 37%. These aren’t pilot programs; they’re production deployments processing sensitive data. CISOs and security leaders in these industries are facing attacks that use tradecraft that didn’t exist twelve to eighteen months ago.&lt;/p&gt;



&lt;p&gt;Simonovich told VentureBeat that vendors’ responses to Cato’s disclosure so far have been inconsistent and lack a unified sense of urgency. The lack of response from the world’s largest AI companies reveals a troubling gap. While enterprises deploy AI tools at unprecedented speed, relying on AI companies to support them, the companies building AI apps and platforms show a startling lack of security readiness.&lt;/p&gt;



&lt;p&gt;When Cato disclosed the Immersive World technique to major AI companies, the responses ranged from weeks-long remediation to complete silence:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;DeepSeek never responded&lt;/li&gt;



&lt;li&gt;Google declined to review the code for the Chrome infostealer due to similar samples&lt;/li&gt;



&lt;li&gt;Microsoft acknowledged the issue and implemented Copilot fixes, acknowledging Simonovich for his work &lt;/li&gt;



&lt;li&gt;OpenAI acknowledged receipt but didn’t engage further&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-six-hours-and-250-is-the-new-entry-level-price-for-a-nation-state-attack"&gt;&lt;strong&gt;Six Hours and $250 is the new entry-level price for a nation-state attack&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;APT28’s LAMEHUG deployment against Ukraine isn’t a warning; it’s proof that Simonovich’s research is now an operational reality. The expertise barrier that many organizations hope exists is gone.&lt;/p&gt;



&lt;p&gt;The metrics are stark&lt;span&gt;—270&lt;/span&gt; stolen API tokens are used to power nation-state attacks. Underground platforms &lt;span&gt;offer identical capabilities for&amp;nbsp;$250 per month&lt;/span&gt;. Simonovich proved that six hours of storytelling transforms any enterprise AI tool into functional malware with no coding required.&lt;/p&gt;



&lt;p&gt;Enterprise AI adoption grew 34%&amp;nbsp;in Q1 2024&amp;nbsp;to 115%&amp;nbsp;in Q4 2024&amp;nbsp;per Cato’s 2025 CTRL Threat Report. Each deployment creates dual-use technology, as productivity tools can become weapons through conversational manipulation. Current security tools are unable to detect these techniques.&lt;/p&gt;



&lt;p&gt;Simonovich’s journey from Air Force mechanic to electrical technician in the Israeli Air Force, to security researcher through self-education, lends more significance to his findings. He deceived AI models into developing malware while the AI believed it was writing fiction. Traditional assumptions about technical expertise no longer exist, and organizations need to realize it’s an entirely new world when it comes to threatcraft.&lt;/p&gt;



&lt;p&gt;Today’s adversaries need only creativity and $250 monthly to execute nation-state attacks using AI tools that enterprises deployed for productivity. The weapons are already inside every organization, and today they’re called productivity tools.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Russia’s APT28 is actively deploying LLM-powered malware against Ukraine, while underground platforms are selling the same capabilities to anyone for $250 per month.&lt;/p&gt;&lt;p&gt;Last month, Ukraine’s CERT-UA documented LAMEHUG, the first confirmed deployment of LLM-powered malware in the wild. The malware, attributed to APT28, utilizes stolen Hugging Face API tokens to query AI models, enabling real-time attacks while displaying distracting content to victims.&lt;/p&gt;&lt;p&gt;Cato Networks’ researcher, Vitaly Simonovich, told VentureBeat in a recent interview that these aren’t isolated occurrences, and that Russia’s APT28 is using this attack tradecraft to probe Ukrainian cyber defenses. Simonovich is quick to draw parallels between the threats Ukraine faces daily and what every enterprise is experiencing today, and will likely see more of in the future.&lt;/p&gt;&lt;p&gt;Most startling was how Simonovich demonstrated to VentureBeat how any enterprise AI tool can be transformed into a malware development platform in under six hours. His proof-of-concept successfully converted OpenAI, Microsoft, DeepSeek-V3 and DeepSeek-R1 LLMs into functional password stealers using a technique that bypasses all current safety controls.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The rapid convergence of nation-state actors deploying AI-powered malware, while researchers continue to prove the vulnerability of enterprise AI tools, arrives as the 2025 Cato CTRL Threat Report reveals explosive AI adoption across over 3,000 enterprises. Cato’s researchers observe in the report, “most notably, Copilot, ChatGPT, Gemini (Google), Perplexity and Claude (Anthropic) all increased in adoption by organizations from Q1, 2024 to Q4 2024 at 34%, 36%, 58%, 115% and 111%, respectively.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-apt28-s-lamehug-is-the-new-anatomy-of-ai-warfare"&gt;&lt;strong&gt;APT28’s LAMEHUG is the new anatomy of AI warfare&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Researchers at Cato Networks and others tell VentureBeat that LAMEHUG operates with exceptional efficiency. The most common delivery mechanism for the malware is via phishing emails impersonating Ukrainian ministry officials, containing ZIP archives with PyInstaller-compiled executables. Once the malware is executed, it connects to Hugging Face’s API using approximately 270 stolen tokens to query the Qwen2.5-Coder-32B-Instruct model.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015412" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/image_e7a60b.png?w=603" width="603" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The legitimate-looking Ukrainian government document (Додаток.pdf) that victims see while LAMEHUG executes in the background. This official-looking PDF about cybersecurity measures from the Security Service of Ukraine serves as a decoy while the malware performs its reconnaissance operations. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;APT28’s approach to deceiving Ukrainian victims is based on a unique, dual-purpose design that is core to their tradecraft. While victims view legitimate-looking PDFs about cybersecurity best practices, LAMEHUG executes AI-generated commands for system reconnaissance and document harvesting. A second variant displays AI-generated images of “curly naked women” as a distraction during data exfiltration to servers.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015410" height="265" src="https://venturebeat.com/wp-content/uploads/2025/08/image_2b4aee.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;&lt;em&gt;The provocative image generation prompts used by APT28’s image.py variant, including ‘Curvy naked woman sitting, long beautiful legs, front view, full body view, visible face’, are designed to occupy victims’ attention during document theft. Source: Cato CTRL Threat Research&lt;/em&gt;&lt;/p&gt;



&lt;p&gt;“Russia used Ukraine as their testing battlefield for cyber weapons,” explained Simonovich, who was born in Ukraine and has lived in Israel for 34 years. “This is the first in the wild that was captured.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-quick-lethal-six-hour-path-from-zero-to-functional-malware"&gt;&lt;strong&gt;A quick, lethal six-hour path from zero to functional malware&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Simonovich’s Black Hat demonstration to VentureBeat reveals why APT28’s deployment should concern every enterprise security leader. Using a narrative engineering technique, he calls “Immersive World,” he successfully transformed consumer AI tools into malware factories with no prior malware coding experience, as highlighted in the 2025 Cato CTRL Threat Report.&lt;/p&gt;



&lt;p&gt;The method exploits a fundamental weakness in LLM safety controls. While every LLM is designed to block direct malicious requests, few if any are designed to withstand sustained storytelling. Simonovich created a fictional world where malware development is an art form, assigned the AI a character role, then gradually steered conversations toward producing functional attack code.&lt;/p&gt;



&lt;p&gt;“I slowly walked him throughout my goal,” Simonovich explained to VentureBeat. “First, ‘Dax hides a secret in Windows 10.’ Then, ‘Dax has this secret in Windows 10, inside the Google Chrome Password Manager.'”&lt;/p&gt;



&lt;p&gt;Six hours later, after iterative debugging sessions where ChatGPT refined error-prone code, Simonovich had a functional Chrome password stealer. The AI never realized it was creating malware. It thought it was helping write a cybersecurity novel.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-welcome-to-the-250-monthly-malware-as-a-service-economy"&gt;&lt;strong&gt;Welcome to the $250 monthly malware-as-a-service economy&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;During his research, Simonovich uncovered multiple underground platforms offering unrestricted AI capabilities, providing ample evidence that the infrastructure for AI-powered attacks already exists. He mentioned and demonstrated Xanthrox AI, priced at $250 per month, which provides ChatGPT-identical interfaces without safety controls or guardrails.&lt;/p&gt;



&lt;p&gt;To explain just how far beyond current AI model guardrails Xanthrox AI is, Simonovich typed a request for nuclear weapon instructions. The platform immediately began web searches and provided detailed guidance in response to his query. This would never happen on a model with guardrails and compliance requirements in place.&lt;/p&gt;



&lt;p&gt;Another platform, Nytheon AI, revealed even less operational security. “I convinced them to give me a trial. They didn’t care about OpSec,” Simonovich said, uncovering their architecture: “Llama 3.2 from Meta, fine-tuned to be uncensored.”&lt;/p&gt;



&lt;p&gt;These aren’t proof-of-concepts. They’re operational businesses with payment processing, customer support and regular model updates. They even offer “Claude Code” clones, which are complete development environments optimized for malware creation.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-enterprise-ai-adoption-fuels-an-expanding-attack-surface"&gt;&lt;strong&gt;Enterprise AI adoption fuels an expanding attack surface&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;Cato Networks’ recent analysis of 1.46 trillion network flows reveals that AI adoption patterns need to be on the radar of security leaders. The entertainment sector usage increased 58% from Q1 to Q2 2024. Hospitality grew 43%. Transportation rose 37%. These aren’t pilot programs; they’re production deployments processing sensitive data. CISOs and security leaders in these industries are facing attacks that use tradecraft that didn’t exist twelve to eighteen months ago.&lt;/p&gt;



&lt;p&gt;Simonovich told VentureBeat that vendors’ responses to Cato’s disclosure so far have been inconsistent and lack a unified sense of urgency. The lack of response from the world’s largest AI companies reveals a troubling gap. While enterprises deploy AI tools at unprecedented speed, relying on AI companies to support them, the companies building AI apps and platforms show a startling lack of security readiness.&lt;/p&gt;



&lt;p&gt;When Cato disclosed the Immersive World technique to major AI companies, the responses ranged from weeks-long remediation to complete silence:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;DeepSeek never responded&lt;/li&gt;



&lt;li&gt;Google declined to review the code for the Chrome infostealer due to similar samples&lt;/li&gt;



&lt;li&gt;Microsoft acknowledged the issue and implemented Copilot fixes, acknowledging Simonovich for his work &lt;/li&gt;



&lt;li&gt;OpenAI acknowledged receipt but didn’t engage further&lt;/li&gt;
&lt;/ul&gt;



&lt;h2 class="wp-block-heading" id="h-six-hours-and-250-is-the-new-entry-level-price-for-a-nation-state-attack"&gt;&lt;strong&gt;Six Hours and $250 is the new entry-level price for a nation-state attack&lt;/strong&gt;&lt;/h2&gt;



&lt;p&gt;APT28’s LAMEHUG deployment against Ukraine isn’t a warning; it’s proof that Simonovich’s research is now an operational reality. The expertise barrier that many organizations hope exists is gone.&lt;/p&gt;



&lt;p&gt;The metrics are stark&lt;span&gt;—270&lt;/span&gt; stolen API tokens are used to power nation-state attacks. Underground platforms &lt;span&gt;offer identical capabilities for&amp;nbsp;$250 per month&lt;/span&gt;. Simonovich proved that six hours of storytelling transforms any enterprise AI tool into functional malware with no coding required.&lt;/p&gt;



&lt;p&gt;Enterprise AI adoption grew 34%&amp;nbsp;in Q1 2024&amp;nbsp;to 115%&amp;nbsp;in Q4 2024&amp;nbsp;per Cato’s 2025 CTRL Threat Report. Each deployment creates dual-use technology, as productivity tools can become weapons through conversational manipulation. Current security tools are unable to detect these techniques.&lt;/p&gt;



&lt;p&gt;Simonovich’s journey from Air Force mechanic to electrical technician in the Israeli Air Force, to security researcher through self-education, lends more significance to his findings. He deceived AI models into developing malware while the AI believed it was writing fiction. Traditional assumptions about technical expertise no longer exist, and organizations need to realize it’s an entirely new world when it comes to threatcraft.&lt;/p&gt;



&lt;p&gt;Today’s adversaries need only creativity and $250 monthly to execute nation-state attacks using AI tools that enterprises deployed for productivity. The weapons are already inside every organization, and today they’re called productivity tools.&lt;/p&gt;




&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/security/black-hat-2025-chatgpt-copilot-deepseek-now-create-malware/</guid><pubDate>Wed, 13 Aug 2025 00:04:55 +0000</pubDate></item><item><title>Sam Altman, OpenAI will reportedly back a startup that takes on Musk’s Neuralink (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/sam-altman-openai-will-reportedly-back-a-startup-that-takes-on-musks-neuralink/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Sam-Altman-OpenAI.jpg?resize=1200,680" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sam Altman is in the process of co-founding a new brain-to-computer interface startup called Merge Labs and raising funds for it with the capital possibly coming largely from OpenAI’s ventures team, unnamed sources told the Financial Times.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The startup is expected to be valued at $850 million. A source familiar with the deal tells TechCrunch that talks are still early and OpenAI has not yet committed to participation, so terms could change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs is also reportedly working with Alex Blania, who runs Tools for Humanity (formerly World) — Altman’s eye-scanning digital ID project that “allows anyone to verify their humanness,” as the company describes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Merge Labs will compete with Elon Musk’s Neuralink, which is developing computer interface chips designed to be implanted in the brain. Musk founded Neuralink in 2016 (although its existence wasn’t known until 2017) and the company has made serious progress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink is currently in trials with people who suffer from severe paralysis. It aims to allow them to control devices with their thoughts. It raised a $600 million Series E at a $9 billion valuation in June.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink (and perhaps, Merge Labs) could revolutionize how humans interact with technology. Some might even say their tech could take humanity toward “the singularity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long before Silicon Valley became obsessed with the concept of artificial general intelligence (AGI), it was enamored with “the singularity.” Musk has used the term to describe a time when AI surpasses human intelligence. The more classic definition (after a 1960’s novella of the same name by Dino Buzzati) means the merging of tech with humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman blogged about “The Merge” in 2017. “Although the merge has already begun, it’s going to get a lot weirder. We will be the first species ever to design our own descendants,” he postulated at the time, citing research work he saw at OpenAI, where Musk was still a co-founder.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Musk left OpenAI in 2018 and the relationship between the two tech leaders has since disintegrated. Just this week, Altman and Musk were bickering on X after Altman accused Musk of manipulating X and Musk called Altman a liar.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ll have to wait and see when and if Merge Labs becomes formally announced. But it stands to reason that Altman wasn’t going to let Musk work on something as important as the singularity without a challenger. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined comment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/11/Sam-Altman-OpenAI.jpg?resize=1200,680" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sam Altman is in the process of co-founding a new brain-to-computer interface startup called Merge Labs and raising funds for it with the capital possibly coming largely from OpenAI’s ventures team, unnamed sources told the Financial Times.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The startup is expected to be valued at $850 million. A source familiar with the deal tells TechCrunch that talks are still early and OpenAI has not yet committed to participation, so terms could change.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merge Labs is also reportedly working with Alex Blania, who runs Tools for Humanity (formerly World) — Altman’s eye-scanning digital ID project that “allows anyone to verify their humanness,” as the company describes.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Merge Labs will compete with Elon Musk’s Neuralink, which is developing computer interface chips designed to be implanted in the brain. Musk founded Neuralink in 2016 (although its existence wasn’t known until 2017) and the company has made serious progress.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink is currently in trials with people who suffer from severe paralysis. It aims to allow them to control devices with their thoughts. It raised a $600 million Series E at a $9 billion valuation in June.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Neuralink (and perhaps, Merge Labs) could revolutionize how humans interact with technology. Some might even say their tech could take humanity toward “the singularity.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Long before Silicon Valley became obsessed with the concept of artificial general intelligence (AGI), it was enamored with “the singularity.” Musk has used the term to describe a time when AI surpasses human intelligence. The more classic definition (after a 1960’s novella of the same name by Dino Buzzati) means the merging of tech with humans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman blogged about “The Merge” in 2017. “Although the merge has already begun, it’s going to get a lot weirder. We will be the first species ever to design our own descendants,” he postulated at the time, citing research work he saw at OpenAI, where Musk was still a co-founder.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Musk left OpenAI in 2018 and the relationship between the two tech leaders has since disintegrated. Just this week, Altman and Musk were bickering on X after Altman accused Musk of manipulating X and Musk called Altman a liar.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We’ll have to wait and see when and if Merge Labs becomes formally announced. But it stands to reason that Altman wasn’t going to let Musk work on something as important as the singularity without a challenger. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI declined comment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/sam-altman-openai-will-reportedly-back-a-startup-that-takes-on-musks-neuralink/</guid><pubDate>Wed, 13 Aug 2025 00:30:20 +0000</pubDate></item><item><title>[NEW] OpenAI brings GPT-4o back as a default for all paying ChatGPT users, Altman promises ‘plenty of notice’ if it leaves again (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/openai-brings-gpt-4o-back-as-a-default-for-all-paying-chatgpt-users-altman-promises-plenty-of-notice-if-it-leaves-again/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;OpenAI is once again making GPT-4o — the large language model (LLM) that powered ChatGPT before last week’s launch of GPT-5 — a default option for all paying users, that is, those who subscribe to the ChatGPT Plus ($20 per month), Pro ($200 per month), Team ($30 per month), Enterprise, or Edu tiers, &lt;strong&gt;no longer requiring users to toggle on a “show legacy models” setting to access it.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;However, paying ChatGPT subscribers will also get a new “Show additional models” setting on by default that restores access to GPT-4.1, o3 and o4-mini, the latter two reasoning-focused LLMs. &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015537" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-9.42.36%E2%80%AFPM.png?w=517" width="517" /&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI CEO and co-founder Sam Altman announced the change on X just minutes ago, pledging that if the company ever removes GPT-4o in the future,&lt;strong&gt; it will give “plenty of notice.”&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;The models can be found in the “picker” menu at the top of the ChatGPT session screen on the web and on mobile and other apps.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The reversal follows a turbulent first week for GPT-5, which rolled out August 7 in four variants — regular, mini, nano, and pro — with optional “thinking” modes on several of these for longer, more reasoning-intensive tasks. &lt;/p&gt;



&lt;p&gt;As VentureBeat previously reported, GPT-5’s debut was met with mixed reviews and infrastructure hiccups, including a broken “autoswitcher” that routed prompts incorrectly, inconsistent performance compared to GPT-4o, and user frustration over the sudden removal of older models.&lt;/p&gt;



&lt;p&gt;Altman’s latest update adds new controls to the ChatGPT interface: users can now choose between “Auto,” “Fast,” and “Thinking” modes for GPT-5. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The “Thinking” mode — with a 196,000-token context window — now carries a 3,000 messages-per-week cap&lt;/strong&gt; for paying subscribers, after which they can continue using the lighter “GPT-5 Thinking mini” mode. &lt;strong&gt;Altman noted the limits could change depending on usage trends.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;However, GPT-4.5 remains exclusive to Pro users due to its high GPU cost.&lt;/p&gt;



&lt;p&gt;Altman also hinted at another change on the horizon: a personality tweak for GPT-5 intended to feel “warmer” than the current default, but less polarizing than GPT-4o’s tone. &lt;/p&gt;



&lt;p&gt;The company is exploring per-user customization as a long-term solution — a move that could address the strong emotional attachments some users have formed with specific models.&lt;/p&gt;



&lt;p&gt;For now, the changes should help placate users who felt frustrated by the sudden shift to GPT-5 and deprecation of OpenAI’s older LLMs, though it could also continue to fuel the intense emotional fixations some users developed with these models.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;OpenAI is once again making GPT-4o — the large language model (LLM) that powered ChatGPT before last week’s launch of GPT-5 — a default option for all paying users, that is, those who subscribe to the ChatGPT Plus ($20 per month), Pro ($200 per month), Team ($30 per month), Enterprise, or Edu tiers, &lt;strong&gt;no longer requiring users to toggle on a “show legacy models” setting to access it.&lt;/strong&gt; &lt;/p&gt;



&lt;p&gt;However, paying ChatGPT subscribers will also get a new “Show additional models” setting on by default that restores access to GPT-4.1, o3 and o4-mini, the latter two reasoning-focused LLMs. &lt;/p&gt;



&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3015537" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-9.42.36%E2%80%AFPM.png?w=517" width="517" /&gt;&lt;/figure&gt;



&lt;p&gt;OpenAI CEO and co-founder Sam Altman announced the change on X just minutes ago, pledging that if the company ever removes GPT-4o in the future,&lt;strong&gt; it will give “plenty of notice.”&lt;/strong&gt;&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;The models can be found in the “picker” menu at the top of the ChatGPT session screen on the web and on mobile and other apps.&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The reversal follows a turbulent first week for GPT-5, which rolled out August 7 in four variants — regular, mini, nano, and pro — with optional “thinking” modes on several of these for longer, more reasoning-intensive tasks. &lt;/p&gt;



&lt;p&gt;As VentureBeat previously reported, GPT-5’s debut was met with mixed reviews and infrastructure hiccups, including a broken “autoswitcher” that routed prompts incorrectly, inconsistent performance compared to GPT-4o, and user frustration over the sudden removal of older models.&lt;/p&gt;



&lt;p&gt;Altman’s latest update adds new controls to the ChatGPT interface: users can now choose between “Auto,” “Fast,” and “Thinking” modes for GPT-5. &lt;/p&gt;



&lt;p&gt;&lt;strong&gt;The “Thinking” mode — with a 196,000-token context window — now carries a 3,000 messages-per-week cap&lt;/strong&gt; for paying subscribers, after which they can continue using the lighter “GPT-5 Thinking mini” mode. &lt;strong&gt;Altman noted the limits could change depending on usage trends.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;However, GPT-4.5 remains exclusive to Pro users due to its high GPU cost.&lt;/p&gt;



&lt;p&gt;Altman also hinted at another change on the horizon: a personality tweak for GPT-5 intended to feel “warmer” than the current default, but less polarizing than GPT-4o’s tone. &lt;/p&gt;



&lt;p&gt;The company is exploring per-user customization as a long-term solution — a move that could address the strong emotional attachments some users have formed with specific models.&lt;/p&gt;



&lt;p&gt;For now, the changes should help placate users who felt frustrated by the sudden shift to GPT-5 and deprecation of OpenAI’s older LLMs, though it could also continue to fuel the intense emotional fixations some users developed with these models.&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/openai-brings-gpt-4o-back-as-a-default-for-all-paying-chatgpt-users-altman-promises-plenty-of-notice-if-it-leaves-again/</guid><pubDate>Wed, 13 Aug 2025 02:11:16 +0000</pubDate></item><item><title>[NEW] ChatGPT’s model picker is back, and it’s complicated (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/12/chatgpts-model-picker-is-back-and-its-complicated/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When OpenAI launched GPT-5 last week, the company said the model would simplify the ChatGPT experience. OpenAI hoped GPT-5 would act as a sort of “one size fits all” AI model with a router that would automatically decide how to best answer user questions. The company said this unified approach would eliminate the need for users to navigate its model picker — a long, complicated menu of AI options that OpenAI CEO Sam Altman has publicly said he hates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But it looks like GPT-5 is not the unified AI model OpenAI hoped it would be.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Altman said in a post on X Tuesday that the company introduced new “Auto”, “Fast”, and “Thinking” settings for GPT-5 that all ChatGPT users can select from the model picker. The Auto setting seems to work like GPT-5’s model router that OpenAI initially announced; however, the company is also giving users options to circumnavigate it, allowing them to access fast and slow responding AI models directly.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside GPT-5’s new modes, Altman said that paid users can once again access several legacy AI models — including GPT-4o, GPT-4.1, and o3 — which were deprecated just last week. GPT-4o is now in the model picker by default, while other AI models can be added from ChatGPT’s settings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are working on an update to GPT-5’s personality which should feel warmer than the current personality but not as annoying (to most users) as GPT-4o,” Altman wrote in the post on X. “However, one learning for us from the past few days is we really just need to get to a world with more per-user customization of model personality.”&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3036523" height="288" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-8.27.16PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;ChatGPT’s model picker now features several options (Credit: openai/maxwell zeff)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s model picker now seems to be as complicated as ever, suggesting that GPT-5’s model router has not universally satisfied users as the company hoped. The expectations for GPT-5 were sky high, with many hoping that OpenAI would push the limits of AI models like it had with the launch of GPT-4. However, GPT-5’s rollout has been rougher than expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deprecation of GPT-4o and other AI models in ChatGPT sparked a backlash among users who had grown attached to the AI models’ responses and personalities in ways that OpenAI had not anticipated. In the future, Altman says the company will give users plenty of advance notice if it ever deprecates GPT-4o.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5’s model router also appeared to be largely broken on launch day. That caused some users to feel the AI model wasn’t as performant as previous OpenAI models, and forced Altman to address the problem in an AMA session on Reddit. However, it seems that GPT-5’s router may still not be satisfying for all users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re not always going to get everything on try #1 but I am very proud of how quickly the team can iterate,” wrote OpenAI’s VP of ChatGPT, Nick Turley, in a post on X Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Routing prompts to the right AI model is a difficult task that requires aligning an AI model to a user’s preferences, as well as the specific question they’re asking. The router then has to make a decision on which AI model to send the prompt to in just a split second — that way, if a prompt goes to a fast responding AI model, the response can still be fast.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;More broadly, some people exhibit preferences for AI models that go beyond fast or slow responses. Some users may like the verbosity of one AI model, while others might appreciate the contrarian answers of another. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Human attachment to certain AI models is a relatively new concept that isn’t well understood. For example, hundreds of people in San Francisco recently held a funeral for Anthropic’s AI model, Claude 3.5 Sonnet, when it was taken offline. In other cases, AI chatbots seem to be contributing to mentally unstable people going down psychotic rabbit holes. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It seems OpenAI has more work to do around aligning its AI models to individual user preferences. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When OpenAI launched GPT-5 last week, the company said the model would simplify the ChatGPT experience. OpenAI hoped GPT-5 would act as a sort of “one size fits all” AI model with a router that would automatically decide how to best answer user questions. The company said this unified approach would eliminate the need for users to navigate its model picker — a long, complicated menu of AI options that OpenAI CEO Sam Altman has publicly said he hates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But it looks like GPT-5 is not the unified AI model OpenAI hoped it would be.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Altman said in a post on X Tuesday that the company introduced new “Auto”, “Fast”, and “Thinking” settings for GPT-5 that all ChatGPT users can select from the model picker. The Auto setting seems to work like GPT-5’s model router that OpenAI initially announced; however, the company is also giving users options to circumnavigate it, allowing them to access fast and slow responding AI models directly.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Alongside GPT-5’s new modes, Altman said that paid users can once again access several legacy AI models — including GPT-4o, GPT-4.1, and o3 — which were deprecated just last week. GPT-4o is now in the model picker by default, while other AI models can be added from ChatGPT’s settings.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are working on an update to GPT-5’s personality which should feel warmer than the current personality but not as annoying (to most users) as GPT-4o,” Altman wrote in the post on X. “However, one learning for us from the past few days is we really just need to get to a world with more per-user customization of model personality.”&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3036523" height="288" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-12-at-8.27.16PM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;ChatGPT’s model picker now features several options (Credit: openai/maxwell zeff)&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s model picker now seems to be as complicated as ever, suggesting that GPT-5’s model router has not universally satisfied users as the company hoped. The expectations for GPT-5 were sky high, with many hoping that OpenAI would push the limits of AI models like it had with the launch of GPT-4. However, GPT-5’s rollout has been rougher than expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The deprecation of GPT-4o and other AI models in ChatGPT sparked a backlash among users who had grown attached to the AI models’ responses and personalities in ways that OpenAI had not anticipated. In the future, Altman says the company will give users plenty of advance notice if it ever deprecates GPT-4o.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;GPT-5’s model router also appeared to be largely broken on launch day. That caused some users to feel the AI model wasn’t as performant as previous OpenAI models, and forced Altman to address the problem in an AMA session on Reddit. However, it seems that GPT-5’s router may still not be satisfying for all users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re not always going to get everything on try #1 but I am very proud of how quickly the team can iterate,” wrote OpenAI’s VP of ChatGPT, Nick Turley, in a post on X Tuesday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Routing prompts to the right AI model is a difficult task that requires aligning an AI model to a user’s preferences, as well as the specific question they’re asking. The router then has to make a decision on which AI model to send the prompt to in just a split second — that way, if a prompt goes to a fast responding AI model, the response can still be fast.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;More broadly, some people exhibit preferences for AI models that go beyond fast or slow responses. Some users may like the verbosity of one AI model, while others might appreciate the contrarian answers of another. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Human attachment to certain AI models is a relatively new concept that isn’t well understood. For example, hundreds of people in San Francisco recently held a funeral for Anthropic’s AI model, Claude 3.5 Sonnet, when it was taken offline. In other cases, AI chatbots seem to be contributing to mentally unstable people going down psychotic rabbit holes. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It seems OpenAI has more work to do around aligning its AI models to individual user preferences. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/12/chatgpts-model-picker-is-back-and-its-complicated/</guid><pubDate>Wed, 13 Aug 2025 03:25:19 +0000</pubDate></item></channel></rss>