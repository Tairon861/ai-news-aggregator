<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Mon, 23 Feb 2026 13:11:34 +0000</lastBuildDate><item><title>Hitachi bets on industrial expertise to win the physical AI race (AI News)</title><link>https://www.artificialintelligence-news.com/news/hitachi-physical-ai-industrial-expertise/</link><description>&lt;p&gt;Physical AI – the branch of artificial intelligence that controls robots and industrial machinery in the real world – has a hierarchy problem. At the top, OpenAI and Google are scaling multimodal foundation models. In the middle, Nvidia is building the platforms and tools for physical AI development.&lt;/p&gt;&lt;p&gt;And then there is a third camp: industrial manufacturers like Hitachi and Germany’s Siemens, that are making the quieter but arguably more grounded argument that you cannot train machines to navigate the physical world without first understanding it.&lt;/p&gt;&lt;p&gt;That argument is now moving from boardroom strategy to factory floor deployment, as Hitachi revealed in a recent interview with&lt;em&gt; Nikkei Asia&lt;/em&gt;.&lt;/p&gt;&lt;h3&gt;Why Physical AI needs a better model&lt;/h3&gt;&lt;p&gt;Kosuke Yanai, deputy director of Hitachi’s Centre for Technology Innovation-Artificial Intelligence, is direct about what separates viable physical AI from the theoretical kind. “Physical AI cannot be implemented in society without a systematic understanding that begins with foundational knowledge of physics and industrial equipment,” he told &lt;em&gt;Nikkei&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Hitachi’s pitch is that it already holds much of that foundational knowledge – accumulated over decades of building railways, power infrastructure, and industrial control systems. The company has thermal fluid simulation technology that models the behaviour of gases and liquids, and signal-processing tools for monitoring equipment condition – what Yanai describes as the engineering foundation underpinning Hitachi’s ‘extensive knowledge of product design and control logic construction.’&lt;/p&gt;&lt;h3&gt;Daikin and JR East&lt;/h3&gt;&lt;p&gt;While Hitachi’s overarching physical AI architecture – the Integrated World Infrastructure Model (IWIM), which it describes as a mixture-of-experts system integrating multiple specialised models and data sets – remains in the concept verification stage, two real-world deployments signal that the underlying approach is already producing results.&lt;/p&gt;&lt;p&gt;In collaboration with Daikin Industries, Hitachi has deployed an AI system that diagnoses malfunctions in commercial air-conditioner manufacturing equipment. The system, trained on equipment maintenance records, procedure manuals, and design drawings, can now identify which component is likely failing when an anomaly is detected – the kind of operational intuition that previously existed only in the heads of experienced engineers.&lt;/p&gt;&lt;p&gt;With East Japan Railway (JR East), Hitachi has built an AI that identifies the root cause of malfunctions in the control devices running the Tokyo metropolitan area’s railway traffic management system, and then assists operators in formulating a response plan. In a network where delays ripple in millions of daily journeys, the ability to accelerate fault diagnosis carries real operational weight.&lt;/p&gt;&lt;h3&gt;The R&amp;amp;D pipeline: Cutting development time&lt;/h3&gt;&lt;p&gt;Hitachi’s physical AI push is also showing up in its research output. In December 2025, the company published findings from two projects presented at ASE 2025, a top-tier software engineering conference, that address a persistent bottleneck in industrial AI: the time and effort required to write and adapt control software.&lt;/p&gt;&lt;p&gt;In the automotive sector, Hitachi and its subsidiary Astemo developed a system that uses retrieval-augmented generation to automatically produce integration test scripts for vehicle electronic control units (ECUs) – pulling from hardware-specific API information and frontline engineering knowledge. In a pilot involving multi-core ECU testing, the technology reduced integration testing man-hours by 43% compared to manual execution.&lt;/p&gt;&lt;p&gt;In logistics, the company developed variability management technology that modularises robot control software into reusable components structured around a robot operating system (ROS). By mapping out the environmental variables and operational requirements of different warehouse settings in advance, the system lets operators adapt robotic picking-and-placing workflows to new products or layouts without rewriting software from scratch.&lt;/p&gt;&lt;h3&gt;Safety a structural requirement&lt;/h3&gt;&lt;p&gt;One thread that runs through all of Hitachi’s physical AI work is its emphasis on safety guardrails – not as a compliance checkbox, but as an engineering constraint baked into system design. Yanai told &lt;em&gt;Nikkei&lt;/em&gt; that the company is integrating its control and reliability technology from social infrastructure development to prevent AI outputs from deviating from human-approved operating parameters.&lt;/p&gt;&lt;p&gt;This includes input validation to screen out data that models should not be trained on, output verification to ensure machine actions do not endanger people or property, and real-time monitoring of the AI model itself for operational anomalies.&lt;/p&gt;&lt;p&gt;It is a distinction. Physical AI systems fail in the real world, not in a sandbox. The stakes for an AI controlling railway signalling or factory robotics are categorically different from those governing a chatbot.&lt;/p&gt;&lt;h3&gt;Infrastructure to match ambition&lt;/h3&gt;&lt;p&gt;On the infrastructure side, Hitachi Vantara – the group’s data and digital infrastructure arm – is positioning itself as an early adopter of NVIDIA’s RTX PRO Servers, built on the RTX PRO 6000 Blackwell Server Edition GPU, designed to accelerate agentic and physical AI workloads. The hardware is being paired with Hitachi’s iQ platform and used to build digital twins – virtual replicas of physical systems – that can simulate everything from grid fluctuations to robotic motion at scale.&lt;/p&gt;&lt;p&gt;The IWIM concept, meanwhile, is designed to connect Nvidia’s open-source Cosmos physical AI development platform with specialised Japanese-language LLMs and visual language models via the model context protocol (MCP) – essentially a framework to stitch together the models, simulation tools, and industrial datasets that physical AI systems require.&lt;/p&gt;&lt;p&gt;The broader race in physical AI is far from settled. But Hitachi’s position – that domain expertise and operational data are as important as model architecture – is increasingly hard to dismiss, particularly as deployments with partners like Daikin and JR East begin to demonstrate what that expertise is actually worth in practice.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Sources: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;Nikkei Asia (Feb 21, 2026); Hitachi R&amp;amp;D (Dec 24, 2025); Hitachi Vantara Blog (Aug 27, 2025)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also:&lt;/strong&gt;Alibaba enters physical AI race with open-source robot model RynnBrain&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Physical AI – the branch of artificial intelligence that controls robots and industrial machinery in the real world – has a hierarchy problem. At the top, OpenAI and Google are scaling multimodal foundation models. In the middle, Nvidia is building the platforms and tools for physical AI development.&lt;/p&gt;&lt;p&gt;And then there is a third camp: industrial manufacturers like Hitachi and Germany’s Siemens, that are making the quieter but arguably more grounded argument that you cannot train machines to navigate the physical world without first understanding it.&lt;/p&gt;&lt;p&gt;That argument is now moving from boardroom strategy to factory floor deployment, as Hitachi revealed in a recent interview with&lt;em&gt; Nikkei Asia&lt;/em&gt;.&lt;/p&gt;&lt;h3&gt;Why Physical AI needs a better model&lt;/h3&gt;&lt;p&gt;Kosuke Yanai, deputy director of Hitachi’s Centre for Technology Innovation-Artificial Intelligence, is direct about what separates viable physical AI from the theoretical kind. “Physical AI cannot be implemented in society without a systematic understanding that begins with foundational knowledge of physics and industrial equipment,” he told &lt;em&gt;Nikkei&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;Hitachi’s pitch is that it already holds much of that foundational knowledge – accumulated over decades of building railways, power infrastructure, and industrial control systems. The company has thermal fluid simulation technology that models the behaviour of gases and liquids, and signal-processing tools for monitoring equipment condition – what Yanai describes as the engineering foundation underpinning Hitachi’s ‘extensive knowledge of product design and control logic construction.’&lt;/p&gt;&lt;h3&gt;Daikin and JR East&lt;/h3&gt;&lt;p&gt;While Hitachi’s overarching physical AI architecture – the Integrated World Infrastructure Model (IWIM), which it describes as a mixture-of-experts system integrating multiple specialised models and data sets – remains in the concept verification stage, two real-world deployments signal that the underlying approach is already producing results.&lt;/p&gt;&lt;p&gt;In collaboration with Daikin Industries, Hitachi has deployed an AI system that diagnoses malfunctions in commercial air-conditioner manufacturing equipment. The system, trained on equipment maintenance records, procedure manuals, and design drawings, can now identify which component is likely failing when an anomaly is detected – the kind of operational intuition that previously existed only in the heads of experienced engineers.&lt;/p&gt;&lt;p&gt;With East Japan Railway (JR East), Hitachi has built an AI that identifies the root cause of malfunctions in the control devices running the Tokyo metropolitan area’s railway traffic management system, and then assists operators in formulating a response plan. In a network where delays ripple in millions of daily journeys, the ability to accelerate fault diagnosis carries real operational weight.&lt;/p&gt;&lt;h3&gt;The R&amp;amp;D pipeline: Cutting development time&lt;/h3&gt;&lt;p&gt;Hitachi’s physical AI push is also showing up in its research output. In December 2025, the company published findings from two projects presented at ASE 2025, a top-tier software engineering conference, that address a persistent bottleneck in industrial AI: the time and effort required to write and adapt control software.&lt;/p&gt;&lt;p&gt;In the automotive sector, Hitachi and its subsidiary Astemo developed a system that uses retrieval-augmented generation to automatically produce integration test scripts for vehicle electronic control units (ECUs) – pulling from hardware-specific API information and frontline engineering knowledge. In a pilot involving multi-core ECU testing, the technology reduced integration testing man-hours by 43% compared to manual execution.&lt;/p&gt;&lt;p&gt;In logistics, the company developed variability management technology that modularises robot control software into reusable components structured around a robot operating system (ROS). By mapping out the environmental variables and operational requirements of different warehouse settings in advance, the system lets operators adapt robotic picking-and-placing workflows to new products or layouts without rewriting software from scratch.&lt;/p&gt;&lt;h3&gt;Safety a structural requirement&lt;/h3&gt;&lt;p&gt;One thread that runs through all of Hitachi’s physical AI work is its emphasis on safety guardrails – not as a compliance checkbox, but as an engineering constraint baked into system design. Yanai told &lt;em&gt;Nikkei&lt;/em&gt; that the company is integrating its control and reliability technology from social infrastructure development to prevent AI outputs from deviating from human-approved operating parameters.&lt;/p&gt;&lt;p&gt;This includes input validation to screen out data that models should not be trained on, output verification to ensure machine actions do not endanger people or property, and real-time monitoring of the AI model itself for operational anomalies.&lt;/p&gt;&lt;p&gt;It is a distinction. Physical AI systems fail in the real world, not in a sandbox. The stakes for an AI controlling railway signalling or factory robotics are categorically different from those governing a chatbot.&lt;/p&gt;&lt;h3&gt;Infrastructure to match ambition&lt;/h3&gt;&lt;p&gt;On the infrastructure side, Hitachi Vantara – the group’s data and digital infrastructure arm – is positioning itself as an early adopter of NVIDIA’s RTX PRO Servers, built on the RTX PRO 6000 Blackwell Server Edition GPU, designed to accelerate agentic and physical AI workloads. The hardware is being paired with Hitachi’s iQ platform and used to build digital twins – virtual replicas of physical systems – that can simulate everything from grid fluctuations to robotic motion at scale.&lt;/p&gt;&lt;p&gt;The IWIM concept, meanwhile, is designed to connect Nvidia’s open-source Cosmos physical AI development platform with specialised Japanese-language LLMs and visual language models via the model context protocol (MCP) – essentially a framework to stitch together the models, simulation tools, and industrial datasets that physical AI systems require.&lt;/p&gt;&lt;p&gt;The broader race in physical AI is far from settled. But Hitachi’s position – that domain expertise and operational data are as important as model architecture – is increasingly hard to dismiss, particularly as deployments with partners like Daikin and JR East begin to demonstrate what that expertise is actually worth in practice.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;Sources: &lt;/em&gt;&lt;/strong&gt;&lt;em&gt;Nikkei Asia (Feb 21, 2026); Hitachi R&amp;amp;D (Dec 24, 2025); Hitachi Vantara Blog (Aug 27, 2025)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also:&lt;/strong&gt;Alibaba enters physical AI race with open-source robot model RynnBrain&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/hitachi-physical-ai-industrial-expertise/</guid><pubDate>Mon, 23 Feb 2026 07:00:00 +0000</pubDate></item><item><title>[NEW] How Amul is using AI dairy farming to put 36 million farmers first (AI News)</title><link>https://www.artificialintelligence-news.com/news/amul-ai-dairy-farming-platform-india/</link><description>&lt;p&gt;AI dairy farming has found its most ambitious deployment yet – not in a Silicon Valley lab nor a European agri-tech campus, but in the villages of Gujarat, India, where 36 lakh (3.6 million) women milk producers are now being served by an AI assistant named Sarlaben.&lt;/p&gt;&lt;p&gt;Amul, the world’s largest dairy cooperative, has launched what it calls Amul AI: a platform built on five decades of cooperative data, designed to give every farmer in its network round-the-clock, personalised guidance in their own language.&lt;/p&gt;&lt;p&gt;Amul was launched just ahead of India’s AI Impact Summit 2026 and backed by the Ministry of Electronics and Information Technology (MeitY) with the EkStep Foundation. It is a test case for whether AI – the kind being debated in boardrooms and policy forums globally – can actually reach the last mile.&lt;/p&gt;&lt;h3&gt;Meet Sarlaben: The AI dairy farming assistant&lt;/h3&gt;&lt;p&gt;Sarlaben draws from one of India’s most comprehensive agricultural data repositories. It’s accessible via the Amul Farmer mobile app – already downloaded by over 10 lakh (one million) users on Android and iOS – as well as through voice calls for farmers using feature phones or landlines.&lt;/p&gt;&lt;p&gt;The system is integrated with Amul’s Automatic Milk Collection System (AMCS) and the Pashudhan application, allowing it to offer personalised, cattle-specific guidance.&lt;/p&gt;&lt;p&gt;What makes Amul AI substantially different from most agricultural chatbots is the scale of its training data. The platform was built on a digital backbone managing over 200 crore (two billion) milk procurement transactions annually, veterinary treatment records from more than 1,200 doctors covering nearly 3 crore (30 million) cattle, approximately 70 lakh (seven million) artificial inseminations conducted each year, ISRO satellite imagery for fodder production mapping, and a cattle census conducted every five years.&lt;/p&gt;&lt;p&gt;Every animal in the system carries a unique ID, with individual records of feed intake, disease history and milking status. “Amul AI is about taking dependable, verified information directly to the farmer – instantly and in a language they are comfortable with,” said Jayen Mehta, Managing Director of the Gujarat Cooperative Milk Marketing Federation (GCMMF), which markets the Amul brand.&lt;/p&gt;&lt;p&gt;He said how, by using decades of structured data and integrating it with their operational systems, the platform will help farmers make timely decisions that improve animal productivity and income.&lt;/p&gt;&lt;h2&gt;India’s productivity paradox&lt;/h2&gt;&lt;p&gt;India is the world’s largest producer of milk, generating 347.87 million tonnes in 2024-25 according to the Department of Animal Husbandry and Dairying – more than double the US’s 102.70 million tonnes. And yet despite leading in volume, India’s per-animal milk yield remains among the lowest globally.&lt;/p&gt;&lt;p&gt;The reasons are structural. India’s dairy sector is characterised by small herd sizes, low-quality feed, limited access to veterinary care in rural areas, and widespread lack of awareness about modern breeding and husbandry practices. Amul’s network spans more than 18,600 villages in Gujarat, where farmers supply over 350 lakh litres (35 million litres) of milk daily.&lt;/p&gt;&lt;p&gt;But information asymmetry has long been a bottleneck – a farmer facing a sick animal at midnight in a remote village has few places to turn; the gap Amul AI is designed to close.&lt;/p&gt;&lt;p&gt;Available initially in Gujarati – the primary language of the cooperative’s farmer base – the platform is built on the government’s Bhashini multilingual framework and could, in principle, be extended to 20 Indian languages, reaching Amul’s presence in 20,000 villages in 20 states.&lt;/p&gt;&lt;h2&gt;The cooperative model&lt;/h2&gt;&lt;p&gt;The technology story here is inseparable from the institutional one. Amul’s cooperative structure – built over five decades under the original White Revolution – created the data infrastructure that makes Amul AI possible.&lt;/p&gt;&lt;p&gt;Most private agri-tech startups are working backwards: collecting data first, building products second. Amul already had the data. What was needed was a way to make it actionable at the farmer level.&lt;/p&gt;&lt;p&gt;Experts tracking the dairy-tech space see this as significant. Sreeshankar Nair, Founder of Brainwired, a dairy-tech startup, identifies three specific challenges that Amul AI could meaningfully address: farmer awareness, access to quality veterinary guidance, and connectivity to grazing and feed resources.&lt;/p&gt;&lt;p&gt;“If AI can integrate local dialects of Indian languages, India can have White Revolution 2.0,” Nair said, pointing to the transformative potential of vernacular AI in a sector where not every farmer speaks the same dialect.&lt;/p&gt;&lt;p&gt;Saswata Narayan Biswas, Director of the Institute of Rural Management, Anand (IRMA) – the institution closely associated with Amul’s founding ethos – frames it as an AI embedded in a cooperative framework. It becomes “not a technology upgrade, but an instrument of inclusive rural transformation.”&lt;/p&gt;&lt;p&gt;For Biswas, the specific abilities Amul AI brings – predictive disease detection, oestrus tracking, optimised feed formulation, localised weather risk advisories – are abilities Amul had been building for years. AI accelerates and democratises them.&lt;/p&gt;&lt;h2&gt;Scale and the test ahead&lt;/h2&gt;&lt;p&gt;The launch has drawn backing from the highest levels of government. Gujarat Chief Minister Bhupendra Patel launched the platform and confirmed it will be showcased at the AI Impact Summit 2026. The cooperative has acknowledged MeitY and the EkStep Foundation – an open digital infrastructure nonprofit – as partners in building the AI layer.&lt;/p&gt;&lt;p&gt;Farmers not affiliated with Amul can also access general dairying and animal husbandry information through the app. At its current scale, Amul AI already covers more cattle – nearly 3 crore (30 million) – than most national veterinary databases anywhere in the world.&lt;/p&gt;&lt;p&gt;The harder question, as with most AI deployments at a population scale, is whether the tool will serve those who need it most. The farmers most likely to benefit first – those already comfortable with smartphones, already plugged into Amul’s digital system – may not be the ones with the greatest information deficit.&lt;/p&gt;&lt;p&gt;The rollout of Bhashini-enabled dialect support, the adoption rate among feature-phone users relying on voice calls, and whether AI-driven advisories translate into measurable yield improvements will be the metrics that determine whether this is genuinely White Revolution 2.0.&lt;/p&gt;&lt;p&gt;Amul has built an AI system grounded in half a century of real cooperative transactions, real animals, and real farmers. Such an infrastructure is, arguably, the most credible foundation for AI dairy farming at scale. Whether it fulfils its promise will depend on execution – and on whether Sarlaben’s voice can reach in the last few miles; those that have always been the hardest to cross.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also:&lt;/strong&gt; &lt;strong&gt;Hitachi bets on industrial expertise to win the physical AI race&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;AI dairy farming has found its most ambitious deployment yet – not in a Silicon Valley lab nor a European agri-tech campus, but in the villages of Gujarat, India, where 36 lakh (3.6 million) women milk producers are now being served by an AI assistant named Sarlaben.&lt;/p&gt;&lt;p&gt;Amul, the world’s largest dairy cooperative, has launched what it calls Amul AI: a platform built on five decades of cooperative data, designed to give every farmer in its network round-the-clock, personalised guidance in their own language.&lt;/p&gt;&lt;p&gt;Amul was launched just ahead of India’s AI Impact Summit 2026 and backed by the Ministry of Electronics and Information Technology (MeitY) with the EkStep Foundation. It is a test case for whether AI – the kind being debated in boardrooms and policy forums globally – can actually reach the last mile.&lt;/p&gt;&lt;h3&gt;Meet Sarlaben: The AI dairy farming assistant&lt;/h3&gt;&lt;p&gt;Sarlaben draws from one of India’s most comprehensive agricultural data repositories. It’s accessible via the Amul Farmer mobile app – already downloaded by over 10 lakh (one million) users on Android and iOS – as well as through voice calls for farmers using feature phones or landlines.&lt;/p&gt;&lt;p&gt;The system is integrated with Amul’s Automatic Milk Collection System (AMCS) and the Pashudhan application, allowing it to offer personalised, cattle-specific guidance.&lt;/p&gt;&lt;p&gt;What makes Amul AI substantially different from most agricultural chatbots is the scale of its training data. The platform was built on a digital backbone managing over 200 crore (two billion) milk procurement transactions annually, veterinary treatment records from more than 1,200 doctors covering nearly 3 crore (30 million) cattle, approximately 70 lakh (seven million) artificial inseminations conducted each year, ISRO satellite imagery for fodder production mapping, and a cattle census conducted every five years.&lt;/p&gt;&lt;p&gt;Every animal in the system carries a unique ID, with individual records of feed intake, disease history and milking status. “Amul AI is about taking dependable, verified information directly to the farmer – instantly and in a language they are comfortable with,” said Jayen Mehta, Managing Director of the Gujarat Cooperative Milk Marketing Federation (GCMMF), which markets the Amul brand.&lt;/p&gt;&lt;p&gt;He said how, by using decades of structured data and integrating it with their operational systems, the platform will help farmers make timely decisions that improve animal productivity and income.&lt;/p&gt;&lt;h2&gt;India’s productivity paradox&lt;/h2&gt;&lt;p&gt;India is the world’s largest producer of milk, generating 347.87 million tonnes in 2024-25 according to the Department of Animal Husbandry and Dairying – more than double the US’s 102.70 million tonnes. And yet despite leading in volume, India’s per-animal milk yield remains among the lowest globally.&lt;/p&gt;&lt;p&gt;The reasons are structural. India’s dairy sector is characterised by small herd sizes, low-quality feed, limited access to veterinary care in rural areas, and widespread lack of awareness about modern breeding and husbandry practices. Amul’s network spans more than 18,600 villages in Gujarat, where farmers supply over 350 lakh litres (35 million litres) of milk daily.&lt;/p&gt;&lt;p&gt;But information asymmetry has long been a bottleneck – a farmer facing a sick animal at midnight in a remote village has few places to turn; the gap Amul AI is designed to close.&lt;/p&gt;&lt;p&gt;Available initially in Gujarati – the primary language of the cooperative’s farmer base – the platform is built on the government’s Bhashini multilingual framework and could, in principle, be extended to 20 Indian languages, reaching Amul’s presence in 20,000 villages in 20 states.&lt;/p&gt;&lt;h2&gt;The cooperative model&lt;/h2&gt;&lt;p&gt;The technology story here is inseparable from the institutional one. Amul’s cooperative structure – built over five decades under the original White Revolution – created the data infrastructure that makes Amul AI possible.&lt;/p&gt;&lt;p&gt;Most private agri-tech startups are working backwards: collecting data first, building products second. Amul already had the data. What was needed was a way to make it actionable at the farmer level.&lt;/p&gt;&lt;p&gt;Experts tracking the dairy-tech space see this as significant. Sreeshankar Nair, Founder of Brainwired, a dairy-tech startup, identifies three specific challenges that Amul AI could meaningfully address: farmer awareness, access to quality veterinary guidance, and connectivity to grazing and feed resources.&lt;/p&gt;&lt;p&gt;“If AI can integrate local dialects of Indian languages, India can have White Revolution 2.0,” Nair said, pointing to the transformative potential of vernacular AI in a sector where not every farmer speaks the same dialect.&lt;/p&gt;&lt;p&gt;Saswata Narayan Biswas, Director of the Institute of Rural Management, Anand (IRMA) – the institution closely associated with Amul’s founding ethos – frames it as an AI embedded in a cooperative framework. It becomes “not a technology upgrade, but an instrument of inclusive rural transformation.”&lt;/p&gt;&lt;p&gt;For Biswas, the specific abilities Amul AI brings – predictive disease detection, oestrus tracking, optimised feed formulation, localised weather risk advisories – are abilities Amul had been building for years. AI accelerates and democratises them.&lt;/p&gt;&lt;h2&gt;Scale and the test ahead&lt;/h2&gt;&lt;p&gt;The launch has drawn backing from the highest levels of government. Gujarat Chief Minister Bhupendra Patel launched the platform and confirmed it will be showcased at the AI Impact Summit 2026. The cooperative has acknowledged MeitY and the EkStep Foundation – an open digital infrastructure nonprofit – as partners in building the AI layer.&lt;/p&gt;&lt;p&gt;Farmers not affiliated with Amul can also access general dairying and animal husbandry information through the app. At its current scale, Amul AI already covers more cattle – nearly 3 crore (30 million) – than most national veterinary databases anywhere in the world.&lt;/p&gt;&lt;p&gt;The harder question, as with most AI deployments at a population scale, is whether the tool will serve those who need it most. The farmers most likely to benefit first – those already comfortable with smartphones, already plugged into Amul’s digital system – may not be the ones with the greatest information deficit.&lt;/p&gt;&lt;p&gt;The rollout of Bhashini-enabled dialect support, the adoption rate among feature-phone users relying on voice calls, and whether AI-driven advisories translate into measurable yield improvements will be the metrics that determine whether this is genuinely White Revolution 2.0.&lt;/p&gt;&lt;p&gt;Amul has built an AI system grounded in half a century of real cooperative transactions, real animals, and real farmers. Such an infrastructure is, arguably, the most credible foundation for AI dairy farming at scale. Whether it fulfils its promise will depend on execution – and on whether Sarlaben’s voice can reach in the last few miles; those that have always been the hardest to cross.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also:&lt;/strong&gt; &lt;strong&gt;Hitachi bets on industrial expertise to win the physical AI race&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/amul-ai-dairy-farming-platform-india/</guid><pubDate>Mon, 23 Feb 2026 09:00:00 +0000</pubDate></item><item><title>[NEW] Inside Chicago’s surveillance panopticon (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/23/1132740/inside-chicago-surveillance-panopticon/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Early on the morning of September 2, 2024, a Chicago Transit Authority Blue Line train was the scene of a random and horrific mass shooting. Four people were shot and killed on a westbound train as it approached the suburb of Forest Park.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The police swiftly activated a digital dragnet—a surveillance network that connects thousands of cameras in the city.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The process began with a quick review of the transit agency’s surveillance cameras, which captured the alleged gunman shooting the victims execution style. Law enforcement followed the suspect, through real-time footage, across the rapid-­transit system. Police officials circulated the images to transit staff and to thousands of officers. An officer in the adjacent suburb of Riverdale recognized the suspect from a previous arrest. By the time he was captured at another train station, just 90&amp;nbsp;minutes after the shooting, authorities already had his name, address, and previous arrest history.&lt;/p&gt;  &lt;p&gt;Little of this process would come as much surprise to Chicagoans. The city has tens of thousands of surveillance cameras—up to 45,000, by some estimates. That’s among the highest numbers per capita in the US. Chicago boasts one of the largest license plate reader systems in the country, and the ability to access audio and video surveillance from independent agencies such as the Chicago Public Schools, the Chicago Park District, and the public transportation system as well as many residential and commercial security systems such as Ring doorbell cameras.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Law enforcement and security advocates say this vast monitoring system protects public safety and works well. But activists and many residents say it’s a surveillance panopticon that creates a chilling effect on behavior and violates guarantees of privacy and free speech.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Black and Latino communities in Chicago have historically been targeted by excessive policing and surveillance, says Lance Williams, a scholar of urban violence at Northeastern Illinois University. That scrutiny has created new problems without delivering the promised safety, he suggests. In order to “solve the problem of crime or violence and make these communities safer,” he says, “you have to deal with structural problems,” such as the shortage of livable-wage jobs, affordable housing, and mental-health services across the city.&lt;/p&gt; 
 &lt;p&gt;Recent years have seen some effective pushback against the surveillance. Until recently, for example, the city was the largest customer of ShotSpotter acoustic sensors, which are designed to detect gunfire and alert police. The system was introduced in a small area on the South Side in 2012. By 2018, an area of about 136 square miles—some 60% of the city—was covered by the acoustic surveillance network.&lt;/p&gt;  &lt;p&gt;Critics questioned ShotSpotter’s effectiveness and objected that the sensors were installed largely in Black and Latino neighborhoods. Those critiques gained urgency with the fatal shooting in March 2021 of a 13-year-old, Adam Toledo, by police responding to a ShotSpotter alert. The tragedy became the touchstone of the #StopShotSpotter protest movement and one of the major issues in Brandon Johnson’s successful mayoral campaign in 2023. When he reached office, Johnson followed through, ending the city’s contract with SoundThinking, the San Francisco Bay Area company behind ShotSpotter. In total, it’s estimated the city paid more than $53 million for the system.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;In response to a request for comment, SoundThinking said that ShotSpotter enables law enforcement “to reach the scene faster, render aid to victims, and locate evidence more effectively.” It stated the company “plays no part in the selection of deployment areas” but added: “We believe communities experiencing the highest levels of gun violence deserve the same rapid emergency response as any other neighborhood.”&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;While there has been successful resistance to police surveillance in the nation’s third-largest city, there are also countervailing forces: governments and officials in Chicago and the surrounding suburbs are moving to expand the use of surveillance, also in response to public pressure. Even the victory against acoustic surveillance might be short-lived. Early last year, the city issued a request for proposals for gun violence detection technology.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;    &lt;p&gt;Many people in and around Chicago—digital privacy and surveillance activists, defense attorneys, law enforcement officials, and ordinary citizens—are part of this push and pull. Here are some of their stories.&amp;nbsp;&lt;/p&gt;    &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt; &lt;/div&gt;  &lt;h3 class="wp-block-heading"&gt;Alejandro Ruizesparza and Freddy Martinez&lt;br /&gt;Cofounders, Lucy Parsons Labs&lt;/h3&gt;  &lt;p&gt;Oak Park, a quiet suburb at Chicago’s western border, is the birthplace of Ernest Hemingway. It includes the world’s largest collection of Frank Lloyd Wright–designed buildings and homes.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Until recently, the village of Oak Park was also the center of a three-year-long campaign against an unwelcome addition to its manicured lawns and Prairie-style architecture: automated license plate readers from a company called Flock Safety. These are high-speed cameras that automatically scan license plates to look for stolen or wanted vehicles, or for drivers with outstanding warrants.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132945" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/LPL_DSF7601.jpg?w=2701" width="2701" /&gt;&lt;figcaption class="wp-element-caption"&gt;Freddy Martinez (left) and Alejandro Ruizesparza (right) direct Lucy Parsons Labs, a charitable organization focused on digital rights.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;An Oak Park group called Freedom to Thrive—made up of parents, activists, lawyers, data scientists, and many others—suspected that this technology was not a good or equitable addition to their neighborhood. So the group engaged the Chicago-based nonprofit Lucy Parsons Labs to help navigate the often intimidating process of requesting license plate reader data under the Illinois Freedom of Information Act.&lt;/p&gt;  &lt;p&gt;Lucy Parsons Labs, which is named for a turn-of-the-century Chicago labor organizer, investigates technologies such as license plate readers, gunshot detection systems, and police bodycams.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;LPL provides digital security and public records training to a variety of groups and is frequently called on to help community members audit and analyze surveillance systems that are targeting their neighborhoods. It’s led by two first-­generation Mexican-Americans from the city’s Southwest Side. Alejandro Ruizesparza has a background in community organizing and data science. Freddy Martinez was also a community organizer and has a background in physics.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;The group is now approaching its 10th year, but it was an all-volunteer effort until 2022. That’s when LPL received its first unrestricted, multi-year operational grant from a large foundation: the Chicago-based John D. and Catherine T. MacArthur Foundation, known worldwide for its so-called “genius grants.” A grant from the Ford Foundation followed the next year.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The additional resources—a significant amount compared with the previous all-volunteer budget, acknowledges Ruizesparza—meant the two cofounders and two volunteers became full-time employees. But the group is determined not to become “too comfortable” and lose its edge. There is a tenacity to Lucy Parsons Labs’ work—a “sense of scrappiness,” they say—because “we did so much of this work with no money.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One of LPL’s primary strategies is filing extensive FOIA requests for raw data sets of police surveillance. The process can take a while, but it often reveals issues.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In the case of Oak Park, the FOIA requests were just one tool that Freedom to Thrive and LPL used to sort out what was going on. The data revealed that in the first 10 months of operation, the eight Flock license plate readers the town had deployed scanned 3,000,000 plates. But only 42 scans led to an alert—an infinitesimal yield of 0.000014%.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;At the same time, the impacts of those few flagged license plates were disproportionate. While Oak Park’s population of about 53,000 is only 19% Black, Black drivers made up 85% of those flagged by the Flock cameras, seemingly amplifying what were already concerning racial disparities in the village’s traffic stops. Flock did not respond to a request for comment.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“We became almost de facto experts in navigating the process and the law. I think that sort of speaks to some of the DIY punk aesthetic.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Freddy Martinez, cofounder, Lucy Parsons Labs&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;LPL brings a mix of radical politics and critical theory to its mission. Most surveillance technologies are “largely extensions of the plantation systems,” says Ruizesparza.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The comparison makes sense: Many slaveholding communities required enslaved persons to carry signed documents to leave plantations and wear badges with numbers sewn to their clothing. The group says it aims to empower local communities to push back against biased policing technologies through technical assistance, training, and litigation—and to de­mystify algorithms and surveillance tools in the process.&lt;/p&gt;  &lt;p&gt;“When we talk to people, they realize that you don’t need to know how to run a regression to understand that a technology has negative implications on your life,” says Ruizesparza. “You don’t need to understand how circuits work to understand that you probably shouldn’t have all of these cameras embedded in only Black and brown regions of a city.”&lt;/p&gt; 
 &lt;p&gt;The group came by some of its techniques through experimentation. “When LPL was first getting started, we didn’t really feel like FOIA would have been a good way of getting information. We didn’t know anything about it,” says Martinez. “Along the way, we were very successful in uncovering a lot of surveillance practices.”&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;One of the covert surveillance practices uncovered by those aggressive FOIA requests, for example, was the Chicago Police Department’s use of “Stingray” equipment, portable surveillance devices deployed to track and monitor mobile phones.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;The contentious issue of Oak Park’s license plate readers was finally put to a vote in late August. The village trustees voted 5–2 to terminate the contract with Flock Safety.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Since then, community-­based groups from across the country—as far away as California—have contacted LPL to say the Chicago collective’s work has inspired their own efforts, says Martinez: “We became almost de facto experts in navigating the process and the law. I think that sort of speaks to some of the DIY punk aesthetic.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Brian Strockis &lt;br /&gt;Chief, Oak Brook Police Department&lt;/h3&gt;  &lt;p&gt;If you drive about 20 miles west of Chicago, you’ll find Oakbrook Center, one of the nation’s leading luxury shopping destinations. The open-air mall includes Neiman-Marcus, Louis Vuitton, and Gucci and attracts high-end shoppers from across the region. It’s also become a destination for retail theft crews that coordinate “smash and grabs” and often escape with thousands of dollars’ worth of inventory that can be quickly sold, such as sunglasses or luxury handbags.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In early December, police say, a Chicago man tried to lead officers on what could have been a dangerous high-speed chase from the mall. Patrol cars raced to the scene. So did a “first responder drone,” built by Flock Safety and deployed by the Oak Brook Police Department. &amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;The drone identified the suspect vehicle from the mall parking lot using its license plate reader and snapped high-definition photos that were texted to officers on the ground. The suspect was later tracked to Chicago, where he was arrested.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132947" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/BrianStorkis_DSF6009.jpg?w=2756" width="2756" /&gt;&lt;figcaption class="wp-element-caption"&gt;Brian Strockis, chief of the Oak Brook Police Department, led the way in introducing drones as first responders in the state of Illinois.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;This was the type of outcome that Brian Strockis, chief of the Oak Brook Police Department, hoped for when he pioneered the “drone as first responder,” or DFR, program in Illinois. A longtime member of the force, he joined the department almost 25 years ago as a patrol officer, worked his way up the brass ladder, and was awarded the top job in 2022.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Oak Brook was the first municipality in Illinois to deploy a drone as a first responder. One of the main reasons, says Strockis, was to reduce the number of high-speed chases, which are potentially dangerous to officers, suspects, and civilians. A drone is also a more effective and cost-efficient way to deal with suspects in fleeing vehicles, says Strockis.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Police say there was the potential for a dangerous high-speed chase. Patrol cars raced to the scene. But the first unit to arrive was a drone.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;“It’s a force multiplier in that we’re able to do more with less,” says the chief, who spoke with me in his office at Oak Brook’s Village Hall.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The department’s drone autonomously launches from the roof of the building and responds to about 10 to 12 service calls per day, at speeds up to 45 miles per hour. It arrives at crime scenes before patrol officers in nine out of every 10 cases.&lt;/p&gt;  &lt;p&gt;Next door to Village Hall is the Oak Brook Police Department’s real-time crime center, a large room with two video walls that integrates livestreams from the first-responder drone, handheld drones, traffic cameras, license plate readers, and about a thousand private security cameras. When I visited, the two DFR operators demonstrated how the machine can fly itself or be directed to locations from a destination entered on Google Maps. They sent it off to a nearby forest preserve and then directed it to return to the rooftop base, where it docks automatically, changes batteries, and charges. After the demo, one of the drone operators logged the flight, as required by state law.&lt;/p&gt;  &lt;p&gt;Strockis says he is aware of the privacy concerns around using this technology but that protections are in place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For example, the drone cannot be used for random or mass surveillance, he says, because the camera is always pointed straight ahead during flight and does not angle down until it reaches its desired location. The drone’s payload does not include facial recognition technology, which is restricted by state law, he says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;The drone video footage is invaluable, he adds, because “you are seeing the events as they’re transpiring from an angle that you wouldn’t otherwise be privy to.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s an extra layer of protection for the public as well as for the officers, says the chief: “For every incident that an officer responds to now, you have squad car and bodycam video. You likely have cell-phone video from the public, officers, complainants, from offenders. So adding this element is probably the best video source on a scene that the police are going to anyway.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Mark Wallace &lt;br /&gt;Executive director, Citizens to Abolish Red Light Cameras&lt;/h3&gt;  &lt;p&gt;Mark Wallace wears several hats. By day he is a real estate investor and mortgage lender. But he is probably best known to many Chicagoans—especially across the city’s largely African-American communities on the South and West Sides—as a talk radio host for the station WVON and one of the leading voices against the city’s extensive network of red-light and speed cameras.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For the past two decades, city officials have maintained that the cameras—which are officially known as “automated enforcement”—are a crucial safety measure. They are also a substantial revenue stream, generating around $150 million a year and a total of some $2.5 billion since they were installed.&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132948" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MarkWallace_DSF6241.jpg?w=1567" width="1567" /&gt;&lt;figcaption class="wp-element-caption"&gt;Urged on by a radio listener, Mark Wallace started organizing against Chicago’s red-light and speed cameras, a substantial revenue stream for the city that has been found to disproportionately burden majority Black and Latino areas.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“The one thing that the cameras have the ability to do is generate a lot of money,” Wallace says. He describes the tickets as a “cash grab” that disproportionately affects Black and Latino communities.&lt;/p&gt;  &lt;p&gt;A groundbreaking 2022 analysis by ProPublica found, in fact, that households in majority Black and Latino zip codes were ticketed at much higher rates than others, in part because the cameras in those areas were more likely to be installed near expressway ramps and on wider streets, which encouraged faster speeds. The tickets, which can quickly rack up late fees, were also found to cause more of a financial burden in such communities, the report found.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;These were some of the same concerns that many people expressed on the radio and in meetings, Wallace says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Chicago’s automated traffic enforcement began in 2003, and it became the most extensive—and most lucrative—such program in the country. About 300 red-light cameras and 200 speed cameras are set up near schools and parks. The cost of the tickets can quickly double if they are not paid or contested—providing a windfall for the city. &amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt; &lt;p&gt;Wallace began his advocacy against the cameras soon after arriving at the radio station in the early 2010s. A younger listener called in and said, he recalls, “that he enjoyed the information that came from WVON but that we didn’t do anything.” The comment stuck with him, especially in light of WVON’s storied history. The station was closely involved in the civil rights movement of the 1960s and broadcast Martin Luther King Jr.’s speeches during his Chicago campaign.&lt;/p&gt;  &lt;p&gt;Wallace hoped to change the caller’s perception about the station. He had firsthand experience with red-light cameras,&amp;nbsp; having been ticketed himself, and decided to take them on as a cause. He scheduled a meeting at his church for a Friday night, promoting it on his show. “More than 300 people showed up,” he remembers, chatting with me in the spacious project studio and office in the basement of his townhouse on the city’s South Side. “That said to me there are a lot of people who see this in­equity and injustice.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt; &lt;p&gt;Wallace began using his platform on WVON—&lt;em&gt;The People’s Show&lt;/em&gt;—to mobilize communities around social and economic justice, and many discussions revolved around the automated enforcement program. The cause gained traction after city and state officials were found to have taken thousands of dollars from technology and surveillance companies to make sure their cameras remained on the streets.&lt;/p&gt;  &lt;p&gt;Wallace and his group, Citizens to Abolish Red Light Cameras, want to repeal the ordinances authorizing the city’s camera programs. That hasn’t happened so far, but political pressure from the group paved the way for a Chicago City Council ordinance that required public meetings before any red-light cameras are installed, removed, or relocated. The group hopes for more restrictions for speed cameras, too.&lt;/p&gt;  &lt;p&gt;“It was never about me personally. It was about ensuring that we could demonstrate to people that you have power,” says Wallace. “If you don’t like something, as Barack Obama would say, get a pen and clipboard and go to work to fight to make these changes.”&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Jonathan Manes &lt;br /&gt;Senior counsel, MacArthur Justice Center&lt;/h3&gt;  &lt;p&gt;Derick Scruggs, a 30-year-old father and licensed armed security guard, was working in the parking lot of an AutoZone on Chicago’s Southwest Side on April 19, 2021. That’s when he was detained, interrogated, and subjected to a “humiliating body search” by two Chicago police officers, Scruggs later attested. “I was just doing my job when police officers came at me, handcuffed me, and treated me like a criminal—just because I was near a ShotSpotter alert,” he says.&lt;/p&gt;  &lt;p&gt;The officers found no evidence of a shooting and released Scruggs. But the next day, the police returned and arrested him for an alleged violation related to his security guard paperwork. Prosecutors later dismissed the charges, but he was held in custody overnight and was then fired from his job. “Because of what they did,” he says, “I lost my job, couldn’t work for months, and got evicted from my apartment.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132949" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/JonathanM_DSF6795.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;Jonathan Manes litigated cases related to detentions at Guantanamo Bay and the legality of drone strikes before turning his attention to Chicago’s implementation of gunshot detection technology.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Scruggs is believed to be among thousands of Chicagoans who’ve been questioned, detained, or arrested by police because they were near the location of a ShotSpotter alert, according to an analysis by the City of Chicago Office of Inspector General. The case caught the attention of Jonathan Manes, a law professor at Northwestern and senior counsel at the MacArthur Justice Center, a public interest law firm.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_28"&gt; &lt;p&gt;Manes previously worked in national security law, but when he joined the justice center about six years ago, he chose to focus squarely on the intersection of civil rights with police surveillance and technology. “My goal was to identify areas that weren’t well covered by other civil rights organizations but were a concern for people here in Chicago,” he says.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“There is a need for much broader structural change to how the city chooses to use surveillance technology and then deploys it.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Jonathan Manes, senior counsel, MacArthur Justice Center&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;And when he and his colleagues looked into ShotSpotter, they revealed a disturbing problem: The system generated alerts that yielded no evidence of gun-­related crimes but were used by police as a pretext for other actions. There seemed to be “a pattern of people being stopped, detained, questioned, sometimes arrested, in response to a ShotSpotter alert—often resulting in charges that have nothing to do with guns,” Manes says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The system also directed a “massive number of police deployments onto the South and West Sides of the city,” Manes says. Those regions are home to most of Chicago’s Black and Latino residents. The research showed that 80% of the city’s Black population but only 30% of its white population lived in districts covered by the system.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Manes brought Scruggs’s case into a lawsuit that he was already developing against the city’s use of ShotSpotter. In late 2025, he and his colleagues reached a settlement that prohibits police officers from doing what they did in Scruggs’s case—stopping or searching people simply because they are near the location of a gunshot detection alert.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_30"&gt;&lt;p&gt;Chicago had already decommissioned ShotSpotter in 2024, but the agreement will cover any future gunshot detection systems. Manes is carefully watching to see what happens next.&lt;/p&gt;  &lt;p&gt;Though Manes is pleased with the settlement, he points out that it narrowly focused on how police resources were used &lt;em&gt;after&lt;/em&gt; the gunshot detection system was operational. “There is a need for much broader structural change to how the city chooses to use surveillance technology and then deploys it,” he adds. He supports laws that require disclosure from local officials and law enforcement about what technologies are being proposed and how civil rights could be affected. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;More than two dozen jurisdictions nationwide have adopted surveillance transparency laws, including San Francisco, Seattle, Boston, and New York City. But so far Chicago is not on that list.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Rod McCullom is a Chicago-based science and technology writer whose focus areas include AI, biometrics, cognition, and the science of crime and violence. &amp;nbsp;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Early on the morning of September 2, 2024, a Chicago Transit Authority Blue Line train was the scene of a random and horrific mass shooting. Four people were shot and killed on a westbound train as it approached the suburb of Forest Park.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The police swiftly activated a digital dragnet—a surveillance network that connects thousands of cameras in the city.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_3"&gt; &lt;p&gt;The process began with a quick review of the transit agency’s surveillance cameras, which captured the alleged gunman shooting the victims execution style. Law enforcement followed the suspect, through real-time footage, across the rapid-­transit system. Police officials circulated the images to transit staff and to thousands of officers. An officer in the adjacent suburb of Riverdale recognized the suspect from a previous arrest. By the time he was captured at another train station, just 90&amp;nbsp;minutes after the shooting, authorities already had his name, address, and previous arrest history.&lt;/p&gt;  &lt;p&gt;Little of this process would come as much surprise to Chicagoans. The city has tens of thousands of surveillance cameras—up to 45,000, by some estimates. That’s among the highest numbers per capita in the US. Chicago boasts one of the largest license plate reader systems in the country, and the ability to access audio and video surveillance from independent agencies such as the Chicago Public Schools, the Chicago Park District, and the public transportation system as well as many residential and commercial security systems such as Ring doorbell cameras.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_5"&gt; &lt;p&gt;Law enforcement and security advocates say this vast monitoring system protects public safety and works well. But activists and many residents say it’s a surveillance panopticon that creates a chilling effect on behavior and violates guarantees of privacy and free speech.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Black and Latino communities in Chicago have historically been targeted by excessive policing and surveillance, says Lance Williams, a scholar of urban violence at Northeastern Illinois University. That scrutiny has created new problems without delivering the promised safety, he suggests. In order to “solve the problem of crime or violence and make these communities safer,” he says, “you have to deal with structural problems,” such as the shortage of livable-wage jobs, affordable housing, and mental-health services across the city.&lt;/p&gt; 
 &lt;p&gt;Recent years have seen some effective pushback against the surveillance. Until recently, for example, the city was the largest customer of ShotSpotter acoustic sensors, which are designed to detect gunfire and alert police. The system was introduced in a small area on the South Side in 2012. By 2018, an area of about 136 square miles—some 60% of the city—was covered by the acoustic surveillance network.&lt;/p&gt;  &lt;p&gt;Critics questioned ShotSpotter’s effectiveness and objected that the sensors were installed largely in Black and Latino neighborhoods. Those critiques gained urgency with the fatal shooting in March 2021 of a 13-year-old, Adam Toledo, by police responding to a ShotSpotter alert. The tragedy became the touchstone of the #StopShotSpotter protest movement and one of the major issues in Brandon Johnson’s successful mayoral campaign in 2023. When he reached office, Johnson followed through, ending the city’s contract with SoundThinking, the San Francisco Bay Area company behind ShotSpotter. In total, it’s estimated the city paid more than $53 million for the system.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;In response to a request for comment, SoundThinking said that ShotSpotter enables law enforcement “to reach the scene faster, render aid to victims, and locate evidence more effectively.” It stated the company “plays no part in the selection of deployment areas” but added: “We believe communities experiencing the highest levels of gun violence deserve the same rapid emergency response as any other neighborhood.”&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;While there has been successful resistance to police surveillance in the nation’s third-largest city, there are also countervailing forces: governments and officials in Chicago and the surrounding suburbs are moving to expand the use of surveillance, also in response to public pressure. Even the victory against acoustic surveillance might be short-lived. Early last year, the city issued a request for proposals for gun violence detection technology.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;    &lt;p&gt;Many people in and around Chicago—digital privacy and surveillance activists, defense attorneys, law enforcement officials, and ordinary citizens—are part of this push and pull. Here are some of their stories.&amp;nbsp;&lt;/p&gt;    &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt; &lt;/div&gt;  &lt;h3 class="wp-block-heading"&gt;Alejandro Ruizesparza and Freddy Martinez&lt;br /&gt;Cofounders, Lucy Parsons Labs&lt;/h3&gt;  &lt;p&gt;Oak Park, a quiet suburb at Chicago’s western border, is the birthplace of Ernest Hemingway. It includes the world’s largest collection of Frank Lloyd Wright–designed buildings and homes.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Until recently, the village of Oak Park was also the center of a three-year-long campaign against an unwelcome addition to its manicured lawns and Prairie-style architecture: automated license plate readers from a company called Flock Safety. These are high-speed cameras that automatically scan license plates to look for stolen or wanted vehicles, or for drivers with outstanding warrants.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132945" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/LPL_DSF7601.jpg?w=2701" width="2701" /&gt;&lt;figcaption class="wp-element-caption"&gt;Freddy Martinez (left) and Alejandro Ruizesparza (right) direct Lucy Parsons Labs, a charitable organization focused on digital rights.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;An Oak Park group called Freedom to Thrive—made up of parents, activists, lawyers, data scientists, and many others—suspected that this technology was not a good or equitable addition to their neighborhood. So the group engaged the Chicago-based nonprofit Lucy Parsons Labs to help navigate the often intimidating process of requesting license plate reader data under the Illinois Freedom of Information Act.&lt;/p&gt;  &lt;p&gt;Lucy Parsons Labs, which is named for a turn-of-the-century Chicago labor organizer, investigates technologies such as license plate readers, gunshot detection systems, and police bodycams.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;LPL provides digital security and public records training to a variety of groups and is frequently called on to help community members audit and analyze surveillance systems that are targeting their neighborhoods. It’s led by two first-­generation Mexican-Americans from the city’s Southwest Side. Alejandro Ruizesparza has a background in community organizing and data science. Freddy Martinez was also a community organizer and has a background in physics.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt; &lt;p&gt;The group is now approaching its 10th year, but it was an all-volunteer effort until 2022. That’s when LPL received its first unrestricted, multi-year operational grant from a large foundation: the Chicago-based John D. and Catherine T. MacArthur Foundation, known worldwide for its so-called “genius grants.” A grant from the Ford Foundation followed the next year.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_11"&gt; &lt;p&gt;The additional resources—a significant amount compared with the previous all-volunteer budget, acknowledges Ruizesparza—meant the two cofounders and two volunteers became full-time employees. But the group is determined not to become “too comfortable” and lose its edge. There is a tenacity to Lucy Parsons Labs’ work—a “sense of scrappiness,” they say—because “we did so much of this work with no money.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;One of LPL’s primary strategies is filing extensive FOIA requests for raw data sets of police surveillance. The process can take a while, but it often reveals issues.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In the case of Oak Park, the FOIA requests were just one tool that Freedom to Thrive and LPL used to sort out what was going on. The data revealed that in the first 10 months of operation, the eight Flock license plate readers the town had deployed scanned 3,000,000 plates. But only 42 scans led to an alert—an infinitesimal yield of 0.000014%.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;At the same time, the impacts of those few flagged license plates were disproportionate. While Oak Park’s population of about 53,000 is only 19% Black, Black drivers made up 85% of those flagged by the Flock cameras, seemingly amplifying what were already concerning racial disparities in the village’s traffic stops. Flock did not respond to a request for comment.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“We became almost de facto experts in navigating the process and the law. I think that sort of speaks to some of the DIY punk aesthetic.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Freddy Martinez, cofounder, Lucy Parsons Labs&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;LPL brings a mix of radical politics and critical theory to its mission. Most surveillance technologies are “largely extensions of the plantation systems,” says Ruizesparza.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The comparison makes sense: Many slaveholding communities required enslaved persons to carry signed documents to leave plantations and wear badges with numbers sewn to their clothing. The group says it aims to empower local communities to push back against biased policing technologies through technical assistance, training, and litigation—and to de­mystify algorithms and surveillance tools in the process.&lt;/p&gt;  &lt;p&gt;“When we talk to people, they realize that you don’t need to know how to run a regression to understand that a technology has negative implications on your life,” says Ruizesparza. “You don’t need to understand how circuits work to understand that you probably shouldn’t have all of these cameras embedded in only Black and brown regions of a city.”&lt;/p&gt; 
 &lt;p&gt;The group came by some of its techniques through experimentation. “When LPL was first getting started, we didn’t really feel like FOIA would have been a good way of getting information. We didn’t know anything about it,” says Martinez. “Along the way, we were very successful in uncovering a lot of surveillance practices.”&amp;nbsp;&lt;/p&gt;  &lt;div class="wp-block-group is-layout-constrained wp-block-group-is-layout-constrained"&gt; &lt;p&gt;One of the covert surveillance practices uncovered by those aggressive FOIA requests, for example, was the Chicago Police Department’s use of “Stingray” equipment, portable surveillance devices deployed to track and monitor mobile phones.&amp;nbsp;&lt;/p&gt;    &lt;p&gt;The contentious issue of Oak Park’s license plate readers was finally put to a vote in late August. The village trustees voted 5–2 to terminate the contract with Flock Safety.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;  &lt;p&gt;Since then, community-­based groups from across the country—as far away as California—have contacted LPL to say the Chicago collective’s work has inspired their own efforts, says Martinez: “We became almost de facto experts in navigating the process and the law. I think that sort of speaks to some of the DIY punk aesthetic.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Brian Strockis &lt;br /&gt;Chief, Oak Brook Police Department&lt;/h3&gt;  &lt;p&gt;If you drive about 20 miles west of Chicago, you’ll find Oakbrook Center, one of the nation’s leading luxury shopping destinations. The open-air mall includes Neiman-Marcus, Louis Vuitton, and Gucci and attracts high-end shoppers from across the region. It’s also become a destination for retail theft crews that coordinate “smash and grabs” and often escape with thousands of dollars’ worth of inventory that can be quickly sold, such as sunglasses or luxury handbags.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In early December, police say, a Chicago man tried to lead officers on what could have been a dangerous high-speed chase from the mall. Patrol cars raced to the scene. So did a “first responder drone,” built by Flock Safety and deployed by the Oak Brook Police Department. &amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;The drone identified the suspect vehicle from the mall parking lot using its license plate reader and snapped high-definition photos that were texted to officers on the ground. The suspect was later tracked to Chicago, where he was arrested.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132947" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/BrianStorkis_DSF6009.jpg?w=2756" width="2756" /&gt;&lt;figcaption class="wp-element-caption"&gt;Brian Strockis, chief of the Oak Brook Police Department, led the way in introducing drones as first responders in the state of Illinois.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;This was the type of outcome that Brian Strockis, chief of the Oak Brook Police Department, hoped for when he pioneered the “drone as first responder,” or DFR, program in Illinois. A longtime member of the force, he joined the department almost 25 years ago as a patrol officer, worked his way up the brass ladder, and was awarded the top job in 2022.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Oak Brook was the first municipality in Illinois to deploy a drone as a first responder. One of the main reasons, says Strockis, was to reduce the number of high-speed chases, which are potentially dangerous to officers, suspects, and civilians. A drone is also a more effective and cost-efficient way to deal with suspects in fleeing vehicles, says Strockis.&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;Police say there was the potential for a dangerous high-speed chase. Patrol cars raced to the scene. But the first unit to arrive was a drone.&lt;/strong&gt;&lt;/p&gt; &lt;/blockquote&gt;  &lt;p&gt;“It’s a force multiplier in that we’re able to do more with less,” says the chief, who spoke with me in his office at Oak Brook’s Village Hall.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The department’s drone autonomously launches from the roof of the building and responds to about 10 to 12 service calls per day, at speeds up to 45 miles per hour. It arrives at crime scenes before patrol officers in nine out of every 10 cases.&lt;/p&gt;  &lt;p&gt;Next door to Village Hall is the Oak Brook Police Department’s real-time crime center, a large room with two video walls that integrates livestreams from the first-responder drone, handheld drones, traffic cameras, license plate readers, and about a thousand private security cameras. When I visited, the two DFR operators demonstrated how the machine can fly itself or be directed to locations from a destination entered on Google Maps. They sent it off to a nearby forest preserve and then directed it to return to the rooftop base, where it docks automatically, changes batteries, and charges. After the demo, one of the drone operators logged the flight, as required by state law.&lt;/p&gt;  &lt;p&gt;Strockis says he is aware of the privacy concerns around using this technology but that protections are in place.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For example, the drone cannot be used for random or mass surveillance, he says, because the camera is always pointed straight ahead during flight and does not angle down until it reaches its desired location. The drone’s payload does not include facial recognition technology, which is restricted by state law, he says.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_20"&gt; &lt;p&gt;The drone video footage is invaluable, he adds, because “you are seeing the events as they’re transpiring from an angle that you wouldn’t otherwise be privy to.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;It’s an extra layer of protection for the public as well as for the officers, says the chief: “For every incident that an officer responds to now, you have squad car and bodycam video. You likely have cell-phone video from the public, officers, complainants, from offenders. So adding this element is probably the best video source on a scene that the police are going to anyway.”&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Mark Wallace &lt;br /&gt;Executive director, Citizens to Abolish Red Light Cameras&lt;/h3&gt;  &lt;p&gt;Mark Wallace wears several hats. By day he is a real estate investor and mortgage lender. But he is probably best known to many Chicagoans—especially across the city’s largely African-American communities on the South and West Sides—as a talk radio host for the station WVON and one of the leading voices against the city’s extensive network of red-light and speed cameras.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For the past two decades, city officials have maintained that the cameras—which are officially known as “automated enforcement”—are a crucial safety measure. They are also a substantial revenue stream, generating around $150 million a year and a total of some $2.5 billion since they were installed.&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132948" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/MarkWallace_DSF6241.jpg?w=1567" width="1567" /&gt;&lt;figcaption class="wp-element-caption"&gt;Urged on by a radio listener, Mark Wallace started organizing against Chicago’s red-light and speed cameras, a substantial revenue stream for the city that has been found to disproportionately burden majority Black and Latino areas.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;“The one thing that the cameras have the ability to do is generate a lot of money,” Wallace says. He describes the tickets as a “cash grab” that disproportionately affects Black and Latino communities.&lt;/p&gt;  &lt;p&gt;A groundbreaking 2022 analysis by ProPublica found, in fact, that households in majority Black and Latino zip codes were ticketed at much higher rates than others, in part because the cameras in those areas were more likely to be installed near expressway ramps and on wider streets, which encouraged faster speeds. The tickets, which can quickly rack up late fees, were also found to cause more of a financial burden in such communities, the report found.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_22"&gt; &lt;p&gt;These were some of the same concerns that many people expressed on the radio and in meetings, Wallace says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Chicago’s automated traffic enforcement began in 2003, and it became the most extensive—and most lucrative—such program in the country. About 300 red-light cameras and 200 speed cameras are set up near schools and parks. The cost of the tickets can quickly double if they are not paid or contested—providing a windfall for the city. &amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_24"&gt; &lt;p&gt;Wallace began his advocacy against the cameras soon after arriving at the radio station in the early 2010s. A younger listener called in and said, he recalls, “that he enjoyed the information that came from WVON but that we didn’t do anything.” The comment stuck with him, especially in light of WVON’s storied history. The station was closely involved in the civil rights movement of the 1960s and broadcast Martin Luther King Jr.’s speeches during his Chicago campaign.&lt;/p&gt;  &lt;p&gt;Wallace hoped to change the caller’s perception about the station. He had firsthand experience with red-light cameras,&amp;nbsp; having been ticketed himself, and decided to take them on as a cause. He scheduled a meeting at his church for a Friday night, promoting it on his show. “More than 300 people showed up,” he remembers, chatting with me in the spacious project studio and office in the basement of his townhouse on the city’s South Side. “That said to me there are a lot of people who see this in­equity and injustice.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt; &lt;p&gt;Wallace began using his platform on WVON—&lt;em&gt;The People’s Show&lt;/em&gt;—to mobilize communities around social and economic justice, and many discussions revolved around the automated enforcement program. The cause gained traction after city and state officials were found to have taken thousands of dollars from technology and surveillance companies to make sure their cameras remained on the streets.&lt;/p&gt;  &lt;p&gt;Wallace and his group, Citizens to Abolish Red Light Cameras, want to repeal the ordinances authorizing the city’s camera programs. That hasn’t happened so far, but political pressure from the group paved the way for a Chicago City Council ordinance that required public meetings before any red-light cameras are installed, removed, or relocated. The group hopes for more restrictions for speed cameras, too.&lt;/p&gt;  &lt;p&gt;“It was never about me personally. It was about ensuring that we could demonstrate to people that you have power,” says Wallace. “If you don’t like something, as Barack Obama would say, get a pen and clipboard and go to work to fight to make these changes.”&amp;nbsp;&lt;/p&gt;  &lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;  &lt;h3 class="wp-block-heading"&gt;Jonathan Manes &lt;br /&gt;Senior counsel, MacArthur Justice Center&lt;/h3&gt;  &lt;p&gt;Derick Scruggs, a 30-year-old father and licensed armed security guard, was working in the parking lot of an AutoZone on Chicago’s Southwest Side on April 19, 2021. That’s when he was detained, interrogated, and subjected to a “humiliating body search” by two Chicago police officers, Scruggs later attested. “I was just doing my job when police officers came at me, handcuffed me, and treated me like a criminal—just because I was near a ShotSpotter alert,” he says.&lt;/p&gt;  &lt;p&gt;The officers found no evidence of a shooting and released Scruggs. But the next day, the police returned and arrested him for an alleged violation related to his security guard paperwork. Prosecutors later dismissed the charges, but he was held in custody overnight and was then fired from his job. “Because of what they did,” he says, “I lost my job, couldn’t work for months, and got evicted from my apartment.”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1132949" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/JonathanM_DSF6795.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;Jonathan Manes litigated cases related to detentions at Guantanamo Bay and the legality of drone strikes before turning his attention to Chicago’s implementation of gunshot detection technology.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;AKILAH TOWNSEND&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Scruggs is believed to be among thousands of Chicagoans who’ve been questioned, detained, or arrested by police because they were near the location of a ShotSpotter alert, according to an analysis by the City of Chicago Office of Inspector General. The case caught the attention of Jonathan Manes, a law professor at Northwestern and senior counsel at the MacArthur Justice Center, a public interest law firm.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_28"&gt; &lt;p&gt;Manes previously worked in national security law, but when he joined the justice center about six years ago, he chose to focus squarely on the intersection of civil rights with police surveillance and technology. “My goal was to identify areas that weren’t well covered by other civil rights organizations but were a concern for people here in Chicago,” he says.&amp;nbsp;&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“There is a need for much broader structural change to how the city chooses to use surveillance technology and then deploys it.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Jonathan Manes, senior counsel, MacArthur Justice Center&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;And when he and his colleagues looked into ShotSpotter, they revealed a disturbing problem: The system generated alerts that yielded no evidence of gun-­related crimes but were used by police as a pretext for other actions. There seemed to be “a pattern of people being stopped, detained, questioned, sometimes arrested, in response to a ShotSpotter alert—often resulting in charges that have nothing to do with guns,” Manes says.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The system also directed a “massive number of police deployments onto the South and West Sides of the city,” Manes says. Those regions are home to most of Chicago’s Black and Latino residents. The research showed that 80% of the city’s Black population but only 30% of its white population lived in districts covered by the system.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Manes brought Scruggs’s case into a lawsuit that he was already developing against the city’s use of ShotSpotter. In late 2025, he and his colleagues reached a settlement that prohibits police officers from doing what they did in Scruggs’s case—stopping or searching people simply because they are near the location of a gunshot detection alert.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_30"&gt;&lt;p&gt;Chicago had already decommissioned ShotSpotter in 2024, but the agreement will cover any future gunshot detection systems. Manes is carefully watching to see what happens next.&lt;/p&gt;  &lt;p&gt;Though Manes is pleased with the settlement, he points out that it narrowly focused on how police resources were used &lt;em&gt;after&lt;/em&gt; the gunshot detection system was operational. “There is a need for much broader structural change to how the city chooses to use surveillance technology and then deploys it,” he adds. He supports laws that require disclosure from local officials and law enforcement about what technologies are being proposed and how civil rights could be affected. &amp;nbsp;&lt;/p&gt;  &lt;p&gt;More than two dozen jurisdictions nationwide have adopted surveillance transparency laws, including San Francisco, Seattle, Boston, and New York City. But so far Chicago is not on that list.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Rod McCullom is a Chicago-based science and technology writer whose focus areas include AI, biometrics, cognition, and the science of crime and violence. &amp;nbsp;&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/23/1132740/inside-chicago-surveillance-panopticon/</guid><pubDate>Mon, 23 Feb 2026 10:00:00 +0000</pubDate></item><item><title>[NEW] Mastercard’s AI payment demo points to agent-led commerce (AI News)</title><link>https://www.artificialintelligence-news.com/news/mastercard-ai-payment-demo-points-to-agent-led-commerce/</link><description>&lt;p&gt;A recent demonstration from Mastercard suggests that payment systems may be heading toward a future where software agents, not people, complete purchases. During the India AI Impact Summit 2026, Mastercard showed what it described as its first fully authenticated “agentic commerce” transaction.&lt;/p&gt;&lt;p&gt;In the demo, as reported by &lt;em&gt;Times of India&lt;/em&gt;, an AI agent searched for a product, assessed the website, and completed the purchase using stored payment credentials, without the user opening an app or entering card details. The company said the transaction took place inside a secure payment framework designed to verify both the user and the AI acting on their behalf.&lt;/p&gt;&lt;p&gt;The demonstration was controlled, not a public rollout. Mastercard executives told reporters that broader deployment would depend on regulatory approval and ecosystem readiness. Still, the test highlights a change that many enterprises may need to prepare for: the possibility that customers – or corporate systems – will increasingly rely on AI agents to initiate and complete transactions.&lt;/p&gt;&lt;h3&gt;Assisted checkout to delegated spending&lt;/h3&gt;&lt;p&gt;Digital payments have usually focused on reducing friction for human users through tokenisation, saved credentials, and one-click checkout. Agentic commerce goes further. Instead of helping a user complete a purchase, the system allows software to handle the process from start to finish once permission rules are in place.&lt;/p&gt;&lt;p&gt;The model relies on several building blocks already used in modern payments: identity verification, tokenised card data, and risk monitoring. What changes is who performs the action. If AI agents can act in defined limits, like spending caps or merchant restrictions, checkout may change from a user interaction to a background workflow.&lt;/p&gt;&lt;p&gt;For enterprises, the issue is if software can spend money automatically, procurement rules, approval chains, and audit trails need to account for machine decisions, not human ones. Finance teams may need clearer policies on when an AI agent can commit funds, how liability is assigned if something goes wrong, and how fraud detection should treat automated transactions.&lt;/p&gt;&lt;h3&gt;Payment networks position for machine customers&lt;/h3&gt;&lt;p&gt;Mastercard is not alone in exploring this direction. Across the payments sector, providers are testing ways to embed transactions into AI-driven tools and digital assistants. The goal is to ensure that when autonomous software begins purchasing goods or services, payment networks remain part of the trust and verification layer.&lt;/p&gt;&lt;p&gt;In public statements tied to the summit demo, Mastercard framed the effort as building infrastructure that allows AI agents to transact safely on behalf of users. That framing points to a broader industry race: not to build smarter AI shopping tools, but to control the authentication systems that make those tools safe enough for financial use.&lt;/p&gt;&lt;p&gt;For banks and fintech firms, the change could affect how customer identity is managed. Traditional authentication often assumes a person is present, entering a password or approving a prompt. Agentic commerce assumes the opposite: the user may not be involved at the moment of purchase. That means identity systems must verify both the account owner’s prior consent and the agent’s authority at the time of transaction.&lt;/p&gt;&lt;h3&gt;Merchants may need API-ready storefronts&lt;/h3&gt;&lt;p&gt;If AI agents begin acting as buyers, merchant systems may also need to adapt. Online stores built mainly for human browsing may struggle if automated agents become a meaningful share of customers.&lt;/p&gt;&lt;p&gt;To support machine-driven purchases, product catalogues, pricing data, and checkout processes may need to be accessible through structured APIs not only visual web pages. Inventory accuracy, transparent pricing, and clear return policies become more important when decisions are made by software trained to compare options instantly.&lt;/p&gt;&lt;p&gt;This could also influence competition. If agents optimise for price and delivery speed, merchants with inconsistent data or hidden fees may be filtered out before a human even sees them.&lt;/p&gt;&lt;h3&gt;Security risks move, not disappear&lt;/h3&gt;&lt;p&gt;While agentic commerce promises convenience, it also introduces new risks. A compromised AI assistant with payment authority could execute purchases at scale before detection. Fraud models that look for unusual user behaviour may need updating to distinguish between legitimate automated spending and malicious activity.&lt;/p&gt;&lt;p&gt;Regulators are likely to take a cautious approach. Mastercard’s own comments that the system still awaits approvals suggest that compliance frameworks for AI-initiated payments are still taking shape.&lt;/p&gt;&lt;p&gt;In enterprises deploying AI internally, similar concerns apply. Automated purchasing agents integrated into enterprise resource planning systems could streamline routine procurement, but they also expand the attack surface. Access controls and spending thresholds will matter more when software can execute financial actions without real-time human confirmation.&lt;/p&gt;&lt;h3&gt;Where commerce may head&lt;/h3&gt;&lt;p&gt;Mastercard’s demonstration does not mean agent-led payments will reach consumers immediately. Yet it offers a glimpse of how commerce may change as AI systems move from advisory roles into operational ones.&lt;/p&gt;&lt;p&gt;If the model matures, the most visible change may be that checkout disappears as a distinct step. Instead of visiting a site and paying, users or companies may set rules, and their software will handle the rest.&lt;/p&gt;&lt;p&gt;For enterprises, the important takeaway is less about Mastercard’s AI technology and more about the direction of travel. As AI agents gain the authority to act, payment systems, identity frameworks, and digital storefronts may need to treat software not as a tool, but as a participant in the transaction.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Cova Software)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;A recent demonstration from Mastercard suggests that payment systems may be heading toward a future where software agents, not people, complete purchases. During the India AI Impact Summit 2026, Mastercard showed what it described as its first fully authenticated “agentic commerce” transaction.&lt;/p&gt;&lt;p&gt;In the demo, as reported by &lt;em&gt;Times of India&lt;/em&gt;, an AI agent searched for a product, assessed the website, and completed the purchase using stored payment credentials, without the user opening an app or entering card details. The company said the transaction took place inside a secure payment framework designed to verify both the user and the AI acting on their behalf.&lt;/p&gt;&lt;p&gt;The demonstration was controlled, not a public rollout. Mastercard executives told reporters that broader deployment would depend on regulatory approval and ecosystem readiness. Still, the test highlights a change that many enterprises may need to prepare for: the possibility that customers – or corporate systems – will increasingly rely on AI agents to initiate and complete transactions.&lt;/p&gt;&lt;h3&gt;Assisted checkout to delegated spending&lt;/h3&gt;&lt;p&gt;Digital payments have usually focused on reducing friction for human users through tokenisation, saved credentials, and one-click checkout. Agentic commerce goes further. Instead of helping a user complete a purchase, the system allows software to handle the process from start to finish once permission rules are in place.&lt;/p&gt;&lt;p&gt;The model relies on several building blocks already used in modern payments: identity verification, tokenised card data, and risk monitoring. What changes is who performs the action. If AI agents can act in defined limits, like spending caps or merchant restrictions, checkout may change from a user interaction to a background workflow.&lt;/p&gt;&lt;p&gt;For enterprises, the issue is if software can spend money automatically, procurement rules, approval chains, and audit trails need to account for machine decisions, not human ones. Finance teams may need clearer policies on when an AI agent can commit funds, how liability is assigned if something goes wrong, and how fraud detection should treat automated transactions.&lt;/p&gt;&lt;h3&gt;Payment networks position for machine customers&lt;/h3&gt;&lt;p&gt;Mastercard is not alone in exploring this direction. Across the payments sector, providers are testing ways to embed transactions into AI-driven tools and digital assistants. The goal is to ensure that when autonomous software begins purchasing goods or services, payment networks remain part of the trust and verification layer.&lt;/p&gt;&lt;p&gt;In public statements tied to the summit demo, Mastercard framed the effort as building infrastructure that allows AI agents to transact safely on behalf of users. That framing points to a broader industry race: not to build smarter AI shopping tools, but to control the authentication systems that make those tools safe enough for financial use.&lt;/p&gt;&lt;p&gt;For banks and fintech firms, the change could affect how customer identity is managed. Traditional authentication often assumes a person is present, entering a password or approving a prompt. Agentic commerce assumes the opposite: the user may not be involved at the moment of purchase. That means identity systems must verify both the account owner’s prior consent and the agent’s authority at the time of transaction.&lt;/p&gt;&lt;h3&gt;Merchants may need API-ready storefronts&lt;/h3&gt;&lt;p&gt;If AI agents begin acting as buyers, merchant systems may also need to adapt. Online stores built mainly for human browsing may struggle if automated agents become a meaningful share of customers.&lt;/p&gt;&lt;p&gt;To support machine-driven purchases, product catalogues, pricing data, and checkout processes may need to be accessible through structured APIs not only visual web pages. Inventory accuracy, transparent pricing, and clear return policies become more important when decisions are made by software trained to compare options instantly.&lt;/p&gt;&lt;p&gt;This could also influence competition. If agents optimise for price and delivery speed, merchants with inconsistent data or hidden fees may be filtered out before a human even sees them.&lt;/p&gt;&lt;h3&gt;Security risks move, not disappear&lt;/h3&gt;&lt;p&gt;While agentic commerce promises convenience, it also introduces new risks. A compromised AI assistant with payment authority could execute purchases at scale before detection. Fraud models that look for unusual user behaviour may need updating to distinguish between legitimate automated spending and malicious activity.&lt;/p&gt;&lt;p&gt;Regulators are likely to take a cautious approach. Mastercard’s own comments that the system still awaits approvals suggest that compliance frameworks for AI-initiated payments are still taking shape.&lt;/p&gt;&lt;p&gt;In enterprises deploying AI internally, similar concerns apply. Automated purchasing agents integrated into enterprise resource planning systems could streamline routine procurement, but they also expand the attack surface. Access controls and spending thresholds will matter more when software can execute financial actions without real-time human confirmation.&lt;/p&gt;&lt;h3&gt;Where commerce may head&lt;/h3&gt;&lt;p&gt;Mastercard’s demonstration does not mean agent-led payments will reach consumers immediately. Yet it offers a glimpse of how commerce may change as AI systems move from advisory roles into operational ones.&lt;/p&gt;&lt;p&gt;If the model matures, the most visible change may be that checkout disappears as a distinct step. Instead of visiting a site and paying, users or companies may set rules, and their software will handle the rest.&lt;/p&gt;&lt;p&gt;For enterprises, the important takeaway is less about Mastercard’s AI technology and more about the direction of travel. As AI agents gain the authority to act, payment systems, identity frameworks, and digital storefronts may need to treat software not as a tool, but as a participant in the transaction.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Photo by Cova Software)&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/ai-expo-banner-2025.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and co-located with other leading technology events. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/mastercard-ai-payment-demo-points-to-agent-led-commerce/</guid><pubDate>Mon, 23 Feb 2026 10:00:00 +0000</pubDate></item></channel></rss>