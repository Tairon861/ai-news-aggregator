<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 13 Feb 2026 07:02:34 +0000</lastBuildDate><item><title>Attackers prompted Gemini over 100,000 times while trying to clone it, Google says (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Distillation technique lets copycats mimic Gemini at a fraction of the development cost.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Google Gemini logo." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/gemini_header-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Google Gemini logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/gemini_header-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Google Gemini logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, Google announced that “commercially motivated” actors have attempted to clone knowledge from its Gemini AI chatbot by simply prompting it. One adversarial session reportedly prompted the model more than 100,000 times across various non-English languages, collecting responses ostensibly to train a cheaper copycat.&lt;/p&gt;
&lt;p&gt;Google published the findings in what amounts to a quarterly self-assessment of threats to its own products that frames the company as the victim and the hero, which is not unusual in these self-authored assessments. Google calls the illicit activity “model extraction” and considers it intellectual property theft, which is a somewhat loaded position, given that Google’s LLM was built from materials scraped from the Internet without permission.&lt;/p&gt;
&lt;p&gt;Google is also no stranger to the copycat practice. In 2023, The Information reported that Google’s Bard team had been accused of using ChatGPT outputs from ShareGPT, a public site where users share chatbot conversations, to help train its own chatbot. Senior Google AI researcher Jacob Devlin, who created the influential BERT language model, warned leadership that this violated OpenAI’s terms of service, then resigned and joined OpenAI. Google denied the claim but reportedly stopped using the data.&lt;/p&gt;
&lt;p&gt;Even so, Google’s terms of service forbid people from extracting data from its AI models this way, and the report is a window into the world of somewhat shady AI model-cloning tactics. The company believes the culprits are mostly private companies and researchers looking for a competitive edge, and said the attacks have come from around the world. Google declined to name suspects.&lt;/p&gt;
&lt;h2&gt;The deal with distillation&lt;/h2&gt;
&lt;p&gt;Typically, the industry calls this practice of training a new model on a previous model’s outputs “distillation,” and it works like this: If you want to build your own large language model (LLM) but lack the billions of dollars and years of work that Google spent training Gemini, you can use a previously trained LLM as a shortcut.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To do so, you need to feed the existing AI model thousands of carefully chosen prompts, collect all the responses, and then use those input-output pairs to train a smaller, cheaper model. The result will closely mimic the parent model’s output behavior but will typically be smaller overall. It’s not perfect, but it can be a far more efficient training technique than hoping to build a useful model on random Internet data that includes a lot of noise.&lt;/p&gt;
&lt;p&gt;The copycat model never sees Gemini’s code or training data, but by studying enough of its outputs, it can learn to replicate many of its capabilities. You can think of it as reverse-engineering a chef’s recipes by ordering every dish on the menu and working backward from taste and appearance alone.&lt;/p&gt;
&lt;p&gt;In the report published by Google, its threat intelligence group describes a growing wave of these distillation attacks against Gemini. Many of the campaigns specifically targeted the algorithms that help the model perform simulated reasoning tasks, or decide how to process information step by step.&lt;/p&gt;
&lt;p&gt;Google said it identified the 100,000-prompt campaign and adjusted Gemini’s defenses, but it did not detail what those countermeasures involve.&lt;/p&gt;
&lt;h2&gt;A clone of a clone&lt;/h2&gt;
&lt;p&gt;Google is not the only company worried about distillation. OpenAI accused Chinese rival DeepSeek last year of using distillation to improve its own models, and the technique has since spread across the industry as a standard for building cheaper, smaller AI models from larger ones.&lt;/p&gt;
&lt;p&gt;The line between standard distillation and theft depends on whose model you’re distilling and whether you have permission, a distinction that tech companies have spent billions of dollars trying to protect but that no court has tested.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Competitors have been using distillation to clone AI language model capabilities since at least the GPT-3 era, with ChatGPT a popular target after its launch.&lt;/p&gt;
&lt;p&gt;In March 2023, shortly after Meta’s LLaMA model weights leaked online, Stanford University researchers built a model called Alpaca by fine-tuning LLaMA on 52,000 outputs generated by OpenAI’s GPT-3.5. The total cost was about $600. The result behaved so much like ChatGPT that it raised immediate questions about whether any AI model’s capabilities could be protected once it was accessible through an API.&lt;/p&gt;
&lt;p&gt;Later that year, Elon Musk’s xAI launched its Grok chatbot, which promptly cited “OpenAI’s use case policy” when refusing certain requests. An xAI engineer blamed accidental ingestion of ChatGPT outputs during web scraping, but the specificity of the behavior, down to ChatGPT’s characteristic refusal phrasing and habit of wrapping responses with “Overall…” summaries, left many in the AI community unconvinced.&lt;/p&gt;
&lt;p&gt;As long as an LLM is accessible to the public, no foolproof technical barrier prevents a determined actor from doing the same thing to someone else’s model over time (though rate-limiting helps), which is exactly what Google says happened to Gemini.&lt;/p&gt;
&lt;p&gt;Distillation also occurs within companies, and it’s frequently used to create smaller, faster-to-run versions of older, larger AI models. OpenAI created GPT-4o Mini as a distillation of GPT-4o, for example, and Microsoft built its compact Phi-3 model family using carefully filtered synthetic data generated by larger models.&lt;/p&gt;
&lt;p&gt;DeepSeek has also officially published six distilled versions of its R1 reasoning model, the smallest of which can run on a laptop.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Distillation technique lets copycats mimic Gemini at a fraction of the development cost.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The Google Gemini logo." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/gemini_header-300x169.jpg" width="300" /&gt;
                  &lt;img alt="The Google Gemini logo." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/12/gemini_header-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The Google Gemini logo.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, Google announced that “commercially motivated” actors have attempted to clone knowledge from its Gemini AI chatbot by simply prompting it. One adversarial session reportedly prompted the model more than 100,000 times across various non-English languages, collecting responses ostensibly to train a cheaper copycat.&lt;/p&gt;
&lt;p&gt;Google published the findings in what amounts to a quarterly self-assessment of threats to its own products that frames the company as the victim and the hero, which is not unusual in these self-authored assessments. Google calls the illicit activity “model extraction” and considers it intellectual property theft, which is a somewhat loaded position, given that Google’s LLM was built from materials scraped from the Internet without permission.&lt;/p&gt;
&lt;p&gt;Google is also no stranger to the copycat practice. In 2023, The Information reported that Google’s Bard team had been accused of using ChatGPT outputs from ShareGPT, a public site where users share chatbot conversations, to help train its own chatbot. Senior Google AI researcher Jacob Devlin, who created the influential BERT language model, warned leadership that this violated OpenAI’s terms of service, then resigned and joined OpenAI. Google denied the claim but reportedly stopped using the data.&lt;/p&gt;
&lt;p&gt;Even so, Google’s terms of service forbid people from extracting data from its AI models this way, and the report is a window into the world of somewhat shady AI model-cloning tactics. The company believes the culprits are mostly private companies and researchers looking for a competitive edge, and said the attacks have come from around the world. Google declined to name suspects.&lt;/p&gt;
&lt;h2&gt;The deal with distillation&lt;/h2&gt;
&lt;p&gt;Typically, the industry calls this practice of training a new model on a previous model’s outputs “distillation,” and it works like this: If you want to build your own large language model (LLM) but lack the billions of dollars and years of work that Google spent training Gemini, you can use a previously trained LLM as a shortcut.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To do so, you need to feed the existing AI model thousands of carefully chosen prompts, collect all the responses, and then use those input-output pairs to train a smaller, cheaper model. The result will closely mimic the parent model’s output behavior but will typically be smaller overall. It’s not perfect, but it can be a far more efficient training technique than hoping to build a useful model on random Internet data that includes a lot of noise.&lt;/p&gt;
&lt;p&gt;The copycat model never sees Gemini’s code or training data, but by studying enough of its outputs, it can learn to replicate many of its capabilities. You can think of it as reverse-engineering a chef’s recipes by ordering every dish on the menu and working backward from taste and appearance alone.&lt;/p&gt;
&lt;p&gt;In the report published by Google, its threat intelligence group describes a growing wave of these distillation attacks against Gemini. Many of the campaigns specifically targeted the algorithms that help the model perform simulated reasoning tasks, or decide how to process information step by step.&lt;/p&gt;
&lt;p&gt;Google said it identified the 100,000-prompt campaign and adjusted Gemini’s defenses, but it did not detail what those countermeasures involve.&lt;/p&gt;
&lt;h2&gt;A clone of a clone&lt;/h2&gt;
&lt;p&gt;Google is not the only company worried about distillation. OpenAI accused Chinese rival DeepSeek last year of using distillation to improve its own models, and the technique has since spread across the industry as a standard for building cheaper, smaller AI models from larger ones.&lt;/p&gt;
&lt;p&gt;The line between standard distillation and theft depends on whose model you’re distilling and whether you have permission, a distinction that tech companies have spent billions of dollars trying to protect but that no court has tested.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Competitors have been using distillation to clone AI language model capabilities since at least the GPT-3 era, with ChatGPT a popular target after its launch.&lt;/p&gt;
&lt;p&gt;In March 2023, shortly after Meta’s LLaMA model weights leaked online, Stanford University researchers built a model called Alpaca by fine-tuning LLaMA on 52,000 outputs generated by OpenAI’s GPT-3.5. The total cost was about $600. The result behaved so much like ChatGPT that it raised immediate questions about whether any AI model’s capabilities could be protected once it was accessible through an API.&lt;/p&gt;
&lt;p&gt;Later that year, Elon Musk’s xAI launched its Grok chatbot, which promptly cited “OpenAI’s use case policy” when refusing certain requests. An xAI engineer blamed accidental ingestion of ChatGPT outputs during web scraping, but the specificity of the behavior, down to ChatGPT’s characteristic refusal phrasing and habit of wrapping responses with “Overall…” summaries, left many in the AI community unconvinced.&lt;/p&gt;
&lt;p&gt;As long as an LLM is accessible to the public, no foolproof technical barrier prevents a determined actor from doing the same thing to someone else’s model over time (though rate-limiting helps), which is exactly what Google says happened to Gemini.&lt;/p&gt;
&lt;p&gt;Distillation also occurs within companies, and it’s frequently used to create smaller, faster-to-run versions of older, larger AI models. OpenAI created GPT-4o Mini as a distillation of GPT-4o, for example, and Microsoft built its compact Phi-3 model family using carefully filtered synthetic data generated by larger models.&lt;/p&gt;
&lt;p&gt;DeepSeek has also officially published six distilled versions of its R1 reasoning model, the smallest of which can run on a laptop.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/attackers-prompted-gemini-over-100000-times-while-trying-to-clone-it-google-says/</guid><pubDate>Thu, 12 Feb 2026 19:42:08 +0000</pubDate></item><item><title>Anthropic raises another $30B in Series G, with a new value of $380B (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/12/anthropic-raises-another-30-billion-in-series-g-with-a-new-value-of-380-billion/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2256664479.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic has just concluded a $30 billion Series G fundraising round, the company announced on Thursday. The company’s new value is $380 billion — a huge jump from its previous Series F valuation of $183 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some details of the round were reported earlier this week by Bloomberg.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new round was led by Singaporean wealth fund GIC and investment management firm Coatue, with a number of other prominent firms — including D. E. Shaw Ventures, Peter Thiel’s Founders Fund, and Abu Dhabi’s MGX — co-leading the round. Other significant investors listed include Accel, General Catalyst, Jane Street, and the Qatar Investment Authority, among many others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The infusion of funding for the AI startup takes place as it is vying for customers and cultural attention with its competitor, OpenAI. OpenAI also recently made it known that it is seeking to clinch an additional $100 billion in funding, which, were it to secure the funds, would balloon the company’s valuation to some $830 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Whether it is entrepreneurs, startups, or the world’s largest enterprises, the message from our customers is the same: Claude is increasingly becoming more critical to how businesses work,” said Krishna Rao, Anthropic’s chief financial officer, in a press release. “This fundraising reflects the incredible demand we are seeing from these customers, and we will use this investment to continue building the enterprise-grade products and models they have come to depend on.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2256664479.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic has just concluded a $30 billion Series G fundraising round, the company announced on Thursday. The company’s new value is $380 billion — a huge jump from its previous Series F valuation of $183 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Some details of the round were reported earlier this week by Bloomberg.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new round was led by Singaporean wealth fund GIC and investment management firm Coatue, with a number of other prominent firms — including D. E. Shaw Ventures, Peter Thiel’s Founders Fund, and Abu Dhabi’s MGX — co-leading the round. Other significant investors listed include Accel, General Catalyst, Jane Street, and the Qatar Investment Authority, among many others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The infusion of funding for the AI startup takes place as it is vying for customers and cultural attention with its competitor, OpenAI. OpenAI also recently made it known that it is seeking to clinch an additional $100 billion in funding, which, were it to secure the funds, would balloon the company’s valuation to some $830 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Whether it is entrepreneurs, startups, or the world’s largest enterprises, the message from our customers is the same: Claude is increasingly becoming more critical to how businesses work,” said Krishna Rao, Anthropic’s chief financial officer, in a press release. “This fundraising reflects the incredible demand we are seeing from these customers, and we will use this investment to continue building the enterprise-grade products and models they have come to depend on.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/12/anthropic-raises-another-30-billion-in-series-g-with-a-new-value-of-380-billion/</guid><pubDate>Thu, 12 Feb 2026 20:18:37 +0000</pubDate></item><item><title>Didero lands $30M to put manufacturing procurement on ‘agentic’ autopilot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/12/didero-lands-30m-to-put-manufacturing-procurement-on-agentic-autopilot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Founders_Exterior_Mid-3.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tim Spencer realized just how complicated manufacturing procurement can be while running Markai, an e-commerce startup in Asia, during the pandemic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had thousands of suppliers, and we were distributing products into dozens of countries around the world,” Spencer (pictured left) told TechCrunch. His staff was overwhelmed by the manual complexity of sourcing suppliers, negotiating pricing, tracking orders, and managing payments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I found myself running this big team that was not really set up for success,” he said. He sold Markai in 2023, just as it was becoming clear that generative AI could streamline the most time-consuming procurement hurdles for manufacturers and distributors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later that year, Spencer launched Didero with Lorenz Pallhuber (pictured center), a veteran of McKinsey’s procurement practice, and Tom Petit, the former technical co-founder of Landis.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Didero, whose mission is to automate many of the complexities of global procurement, just raised a $30 million Series A co-led by Chemistry and Headline, with participation from Microsoft’s venture fund M12.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Global trade runs on natural language communication,” Spencer said. “It’s emails, WeChat, phone calls, purchase orders, and packing lists.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Until the advent of generative AI, these fragmented pieces had to be tracked by humans who spent their days chasing suppliers and manually updating systems of record. Didero claims its platform can ingest that communication, putting a significant portion of the procurement workflow on autopilot.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Didero functions as an agentic AI layer that sits on top of a company’s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The goal is to go from ‘I need a good’ to payment without having to lift a finger,” Spencer said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Levelpath, Zip, or Oro Labs, which use AI to streamline corporate purchasing, Didero focuses on the supply chain. Its platform is designed for manufacturers and distributors who need to source raw materials and inputs required to build or sell their products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Didero has a few smaller competitors that can handle some of the tasks that the company does. &lt;span&gt;For instance,&amp;nbsp;Cavela&amp;nbsp;and&amp;nbsp;Pietra&amp;nbsp;help brands source and negotiate pricing with manufacturers, but according to Spencer, these companies serve &lt;/span&gt;small and medium-sized companies and don’t handle the full procurement process, from the first quote to the final payment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Didero has dozens of customers but named only one, Footprint, a provider of sustainable, plant-based packaging.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/Founders_Exterior_Mid-3.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tim Spencer realized just how complicated manufacturing procurement can be while running Markai, an e-commerce startup in Asia, during the pandemic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We had thousands of suppliers, and we were distributing products into dozens of countries around the world,” Spencer (pictured left) told TechCrunch. His staff was overwhelmed by the manual complexity of sourcing suppliers, negotiating pricing, tracking orders, and managing payments.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I found myself running this big team that was not really set up for success,” he said. He sold Markai in 2023, just as it was becoming clear that generative AI could streamline the most time-consuming procurement hurdles for manufacturers and distributors.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Later that year, Spencer launched Didero with Lorenz Pallhuber (pictured center), a veteran of McKinsey’s procurement practice, and Tom Petit, the former technical co-founder of Landis.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Didero, whose mission is to automate many of the complexities of global procurement, just raised a $30 million Series A co-led by Chemistry and Headline, with participation from Microsoft’s venture fund M12.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Global trade runs on natural language communication,” Spencer said. “It’s emails, WeChat, phone calls, purchase orders, and packing lists.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Until the advent of generative AI, these fragmented pieces had to be tracked by humans who spent their days chasing suppliers and manually updating systems of record. Didero claims its platform can ingest that communication, putting a significant portion of the procurement workflow on autopilot.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Didero functions as an agentic AI layer that sits on top of a company’s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The goal is to go from ‘I need a good’ to payment without having to lift a finger,” Spencer said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Unlike Levelpath, Zip, or Oro Labs, which use AI to streamline corporate purchasing, Didero focuses on the supply chain. Its platform is designed for manufacturers and distributors who need to source raw materials and inputs required to build or sell their products.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Didero has a few smaller competitors that can handle some of the tasks that the company does. &lt;span&gt;For instance,&amp;nbsp;Cavela&amp;nbsp;and&amp;nbsp;Pietra&amp;nbsp;help brands source and negotiate pricing with manufacturers, but according to Spencer, these companies serve &lt;/span&gt;small and medium-sized companies and don’t handle the full procurement process, from the first quote to the final payment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Didero has dozens of customers but named only one, Footprint, a provider of sustainable, plant-based packaging.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/12/didero-lands-30m-to-put-manufacturing-procurement-on-agentic-autopilot/</guid><pubDate>Thu, 12 Feb 2026 20:31:47 +0000</pubDate></item><item><title>Code, Compute and Connection: Inside the Inaugural NVIDIA AI Day São Paulo (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/ai-day-sao-paulo/</link><description>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	



	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.9 (Yoast SEO v26.9) - https://yoast.com/product/yoast-seo-premium-wordpress/ --&gt;
	Inside the Inaugural NVIDIA AI Day São Paulo | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;







































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		


	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of a blog series highlighting &lt;/i&gt;&lt;i&gt;NVIDIA AI Days&lt;/i&gt;&lt;i&gt; across the globe.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;The worldwide tour of NVIDIA AI Days — bringing together AI enthusiasts, developers, researchers and startups — made its latest stop in São Paulo, Brazil.&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-check-in-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Attendees check in at NVIDIA AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;More than 500 attendees joined NVIDIA AI Day São Paulo in January to learn about sovereign AI — including breakout sessions on AI agents and open models.&lt;/p&gt;&lt;p&gt;“NVIDIA solutions are fundamental to all the technologies we develop,” said Paulo Perez, cofounder and CEO of biotechnology startup Biofy. “DNA is composed of a gigantic amount of data, which we call nucleotides. Analyzing this data takes a long time when done using traditional methods with CPUs. In this regard, NVIDIA’s GPUs, algorithms and frameworks accelerate the results we are capable of delivering by hundreds of times.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="&amp;quot;NVIDIA’s GPUs, algorithms and frameworks accelerate the results we are capable of delivering by hundreds of times,&amp;quot; said Paulo Perez, cofounder and CEO of Biofy." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/paulo-perez-pull-quote-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Why It Matters&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The latest AI trends in Brazil showcase how the technology is driving advancements in Latin America and beyond.&lt;/p&gt;&lt;p&gt;The Brazilian Artificial Intelligence Plan for 2024-2028, called “AI for the Good of All,” outlines 50+ targeted initiatives across public services, R&amp;amp;D, infrastructure, industry and government.&lt;/p&gt;&lt;p&gt;The Brazil government plans to invest about $4 billion through 2028, focused on promoting infrastructure for AI development, dissemination, training and professional qualification; improving public services; fostering business innovation; and enhancing regulatory and governance processes in the sector.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-all-conference-session-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			An all-conference session at NVIDIA AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Leading startups in the region are developing breakthrough applications in financial services, healthcare, retail, agriculture and manufacturing — with top universities in Brazil allocating high-performance computing infrastructure to the students and researchers who will fuel the future of AI in the nation.&lt;/p&gt;&lt;p&gt;The numbers help showcase Brazil’s expanding AI ecosystem:&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="Infographic that says there are 1,000 NVIDIA Inception startups in Brazil, 40 Brazilian universities engaging with NVIDIA, 19,000 NVIDIA Deep Learning Institute trainees in Brazil, 47 million CUDA downloads from Brazil and 123,000 developers in Brazil using NVIDIA technologies." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-infographic-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Event Highlights&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;In addition to four NVIDIA Deep Learning Institute technical labs, the event featured sessions on the fundamentals to AI agent creation as well as large language model (LLM) and retrieval-augmented generation labs focused on accelerated linguistic diversity.&lt;/p&gt;&lt;p&gt;An all-conference plenary session hosted by the NVIDIA Inception program for startups featured Howard Wright, vice president of startups ecosystem at NVIDIA, who discussed how sovereign AI empowers Brazil to unlock national potential, fostering economic growth, technological autonomy and leadership in the regional AI landscape.&lt;/p&gt;&lt;p&gt;Another all-conference panel, called “Sovereign AI in Action: Learnings and Partnerships Driving Local Innovation,” explored how startups, academia and AI hubs across Latin America are crafting partnerships and nurturing specialized talent to bolster AI innovation, including using NVIDIA NeMo software and NVIDIA NIM microservices.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-sovereign-ai-session-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Sovereign AI panel at NVIDIA AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Industry in Motion&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Brazil-based NVIDIA partners are helping fuel the AI industrial revolution.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At the event:&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Amadeus AI showcased advanced techniques in efficiently fine‑tuning LLMs for specific domains and languages, including using reinforcement learning with human feedback. The company emphasized cost‑effective fine‑tuning pipelines using GPUs and open source tools to balance performance and scalability.&lt;/li&gt;
&lt;li&gt;Langflow shared architecture patterns, best practices for evaluation and governance, and methods of combining Langflow with NVIDIA technologies to build robust, cost‑efficient agents aligned with business goals.​&amp;nbsp;&lt;/li&gt;
&lt;li&gt;WideLabs presented how Latin American governments and enterprises are building sovereign AI platforms, ranging from national dataset initiatives to applications with stringent safety and governance requirements, all built on the NVIDIA AI stack. The company also presented its new AI synthetic data pipeline, Nemotron Personas Brazil.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;“At NVIDIA AI Days, we were able to gain a much more thorough understanding of the NVIDIA NeMo framework,” said Rodrigo Malossi, cofounder and chief technology officer of WideLabs. “The event also allowed us to better understand NVIDIA’s new initiatives and what they are proposing with respect to large-scale, national-level sovereign AI efforts.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-inception-session-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			NVIDIA Inception session at AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;What’s Next&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The NVIDIA developer ecosystem in the region will continue driving innovation in support of the Brazilian Artificial Intelligence Plan, with a focus on LLM development, healthcare and financial services.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In addition, NVIDIA is partnering with Brazil-founded telecommunications provider Claro — the first NVIDIA Cloud Partner in Latin America — to accelerate sovereign AI in the region.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Learn more about &lt;/i&gt;&lt;i&gt;NVIDIA AI Days&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</description><content:encoded>&lt;!-- OneTrust Cookies Consent Notice start for nvidia.com --&gt;


&lt;!-- OneTrust Cookies Consent Notice end for nvidia.com --&gt;


	
	
	
	
	
	

	

	



	&lt;!-- This site is optimized with the Yoast SEO Premium plugin v26.9 (Yoast SEO v26.9) - https://yoast.com/product/yoast-seo-premium-wordpress/ --&gt;
	Inside the Inaugural NVIDIA AI Day São Paulo | NVIDIA Blog
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	&lt;!-- / Yoast SEO Premium plugin. --&gt;







































&lt;!-- Stream WordPress user activity plugin v4.1.1 --&gt;


	
				&lt;!-- Hotjar Tracking Code for NVIDIA --&gt;
			
			


				
				



		
		

&lt;div class="hfeed site" id="page"&gt;
	Skip to content

	&lt;!-- #masthead --&gt;
		
		&lt;div class="full-width-layout light"&gt;
		

		


	
	
		&lt;div class="full-width-layout__sections"&gt;
&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;&lt;i&gt;Editor’s note: This post is part of a blog series highlighting &lt;/i&gt;&lt;i&gt;NVIDIA AI Days&lt;/i&gt;&lt;i&gt; across the globe.&lt;/i&gt;&lt;/p&gt;&lt;p&gt;The worldwide tour of NVIDIA AI Days — bringing together AI enthusiasts, developers, researchers and startups — made its latest stop in São Paulo, Brazil.&amp;nbsp;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-check-in-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Attendees check in at NVIDIA AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;More than 500 attendees joined NVIDIA AI Day São Paulo in January to learn about sovereign AI — including breakout sessions on AI agents and open models.&lt;/p&gt;&lt;p&gt;“NVIDIA solutions are fundamental to all the technologies we develop,” said Paulo Perez, cofounder and CEO of biotechnology startup Biofy. “DNA is composed of a gigantic amount of data, which we call nucleotides. Analyzing this data takes a long time when done using traditional methods with CPUs. In this regard, NVIDIA’s GPUs, algorithms and frameworks accelerate the results we are capable of delivering by hundreds of times.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="&amp;quot;NVIDIA’s GPUs, algorithms and frameworks accelerate the results we are capable of delivering by hundreds of times,&amp;quot; said Paulo Perez, cofounder and CEO of Biofy." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/paulo-perez-pull-quote-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Why It Matters&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The latest AI trends in Brazil showcase how the technology is driving advancements in Latin America and beyond.&lt;/p&gt;&lt;p&gt;The Brazilian Artificial Intelligence Plan for 2024-2028, called “AI for the Good of All,” outlines 50+ targeted initiatives across public services, R&amp;amp;D, infrastructure, industry and government.&lt;/p&gt;&lt;p&gt;The Brazil government plans to invest about $4 billion through 2028, focused on promoting infrastructure for AI development, dissemination, training and professional qualification; improving public services; fostering business innovation; and enhancing regulatory and governance processes in the sector.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-all-conference-session-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			An all-conference session at NVIDIA AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Leading startups in the region are developing breakthrough applications in financial services, healthcare, retail, agriculture and manufacturing — with top universities in Brazil allocating high-performance computing infrastructure to the students and researchers who will fuel the future of AI in the nation.&lt;/p&gt;&lt;p&gt;The numbers help showcase Brazil’s expanding AI ecosystem:&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="Infographic that says there are 1,000 NVIDIA Inception startups in Brazil, 40 Brazilian universities engaging with NVIDIA, 19,000 NVIDIA Deep Learning Institute trainees in Brazil, 47 million CUDA downloads from Brazil and 123,000 developers in Brazil using NVIDIA technologies." class="full-width-layout__image" height="819" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-infographic-scaled.jpg" width="2048" /&gt;	
	&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Event Highlights&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;In addition to four NVIDIA Deep Learning Institute technical labs, the event featured sessions on the fundamentals to AI agent creation as well as large language model (LLM) and retrieval-augmented generation labs focused on accelerated linguistic diversity.&lt;/p&gt;&lt;p&gt;An all-conference plenary session hosted by the NVIDIA Inception program for startups featured Howard Wright, vice president of startups ecosystem at NVIDIA, who discussed how sovereign AI empowers Brazil to unlock national potential, fostering economic growth, technological autonomy and leadership in the regional AI landscape.&lt;/p&gt;&lt;p&gt;Another all-conference panel, called “Sovereign AI in Action: Learnings and Partnerships Driving Local Innovation,” explored how startups, academia and AI hubs across Latin America are crafting partnerships and nurturing specialized talent to bolster AI innovation, including using NVIDIA NeMo software and NVIDIA NIM microservices.&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__full-width-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-sovereign-ai-session-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			Sovereign AI panel at NVIDIA AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;Industry in Motion&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;Brazil-based NVIDIA partners are helping fuel the AI industrial revolution.&amp;nbsp;&lt;/p&gt;&lt;p&gt;At the event:&lt;/p&gt;&lt;ul&gt;
&lt;li&gt;Amadeus AI showcased advanced techniques in efficiently fine‑tuning LLMs for specific domains and languages, including using reinforcement learning with human feedback. The company emphasized cost‑effective fine‑tuning pipelines using GPUs and open source tools to balance performance and scalability.&lt;/li&gt;
&lt;li&gt;Langflow shared architecture patterns, best practices for evaluation and governance, and methods of combining Langflow with NVIDIA technologies to build robust, cost‑efficient agents aligned with business goals.​&amp;nbsp;&lt;/li&gt;
&lt;li&gt;WideLabs presented how Latin American governments and enterprises are building sovereign AI platforms, ranging from national dataset initiatives to applications with stringent safety and governance requirements, all built on the NVIDIA AI stack. The company also presented its new AI synthetic data pipeline, Nemotron Personas Brazil.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;&lt;p&gt;“At NVIDIA AI Days, we were able to gain a much more thorough understanding of the NVIDIA NeMo framework,” said Rodrigo Malossi, cofounder and chief technology officer of WideLabs. “The event also allowed us to better understand NVIDIA’s new initiatives and what they are proposing with respect to large-scale, national-level sovereign AI efforts.”&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;

&lt;div class="full-width-layout__standard-image-section"&gt;
			&lt;img alt="alt" class="full-width-layout__image" height="1363" src="https://blogs.nvidia.com/wp-content/uploads/2026/02/sao-paulo-inception-session-scaled.jpeg" width="2048" /&gt;	
	
&lt;p&gt;
			&lt;span class="full-width-layout__media-caption-callout"&gt;
			NVIDIA Inception session at AI Day São Paulo.		&lt;/span&gt;
	
	&lt;/p&gt;
&lt;/div&gt;

&lt;div class="full-width-layout__article-copy-section light"&gt;
	&lt;h2 class="full-width-layout__heading"&gt;What’s Next&lt;/h2&gt;&lt;div class="full-width-layout__copy"&gt;&lt;p&gt;The NVIDIA developer ecosystem in the region will continue driving innovation in support of the Brazilian Artificial Intelligence Plan, with a focus on LLM development, healthcare and financial services.&amp;nbsp;&lt;/p&gt;&lt;p&gt;In addition, NVIDIA is partnering with Brazil-founded telecommunications provider Claro — the first NVIDIA Cloud Partner in Latin America — to accelerate sovereign AI in the region.&lt;/p&gt;&lt;p&gt;&lt;i&gt;Learn more about &lt;/i&gt;&lt;i&gt;NVIDIA AI Days&lt;/i&gt;&lt;i&gt;.&lt;/i&gt;&lt;/p&gt;
&lt;/div&gt;&lt;/div&gt;
&lt;/div&gt;
	&lt;div class="full-width-layout__news-section"&gt;
		&lt;p&gt;Related News&lt;/p&gt;

		
	&lt;/div&gt;
		&lt;/div&gt;
	


&lt;!-- #colophon --&gt;

&lt;/div&gt;&lt;!-- #page --&gt;


&lt;!-- #has-highlight-and-share --&gt;		&lt;svg class="hidden" height="0" width="0" xmlns="http://www.w3.org/2000/svg"&gt;
			
				&lt;g&gt;&lt;path d="M18.244 2.25h3.308l-7.227 8.26 8.502 11.24H16.17l-5.214-6.817L4.99 21.75H1.68l7.73-8.835L1.254 2.25H8.08l4.713 6.231zm-1.161 17.52h1.833L7.084 4.126H5.117z" fill="currentColor"&gt;&lt;/g&gt;
			
			
				&lt;path d="M279.14 288l14.22-92.66h-88.91v-60.13c0-25.35 12.42-50.06 52.24-50.06h40.42V6.26S260.43 0 225.36 0c-73.22 0-121.08 44.38-121.08 124.72v70.62H22.89V288h81.39v224h100.17V288z" fill="currentColor"&gt;
			
			
				&lt;path d="M256 8C118.941 8 8 118.919 8 256c0 137.059 110.919 248 248 248 48.154 0 95.342-14.14 135.408-40.223 12.005-7.815 14.625-24.288 5.552-35.372l-10.177-12.433c-7.671-9.371-21.179-11.667-31.373-5.129C325.92 429.757 291.314 440 256 440c-101.458 0-184-82.542-184-184S154.542 72 256 72c100.139 0 184 57.619 184 160 0 38.786-21.093 79.742-58.17 83.693-17.349-.454-16.91-12.857-13.476-30.024l23.433-121.11C394.653 149.75 383.308 136 368.225 136h-44.981a13.518 13.518 0 0 0-13.432 11.993l-.01.092c-14.697-17.901-40.448-21.775-59.971-21.775-74.58 0-137.831 62.234-137.831 151.46 0 65.303 36.785 105.87 96 105.87 26.984 0 57.369-15.637 74.991-38.333 9.522 34.104 40.613 34.103 70.71 34.103C462.609 379.41 504 307.798 504 232 504 95.653 394.023 8 256 8zm-21.68 304.43c-22.249 0-36.07-15.623-36.07-40.771 0-44.993 30.779-72.729 58.63-72.729 22.292 0 35.601 15.241 35.601 40.77 0 45.061-33.875 72.73-58.161 72.73z" fill="currentColor"&gt;
			
			
				&lt;path d="M100.28 448H7.4V148.9h92.88zM53.79 108.1C24.09 108.1 0 83.5 0 53.8a53.79 53.79 0 0 1 107.58 0c0 29.7-24.1 54.3-53.79 54.3zM447.9 448h-92.68V302.4c0-34.7-.7-79.2-48.29-79.2-48.29 0-55.69 37.7-55.69 76.7V448h-92.78V148.9h89.08v40.8h1.3c12.4-23.5 42.69-48.3 87.88-48.3 94 0 111.28 61.9 111.28 142.3V448z" fill="currentColor"&gt;
			
			
				&lt;path d="M162.7 210c-1.8 3.3-25.2 44.4-70.1 123.5-4.9 8.3-10.8 12.5-17.7 12.5H9.8c-7.7 0-12.1-7.5-8.5-14.4l69-121.3c.2 0 .2-.1 0-.3l-43.9-75.6c-4.3-7.8.3-14.1 8.5-14.1H100c7.3 0 13.3 4.1 18 12.2l44.7 77.5zM382.6 46.1l-144 253v.3L330.2 466c3.9 7.1.2 14.1-8.5 14.1h-65.2c-7.6 0-13.6-4-18-12.2l-92.4-168.5c3.3-5.8 51.5-90.8 144.8-255.2 4.6-8.1 10.4-12.2 17.5-12.2h65.7c8 0 12.3 6.7 8.5 14.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z" fill="currentColor"&gt;
			
			
				&lt;path d="M320 448v40c0 13.255-10.745 24-24 24H24c-13.255 0-24-10.745-24-24V120c0-13.255 10.745-24 24-24h72v296c0 30.879 25.121 56 56 56h168zm0-344V0H152c-13.255 0-24 10.745-24 24v368c0 13.255 10.745 24 24 24h272c13.255 0 24-10.745 24-24V128H344c-13.2 0-24-10.8-24-24zm120.971-31.029L375.029 7.029A24 24 0 0 0 358.059 0H352v96h96v-6.059a24 24 0 0 0-7.029-16.97z" fill="currentColor"&gt;
			
			
				&lt;path d="M352 320c-22.608 0-43.387 7.819-59.79 20.895l-102.486-64.054a96.551 96.551 0 0 0 0-41.683l102.486-64.054C308.613 184.181 329.392 192 352 192c53.019 0 96-42.981 96-96S405.019 0 352 0s-96 42.981-96 96c0 7.158.79 14.13 2.276 20.841L155.79 180.895C139.387 167.819 118.608 160 96 160c-53.019 0-96 42.981-96 96s42.981 96 96 96c22.608 0 43.387-7.819 59.79-20.895l102.486 64.054A96.301 96.301 0 0 0 256 416c0 53.019 42.981 96 96 96s96-42.981 96-96-42.981-96-96-96z" fill="currentColor"&gt;
			
			
				&lt;path d="M440.3 203.5c-15 0-28.2 6.2-37.9 15.9-35.7-24.7-83.8-40.6-137.1-42.3L293 52.3l88.2 19.8c0 21.6 17.6 39.2 39.2 39.2 22 0 39.7-18.1 39.7-39.7s-17.6-39.7-39.7-39.7c-15.4 0-28.7 9.3-35.3 22l-97.4-21.6c-4.9-1.3-9.7 2.2-11 7.1L246.3 177c-52.9 2.2-100.5 18.1-136.3 42.8-9.7-10.1-23.4-16.3-38.4-16.3-55.6 0-73.8 74.6-22.9 100.1-1.8 7.9-2.6 16.3-2.6 24.7 0 83.8 94.4 151.7 210.3 151.7 116.4 0 210.8-67.9 210.8-151.7 0-8.4-.9-17.2-3.1-25.1 49.9-25.6 31.5-99.7-23.8-99.7zM129.4 308.9c0-22 17.6-39.7 39.7-39.7 21.6 0 39.2 17.6 39.2 39.7 0 21.6-17.6 39.2-39.2 39.2-22 .1-39.7-17.6-39.7-39.2zm214.3 93.5c-36.4 36.4-139.1 36.4-175.5 0-4-3.5-4-9.7 0-13.7 3.5-3.5 9.7-3.5 13.2 0 27.8 28.5 120 29 149 0 3.5-3.5 9.7-3.5 13.2 0 4.1 4 4.1 10.2.1 13.7zm-.8-54.2c-21.6 0-39.2-17.6-39.2-39.2 0-22 17.6-39.7 39.2-39.7 22 0 39.7 17.6 39.7 39.7-.1 21.5-17.7 39.2-39.7 39.2z" fill="currentColor"&gt;
			
			
				&lt;path d="M446.7 98.6l-67.6 318.8c-5.1 22.5-18.4 28.1-37.3 17.5l-103-75.9-49.7 47.8c-5.5 5.5-10.1 10.1-20.7 10.1l7.4-104.9 190.9-172.5c8.3-7.4-1.8-11.5-12.9-4.1L117.8 284 16.2 252.2c-22.1-6.9-22.5-22.1 4.6-32.7L418.2 66.4c18.4-6.9 34.5 4.1 28.5 32.2z" fill="currentColor"&gt;
			
			
				&lt;g&gt;
					&lt;path d="M97.2800192,3.739673 L100.160021,15.3787704 C88.8306631,18.1647705 77.9879854,22.6484879 68.0000023,28.6777391 L61.8399988,18.3985363 C72.8467373,11.7537029 84.7951803,6.81153332 97.2800192,3.739673 Z M158.720055,3.739673 L155.840053,15.3787704 C167.169411,18.1647705 178.012089,22.6484879 188.000072,28.6777391 L194.200075,18.3985363 C183.180932,11.7499974 171.218739,6.80771878 158.720055,3.739673 L158.720055,3.739673 Z M18.3999736,61.8351679 C11.7546212,72.8410466 6.81206547,84.7885562 3.73996516,97.2724198 L15.3799719,100.152197 C18.1661896,88.8237238 22.6502573,77.981893 28.6799796,67.9946902 L18.3999736,61.8351679 Z M11.9999699,127.990038 C11.9961044,122.172725 12.4306685,116.363392 13.2999707,110.611385 L1.43996383,108.811525 C-0.479938607,121.525138 -0.479938607,134.454937 1.43996383,147.168551 L13.2999707,145.36869 C12.4306685,139.616684 11.9961044,133.807351 11.9999699,127.990038 L11.9999699,127.990038 Z M194.160075,237.581539 L188.000072,227.302336 C178.024494,233.327885 167.195565,237.811494 155.880053,240.601305 L158.760055,252.240403 C171.231048,249.164732 183.165742,244.222671 194.160075,237.581539 L194.160075,237.581539 Z M244.000104,127.990038 C244.00397,133.807351 243.569406,139.616684 242.700103,145.36869 L254.56011,147.168551 C256.480013,134.454937 256.480013,121.525138 254.56011,108.811525 L242.700103,110.611385 C243.569406,116.363392 244.00397,122.172725 244.000104,127.990038 Z M252.260109,158.707656 L240.620102,155.827879 C237.833884,167.156352 233.349817,177.998183 227.320094,187.985385 L237.6001,194.184905 C244.249159,183.166622 249.191823,171.205364 252.260109,158.707656 L252.260109,158.707656 Z M145.380047,242.701142 C133.858209,244.43447 122.141865,244.43447 110.620027,242.701142 L108.820026,254.560223 C121.534632,256.479975 134.465442,256.479975 147.180048,254.560223 L145.380047,242.701142 Z M221.380091,196.804701 C214.461479,206.174141 206.175877,214.452354 196.800077,221.362797 L203.920081,231.022048 C214.262958,223.418011 223.404944,214.303705 231.040097,203.984145 L221.380091,196.804701 Z M196.800077,34.6172785 C206.177345,41.5338058 214.463023,49.8188367 221.380091,59.1953726 L231.040097,51.9959309 C223.429284,41.6822474 214.31457,32.5682452 204.000081,24.9580276 L196.800077,34.6172785 Z M34.619983,59.1953726 C41.5370506,49.8188367 49.8227288,41.5338058 59.1999972,34.6172785 L51.9999931,24.9580276 C41.6855038,32.5682452 32.5707896,41.6822474 24.9599774,51.9959309 L34.619983,59.1953726 Z M237.6001,61.8351679 L227.320094,67.9946902 C233.346114,77.969489 237.830073,88.7975718 240.620102,100.1122 L252.260109,97.2324229 C249.184198,84.7624043 244.241751,72.8286423 237.6001,61.8351679 L237.6001,61.8351679 Z M110.620027,13.2989317 C122.141865,11.5656035 133.858209,11.5656035 145.380047,13.2989317 L147.180048,1.43985134 C134.465442,-0.479901112 121.534632,-0.479901112 108.820026,1.43985134 L110.620027,13.2989317 Z M40.7799866,234.201801 L15.9999722,239.981353 L21.7799756,215.203275 L10.0999688,212.463487 L4.3199655,237.241566 C3.3734444,241.28318 4.58320332,245.526897 7.51859925,248.462064 C10.4539952,251.39723 14.6980441,252.606895 18.7399738,251.660448 L43.4999881,245.980888 L40.7799866,234.201801 Z M12.5999703,201.764317 L24.279977,204.484106 L28.2799793,187.305438 C22.4496684,177.507146 18.1025197,166.899584 15.3799719,155.827879 L3.73996516,158.707656 C6.34937618,169.311891 10.3154147,179.535405 15.539972,189.125297 L12.5999703,201.764317 Z M68.6000027,227.762301 L51.4199927,231.761991 L54.1399943,243.441085 L66.7800016,240.501313 C76.3706428,245.725462 86.5949557,249.691191 97.2000192,252.300398 L100.080021,240.6613 C89.0307035,237.906432 78.4495684,233.532789 68.6800027,227.682307 L68.6000027,227.762301 Z M128.000037,23.9980665 C90.1565244,24.0177003 55.3105242,44.590631 37.01511,77.715217 C18.7196958,110.839803 19.8628631,151.287212 39.9999861,183.325747 L29.9999803,225.982439 L72.660005,215.983214 C110.077932,239.548522 158.307237,236.876754 192.892851,209.322653 C227.478464,181.768552 240.856271,135.358391 226.242944,93.6248278 C211.629616,51.8912646 172.221191,23.9617202 128.000037,23.9980665 Z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g&gt;
					&lt;path d="M357.1,324.5c-24.1,15.3-57.2,21.4-79.1,23.6l18.4,18.1l67,67c24.5,25.1-15.4,64.4-40.2,40.2c-16.8-17-41.4-41.6-67-67.3
						l-67,67.2c-24.8,24.2-64.7-15.5-39.9-40.2c17-17,41.4-41.6,67-67l18.1-18.1c-21.6-2.3-55.3-8-79.6-23.6
						c-28.6-18.5-41.2-29.3-30.1-51.8c6.5-12.8,24.3-23.6,48-5c0,0,31.9,25.4,83.4,25.4s83.4-25.4,83.4-25.4c23.6-18.5,41.4-7.8,48,5
						C398.3,295.1,385.7,305.9,357.1,324.5L357.1,324.5z M142,145c0-63,51.2-114,114-114s114,51,114,114c0,62.7-51.2,113.7-114,113.7
						S142,207.7,142,145L142,145z M200,145c0,30.8,25.1,56,56,56s56-25.1,56-56c0-31.1-25.1-56.2-56-56.2S200,113.9,200,145z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			
				&lt;g transform="translate(0,664)"&gt;
					&lt;path d="m 1073.3513,-606.40537 h 196.278 c 179.2103,0 221.8795,42.66915 221.8795,221.8795 v 196.27799 c 0,179.2103512 -42.6692,221.879451 -221.8795,221.879451 h -196.278 c -179.21038,0 -221.87951,-42.6691298 -221.87951,-221.879451 v -196.27801 c 0,-179.21035 42.66913,-221.87946 221.87951,-221.87948 z" fill="currentColor"&gt;
					&lt;path d="m 1375.0576,-393.98425 c 2.9513,-9.7072 0,-16.85429 -14.1342,-16.85429 h -46.6693 c -11.8763,0 -17.3521,6.16927 -20.3212,12.97854 0,0 -23.7347,56.82106 -57.3544,93.74763 -10.8806,10.66728 -15.8232,14.08081 -21.7613,14.08081 -2.969,0 -7.2715,-3.39577 -7.2715,-13.12075 v -90.83194 c 0,-11.66288 -3.4491,-16.85429 -13.3341,-16.85429 h -73.3553 c -7.4138,0 -11.8763,5.40476 -11.8763,10.54286 0,11.0406 16.8188,13.60078 18.5433,44.67814 v 67.52388 c 0,14.80973 -2.7202,17.49433 -8.6583,17.49433 -15.8231,0 -54.3143,-57.08773 -77.16,-122.40705 -4.4447,-12.71185 -8.9427,-17.83214 -20.8723,-17.83214 h -46.68718 c -13.3341,0 -16.0009,6.16925 -16.0009,12.97852 0,12.12515 15.8232,72.35973 73.69318,152.02656 38.58,54.40315 92.8942,83.89819 142.3726,83.89819 29.6729,0 33.3353,-6.54262 33.3353,-17.83216 v -41.12238 c 0,-13.10297 2.809,-15.71646 12.214,-15.71646 6.9338,0 18.7922,3.41353 46.4916,29.63728 31.6463,31.09512 36.8555,45.03372 54.6698,45.03372 h 46.6694 c 13.3341,0 20.0189,-6.54262 16.1787,-19.46781 -4.2313,-12.88962 -19.3433,-31.57515 -39.38,-53.74532 -10.8807,-12.62294 -27.2016,-26.22375 -32.1441,-33.03302 -6.9338,-8.72941 -4.9603,-12.62294 0,-20.39227 0,0 56.8566,-78.68897 62.7947,-105.41058 z" fill="currentColor"&gt;
					&lt;path d="m 567.69877,-429.06912 c 3.15618,-10.38133 0,-18.0247 -15.11579,-18.0247 h -49.91013 c -12.70096,0 -18.55706,6.59763 -21.73232,13.87977 0,0 -25.38286,60.76685 -61.33724,100.25768 -11.63627,11.40806 -16.92197,15.05863 -23.27242,15.05863 -3.17519,0 -7.77644,-3.63156 -7.77644,-14.0319 v -97.13948 c 0,-12.47278 -3.68869,-18.0247 -14.26014,-18.0247 h -78.44923 c -7.92857,0 -12.70097,5.78005 -12.70097,11.27491 0,11.80736 17.98666,14.54527 19.83094,47.78071 v 72.21293 c 0,15.83815 -2.9091,18.70918 -9.25948,18.70918 -16.92197,0 -58.08598,-61.05206 -82.51817,-130.90731 -4.75337,-13.59458 -9.56381,-19.07042 -22.32175,-19.07042 h -49.92915 c -14.26014,0 -17.11213,6.59763 -17.11213,13.87977 0,12.96714 16.92197,77.38454 78.81059,162.58363 41.25909,58.18101 99.34506,89.72424 152.25931,89.72424 31.73343,0 35.65018,-6.99691 35.65018,-19.07043 v -43.978 c 0,-14.01288 3.00405,-16.80786 13.0622,-16.80786 7.41521,0 20.09716,3.65057 49.71998,31.69536 33.84387,33.25443 39.41486,48.16093 58.46622,48.16093 h 49.91026 c 14.26,0 21.40913,-6.99691 17.30216,-20.81966 -4.5252,-13.78473 -20.68653,-33.76783 -42.11468,-57.47752 -11.63621,-13.49953 -29.09043,-28.04479 -34.37631,-35.32694 -7.41508,-9.33557 -5.30458,-13.4995 0,-21.80835 0,0 60.80491,-84.15334 67.15549,-112.73048 z" fill="currentColor"&gt;
				&lt;/g&gt;
			
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M512 208L320 384H288V288H208c-61.9 0-112 50.1-112 112c0 48 32 80 32 80s-128-48-128-176c0-97.2 78.8-176 176-176H288V32h32L512 208z" fill="currentColor"&gt;
			&lt;path d="M309.8 480.3c-13.6 14.5-50 31.7-97.4 31.7-120.8 0-147-88.8-147-140.6v-144H17.9c-5.5 0-10-4.5-10-10v-68c0-7.2 4.5-13.6 11.3-16 62-21.8 81.5-76 84.3-117.1.8-11 6.5-16.3 16.1-16.3h70.9c5.5 0 10 4.5 10 10v115.2h83c5.5 0 10 4.4 10 9.9v81.7c0 5.5-4.5 10-10 10h-83.4V360c0 34.2 23.7 53.6 68 35.8 4.8-1.9 9-3.2 12.7-2.2 3.5.9 5.8 3.4 7.4 7.9l22 64.3c1.8 5 3.3 10.6-.4 14.5z" fill="currentColor"&gt;
			&lt;path d="M433 179.1c0-97.2-63.7-125.7-63.7-125.7-62.5-28.7-228.6-28.4-290.5 0 0 0-63.7 28.5-63.7 125.7 0 115.7-6.6 259.4 105.6 289.1 40.5 10.7 75.3 13 103.3 11.4 50.8-2.8 79.3-18.1 79.3-18.1l-1.7-36.9s-36.3 11.4-77.1 10.1c-40.4-1.4-83-4.4-89.6-54a102.5 102.5 0 0 1 -.9-13.9c85.6 20.9 158.7 9.1 178.8 6.7 56.1-6.7 105-41.3 111.2-72.9 9.8-49.8 9-121.5 9-121.5zm-75.1 125.2h-46.6v-114.2c0-49.7-64-51.6-64 6.9v62.5h-46.3V197c0-58.5-64-56.6-64-6.9v114.2H90.2c0-122.1-5.2-147.9 18.4-175 25.9-28.9 79.8-30.8 103.8 6.1l11.6 19.5 11.6-19.5c24.1-37.1 78.1-34.8 103.8-6.1 23.7 27.3 18.4 53 18.4 175z" fill="currentColor"&gt;
			
				&lt;path d="M331.5 235.7c2.2 .9 4.2 1.9 6.3 2.8c29.2 14.1 50.6 35.2 61.8 61.4c15.7 36.5 17.2 95.8-30.3 143.2c-36.2 36.2-80.3 52.5-142.6 53h-.3c-70.2-.5-124.1-24.1-160.4-70.2c-32.3-41-48.9-98.1-49.5-169.6V256v-.2C17 184.3 33.6 127.2 65.9 86.2C102.2 40.1 156.2 16.5 226.4 16h.3c70.3 .5 124.9 24 162.3 69.9c18.4 22.7 32 50 40.6 81.7l-40.4 10.8c-7.1-25.8-17.8-47.8-32.2-65.4c-29.2-35.8-73-54.2-130.5-54.6c-57 .5-100.1 18.8-128.2 54.4C72.1 146.1 58.5 194.3 58 256c.5 61.7 14.1 109.9 40.3 143.3c28 35.6 71.2 53.9 128.2 54.4c51.4-.4 85.4-12.6 113.7-40.9c32.3-32.2 31.7-71.8 21.4-95.9c-6.1-14.2-17.1-26-31.9-34.9c-3.7 26.9-11.8 48.3-24.7 64.8c-17.1 21.8-41.4 33.6-72.7 35.3c-23.6 1.3-46.3-4.4-63.9-16c-20.8-13.8-33-34.8-34.3-59.3c-2.5-48.3 35.7-83 95.2-86.4c21.1-1.2 40.9-.3 59.2 2.8c-2.4-14.8-7.3-26.6-14.6-35.2c-10-11.7-25.6-17.7-46.2-17.8H227c-16.6 0-39 4.6-53.3 26.3l-34.4-23.6c19.2-29.1 50.3-45.1 87.8-45.1h.8c62.6 .4 99.9 39.5 103.7 107.7l-.2 .2zm-156 68.8c1.3 25.1 28.4 36.8 54.6 35.3c25.6-1.4 54.6-11.4 59.5-73.2c-13.2-2.9-27.8-4.4-43.4-4.4c-4.8 0-9.6 .1-14.4 .4c-42.9 2.4-57.2 23.2-56.2 41.8l-.1 .1z" fill="currentColor"&gt;
			
			
				&lt;path d="M407.8 294.7c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3zM288 227.1C261.9 176.4 190.9 81.9 124.9 35.3C61.6-9.4 37.5-1.7 21.6 5.5C3.3 13.8 0 41.9 0 58.4S9.1 194 15 213.9c19.5 65.7 89.1 87.9 153.2 80.7c3.3-.5 6.6-.9 10-1.4c-3.3 .5-6.6 1-10 1.4C74.3 308.6-9.1 342.8 100.3 464.5C220.6 589.1 265.1 437.8 288 361.1c22.9 76.7 49.2 222.5 185.6 103.4c102.4-103.4 28.1-156-65.8-169.9c-3.3-.4-6.7-.8-10-1.3c3.4 .4 6.7 .9 10 1.3c64.1 7.1 133.6-15.1 153.2-80.7C566.9 194 576 75 576 58.4s-3.3-44.7-21.6-52.9c-15.8-7.1-40-14.9-103.2 29.8C385.1 81.9 314.1 176.4 288 227.1z" fill="currentColor"&gt;
			
			
				&lt;path d="M204 6.5C101.4 6.5 0 74.9 0 185.6 0 256 39.6 296 63.6 296c9.9 0 15.6-27.6 15.6-35.4 0-9.3-23.7-29.1-23.7-67.8 0-80.4 61.2-137.4 140.4-137.4 68.1 0 118.5 38.7 118.5 109.8 0 53.1-21.3 152.7-90.3 152.7-24.9 0-46.2-18-46.2-43.8 0-37.8 26.4-74.4 26.4-113.4 0-66.2-93.9-54.2-93.9 25.8 0 16.8 2.1 35.4 9.6 50.7-13.8 59.4-42 147.9-42 209.1 0 18.9 2.7 37.5 4.5 56.4 3.4 3.8 1.7 3.4 6.9 1.5 50.4-69 48.6-82.5 71.4-172.8 12.3 23.4 44.1 36 69.3 36 106.2 0 153.9-103.5 153.9-196.8C384 71.3 298.2 6.5 204 6.5z" fill="currentColor"&gt;
			
		&lt;/svg&gt;
		&lt;div id="has-mastodon-prompt"&gt;
			&lt;h3&gt;Share on Mastodon&lt;/h3&gt;
			
		&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/ai-day-sao-paulo/</guid><pubDate>Thu, 12 Feb 2026 22:00:58 +0000</pubDate></item><item><title>Musk needed a new vision for SpaceX and xAI. He landed on Moonbase Alpha. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;“Join xAI if the idea of mass drivers on the Moon appeals to you,” CEO Elon Musk proclaimed yesterday following a restructuring that saw a stream of former executives exit the AI lab.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is an interesting recruitment strategy after the company’s merger with Musk’s rocket maker, SpaceX, and the combined company’s anticipated IPO. You might think that xAI employees ought to be fascinated with achieving AGI, using deep learning models to disrupt traditional software companies, or simply bad wordplay like “Macrohard.” But instead, Elon is going to the moon.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After outlining plans to build AI data centers in orbit, the primary synergy between the two companies, Musk took the idea further. “What if you want to go beyond a mere terawatt per year?” Musk asked. “To do that, you have to go to the moon…I really want to see a mass driver on the moon that is shooting AI satellites into deep space.”&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3092618" height="377" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-at-10.37.51-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;New year, new dream&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SpaceX&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In Musk’s telling, the step beyond data centers orbiting Earth is even larger computers in deep space. And furthermore, Musk says the best way to achieve that is to build a city on the moon to manufacture space computers and hurl them into the solar system using a big maglev train.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If that all feels a bit much, veteran Musk watchers know there’s a clue about where the discussion appears in a video of an all-hands meeting xAI shared with the public. The slide describing the moon base comes at the end of the presentation deck, where, during SpaceX pep talks, Musk typically shares renderings of SpaceX rockets landing on Mars and waxes rhapsodic about the future of multi-planetary humanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the moon base comes just after SpaceX has publicly backed away from its long-held goal of colonizing Mars. Now, with xAI in the corporate fold, Musk needs a new science fiction metaphor for the future: In this case, the Kardashev Scale, a theoretical measure of galactic civilizations coined by the eponymous Soviet astronomer in the 1960s. The idea is climbing the scale of energy usage — early civilizations figure out how to leverage all the power sources on their planets, and then (hypothetically) go to space and build infrastructure to capture the energy of the sun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the moon base, Musk says the company could harness “maybe even a few percent of the sun’s energy” to train and operate AI models. “It’s difficult to imagine what an intelligence of that scale would think about,” he told his staff, “but it’s going to be incredibly exciting to see it happen.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In the nine years since Musk unveiled his plan for Martian exploration and colonization, the vision has been an effective hiring tool for SpaceX: The founding tale of Musk’s interest in the Red Planet offered a long-term vision that united the company’s various development efforts, and signaled the company’s ambition among other space contractors that settled for incremental work on government priorities. “Occupy Mars” t-shirts offered a visible symbol of SpaceX’s aspirations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where the hypothetical moon base fits in — part of a long history of Musk wrapping his companies in a powerful narrative. It’s one million people living on Mars, but now catering to a future where AI is the most interesting thing. Martian mission creep became apparent less in Musk’s May 2025 Starship update, when the presentation ended with a now-cancelled vision of Tesla Optimus robots clomping across the Red Planet.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3092593" height="380" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-at-10.25.18-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Poor robot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SpaceX&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;There was just one problem with SpaceX and Mars: No one wanted to pay them to go there. Plans announced in 2016 to repurpose the company’s Dragon spacecraft as a Mars lander were abandoned the next year after the technical challenges became too costly. And since Musk unveiled the vehicle that would become Starship in 2016, its capabilities, initially intended for Mars colonization, have been scaled back to focus on two more remunerative tasks: launching satellites for the Starlink comms network and $4 billion worth of contracts to land astronauts on the moon for NASA.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Unlike a multi-planetary civilization, there may be some logic in having SpaceX purchase a money-burning AI and social media to build data centers in Earth orbit, particularly if forecasts of rising demand and costs on the ground come true. Experts suggest that it might be possible in the 2030s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hypothetically, building satellites on the moon would require a lot more of Musk’s other dreams coming true first. Scientists and startups are experimenting with building chips and other precision components in space. But mass-producing many tons of advanced computers on the moon means we’re living in a universe where it is dramatically cheaper to get to space, which is the central requirement for those technologies, getting all the raw materials for such an effort to the moon, plus whatever is required for a “self-sustaining city.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a sense, that’s the point: This is the, uh, stretch goal. If meme-happy retail investors buy the argument, they could turn SpaceX shares into the next Tesla. The engineers, AI or aerospace, who Musk needs to achieve his goals may find the shift jarring. But the vision is one way to explain what xAI is about, other than an LLM perhaps best known as a pervert. As one of the company’s departing executives said on his way out the door, “all AI labs are building the exact same thing, and it’s boring.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mass-producing a solar system-scale supercomputer on the moon is many things (I’m going to get emails for not using the word “insane”), but it is not the exact same thing, and it is not boring.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;“Join xAI if the idea of mass drivers on the Moon appeals to you,” CEO Elon Musk proclaimed yesterday following a restructuring that saw a stream of former executives exit the AI lab.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is an interesting recruitment strategy after the company’s merger with Musk’s rocket maker, SpaceX, and the combined company’s anticipated IPO. You might think that xAI employees ought to be fascinated with achieving AGI, using deep learning models to disrupt traditional software companies, or simply bad wordplay like “Macrohard.” But instead, Elon is going to the moon.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After outlining plans to build AI data centers in orbit, the primary synergy between the two companies, Musk took the idea further. “What if you want to go beyond a mere terawatt per year?” Musk asked. “To do that, you have to go to the moon…I really want to see a mass driver on the moon that is shooting AI satellites into deep space.”&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3092618" height="377" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-at-10.37.51-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;New year, new dream&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SpaceX&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In Musk’s telling, the step beyond data centers orbiting Earth is even larger computers in deep space. And furthermore, Musk says the best way to achieve that is to build a city on the moon to manufacture space computers and hurl them into the solar system using a big maglev train.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;If that all feels a bit much, veteran Musk watchers know there’s a clue about where the discussion appears in a video of an all-hands meeting xAI shared with the public. The slide describing the moon base comes at the end of the presentation deck, where, during SpaceX pep talks, Musk typically shares renderings of SpaceX rockets landing on Mars and waxes rhapsodic about the future of multi-planetary humanity.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, the moon base comes just after SpaceX has publicly backed away from its long-held goal of colonizing Mars. Now, with xAI in the corporate fold, Musk needs a new science fiction metaphor for the future: In this case, the Kardashev Scale, a theoretical measure of galactic civilizations coined by the eponymous Soviet astronomer in the 1960s. The idea is climbing the scale of energy usage — early civilizations figure out how to leverage all the power sources on their planets, and then (hypothetically) go to space and build infrastructure to capture the energy of the sun.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the moon base, Musk says the company could harness “maybe even a few percent of the sun’s energy” to train and operate AI models. “It’s difficult to imagine what an intelligence of that scale would think about,” he told his staff, “but it’s going to be incredibly exciting to see it happen.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;In the nine years since Musk unveiled his plan for Martian exploration and colonization, the vision has been an effective hiring tool for SpaceX: The founding tale of Musk’s interest in the Red Planet offered a long-term vision that united the company’s various development efforts, and signaled the company’s ambition among other space contractors that settled for incremental work on government priorities. “Occupy Mars” t-shirts offered a visible symbol of SpaceX’s aspirations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s where the hypothetical moon base fits in — part of a long history of Musk wrapping his companies in a powerful narrative. It’s one million people living on Mars, but now catering to a future where AI is the most interesting thing. Martian mission creep became apparent less in Musk’s May 2025 Starship update, when the presentation ended with a now-cancelled vision of Tesla Optimus robots clomping across the Red Planet.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3092593" height="380" src="https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-at-10.25.18-AM.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Poor robot&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SpaceX&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;There was just one problem with SpaceX and Mars: No one wanted to pay them to go there. Plans announced in 2016 to repurpose the company’s Dragon spacecraft as a Mars lander were abandoned the next year after the technical challenges became too costly. And since Musk unveiled the vehicle that would become Starship in 2016, its capabilities, initially intended for Mars colonization, have been scaled back to focus on two more remunerative tasks: launching satellites for the Starlink comms network and $4 billion worth of contracts to land astronauts on the moon for NASA.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Unlike a multi-planetary civilization, there may be some logic in having SpaceX purchase a money-burning AI and social media to build data centers in Earth orbit, particularly if forecasts of rising demand and costs on the ground come true. Experts suggest that it might be possible in the 2030s.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hypothetically, building satellites on the moon would require a lot more of Musk’s other dreams coming true first. Scientists and startups are experimenting with building chips and other precision components in space. But mass-producing many tons of advanced computers on the moon means we’re living in a universe where it is dramatically cheaper to get to space, which is the central requirement for those technologies, getting all the raw materials for such an effort to the moon, plus whatever is required for a “self-sustaining city.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a sense, that’s the point: This is the, uh, stretch goal. If meme-happy retail investors buy the argument, they could turn SpaceX shares into the next Tesla. The engineers, AI or aerospace, who Musk needs to achieve his goals may find the shift jarring. But the vision is one way to explain what xAI is about, other than an LLM perhaps best known as a pervert. As one of the company’s departing executives said on his way out the door, “all AI labs are building the exact same thing, and it’s boring.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mass-producing a solar system-scale supercomputer on the moon is many things (I’m going to get emails for not using the word “insane”), but it is not the exact same thing, and it is not boring.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/</guid><pubDate>Thu, 12 Feb 2026 22:10:55 +0000</pubDate></item><item><title>OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI’s new GPT‑5.3‑Codex‑Spark is 15 times faster at coding than its predecessor.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A man using a metal grinder causing sparks to fly." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2225076517_resize-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A man using a metal grinder causing sparks to fly." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2225076517_resize-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Teera Konakan / Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, OpenAI released its first production AI model to run on non-Nvidia hardware, deploying the new GPT-5.3-Codex-Spark coding model on chips from Cerebras. The model delivers code at more than 1,000 tokens (chunks of data) per second, which is reported to be roughly 15 times faster than its predecessor. To compare, Anthropic’s Claude Opus 4.6 in its new premium-priced fast mode reaches about 2.5 times its standard speed of 68.2 tokens per second, although it is a larger and more capable model than Spark.&lt;/p&gt;
&lt;p&gt;“Cerebras has been a great engineering partner, and we’re excited about adding fast inference as a new platform capability,” Sachin Katti, head of compute at OpenAI, said in a statement.&lt;/p&gt;
&lt;p&gt;Codex-Spark is a research preview available to ChatGPT Pro subscribers ($200/month) through the Codex app, command-line interface, and VS Code extension. OpenAI is rolling out API access to select design partners. The model ships with a 128,000-token context window and handles text only at launch.&lt;/p&gt;
&lt;p&gt;The release builds on the full GPT-5.3-Codex model that OpenAI launched earlier this month. Where the full model handles heavyweight agentic coding tasks, OpenAI tuned Spark for speed over depth of knowledge.&amp;nbsp; OpenAI built it as a text-only model and tuned it specifically for coding, not for the general-purpose tasks that the larger version of GPT-5.3 handles.&lt;/p&gt;
&lt;p&gt;On SWE-Bench Pro and Terminal-Bench 2.0, two benchmarks for evaluating software engineering ability, Spark reportedly outperforms the older GPT-5.1-Codex-mini while completing tasks in a fraction of the time, according to OpenAI. The company did not share independent validation of those numbers.&lt;/p&gt;
&lt;p&gt;Anecdotally, Codex’s speed has been a sore spot; when Ars tested four AI coding agents building &lt;em&gt;Minesweeper&lt;/em&gt; clones in December, Codex took roughly twice as long as Anthropic’s Claude Code to produce a working game.&lt;/p&gt;
&lt;h2&gt;The coding agent arms race&lt;/h2&gt;
&lt;p&gt;For context, GPT-5.3-Codex-Spark’s 1,000 tokens per second represents a fairly dramatic leap over anything OpenAI has previously served through its own infrastructure. According to independent benchmarks from Artificial Analysis, OpenAI’s fastest models on Nvidia hardware top out well below that mark: GPT-4o delivers roughly 147 tokens per second, o3-mini hits about 167, and GPT-4o mini clocks around 52.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But 1,000 tokens per second is actually modest by Cerebras standards. The company has measured 2,100 tokens per second on Llama 3.1 70B and reported 3,000 tokens per second on OpenAI’s own open-weight gpt-oss-120B model, suggesting that Codex-Spark’s comparatively lower speed reflects the overhead of a larger or more complex model.&lt;/p&gt;
&lt;p&gt;AI coding agents have had a breakout year, with tools like OpenAI’s Codex and Anthropic’s Claude Code reaching a new level of usefulness for rapidly building prototypes, interfaces, and boilerplate code. OpenAI, Google, and Anthropic have all been racing to ship more capable coding agents, and latency has become what separates the winners; a model that codes faster lets a developer iterate faster.&lt;/p&gt;
&lt;p&gt;With fierce competition from Anthropic, OpenAI has been iterating on its Codex line at a rapid rate, releasing GPT-5.2 in December after CEO Sam Altman issued an internal “code red” memo about competitive pressure from Google, then shipping GPT-5.3-Codex just days ago.&lt;/p&gt;
&lt;h2&gt;Diversifying away from Nvidia&lt;/h2&gt;
&lt;p&gt;Spark’s deeper hardware story may be more consequential than its benchmark scores. The model runs on Cerebras’ Wafer Scale Engine 3, a chip the size of a dinner plate that Cerebras has built its business around since at least 2022. OpenAI and Cerebras announced their partnership in January, and Codex-Spark is the first product to come out of it.&lt;/p&gt;
&lt;p&gt;OpenAI has spent the past year systematically reducing its dependence on Nvidia. The company signed a massive multi-year deal with AMD in October 2025, struck a $38 billion cloud computing agreement with Amazon in November, and has been designing its own custom AI chip for eventual fabrication by TSMC.&lt;/p&gt;
&lt;p&gt;Meanwhile, a planned $100 billion infrastructure deal with Nvidia has fizzled so far, though Nvidia has since committed to a $20 billion investment. Reuters reported that OpenAI grew unsatisfied with the speed of some Nvidia chips for inference tasks, which is exactly the kind of workload that OpenAI designed Codex-Spark for.&lt;/p&gt;
&lt;p&gt;Regardless of which chip is under the hood, speed matters, though it may come at the cost of accuracy. For developers who spend their days inside a code editor waiting for AI suggestions, 1,000 tokens per second may feel less like carefully piloting a jigsaw and more like running a rip saw. Just watch what you’re cutting.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI’s new GPT‑5.3‑Codex‑Spark is 15 times faster at coding than its predecessor.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A man using a metal grinder causing sparks to fly." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2225076517_resize-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A man using a metal grinder causing sparks to fly." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2225076517_resize-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Teera Konakan / Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Thursday, OpenAI released its first production AI model to run on non-Nvidia hardware, deploying the new GPT-5.3-Codex-Spark coding model on chips from Cerebras. The model delivers code at more than 1,000 tokens (chunks of data) per second, which is reported to be roughly 15 times faster than its predecessor. To compare, Anthropic’s Claude Opus 4.6 in its new premium-priced fast mode reaches about 2.5 times its standard speed of 68.2 tokens per second, although it is a larger and more capable model than Spark.&lt;/p&gt;
&lt;p&gt;“Cerebras has been a great engineering partner, and we’re excited about adding fast inference as a new platform capability,” Sachin Katti, head of compute at OpenAI, said in a statement.&lt;/p&gt;
&lt;p&gt;Codex-Spark is a research preview available to ChatGPT Pro subscribers ($200/month) through the Codex app, command-line interface, and VS Code extension. OpenAI is rolling out API access to select design partners. The model ships with a 128,000-token context window and handles text only at launch.&lt;/p&gt;
&lt;p&gt;The release builds on the full GPT-5.3-Codex model that OpenAI launched earlier this month. Where the full model handles heavyweight agentic coding tasks, OpenAI tuned Spark for speed over depth of knowledge.&amp;nbsp; OpenAI built it as a text-only model and tuned it specifically for coding, not for the general-purpose tasks that the larger version of GPT-5.3 handles.&lt;/p&gt;
&lt;p&gt;On SWE-Bench Pro and Terminal-Bench 2.0, two benchmarks for evaluating software engineering ability, Spark reportedly outperforms the older GPT-5.1-Codex-mini while completing tasks in a fraction of the time, according to OpenAI. The company did not share independent validation of those numbers.&lt;/p&gt;
&lt;p&gt;Anecdotally, Codex’s speed has been a sore spot; when Ars tested four AI coding agents building &lt;em&gt;Minesweeper&lt;/em&gt; clones in December, Codex took roughly twice as long as Anthropic’s Claude Code to produce a working game.&lt;/p&gt;
&lt;h2&gt;The coding agent arms race&lt;/h2&gt;
&lt;p&gt;For context, GPT-5.3-Codex-Spark’s 1,000 tokens per second represents a fairly dramatic leap over anything OpenAI has previously served through its own infrastructure. According to independent benchmarks from Artificial Analysis, OpenAI’s fastest models on Nvidia hardware top out well below that mark: GPT-4o delivers roughly 147 tokens per second, o3-mini hits about 167, and GPT-4o mini clocks around 52.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But 1,000 tokens per second is actually modest by Cerebras standards. The company has measured 2,100 tokens per second on Llama 3.1 70B and reported 3,000 tokens per second on OpenAI’s own open-weight gpt-oss-120B model, suggesting that Codex-Spark’s comparatively lower speed reflects the overhead of a larger or more complex model.&lt;/p&gt;
&lt;p&gt;AI coding agents have had a breakout year, with tools like OpenAI’s Codex and Anthropic’s Claude Code reaching a new level of usefulness for rapidly building prototypes, interfaces, and boilerplate code. OpenAI, Google, and Anthropic have all been racing to ship more capable coding agents, and latency has become what separates the winners; a model that codes faster lets a developer iterate faster.&lt;/p&gt;
&lt;p&gt;With fierce competition from Anthropic, OpenAI has been iterating on its Codex line at a rapid rate, releasing GPT-5.2 in December after CEO Sam Altman issued an internal “code red” memo about competitive pressure from Google, then shipping GPT-5.3-Codex just days ago.&lt;/p&gt;
&lt;h2&gt;Diversifying away from Nvidia&lt;/h2&gt;
&lt;p&gt;Spark’s deeper hardware story may be more consequential than its benchmark scores. The model runs on Cerebras’ Wafer Scale Engine 3, a chip the size of a dinner plate that Cerebras has built its business around since at least 2022. OpenAI and Cerebras announced their partnership in January, and Codex-Spark is the first product to come out of it.&lt;/p&gt;
&lt;p&gt;OpenAI has spent the past year systematically reducing its dependence on Nvidia. The company signed a massive multi-year deal with AMD in October 2025, struck a $38 billion cloud computing agreement with Amazon in November, and has been designing its own custom AI chip for eventual fabrication by TSMC.&lt;/p&gt;
&lt;p&gt;Meanwhile, a planned $100 billion infrastructure deal with Nvidia has fizzled so far, though Nvidia has since committed to a $20 billion investment. Reuters reported that OpenAI grew unsatisfied with the speed of some Nvidia chips for inference tasks, which is exactly the kind of workload that OpenAI designed Codex-Spark for.&lt;/p&gt;
&lt;p&gt;Regardless of which chip is under the hood, speed matters, though it may come at the cost of accuracy. For developers who spend their days inside a code editor waiting for AI suggestions, 1,000 tokens per second may feel less like carefully piloting a jigsaw and more like running a rip saw. Just watch what you’re cutting.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/</guid><pubDate>Thu, 12 Feb 2026 22:56:02 +0000</pubDate></item><item><title>IBM will hire your entry-level talent in the age of AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/04/GettyImages-1254279163.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While the artificial intelligence industry touts that AI will replace entry-level jobs, not every company is scaling back hiring these positions. In IBM’s case, it’s going all in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hardware giant IBM plans to triple entry-level hiring in the U.S. in 2026, according to reporting from Bloomberg. Nickle LaMoreaux, IBM’s chief human resource officer, announced the initiative at Charter’s Leading with AI Summit on Tuesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“And yes, it’s for all these jobs that we’re being told AI can do,” LaMoreaux said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These jobs will look different than the entry-level jobs IBM used to offer, she explained. According to LaMoreaux, she went through and changed the descriptions for these entry-level jobs so they were less focused on areas AI can actually automate — like coding — and more focused on people-forward areas like engaging with customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This strategy makes sense. Even if an enterprise like IBM doesn’t necessarily need the same amount of entry-level talent that it did before, fostering less experienced workers helps ensure these employees have the skills needed for the higher-level roles down the road.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;IBM didn’t specify how many people they would be hiring in this initiative. TechCrunch reached out to IBM for more information on the hiring plans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year could be a pivotal one regarding what the impact of AI on the hiring market will look like. An MIT study in 2025 estimated that 11.7% of jobs could likely already be automated by AI. A TechCrunch survey found that multiple investors think 2026 will start to show AI’s potential impact on the labor market — despite not being asked about labor specifically.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/04/GettyImages-1254279163.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;While the artificial intelligence industry touts that AI will replace entry-level jobs, not every company is scaling back hiring these positions. In IBM’s case, it’s going all in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hardware giant IBM plans to triple entry-level hiring in the U.S. in 2026, according to reporting from Bloomberg. Nickle LaMoreaux, IBM’s chief human resource officer, announced the initiative at Charter’s Leading with AI Summit on Tuesday.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“And yes, it’s for all these jobs that we’re being told AI can do,” LaMoreaux said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These jobs will look different than the entry-level jobs IBM used to offer, she explained. According to LaMoreaux, she went through and changed the descriptions for these entry-level jobs so they were less focused on areas AI can actually automate — like coding — and more focused on people-forward areas like engaging with customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This strategy makes sense. Even if an enterprise like IBM doesn’t necessarily need the same amount of entry-level talent that it did before, fostering less experienced workers helps ensure these employees have the skills needed for the higher-level roles down the road.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;IBM didn’t specify how many people they would be hiring in this initiative. TechCrunch reached out to IBM for more information on the hiring plans.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This year could be a pivotal one regarding what the impact of AI on the hiring market will look like. An MIT study in 2025 estimated that 11.7% of jobs could likely already be automated by AI. A TechCrunch survey found that multiple investors think 2026 will start to show AI’s potential impact on the labor market — despite not being asked about labor specifically.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/</guid><pubDate>Thu, 12 Feb 2026 23:23:17 +0000</pubDate></item><item><title>Amid disappointing earnings, Pinterest claims it sees more searches than ChatGPT (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/pinterest-header.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a particularly poor performance on its fourth-quarter earnings, Pinterest CEO Bill Ready attempted to favorably compare the digital pinboarding site to the popular AI chatbot ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trying to highlight its potential as a unique search destination, Ready asserted that the site sees larger search volume than ChatGPT. According to third-party data, ChatGPT sees 75 billion searches per month, while Pinterest sees 80 billion searches and generates 1.7 billion monthly clicks, he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“That makes us one of the largest search destinations in the world. And importantly, more than half of those searches are commercial in nature, compared to, I think . . . approximately 2% [of ChatGPT searches],” Ready added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pinterest in the fourth quarter missed expectations on both revenue and earnings per share, reporting $1.32 billion in revenue versus $1.33 billion expected, and earnings per share of 67 cents, compared to the 69 cents projected. It also forecast that first-quarter 2026 sales will come in between $951 million to $971 million, below the $980 million expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company blamed its shortfall on larger advertisers pulling back on spend, particularly in Europe, and a new furniture tariff implemented in October that caused issues within the home category. It said those trends could worsen in the first quarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surprisingly, Pinterest missed on earnings despite a user base that’s growing faster than expected. The company reported monthly active users were up 12% year-over-year to 619 million, when Wall Street had forecast 613 million users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shares dropped 20% in after-hours trading.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Pinterest has long struggled to translate the high usage of its platform into ad dollars, as its users often go to Pinterest to plan and dream, not shop and buy. That challenge could become even more acute in the AI era, especially if advertisers shift their dollars to platforms where intent to buy is clearer — such as chatbot requests that ask for product recommendations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked about how Pinterest will navigate the shift toward AI-powered shopping, Ready pointed to the company’s visual search, discovery, and personalization features, which he said would point users to relevant products when they open the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re helping them complete those commercial journeys without having to type in a single prompt,” he said, also noting that Pinterest had benefited from an easier checkout flow that came from its partnership with Amazon. He said customers didn’t yet seem ready to allow an AI to make a purchase on their behalf, but said Pinterest would be ready if that time came.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“That’ll actually be one of the easiest parts of the commercial journey to solve,” he claimed. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/pinterest-header.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After a particularly poor performance on its fourth-quarter earnings, Pinterest CEO Bill Ready attempted to favorably compare the digital pinboarding site to the popular AI chatbot ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Trying to highlight its potential as a unique search destination, Ready asserted that the site sees larger search volume than ChatGPT. According to third-party data, ChatGPT sees 75 billion searches per month, while Pinterest sees 80 billion searches and generates 1.7 billion monthly clicks, he said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“That makes us one of the largest search destinations in the world. And importantly, more than half of those searches are commercial in nature, compared to, I think . . . approximately 2% [of ChatGPT searches],” Ready added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Pinterest in the fourth quarter missed expectations on both revenue and earnings per share, reporting $1.32 billion in revenue versus $1.33 billion expected, and earnings per share of 67 cents, compared to the 69 cents projected. It also forecast that first-quarter 2026 sales will come in between $951 million to $971 million, below the $980 million expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company blamed its shortfall on larger advertisers pulling back on spend, particularly in Europe, and a new furniture tariff implemented in October that caused issues within the home category. It said those trends could worsen in the first quarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Surprisingly, Pinterest missed on earnings despite a user base that’s growing faster than expected. The company reported monthly active users were up 12% year-over-year to 619 million, when Wall Street had forecast 613 million users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shares dropped 20% in after-hours trading.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Pinterest has long struggled to translate the high usage of its platform into ad dollars, as its users often go to Pinterest to plan and dream, not shop and buy. That challenge could become even more acute in the AI era, especially if advertisers shift their dollars to platforms where intent to buy is clearer — such as chatbot requests that ask for product recommendations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked about how Pinterest will navigate the shift toward AI-powered shopping, Ready pointed to the company’s visual search, discovery, and personalization features, which he said would point users to relevant products when they open the app.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re helping them complete those commercial journeys without having to type in a single prompt,” he said, also noting that Pinterest had benefited from an easier checkout flow that came from its partnership with Amazon. He said customers didn’t yet seem ready to allow an AI to make a purchase on their behalf, but said Pinterest would be ready if that time came.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“That’ll actually be one of the easiest parts of the commercial journey to solve,” he claimed. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/</guid><pubDate>Thu, 12 Feb 2026 23:26:56 +0000</pubDate></item><item><title>New J-PAL research and policy initiative to test and scale AI innovations to fight poverty (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/new-j-pal-research-policy-initiative-to-test-scale-ai-innovations-fight-poverty-0212</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/mit-j-pal-letrus.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The Abdul Latif Jameel Poverty Action Lab (J-PAL) at MIT has awarded funding to eight new research studies to understand how artificial intelligence innovations can be used in the fight against poverty through its new Project AI Evidence.&lt;/p&gt;&lt;p&gt;The age of AI has brought wide-ranging optimism and skepticism about its effects on society. To realize AI’s full potential, Project AI Evidence (PAIE) will identify which AI solutions work and for whom, and scale only the most effective, inclusive, and responsible solutions — while scaling down those that may potentially cause harm.&lt;/p&gt;&lt;p&gt;PAIE will generate evidence on what works by connecting governments, tech companies, and nonprofits with world-class economists at MIT and across J-PAL’s global network to evaluate and improve AI solutions to entrenched social challenges.&lt;/p&gt;&lt;p&gt;The new initiative is prioritizing questions policymakers are already asking: Do AI-assisted teaching tools help all children learn? How can early-warning flood systems help people affected by natural disasters? Can machine learning algorithms help reduce deforestation in the Amazon? Can AI-powered chatbots help improve people’s health? In the coming years, PAIE will run a series of funding competitions to invite proposals for evaluations of AI tools that address questions like these, and many more.&lt;/p&gt;&lt;p&gt;PAIE is financially supported by a grant from Google.org, philanthropic support from Community Jameel, a grant from Canada’s International Development Research Centre and UK International Development, and a collaboration agreement with Amazon Web Services. Through a grant from Eric and Wendy Schmidt, awarded by recommendation of Schmidt Sciences, the initiative will also study generative AI in the workplace, particularly in low- and middle-income countries.&lt;/p&gt;&lt;p&gt;Alex Diaz, head of AI for social good at Google.org, says, “we’re thrilled to collaborate with MIT and J-PAL, already leaders in this space, on Project AI Evidence. AI has great potential to benefit all people, but we urgently need to study what works, what doesn’t, and why, if we are to realize this potential.”&lt;/p&gt;&lt;p&gt;“Artificial intelligence holds extraordinary potential, but only if the tools, knowledge, and power to shape it are accessible to all — that includes contextually grounded research and evidence on what works and what does not,” adds Maggie Gorman-Velez, vice president of strategy, regions, and policies at IDRC. “That is why IDRC is proud to be supporting this new evaluation work as part of our ongoing commitment to the responsible scaling of proven safe, inclusive, and locally relevant AI innovations.”&lt;/p&gt;&lt;p&gt;J-PAL is uniquely positioned to help understand AI’s effects on society: Since its inception in 2003, J-PAL’s network of researchers has led over 2,500 rigorous evaluations of social policies and programs around the world. Through PAIE, J-PAL will bring together leading experts in AI technology, research, and social policy, in alignment with MIT president Sally Kornbluth’s focus on generative AI as a strategic priority.&lt;/p&gt;&lt;p&gt;PAIE is chaired by Professor Joshua Blumenstock of the University of California at Berkeley; J-PAL Global Executive Director Iqbal Dhaliwal; and Professor David Yanagizawa-Drott of the University of Zurich.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;New evaluations of urgent policy questions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The studies funded in PAIE’s first round of competition explore urgent questions in key sectors like education, health, climate, and economic opportunity.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How can AI be most effective in classrooms, helping both students and teachers?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Existing research shows that personalized learning is important for students, but challenging to implement with limited resources. In Kenya, education social enterprise EIDU has developed an AI tool that helps teachers identify learning gaps and adapt their daily lesson plans. In India, the nongovernmental organization (NGO) Pratham is developing an AI tool to increase the impact and scale of the evidence-informed Teaching at the Right Level approach. J-PAL researchers Daron Acemoglu, Iqbal Dhaliwal, and Francisco Gallego will work with both organizations to study the effects and potential of these different use cases on teachers’ productivity and students’ learning.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Can AI tools reduce gender bias in schools?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Researchers are collaborating with Italy’s Ministry of Education to evaluate whether AI tools can help close gender gaps in students’ performance by addressing teachers’ unconscious biases. J-PAL affiliates Michela Carlana and Will Dobbie, along with Francesca Miserocchi and Eleonora Patacchini, will study the impacts of two AI tools, one that helps teachers predict performance and a second that gives real-time feedback on the diversity of their decisions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Can AI help career counselors uncover more job opportunities?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In Kenya, researchers are evaluating if an AI tool can identify overlooked skills and unlock employment opportunities, particularly for youth, women, and those without formal education. In collaboration with NGOs Swahilipot and Tabiya, Jasmin Baier and J-PAL researcher Christian Meyer will evaluate how the tool changes people’s job search strategies and employment. This study will shed light on AI as a complement, rather than a substitute, for human expertise in career guidance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Looking forward&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As use of AI in the social sector evolves, these evaluations are a first step in discovering effective, responsible solutions that will go the furthest in alleviating poverty and inequality.&lt;/p&gt;&lt;p&gt;J-PAL’s Dhaliwal notes, “J-PAL has a long history of evaluating innovative technology and its ability to improve people’s lives. While AI has incredible potential, we need to maximize its benefits and minimize possible harms. We’re grateful to our donors, sponsors, and collaborators for their catalytic support in launching PAIE, which will help us do exactly that by continuing to expand evidence on the impacts of AI innovations.”&lt;/p&gt;&lt;p&gt;J-PAL is also seeking new collaborators who share its vision of discovering and scaling up real-world AI solutions. It aims to support more governments and social sector organizations that want to adopt AI responsibly, and will continue to expand funding for new evaluations and provide policy guidance based on the latest research.&lt;/p&gt;&lt;p&gt;To learn more about Project AI Evidence, subscribe to J-PAL's newsletter or contact paie@povertyactionlab.org.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/mit-j-pal-letrus.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;The Abdul Latif Jameel Poverty Action Lab (J-PAL) at MIT has awarded funding to eight new research studies to understand how artificial intelligence innovations can be used in the fight against poverty through its new Project AI Evidence.&lt;/p&gt;&lt;p&gt;The age of AI has brought wide-ranging optimism and skepticism about its effects on society. To realize AI’s full potential, Project AI Evidence (PAIE) will identify which AI solutions work and for whom, and scale only the most effective, inclusive, and responsible solutions — while scaling down those that may potentially cause harm.&lt;/p&gt;&lt;p&gt;PAIE will generate evidence on what works by connecting governments, tech companies, and nonprofits with world-class economists at MIT and across J-PAL’s global network to evaluate and improve AI solutions to entrenched social challenges.&lt;/p&gt;&lt;p&gt;The new initiative is prioritizing questions policymakers are already asking: Do AI-assisted teaching tools help all children learn? How can early-warning flood systems help people affected by natural disasters? Can machine learning algorithms help reduce deforestation in the Amazon? Can AI-powered chatbots help improve people’s health? In the coming years, PAIE will run a series of funding competitions to invite proposals for evaluations of AI tools that address questions like these, and many more.&lt;/p&gt;&lt;p&gt;PAIE is financially supported by a grant from Google.org, philanthropic support from Community Jameel, a grant from Canada’s International Development Research Centre and UK International Development, and a collaboration agreement with Amazon Web Services. Through a grant from Eric and Wendy Schmidt, awarded by recommendation of Schmidt Sciences, the initiative will also study generative AI in the workplace, particularly in low- and middle-income countries.&lt;/p&gt;&lt;p&gt;Alex Diaz, head of AI for social good at Google.org, says, “we’re thrilled to collaborate with MIT and J-PAL, already leaders in this space, on Project AI Evidence. AI has great potential to benefit all people, but we urgently need to study what works, what doesn’t, and why, if we are to realize this potential.”&lt;/p&gt;&lt;p&gt;“Artificial intelligence holds extraordinary potential, but only if the tools, knowledge, and power to shape it are accessible to all — that includes contextually grounded research and evidence on what works and what does not,” adds Maggie Gorman-Velez, vice president of strategy, regions, and policies at IDRC. “That is why IDRC is proud to be supporting this new evaluation work as part of our ongoing commitment to the responsible scaling of proven safe, inclusive, and locally relevant AI innovations.”&lt;/p&gt;&lt;p&gt;J-PAL is uniquely positioned to help understand AI’s effects on society: Since its inception in 2003, J-PAL’s network of researchers has led over 2,500 rigorous evaluations of social policies and programs around the world. Through PAIE, J-PAL will bring together leading experts in AI technology, research, and social policy, in alignment with MIT president Sally Kornbluth’s focus on generative AI as a strategic priority.&lt;/p&gt;&lt;p&gt;PAIE is chaired by Professor Joshua Blumenstock of the University of California at Berkeley; J-PAL Global Executive Director Iqbal Dhaliwal; and Professor David Yanagizawa-Drott of the University of Zurich.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;New evaluations of urgent policy questions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The studies funded in PAIE’s first round of competition explore urgent questions in key sectors like education, health, climate, and economic opportunity.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;How can AI be most effective in classrooms, helping both students and teachers?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Existing research shows that personalized learning is important for students, but challenging to implement with limited resources. In Kenya, education social enterprise EIDU has developed an AI tool that helps teachers identify learning gaps and adapt their daily lesson plans. In India, the nongovernmental organization (NGO) Pratham is developing an AI tool to increase the impact and scale of the evidence-informed Teaching at the Right Level approach. J-PAL researchers Daron Acemoglu, Iqbal Dhaliwal, and Francisco Gallego will work with both organizations to study the effects and potential of these different use cases on teachers’ productivity and students’ learning.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Can AI tools reduce gender bias in schools?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Researchers are collaborating with Italy’s Ministry of Education to evaluate whether AI tools can help close gender gaps in students’ performance by addressing teachers’ unconscious biases. J-PAL affiliates Michela Carlana and Will Dobbie, along with Francesca Miserocchi and Eleonora Patacchini, will study the impacts of two AI tools, one that helps teachers predict performance and a second that gives real-time feedback on the diversity of their decisions.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Can AI help career counselors uncover more job opportunities?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In Kenya, researchers are evaluating if an AI tool can identify overlooked skills and unlock employment opportunities, particularly for youth, women, and those without formal education. In collaboration with NGOs Swahilipot and Tabiya, Jasmin Baier and J-PAL researcher Christian Meyer will evaluate how the tool changes people’s job search strategies and employment. This study will shed light on AI as a complement, rather than a substitute, for human expertise in career guidance.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Looking forward&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;As use of AI in the social sector evolves, these evaluations are a first step in discovering effective, responsible solutions that will go the furthest in alleviating poverty and inequality.&lt;/p&gt;&lt;p&gt;J-PAL’s Dhaliwal notes, “J-PAL has a long history of evaluating innovative technology and its ability to improve people’s lives. While AI has incredible potential, we need to maximize its benefits and minimize possible harms. We’re grateful to our donors, sponsors, and collaborators for their catalytic support in launching PAIE, which will help us do exactly that by continuing to expand evidence on the impacts of AI innovations.”&lt;/p&gt;&lt;p&gt;J-PAL is also seeking new collaborators who share its vision of discovering and scaling up real-world AI solutions. It aims to support more governments and social sector organizations that want to adopt AI responsibly, and will continue to expand funding for new evaluations and provide policy guidance based on the latest research.&lt;/p&gt;&lt;p&gt;To learn more about Project AI Evidence, subscribe to J-PAL's newsletter or contact paie@povertyactionlab.org.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/new-j-pal-research-policy-initiative-to-test-scale-ai-innovations-fight-poverty-0212</guid><pubDate>Thu, 12 Feb 2026 23:50:00 +0000</pubDate></item></channel></rss>