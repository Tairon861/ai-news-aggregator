<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 23 Aug 2025 01:40:07 +0000</lastBuildDate><item><title>Huawei Cloud’s broad, open approach wins it Gartner honours (AI News)</title><link>https://www.artificialintelligence-news.com/news/huawei-clouds-open-approach-wins-it-gartner-honours-magic-quadrant-2025-for-container-management/</link><description>&lt;p&gt;The big three cloud providers tend to snap up the majority of hosting honours for containerised workflows. Google, AWS, and Microsoft are the &lt;em&gt;de facto&lt;/em&gt; hosting providers, as you might expect, with Red Hat, Alibaba, and SUSE comprising the other household names in the microservices space.&lt;/p&gt;&lt;p&gt;But the latest Gartner Magic Quadrant for Container Management 2025 positions Huawei in the Leaders quadrant for the first time. Huawei Cloud is a company that’s quietly making inroads into enterprise mindsets all over the world, and innovating – especially with AI-related workloads – despite the best efforts of the current US government to stymie global competition in the space.&lt;/p&gt;&lt;p&gt;Huawei Cloud scored the highest global customer recognition score (4.7) of the companies in Gartner’s paper, beating fellow Chinese behemoths Tencent and Alibaba, plus the ‘big three’ of AWS, Google GCP and Microsoft Azure.&lt;/p&gt;&lt;p&gt;According to Gartner, Huawei Cloud offers the most complete container product matrix in the cloud industry, where its platforms can be found in public, distributed, and hybrid clouds, and edge environments.&lt;/p&gt;&lt;p&gt;The company’s big wins in terms of clients and users get little coverage in the US and Europe, but it’s proving an effective provider for companies like media service Starzplay (which streamed the 2024 Cricket World Cup across the Middle East and Central Asia) and logistics giant Ninja Van in Singapore.&lt;/p&gt;&lt;p&gt;South America and Africa, too, have been the scene of several successes for the Chinese company, notably Nigeria’s e-commerce platform Konga, which uses a cloud native architecture based on Huawei Cloud’s CCT Turbo, and major power utility Chilquina Energia in Chile. The latter organisation speaks of a 90% average performance improvement across its stack.&lt;/p&gt;&lt;p&gt;The Linux Foundation’s CNCF (cloud-native computing foundation) steers an open and interoperable approach to all elements of cloud computing, and Huawei is the only Chinese cloud provider with a vice-chair position on the organisation’s Technical Oversight Committee. The company also maintains more than 20 project maintainer seats at the CNCF. It’s also an active donor to projects under the CNCF’s oversight, including KubeEdge, Karmada, and Kuasar.&lt;/p&gt;&lt;p&gt;Huawei’s offerings include container products like CCE Turbo, CCE Autopilot, the distributed cloud-native service UCS, and its Cloud Container Instance (CCI). CCE AI clusters form the infrastructure for CloudMatrix384 supernodes, which deliver 300 petaflops of processing grunt and outperform the Nvidia NVL72.&lt;/p&gt;&lt;p&gt;Despite being regarded with some suspicion by large enterprises in the West – it’s Chinese origins creating an automatic xenophobic distrust – Huawei continues to innovate in the AI and microservices spaces despite, or perhaps because of, continued economic, trade, and rhetorical pressure applied by the current US administration.&lt;/p&gt;&lt;p&gt;AI market watchers will be aware of Huawei’s Pangu models that come pre-configured with directed learning &lt;em&gt;corpora&lt;/em&gt; for specific industries, including utilities, media, engineering, and telecoms.&lt;/p&gt;&lt;p&gt;Huawei Cloud is available in 34 geographical regions, with 101 AZs (availability zones). Huawei’s AI Cloud Services provide AI compute for over 1,300 customers, the company says, including well-known brands around the world, public sector organisations, and academic institutions.&lt;/p&gt;&lt;p&gt;The commitment by Huawei, Huawei Cloud and other Chinese providers such as DeepMind to the development of models in the open are at odds with the approach of Western companies, where proprietary technology and advances are closely-guarded secrets.&lt;/p&gt;&lt;p&gt;Huawei Cloud’s leadership of open-source projects KubeEdge and Volcano show a commitment to a broad range of open-source projects that widen the company’s ability and scope in AI and containers, something that’s reflected by Gartner’s findings.&lt;/p&gt;&lt;p&gt;The company’s ability to provide supporting technologies related and adjacent to container management, (AI silicon, security, etc.) helped position the company in the Leaders section of the latest Gartner paper.&lt;/p&gt;&lt;p&gt;The full Gartner Peer Insights Magic Quadrant for Container Management 2025 is available to read here.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image based on “Clouds” by CSLmedia Productions and is licensed under CC BY-NC-SA 2.0.&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The big three cloud providers tend to snap up the majority of hosting honours for containerised workflows. Google, AWS, and Microsoft are the &lt;em&gt;de facto&lt;/em&gt; hosting providers, as you might expect, with Red Hat, Alibaba, and SUSE comprising the other household names in the microservices space.&lt;/p&gt;&lt;p&gt;But the latest Gartner Magic Quadrant for Container Management 2025 positions Huawei in the Leaders quadrant for the first time. Huawei Cloud is a company that’s quietly making inroads into enterprise mindsets all over the world, and innovating – especially with AI-related workloads – despite the best efforts of the current US government to stymie global competition in the space.&lt;/p&gt;&lt;p&gt;Huawei Cloud scored the highest global customer recognition score (4.7) of the companies in Gartner’s paper, beating fellow Chinese behemoths Tencent and Alibaba, plus the ‘big three’ of AWS, Google GCP and Microsoft Azure.&lt;/p&gt;&lt;p&gt;According to Gartner, Huawei Cloud offers the most complete container product matrix in the cloud industry, where its platforms can be found in public, distributed, and hybrid clouds, and edge environments.&lt;/p&gt;&lt;p&gt;The company’s big wins in terms of clients and users get little coverage in the US and Europe, but it’s proving an effective provider for companies like media service Starzplay (which streamed the 2024 Cricket World Cup across the Middle East and Central Asia) and logistics giant Ninja Van in Singapore.&lt;/p&gt;&lt;p&gt;South America and Africa, too, have been the scene of several successes for the Chinese company, notably Nigeria’s e-commerce platform Konga, which uses a cloud native architecture based on Huawei Cloud’s CCT Turbo, and major power utility Chilquina Energia in Chile. The latter organisation speaks of a 90% average performance improvement across its stack.&lt;/p&gt;&lt;p&gt;The Linux Foundation’s CNCF (cloud-native computing foundation) steers an open and interoperable approach to all elements of cloud computing, and Huawei is the only Chinese cloud provider with a vice-chair position on the organisation’s Technical Oversight Committee. The company also maintains more than 20 project maintainer seats at the CNCF. It’s also an active donor to projects under the CNCF’s oversight, including KubeEdge, Karmada, and Kuasar.&lt;/p&gt;&lt;p&gt;Huawei’s offerings include container products like CCE Turbo, CCE Autopilot, the distributed cloud-native service UCS, and its Cloud Container Instance (CCI). CCE AI clusters form the infrastructure for CloudMatrix384 supernodes, which deliver 300 petaflops of processing grunt and outperform the Nvidia NVL72.&lt;/p&gt;&lt;p&gt;Despite being regarded with some suspicion by large enterprises in the West – it’s Chinese origins creating an automatic xenophobic distrust – Huawei continues to innovate in the AI and microservices spaces despite, or perhaps because of, continued economic, trade, and rhetorical pressure applied by the current US administration.&lt;/p&gt;&lt;p&gt;AI market watchers will be aware of Huawei’s Pangu models that come pre-configured with directed learning &lt;em&gt;corpora&lt;/em&gt; for specific industries, including utilities, media, engineering, and telecoms.&lt;/p&gt;&lt;p&gt;Huawei Cloud is available in 34 geographical regions, with 101 AZs (availability zones). Huawei’s AI Cloud Services provide AI compute for over 1,300 customers, the company says, including well-known brands around the world, public sector organisations, and academic institutions.&lt;/p&gt;&lt;p&gt;The commitment by Huawei, Huawei Cloud and other Chinese providers such as DeepMind to the development of models in the open are at odds with the approach of Western companies, where proprietary technology and advances are closely-guarded secrets.&lt;/p&gt;&lt;p&gt;Huawei Cloud’s leadership of open-source projects KubeEdge and Volcano show a commitment to a broad range of open-source projects that widen the company’s ability and scope in AI and containers, something that’s reflected by Gartner’s findings.&lt;/p&gt;&lt;p&gt;The company’s ability to provide supporting technologies related and adjacent to container management, (AI silicon, security, etc.) helped position the company in the Leaders section of the latest Gartner paper.&lt;/p&gt;&lt;p&gt;The full Gartner Peer Insights Magic Quadrant for Container Management 2025 is available to read here.&lt;/p&gt;&lt;p&gt;&lt;em&gt;(Image based on “Clouds” by CSLmedia Productions and is licensed under CC BY-NC-SA 2.0.&lt;/em&gt;)&lt;/p&gt;&lt;p&gt;&lt;img src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" /&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/huawei-clouds-open-approach-wins-it-gartner-honours-magic-quadrant-2025-for-container-management/</guid><pubDate>Fri, 22 Aug 2025 14:21:33 +0000</pubDate></item><item><title>Rachel James, AbbVie: Harnessing AI for corporate cybersecurity (AI News)</title><link>https://www.artificialintelligence-news.com/news/rachel-james-abbvie-harnessing-ai-for-corporate-cybersecurity/</link><description>&lt;p&gt;Cybersecurity is in the midst of a fresh arms race, and the powerful weapon of choice in this new era is AI.&lt;/p&gt;&lt;p&gt;AI offers a classic double-edged sword: a powerful shield for defenders and a potent new tool for those with malicious intent. Navigating this complex battleground requires a steady hand and a deep understanding of both the technology and the people who would abuse it.&lt;/p&gt;&lt;p&gt;To get a view from the front lines, AI News caught up with Rachel James, Principal AI ML Threat Intelligence Engineer at global biopharmaceutical company AbbVie.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full is-resized"&gt;&lt;img alt="Headshot of Rachel James, Principal AI ML Threat Intelligence Engineer at global biopharmaceutical company AbbVie, for an article on business cybersecurity in this new era." class="wp-image-109101" height="599" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/rachel-james-ai-cybersecurity-abbvie-big-data-expo-security.jpeg" width="599" /&gt;&lt;/figure&gt;&lt;p&gt;“In addition to the built in AI augmentation that has been vendor-provided in our current tools, we also use LLM analysis on our detections, observations, correlations and associated rules,” James explains.&lt;/p&gt;&lt;p&gt;James and her team are using large language models to sift through a mountain of security alerts, looking for patterns, spotting duplicates, and finding dangerous gaps in their defences before an attacker can.&lt;/p&gt;&lt;p&gt;“We use this to determine similarity, duplication and provide gap analysis,” she adds, noting that the next step is to weave in even more external threat data. “We are looking to enhance this with the integration of threat intelligence in our next phase.”&lt;/p&gt;&lt;p&gt;Central to this operation is a specialised threat intelligence platform called OpenCTI, which helps them build a unified picture of threats from a sea of digital noise.&lt;/p&gt;&lt;p&gt;AI is the engine that makes this cybersecurity effort possible, taking vast quantities of jumbled, unstructured text and neatly organising it into a standard format known as STIX. The grand vision, James says, is to use language models to connect this core intelligence with all other areas of their security operation, from vulnerability management to third-party risk.&lt;/p&gt;&lt;p&gt;Taking advantage of this power, however, comes with a healthy dose of caution. As a key contributor to a major industry initiative, James is acutely aware of the pitfalls.&lt;/p&gt;&lt;p&gt;“I would be remiss if I didn’t mention the work of a wonderful group of folks I am a part of – the ’OWASP Top 10 for GenAI’ as a foundational way of understanding vulnerabilities that GenAI can introduce,” she says.&lt;/p&gt;&lt;p&gt;Beyond specific vulnerabilities, James points at three fundamental trade-offs that business leaders must confront:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Accepting the risk that comes with the creative but often unpredictable nature of generative AI.&lt;/li&gt;&lt;li&gt;The loss of transparency in how AI reaches its conclusions, a problem that only grows as the models become more complex.&lt;/li&gt;&lt;li&gt;The danger of poorly judging the real return on investment for any AI project, where the hype can easily lead to overestimating the benefits or underestimating the effort required in such a fast-moving field.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;To build a better cybersecurity posture in the AI era, you have to understand your attacker. This is where James’ deep expertise comes into play.&lt;/p&gt;&lt;p&gt;“This is actually my particular expertise – I have a cyber threat intelligence background and have conducted and documented extensive research into threat actor’s interest, use, and development of AI,” she notes.&lt;/p&gt;&lt;p&gt;James actively tracks adversary chatter and tool development through open-source channels and her own automated collections from the dark web, sharing her findings on her cybershujin GitHub. Her work also involves getting her own hands dirty.&lt;/p&gt;&lt;p&gt;“As the lead for the Prompt Injection entry for OWASP, and co-author of the Guide to Red Teaming GenAI, I also spend time developing adversarial input techniques myself and maintain a network of experts also in this field,” James adds.&lt;/p&gt;&lt;p&gt;So, what does this all mean for the future of the industry? For James, the path forward is clear. She points to a fascinating parallel she discovered years ago: “The cyber threat intelligence lifecycle is almost identical to the data science lifecycle foundational to AI ML systems.”&lt;/p&gt;&lt;p&gt;This alignment is a massive opportunity. “Without a doubt, in terms of the datasets we can operate with, defenders have a unique chance to capitalise on the power of intelligence data sharing and AI,” she asserts.&lt;/p&gt;&lt;p&gt;Her final message offers both encouragement and a warning for her peers in the cybersecurity world: “Data science and AI will be a part of every cybersecurity professional’s life moving forward, embrace it.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Rachel James will be sharing her insights at this year’s &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Expo Europe&lt;/em&gt;&lt;em&gt; in Amsterdam on 24-25 September 2025. Be sure to check out her day two presentation on ‘From Principle to Practice – Embedding AI Ethics at Scale’.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google Cloud unveils AI ally for security teams&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Cybersecurity is in the midst of a fresh arms race, and the powerful weapon of choice in this new era is AI.&lt;/p&gt;&lt;p&gt;AI offers a classic double-edged sword: a powerful shield for defenders and a potent new tool for those with malicious intent. Navigating this complex battleground requires a steady hand and a deep understanding of both the technology and the people who would abuse it.&lt;/p&gt;&lt;p&gt;To get a view from the front lines, AI News caught up with Rachel James, Principal AI ML Threat Intelligence Engineer at global biopharmaceutical company AbbVie.&lt;/p&gt;&lt;figure class="wp-block-image alignleft size-full is-resized"&gt;&lt;img alt="Headshot of Rachel James, Principal AI ML Threat Intelligence Engineer at global biopharmaceutical company AbbVie, for an article on business cybersecurity in this new era." class="wp-image-109101" height="599" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/08/rachel-james-ai-cybersecurity-abbvie-big-data-expo-security.jpeg" width="599" /&gt;&lt;/figure&gt;&lt;p&gt;“In addition to the built in AI augmentation that has been vendor-provided in our current tools, we also use LLM analysis on our detections, observations, correlations and associated rules,” James explains.&lt;/p&gt;&lt;p&gt;James and her team are using large language models to sift through a mountain of security alerts, looking for patterns, spotting duplicates, and finding dangerous gaps in their defences before an attacker can.&lt;/p&gt;&lt;p&gt;“We use this to determine similarity, duplication and provide gap analysis,” she adds, noting that the next step is to weave in even more external threat data. “We are looking to enhance this with the integration of threat intelligence in our next phase.”&lt;/p&gt;&lt;p&gt;Central to this operation is a specialised threat intelligence platform called OpenCTI, which helps them build a unified picture of threats from a sea of digital noise.&lt;/p&gt;&lt;p&gt;AI is the engine that makes this cybersecurity effort possible, taking vast quantities of jumbled, unstructured text and neatly organising it into a standard format known as STIX. The grand vision, James says, is to use language models to connect this core intelligence with all other areas of their security operation, from vulnerability management to third-party risk.&lt;/p&gt;&lt;p&gt;Taking advantage of this power, however, comes with a healthy dose of caution. As a key contributor to a major industry initiative, James is acutely aware of the pitfalls.&lt;/p&gt;&lt;p&gt;“I would be remiss if I didn’t mention the work of a wonderful group of folks I am a part of – the ’OWASP Top 10 for GenAI’ as a foundational way of understanding vulnerabilities that GenAI can introduce,” she says.&lt;/p&gt;&lt;p&gt;Beyond specific vulnerabilities, James points at three fundamental trade-offs that business leaders must confront:&lt;/p&gt;&lt;ol class="wp-block-list"&gt;&lt;li&gt;Accepting the risk that comes with the creative but often unpredictable nature of generative AI.&lt;/li&gt;&lt;li&gt;The loss of transparency in how AI reaches its conclusions, a problem that only grows as the models become more complex.&lt;/li&gt;&lt;li&gt;The danger of poorly judging the real return on investment for any AI project, where the hype can easily lead to overestimating the benefits or underestimating the effort required in such a fast-moving field.&lt;/li&gt;&lt;/ol&gt;&lt;p&gt;To build a better cybersecurity posture in the AI era, you have to understand your attacker. This is where James’ deep expertise comes into play.&lt;/p&gt;&lt;p&gt;“This is actually my particular expertise – I have a cyber threat intelligence background and have conducted and documented extensive research into threat actor’s interest, use, and development of AI,” she notes.&lt;/p&gt;&lt;p&gt;James actively tracks adversary chatter and tool development through open-source channels and her own automated collections from the dark web, sharing her findings on her cybershujin GitHub. Her work also involves getting her own hands dirty.&lt;/p&gt;&lt;p&gt;“As the lead for the Prompt Injection entry for OWASP, and co-author of the Guide to Red Teaming GenAI, I also spend time developing adversarial input techniques myself and maintain a network of experts also in this field,” James adds.&lt;/p&gt;&lt;p&gt;So, what does this all mean for the future of the industry? For James, the path forward is clear. She points to a fascinating parallel she discovered years ago: “The cyber threat intelligence lifecycle is almost identical to the data science lifecycle foundational to AI ML systems.”&lt;/p&gt;&lt;p&gt;This alignment is a massive opportunity. “Without a doubt, in terms of the datasets we can operate with, defenders have a unique chance to capitalise on the power of intelligence data sharing and AI,” she asserts.&lt;/p&gt;&lt;p&gt;Her final message offers both encouragement and a warning for her peers in the cybersecurity world: “Data science and AI will be a part of every cybersecurity professional’s life moving forward, embrace it.”&lt;/p&gt;&lt;p&gt;&lt;em&gt;Rachel James will be sharing her insights at this year’s &lt;/em&gt;&lt;em&gt;AI &amp;amp; Big Data Expo Europe&lt;/em&gt;&lt;em&gt; in Amsterdam on 24-25 September 2025. Be sure to check out her day two presentation on ‘From Principle to Practice – Embedding AI Ethics at Scale’.&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Google Cloud unveils AI ally for security teams&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/rachel-james-abbvie-harnessing-ai-for-corporate-cybersecurity/</guid><pubDate>Fri, 22 Aug 2025 14:48:49 +0000</pubDate></item><item><title>Hot Topics at Hot Chips: Inference, Networking, AI Innovation at Every Scale — All Built on NVIDIA (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/hot-chips-inference-networking/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI reasoning, inference and networking will be top of mind for attendees of next week’s Hot Chips conference.&lt;/p&gt;
&lt;p&gt;A key forum for processor and system architects from industry and academia, Hot Chips — running Aug. 24-26 at Stanford University — showcases the latest innovations poised to advance AI factories and drive revenue for the trillion-dollar data center computing market.&lt;/p&gt;
&lt;p&gt;At the conference, NVIDIA will join industry leaders including Google and Microsoft in a “tutorial” session — taking place on Sunday, Aug. 24 — that discusses designing rack-scale architecture for data centers.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA experts will present at four sessions and one tutorial detailing how:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NVIDIA networking, including the NVIDIA ConnectX-8 SuperNIC, delivers AI reasoning at rack- and data-center scale. &lt;em&gt;(Featuring Idan Burstein, principal architect of network adapters and systems-on-a-chip at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Neural rendering advancements and massive leaps in inference — powered by the NVIDIA Blackwell architecture, including the NVIDIA GeForce RTX 5090 GPU — provide next-level graphics and simulation capabilities. &lt;em&gt;(Featuring Marc Blackstein, senior director of architecture at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Co-packaged optics (CPO) switches with integrated silicon photonics — built with light-speed fiber rather than copper wiring to send information quicker and using less power — enable efficient, high-performance, gigawatt-scale AI factories. The talk will also highlight NVIDIA Spectrum-XGS Ethernet, a new scale-across technology for unifying distributed data centers into AI super-factories. &lt;em&gt;(Featuring Gilad Shainer, senior vice president of networking at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The NVIDIA GB10 Superchip serves as the engine within the NVIDIA DGX Spark desktop supercomputer. &lt;em&gt;(Featuring Andi Skende, senior distinguished engineer at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s all part of how NVIDIA’s latest technologies are accelerating inference to drive AI innovation everywhere, at every scale.&lt;/p&gt;
&lt;h2&gt;NVIDIA Networking Fosters AI Innovation at Scale&lt;/h2&gt;
&lt;p&gt;AI reasoning — when artificial intelligence systems can analyze and solve complex problems through multiple AI inference passes — requires rack-scale performance to deliver optimal user experiences efficiently.&lt;/p&gt;
&lt;p&gt;In data centers powering today’s AI workloads, networking acts as the central nervous system, connecting all the components — servers, storage devices and other hardware — into a single, cohesive, powerful computing unit.&lt;/p&gt;
&lt;figure class="wp-caption alignleft" id="attachment_84155"&gt;&lt;img alt="alt" class="wp-image-84155 size-full" height="171" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/two-nvidia-connectx08-supernic.png" width="303" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84155"&gt;NVIDIA ConnectX-8 SuperNIC&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Burstein’s Hot Chips session will dive into how NVIDIA networking technologies — particularly NVIDIA ConnectX-8 SuperNICs — enable high-speed, low-latency, multi-GPU communication to deliver market-leading AI reasoning performance at scale.&lt;/p&gt;
&lt;p&gt;As part of the NVIDIA networking platform, NVIDIA NVLink, NVLink Switch and NVLink Fusion deliver scale-up connectivity — linking GPUs and compute elements within and across servers for ultra low-latency, high-bandwidth data exchange.&lt;/p&gt;
&lt;p&gt;NVIDIA Spectrum-X Ethernet provides the scale-out fabric to connect entire clusters, rapidly streaming massive datasets into AI models and orchestrating GPU-to-GPU communication across the data center. Spectrum-XGS Ethernet scale-across technology extends the extreme performance and scale of Spectrum-X Ethernet to interconnect multiple, distributed data centers to form AI super-factories capable of giga-scale intelligence.&lt;/p&gt;
&lt;figure class="wp-caption alignright" id="attachment_84152"&gt;&lt;img alt="alt" class="wp-image-84152 size-full" height="235" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/three-distributed-ai-data-centers.png" width="423" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84152"&gt;Connecting distributed AI data centers with NVIDIA Spectrum-XGS Ethernet.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;At the heart of Spectrum-X Ethernet, CPO switches push the limits of performance and efficiency for AI infrastructure at scale, and will be covered in detail by Shainer in his talk.&lt;/p&gt;
&lt;p&gt;NVIDIA GB200 NVL72 — an exascale computer in a single rack — features 36 NVIDIA GB200 Superchips, each containing two NVIDIA B200 GPUs and an NVIDIA Grace CPU, interconnected by the largest NVLink domain ever offered, with NVLink Switch providing 130 terabytes per second of low-latency GPU communications for AI and high-performance computing workloads.&lt;/p&gt;
&lt;figure class="wp-caption alignleft" id="attachment_84143"&gt;&lt;img alt="alt" class="wp-image-84143 size-full" height="159" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/four-rack-scale-system.png" width="282" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84143"&gt;An NVIDIA rack-scale system.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Built with the NVIDIA Blackwell architecture, GB200 NVL72 systems deliver massive leaps in reasoning inference performance.&lt;/p&gt;
&lt;h2&gt;NVIDIA Blackwell and CUDA Bring AI to Millions of Developers&lt;/h2&gt;
&lt;p&gt;The NVIDIA GeForce RTX 5090 GPU — also powered by Blackwell and to be covered in Blackstein’s talk — doubles performance in today’s games with NVIDIA DLSS 4 technology.&lt;/p&gt;
&lt;figure class="wp-caption alignright" id="attachment_84140"&gt;&lt;img alt="alt" class="wp-image-84140 size-full" height="144" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/five-geforce.jpg" width="256" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84140"&gt;NVIDIA GeForce RTX 5090 GPU&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;It can also add neural rendering features for games to deliver up to 10x performance, 10x footprint amplification and a 10x reduction in design cycles,&amp;nbsp; helping enhance realism in computer graphics and simulation. This offers smooth, responsive visual experiences at low energy consumption and improves the lifelike simulation of characters and effects.&lt;/p&gt;
&lt;p&gt;NVIDIA CUDA, the world’s most widely available computing infrastructure, lets users deploy and run AI models using NVIDIA Blackwell anywhere.&lt;/p&gt;
&lt;p&gt;Hundreds of millions of GPUs run CUDA across the globe, from NVIDIA GB200 NVL72 rack-scale systems to GeForce RTX– and NVIDIA RTX PRO-powered PCs and workstations, with NVIDIA DGX Spark powered by NVIDIA GB10 — discussed in Skende’s session — coming soon.&lt;/p&gt;
&lt;h2&gt;From Algorithms to AI Supercomputers — Optimized for LLMs&lt;/h2&gt;
&lt;figure class="wp-caption alignleft" id="attachment_84149"&gt;&lt;img alt="alt" class="wp-image-84149 size-full" height="164" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/six-dgx-spark.png" width="292" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84149"&gt;NVIDIA DGX Spark&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Delivering powerful performance and capabilities in a compact package, DGX Spark lets developers, researchers, data scientists and students push the boundaries of generative AI right at their desktops, and accelerate workloads across industries.&lt;/p&gt;
&lt;p&gt;As part of the NVIDIA Blackwell platform, DGX Spark brings support for NVFP4, a low-precision numerical format to enable efficient agentic AI inference, particularly of large language models (LLMs). Learn more about NVFP4 in this NVIDIA Technical Blog.&lt;/p&gt;
&lt;h2&gt;Open-Source Collaborations Propel Inference Innovation&lt;/h2&gt;
&lt;p&gt;NVIDIA accelerates several open-source libraries and frameworks to accelerate and optimize AI workloads for LLMs and distributed inference. These include NVIDIA TensorRT-LLM, NVIDIA Dynamo, TileIR, Cutlass, the NVIDIA Collective Communication Library and NIX — which are integrated into millions of workflows.&lt;/p&gt;
&lt;p&gt;Allowing developers to build with their framework of choice, NVIDIA has collaborated with top open framework providers to offer model optimizations for FlashInfer, PyTorch, SGLang, vLLM and others.&lt;/p&gt;
&lt;p&gt;Plus, NVIDIA NIM microservices are available for popular open models like OpenAI’s gpt-oss and Llama 4, &amp;nbsp;making it easy for developers to operate managed application programming interfaces with the flexibility and security of self-hosting models on their preferred infrastructure.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Learn more about the latest advancements in inference and accelerated computing by joining &lt;/em&gt;&lt;em&gt;NVIDIA at Hot Chips&lt;/em&gt;&lt;em&gt;. &lt;/em&gt;&lt;/p&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;AI reasoning, inference and networking will be top of mind for attendees of next week’s Hot Chips conference.&lt;/p&gt;
&lt;p&gt;A key forum for processor and system architects from industry and academia, Hot Chips — running Aug. 24-26 at Stanford University — showcases the latest innovations poised to advance AI factories and drive revenue for the trillion-dollar data center computing market.&lt;/p&gt;
&lt;p&gt;At the conference, NVIDIA will join industry leaders including Google and Microsoft in a “tutorial” session — taking place on Sunday, Aug. 24 — that discusses designing rack-scale architecture for data centers.&lt;/p&gt;
&lt;p&gt;In addition, NVIDIA experts will present at four sessions and one tutorial detailing how:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NVIDIA networking, including the NVIDIA ConnectX-8 SuperNIC, delivers AI reasoning at rack- and data-center scale. &lt;em&gt;(Featuring Idan Burstein, principal architect of network adapters and systems-on-a-chip at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Neural rendering advancements and massive leaps in inference — powered by the NVIDIA Blackwell architecture, including the NVIDIA GeForce RTX 5090 GPU — provide next-level graphics and simulation capabilities. &lt;em&gt;(Featuring Marc Blackstein, senior director of architecture at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;Co-packaged optics (CPO) switches with integrated silicon photonics — built with light-speed fiber rather than copper wiring to send information quicker and using less power — enable efficient, high-performance, gigawatt-scale AI factories. The talk will also highlight NVIDIA Spectrum-XGS Ethernet, a new scale-across technology for unifying distributed data centers into AI super-factories. &lt;em&gt;(Featuring Gilad Shainer, senior vice president of networking at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The NVIDIA GB10 Superchip serves as the engine within the NVIDIA DGX Spark desktop supercomputer. &lt;em&gt;(Featuring Andi Skende, senior distinguished engineer at NVIDIA)&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It’s all part of how NVIDIA’s latest technologies are accelerating inference to drive AI innovation everywhere, at every scale.&lt;/p&gt;
&lt;h2&gt;NVIDIA Networking Fosters AI Innovation at Scale&lt;/h2&gt;
&lt;p&gt;AI reasoning — when artificial intelligence systems can analyze and solve complex problems through multiple AI inference passes — requires rack-scale performance to deliver optimal user experiences efficiently.&lt;/p&gt;
&lt;p&gt;In data centers powering today’s AI workloads, networking acts as the central nervous system, connecting all the components — servers, storage devices and other hardware — into a single, cohesive, powerful computing unit.&lt;/p&gt;
&lt;figure class="wp-caption alignleft" id="attachment_84155"&gt;&lt;img alt="alt" class="wp-image-84155 size-full" height="171" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/two-nvidia-connectx08-supernic.png" width="303" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84155"&gt;NVIDIA ConnectX-8 SuperNIC&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Burstein’s Hot Chips session will dive into how NVIDIA networking technologies — particularly NVIDIA ConnectX-8 SuperNICs — enable high-speed, low-latency, multi-GPU communication to deliver market-leading AI reasoning performance at scale.&lt;/p&gt;
&lt;p&gt;As part of the NVIDIA networking platform, NVIDIA NVLink, NVLink Switch and NVLink Fusion deliver scale-up connectivity — linking GPUs and compute elements within and across servers for ultra low-latency, high-bandwidth data exchange.&lt;/p&gt;
&lt;p&gt;NVIDIA Spectrum-X Ethernet provides the scale-out fabric to connect entire clusters, rapidly streaming massive datasets into AI models and orchestrating GPU-to-GPU communication across the data center. Spectrum-XGS Ethernet scale-across technology extends the extreme performance and scale of Spectrum-X Ethernet to interconnect multiple, distributed data centers to form AI super-factories capable of giga-scale intelligence.&lt;/p&gt;
&lt;figure class="wp-caption alignright" id="attachment_84152"&gt;&lt;img alt="alt" class="wp-image-84152 size-full" height="235" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/three-distributed-ai-data-centers.png" width="423" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84152"&gt;Connecting distributed AI data centers with NVIDIA Spectrum-XGS Ethernet.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;At the heart of Spectrum-X Ethernet, CPO switches push the limits of performance and efficiency for AI infrastructure at scale, and will be covered in detail by Shainer in his talk.&lt;/p&gt;
&lt;p&gt;NVIDIA GB200 NVL72 — an exascale computer in a single rack — features 36 NVIDIA GB200 Superchips, each containing two NVIDIA B200 GPUs and an NVIDIA Grace CPU, interconnected by the largest NVLink domain ever offered, with NVLink Switch providing 130 terabytes per second of low-latency GPU communications for AI and high-performance computing workloads.&lt;/p&gt;
&lt;figure class="wp-caption alignleft" id="attachment_84143"&gt;&lt;img alt="alt" class="wp-image-84143 size-full" height="159" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/four-rack-scale-system.png" width="282" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84143"&gt;An NVIDIA rack-scale system.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Built with the NVIDIA Blackwell architecture, GB200 NVL72 systems deliver massive leaps in reasoning inference performance.&lt;/p&gt;
&lt;h2&gt;NVIDIA Blackwell and CUDA Bring AI to Millions of Developers&lt;/h2&gt;
&lt;p&gt;The NVIDIA GeForce RTX 5090 GPU — also powered by Blackwell and to be covered in Blackstein’s talk — doubles performance in today’s games with NVIDIA DLSS 4 technology.&lt;/p&gt;
&lt;figure class="wp-caption alignright" id="attachment_84140"&gt;&lt;img alt="alt" class="wp-image-84140 size-full" height="144" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/five-geforce.jpg" width="256" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84140"&gt;NVIDIA GeForce RTX 5090 GPU&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;It can also add neural rendering features for games to deliver up to 10x performance, 10x footprint amplification and a 10x reduction in design cycles,&amp;nbsp; helping enhance realism in computer graphics and simulation. This offers smooth, responsive visual experiences at low energy consumption and improves the lifelike simulation of characters and effects.&lt;/p&gt;
&lt;p&gt;NVIDIA CUDA, the world’s most widely available computing infrastructure, lets users deploy and run AI models using NVIDIA Blackwell anywhere.&lt;/p&gt;
&lt;p&gt;Hundreds of millions of GPUs run CUDA across the globe, from NVIDIA GB200 NVL72 rack-scale systems to GeForce RTX– and NVIDIA RTX PRO-powered PCs and workstations, with NVIDIA DGX Spark powered by NVIDIA GB10 — discussed in Skende’s session — coming soon.&lt;/p&gt;
&lt;h2&gt;From Algorithms to AI Supercomputers — Optimized for LLMs&lt;/h2&gt;
&lt;figure class="wp-caption alignleft" id="attachment_84149"&gt;&lt;img alt="alt" class="wp-image-84149 size-full" height="164" src="https://blogs.nvidia.com/wp-content/uploads/2025/08/six-dgx-spark.png" width="292" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-84149"&gt;NVIDIA DGX Spark&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;Delivering powerful performance and capabilities in a compact package, DGX Spark lets developers, researchers, data scientists and students push the boundaries of generative AI right at their desktops, and accelerate workloads across industries.&lt;/p&gt;
&lt;p&gt;As part of the NVIDIA Blackwell platform, DGX Spark brings support for NVFP4, a low-precision numerical format to enable efficient agentic AI inference, particularly of large language models (LLMs). Learn more about NVFP4 in this NVIDIA Technical Blog.&lt;/p&gt;
&lt;h2&gt;Open-Source Collaborations Propel Inference Innovation&lt;/h2&gt;
&lt;p&gt;NVIDIA accelerates several open-source libraries and frameworks to accelerate and optimize AI workloads for LLMs and distributed inference. These include NVIDIA TensorRT-LLM, NVIDIA Dynamo, TileIR, Cutlass, the NVIDIA Collective Communication Library and NIX — which are integrated into millions of workflows.&lt;/p&gt;
&lt;p&gt;Allowing developers to build with their framework of choice, NVIDIA has collaborated with top open framework providers to offer model optimizations for FlashInfer, PyTorch, SGLang, vLLM and others.&lt;/p&gt;
&lt;p&gt;Plus, NVIDIA NIM microservices are available for popular open models like OpenAI’s gpt-oss and Llama 4, &amp;nbsp;making it easy for developers to operate managed application programming interfaces with the flexibility and security of self-hosting models on their preferred infrastructure.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Learn more about the latest advancements in inference and accelerated computing by joining &lt;/em&gt;&lt;em&gt;NVIDIA at Hot Chips&lt;/em&gt;&lt;em&gt;. &lt;/em&gt;&lt;/p&gt;


		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/hot-chips-inference-networking/</guid><pubDate>Fri, 22 Aug 2025 15:00:29 +0000</pubDate></item><item><title>Google makes it easier to edit Drive videos with a new Vids shortcut button (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/22/google-makes-it-easier-to-edit-drive-videos-with-a-new-vids-shortcut-button/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google announced Friday that it’s enhancing the editing experience for Drive videos with a new shortcut button for Vids, the tech giant’s AI-powered video-creation tool.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new feature allows Workspace users to initiate a video edit using Vids directly from the Google Drive interface. Now, while previewing a video in Drive, users will see an “Open” button in the top right corner that opens the video in the Vids app. Vids will automatically launch the video file, allowing further edits such as trimming the clip or incorporating music and text.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039086" height="425" src="https://techcrunch.com/wp-content/uploads/2025/08/edit-drive-videos-in-vids.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This new shortcut, which is activated by default, suggests that the company is integrating the app more closely with Google’s Workspace suite. Launched last year, Vids aims to streamline video production, including the ability to generate videos from basic text prompts, automatically craft scripts, rearrange video clips, add transitions, and more.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This comes on the heels of the company introducing another Gemini AI feature for Workspace users in May, which allows them to use AI to summarize video files stored in Google Drive.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google announced Friday that it’s enhancing the editing experience for Drive videos with a new shortcut button for Vids, the tech giant’s AI-powered video-creation tool.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new feature allows Workspace users to initiate a video edit using Vids directly from the Google Drive interface. Now, while previewing a video in Drive, users will see an “Open” button in the top right corner that opens the video in the Vids app. Vids will automatically launch the video file, allowing further edits such as trimming the clip or incorporating music and text.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3039086" height="425" src="https://techcrunch.com/wp-content/uploads/2025/08/edit-drive-videos-in-vids.gif?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;This new shortcut, which is activated by default, suggests that the company is integrating the app more closely with Google’s Workspace suite. Launched last year, Vids aims to streamline video production, including the ability to generate videos from basic text prompts, automatically craft scripts, rearrange video clips, add transitions, and more.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This comes on the heels of the company introducing another Gemini AI feature for Workspace users in May, which allows them to use AI to summarize video files stored in Google Drive.&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us!&amp;nbsp;&lt;/em&gt;&lt;em&gt;Fill out this survey to let us know how we’re doing&lt;/em&gt;&amp;nbsp;a&lt;em&gt;nd get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/22/google-makes-it-easier-to-edit-drive-videos-with-a-new-vids-shortcut-button/</guid><pubDate>Fri, 22 Aug 2025 15:33:29 +0000</pubDate></item><item><title>Nvidia reportedly halts production on its H20 AI chips (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/22/nvidia-reportedly-halts-production-on-its-h20-ai-chips/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Beijing may have thrown a wrench into Nvidia’s plans on making a comeback in China’s AI market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia has instructed its component suppliers to stop production related to its H20 AI chip, according to The Information.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The production halt comes after Beijing reportedly warned Chinese companies against using these chips because of potential security issues and fears of backdoors that would give the U.S. access to sensitive data. China’s government is urging companies to use domestic chips instead, The Information reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This comes a month after companies including Nvidia were given the green light to start selling its AI chips designed for China’s market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Nvidia spokesperson sent TechCrunch the following statement, “We constantly manage our supply chain to address market conditions. Cybersecurity is critically important to us. NVIDIA does not have ‘backdoors’ in our chips that would give anyone a remote way to access or control them. The market can use the H20 with confidence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183848501.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Beijing may have thrown a wrench into Nvidia’s plans on making a comeback in China’s AI market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia has instructed its component suppliers to stop production related to its H20 AI chip, according to The Information.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The production halt comes after Beijing reportedly warned Chinese companies against using these chips because of potential security issues and fears of backdoors that would give the U.S. access to sensitive data. China’s government is urging companies to use domestic chips instead, The Information reported.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This comes a month after companies including Nvidia were given the green light to start selling its AI chips designed for China’s market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Nvidia spokesperson sent TechCrunch the following statement, “We constantly manage our supply chain to address market conditions. Cybersecurity is critically important to us. NVIDIA does not have ‘backdoors’ in our chips that would give anyone a remote way to access or control them. The market can use the H20 with confidence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/22/nvidia-reportedly-halts-production-on-its-h20-ai-chips/</guid><pubDate>Fri, 22 Aug 2025 16:53:47 +0000</pubDate></item><item><title>Apple is in talks to use Google’s Gemini for Siri revamp, report says (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/22/apple-is-in-talks-to-use-googles-gemini-for-siri-revamp-report-says/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/CMC_7975.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple is falling behind in the race to transform Siri into an AI assistant that’s as powerful as its competitors. As consumers grow more impatient, Apple is considering using another company’s tech instead of developing its own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple is now exploring a partnership with Google, its most direct competitor in the smartphone business, according to Bloomberg editor and Apple insider Mark Gurman.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company previously approached OpenAI and Anthropic for similar discussions about using their technology to power Siri, and reportedly, Google has begun training a model that could run on Apple’s servers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple is not expected to make a decision about whether to bring on a partner for the Siri revamp for another several weeks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/CMC_7975.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple is falling behind in the race to transform Siri into an AI assistant that’s as powerful as its competitors. As consumers grow more impatient, Apple is considering using another company’s tech instead of developing its own.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple is now exploring a partnership with Google, its most direct competitor in the smartphone business, according to Bloomberg editor and Apple insider Mark Gurman.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company previously approached OpenAI and Anthropic for similar discussions about using their technology to power Siri, and reportedly, Google has begun training a model that could run on Apple’s servers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple is not expected to make a decision about whether to bring on a partner for the Siri revamp for another several weeks. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/22/apple-is-in-talks-to-use-googles-gemini-for-siri-revamp-report-says/</guid><pubDate>Fri, 22 Aug 2025 18:15:08 +0000</pubDate></item><item><title>[NEW] Google says it dropped the energy cost of AI queries by 33x in one year (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/08/google-says-it-dropped-the-energy-cost-of-ai-queries-by-33x-in-one-year/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The company claims that a text query now burns the equivalent of 9 seconds of TV.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2229069552-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2229069552-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A data center in Ashburn, Virginia.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;So far this year, electricity use in the US is up nearly 4 percent compared to the same period the year prior. That comes after decades of essentially flat use, a change that has been associated with a rapid expansion of data centers. And a lot of those data centers are being built to serve the boom in AI usage. Given that some of this rising demand is being met by increased coal use (as of May, coal's share of generation is up about 20 percent compared to the year prior), the environmental impact of AI is looking pretty bad.&lt;/p&gt;
&lt;p&gt;But it's difficult to know for certain without access to the sorts of details that you'd only get by running a data center, such as how often the hardware is in use, and how often it's serving AI queries. So, while academics can test the power needs of individual AI models, it's hard to extrapolate that to real-world use cases.&lt;/p&gt;
&lt;p&gt;By contrast, Google has all sorts of data available from real-world use cases. As such, its release of a new analysis of AI's environmental impact is a rare opportunity to peer a tiny bit under the hood. But the new analysis suggests that energy estimates are currently a moving target, as the company says its data shows the energy drain of a search has dropped by a factor of 33 in just the past year.&lt;/p&gt;
&lt;h2&gt;What’s in, what’s out&lt;/h2&gt;
&lt;p&gt;One of the big questions when doing these analyses is what to include. There's obviously the energy consumed by the processors when handling a request. But there's also the energy required for memory, storage, cooling, and more needed to support those processors. Beyond that, there's the energy used to manufacture all that hardware and build the facilities that house them. AIs also require a lot of energy during training, a fraction of which might be counted against any single request made to the model post-training.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Any analysis of energy use needs to make decisions about which of these factors to consider. For many of the ones that have been done in the past, various factors have been skipped largely because the people performing the analysis don't have access to the relevant data. They probably don't know how many processors need to be dedicated to a given task, much less the carbon emissions associated with producing them.&lt;/p&gt;
&lt;p&gt;But Google has access to pretty much everything: the energy used to service a request, the hardware needed to do so, the cooling requirements, and more. And, since it's becoming standard practice to follow both Scope 2 and Scope 3 emissions that are produced due to the company's activities (either directly, through things like power generation, or indirectly through a supply chain), the company likely has access to those, as well.&lt;/p&gt;
&lt;p&gt;For the new analysis, Google tracks the energy of CPUs, dedicated AI accelerators, and memory, both when active on handling queries and while idling in between queries. It also follows the energy and water use of the data center as a whole and knows what else is in that data center so it can estimate the fraction that's given over to serving AI queries. It's also tracking the carbon emissions associated with the electricity supply, as well as the emissions that resulted from the production of all the hardware it's using.&lt;/p&gt;
&lt;p&gt;Three major factors don't make the cut. One is the environmental cost of the networking capacity used to receive requests and deliver results, which will vary considerably depending on the request. The same applies to the computational load on the end-user hardware; that's going to see vast differences between someone using a gaming desktop and someone using a smartphone. The one thing that Google could have made a reasonable estimate of, but didn't, is the impact of training its models. At this point, it will clearly know the energy costs there and can probably make reasonable estimates of a trained model's useful lifetime and number of requests handled during that period. But it didn't include that in the current estimates.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To come up with typical numbers, the team that did the analysis tracked requests and the hardware that served them for a 24 hour period, as well as the idle time for that hardware. This gives them an energy per request estimate, which differs based on the model being used. For each day, they identify the median prompt and use that to calculate the environmental impact.&lt;/p&gt;
&lt;h2&gt;Going down&lt;/h2&gt;
&lt;p&gt;Using those estimates, they find that the impact of an individual text request is pretty small. "We estimate the median Gemini Apps text prompt uses 0.24 watt-hours of energy, emits 0.03 grams of carbon dioxide equivalent (gCO2e), and consumes 0.26 milliliters (or about five drops) of water," they conclude. To put that in context, they estimate that the energy use is similar to about nine seconds of TV viewing.&lt;/p&gt;
&lt;p&gt;The bad news is that the volume of requests is undoubtedly very high. The company has chosen to execute an AI operation with every single search request, a compute demand that simply didn't exist a couple of years ago. So, while the individual impact is small, the cumulative cost is likely to be considerable.&lt;/p&gt;
&lt;p&gt;The good news? Just a year ago, it would have been far, far worse.&lt;/p&gt;
&lt;p&gt;Some of this is just down to circumstances. With the boom in solar power in the US and elsewhere, it has gotten easier for Google to arrange for renewable power. As a result, the carbon emissions per unit of energy consumed saw a 1.4x reduction over the past year. But the biggest wins have been on the software side, where different approaches have led to a 33x reduction in energy consumed per prompt.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2113414 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A color bar showing the percentage of energy used by different hardware. AI accelerators are the largest use, followed by CPU and RAM. Idle machines and overhead account for about 10 percent each." class="fullwidth full" height="604" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Screenshot-2025-08-22-at-12.25.32-PM.png" width="1286" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Most of the energy use in serving AI requests comes from time spent in the custom accelerator chips.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Elsworth, et. al.

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The Google team describes a number of optimizations the company has made that contribute to this. One is an approach termed Mixture-of-Experts, which involves figuring out how to only activate the portion of an AI model needed to handle specific requests, which can drop computational needs by a factor of 10 to 100. They've developed a number of compact versions of their main model, which also reduce the computational load. Data center management also plays a role, as the company can make sure that any active hardware is fully utilized, while allowing the rest to stay in a low-power state.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The other thing is that Google designs its own custom AI accelerators, and it architects the software that runs on them, allowing it to optimize both sides of the hardware/software divide to operate well with each other. That's especially critical given that activity on the AI accelerators accounts for over half of the total energy use of a query. Google also has lots of experience running efficient data centers that carries over to the experience with AI.&lt;/p&gt;
&lt;p&gt;The result of all this is that it estimates that the energy consumption of a typical text query has gone down by 33x in the last year alone. That has knock-on effects, since things like the carbon emissions associated with, say, building the hardware gets diluted out by the fact that the hardware can handle far more queries over the course of its useful lifetime.&lt;/p&gt;
&lt;p&gt;Given these efficiency gains, it would have been easy for Google to simply use the results as a PR exercise; instead, the company has detailed its methodology and considerations in something that reads very much like an academic publication. It's taking that approach because the people behind this work would like to see others in the field adopt its approach. "We advocate for the widespread adoption of this or similarly comprehensive measurement frameworks to ensure that as the capabilities of AI advance, their environmental efficiency does as well," they conclude.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The company claims that a text query now burns the equivalent of 9 seconds of TV.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="480" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2229069552-640x480.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/GettyImages-2229069552-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A data center in Ashburn, Virginia.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;So far this year, electricity use in the US is up nearly 4 percent compared to the same period the year prior. That comes after decades of essentially flat use, a change that has been associated with a rapid expansion of data centers. And a lot of those data centers are being built to serve the boom in AI usage. Given that some of this rising demand is being met by increased coal use (as of May, coal's share of generation is up about 20 percent compared to the year prior), the environmental impact of AI is looking pretty bad.&lt;/p&gt;
&lt;p&gt;But it's difficult to know for certain without access to the sorts of details that you'd only get by running a data center, such as how often the hardware is in use, and how often it's serving AI queries. So, while academics can test the power needs of individual AI models, it's hard to extrapolate that to real-world use cases.&lt;/p&gt;
&lt;p&gt;By contrast, Google has all sorts of data available from real-world use cases. As such, its release of a new analysis of AI's environmental impact is a rare opportunity to peer a tiny bit under the hood. But the new analysis suggests that energy estimates are currently a moving target, as the company says its data shows the energy drain of a search has dropped by a factor of 33 in just the past year.&lt;/p&gt;
&lt;h2&gt;What’s in, what’s out&lt;/h2&gt;
&lt;p&gt;One of the big questions when doing these analyses is what to include. There's obviously the energy consumed by the processors when handling a request. But there's also the energy required for memory, storage, cooling, and more needed to support those processors. Beyond that, there's the energy used to manufacture all that hardware and build the facilities that house them. AIs also require a lot of energy during training, a fraction of which might be counted against any single request made to the model post-training.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Any analysis of energy use needs to make decisions about which of these factors to consider. For many of the ones that have been done in the past, various factors have been skipped largely because the people performing the analysis don't have access to the relevant data. They probably don't know how many processors need to be dedicated to a given task, much less the carbon emissions associated with producing them.&lt;/p&gt;
&lt;p&gt;But Google has access to pretty much everything: the energy used to service a request, the hardware needed to do so, the cooling requirements, and more. And, since it's becoming standard practice to follow both Scope 2 and Scope 3 emissions that are produced due to the company's activities (either directly, through things like power generation, or indirectly through a supply chain), the company likely has access to those, as well.&lt;/p&gt;
&lt;p&gt;For the new analysis, Google tracks the energy of CPUs, dedicated AI accelerators, and memory, both when active on handling queries and while idling in between queries. It also follows the energy and water use of the data center as a whole and knows what else is in that data center so it can estimate the fraction that's given over to serving AI queries. It's also tracking the carbon emissions associated with the electricity supply, as well as the emissions that resulted from the production of all the hardware it's using.&lt;/p&gt;
&lt;p&gt;Three major factors don't make the cut. One is the environmental cost of the networking capacity used to receive requests and deliver results, which will vary considerably depending on the request. The same applies to the computational load on the end-user hardware; that's going to see vast differences between someone using a gaming desktop and someone using a smartphone. The one thing that Google could have made a reasonable estimate of, but didn't, is the impact of training its models. At this point, it will clearly know the energy costs there and can probably make reasonable estimates of a trained model's useful lifetime and number of requests handled during that period. But it didn't include that in the current estimates.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To come up with typical numbers, the team that did the analysis tracked requests and the hardware that served them for a 24 hour period, as well as the idle time for that hardware. This gives them an energy per request estimate, which differs based on the model being used. For each day, they identify the median prompt and use that to calculate the environmental impact.&lt;/p&gt;
&lt;h2&gt;Going down&lt;/h2&gt;
&lt;p&gt;Using those estimates, they find that the impact of an individual text request is pretty small. "We estimate the median Gemini Apps text prompt uses 0.24 watt-hours of energy, emits 0.03 grams of carbon dioxide equivalent (gCO2e), and consumes 0.26 milliliters (or about five drops) of water," they conclude. To put that in context, they estimate that the energy use is similar to about nine seconds of TV viewing.&lt;/p&gt;
&lt;p&gt;The bad news is that the volume of requests is undoubtedly very high. The company has chosen to execute an AI operation with every single search request, a compute demand that simply didn't exist a couple of years ago. So, while the individual impact is small, the cumulative cost is likely to be considerable.&lt;/p&gt;
&lt;p&gt;The good news? Just a year ago, it would have been far, far worse.&lt;/p&gt;
&lt;p&gt;Some of this is just down to circumstances. With the boom in solar power in the US and elsewhere, it has gotten easier for Google to arrange for renewable power. As a result, the carbon emissions per unit of energy consumed saw a 1.4x reduction over the past year. But the biggest wins have been on the software side, where different approaches have led to a 33x reduction in energy consumed per prompt.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2113414 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="A color bar showing the percentage of energy used by different hardware. AI accelerators are the largest use, followed by CPU and RAM. Idle machines and overhead account for about 10 percent each." class="fullwidth full" height="604" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/Screenshot-2025-08-22-at-12.25.32-PM.png" width="1286" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Most of the energy use in serving AI requests comes from time spent in the custom accelerator chips.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Elsworth, et. al.

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The Google team describes a number of optimizations the company has made that contribute to this. One is an approach termed Mixture-of-Experts, which involves figuring out how to only activate the portion of an AI model needed to handle specific requests, which can drop computational needs by a factor of 10 to 100. They've developed a number of compact versions of their main model, which also reduce the computational load. Data center management also plays a role, as the company can make sure that any active hardware is fully utilized, while allowing the rest to stay in a low-power state.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The other thing is that Google designs its own custom AI accelerators, and it architects the software that runs on them, allowing it to optimize both sides of the hardware/software divide to operate well with each other. That's especially critical given that activity on the AI accelerators accounts for over half of the total energy use of a query. Google also has lots of experience running efficient data centers that carries over to the experience with AI.&lt;/p&gt;
&lt;p&gt;The result of all this is that it estimates that the energy consumption of a typical text query has gone down by 33x in the last year alone. That has knock-on effects, since things like the carbon emissions associated with, say, building the hardware gets diluted out by the fact that the hardware can handle far more queries over the course of its useful lifetime.&lt;/p&gt;
&lt;p&gt;Given these efficiency gains, it would have been easy for Google to simply use the results as a PR exercise; instead, the company has detailed its methodology and considerations in something that reads very much like an academic publication. It's taking that approach because the people behind this work would like to see others in the field adopt its approach. "We advocate for the widespread adoption of this or similarly comprehensive measurement frameworks to ensure that as the capabilities of AI advance, their environmental efficiency does as well," they conclude.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/08/google-says-it-dropped-the-energy-cost-of-ai-queries-by-33x-in-one-year/</guid><pubDate>Fri, 22 Aug 2025 18:53:12 +0000</pubDate></item><item><title>[NEW] Apple gets ready for AI in the enterprise with new ChatGPT configuration options (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/22/apple-gets-ready-for-ai-in-the-enterprise-with-new-chatgpt-configuration-options/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI technology makes its way into the enterprise, Apple is rolling out new tools that will give businesses more granular control over where and how their employees can tap into artificial intelligence. With the release of Apple’s software updates arriving in September, the tech giant is adding another option for enterprise customers: the ability to configure the use of an enterprise version of OpenAI’s ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has already seen the demand for ChatGPT for Enterprise, which OpenAI says now has over 5 million business customers. These companies use the AI service to connect with their own internal data when using AI agents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, what’s interesting about the way Apple’s integration with ChatGPT for Enterprise has been structured is that it’s not hard-coded to only restrict or allow ChatGPT itself. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, Apple’s support documents indicate that IT administrators will be able to restrict or allow any “external” artificial intelligence provider, not just OpenAI’s technology. That leaves the door open for Apple to forge other deals with large AI players used in the enterprise environment, without having to recode things at the protocol level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Apple has rolled out new AI features aimed at its devices’ end users — like writing tools or visual intelligence, for example — it’s also rolled out ways for IT departments to control access to those features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the company fully believes in its Private Cloud Compute architecture, it knows that it can take time for companies to agree to make changes to sensitive systems and data. That’s why it leaves it up to businesses to decide if data should be processed in the cloud or on the device, for example.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to letting businesses pick and choose which AI features to enable, this setup allows businesses to decide whether employees’ AI requests can go to ChatGPT’s cloud service, even when the business doesn’t have its own enterprise deal with OpenAI. (ChatGPT, you’ll recall, has been integrated with Apple Intelligence across Apple’s software platform to handle AI requests that Apple’s own cloud can’t. Because requests never go from Apple’s cloud to ChatGPT directly — it’s either/or — it’s easier to disable the ChatGPT setting.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI updates are a highlight of the enterprise-related updates due out in the fall, Apple is also rolling out other new features to its largest customers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It will launch an API for its Apple Business Manager service, which will allow the service’s functions to be integrated into other IT tools, like MDM products, inventory management services, or help desks, among others. It’s also debuting new tools for Device Management to make it easier to migrate devices to a different management service — something that often comes up in M&amp;amp;A scenarios when a new company takes over employee devices and assets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple’s Return to Service solution, which lets devices quickly get wiped and readied for the next user, will now offer the option to leave all apps installed, saving time and bandwidth since IT admins and users won’t need to reinstall them. Plus, Return to Service will become available for Vision Pro for the first time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On shared Macs, an authenticated Guest Mode lets employees log in with account credentials from their identity provider, then has their data (but not apps) erased upon logout. Another option lets businesses add NFC readers to Macs, so employees can just tap their watch or phone to log in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These tools will also roll out in September as part of Apple’s broader software updates for iPhone, iPad, Mac and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI technology makes its way into the enterprise, Apple is rolling out new tools that will give businesses more granular control over where and how their employees can tap into artificial intelligence. With the release of Apple’s software updates arriving in September, the tech giant is adding another option for enterprise customers: the ability to configure the use of an enterprise version of OpenAI’s ChatGPT.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has already seen the demand for ChatGPT for Enterprise, which OpenAI says now has over 5 million business customers. These companies use the AI service to connect with their own internal data when using AI agents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, what’s interesting about the way Apple’s integration with ChatGPT for Enterprise has been structured is that it’s not hard-coded to only restrict or allow ChatGPT itself. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Instead, Apple’s support documents indicate that IT administrators will be able to restrict or allow any “external” artificial intelligence provider, not just OpenAI’s technology. That leaves the door open for Apple to forge other deals with large AI players used in the enterprise environment, without having to recode things at the protocol level.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Apple has rolled out new AI features aimed at its devices’ end users — like writing tools or visual intelligence, for example — it’s also rolled out ways for IT departments to control access to those features.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the company fully believes in its Private Cloud Compute architecture, it knows that it can take time for companies to agree to make changes to sensitive systems and data. That’s why it leaves it up to businesses to decide if data should be processed in the cloud or on the device, for example.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to letting businesses pick and choose which AI features to enable, this setup allows businesses to decide whether employees’ AI requests can go to ChatGPT’s cloud service, even when the business doesn’t have its own enterprise deal with OpenAI. (ChatGPT, you’ll recall, has been integrated with Apple Intelligence across Apple’s software platform to handle AI requests that Apple’s own cloud can’t. Because requests never go from Apple’s cloud to ChatGPT directly — it’s either/or — it’s easier to disable the ChatGPT setting.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI updates are a highlight of the enterprise-related updates due out in the fall, Apple is also rolling out other new features to its largest customers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It will launch an API for its Apple Business Manager service, which will allow the service’s functions to be integrated into other IT tools, like MDM products, inventory management services, or help desks, among others. It’s also debuting new tools for Device Management to make it easier to migrate devices to a different management service — something that often comes up in M&amp;amp;A scenarios when a new company takes over employee devices and assets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple’s Return to Service solution, which lets devices quickly get wiped and readied for the next user, will now offer the option to leave all apps installed, saving time and bandwidth since IT admins and users won’t need to reinstall them. Plus, Return to Service will become available for Vision Pro for the first time.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On shared Macs, an authenticated Guest Mode lets employees log in with account credentials from their identity provider, then has their data (but not apps) erased upon logout. Another option lets businesses add NFC readers to Macs, so employees can just tap their watch or phone to log in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;These tools will also roll out in September as part of Apple’s broader software updates for iPhone, iPad, Mac and more.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/22/apple-gets-ready-for-ai-in-the-enterprise-with-new-chatgpt-configuration-options/</guid><pubDate>Fri, 22 Aug 2025 20:00:34 +0000</pubDate></item><item><title>[NEW] MCP-Universe benchmark shows GPT-5 fails more than half of real-world orchestration tasks (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/mcp-universe-benchmark-shows-gpt-5-fails-more-than-half-of-real-world-orchestration-tasks/</link><description>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The adoption of interoperability standards, such as the Model Context Protocol (MCP), can provide enterprises with insights into how agents and models function outside their walled confines. However, many benchmarks fail to capture real-life interactions with MCP.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Salesforce AI Research developed a new open-source benchmark it calls MCP-Universe, which aims to track LLMs as these interact with MCP servers in the real world, arguing that it will paint a better picture of real-life and real-time interactions of models with tools enterprises actually use. In its initial testing, it found that models like OpenAI’s recently released GPT-5 are strong, but still do not perform as well in real-life scenarios.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Existing benchmarks predominantly focus on isolated aspects of LLM performance, such as instruction following, math reasoning, or function calling, without providing a comprehensive assessment of how models interact with real-world MCP servers across diverse scenarios,” Salesforce said in a paper.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;MCP-Universe captures model performance through tool usage, multi-turn tool calls, long context windows and large tool spaces. It’s grounded on existing MCP servers with access to actual data sources and environments.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Junnan Li, director of AI research at Salesforce, told VentureBeat that many models “still face limitations that hold them back on enterprise-grade tasks.”&lt;/p&gt;



&lt;p&gt;“Two of the biggest are: Long context challenges, models can lose track of information or struggle to reason consistently when handling very long or complex inputs,” Li said. “And, Unknown tool challenges, models often aren’t able to seamlessly use unfamiliar tools or systems in the way humans can adapt on the fly. This is why it’s crucial not to take a DIY approach with a single model to power agents alone, but instead, to rely on a platform that combines data context, enhanced reasoning, and trust guardrails to truly meet the needs of enterprise AI.”&lt;/p&gt;



&lt;p&gt;MCP-Universe joins other MCP-based proposed benchmarks&lt;span&gt;, such as&amp;nbsp;MCP-Radar&amp;nbsp;from the University of Massachusetts Amherst and Xi’an Jiaotong University, as well as the&lt;/span&gt; Beijing University of Posts and Telecommunications’ MCPWorld. It also builds on MCPEvals, which Salesforce released in July, which focuses mainly on agents. Li said the biggest difference between MCP-Universe and MCPEvals is that the latter is evaluated with synthetic tasks.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-it-works"&gt;How it works&lt;/h2&gt;



&lt;p&gt;MCP-Universe evaluates how well each model performs a series of tasks that mimic those undertaken by enterprises. Salesforce said it designed MCP-Universe to encompass six core domains used by enterprises: location navigation, repository management, financial analysis, 3D design, browser automation and web search. It accessed 11 MCP servers for a total of 231 tasks.&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Location navigation focuses on geographic reasoning and the execution of spatial tasks. The researchers tapped the Google Maps MCP server for this process.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;The repository management domain looks at codebase operations and connects to the GitHub MCP to expose version control tools like repo search, issue tracking and code editing.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Financial analysis connects to the Yahoo Finance MCP server to evaluate quantitative reasoning and financial market decision-making.&lt;/li&gt;



&lt;li&gt;3D design evaluates the use of computer-aided design tools through the Blender MCP.&lt;/li&gt;



&lt;li&gt;Browser automation, connected to Playwright’s MCP, tests browser interaction.&lt;/li&gt;



&lt;li&gt;The web searching domain employs the Google Search MCP server and the Fetch MCP&amp;nbsp; to check “open-domain information seeking” and is structured as a more open-ended task.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Salesforce said that it had to design new MCP tasks that reflect real use cases. For each domain, they created four to five kinds of tasks that the researchers think LLMs can easily complete. For example, the researchers assigned the models a goal that involved route planning, identifying the optimal stops and then locating the destination.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015992" height="301" src="https://venturebeat.com/wp-content/uploads/2025/08/Screen-Shot-2025-08-22-at-13.46.54-PM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Each model is evaluated on how they completed the tasks. Li and his team opted to follow an execution-based evaluation paradigm rather than the more common LLM-as-a-judge system. The researchers noted the LLM-as-a-judge paradigm “is not well-suited for our MCP-Universe scenario, since some tasks are designed to use real-time data, while the knowledge of the LLM judge is static.”&lt;/p&gt;



&lt;p&gt;Salesforce researchers used three types of evaluators: format evaluators to see if the agents and models follow format requirements, static evaluators to assess correctness over time and dynamic evaluators for fluctuating answers like flight prices or GitHub issues.&lt;/p&gt;



&lt;p&gt;“MCP-Universe focuses on creating challenging real-world tasks with execution-based evaluators, which can stress-test the agent in complex scenarios. Furthermore, MCP-Universe offers an extendable framework/codebase for building and evaluating agents,” Li said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-even-the-big-models-have-trouble"&gt;Even the big models have trouble&lt;/h2&gt;



&lt;p&gt;To test MCP-Universe, Salesforce evaluated several popular proprietary and open-source models. These include Grok-4 from xAI, Anthropic’s Claude-4 Sonnet and Claude 3.7 Sonnet, OpenAI’s GPT-5, o4-mini, o3, GPT-4.1, GPT-4o, GPT-oss, Google’s Gemini 2.5 Pro and Gemini 2.5 Fkash, GLM-4.5 from Zai, Moonshot’s Kimi-K2, Qwen’s Qwen3 Coder and Qwen3-235B-A22B-Instruct-2507 and DeepSeek-V3-0304 from DeepSeek. Each model tested had at least 120B parameters.&lt;/p&gt;



&lt;p&gt;In its testing, Salesforce found GPT-5 had the best success rate, especially for financial analysis tasks. Grok-4 followed, beating all the models for browser automation, and Claude-4.0 Sonnet rounds out the top three, although it did not post any performance numbers higher than either of the models it follows. Among open-source models, GLM-4.5 performed the best.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015993" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screen-Shot-2025-08-22-at-14.54.33-PM.png?w=734" width="734" /&gt;&lt;/figure&gt;



&lt;p&gt;However, MCP-Universe showed the models had difficulty handling long contexts, especially for location navigation, browser automation and financial analysis, with efficiency falling significantly. The moment the LLMs encounter unknown tools, their performance also drops. The LLMs demonstrated difficulty in completing more than half of the tasks that enterprises typically perform.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015994" height="279" src="https://venturebeat.com/wp-content/uploads/2025/08/Screen-Shot-2025-08-22-at-15.14.40-PM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;“These findings highlight that current frontier LLMs still fall short in reliably executing tasks across diverse real-world MCP tasks. Our MCP-Universe benchmark, therefore, provides a challenging and necessary testbed for evaluating LLM performance in areas underserved by existing benchmarks,” the paper said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Li told VentureBeat that he hopes enterprises will use MCP-Universe to gain a deeper understanding of where agents and models fail on tasks so that they can improve either their frameworks or the implementation of their MCP tools.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</description><content:encoded>&lt;div class="post-boilerplate boilerplate-before" id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;The adoption of interoperability standards, such as the Model Context Protocol (MCP), can provide enterprises with insights into how agents and models function outside their walled confines. However, many benchmarks fail to capture real-life interactions with MCP.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Salesforce AI Research developed a new open-source benchmark it calls MCP-Universe, which aims to track LLMs as these interact with MCP servers in the real world, arguing that it will paint a better picture of real-life and real-time interactions of models with tools enterprises actually use. In its initial testing, it found that models like OpenAI’s recently released GPT-5 are strong, but still do not perform as well in real-life scenarios.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;“Existing benchmarks predominantly focus on isolated aspects of LLM performance, such as instruction following, math reasoning, or function calling, without providing a comprehensive assessment of how models interact with real-world MCP servers across diverse scenarios,” Salesforce said in a paper.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;MCP-Universe captures model performance through tool usage, multi-turn tool calls, long context windows and large tool spaces. It’s grounded on existing MCP servers with access to actual data sources and environments.&amp;nbsp;&lt;/p&gt;



&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Junnan Li, director of AI research at Salesforce, told VentureBeat that many models “still face limitations that hold them back on enterprise-grade tasks.”&lt;/p&gt;



&lt;p&gt;“Two of the biggest are: Long context challenges, models can lose track of information or struggle to reason consistently when handling very long or complex inputs,” Li said. “And, Unknown tool challenges, models often aren’t able to seamlessly use unfamiliar tools or systems in the way humans can adapt on the fly. This is why it’s crucial not to take a DIY approach with a single model to power agents alone, but instead, to rely on a platform that combines data context, enhanced reasoning, and trust guardrails to truly meet the needs of enterprise AI.”&lt;/p&gt;



&lt;p&gt;MCP-Universe joins other MCP-based proposed benchmarks&lt;span&gt;, such as&amp;nbsp;MCP-Radar&amp;nbsp;from the University of Massachusetts Amherst and Xi’an Jiaotong University, as well as the&lt;/span&gt; Beijing University of Posts and Telecommunications’ MCPWorld. It also builds on MCPEvals, which Salesforce released in July, which focuses mainly on agents. Li said the biggest difference between MCP-Universe and MCPEvals is that the latter is evaluated with synthetic tasks.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-how-it-works"&gt;How it works&lt;/h2&gt;



&lt;p&gt;MCP-Universe evaluates how well each model performs a series of tasks that mimic those undertaken by enterprises. Salesforce said it designed MCP-Universe to encompass six core domains used by enterprises: location navigation, repository management, financial analysis, 3D design, browser automation and web search. It accessed 11 MCP servers for a total of 231 tasks.&amp;nbsp;&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li&gt;Location navigation focuses on geographic reasoning and the execution of spatial tasks. The researchers tapped the Google Maps MCP server for this process.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;The repository management domain looks at codebase operations and connects to the GitHub MCP to expose version control tools like repo search, issue tracking and code editing.&amp;nbsp;&lt;/li&gt;



&lt;li&gt;Financial analysis connects to the Yahoo Finance MCP server to evaluate quantitative reasoning and financial market decision-making.&lt;/li&gt;



&lt;li&gt;3D design evaluates the use of computer-aided design tools through the Blender MCP.&lt;/li&gt;



&lt;li&gt;Browser automation, connected to Playwright’s MCP, tests browser interaction.&lt;/li&gt;



&lt;li&gt;The web searching domain employs the Google Search MCP server and the Fetch MCP&amp;nbsp; to check “open-domain information seeking” and is structured as a more open-ended task.&amp;nbsp;&lt;/li&gt;
&lt;/ul&gt;



&lt;p&gt;Salesforce said that it had to design new MCP tasks that reflect real use cases. For each domain, they created four to five kinds of tasks that the researchers think LLMs can easily complete. For example, the researchers assigned the models a goal that involved route planning, identifying the optimal stops and then locating the destination.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015992" height="301" src="https://venturebeat.com/wp-content/uploads/2025/08/Screen-Shot-2025-08-22-at-13.46.54-PM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;Each model is evaluated on how they completed the tasks. Li and his team opted to follow an execution-based evaluation paradigm rather than the more common LLM-as-a-judge system. The researchers noted the LLM-as-a-judge paradigm “is not well-suited for our MCP-Universe scenario, since some tasks are designed to use real-time data, while the knowledge of the LLM judge is static.”&lt;/p&gt;



&lt;p&gt;Salesforce researchers used three types of evaluators: format evaluators to see if the agents and models follow format requirements, static evaluators to assess correctness over time and dynamic evaluators for fluctuating answers like flight prices or GitHub issues.&lt;/p&gt;



&lt;p&gt;“MCP-Universe focuses on creating challenging real-world tasks with execution-based evaluators, which can stress-test the agent in complex scenarios. Furthermore, MCP-Universe offers an extendable framework/codebase for building and evaluating agents,” Li said.&amp;nbsp;&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-even-the-big-models-have-trouble"&gt;Even the big models have trouble&lt;/h2&gt;



&lt;p&gt;To test MCP-Universe, Salesforce evaluated several popular proprietary and open-source models. These include Grok-4 from xAI, Anthropic’s Claude-4 Sonnet and Claude 3.7 Sonnet, OpenAI’s GPT-5, o4-mini, o3, GPT-4.1, GPT-4o, GPT-oss, Google’s Gemini 2.5 Pro and Gemini 2.5 Fkash, GLM-4.5 from Zai, Moonshot’s Kimi-K2, Qwen’s Qwen3 Coder and Qwen3-235B-A22B-Instruct-2507 and DeepSeek-V3-0304 from DeepSeek. Each model tested had at least 120B parameters.&lt;/p&gt;



&lt;p&gt;In its testing, Salesforce found GPT-5 had the best success rate, especially for financial analysis tasks. Grok-4 followed, beating all the models for browser automation, and Claude-4.0 Sonnet rounds out the top three, although it did not post any performance numbers higher than either of the models it follows. Among open-source models, GLM-4.5 performed the best.&amp;nbsp;&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015993" height="600" src="https://venturebeat.com/wp-content/uploads/2025/08/Screen-Shot-2025-08-22-at-14.54.33-PM.png?w=734" width="734" /&gt;&lt;/figure&gt;



&lt;p&gt;However, MCP-Universe showed the models had difficulty handling long contexts, especially for location navigation, browser automation and financial analysis, with efficiency falling significantly. The moment the LLMs encounter unknown tools, their performance also drops. The LLMs demonstrated difficulty in completing more than half of the tasks that enterprises typically perform.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3015994" height="279" src="https://venturebeat.com/wp-content/uploads/2025/08/Screen-Shot-2025-08-22-at-15.14.40-PM.png?w=800" width="800" /&gt;&lt;/figure&gt;



&lt;p&gt;“These findings highlight that current frontier LLMs still fall short in reliably executing tasks across diverse real-world MCP tasks. Our MCP-Universe benchmark, therefore, provides a challenging and necessary testbed for evaluating LLM performance in areas underserved by existing benchmarks,” the paper said.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Li told VentureBeat that he hopes enterprises will use MCP-Universe to gain a deeper understanding of where agents and models fail on tasks so that they can improve either their frameworks or the implementation of their MCP tools.&amp;nbsp;&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/mcp-universe-benchmark-shows-gpt-5-fails-more-than-half-of-real-world-orchestration-tasks/</guid><pubDate>Fri, 22 Aug 2025 20:50:55 +0000</pubDate></item><item><title>[NEW] Coinbase CEO explains why he fired engineers who didn’t try AI immediately (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/22/coinbase-ceo-explains-why-he-fired-engineers-who-didnt-try-ai-immediately/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-22-at-11.08.48AM.png?resize=1200,738" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s hard to find programmers these days who aren’t using AI coding assistants in some capacity, especially to write the repetitive, mundane bits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But those who refused to try the tools when Coinbase bought enterprise licenses for GitHub Copilot and Cursor got promptly fired, CEO Brian Armstrong said this week on John Collison’s podcast “Cheeky Pint.” (Collison is the co-founder and president of the payments company Stripe.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After getting licenses to cover every engineer, some at the cryptocurrency exchange warned Armstrong that adoption would be slow, predicting it would take months to get even half the engineers using AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armstrong was shocked at the thought. “I went rogue,” he said, and posted a mandate in the company’s main engineering Slack channel. “I said, ‘AI is important. We need you to all learn it and at least onboard. You don’t have to use it every day yet until we do some training, but at least onboard by the end of the week. And if not, I’m hosting a meeting on Saturday with everybody who hasn’t done it and I’d like to meet with you to understand why.’”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the meeting, some people had reasonable explanations for not getting their AI assistant accounts set up during the week, like being on vacation, Armstrong said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I jumped on this call on Saturday and there were a couple people that had not done it. Some of them had a good reason, because they were just getting back from some trip or something, and some of them didn’t [have a good reason]. And they got fired.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armstrong admits that it was a “heavy-handed approach” and there were people in the company who “didn’t like it.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While it doesn’t sound like very many people were fired, Armstrong said it sent a clear message that AI is not optional. Still, everything about that story is wild: that there were engineers who wouldn’t spend a few minutes of their week signing up for and testing the AI assistant — the most hyped tech for coders ever — and that Armstrong was willing to fire them over it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Coinbase did not respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, Armstrong has leaned further into the training. He said the company hosts monthly meetings where teams who have mastered creative ways to use AI share what they have learned.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Interestingly, Collison, who has been programming since childhood, questioned how much companies should be relying on AI-generated code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s clear that it is very helpful to have AI helping you write code. It’s not clear how you run an AI-coded code base,” he commented.  Armstrong replied, “I agree.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, as TechCrunch previously reported, a former OpenAI engineer described that company’s central code repository as “a bit of a dumping ground.” The engineer said management had begun dedicating engineering resources to improve the situation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Screenshot-2025-08-22-at-11.08.48AM.png?resize=1200,738" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s hard to find programmers these days who aren’t using AI coding assistants in some capacity, especially to write the repetitive, mundane bits.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But those who refused to try the tools when Coinbase bought enterprise licenses for GitHub Copilot and Cursor got promptly fired, CEO Brian Armstrong said this week on John Collison’s podcast “Cheeky Pint.” (Collison is the co-founder and president of the payments company Stripe.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;After getting licenses to cover every engineer, some at the cryptocurrency exchange warned Armstrong that adoption would be slow, predicting it would take months to get even half the engineers using AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armstrong was shocked at the thought. “I went rogue,” he said, and posted a mandate in the company’s main engineering Slack channel. “I said, ‘AI is important. We need you to all learn it and at least onboard. You don’t have to use it every day yet until we do some training, but at least onboard by the end of the week. And if not, I’m hosting a meeting on Saturday with everybody who hasn’t done it and I’d like to meet with you to understand why.’”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the meeting, some people had reasonable explanations for not getting their AI assistant accounts set up during the week, like being on vacation, Armstrong said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I jumped on this call on Saturday and there were a couple people that had not done it. Some of them had a good reason, because they were just getting back from some trip or something, and some of them didn’t [have a good reason]. And they got fired.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Armstrong admits that it was a “heavy-handed approach” and there were people in the company who “didn’t like it.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;While it doesn’t sound like very many people were fired, Armstrong said it sent a clear message that AI is not optional. Still, everything about that story is wild: that there were engineers who wouldn’t spend a few minutes of their week signing up for and testing the AI assistant — the most hyped tech for coders ever — and that Armstrong was willing to fire them over it.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Coinbase did not respond to a request for comment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, Armstrong has leaned further into the training. He said the company hosts monthly meetings where teams who have mastered creative ways to use AI share what they have learned.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Interestingly, Collison, who has been programming since childhood, questioned how much companies should be relying on AI-generated code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s clear that it is very helpful to have AI helping you write code. It’s not clear how you run an AI-coded code base,” he commented.  Armstrong replied, “I agree.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, as TechCrunch previously reported, a former OpenAI engineer described that company’s central code repository as “a bit of a dumping ground.” The engineer said management had begun dedicating engineering resources to improve the situation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/22/coinbase-ceo-explains-why-he-fired-engineers-who-didnt-try-ai-immediately/</guid><pubDate>Fri, 22 Aug 2025 21:07:21 +0000</pubDate></item><item><title>[NEW] Meta partners with Midjourney on AI image and video models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/08/22/meta-partners-with-midjourney-on-ai-image-and-video-models/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2173579243.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is partnering with Midjourney to license the startup’s AI image and video generation technology, Meta Chief AI Officer Alexandr Wang announced Friday in a post on Threads. Wang says Meta’s research teams will collaborate with Midjourney to bring its technology into future AI models and products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To ensure Meta is able to deliver the best possible products for people it will require taking an all-of-the-above approach,” Wang said. “This means world-class talent, ambitious compute roadmap, and working with the best players across the industry.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Midjourney partnership could help Meta develop products that compete with industry-leading AI image and video models, such as OpenAI’s Sora, Black Forest Lab’s Flux, and Google’s Veo. Last year, Meta rolled out its own AI image generation tool, Imagine, into several of its products, including Facebook, Instagram, and Messenger. Meta also has an AI video generation tool, Movie Gen, that allows users to create videos from prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The licensing agreement with Midjourney marks Meta’s latest deal to get ahead in the AI race. Earlier this year, CEO Mark Zuckerberg went on a hiring spree for AI talent, offering some researchers compensation packages worth upwards of $100 million. The social media giant also invested $14 billion in Scale AI, and acquired the AI voice startup Play AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has held talks with several other leading AI labs about other acquisitions, and Zuckerberg even spoke with Elon Musk about joining his $97 billion takeover bid of OpenAI (Meta ultimately did not join the offer, and OpenAI denied Musk’s bid).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the terms of Meta’s deal with Midjourney remain unknown, the startup’s CEO, David Holz, said in a post on X that his company remains independent with no investors; Midjourney is one of the few leading AI model developers that has never taken on outside funding. At one point, Meta talked with Midjourney about acquiring the startup, according to Upstarts Media.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Midjourney was founded in 2022 and quickly became a leader in the AI image generation space for its realistic, unique style. By 2023, the startup was reportedly on pace to generate $200 million in revenue. The startup sells subscriptions starting at $10 per month. It offers pricier tiers, which offer more AI image generations, that cost as much as $120 per month. In June, the startup released its first AI video model, V1.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s partnership with Midjourney comes just two months after the startup was sued by Disney and Universal, alleging that it trained AI image models on copyrighted works. Several AI model developers — including Meta — face similar allegations from copyright holders, however, recent court cases pertaining to AI training data have sided with tech companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;&lt;/em&gt;&lt;em&gt;@rebeccabellan&lt;/em&gt;&lt;em&gt;.491 and&amp;nbsp;&lt;/em&gt;&lt;em&gt;@mzeff&lt;/em&gt;&lt;em&gt;.88.&lt;/em&gt;&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/09/GettyImages-2173579243.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta is partnering with Midjourney to license the startup’s AI image and video generation technology, Meta Chief AI Officer Alexandr Wang announced Friday in a post on Threads. Wang says Meta’s research teams will collaborate with Midjourney to bring its technology into future AI models and products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“To ensure Meta is able to deliver the best possible products for people it will require taking an all-of-the-above approach,” Wang said. “This means world-class talent, ambitious compute roadmap, and working with the best players across the industry.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Midjourney partnership could help Meta develop products that compete with industry-leading AI image and video models, such as OpenAI’s Sora, Black Forest Lab’s Flux, and Google’s Veo. Last year, Meta rolled out its own AI image generation tool, Imagine, into several of its products, including Facebook, Instagram, and Messenger. Meta also has an AI video generation tool, Movie Gen, that allows users to create videos from prompts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The licensing agreement with Midjourney marks Meta’s latest deal to get ahead in the AI race. Earlier this year, CEO Mark Zuckerberg went on a hiring spree for AI talent, offering some researchers compensation packages worth upwards of $100 million. The social media giant also invested $14 billion in Scale AI, and acquired the AI voice startup Play AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta has held talks with several other leading AI labs about other acquisitions, and Zuckerberg even spoke with Elon Musk about joining his $97 billion takeover bid of OpenAI (Meta ultimately did not join the offer, and OpenAI denied Musk’s bid).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the terms of Meta’s deal with Midjourney remain unknown, the startup’s CEO, David Holz, said in a post on X that his company remains independent with no investors; Midjourney is one of the few leading AI model developers that has never taken on outside funding. At one point, Meta talked with Midjourney about acquiring the startup, according to Upstarts Media.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Midjourney was founded in 2022 and quickly became a leader in the AI image generation space for its realistic, unique style. By 2023, the startup was reportedly on pace to generate $200 million in revenue. The startup sells subscriptions starting at $10 per month. It offers pricier tiers, which offer more AI image generations, that cost as much as $120 per month. In June, the startup released its first AI video model, V1.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s partnership with Midjourney comes just two months after the startup was sued by Disney and Universal, alleging that it trained AI image models on copyrighted works. Several AI model developers — including Meta — face similar allegations from copyright holders, however, recent court cases pertaining to AI training data have sided with tech companies.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at&amp;nbsp;&lt;/em&gt;&lt;em&gt;rebecca.bellan@techcrunch.com&lt;/em&gt;&lt;em&gt;&amp;nbsp;and Maxwell Zeff at&amp;nbsp;&lt;/em&gt;&lt;em&gt;maxwell.zeff@techcrunch.com&lt;/em&gt;&lt;em&gt;. For secure communication, you can contact us via Signal at&amp;nbsp;&lt;/em&gt;&lt;em&gt;@rebeccabellan&lt;/em&gt;&lt;em&gt;.491 and&amp;nbsp;&lt;/em&gt;&lt;em&gt;@mzeff&lt;/em&gt;&lt;em&gt;.88.&lt;/em&gt;&lt;/p&gt;

&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;We’re always looking to evolve, and by providing some insight into your perspective and feedback into TechCrunch and our coverage and events, you can help us! Fill out&amp;nbsp;&lt;/em&gt;&lt;em&gt;this survey&lt;/em&gt;&lt;em&gt;&amp;nbsp;to let us know how we’re doing and get the chance to win a prize in return!&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/08/22/meta-partners-with-midjourney-on-ai-image-and-video-models/</guid><pubDate>Fri, 22 Aug 2025 21:41:31 +0000</pubDate></item><item><title>[NEW] Meta is partnering with Midjourney and will license its technology for ‘future models and products’ (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/meta-is-partnering-with-midjourney-and-will-license-its-technology-for-future-models-and-products/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Even three years after its debut, with ever increasing competition in the AI image generation space, Midjourney, the boostrapped San Francisco startup, remains the “gold standard” for its 20 million users — including us here at VentureBeat, where we use it to generate the “header” art to many of our articles. &lt;/p&gt;&lt;p&gt;Apparently, the leaders of Facebook and Instagram parent company Meta feel similarly.&lt;/p&gt;&lt;p&gt;Today, &lt;strong&gt;Alexandr Wang, the former Scale AI founder and CEO who has become Meta’s Chief AI Officer&lt;/strong&gt; and head of the company’s newly formed Meta Superintelligence Labs (MSL), announced a&lt;strong&gt; partnership with Midjourney — believed to be the first of its kind for the independent AI image startup. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Meta will “license their aesthetic technology for our future models and products, bringing beauty to billions,” Wang wrote on X, a rival social network to Meta’s own Threads and Facebook. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;1/ Today we’re proud to announce a partnership with @midjourney, to license their aesthetic technology for our future models and products, bringing beauty to billions.&lt;/p&gt;— Alexandr Wang (@alexandr_wang) August 22, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Midjourney had previously reportedly been in discussions with Elon Musk and xAI for some integration with the latter company’s Grok image generation capabilities, but xAI debuted Grok image generation powered by startup Black Forest Labs’ Flux AI image model initially, and now appears to have native image generation capabilities. &lt;/p&gt;







&lt;p&gt;Wang framed the move as part of a bigger philosophy—Meta’s “all-of-the-above” approach to building advanced AI. &lt;/p&gt;



&lt;p&gt;That means recruiting top research talent, pouring billions into computing infrastructure, and, in this case, teaming up with a company whose work complements Meta’s in ways it can’t easily build on its own. &lt;/p&gt;



&lt;p&gt;Midjourney, Wang said, has achieved “true feats of technical and aesthetic excellence,” and Meta is eager to put that expertise to work.&lt;/p&gt;



&lt;p&gt;For Midjourney, the partnership is an opportunity to see its technology woven into one of the largest digital ecosystems on the planet. &lt;/p&gt;



&lt;p&gt;But in his own X post, Midjourney founder David Holz was quick to stress what isn’t changing: the lab’s independence. &lt;/p&gt;



&lt;p&gt;He r&lt;strong&gt;eminded followers that Midjourney remains community-backed, has no outside investors, and is still pursuing an ambitious slate of projects &lt;/strong&gt;aimed at shaping what he calls more “humane futures.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Bringing sublime tools of creation and beauty to billions of people is squarely within our mission. Excited to partner with the titans of industry to make this happen. https://t.co/LJqcrDtGSz&lt;/p&gt;— David (@DavidSHolz) August 22, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We remain an independent, community-backed research lab, with no investors, working on a staggering array of ambitious projects focused on bringing about humane futures where we are all mid-journey. Join us!&lt;/p&gt;— David (@DavidSHolz) August 22, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;On paper, the tie-up makes sense. Meta brings scale, distribution, and staggering compute power. Midjourney brings a creative edge, honed through years of training models to generate imagery that resonates with actual human tastes. It’s a marriage of brute force and design flair, an alliance that could help Meta’s AI systems feel less utilitarian and more inspired.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-details-are-lacking-how-much-is-midjourney-getting-from-the-partnership"&gt;Details are lacking: how much $$$ is Midjourney getting from the partnership?&lt;/h2&gt;



&lt;p&gt;But for now, the details are hazy. Neither company has said how much the deal is worth. &lt;/p&gt;



&lt;p&gt;There’s been &lt;strong&gt;no statements as to when Midjourney’s technology will start showing up in Meta’s products, or to what degree it will be baked into the company’s AI strategy.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Is this about &lt;strong&gt;upgrading the polish of Meta’s widely mocked and recently criticized chatbots&lt;/strong&gt; — one of which a user allegedly mistook for a real person and died traveling to visit? &lt;/p&gt;



&lt;p&gt;Will it be used to enhance Meta’s virtual reality worlds? Or supercharge creative tools across Instagram and Facebook? The answers remain vague for now.&lt;/p&gt;



&lt;p&gt;Similarly, a &lt;strong&gt;big question concerns what will happen with Midjourney’s stated plans to pursue an external application programming interface (API)&lt;/strong&gt; for other enterprises to build products and services atop of its powerful image generation models.&lt;/p&gt;



&lt;p&gt;Last month, the official Midjourney account on X posted that it was “starting to investigate opening up an Enterprise API for people to start integrating Midjourney into their companies/services,” and provided an Enterprise API application questionnaire for interested parties to fill out.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We're starting to investigate opening up an Enterprise API for people to start integrating Midjourney into their companies/services. If you'd like to apply, help us figure out what to provide, or just want follow-up updates please fill out our Enterprise API application below ?&lt;/p&gt;— Midjourney (@midjourney) July 16, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;That application remains online for now, but with &lt;strong&gt;Meta inking a deal with Midjourney, the question becomes whether or not is exclusive and will stop plans for a separate Midjourney API&lt;/strong&gt; in its tracks. I messaged founder Holz and have asked about the API and will update upon receiving a response.&lt;/p&gt;







&lt;p&gt;The announcement lands against the backdrop of Meta’s massive internal shake-up. In August, the company reorganized its AI operations, creating Meta Superintelligence Labs, with Wang — who joined after Meta’s $14.3 billion investment in Scale AI — at the helm. &lt;/p&gt;



&lt;p&gt;The reorg split AI work into four core tracks: research, training, product, and infrastructure, as &lt;em&gt;Business Insider&lt;/em&gt; reported initially. &lt;/p&gt;



&lt;p&gt;Wang now oversees an elite bench of talent recruited from OpenAI, Anthropic, Google DeepMind, and beyond — recruited for eye-watering pay packages in the multi-hundred million dollar range — now tasked with pushing Meta toward its stated goal: personalized artificial superintelligence for each user.&lt;/p&gt;



&lt;p&gt;It’s an ambitious mission, and a controversial one. Some researchers inside Meta are reportedly uneasy about the pace and scope of the changes. Others see Wang’s rapid consolidation of power as both necessary and risky. What’s clear is that Meta is betting heavily on AI as its future, and the Midjourney deal is one more sign of just how expansive that bet has become.&lt;/p&gt;



&lt;p&gt;For Midjourney, aligning with Meta carries its own risks. Independence is central to its identity, and some in its community may worry that partnering with a tech giant could dilute that ethos. &lt;/p&gt;



&lt;p&gt;Holz’s messaging suggests he knows this, which may explain why he emphasized Midjourney’s continued autonomy in the same breath as announcing the deal.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;What happens next will depend on how the partnership translates from announcement to execution.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For now, the only certainty is that the ever-changing AI product landscape just took another big twist — and we’re all along for the ride. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;Even three years after its debut, with ever increasing competition in the AI image generation space, Midjourney, the boostrapped San Francisco startup, remains the “gold standard” for its 20 million users — including us here at VentureBeat, where we use it to generate the “header” art to many of our articles. &lt;/p&gt;&lt;p&gt;Apparently, the leaders of Facebook and Instagram parent company Meta feel similarly.&lt;/p&gt;&lt;p&gt;Today, &lt;strong&gt;Alexandr Wang, the former Scale AI founder and CEO who has become Meta’s Chief AI Officer&lt;/strong&gt; and head of the company’s newly formed Meta Superintelligence Labs (MSL), announced a&lt;strong&gt; partnership with Midjourney — believed to be the first of its kind for the independent AI image startup. &lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Meta will “license their aesthetic technology for our future models and products, bringing beauty to billions,” Wang wrote on X, a rival social network to Meta’s own Threads and Facebook. &lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;1/ Today we’re proud to announce a partnership with @midjourney, to license their aesthetic technology for our future models and products, bringing beauty to billions.&lt;/p&gt;— Alexandr Wang (@alexandr_wang) August 22, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;Midjourney had previously reportedly been in discussions with Elon Musk and xAI for some integration with the latter company’s Grok image generation capabilities, but xAI debuted Grok image generation powered by startup Black Forest Labs’ Flux AI image model initially, and now appears to have native image generation capabilities. &lt;/p&gt;







&lt;p&gt;Wang framed the move as part of a bigger philosophy—Meta’s “all-of-the-above” approach to building advanced AI. &lt;/p&gt;



&lt;p&gt;That means recruiting top research talent, pouring billions into computing infrastructure, and, in this case, teaming up with a company whose work complements Meta’s in ways it can’t easily build on its own. &lt;/p&gt;



&lt;p&gt;Midjourney, Wang said, has achieved “true feats of technical and aesthetic excellence,” and Meta is eager to put that expertise to work.&lt;/p&gt;



&lt;p&gt;For Midjourney, the partnership is an opportunity to see its technology woven into one of the largest digital ecosystems on the planet. &lt;/p&gt;



&lt;p&gt;But in his own X post, Midjourney founder David Holz was quick to stress what isn’t changing: the lab’s independence. &lt;/p&gt;



&lt;p&gt;He r&lt;strong&gt;eminded followers that Midjourney remains community-backed, has no outside investors, and is still pursuing an ambitious slate of projects &lt;/strong&gt;aimed at shaping what he calls more “humane futures.”&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Bringing sublime tools of creation and beauty to billions of people is squarely within our mission. Excited to partner with the titans of industry to make this happen. https://t.co/LJqcrDtGSz&lt;/p&gt;— David (@DavidSHolz) August 22, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We remain an independent, community-backed research lab, with no investors, working on a staggering array of ambitious projects focused on bringing about humane futures where we are all mid-journey. Join us!&lt;/p&gt;— David (@DavidSHolz) August 22, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;On paper, the tie-up makes sense. Meta brings scale, distribution, and staggering compute power. Midjourney brings a creative edge, honed through years of training models to generate imagery that resonates with actual human tastes. It’s a marriage of brute force and design flair, an alliance that could help Meta’s AI systems feel less utilitarian and more inspired.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-details-are-lacking-how-much-is-midjourney-getting-from-the-partnership"&gt;Details are lacking: how much $$$ is Midjourney getting from the partnership?&lt;/h2&gt;



&lt;p&gt;But for now, the details are hazy. Neither company has said how much the deal is worth. &lt;/p&gt;



&lt;p&gt;There’s been &lt;strong&gt;no statements as to when Midjourney’s technology will start showing up in Meta’s products, or to what degree it will be baked into the company’s AI strategy.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;Is this about &lt;strong&gt;upgrading the polish of Meta’s widely mocked and recently criticized chatbots&lt;/strong&gt; — one of which a user allegedly mistook for a real person and died traveling to visit? &lt;/p&gt;



&lt;p&gt;Will it be used to enhance Meta’s virtual reality worlds? Or supercharge creative tools across Instagram and Facebook? The answers remain vague for now.&lt;/p&gt;



&lt;p&gt;Similarly, a &lt;strong&gt;big question concerns what will happen with Midjourney’s stated plans to pursue an external application programming interface (API)&lt;/strong&gt; for other enterprises to build products and services atop of its powerful image generation models.&lt;/p&gt;



&lt;p&gt;Last month, the official Midjourney account on X posted that it was “starting to investigate opening up an Enterprise API for people to start integrating Midjourney into their companies/services,” and provided an Enterprise API application questionnaire for interested parties to fill out.&lt;/p&gt;



&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;We're starting to investigate opening up an Enterprise API for people to start integrating Midjourney into their companies/services. If you'd like to apply, help us figure out what to provide, or just want follow-up updates please fill out our Enterprise API application below ?&lt;/p&gt;— Midjourney (@midjourney) July 16, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;



&lt;p&gt;That application remains online for now, but with &lt;strong&gt;Meta inking a deal with Midjourney, the question becomes whether or not is exclusive and will stop plans for a separate Midjourney API&lt;/strong&gt; in its tracks. I messaged founder Holz and have asked about the API and will update upon receiving a response.&lt;/p&gt;







&lt;p&gt;The announcement lands against the backdrop of Meta’s massive internal shake-up. In August, the company reorganized its AI operations, creating Meta Superintelligence Labs, with Wang — who joined after Meta’s $14.3 billion investment in Scale AI — at the helm. &lt;/p&gt;



&lt;p&gt;The reorg split AI work into four core tracks: research, training, product, and infrastructure, as &lt;em&gt;Business Insider&lt;/em&gt; reported initially. &lt;/p&gt;



&lt;p&gt;Wang now oversees an elite bench of talent recruited from OpenAI, Anthropic, Google DeepMind, and beyond — recruited for eye-watering pay packages in the multi-hundred million dollar range — now tasked with pushing Meta toward its stated goal: personalized artificial superintelligence for each user.&lt;/p&gt;



&lt;p&gt;It’s an ambitious mission, and a controversial one. Some researchers inside Meta are reportedly uneasy about the pace and scope of the changes. Others see Wang’s rapid consolidation of power as both necessary and risky. What’s clear is that Meta is betting heavily on AI as its future, and the Midjourney deal is one more sign of just how expansive that bet has become.&lt;/p&gt;



&lt;p&gt;For Midjourney, aligning with Meta carries its own risks. Independence is central to its identity, and some in its community may worry that partnering with a tech giant could dilute that ethos. &lt;/p&gt;



&lt;p&gt;Holz’s messaging suggests he knows this, which may explain why he emphasized Midjourney’s continued autonomy in the same breath as announcing the deal.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;What happens next will depend on how the partnership translates from announcement to execution.&lt;/strong&gt;&lt;/p&gt;



&lt;p&gt;For now, the only certainty is that the ever-changing AI product landscape just took another big twist — and we’re all along for the ride. &lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/meta-is-partnering-with-midjourney-and-will-license-its-technology-for-future-models-and-products/</guid><pubDate>Fri, 22 Aug 2025 22:12:07 +0000</pubDate></item><item><title>[NEW] College student’s “time travel” AI experiment accidentally outputs real 1834 history (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/08/ai-built-from-1800s-texts-surprises-creator-by-mentioning-real-1834-london-protests/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Hobbyist training AI on Victorian texts gets an unexpected history lesson from his own creation.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A London etching of a demonstration from the late 19th century." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/1800s_protests-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A London etching of a demonstration from the late 19th century." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/1800s_protests-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A London etching of a demonstration from the late 19th century.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          pictore via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A hobbyist developer building AI language models that speak Victorian-era English "just for fun" got an unexpected history lesson this week when his latest creation mentioned real protests from 1834 London—events the developer didn't know had actually happened until he Googled them.&lt;/p&gt;
&lt;p&gt;"I was interested to see if a protest had actually occurred in 1834 London and it really did happen," wrote Reddit user Hayk Grigorian, who is a computer science student at Muhlenberg College in Pennsylvania.&lt;/p&gt;
&lt;p&gt;For the past month, Grigorian has been developing what he calls TimeCapsuleLLM, a small AI language model (like a pint-sized distant cousin to ChatGPT) which has been trained entirely on texts from 1800–1875 London. Grigorian wants to capture an authentic Victorian voice in the AI model's outputs. As a result, the AI model ends up spitting out text that's heavy with biblical references and period-appropriate rhetorical excess.&lt;/p&gt;
&lt;p&gt;Grigorian's project joins a growing field of researchers exploring what some call "Historical Large Language Models" (HLLMs) if they feature a larger base model than the small one Grigorian is using. Similar projects include MonadGPT, which was trained on 11,000 texts from 1400 to 1700 CE that can discuss topics using 17th-century knowledge frameworks, and XunziALLM, which generates classical Chinese poetry following ancient formal rules. These models offer researchers a chance to interact with the linguistic patterns and thought processes of past eras.&lt;/p&gt;
&lt;p&gt;According to Grigorian, TimeCapsuleLLM's most intriguing recent output emerged from a simple test. When he prompted it with "It was the year of our Lord 1834," the AI model—which is trained to continue text from wherever a user leaves off—generated the following:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Curious about the accuracy, Grigorian did some fact-checking. "The output also brought up Lord Palmerston," he wrote, "and after a google search I learned that his actions resulted in the 1834 protests."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The details mentioned in the AI-generated text do appear to align with historical fact: 1834 saw significant civil unrest in England following the Poor Law Amendment Act 1834, and Palmerston served as Foreign Secretary for Great Britain during this turbulent period, later becoming prime minister.&lt;/p&gt;
&lt;p&gt;On the one hand, this output is not very surprising. AI researchers who create AI language models like the kind that power ChatGPT have known for years that these models can synthesize realistic permutations of information learned from those texts. It's how every AI assistant today works.&lt;/p&gt;
&lt;p&gt;But what makes this episode especially interesting is that a small hobbyist model trained by one man appears to have surprised him by reconstructing a coherent historical moment from scattered references across thousands of documents, connecting a specific year to actual events and figures without being explicitly taught these relationships. Grigorian hadn't intentionally trained the model on 1834 protest documentation; the AI assembled these connections from the ambient patterns in 6.25GB of Victorian-era writing.&lt;/p&gt;
&lt;p&gt;"This is all from just 5-6GB of data," Grigorian wrote on Reddit. "Imagine the results with 30GB or more. I’m not sure if just scaling the data up will ever result in reasoning but even now it kinda feels like digital time travel."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Linguistic time travel through statistics&lt;/h2&gt;
&lt;p&gt;Rather than fine-tuning AI language models on modern text sources, developer Hayk Grigorian trains his hobbyist AI models from scratch using exclusively Victorian-era sources—over 7,000 books, legal documents, and newspapers published in London between 1800 and 1875.&amp;nbsp;He calls the process "Selective Temporal Training" or STT. A custom tokenizer that chops words into simplified representations for easier processing excludes modern vocabulary entirely.&lt;/p&gt;
&lt;p&gt;"If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away," Grigorian explained on GitHub about modern data contamination. "If I train from scratch the language model won't pretend to be old, it just will be."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Using architectures from the "small language models" nanoGPT and Microsoft's Phi 1.5, Grigorian has trained three AI models so far, each showing improved historical coherence. Version 0, trained on just 187MB, produced Victorian-flavored gibberish. Version 0.5 achieved grammatically correct period prose but hallucinated facts. The current 700-million parameter version, trained on a rented A100 GPU, has begun generating historical references like the one seen above.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2113480 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="An 1857 photographic portrait of Henry John Temple, also known as Lord Palmerston." class="fullwidth full" height="1318" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/1024px-Henry_John_Temple_3rd_Viscount_Palmerston.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An 1857 photographic portrait of Henry John Temple, also known as Lord Palmerston.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Herbert Watkins (Public Domain)

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Grigorian is finding a reduction in confabulations over time as the emergent effect of scaling the size of high-quality training data, a well-known effect among AI researchers, especially when the models are very small. "Earlier models (v0 and v0.5) could mimic writing styles of the 19th century but would always hallucinate events, people, and facts," Grigorian wrote on Github. "This shows the model is beginning to remember things from the dataset."&lt;/p&gt;
&lt;p&gt;For historians and digital humanities researchers, these kinds of experiments may be useful. Training AI language models on period texts may allow for the creation of interactive period linguistic models that offer a researcher a chance to converse with a simulated speaker of an extinct vernacular or language of the past.&amp;nbsp;The results would not necessarily be factually rigorous due to confabulations, but they could be stylistically illuminating for someone studying antique syntax or vocabulary in use.&lt;/p&gt;
&lt;p&gt;"I want to eventually try different cities also, maybe a Chinese, Russian, or Indian city model," Grigorian wrote, inviting collaboration with others on future AI models he might train. He makes the code, AI model weights, and documentation of his work publicly available on GitHub.&lt;/p&gt;
&lt;p&gt;In an era of frequent AI confabulations, there's something refreshing about a model that accidentally tells the truth about the past. It's almost the opposite of hallucination—an AI model accidentally getting something correct. Call it a "factcident."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Hobbyist training AI on Victorian texts gets an unexpected history lesson from his own creation.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A London etching of a demonstration from the late 19th century." class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/1800s_protests-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A London etching of a demonstration from the late 19th century." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/1800s_protests-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A London etching of a demonstration from the late 19th century.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          pictore via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A hobbyist developer building AI language models that speak Victorian-era English "just for fun" got an unexpected history lesson this week when his latest creation mentioned real protests from 1834 London—events the developer didn't know had actually happened until he Googled them.&lt;/p&gt;
&lt;p&gt;"I was interested to see if a protest had actually occurred in 1834 London and it really did happen," wrote Reddit user Hayk Grigorian, who is a computer science student at Muhlenberg College in Pennsylvania.&lt;/p&gt;
&lt;p&gt;For the past month, Grigorian has been developing what he calls TimeCapsuleLLM, a small AI language model (like a pint-sized distant cousin to ChatGPT) which has been trained entirely on texts from 1800–1875 London. Grigorian wants to capture an authentic Victorian voice in the AI model's outputs. As a result, the AI model ends up spitting out text that's heavy with biblical references and period-appropriate rhetorical excess.&lt;/p&gt;
&lt;p&gt;Grigorian's project joins a growing field of researchers exploring what some call "Historical Large Language Models" (HLLMs) if they feature a larger base model than the small one Grigorian is using. Similar projects include MonadGPT, which was trained on 11,000 texts from 1400 to 1700 CE that can discuss topics using 17th-century knowledge frameworks, and XunziALLM, which generates classical Chinese poetry following ancient formal rules. These models offer researchers a chance to interact with the linguistic patterns and thought processes of past eras.&lt;/p&gt;
&lt;p&gt;According to Grigorian, TimeCapsuleLLM's most intriguing recent output emerged from a simple test. When he prompted it with "It was the year of our Lord 1834," the AI model—which is trained to continue text from wherever a user leaves off—generated the following:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;It was the year of our Lord 1834 and the streets of London were filled with protest and petition. The cause, as many re counted, was not bound in the way of private, but having taken up the same day in the day of Lord Palmerston, the public will receive a short statement of the difficulties under which the day of law has reached us. It is a matter of deep regret, that the present events in the history of the world are clear, and consequently will be'known. It is not true that the very men who first settled in the Gospel at Jerusalem should have so extensive and so interesting a record of the prosperity and prosperity&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Curious about the accuracy, Grigorian did some fact-checking. "The output also brought up Lord Palmerston," he wrote, "and after a google search I learned that his actions resulted in the 1834 protests."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The details mentioned in the AI-generated text do appear to align with historical fact: 1834 saw significant civil unrest in England following the Poor Law Amendment Act 1834, and Palmerston served as Foreign Secretary for Great Britain during this turbulent period, later becoming prime minister.&lt;/p&gt;
&lt;p&gt;On the one hand, this output is not very surprising. AI researchers who create AI language models like the kind that power ChatGPT have known for years that these models can synthesize realistic permutations of information learned from those texts. It's how every AI assistant today works.&lt;/p&gt;
&lt;p&gt;But what makes this episode especially interesting is that a small hobbyist model trained by one man appears to have surprised him by reconstructing a coherent historical moment from scattered references across thousands of documents, connecting a specific year to actual events and figures without being explicitly taught these relationships. Grigorian hadn't intentionally trained the model on 1834 protest documentation; the AI assembled these connections from the ambient patterns in 6.25GB of Victorian-era writing.&lt;/p&gt;
&lt;p&gt;"This is all from just 5-6GB of data," Grigorian wrote on Reddit. "Imagine the results with 30GB or more. I’m not sure if just scaling the data up will ever result in reasoning but even now it kinda feels like digital time travel."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Linguistic time travel through statistics&lt;/h2&gt;
&lt;p&gt;Rather than fine-tuning AI language models on modern text sources, developer Hayk Grigorian trains his hobbyist AI models from scratch using exclusively Victorian-era sources—over 7,000 books, legal documents, and newspapers published in London between 1800 and 1875.&amp;nbsp;He calls the process "Selective Temporal Training" or STT. A custom tokenizer that chops words into simplified representations for easier processing excludes modern vocabulary entirely.&lt;/p&gt;
&lt;p&gt;"If I fine-tune something like GPT-2, it's already pre-trained and that information won't go away," Grigorian explained on GitHub about modern data contamination. "If I train from scratch the language model won't pretend to be old, it just will be."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Using architectures from the "small language models" nanoGPT and Microsoft's Phi 1.5, Grigorian has trained three AI models so far, each showing improved historical coherence. Version 0, trained on just 187MB, produced Victorian-flavored gibberish. Version 0.5 achieved grammatically correct period prose but hallucinated facts. The current 700-million parameter version, trained on a rented A100 GPU, has begun generating historical references like the one seen above.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2113480 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="An 1857 photographic portrait of Henry John Temple, also known as Lord Palmerston." class="fullwidth full" height="1318" src="https://cdn.arstechnica.net/wp-content/uploads/2025/08/1024px-Henry_John_Temple_3rd_Viscount_Palmerston.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An 1857 photographic portrait of Henry John Temple, also known as Lord Palmerston.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Herbert Watkins (Public Domain)

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Grigorian is finding a reduction in confabulations over time as the emergent effect of scaling the size of high-quality training data, a well-known effect among AI researchers, especially when the models are very small. "Earlier models (v0 and v0.5) could mimic writing styles of the 19th century but would always hallucinate events, people, and facts," Grigorian wrote on Github. "This shows the model is beginning to remember things from the dataset."&lt;/p&gt;
&lt;p&gt;For historians and digital humanities researchers, these kinds of experiments may be useful. Training AI language models on period texts may allow for the creation of interactive period linguistic models that offer a researcher a chance to converse with a simulated speaker of an extinct vernacular or language of the past.&amp;nbsp;The results would not necessarily be factually rigorous due to confabulations, but they could be stylistically illuminating for someone studying antique syntax or vocabulary in use.&lt;/p&gt;
&lt;p&gt;"I want to eventually try different cities also, maybe a Chinese, Russian, or Indian city model," Grigorian wrote, inviting collaboration with others on future AI models he might train. He makes the code, AI model weights, and documentation of his work publicly available on GitHub.&lt;/p&gt;
&lt;p&gt;In an era of frequent AI confabulations, there's something refreshing about a model that accidentally tells the truth about the past. It's almost the opposite of hallucination—an AI model accidentally getting something correct. Call it a "factcident."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/08/ai-built-from-1800s-texts-surprises-creator-by-mentioning-real-1834-london-protests/</guid><pubDate>Fri, 22 Aug 2025 22:13:56 +0000</pubDate></item><item><title>[NEW] OpenCUA’s open source computer-use agents rival proprietary models from OpenAI and Anthropic (AI News | VentureBeat)</title><link>https://venturebeat.com/ai/opencuas-open-source-computer-use-agents-rival-proprietary-models-from-openai-and-anthropic/</link><description>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new framework from researchers at The University of Hong Kong (HKU) and collaborating institutions provides an open source foundation for creating robust AI agents that can operate computers. The framework, called OpenCUA, includes the tools, data, and recipes for scaling the development of computer-use agents (CUAs).&lt;/p&gt;&lt;p&gt;Models trained using this framework perform strongly on CUA benchmarks, outperforming existing open source models and competing closely with closed agents from leading AI labs like OpenAI and Anthropic.&lt;/p&gt;&lt;p&gt;Computer-use agents are designed to autonomously complete tasks on a computer, from navigating websites to operating complex software. They can also help automate workflows in the enterprise. However, the most capable CUA systems are proprietary, with critical details about their training data, architectures, and development processes kept private.&lt;/p&gt;&lt;p&gt;“As the lack of transparency limits technical advancements and raises safety concerns, the research community needs truly open CUA frameworks to study their capabilities, limitations, and risks,” the researchers state in their paper.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;At the same time, open source efforts face their own set of hurdles. There has been no scalable infrastructure for collecting the diverse, large-scale data needed to train these agents. Existing open source datasets for graphical user interfaces (GUIs) have limited data, and many research projects provide insufficient detail about their methods, making it difficult for others to replicate their work.&lt;/p&gt;



&lt;p&gt;According to the paper, “These limitations collectively hinder advances in general-purpose CUAs and restrict a meaningful exploration of their scalability, generalizability, and potential learning approaches.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-introducing-opencua"&gt;Introducing OpenCUA&lt;/h2&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016003" height="412" src="https://venturebeat.com/wp-content/uploads/2025/08/image_7fdde4.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;OpenCUA framework Source: XLANG Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;OpenCUA is an open source framework designed to address these challenges by scaling both the data collection and the models themselves. At its core is the AgentNet Tool for recording human demonstrations of computer tasks on different operating systems.&lt;/p&gt;



&lt;p&gt;The tool streamlines data collection by running in the background on an annotator’s personal computer, capturing screen videos, mouse and keyboard inputs, and the underlying accessibility tree, which provides structured information about on-screen elements. This raw data is then processed into “state-action trajectories,” pairing a screenshot of the computer (the state) with the user’s corresponding action (a click, key press, etc.). Annotators can then review, edit, and submit these demonstrations.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016004" height="336" src="https://venturebeat.com/wp-content/uploads/2025/08/image_05f5eb.png" width="684" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;AgentNet tool Source: XLang Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Using this tool, the researchers collected the AgentNet dataset, which contains over 22,600 task demonstrations across Windows, macOS, and Ubuntu, spanning more than 200 applications and websites. “This dataset authentically captures the complexity of human behaviors and environmental dynamics from users’ personal computing environments,” the paper notes.&lt;/p&gt;



&lt;p&gt;Recognizing that screen-recording tools raise significant data privacy concerns for enterprises, the researchers designed the AgentNet Tool with security in mind. Xinyuan Wang, co-author of the paper and PhD student at HKU, explained that they implemented a multi-layer privacy protection framework. “First, annotators themselves can fully observe the data they generate… before deciding whether to submit it,” he told VentureBeat. The data then undergoes manual verification for privacy issues and automated scanning by a large model to detect any remaining sensitive content before release. “This layered process ensures enterprise-grade robustness for environments handling sensitive customer or financial data,” Wang added.&lt;/p&gt;



&lt;p&gt;To accelerate evaluation, the team also curated AgentNetBench, an offline benchmark that provides multiple correct actions for each step, offering a more efficient way to measure an agent’s performance.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-recipe-for-training-agents"&gt;A new recipe for training agents&lt;/h2&gt;



&lt;p&gt;The OpenCUA framework introduces a novel pipeline for processing data and training computer-use agents. The first step converts the raw human demonstrations into clean state-action pairs suitable for training vision-language models (VLMs). However, the researchers found that simply training models on these pairs yields limited performance gains, even with large amounts of data.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016005" height="199" src="https://venturebeat.com/wp-content/uploads/2025/08/image_fb4236.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;OpenCUA chain-of-thought pipeline Source: XLang Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The key insight was to augment these trajectories with chain-of-thought (CoT) reasoning. This process generates a detailed “inner monologue” for each action, which includes planning, memory, and reflection. This structured reasoning is organized into three levels: a high-level observation of the screen, reflective thoughts that analyze the situation and plan the next steps, and finally, the concise, executable action. This approach helps the agent develop a deeper understanding of the tasks.&lt;/p&gt;



&lt;p&gt;“We find natural language reasoning crucial for generalizable computer-use foundation models, helping CUAs internalize cognitive capabilities,” the researchers write.&lt;/p&gt;



&lt;p&gt;This data synthesis pipeline is a general framework that can be adapted by companies to train agents on their own unique internal tools. According to Wang, an enterprise can record demonstrations of its proprietary workflows and use the same “reflector” and “generator” pipeline to create the necessary training data. “This allows them to bootstrap a high-performing agent tailored to their internal tools without needing to handcraft reasoning traces manually,” he explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-putting-opencua-to-the-test"&gt;Putting OpenCUA to the test&lt;/h2&gt;



&lt;p&gt;The researchers applied the OpenCUA framework to train a range of open source VLMs, including variants of Qwen and Kimi-VL, with parameter sizes from 3 billion to 32 billion. The models were evaluated on a suite of online and offline benchmarks that test their ability to perform tasks and understand GUIs.&lt;/p&gt;



&lt;p&gt;The 32-billion-parameter model, OpenCUA-32B, established a new state-of-the-art success rate among open source models on the OSWorld-Verified benchmark. It also surpassed OpenAI’s GPT-4o-based CUA and significantly closed the performance gap with Anthropic’s leading proprietary models.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016002" height="338" src="https://venturebeat.com/wp-content/uploads/2025/08/image_e2e708.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;OpenCUA shows massive improvement over base models (left) while competing with leading CUA models (right) Source: XLANG Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;For enterprise developers and product leaders, the research offers several key findings. The OpenCUA method is broadly applicable, improving performance on models with different architectures (both dense and mixture-of-experts) and sizes. The trained agents also show strong generalization, performing well across a diverse range of tasks and operating systems.&lt;/p&gt;



&lt;p&gt;According to Wang, the framework is particularly suited for automating repetitive, labor-intensive enterprise workflows. “For example, in the AgentNet dataset, we already capture a few demonstrations of launching EC2 instances on Amazon AWS and configuring annotation parameters on MTurk,” he told VentureBeat. “These tasks involve many sequential steps but follow repeatable patterns.”&lt;/p&gt;



&lt;p&gt;However, Wang noted that bridging the gap to live deployment requires addressing key challenges around safety and reliability. “The biggest challenge in real deployment is safety and reliability: the agent must avoid mistakes that could inadvertently alter system settings or trigger harmful side effects beyond the intended task,” he said.&lt;/p&gt;



&lt;p&gt;The researchers have released the code, dataset, and weights for their models.&lt;/p&gt;



&lt;p&gt;As open source agents built on frameworks like OpenCUA become more capable, they could fundamentally evolve the relationship between knowledge workers and their computers. Wang envisions a future where proficiency in complex software becomes less important than the ability to clearly articulate goals to an AI agent.&lt;/p&gt;



&lt;p&gt;He described two primary modes of work: “offline automation, where the agent leverages its broader software knowledge to pursue a task end-to-end,” and “online collaboration, where the agent responds in real-time and works side by side with the human, much like a colleague.” Basically, the humans will provide the strategic “what,” while increasingly sophisticated AI agents handle the operational “how.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</description><content:encoded>&lt;div id="boilerplate_2682874"&gt;&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;em&gt;Want smarter insights in your inbox? Sign up for our weekly newsletters to get only what matters to enterprise AI, data, and security leaders.&lt;/em&gt; &lt;em&gt;Subscribe Now&lt;/em&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator {"opacity":"css","className":"is-style-wide"} --&gt;
&lt;hr class="wp-block-separator has-css-opacity is-style-wide" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;A new framework from researchers at The University of Hong Kong (HKU) and collaborating institutions provides an open source foundation for creating robust AI agents that can operate computers. The framework, called OpenCUA, includes the tools, data, and recipes for scaling the development of computer-use agents (CUAs).&lt;/p&gt;&lt;p&gt;Models trained using this framework perform strongly on CUA benchmarks, outperforming existing open source models and competing closely with closed agents from leading AI labs like OpenAI and Anthropic.&lt;/p&gt;&lt;p&gt;Computer-use agents are designed to autonomously complete tasks on a computer, from navigating websites to operating complex software. They can also help automate workflows in the enterprise. However, the most capable CUA systems are proprietary, with critical details about their training data, architectures, and development processes kept private.&lt;/p&gt;&lt;p&gt;“As the lack of transparency limits technical advancements and raises safety concerns, the research community needs truly open CUA frameworks to study their capabilities, limitations, and risks,” the researchers state in their paper.&lt;/p&gt;&lt;div id="id"&gt;&lt;div class="post-boilerplate boilerplate-speedbump" id="boilerplate_2803147"&gt;&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;&lt;/strong&gt;&lt;strong&gt;AI Scaling Hits Its Limits&lt;/strong&gt;&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;Power caps, rising token costs, and inference delays are reshaping enterprise AI. Join our exclusive salon to discover how top teams are:&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:list --&gt;
&lt;ul class="wp-block-list"&gt;&lt;!-- wp:list-item --&gt;
&lt;li&gt;Turning energy into a strategic advantage&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Architecting efficient inference for real throughput gains&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;

&lt;!-- wp:list-item --&gt;
&lt;li&gt;Unlocking competitive ROI with sustainable AI systems&lt;/li&gt;
&lt;!-- /wp:list-item --&gt;&lt;/ul&gt;
&lt;!-- /wp:list --&gt;

&lt;!-- wp:paragraph --&gt;
&lt;p&gt;&lt;strong&gt;Secure your spot to stay ahead&lt;/strong&gt;: https://bit.ly/4mwGngO&lt;/p&gt;
&lt;!-- /wp:paragraph --&gt;

&lt;!-- wp:separator --&gt;
&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;
&lt;!-- /wp:separator --&gt;&lt;/div&gt;&lt;p&gt;At the same time, open source efforts face their own set of hurdles. There has been no scalable infrastructure for collecting the diverse, large-scale data needed to train these agents. Existing open source datasets for graphical user interfaces (GUIs) have limited data, and many research projects provide insufficient detail about their methods, making it difficult for others to replicate their work.&lt;/p&gt;



&lt;p&gt;According to the paper, “These limitations collectively hinder advances in general-purpose CUAs and restrict a meaningful exploration of their scalability, generalizability, and potential learning approaches.”&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-introducing-opencua"&gt;Introducing OpenCUA&lt;/h2&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016003" height="412" src="https://venturebeat.com/wp-content/uploads/2025/08/image_7fdde4.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;OpenCUA framework Source: XLANG Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;OpenCUA is an open source framework designed to address these challenges by scaling both the data collection and the models themselves. At its core is the AgentNet Tool for recording human demonstrations of computer tasks on different operating systems.&lt;/p&gt;



&lt;p&gt;The tool streamlines data collection by running in the background on an annotator’s personal computer, capturing screen videos, mouse and keyboard inputs, and the underlying accessibility tree, which provides structured information about on-screen elements. This raw data is then processed into “state-action trajectories,” pairing a screenshot of the computer (the state) with the user’s corresponding action (a click, key press, etc.). Annotators can then review, edit, and submit these demonstrations.&lt;/p&gt;



&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-3016004" height="336" src="https://venturebeat.com/wp-content/uploads/2025/08/image_05f5eb.png" width="684" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;AgentNet tool Source: XLang Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;Using this tool, the researchers collected the AgentNet dataset, which contains over 22,600 task demonstrations across Windows, macOS, and Ubuntu, spanning more than 200 applications and websites. “This dataset authentically captures the complexity of human behaviors and environmental dynamics from users’ personal computing environments,” the paper notes.&lt;/p&gt;



&lt;p&gt;Recognizing that screen-recording tools raise significant data privacy concerns for enterprises, the researchers designed the AgentNet Tool with security in mind. Xinyuan Wang, co-author of the paper and PhD student at HKU, explained that they implemented a multi-layer privacy protection framework. “First, annotators themselves can fully observe the data they generate… before deciding whether to submit it,” he told VentureBeat. The data then undergoes manual verification for privacy issues and automated scanning by a large model to detect any remaining sensitive content before release. “This layered process ensures enterprise-grade robustness for environments handling sensitive customer or financial data,” Wang added.&lt;/p&gt;



&lt;p&gt;To accelerate evaluation, the team also curated AgentNetBench, an offline benchmark that provides multiple correct actions for each step, offering a more efficient way to measure an agent’s performance.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-a-new-recipe-for-training-agents"&gt;A new recipe for training agents&lt;/h2&gt;



&lt;p&gt;The OpenCUA framework introduces a novel pipeline for processing data and training computer-use agents. The first step converts the raw human demonstrations into clean state-action pairs suitable for training vision-language models (VLMs). However, the researchers found that simply training models on these pairs yields limited performance gains, even with large amounts of data.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016005" height="199" src="https://venturebeat.com/wp-content/uploads/2025/08/image_fb4236.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;OpenCUA chain-of-thought pipeline Source: XLang Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;The key insight was to augment these trajectories with chain-of-thought (CoT) reasoning. This process generates a detailed “inner monologue” for each action, which includes planning, memory, and reflection. This structured reasoning is organized into three levels: a high-level observation of the screen, reflective thoughts that analyze the situation and plan the next steps, and finally, the concise, executable action. This approach helps the agent develop a deeper understanding of the tasks.&lt;/p&gt;



&lt;p&gt;“We find natural language reasoning crucial for generalizable computer-use foundation models, helping CUAs internalize cognitive capabilities,” the researchers write.&lt;/p&gt;



&lt;p&gt;This data synthesis pipeline is a general framework that can be adapted by companies to train agents on their own unique internal tools. According to Wang, an enterprise can record demonstrations of its proprietary workflows and use the same “reflector” and “generator” pipeline to create the necessary training data. “This allows them to bootstrap a high-performing agent tailored to their internal tools without needing to handcraft reasoning traces manually,” he explained.&lt;/p&gt;



&lt;h2 class="wp-block-heading" id="h-putting-opencua-to-the-test"&gt;Putting OpenCUA to the test&lt;/h2&gt;



&lt;p&gt;The researchers applied the OpenCUA framework to train a range of open source VLMs, including variants of Qwen and Kimi-VL, with parameter sizes from 3 billion to 32 billion. The models were evaluated on a suite of online and offline benchmarks that test their ability to perform tasks and understand GUIs.&lt;/p&gt;



&lt;p&gt;The 32-billion-parameter model, OpenCUA-32B, established a new state-of-the-art success rate among open source models on the OSWorld-Verified benchmark. It also surpassed OpenAI’s GPT-4o-based CUA and significantly closed the performance gap with Anthropic’s leading proprietary models.&lt;/p&gt;



&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3016002" height="338" src="https://venturebeat.com/wp-content/uploads/2025/08/image_e2e708.png?w=800" width="800" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;em&gt;OpenCUA shows massive improvement over base models (left) while competing with leading CUA models (right) Source: XLANG Lab at HKU&lt;/em&gt;&lt;/figcaption&gt;&lt;/figure&gt;



&lt;p&gt;For enterprise developers and product leaders, the research offers several key findings. The OpenCUA method is broadly applicable, improving performance on models with different architectures (both dense and mixture-of-experts) and sizes. The trained agents also show strong generalization, performing well across a diverse range of tasks and operating systems.&lt;/p&gt;



&lt;p&gt;According to Wang, the framework is particularly suited for automating repetitive, labor-intensive enterprise workflows. “For example, in the AgentNet dataset, we already capture a few demonstrations of launching EC2 instances on Amazon AWS and configuring annotation parameters on MTurk,” he told VentureBeat. “These tasks involve many sequential steps but follow repeatable patterns.”&lt;/p&gt;



&lt;p&gt;However, Wang noted that bridging the gap to live deployment requires addressing key challenges around safety and reliability. “The biggest challenge in real deployment is safety and reliability: the agent must avoid mistakes that could inadvertently alter system settings or trigger harmful side effects beyond the intended task,” he said.&lt;/p&gt;



&lt;p&gt;The researchers have released the code, dataset, and weights for their models.&lt;/p&gt;



&lt;p&gt;As open source agents built on frameworks like OpenCUA become more capable, they could fundamentally evolve the relationship between knowledge workers and their computers. Wang envisions a future where proficiency in complex software becomes less important than the ability to clearly articulate goals to an AI agent.&lt;/p&gt;



&lt;p&gt;He described two primary modes of work: “offline automation, where the agent leverages its broader software knowledge to pursue a task end-to-end,” and “online collaboration, where the agent responds in real-time and works side by side with the human, much like a colleague.” Basically, the humans will provide the strategic “what,” while increasingly sophisticated AI agents handle the operational “how.”&lt;/p&gt;
&lt;div class="post-boilerplate boilerplate-after" id="boilerplate_2660155"&gt;&lt;!-- wp:shortcode --&gt;
		&lt;div class="Boilerplate__newsletter-container vb"&gt;
			&lt;div class="Boilerplate__newsletter-main"&gt;
				&lt;p&gt;&lt;strong&gt;Daily insights on business use cases with VB Daily&lt;/strong&gt;&lt;/p&gt;
				&lt;p class="copy"&gt;If you want to impress your boss, VB Daily has you covered. We give you the inside scoop on what companies are doing with generative AI, from regulatory shifts to practical deployments, so you can share insights for maximum ROI.&lt;/p&gt;
				
				&lt;p class="Form__newsletter-legal"&gt;Read our Privacy Policy&lt;/p&gt;
				&lt;p class="Form__success" id="boilerplateNewsletterConfirmation"&gt;
					Thanks for subscribing. Check out more VB newsletters here.
				&lt;/p&gt;
				&lt;p class="Form__error"&gt;An error occured.&lt;/p&gt;
			&lt;/div&gt;

							&lt;div class="image-container"&gt;
					&lt;img alt="alt" src="https://venturebeat.com/wp-content/themes/vb-news/brand/img/vb-daily-phone.png" /&gt;
				&lt;/div&gt;
			
		&lt;/div&gt;
		
&lt;!-- /wp:shortcode --&gt;&lt;/div&gt;			&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/opencuas-open-source-computer-use-agents-rival-proprietary-models-from-openai-and-anthropic/</guid><pubDate>Fri, 22 Aug 2025 23:25:35 +0000</pubDate></item></channel></rss>