<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 29 Oct 2025 06:34:02 +0000</lastBuildDate><item><title>Sam Altman says OpenAI will have a ‘legitimate AI researcher’ by 2028 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/sam-altman-says-openai-will-have-a-legitimate-ai-researcher-by-2028/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-28-at-10.53.15AM.png?resize=1200,671" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI says its deep learning systems are rapidly advancing, with models increasingly able to solve complex tasks faster. So fast, in fact, that internally, OpenAI is tracking toward achieving an intern-level research assistant by September 2026 and a fully automated “legitimate AI researcher” by 2028, CEO Sam Altman said during a livestream Tuesday. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ambitious timeline comes on the same day OpenAI finalized its transition to a public benefit corporation structure, moving away from its non-profit roots. This restructuring releases OpenAI from limitations tied to its non-profit charter, while also opening up new opportunities for capital raising.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jakub Pachocki, OpenAI’s chief scientist, joined Altman on the livestream. He described this AI researcher — not to be confused with a human who researches AI — as a “system capable of autonomously delivering on larger research projects.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe that it is possible that deep learning systems are less than a decade away from superintelligence,” Pachocki added. He described superintelligence as systems smarter than humans across a large number of critical actions. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To achieve those goals, OpenAI is betting on two key strategies: continued algorithmic innovation and dramatically scaling up “test time compute” — essentially how long models spend thinking about problems. Current models can handle tasks with a roughly five-hour time horizon and match top human performers in competitions like the International Mathematical Olympiad, Pachocki said. But he believes this horizon will extend rapidly, in part by allowing models to spend far more computational resources thinking through complex problems. For major scientific breakthroughs, he said, it would be worth dedicating entire data centers’ worth of computing power to a single problem.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says these goals are in line with the firm’s overall push to advance scientific research and allow AI to potentially make discoveries faster than human researchers, tackle complex problems beyond current human capabilities, and dramatically speed up technological innovation across multiple fields like medicine, physics, and technology development. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also said the restructuring creates a framework to support OpenAI’s aggressive timeline for AI research assistants while maintaining a commitment to responsible AI development. Under the new structure, the non-profit OpenAI Foundation, which is focused on scientific advancement, will own 26% of the for-profit and will govern the research direction. The non-profit also has a $25 billion commitment to use AI for curing diseases and will help manage AI research and safety initiatives. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Per Altman, the for-profit arm’s ability to raise more funds means it can scale the necessary infrastructure buildout to achieve scientific advancements. Altman said OpenAI has committed to 30 gigawatts of infrastructure, which is a $1.4 trillion financial obligation, over the next few years. &amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/Screenshot-2025-10-28-at-10.53.15AM.png?resize=1200,671" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI says its deep learning systems are rapidly advancing, with models increasingly able to solve complex tasks faster. So fast, in fact, that internally, OpenAI is tracking toward achieving an intern-level research assistant by September 2026 and a fully automated “legitimate AI researcher” by 2028, CEO Sam Altman said during a livestream Tuesday. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The ambitious timeline comes on the same day OpenAI finalized its transition to a public benefit corporation structure, moving away from its non-profit roots. This restructuring releases OpenAI from limitations tied to its non-profit charter, while also opening up new opportunities for capital raising.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jakub Pachocki, OpenAI’s chief scientist, joined Altman on the livestream. He described this AI researcher — not to be confused with a human who researches AI — as a “system capable of autonomously delivering on larger research projects.” &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe that it is possible that deep learning systems are less than a decade away from superintelligence,” Pachocki added. He described superintelligence as systems smarter than humans across a large number of critical actions. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To achieve those goals, OpenAI is betting on two key strategies: continued algorithmic innovation and dramatically scaling up “test time compute” — essentially how long models spend thinking about problems. Current models can handle tasks with a roughly five-hour time horizon and match top human performers in competitions like the International Mathematical Olympiad, Pachocki said. But he believes this horizon will extend rapidly, in part by allowing models to spend far more computational resources thinking through complex problems. For major scientific breakthroughs, he said, it would be worth dedicating entire data centers’ worth of computing power to a single problem.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says these goals are in line with the firm’s overall push to advance scientific research and allow AI to potentially make discoveries faster than human researchers, tackle complex problems beyond current human capabilities, and dramatically speed up technological innovation across multiple fields like medicine, physics, and technology development. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also said the restructuring creates a framework to support OpenAI’s aggressive timeline for AI research assistants while maintaining a commitment to responsible AI development. Under the new structure, the non-profit OpenAI Foundation, which is focused on scientific advancement, will own 26% of the for-profit and will govern the research direction. The non-profit also has a $25 billion commitment to use AI for curing diseases and will help manage AI research and safety initiatives. &amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Per Altman, the for-profit arm’s ability to raise more funds means it can scale the necessary infrastructure buildout to achieve scientific advancements. Altman said OpenAI has committed to 30 gigawatts of infrastructure, which is a $1.4 trillion financial obligation, over the next few years. &amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/sam-altman-says-openai-will-have-a-legitimate-ai-researcher-by-2028/</guid><pubDate>Tue, 28 Oct 2025 18:46:46 +0000</pubDate></item><item><title>NVIDIA GTC Washington, DC: Live Updates on What’s Next in AI (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/nvidia-gtc-washington-dc-2025-news/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/keynoterecap-featuredimag-updated-scaled.jpg" /&gt;&lt;/div&gt;&lt;h3&gt;Announcing Omniverse DSX — Blueprint for Gigascale AI Factories&lt;/h3&gt;&lt;p&gt;Huang also introduced Omniverse DSX, a comprehensive blueprint for designing and operating 100 megawatt to multi‑gigawatt AI factories — validated at the AI Factory Research Center in Manassas, Virginia.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DSX Flex for dynamic grid collaboration&lt;/li&gt;
&lt;li&gt;DSX Boost for performance-per-watt optimization&lt;/li&gt;
&lt;li&gt;DSX Exchange for unified IT/OT integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“AI infrastructure is an ecosystem-scale challenge requiring hundreds of companies to collaborate. The NVIDIA Omniverse DSX is a blueprint for building and operating gigascale AI factories,” Huang said. “With DSX, NVIDIA partners around the world can build and bring up AI infrastructure faster than ever.”&lt;/p&gt;
&lt;h3&gt;NVIDIA Open Models, Data, Libraries&lt;/h3&gt;
&lt;p&gt;Open source and open models drive innovation for startups, enterprises and researchers worldwide, Huang explained. NVIDIA contributes across model families and data — hundreds of open models and datasets this year alone.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;NVIDIA model families include Nemotron (for agentic and reasoning AI), Cosmos (for synthetic data generation and physical AI), Isaac GR00T (for robotics skills and generalization) and Clara (for biomedical workflows) to power agentic AI, robotics and scientific breakthroughs.&lt;/p&gt;
&lt;p&gt;“We are dedicated to this, and the reason for that is because science needs it, researchers need it, startups need it and companies need it,” Huang said, receiving wide applause from the crowd.&lt;/p&gt;
&lt;p&gt;Huang then went on to highlight the work of AI startups built on NVIDIA, as well as work from Google, Microsoft Azure, Oracle, ServiceNow, SAP, Synopsys, Cadence, CrowdStrike and Palantir.&lt;/p&gt;
&lt;p&gt;Huang announced NVIDIA is partnering with CrowdStrike to make cybersecurity “speed of light,” enabling enterprises to deploy specialized security agents from cloud to edge using NVIDIA Nemotron‑based models and NVIDIA NeMo tooling.&lt;/p&gt;
&lt;p&gt;He also announced that NVIDIA and Palantir are integrating accelerated computing, CUDA‑X libraries and Nemotron open models into Palantir Ontology to “data processing at a much, much larger scale and with more speed.”&lt;/p&gt;
&lt;h3&gt;NVIDIA and Global Leaders Build a Digital Twin Platform for US Reindustrialization&lt;/h3&gt;
&lt;p&gt;Physical AI is powering America’s reindustrialization — transforming factories, logistics and infrastructure with robotics and intelligent systems. In a video, Huang highlighted how partners are putting it to work.&lt;/p&gt;
&lt;p&gt;“The factory is essentially a robot that’s orchestrating robots to build things that are robotic,” he said. “The amount of software necessary to do this is so intense that unless you could do it inside a digital twin, the hopes of getting this to work is nearly impossible.”&lt;/p&gt;
&lt;p&gt;From the stage, Huang called out the work of Foxconn, which is using Omniverse tools to design and validate a new Houston facility for manufacturing NVIDIA AI infrastructure systems; Caterpillar — which is also incorporating digital twins for manufacturing; Brett Adcock who founded a company three and a half year ago, Figure AI, building humanoid robots for the home and workforce, that is now worth almost $4 billion; Johnson &amp;amp; Johnson; and Disney, which is using Omniverse to train the “cutest robot ever.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/10/keynoterecap-featuredimag-updated-scaled.jpg" /&gt;&lt;/div&gt;&lt;h3&gt;Announcing Omniverse DSX — Blueprint for Gigascale AI Factories&lt;/h3&gt;&lt;p&gt;Huang also introduced Omniverse DSX, a comprehensive blueprint for designing and operating 100 megawatt to multi‑gigawatt AI factories — validated at the AI Factory Research Center in Manassas, Virginia.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;DSX Flex for dynamic grid collaboration&lt;/li&gt;
&lt;li&gt;DSX Boost for performance-per-watt optimization&lt;/li&gt;
&lt;li&gt;DSX Exchange for unified IT/OT integration&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;“AI infrastructure is an ecosystem-scale challenge requiring hundreds of companies to collaborate. The NVIDIA Omniverse DSX is a blueprint for building and operating gigascale AI factories,” Huang said. “With DSX, NVIDIA partners around the world can build and bring up AI infrastructure faster than ever.”&lt;/p&gt;
&lt;h3&gt;NVIDIA Open Models, Data, Libraries&lt;/h3&gt;
&lt;p&gt;Open source and open models drive innovation for startups, enterprises and researchers worldwide, Huang explained. NVIDIA contributes across model families and data — hundreds of open models and datasets this year alone.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;NVIDIA model families include Nemotron (for agentic and reasoning AI), Cosmos (for synthetic data generation and physical AI), Isaac GR00T (for robotics skills and generalization) and Clara (for biomedical workflows) to power agentic AI, robotics and scientific breakthroughs.&lt;/p&gt;
&lt;p&gt;“We are dedicated to this, and the reason for that is because science needs it, researchers need it, startups need it and companies need it,” Huang said, receiving wide applause from the crowd.&lt;/p&gt;
&lt;p&gt;Huang then went on to highlight the work of AI startups built on NVIDIA, as well as work from Google, Microsoft Azure, Oracle, ServiceNow, SAP, Synopsys, Cadence, CrowdStrike and Palantir.&lt;/p&gt;
&lt;p&gt;Huang announced NVIDIA is partnering with CrowdStrike to make cybersecurity “speed of light,” enabling enterprises to deploy specialized security agents from cloud to edge using NVIDIA Nemotron‑based models and NVIDIA NeMo tooling.&lt;/p&gt;
&lt;p&gt;He also announced that NVIDIA and Palantir are integrating accelerated computing, CUDA‑X libraries and Nemotron open models into Palantir Ontology to “data processing at a much, much larger scale and with more speed.”&lt;/p&gt;
&lt;h3&gt;NVIDIA and Global Leaders Build a Digital Twin Platform for US Reindustrialization&lt;/h3&gt;
&lt;p&gt;Physical AI is powering America’s reindustrialization — transforming factories, logistics and infrastructure with robotics and intelligent systems. In a video, Huang highlighted how partners are putting it to work.&lt;/p&gt;
&lt;p&gt;“The factory is essentially a robot that’s orchestrating robots to build things that are robotic,” he said. “The amount of software necessary to do this is so intense that unless you could do it inside a digital twin, the hopes of getting this to work is nearly impossible.”&lt;/p&gt;
&lt;p&gt;From the stage, Huang called out the work of Foxconn, which is using Omniverse tools to design and validate a new Houston facility for manufacturing NVIDIA AI infrastructure systems; Caterpillar — which is also incorporating digital twins for manufacturing; Brett Adcock who founded a company three and a half year ago, Figure AI, building humanoid robots for the home and workforce, that is now worth almost $4 billion; Johnson &amp;amp; Johnson; and Disney, which is using Omniverse to train the “cutest robot ever.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/nvidia-gtc-washington-dc-2025-news/</guid><pubDate>Tue, 28 Oct 2025 19:45:40 +0000</pubDate></item><item><title>Microsoft’s Copilot can now build apps and automate your job — here’s how it works (AI | VentureBeat)</title><link>https://venturebeat.com/ai/microsofts-copilot-can-now-build-apps-and-automate-your-job-heres-how-it</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is launching a significant expansion of its &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot AI assistant&lt;/u&gt;&lt;/a&gt; on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.&lt;/p&gt;&lt;p&gt;The new capabilities, called &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;Workflows&lt;/u&gt;&lt;/a&gt;, mark Microsoft&amp;#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated &lt;a href="https://www.microsoft.com/investor/reports/ar25/index.html"&gt;&lt;u&gt;100 million Microsoft 365 users&lt;/u&gt;&lt;/a&gt; to create business tools as easily as they currently draft emails or build spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,&amp;quot; Charles Lamanna, Microsoft&amp;#x27;s president of business and industry Copilot, said in an interview with VentureBeat. &amp;quot;Part of the job will be to build and create these things.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a &lt;a href="https://blogs.microsoft.com/blog/2025/10/28/the-next-chapter-of-the-microsoft-openai-partnership/"&gt;&lt;u&gt;complex partnership with OpenAI&lt;/u&gt;&lt;/a&gt;, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a &lt;a href="https://www.bloomberg.com/news/articles/2025-10-28/microsoft-to-get-27-of-openai-access-to-ai-models-until-2032"&gt;&lt;u&gt;27% ownership stake&lt;/u&gt;&lt;/a&gt; valued at approximately $135 billion.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How natural language prompts now create fully functional business applications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new features transform &lt;a href="http://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot&lt;/u&gt;&lt;/a&gt; from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,&amp;quot; Lamanna explained. &amp;quot;You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; stores data in Microsoft Lists, the company&amp;#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&amp;#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.&lt;/p&gt;&lt;p&gt;A third component, a simplified version of &lt;a href="http://microsoft.com/en/microsoft-copilot/microsoft-copilot-studio"&gt;&lt;u&gt;Microsoft&amp;#x27;s Copilot Studio&lt;/u&gt;&lt;/a&gt; agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.&lt;/p&gt;&lt;p&gt;All three capabilities are included in the existing $30-per-month &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/pricing"&gt;&lt;u&gt;Microsoft 365 Copilot subscription&lt;/u&gt;&lt;/a&gt; at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&amp;#x27;s historical approach of bundling significant value into its productivity suite.&lt;/p&gt;&lt;p&gt;&amp;quot;That&amp;#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,&amp;quot; he said. &amp;quot;If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&amp;#x27;s a pretty good deal.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Microsoft&amp;#x27;s nine-year bet on low-code development is finally paying off&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its &lt;a href="https://www.microsoft.com/en-us/power-platform"&gt;&lt;u&gt;Power Platform&lt;/u&gt;&lt;/a&gt; — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.&lt;/p&gt;&lt;p&gt;Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the big things that we&amp;#x27;re excited about is Copilot — that&amp;#x27;s a tool for literally every office worker,&amp;quot; Lamanna said. &amp;quot;Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.&amp;quot;&lt;/p&gt;&lt;p&gt;The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&amp;#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for &amp;quot;an app for &lt;a href="https://blogs.windows.com/windows-insider/2015/03/30/introducing-project-spartan-the-new-browser-built-for-windows-10/"&gt;&lt;u&gt;Project Spartan&lt;/u&gt;&lt;/a&gt;,&amp;quot; Copilot can draw from existing communications to understand what that project entails and suggest relevant features.&lt;/p&gt;&lt;p&gt;&amp;quot;If you go to those other tools, they have no idea what the heck Project Spartan is,&amp;quot; Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. &amp;quot;But if you do it inside of Copilot and inside of the App Builder, it&amp;#x27;s able to draw from all that information and context.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; claims the apps created through these tools are &amp;quot;full-stack applications&amp;quot; with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where professional developers still matter in an AI-powered workplace&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;While &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.&lt;/p&gt;&lt;p&gt;&amp;quot;Anything that leaves the boundaries of your company warrants developer involvement,&amp;quot; he said. &amp;quot;If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.&amp;quot;&lt;/p&gt;&lt;p&gt;The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. &amp;quot;You don&amp;#x27;t want people getting refunds they shouldn&amp;#x27;t,&amp;quot; Lamanna noted.&lt;/p&gt;&lt;p&gt;For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built &amp;quot;no cliffs,&amp;quot; in Lamanna&amp;#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.&lt;/p&gt;&lt;p&gt;Apps created in the conversational &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; can be opened in &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;Power Apps&lt;/u&gt;&lt;/a&gt;, Microsoft&amp;#x27;s full development environment, where they can be connected to &lt;a href="https://www.microsoft.com/en-us/power-platform/dataverse"&gt;&lt;u&gt;Dataverse&lt;/u&gt;&lt;/a&gt;, the company&amp;#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full &lt;a href="https://www.microsoft.com/en/power-platform/products/power-automate?market=af"&gt;&lt;u&gt;Power Automate platform&lt;/u&gt;&lt;/a&gt;, and basic agents can be enhanced in the complete Copilot Studio.&lt;/p&gt;&lt;p&gt;&amp;quot;We have this mantra called no cliffs,&amp;quot; Lamanna said. &amp;quot;If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&amp;#x27;re really sophisticated, you can even go from those experiences into Azure.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. &amp;quot;People really do not like easy-to-use development tools if I have to throw everything away and start over,&amp;quot; Lamanna said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What happens when every employee can build apps without IT approval&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.&lt;/p&gt;&lt;p&gt;IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the &lt;a href="https://www.office.com/"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt; admin center. They can reassign ownership, disable access at the group level, or &amp;quot;promote&amp;quot; particularly useful employee-created apps to officially supported status.&lt;/p&gt;&lt;p&gt;&amp;quot;We have a bunch of customers who have this approach where it&amp;#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,&amp;quot; Lamanna said.&lt;/p&gt;&lt;p&gt;The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.&lt;/p&gt;&lt;p&gt;Lamanna argued that most employee-created apps don&amp;#x27;t warrant significant IT oversight. &amp;quot;It&amp;#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,&amp;quot; he said. &amp;quot;It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.&amp;quot;&lt;/p&gt;&lt;p&gt;Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&amp;#x27;s increasing emphasis on AI features across its products, with some giving the &lt;a href="https://www.pcworld.com/article/2954732/users-arent-happy-with-copilot-ai-taking-over-the-microsoft-365-app.html"&gt;&lt;u&gt;Microsoft 365 mobile app one-star ratings&lt;/u&gt;&lt;/a&gt; after a recent update prioritized Copilot over traditional file access.&lt;/p&gt;&lt;p&gt;The tools also arrive as enterprises grapple with &amp;quot;&lt;a href="https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure"&gt;&lt;u&gt;shadow IT&lt;/u&gt;&lt;/a&gt;&amp;quot; — unsanctioned software and systems that employees adopt without official approval. While Microsoft&amp;#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The ambitious plan to turn 500 million workers into software builders&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Microsoft&amp;#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&amp;#x27;re just in the finance department or the sales department,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The numbers he&amp;#x27;s targeting are staggering. With &lt;a href="https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q3"&gt;&lt;u&gt;56 million people already using Power Platform&lt;/u&gt;&lt;/a&gt;, Lamanna believes the integration into Copilot could eventually reach 500 million builders. &amp;quot;Early days still, but I think it&amp;#x27;s certainly encouraging,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The features are currently available only to customers in Microsoft&amp;#x27;s &lt;a href="https://adoption.microsoft.com/en-us/copilot/frontier-program/"&gt;&lt;u&gt;Frontier Program&lt;/u&gt;&lt;/a&gt; — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.&lt;/p&gt;&lt;p&gt;The announcement fits within Microsoft&amp;#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&amp;#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.&lt;/p&gt;&lt;p&gt;The aggressive integration of AI features across Microsoft&amp;#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.&lt;/p&gt;&lt;p&gt;For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&amp;#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.&lt;/p&gt;&lt;p&gt;The App Builder and Workflows agents are available starting today through the &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/agents"&gt;&lt;u&gt;Microsoft 365 Copilot Agent Store&lt;/u&gt;&lt;/a&gt; for Frontier Program participants.&lt;/p&gt;&lt;p&gt;Whether that future arrives depends not just on the technology&amp;#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; is launching a significant expansion of its &lt;a href="https://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot AI assistant&lt;/u&gt;&lt;/a&gt; on Tuesday, introducing tools that let employees build applications, automate workflows, and create specialized AI agents using only conversational prompts — no coding required.&lt;/p&gt;&lt;p&gt;The new capabilities, called &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; and &lt;a href="https://www.microsoft.com/en-us/microsoft-365/blog/2025/10/28/microsoft-365-copilot-now-enables-you-to-build-apps-and-workflows/"&gt;&lt;u&gt;Workflows&lt;/u&gt;&lt;/a&gt;, mark Microsoft&amp;#x27;s most aggressive attempt yet to merge artificial intelligence with software development, enabling the estimated &lt;a href="https://www.microsoft.com/investor/reports/ar25/index.html"&gt;&lt;u&gt;100 million Microsoft 365 users&lt;/u&gt;&lt;/a&gt; to create business tools as easily as they currently draft emails or build spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;We really believe that a main part of an AI-forward employee, not just developers, will be to create agents, workflows and apps,&amp;quot; Charles Lamanna, Microsoft&amp;#x27;s president of business and industry Copilot, said in an interview with VentureBeat. &amp;quot;Part of the job will be to build and create these things.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement comes as Microsoft deepens its commitment to AI-powered productivity tools while navigating a &lt;a href="https://blogs.microsoft.com/blog/2025/10/28/the-next-chapter-of-the-microsoft-openai-partnership/"&gt;&lt;u&gt;complex partnership with OpenAI&lt;/u&gt;&lt;/a&gt;, the creator of the underlying technology that powers Copilot. On the same day, OpenAI completed its restructuring into a for-profit entity, with Microsoft receiving a &lt;a href="https://www.bloomberg.com/news/articles/2025-10-28/microsoft-to-get-27-of-openai-access-to-ai-models-until-2032"&gt;&lt;u&gt;27% ownership stake&lt;/u&gt;&lt;/a&gt; valued at approximately $135 billion.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How natural language prompts now create fully functional business applications&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new features transform &lt;a href="http://copilot.microsoft.com/"&gt;&lt;u&gt;Copilot&lt;/u&gt;&lt;/a&gt; from a conversational assistant into what Microsoft envisions as a comprehensive development environment accessible to non-technical workers. Users can now describe an application they need — such as a project tracker with dashboards and task assignments — and Copilot will generate a working app complete with a database backend, user interface, and security controls.&lt;/p&gt;&lt;p&gt;&amp;quot;If you&amp;#x27;re right inside of Copilot, you can now have a conversation to build an application complete with a backing database and a security model,&amp;quot; Lamanna explained. &amp;quot;You can make edit requests and update requests and change requests so you can tune the app to get exactly the experience you want before you share it with other users.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; stores data in Microsoft Lists, the company&amp;#x27;s lightweight database system, and allows users to share finished applications via a simple link—similar to sharing a document. The Workflows agent, meanwhile, automates routine tasks across Microsoft&amp;#x27;s ecosystem of products, including Outlook, Teams, SharePoint, and Planner, by converting natural language descriptions into automated processes.&lt;/p&gt;&lt;p&gt;A third component, a simplified version of &lt;a href="http://microsoft.com/en/microsoft-copilot/microsoft-copilot-studio"&gt;&lt;u&gt;Microsoft&amp;#x27;s Copilot Studio&lt;/u&gt;&lt;/a&gt; agent-building platform, lets users create specialized AI assistants tailored to specific tasks or knowledge domains, drawing from SharePoint documents, meeting transcripts, emails, and external systems.&lt;/p&gt;&lt;p&gt;All three capabilities are included in the existing $30-per-month &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/pricing"&gt;&lt;u&gt;Microsoft 365 Copilot subscription&lt;/u&gt;&lt;/a&gt; at no additional cost — a pricing decision Lamanna characterized as consistent with Microsoft&amp;#x27;s historical approach of bundling significant value into its productivity suite.&lt;/p&gt;&lt;p&gt;&amp;quot;That&amp;#x27;s what Microsoft always does. We try to do a huge amount of value at a low price,&amp;quot; he said. &amp;quot;If you go look at Office, you think about Excel, Word, PowerPoint, Exchange, all that for like eight bucks a month. That&amp;#x27;s a pretty good deal.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why Microsoft&amp;#x27;s nine-year bet on low-code development is finally paying off&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The new tools represent the culmination of a nine-year effort by Microsoft to democratize software development through its &lt;a href="https://www.microsoft.com/en-us/power-platform"&gt;&lt;u&gt;Power Platform&lt;/u&gt;&lt;/a&gt; — a collection of low-code and no-code development tools that has grown to 56 million monthly active users, according to figures the company disclosed in recent earnings reports.&lt;/p&gt;&lt;p&gt;Lamanna, who has led the Power Platform initiative since its inception, said the integration into Copilot marks a fundamental shift in how these capabilities reach users. Rather than requiring workers to visit a separate website or learn a specialized interface, the development tools now exist within the same conversational window they already use for AI-assisted tasks.&lt;/p&gt;&lt;p&gt;&amp;quot;One of the big things that we&amp;#x27;re excited about is Copilot — that&amp;#x27;s a tool for literally every office worker,&amp;quot; Lamanna said. &amp;quot;Every office worker, just like they research data, they analyze data, they reason over topics, they also will be creating apps, agents and workflows.&amp;quot;&lt;/p&gt;&lt;p&gt;The integration offers significant technical advantages, he argued. Because Copilot already indexes a user&amp;#x27;s Microsoft 365 content — emails, documents, meetings, and organizational data — it can incorporate that context into the applications and workflows it builds. If a user asks for &amp;quot;an app for &lt;a href="https://blogs.windows.com/windows-insider/2015/03/30/introducing-project-spartan-the-new-browser-built-for-windows-10/"&gt;&lt;u&gt;Project Spartan&lt;/u&gt;&lt;/a&gt;,&amp;quot; Copilot can draw from existing communications to understand what that project entails and suggest relevant features.&lt;/p&gt;&lt;p&gt;&amp;quot;If you go to those other tools, they have no idea what the heck Project Spartan is,&amp;quot; Lamanna said, referencing competing low-code platforms from companies like Google, Salesforce, and ServiceNow. &amp;quot;But if you do it inside of Copilot and inside of the App Builder, it&amp;#x27;s able to draw from all that information and context.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; claims the apps created through these tools are &amp;quot;full-stack applications&amp;quot; with proper databases secured through the same identity systems used across its enterprise products — distinguishing them from simpler front-end tools offered by competitors. The company also emphasized that its existing governance, security, and data loss prevention policies automatically apply to apps and workflows created through Copilot.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Where professional developers still matter in an AI-powered workplace&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;While &lt;a href="https://www.microsoft.com/en-us/"&gt;&lt;u&gt;Microsoft&lt;/u&gt;&lt;/a&gt; positions the new capabilities as accessible to all office workers, Lamanna was careful to delineate where professional developers remain essential. His dividing line centers on whether a system interacts with parties outside the organization.&lt;/p&gt;&lt;p&gt;&amp;quot;Anything that leaves the boundaries of your company warrants developer involvement,&amp;quot; he said. &amp;quot;If you want to build an agent and put it on your website, you should have developers involved. Or if you want to build an automation which interfaces directly with your customers, or an app or a website which interfaces directly with your customers, you want professionals involved.&amp;quot;&lt;/p&gt;&lt;p&gt;The reasoning is risk-based: external-facing systems carry greater potential for data breaches, security vulnerabilities, or business errors. &amp;quot;You don&amp;#x27;t want people getting refunds they shouldn&amp;#x27;t,&amp;quot; Lamanna noted.&lt;/p&gt;&lt;p&gt;For internal use cases — approval workflows, project tracking, team dashboards — Microsoft believes the new tools can handle the majority of needs without IT department involvement. But the company has built &amp;quot;no cliffs,&amp;quot; in Lamanna&amp;#x27;s terminology, allowing users to migrate simple apps to more sophisticated platforms as needs grow.&lt;/p&gt;&lt;p&gt;Apps created in the conversational &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;App Builder&lt;/u&gt;&lt;/a&gt; can be opened in &lt;a href="https://www.microsoft.com/en-us/power-platform/products/power-apps"&gt;&lt;u&gt;Power Apps&lt;/u&gt;&lt;/a&gt;, Microsoft&amp;#x27;s full development environment, where they can be connected to &lt;a href="https://www.microsoft.com/en-us/power-platform/dataverse"&gt;&lt;u&gt;Dataverse&lt;/u&gt;&lt;/a&gt;, the company&amp;#x27;s enterprise database, or extended with custom code. Similarly, simple workflows can graduate to the full &lt;a href="https://www.microsoft.com/en/power-platform/products/power-automate?market=af"&gt;&lt;u&gt;Power Automate platform&lt;/u&gt;&lt;/a&gt;, and basic agents can be enhanced in the complete Copilot Studio.&lt;/p&gt;&lt;p&gt;&amp;quot;We have this mantra called no cliffs,&amp;quot; Lamanna said. &amp;quot;If your app gets too complicated for the App Builder, you can always edit and open it in Power Apps. You can jump over to the richer experience, and if you&amp;#x27;re really sophisticated, you can even go from those experiences into Azure.&amp;quot;&lt;/p&gt;&lt;p&gt;This architecture addresses a problem that has plagued previous generations of easy-to-use development tools: users who outgrow the simplified environment often must rebuild from scratch on professional platforms. &amp;quot;People really do not like easy-to-use development tools if I have to throw everything away and start over,&amp;quot; Lamanna said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What happens when every employee can build apps without IT approval&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The democratization of software development raises questions about governance, maintenance, and organizational complexity — issues Microsoft has worked to address through administrative controls.&lt;/p&gt;&lt;p&gt;IT administrators can view all applications, workflows, and agents created within their organization through a centralized inventory in the &lt;a href="https://www.office.com/"&gt;&lt;u&gt;Microsoft 365&lt;/u&gt;&lt;/a&gt; admin center. They can reassign ownership, disable access at the group level, or &amp;quot;promote&amp;quot; particularly useful employee-created apps to officially supported status.&lt;/p&gt;&lt;p&gt;&amp;quot;We have a bunch of customers who have this approach where it&amp;#x27;s like, let 1,000 apps bloom, and then the best ones, I go upgrade and make them IT-governed or central,&amp;quot; Lamanna said.&lt;/p&gt;&lt;p&gt;The system also includes provisions for when employees leave. Apps and workflows remain accessible for 60 days, during which managers can claim ownership — similar to how OneDrive files are handled when someone departs.&lt;/p&gt;&lt;p&gt;Lamanna argued that most employee-created apps don&amp;#x27;t warrant significant IT oversight. &amp;quot;It&amp;#x27;s just not worth inspecting an app that John, Susie, and Bob use to do their job,&amp;quot; he said. &amp;quot;It should concern itself with the app that ends up being used by 2,000 people, and that will pop up in that dashboard.&amp;quot;&lt;/p&gt;&lt;p&gt;Still, the proliferation of employee-created applications could create challenges. Users have expressed frustration with Microsoft&amp;#x27;s increasing emphasis on AI features across its products, with some giving the &lt;a href="https://www.pcworld.com/article/2954732/users-arent-happy-with-copilot-ai-taking-over-the-microsoft-365-app.html"&gt;&lt;u&gt;Microsoft 365 mobile app one-star ratings&lt;/u&gt;&lt;/a&gt; after a recent update prioritized Copilot over traditional file access.&lt;/p&gt;&lt;p&gt;The tools also arrive as enterprises grapple with &amp;quot;&lt;a href="https://venturebeat.com/ai/mit-report-misunderstood-shadow-ai-economy-booms-while-headlines-cry-failure"&gt;&lt;u&gt;shadow IT&lt;/u&gt;&lt;/a&gt;&amp;quot; — unsanctioned software and systems that employees adopt without official approval. While Microsoft&amp;#x27;s governance controls aim to provide visibility, the ease of creating new applications could accelerate the pace at which these systems multiply.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The ambitious plan to turn 500 million workers into software builders&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Microsoft&amp;#x27;s ambitions for the technology extend far beyond incremental productivity gains. Lamanna envisions a fundamental transformation of what it means to be an office worker — one where building software becomes as routine as creating spreadsheets.&lt;/p&gt;&lt;p&gt;&amp;quot;Just like how 20 years ago you put on your resume that you could use pivot tables in Excel, people are going to start saying that they can use App Builder and workflow agents, even if they&amp;#x27;re just in the finance department or the sales department,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The numbers he&amp;#x27;s targeting are staggering. With &lt;a href="https://www.microsoft.com/en-us/investor/events/fy-2025/earnings-fy-2025-q3"&gt;&lt;u&gt;56 million people already using Power Platform&lt;/u&gt;&lt;/a&gt;, Lamanna believes the integration into Copilot could eventually reach 500 million builders. &amp;quot;Early days still, but I think it&amp;#x27;s certainly encouraging,&amp;quot; he said.&lt;/p&gt;&lt;p&gt;The features are currently available only to customers in Microsoft&amp;#x27;s &lt;a href="https://adoption.microsoft.com/en-us/copilot/frontier-program/"&gt;&lt;u&gt;Frontier Program&lt;/u&gt;&lt;/a&gt; — an early access initiative for Microsoft 365 Copilot subscribers. The company has not disclosed how many organizations participate in the program or when the tools will reach general availability.&lt;/p&gt;&lt;p&gt;The announcement fits within Microsoft&amp;#x27;s larger strategy of embedding AI capabilities throughout its product portfolio, driven by its partnership with OpenAI. Under the restructured agreement announced Tuesday, Microsoft will have access to OpenAI&amp;#x27;s technology through 2032, including models that achieve artificial general intelligence (AGI) — though such systems do not yet exist. Microsoft has also begun integrating Copilot into its new companion apps for Windows 11, which provide quick access to contacts, files, and calendar information.&lt;/p&gt;&lt;p&gt;The aggressive integration of AI features across Microsoft&amp;#x27;s ecosystem has drawn mixed reactions. While enterprise customers have shown interest in productivity gains, the rapid pace of change and ubiquity of AI prompts have frustrated some users who prefer traditional workflows.&lt;/p&gt;&lt;p&gt;For Microsoft, however, the calculation is clear: if even a fraction of its user base begins creating applications and automations, it would represent a massive expansion of the effective software development workforce — and further entrench customers in Microsoft&amp;#x27;s ecosystem. The company is betting that the same natural language interface that made ChatGPT accessible to millions can finally unlock the decades-old promise of empowering everyday workers to build their own tools.&lt;/p&gt;&lt;p&gt;The App Builder and Workflows agents are available starting today through the &lt;a href="https://www.microsoft.com/en-us/microsoft-365-copilot/agents"&gt;&lt;u&gt;Microsoft 365 Copilot Agent Store&lt;/u&gt;&lt;/a&gt; for Frontier Program participants.&lt;/p&gt;&lt;p&gt;Whether that future arrives depends not just on the technology&amp;#x27;s capabilities, but on a more fundamental question: Do millions of office workers actually want to become part-time software developers? Microsoft is about to find out if the answer is yes — or if some jobs are better left to the professionals.&lt;/p&gt;&lt;p&gt;
&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/microsofts-copilot-can-now-build-apps-and-automate-your-job-heres-how-it</guid><pubDate>Tue, 28 Oct 2025 20:30:00 +0000</pubDate></item><item><title>Mappa’s AI voice analysis helps you find the best job candidates and will show off its tech at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/mappas-ai-voice-analysis-helps-you-find-the-best-job-candidates-and-will-show-off-its-tech-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Even after reviewing résumés, cover letters, and interviews, choosing the right candidate for a job can be a mysterious process. Hiring managers often rely on their biases about the world or gut feelings to inform their decision, making the process far from an exact science.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Sarah Lucena built Mappa, an AI-powered behavioral intelligence platform that aims to take some of the guesswork out of hiring. Mappa trained an AI model to detect voice patterns that correlate with certain traits, such as communication style, empathy, and confidence. Applicants simply answer some questions from Mappa’s AI agent, and then the platform sends hiring managers a shortlist of candidates with traits that are compatible with the role.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mappa is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Mappa comes to the market with the goal of really, truly understanding people,” Lucena said in an interview with TechCrunch. “We don’t really categorize traits as good or bad. We understand traits as compatible or not.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena founded Mappa in 2023 with her two co-founders, Pablo Bérgolo and Daniel Moretti, and has raised $3.4 million in a seed round led by Tim Draper’s investment firm, Draper Associates. In less than three years, the startup has scaled to more than 130 customers in the U.S. and more than $4 million in annualized recurring revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa claims one of its biggest advantages is data. The startup built highly curated datasets specifically for understanding human behavior. Mappa originally attempted to assess candidates based on video submissions and their online presence; however, they’ve found voice analysis to be the most effective method.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa’s platform has already helped companies find employees who stick around longer, according to Lucena. While the standard annual turnover rate for companies is around 30%, she says employees hired through Mappa have a turnover rate of just 2%.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena says Mappa’s focus is always helping companies find the best people, but that often results in a more equitable hiring process. Mappa has facilitated over 3,000 hires to date, and more than 60% of them were women, LGBTQ+, or immigrants. Lucena, who was born and raised in Brazil, says she’s proud to have created more opportunities for these people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moving forward, Lucena says she sees Mappa evolving from a services company into an infrastructure provider. The startup’s API has seen traction among companies who want to use its behavioral analysis in situations beyond hiring. Tim Draper personally uses Mappa to assess founders his firm is considering investing in, and the educational platform Re-Skilling.ai uses the platform to understand skills that students can improve on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the future, Lucena sees that Mappa could be used to help approve candidates for loans who don’t have an extensive credit history. She sees Mappa as a tool to help assess people more fairly in all kinds of settings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to hear from Mappa firsthand, and see dozens of additional pitches, attend valuable workshops, and make the connections that drive business results, &lt;/em&gt;&lt;em&gt;head here to learn more about this year’s Disrupt&lt;/em&gt;&lt;em&gt;, held October 27 to 29 in San Francisco.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Even after reviewing résumés, cover letters, and interviews, choosing the right candidate for a job can be a mysterious process. Hiring managers often rely on their biases about the world or gut feelings to inform their decision, making the process far from an exact science.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That’s why Sarah Lucena built Mappa, an AI-powered behavioral intelligence platform that aims to take some of the guesswork out of hiring. Mappa trained an AI model to detect voice patterns that correlate with certain traits, such as communication style, empathy, and confidence. Applicants simply answer some questions from Mappa’s AI agent, and then the platform sends hiring managers a shortlist of candidates with traits that are compatible with the role.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mappa is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Mappa comes to the market with the goal of really, truly understanding people,” Lucena said in an interview with TechCrunch. “We don’t really categorize traits as good or bad. We understand traits as compatible or not.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena founded Mappa in 2023 with her two co-founders, Pablo Bérgolo and Daniel Moretti, and has raised $3.4 million in a seed round led by Tim Draper’s investment firm, Draper Associates. In less than three years, the startup has scaled to more than 130 customers in the U.S. and more than $4 million in annualized recurring revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa claims one of its biggest advantages is data. The startup built highly curated datasets specifically for understanding human behavior. Mappa originally attempted to assess candidates based on video submissions and their online presence; however, they’ve found voice analysis to be the most effective method.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mappa’s platform has already helped companies find employees who stick around longer, according to Lucena. While the standard annual turnover rate for companies is around 30%, she says employees hired through Mappa have a turnover rate of just 2%.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Lucena says Mappa’s focus is always helping companies find the best people, but that often results in a more equitable hiring process. Mappa has facilitated over 3,000 hires to date, and more than 60% of them were women, LGBTQ+, or immigrants. Lucena, who was born and raised in Brazil, says she’s proud to have created more opportunities for these people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Moving forward, Lucena says she sees Mappa evolving from a services company into an infrastructure provider. The startup’s API has seen traction among companies who want to use its behavioral analysis in situations beyond hiring. Tim Draper personally uses Mappa to assess founders his firm is considering investing in, and the educational platform Re-Skilling.ai uses the platform to understand skills that students can improve on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the future, Lucena sees that Mappa could be used to help approve candidates for loans who don’t have an extensive credit history. She sees Mappa as a tool to help assess people more fairly in all kinds of settings.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to hear from Mappa firsthand, and see dozens of additional pitches, attend valuable workshops, and make the connections that drive business results, &lt;/em&gt;&lt;em&gt;head here to learn more about this year’s Disrupt&lt;/em&gt;&lt;em&gt;, held October 27 to 29 in San Francisco.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/mappas-ai-voice-analysis-helps-you-find-the-best-job-candidates-and-will-show-off-its-tech-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 22:15:00 +0000</pubDate></item><item><title>Super Teacher is building an AI tutor for elementary schools — catch it at Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/super-teacher-is-building-an-ai-tutor-for-elementary-schools-catch-it-at-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tutoring is one of the most effective tools for improving a child’s education, yet very few kids in the U.S. receive it. A 2023 survey of the nation’s largest school districts found that fewer than 10% of students received tutoring. One factor is that tutoring is too expensive for many families, often costing hundreds or thousands of dollars a month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tim Novikoff, a former Google product manager and educator, wants to change that. His startup, Super Teacher, offers an AI-powered tutoring app for elementary school students that costs $15 a month, or $10 with an annual plan. Super Teacher aims to make private tutoring accessible to families nationwide.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The four-year-old startup is gaining traction. Novikoff says roughly 20,000 families have signed up for Super Teacher, and public schools in New York, New Jersey, and Hawaii now use the app. Super Teacher is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff was previously a math teacher in New York City, first in Harlem and then at a highly rated public school, Stuyvesant High School. In an interview with TechCrunch, he said almost all the students at Stuyvesant received tutoring, whereas many of the students in Harlem didn’t, and the difference in their educational experience was stark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Tutoring] is by far the most effective intervention that can be provided to kids for education, and it’s not even close,” Novikoff said. “It’s really unfair that not everyone gets this opportunity. That’s why I’m pursuing a mission to democratize access to private tutoring.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher’s app features animated tutors with AI-generated voices that guide students through interactive lessons. Students talk to the app using voice, like a conversation with a teacher. But unlike many edtech tools, Super Teacher doesn’t use large language models to generate responses. Instead, its content comes from a deterministic system designed to always give correct answers — avoiding the inaccuracies that can plague LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff thinks AI tutors can have a valuable impact on children’s lives, but he’s adamant that AI will never replace teachers in a school setting. He refers to AI tutors as a tool that teachers can use, such as smart boards or calculators, rather than a replacement altogether.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher is only available for elementary school students, a decision Novikoff made to help his own children and because few edtech companies target that age group. Looking ahead, he hopes to expand to younger and older grades and partner with more school districts across the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff previously founded&lt;strong&gt; &lt;/strong&gt;Fly Labs, a mobile video-editing app acquired by Google in 2015.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Super Teacher from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Tutoring is one of the most effective tools for improving a child’s education, yet very few kids in the U.S. receive it. A 2023 survey of the nation’s largest school districts found that fewer than 10% of students received tutoring. One factor is that tutoring is too expensive for many families, often costing hundreds or thousands of dollars a month.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Tim Novikoff, a former Google product manager and educator, wants to change that. His startup, Super Teacher, offers an AI-powered tutoring app for elementary school students that costs $15 a month, or $10 with an annual plan. Super Teacher aims to make private tutoring accessible to families nationwide.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The four-year-old startup is gaining traction. Novikoff says roughly 20,000 families have signed up for Super Teacher, and public schools in New York, New Jersey, and Hawaii now use the app. Super Teacher is a Startup Battlefield Top 20 finalist at TechCrunch Disrupt 2025 in San Francisco.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff was previously a math teacher in New York City, first in Harlem and then at a highly rated public school, Stuyvesant High School. In an interview with TechCrunch, he said almost all the students at Stuyvesant received tutoring, whereas many of the students in Harlem didn’t, and the difference in their educational experience was stark.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“[Tutoring] is by far the most effective intervention that can be provided to kids for education, and it’s not even close,” Novikoff said. “It’s really unfair that not everyone gets this opportunity. That’s why I’m pursuing a mission to democratize access to private tutoring.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher’s app features animated tutors with AI-generated voices that guide students through interactive lessons. Students talk to the app using voice, like a conversation with a teacher. But unlike many edtech tools, Super Teacher doesn’t use large language models to generate responses. Instead, its content comes from a deterministic system designed to always give correct answers — avoiding the inaccuracies that can plague LLMs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff thinks AI tutors can have a valuable impact on children’s lives, but he’s adamant that AI will never replace teachers in a school setting. He refers to AI tutors as a tool that teachers can use, such as smart boards or calculators, rather than a replacement altogether.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Super Teacher is only available for elementary school students, a decision Novikoff made to help his own children and because few edtech companies target that age group. Looking ahead, he hopes to expand to younger and older grades and partner with more school districts across the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Novikoff previously founded&lt;strong&gt; &lt;/strong&gt;Fly Labs, a mobile video-editing app acquired by Google in 2015.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Super Teacher from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/super-teacher-is-building-an-ai-tutor-for-elementary-schools-catch-it-at-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 22:15:00 +0000</pubDate></item><item><title>Inside CampusAI’s mission to close the AI training gap for everyday workers — check it out at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/inside-campusais-mission-to-close-the-ai-training-gap-for-everyday-workers-check-it-out-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As companies push to increase efficiency and stay competitive, they’re encouraging, or in some cases outright requiring, workers to know how to use AI tools. However, the push for AI use has exposed a training gap.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are few solutions available on the market that are dedicated to non-technical people,” Aureliusz Gorski, founder and CEO of Warsaw-based CampusAI, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CampusAI’s solution? An educational platform focused on making learning accessible to everyday people who want to bring AI into their everyday workflows — whether that’s to help improve sales, HR, legal, or just give your personal branding a boost with AI.&amp;nbsp;The platform aims to help people understand and work with AI, rather than be intimidated by it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Polish startup spoke to TechCrunch ahead of the TechCrunch Disrupt conference, where it’s a Startup Battlefield Top 20 finalist. CampusAI’s main product is a comprehensive online learning ecosystem with two key components: courses featuring an avatar-based learning model and a virtual campus in the metaverse where users can learn more skills, connect with others, participate in community projects, and more.&amp;nbsp;Think of it like Roblox for adults.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI offers its learning platform directly to consumers or to businesses that want to create AI upskilling paths for employees. The startup says it provides access to dozens of AI models — from ChatGPT and Gemini to Midjourney and Flux —&amp;nbsp;so users can experiment and learn in one place without needing to sign up for separate accounts and subscriptions. The team also updates courses every day to keep up with the fast pace of technological change.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062174" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/CampusAI-_Gameplay.mp4.00_00_21_03.Still002.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Me+AI users get a dedicated desk in the virtual campus&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s flagship course for consumers is called Me+AI, priced at $250 per year, and it allows students to personalize their learning experience. The B2B product, called Team+AI, is priced at $25,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are helping with the implementation of the human plus AI readiness culture [within companies], helping companies go smoothly with this transition,” Gorski said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The first three weeks of Team+AI include an AI readiness test for the organization, a workshop for managers, and a webinar for the entire organization. The last four weeks feature personalized development paths for employees that have been adapted to meet company goals. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can come in as a professional of a field, say, an HR expert, or someone who works in finance, and then you’ll find a batch of courses for yourself,” Aleksandra Przegalińska, an AI researcher and scientific adviser to CampusAI, told TechCrunch. “CampusAI is capable of preparing specific pathways for specific organizations so they can do a tailor-made approach.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s learning methodology is based off Przegalińska’s research on human-AI collaboration for improved business results and complex problem-solving. The approach centers on using prompting strategies to develop AI experts that support individuals in enhancing their capabilities.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062176" height="440" src="https://techcrunch.com/wp-content/uploads/2025/10/Zrzut-ekranu-2025-10-24-o-18.58.54.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As such, CampusAI students have access to the company’s prompt book, which not only offers a repository of prompts, but also coaches students to learn how to build better prompts. Within the virtual campus environment, students can also visit the “AI Gym” — a platform where students tackle targeted exercises and challenges created by an AI agent that provides ongoing assessment.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We want to build an environment where you don’t delegate tasks to AI, but rather, you work with it in multiple different modalities,” Przegalińska said. “You can work in parallel with it, it can become your teammate, your sparring partner, your critic, or your coach. We think of this technology as something that is enhancing your work, not something that is taking over your work.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI claims its courses produce a measurable ROI, with employees becoming 40% more efficient and 60% more satisfied with their jobs. And the two-year-old company appears to have had some serious traction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was huge success in Poland in the first two weeks,” Gorski said, noting the company launched in 2023. “We got over 600 clients who decided to buy our lifetime membership, and from that moment, we grew to 35,000 users.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI also boasts 60 enterprise customers, including ING, T-Mobile, Lenovo, and Ikea, and is on track for more than $2 million in ARR in 2025. The company is currently raising a $20 million Series A to help it&lt;strong&gt; &lt;/strong&gt;expand to 40 markets by 2030.&lt;strong&gt; &lt;/strong&gt;CampusAI, which offers its program today in Polish, English, and Spanish, has recently expanded into the U.K. and the U.S., with a focus on building B2B sales before branching into D2C. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users who complete the courses and want to discover more can be invited to join Community+AI, a digital hub for members to connect, share knowledge, and collaborate on projects — like hAI Magazine, an online magazine where users can share sector-specific insights. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond its learning environment, Gorski said CampusAI’s digital twin technology has become a major value proposition. Instead of just running its own virtual campus, CampusAI wants to build and license digital twins of real-life university campuses, corporate showrooms, government institutions, or company headquarters for organizations’ exclusive use. The digital twins product starts at $100,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI recently secured €18 million from the European Commission to collaborate with 11 universities across 10 countries — including Greece, Spain, the U.K., France, Luxembourg, and Germany — to create digital twins and customized learning environments for students. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gorski views these university partnerships as launchpads for local innovation hubs — an approach informed by his seven years at Cambridge Innovation Center, where he created over 10 programs to develop Warsaw’s startup community. These virtual environments are designed as catalysts for building local communities and virtual districts, ultimately creating a social platform tailored for entrepreneurs.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He emphasized that fostering strong local ecosystems is critical to counter big tech dominance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe people should focus on building strong local ecosystems, because if not, the next five years will probably have less and less startups, especially after what we saw recently with OpenAI providing more solutions inside one ecosystem,” he said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about CampusAI from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As companies push to increase efficiency and stay competitive, they’re encouraging, or in some cases outright requiring, workers to know how to use AI tools. However, the push for AI use has exposed a training gap.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“There are few solutions available on the market that are dedicated to non-technical people,” Aureliusz Gorski, founder and CEO of Warsaw-based CampusAI, told TechCrunch.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;CampusAI’s solution? An educational platform focused on making learning accessible to everyday people who want to bring AI into their everyday workflows — whether that’s to help improve sales, HR, legal, or just give your personal branding a boost with AI.&amp;nbsp;The platform aims to help people understand and work with AI, rather than be intimidated by it.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Polish startup spoke to TechCrunch ahead of the TechCrunch Disrupt conference, where it’s a Startup Battlefield Top 20 finalist. CampusAI’s main product is a comprehensive online learning ecosystem with two key components: courses featuring an avatar-based learning model and a virtual campus in the metaverse where users can learn more skills, connect with others, participate in community projects, and more.&amp;nbsp;Think of it like Roblox for adults.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI offers its learning platform directly to consumers or to businesses that want to create AI upskilling paths for employees. The startup says it provides access to dozens of AI models — from ChatGPT and Gemini to Midjourney and Flux —&amp;nbsp;so users can experiment and learn in one place without needing to sign up for separate accounts and subscriptions. The team also updates courses every day to keep up with the fast pace of technological change.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062174" height="383" src="https://techcrunch.com/wp-content/uploads/2025/10/CampusAI-_Gameplay.mp4.00_00_21_03.Still002.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Me+AI users get a dedicated desk in the virtual campus&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s flagship course for consumers is called Me+AI, priced at $250 per year, and it allows students to personalize their learning experience. The B2B product, called Team+AI, is priced at $25,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We are helping with the implementation of the human plus AI readiness culture [within companies], helping companies go smoothly with this transition,” Gorski said.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The first three weeks of Team+AI include an AI readiness test for the organization, a workshop for managers, and a webinar for the entire organization. The last four weeks feature personalized development paths for employees that have been adapted to meet company goals. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“You can come in as a professional of a field, say, an HR expert, or someone who works in finance, and then you’ll find a batch of courses for yourself,” Aleksandra Przegalińska, an AI researcher and scientific adviser to CampusAI, told TechCrunch. “CampusAI is capable of preparing specific pathways for specific organizations so they can do a tailor-made approach.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI’s learning methodology is based off Przegalińska’s research on human-AI collaboration for improved business results and complex problem-solving. The approach centers on using prompting strategies to develop AI experts that support individuals in enhancing their capabilities.&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3062176" height="440" src="https://techcrunch.com/wp-content/uploads/2025/10/Zrzut-ekranu-2025-10-24-o-18.58.54.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;CampusAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;As such, CampusAI students have access to the company’s prompt book, which not only offers a repository of prompts, but also coaches students to learn how to build better prompts. Within the virtual campus environment, students can also visit the “AI Gym” — a platform where students tackle targeted exercises and challenges created by an AI agent that provides ongoing assessment.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We want to build an environment where you don’t delegate tasks to AI, but rather, you work with it in multiple different modalities,” Przegalińska said. “You can work in parallel with it, it can become your teammate, your sparring partner, your critic, or your coach. We think of this technology as something that is enhancing your work, not something that is taking over your work.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI claims its courses produce a measurable ROI, with employees becoming 40% more efficient and 60% more satisfied with their jobs. And the two-year-old company appears to have had some serious traction. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It was huge success in Poland in the first two weeks,” Gorski said, noting the company launched in 2023. “We got over 600 clients who decided to buy our lifetime membership, and from that moment, we grew to 35,000 users.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI also boasts 60 enterprise customers, including ING, T-Mobile, Lenovo, and Ikea, and is on track for more than $2 million in ARR in 2025. The company is currently raising a $20 million Series A to help it&lt;strong&gt; &lt;/strong&gt;expand to 40 markets by 2030.&lt;strong&gt; &lt;/strong&gt;CampusAI, which offers its program today in Polish, English, and Spanish, has recently expanded into the U.K. and the U.S., with a focus on building B2B sales before branching into D2C. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users who complete the courses and want to discover more can be invited to join Community+AI, a digital hub for members to connect, share knowledge, and collaborate on projects — like hAI Magazine, an online magazine where users can share sector-specific insights. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond its learning environment, Gorski said CampusAI’s digital twin technology has become a major value proposition. Instead of just running its own virtual campus, CampusAI wants to build and license digital twins of real-life university campuses, corporate showrooms, government institutions, or company headquarters for organizations’ exclusive use. The digital twins product starts at $100,000 per year. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CampusAI recently secured €18 million from the European Commission to collaborate with 11 universities across 10 countries — including Greece, Spain, the U.K., France, Luxembourg, and Germany — to create digital twins and customized learning environments for students. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gorski views these university partnerships as launchpads for local innovation hubs — an approach informed by his seven years at Cambridge Innovation Center, where he created over 10 programs to develop Warsaw’s startup community. These virtual environments are designed as catalysts for building local communities and virtual districts, ultimately creating a social platform tailored for entrepreneurs.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He emphasized that fostering strong local ecosystems is critical to counter big tech dominance.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We believe people should focus on building strong local ecosystems, because if not, the next five years will probably have less and less startups, especially after what we saw recently with OpenAI providing more solutions inside one ecosystem,” he said.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about CampusAI from the company itself — while also checking out dozens of others, hearing their pitches, and listening to guest speakers on four different stages — join us at Disrupt, October 27 to 29 in San Francisco. &lt;/em&gt;&lt;em&gt;Learn more here.&lt;/em&gt;&lt;em&gt;&amp;nbsp;&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/inside-campusais-mission-to-close-the-ai-training-gap-for-everyday-workers-check-it-out-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 28 Oct 2025 22:15:00 +0000</pubDate></item><item><title>IBM's open source Granite 4.0 Nano AI models are small enough to run locally directly in your browser (AI | VentureBeat)</title><link>https://venturebeat.com/ai/ibms-open-source-granite-4-0-nano-ai-models-are-small-enough-to-run-locally</link><description>[unable to retrieve full-text content]&lt;p&gt;In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values &lt;i&gt;efficiency over enormity&lt;/i&gt;, and &lt;i&gt;accessibility over abstraction&lt;/i&gt;.&lt;/p&gt;&lt;p&gt;The 114-year-old tech giant&amp;#x27;s &lt;a href="https://huggingface.co/blog/ibm-granite/granite-4-nano"&gt;four new Granite 4.0 Nano models&lt;/a&gt;, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. &lt;/p&gt;&lt;p&gt;These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.&lt;/p&gt;&lt;p&gt;In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka &lt;a href="https://x.com/xenovacom/status/1983218720366326002"&gt;Xenova&lt;/a&gt;, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;All the Granite 4.0 Nano models are released under the Apache 2.0 license&lt;/b&gt; — perfect for use by researchers and enterprise or indie developers, even for commercial usage. &lt;/p&gt;&lt;p&gt;They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.&lt;/p&gt;&lt;p&gt;But in this case, small doesn&amp;#x27;t mean less capable — it might just mean smarter design.&lt;/p&gt;&lt;p&gt;These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. &lt;/p&gt;&lt;p&gt;And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. &lt;/p&gt;&lt;p&gt;The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by &lt;i&gt;strategic scaling&lt;/i&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What Exactly Did IBM Release?&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;b&gt;Granite 4.0 Nano&lt;/b&gt; family includes four open-source models now available on &lt;a href="https://huggingface.co/collections/ibm-granite/granite-40-nano-language-models"&gt;Hugging Face&lt;/a&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-1B&lt;/b&gt; (~1.5B parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-350M&lt;/b&gt; (~350M parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-1B&lt;/b&gt; – Transformer-based variant, parameter count closer to 2B&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-350M&lt;/b&gt; – Transformer-based variant&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. &lt;/p&gt;&lt;p&gt;Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. &lt;/p&gt;&lt;p&gt;In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.&lt;/p&gt;&lt;p&gt;“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit &amp;quot;Ask Me Anything&amp;quot; (AMA) session on r/LocalLLaMA.&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Competitive Class of Small Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&amp;#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.&lt;/p&gt;&lt;p&gt;While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.&lt;/p&gt;&lt;p&gt;In benchmark testing, IBM’s new models consistently top the charts in their class. According to data&lt;a href="https://x.com/neurobongo/status/1983224452838985972"&gt; shared on X by David Cox, VP of AI Models at IBM Research:&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.&lt;/p&gt;&lt;p&gt;This performance is especially significant given the hardware constraints these models are designed for. &lt;/p&gt;&lt;p&gt;They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why Model Size Still Matters — But Not Like It Used To&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. &lt;/p&gt;&lt;p&gt;But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.&lt;/p&gt;&lt;p&gt;IBM is banking on this evolution. By releasing open, small models that are &lt;i&gt;competitive in real-world tasks&lt;/i&gt;, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.&lt;/p&gt;&lt;p&gt;In fact, the Nano models address three increasingly important needs:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Deployment flexibility&lt;/b&gt; — they run anywhere, from mobile to microservers.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Inference privacy&lt;/b&gt; — users can keep data local with no need to call out to cloud APIs.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Openness and auditability&lt;/b&gt; — source code and model weights are publicly available under an open license.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;Community Response and Roadmap Signals&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s Granite team didn’t just launch the models and walk away — they took to &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit’s open source community r/LocalLLaMA &lt;/a&gt;to engage directly with developers. &lt;/p&gt;&lt;p&gt;In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.&lt;/p&gt;&lt;p&gt;Notable confirmations from the thread:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A larger Granite 4.0 model is currently in training&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reasoning-focused models (&amp;quot;thinking counterparts&amp;quot;) are in the pipeline&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IBM will release fine-tuning recipes and a full training paper soon&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;More tooling and platform compatibility is on the roadmap&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Users responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Another user remarked:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;&lt;b&gt;Background: IBM Granite and the Enterprise AI Race&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like &lt;i&gt;Granite.13b.instruct&lt;/i&gt; and &lt;i&gt;Granite.13b.chat&lt;/i&gt;. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.&lt;/p&gt;&lt;p&gt;The real inflection point came with &lt;a href="https://venturebeat.com/ai/ibm-debuts-open-source-granite-3-0-llms-for-enterprise-ai/"&gt;Granite 3.0&lt;/a&gt; in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&amp;#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including &lt;a href="https://venturebeat.com/ai/ibm-wants-to-be-the-enterprise-llm-king-with-its-new-open-source-granite-3-1-models/"&gt;Granite 3.1&lt;/a&gt; and &lt;a href="https://venturebeat.com/ai/ibm-granite-3-2-uses-conditional-reasoning-time-series-forecasting-and-document-vision-to-tackle-challenging-enterprise-use-cases/"&gt;Granite 3.2&lt;/a&gt;, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://venturebeat.com/ai/western-qwen-ibm-wows-with-granite-4-llm-launch-and-hybrid-mamba-transformer/"&gt;Granite 4.0&lt;/a&gt; family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.&lt;/p&gt;&lt;p&gt;Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Shift Toward Scalable Efficiency&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.&lt;/p&gt;&lt;p&gt;By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.&lt;/p&gt;&lt;p&gt;For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;In an industry where model size is often seen as a proxy for intelligence, IBM is charting a different course — one that values &lt;i&gt;efficiency over enormity&lt;/i&gt;, and &lt;i&gt;accessibility over abstraction&lt;/i&gt;.&lt;/p&gt;&lt;p&gt;The 114-year-old tech giant&amp;#x27;s &lt;a href="https://huggingface.co/blog/ibm-granite/granite-4-nano"&gt;four new Granite 4.0 Nano models&lt;/a&gt;, released today, range from just 350 million to 1.5 billion parameters, a fraction of the size of their server-bound cousins from the likes of OpenAI, Anthropic, and Google. &lt;/p&gt;&lt;p&gt;These models are designed to be highly accessible: the 350M variants can run comfortably on a modern laptop CPU with 8–16GB of RAM, while the 1.5B models typically require a GPU with at least 6–8GB of VRAM for smooth performance — or sufficient system RAM and swap for CPU-only inference. This makes them well-suited for developers building applications on consumer hardware or at the edge, without relying on cloud compute.&lt;/p&gt;&lt;p&gt;In fact, the smallest ones can even run locally on your own web browser, as Joshua Lochner aka &lt;a href="https://x.com/xenovacom/status/1983218720366326002"&gt;Xenova&lt;/a&gt;, creator of Transformer.js and a machine learning engineer at Hugging Face, wrote on the social network X.&lt;/p&gt;&lt;div&gt;&lt;/div&gt;&lt;p&gt;&lt;b&gt;All the Granite 4.0 Nano models are released under the Apache 2.0 license&lt;/b&gt; — perfect for use by researchers and enterprise or indie developers, even for commercial usage. &lt;/p&gt;&lt;p&gt;They are natively compatible with llama.cpp, vLLM, and MLX and are certified under ISO 42001 for responsible AI development — a standard IBM helped pioneer.&lt;/p&gt;&lt;p&gt;But in this case, small doesn&amp;#x27;t mean less capable — it might just mean smarter design.&lt;/p&gt;&lt;p&gt;These compact models are built not for data centers, but for edge devices, laptops, and local inference, where compute is scarce and latency matters. &lt;/p&gt;&lt;p&gt;And despite their small size, the Nano models are showing benchmark results that rival or even exceed the performance of larger models in the same category. &lt;/p&gt;&lt;p&gt;The release is a signal that a new AI frontier is rapidly forming — one not dominated by sheer scale, but by &lt;i&gt;strategic scaling&lt;/i&gt;.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;What Exactly Did IBM Release?&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;The &lt;b&gt;Granite 4.0 Nano&lt;/b&gt; family includes four open-source models now available on &lt;a href="https://huggingface.co/collections/ibm-granite/granite-40-nano-language-models"&gt;Hugging Face&lt;/a&gt;:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-1B&lt;/b&gt; (~1.5B parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-H-350M&lt;/b&gt; (~350M parameters) – Hybrid-SSM architecture&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-1B&lt;/b&gt; – Transformer-based variant, parameter count closer to 2B&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Granite-4.0-350M&lt;/b&gt; – Transformer-based variant&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;The H-series models — Granite-4.0-H-1B and H-350M — use a hybrid state space architecture (SSM) that combines efficiency with strong performance, ideal for low-latency edge environments. &lt;/p&gt;&lt;p&gt;Meanwhile, the standard transformer variants — Granite-4.0-1B and 350M — offer broader compatibility with tools like llama.cpp, designed for use cases where hybrid architecture isn’t yet supported. &lt;/p&gt;&lt;p&gt;In practice, the transformer 1B model is closer to 2B parameters, but aligns performance-wise with its hybrid sibling, offering developers flexibility based on their runtime constraints.&lt;/p&gt;&lt;p&gt;“The hybrid variant is a true 1B model. However, the non-hybrid variant is closer to 2B, but we opted to keep the naming aligned to the hybrid variant to make the connection easily visible,” explained Emma, Product Marketing lead for Granite, during a &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit &amp;quot;Ask Me Anything&amp;quot; (AMA) session on r/LocalLLaMA.&lt;/a&gt;&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Competitive Class of Small Models&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM is entering a crowded and rapidly evolving market of small language models (SLMs), competing with offerings like Qwen3, Google&amp;#x27;s Gemma, LiquidAI’s LFM2, and even Mistral’s dense models in the sub-2B parameter space.&lt;/p&gt;&lt;p&gt;While OpenAI and Anthropic focus on models that require clusters of GPUs and sophisticated inference optimization, IBM’s Nano family is aimed squarely at developers who want to run performant LLMs on local or constrained hardware.&lt;/p&gt;&lt;p&gt;In benchmark testing, IBM’s new models consistently top the charts in their class. According to data&lt;a href="https://x.com/neurobongo/status/1983224452838985972"&gt; shared on X by David Cox, VP of AI Models at IBM Research:&lt;/a&gt;&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;On IFEval (instruction following), Granite-4.0-H-1B scored 78.5, outperforming Qwen3-1.7B (73.1) and other 1–2B models.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On BFCLv3 (function/tool calling), Granite-4.0-1B led with a score of 54.8, the highest in its size class.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;On safety benchmarks (SALAD and AttaQ), the Granite models scored over 90%, surpassing similarly sized competitors.&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Overall, the Granite-4.0-1B achieved a leading average benchmark score of 68.3% across general knowledge, math, code, and safety domains.&lt;/p&gt;&lt;p&gt;This performance is especially significant given the hardware constraints these models are designed for. &lt;/p&gt;&lt;p&gt;They require less memory, run faster on CPUs or mobile devices, and don’t need cloud infrastructure or GPU acceleration to deliver usable results.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;Why Model Size Still Matters — But Not Like It Used To&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the early wave of LLMs, bigger meant better — more parameters translated to better generalization, deeper reasoning, and richer output. &lt;/p&gt;&lt;p&gt;But as transformer research matured, it became clear that architecture, training quality, and task-specific tuning could allow smaller models to punch well above their weight class.&lt;/p&gt;&lt;p&gt;IBM is banking on this evolution. By releasing open, small models that are &lt;i&gt;competitive in real-world tasks&lt;/i&gt;, the company is offering an alternative to the monolithic AI APIs that dominate today’s application stack.&lt;/p&gt;&lt;p&gt;In fact, the Nano models address three increasingly important needs:&lt;/p&gt;&lt;ol&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Deployment flexibility&lt;/b&gt; — they run anywhere, from mobile to microservers.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Inference privacy&lt;/b&gt; — users can keep data local with no need to call out to cloud APIs.&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;&lt;b&gt;Openness and auditability&lt;/b&gt; — source code and model weights are publicly available under an open license.&lt;/p&gt;&lt;/li&gt;&lt;/ol&gt;&lt;h3&gt;&lt;b&gt;Community Response and Roadmap Signals&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s Granite team didn’t just launch the models and walk away — they took to &lt;a href="https://www.reddit.com/r/LocalLLaMA/comments/1oichb7/granite_40_nano_language_models/"&gt;Reddit’s open source community r/LocalLLaMA &lt;/a&gt;to engage directly with developers. &lt;/p&gt;&lt;p&gt;In an AMA-style thread, Emma (Product Marketing, Granite) answered technical questions, addressed concerns about naming conventions, and dropped hints about what’s next.&lt;/p&gt;&lt;p&gt;Notable confirmations from the thread:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;&lt;p&gt;A larger Granite 4.0 model is currently in training&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;Reasoning-focused models (&amp;quot;thinking counterparts&amp;quot;) are in the pipeline&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;IBM will release fine-tuning recipes and a full training paper soon&lt;/p&gt;&lt;/li&gt;&lt;li&gt;&lt;p&gt;More tooling and platform compatibility is on the roadmap&lt;/p&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Users responded enthusiastically to the models’ capabilities, especially in instruction-following and structured response tasks. One commenter summed it up:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“This is big if true for a 1B model — if quality is nice and it gives consistent outputs. Function-calling tasks, multilingual dialog, FIM completions… this could be a real workhorse.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;p&gt;Another user remarked:&lt;/p&gt;&lt;blockquote&gt;&lt;p&gt;&lt;i&gt;“The Granite Tiny is already my go-to for web search in LM Studio — better than some Qwen models. Tempted to give Nano a shot.”&lt;/i&gt;&lt;/p&gt;&lt;/blockquote&gt;&lt;h3&gt;&lt;b&gt;Background: IBM Granite and the Enterprise AI Race&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;IBM’s push into large language models began in earnest in late 2023 with the debut of the Granite foundation model family, starting with models like &lt;i&gt;Granite.13b.instruct&lt;/i&gt; and &lt;i&gt;Granite.13b.chat&lt;/i&gt;. Released for use within its Watsonx platform, these initial decoder-only models signaled IBM’s ambition to build enterprise-grade AI systems that prioritize transparency, efficiency, and performance. The company open-sourced select Granite code models under the Apache 2.0 license in mid-2024, laying the groundwork for broader adoption and developer experimentation.&lt;/p&gt;&lt;p&gt;The real inflection point came with &lt;a href="https://venturebeat.com/ai/ibm-debuts-open-source-granite-3-0-llms-for-enterprise-ai/"&gt;Granite 3.0&lt;/a&gt; in October 2024 — a fully open-source suite of general-purpose and domain-specialized models ranging from 1B to 8B parameters. These models emphasized efficiency over brute scale, offering capabilities like longer context windows, instruction tuning, and integrated guardrails. IBM positioned Granite 3.0 as a direct competitor to Meta’s Llama, Alibaba’s Qwen, and Google&amp;#x27;s Gemma — but with a uniquely enterprise-first lens. Later versions, including &lt;a href="https://venturebeat.com/ai/ibm-wants-to-be-the-enterprise-llm-king-with-its-new-open-source-granite-3-1-models/"&gt;Granite 3.1&lt;/a&gt; and &lt;a href="https://venturebeat.com/ai/ibm-granite-3-2-uses-conditional-reasoning-time-series-forecasting-and-document-vision-to-tackle-challenging-enterprise-use-cases/"&gt;Granite 3.2&lt;/a&gt;, introduced even more enterprise-friendly innovations: embedded hallucination detection, time-series forecasting, document vision models, and conditional reasoning toggles.&lt;/p&gt;&lt;p&gt;The &lt;a href="https://venturebeat.com/ai/western-qwen-ibm-wows-with-granite-4-llm-launch-and-hybrid-mamba-transformer/"&gt;Granite 4.0&lt;/a&gt; family, launched in October 2025, represents IBM’s most technically ambitious release yet. It introduces a hybrid architecture that blends transformer and Mamba-2 layers — aiming to combine the contextual precision of attention mechanisms with the memory efficiency of state-space models. This design allows IBM to significantly reduce memory and latency costs for inference, making Granite models viable on smaller hardware while still outperforming peers in instruction-following and function-calling tasks. The launch also includes ISO 42001 certification, cryptographic model signing, and distribution across platforms like Hugging Face, Docker, LM Studio, Ollama, and watsonx.ai.&lt;/p&gt;&lt;p&gt;Across all iterations, IBM’s focus has been clear: build trustworthy, efficient, and legally unambiguous AI models for enterprise use cases. With a permissive Apache 2.0 license, public benchmarks, and an emphasis on governance, the Granite initiative not only responds to rising concerns over proprietary black-box models but also offers a Western-aligned open alternative to the rapid progress from teams like Alibaba’s Qwen. In doing so, Granite positions IBM as a leading voice in what may be the next phase of open-weight, production-ready AI.&lt;/p&gt;&lt;h3&gt;&lt;b&gt;A Shift Toward Scalable Efficiency&lt;/b&gt;&lt;/h3&gt;&lt;p&gt;In the end, IBM’s release of Granite 4.0 Nano models reflects a strategic shift in LLM development: from chasing parameter count records to optimizing usability, openness, and deployment reach.&lt;/p&gt;&lt;p&gt;By combining competitive performance, responsible development practices, and deep engagement with the open-source community, IBM is positioning Granite as not just a family of models — but a platform for building the next generation of lightweight, trustworthy AI systems.&lt;/p&gt;&lt;p&gt;For developers and researchers looking for performance without overhead, the Nano release offers a compelling signal: you don’t need 70 billion parameters to build something powerful — just the right ones.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/ibms-open-source-granite-4-0-nano-ai-models-are-small-enough-to-run-locally</guid><pubDate>Tue, 28 Oct 2025 23:23:00 +0000</pubDate></item><item><title>Building a Healthcare Robot from Simulation to Deployment with NVIDIA Isaac (Hugging Face - Blog)</title><link>https://huggingface.co/blog/lerobotxnvidia-healthcare</link><description>&lt;div class="not-prose mb-6 lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="clem"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg" /&gt;
					
			&lt;/li&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="kalyanvadrevu"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://huggingface.co/avatars/e4e855ad75d5d86959765610d67668b3.svg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;



&lt;/div&gt;&lt;/div&gt;
					
					

					&lt;!-- HTML_TAG_START --&gt;

&lt;p&gt;A hands-on guide to collecting data, training policies, and deploying autonomous medical robotics workflows on real hardware&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Table-of-Contents
	&lt;/span&gt;
&lt;/h2&gt;

&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Introduction
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation has been a cornerstone in medical imaging to address the data gap. However, in healthcare robotics until now, it's often been too slow, siloed, or difficult to translate into real-world systems.&lt;/p&gt;
&lt;p&gt;NVIDIA Isaac for Healthcare, a developer framework for AI healthcare robotics, enables healthcare robotics developers in solving these challenges via offering integrated data collection, training, and evaluation pipelines that work across both simulation and hardware. Specifically, the Isaac for Healthcare v0.4 release provides healthcare developers with an end-to-end SO - ARM based starter workflow and the bring your own operating room tutorial. The SO-ARM starter workflow lowers the barrier for MedTech developers to experience the full workflow from simulation to train to deployment and start building and validating autonomous on real hardware right away.&lt;/p&gt;
&lt;p&gt;In this post, we'll walk through the starter workflow and its technical implementation details to help you build a surgical assistant robot in less time than ever imaginable before.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		SO-ARM Starter Workflow; Building an Embodied Surgical Assistant
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;The SO-ARM starter workflow introduces a new way to explore surgical assistance tasks, and providing developers with a complete end-to-end pipeline for autonomous surgical assistance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collect real-world and synthetic data with SO-ARM using the LeRobot&lt;/li&gt;
&lt;li&gt;Fine-tune GR00t N1.5, evaluate in IsaacLab, then deploy to hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This workflow gives developers a safe, repeatable environment to train and refine assistive skills before moving into the Operating Room.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Technical Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow implements a three-stage pipeline that integrates simulation and real hardware:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Collection: Mixed simulation and real-world teleoperation demonstrations using using SO101 and LeRobot&lt;/li&gt;
&lt;li&gt;Model Training: Fine-tuning GR00T N1.5 on combined datasets with dual-camera vision&lt;/li&gt;
&lt;li&gt;Policy Deployment: Real-time inference on physical hardware with RTI DDS communication&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notably, over 93% of the data used for policy training was generated synthetically in simulation, underscoring the strength of simulation in bridging the robotic data gap.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Sim2Real Mixed Training Approach
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow combines simulation and real-world data to address the fundamental challenge that training robots in the real world is expensive and limited, while pure simulation often fails to capture real-world complexities. The approach uses approximately 70 simulation episodes for diverse scenarios and environmental variations, combined with 10-20 real-world episodes for authenticity and grounding. This mixed training creates policies that generalize beyond either domain alone.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Hardware Requirements
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU: RT Core-enabled architecture (Ampere or later) with ≥30GB VRAM for GR00TN1.5 inference&lt;/li&gt;
&lt;li&gt;SO-ARM101 Follower: 6-DOF precision manipulator with dual-camera vision (wrist and room). The SO-ARM101 features WOWROBO vision components, including a wrist-mounted camera with a 3D-printed adapter&lt;/li&gt;
&lt;li&gt;SO-ARM101 Leader: 6-DOF Teleoperation interface for expert demonstration collection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notably, developers could run all the simulation, training and deployment (3 computers needed for physical AI) on one DGX Spark.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Data Collection Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-real-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-real-demo.gif" /&gt;&lt;/p&gt;
&lt;p&gt;For real-world data collection with SO-ARM101 hardware or any other version supported in LeRobot:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;python lerobot-record \ 
  --robot.type=so101_follower \ 
  --robot.port=&amp;lt;follower_port_id&amp;gt; \ 
  --robot.cameras=&lt;span class="hljs-string"&gt;"{wrist: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, room: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}"&lt;/span&gt; \ 
  --robot.id=so101_follower_arm \ 
  --teleop.type=so101_leader \ 
  --teleop.port=&amp;lt;leader_port_id&amp;gt; \ 
  --teleop.id=so101_leader_arm \ 
  --dataset.repo_id=&amp;lt;user&amp;gt;/surgical_assistance/surgical_assistance \ 
  --dataset.num_episodes=15 \ 
  --dataset.single_task=&lt;span class="hljs-string"&gt;"Prepare and hand surgical instruments to surgeon"&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For simulation-based data collection:&lt;/p&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-sim-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-sim-demo.gif" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m simulation.environments.teleoperation_record \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 \ 
  --teleop_device=keyboard


python -m simulation.environments.teleoperation_record \ 
  --port=&amp;lt;your_leader_arm_port_id&amp;gt; \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Simulation Teleoperation Controls
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;For users without physical SO-ARM101 hardware, the workflow provides keyboard-based teleoperation with the following joint controls:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Joint 1 (shoulder_pan): Q (+) / U (-)&lt;/li&gt;
&lt;li&gt;Joint 2 (shoulder_lift): W (+) / I (-)&lt;/li&gt;
&lt;li&gt;Joint 3 (elbow_flex): E (+) / O (-)&lt;/li&gt;
&lt;li&gt;Joint 4 (wrist_flex): A (+) / J (-)&lt;/li&gt;
&lt;li&gt;Joint 5 (wrist_roll): S (+) / K (-)&lt;/li&gt;
&lt;li&gt;Joint 6 (gripper): D (+) / L (-)&lt;/li&gt;
&lt;li&gt;R Key: Reset recording environment&lt;/li&gt;
&lt;li&gt;N Key: Mark episode as successful&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Model Training Pipeline
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;After collecting both simulation and real-world data, convert and combine datasets for training:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m training.hdf5_to_lerobot \ 
  --repo_id=surgical_assistance_dataset \ 
  --hdf5_path=/path/to/your/sim_dataset.hdf5 \ 
  --task_description=&lt;span class="hljs-string"&gt;"Autonomous surgical instrument handling and preparation"&lt;/span&gt; 


python -m training.gr00t_n1_5.train \ 
  --dataset_path /path/to/your/surgical_assistance_dataset \ 
  --output_dir /path/to/surgical_checkpoints \ 
  --data_config so100_dualcam 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trained model processes natural language instructions such as "Prepare the scalpel for the surgeon" or "Hand me the forceps" and executes the corresponding robotic actions. With LeRobot latest release (0.4.0) you will be able to fine-tune Gr00t N1.5 natively in LeRobot!&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		End-to-End Sim Collect–Train–Eval Pipelines
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation is most powerful when it's part of a loop: collect → train → evaluate → deploy.&lt;/p&gt;
&lt;p&gt;With v0.3, IsaacLab supports this full pipeline:&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Generate Synthetic Data in Simulation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Teleoperate robots using keyboard or hardware controllers&lt;/li&gt;
&lt;li&gt;Capture multi-camera observations, robot states, and actions&lt;/li&gt;
&lt;li&gt;Create diverse datasets with edge cases impossible to collect safely in real environments&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Train and Evaluate Policies
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deep integration with Isaac Lab's RL framework for PPO training&lt;/li&gt;
&lt;li&gt;Parallel environments (thousands of simulations simultaneously)&lt;/li&gt;
&lt;li&gt;Built-in trajectory analysis and success metrics&lt;/li&gt;
&lt;li&gt;Statistical validation across varied scenarios&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Convert Models to TensorRT
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Automatic optimization for production deployment&lt;/li&gt;
&lt;li&gt;Support for dynamic shapes and multi-camera inference&lt;/li&gt;
&lt;li&gt;Benchmarking tools to verify real-time performance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This reduces time from experiment to deployment and makes sim2real a practical part of daily development.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Getting Started
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Isaac for Healthcare SO-ARM Starter Workflow is available now. To get started:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository: &lt;code&gt;git clone https://github.com/isaac-for-healthcare/i4h-workflows.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Choose a workflow: Start with the SO-ARM Starter Workflow for surgical assistance or explore other workflows&lt;/li&gt;
&lt;li&gt;Run the setup: Each workflow includes an automated setup script (e.g., &lt;code&gt;tools/env_setup_so_arm_starter.sh&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h3&gt;

&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;div class="not-prose mb-6 lg:hidden"&gt;&lt;div class="SVELTE_HYDRATER contents"&gt;&lt;div class="flex flex-wrap items-center gap-2.5 pt-1  z-1 lg:sticky lg:top-8"&gt;
	


	&lt;ul class="flex items-center  flex-row  text-base   "&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="clem"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://cdn-avatars.huggingface.co/v1/production/uploads/1583857146757-5e67bdd61009063689407479.jpeg" /&gt;
					
			&lt;/li&gt;&lt;li class=" -mr-2 h-5 w-5 md:h-6 md:w-6   bg-linear-to-br block flex-none rounded-full border-2 border-white from-gray-300 to-gray-100 dark:border-gray-900 dark:from-gray-600 dark:to-gray-800" title="kalyanvadrevu"&gt;&lt;img alt="alt" class="overflow-hidden rounded-full" src="https://huggingface.co/avatars/e4e855ad75d5d86959765610d67668b3.svg" /&gt;
					
			&lt;/li&gt;

		&lt;li class="text-xs text-gray-600 hover:text-gray-700 dark:text-gray-400 dark:hover:text-gray-300 order-last ml-3"&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;



&lt;/div&gt;&lt;/div&gt;
					
					

					&lt;!-- HTML_TAG_START --&gt;

&lt;p&gt;A hands-on guide to collecting data, training policies, and deploying autonomous medical robotics workflows on real hardware&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Table-of-Contents
	&lt;/span&gt;
&lt;/h2&gt;

&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Introduction
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation has been a cornerstone in medical imaging to address the data gap. However, in healthcare robotics until now, it's often been too slow, siloed, or difficult to translate into real-world systems.&lt;/p&gt;
&lt;p&gt;NVIDIA Isaac for Healthcare, a developer framework for AI healthcare robotics, enables healthcare robotics developers in solving these challenges via offering integrated data collection, training, and evaluation pipelines that work across both simulation and hardware. Specifically, the Isaac for Healthcare v0.4 release provides healthcare developers with an end-to-end SO - ARM based starter workflow and the bring your own operating room tutorial. The SO-ARM starter workflow lowers the barrier for MedTech developers to experience the full workflow from simulation to train to deployment and start building and validating autonomous on real hardware right away.&lt;/p&gt;
&lt;p&gt;In this post, we'll walk through the starter workflow and its technical implementation details to help you build a surgical assistant robot in less time than ever imaginable before.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		SO-ARM Starter Workflow; Building an Embodied Surgical Assistant
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;The SO-ARM starter workflow introduces a new way to explore surgical assistance tasks, and providing developers with a complete end-to-end pipeline for autonomous surgical assistance:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Collect real-world and synthetic data with SO-ARM using the LeRobot&lt;/li&gt;
&lt;li&gt;Fine-tune GR00t N1.5, evaluate in IsaacLab, then deploy to hardware&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This workflow gives developers a safe, repeatable environment to train and refine assistive skills before moving into the Operating Room.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Technical Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow implements a three-stage pipeline that integrates simulation and real hardware:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Data Collection: Mixed simulation and real-world teleoperation demonstrations using using SO101 and LeRobot&lt;/li&gt;
&lt;li&gt;Model Training: Fine-tuning GR00T N1.5 on combined datasets with dual-camera vision&lt;/li&gt;
&lt;li&gt;Policy Deployment: Real-time inference on physical hardware with RTI DDS communication&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Notably, over 93% of the data used for policy training was generated synthetically in simulation, underscoring the strength of simulation in bridging the robotic data gap.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Sim2Real Mixed Training Approach
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow combines simulation and real-world data to address the fundamental challenge that training robots in the real world is expensive and limited, while pure simulation often fails to capture real-world complexities. The approach uses approximately 70 simulation episodes for diverse scenarios and environmental variations, combined with 10-20 real-world episodes for authenticity and grounding. This mixed training creates policies that generalize beyond either domain alone.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Hardware Requirements
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The workflow requires:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GPU: RT Core-enabled architecture (Ampere or later) with ≥30GB VRAM for GR00TN1.5 inference&lt;/li&gt;
&lt;li&gt;SO-ARM101 Follower: 6-DOF precision manipulator with dual-camera vision (wrist and room). The SO-ARM101 features WOWROBO vision components, including a wrist-mounted camera with a 3D-printed adapter&lt;/li&gt;
&lt;li&gt;SO-ARM101 Leader: 6-DOF Teleoperation interface for expert demonstration collection&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Notably, developers could run all the simulation, training and deployment (3 computers needed for physical AI) on one DGX Spark.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Data Collection Implementation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-real-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-real-demo.gif" /&gt;&lt;/p&gt;
&lt;p&gt;For real-world data collection with SO-ARM101 hardware or any other version supported in LeRobot:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;python lerobot-record \ 
  --robot.type=so101_follower \ 
  --robot.port=&amp;lt;follower_port_id&amp;gt; \ 
  --robot.cameras=&lt;span class="hljs-string"&gt;"{wrist: {type: opencv, index_or_path: 0, width: 640, height: 480, fps: 30}, room: {type: opencv, index_or_path: 2, width: 640, height: 480, fps: 30}}"&lt;/span&gt; \ 
  --robot.id=so101_follower_arm \ 
  --teleop.type=so101_leader \ 
  --teleop.port=&amp;lt;leader_port_id&amp;gt; \ 
  --teleop.id=so101_leader_arm \ 
  --dataset.repo_id=&amp;lt;user&amp;gt;/surgical_assistance/surgical_assistance \ 
  --dataset.num_episodes=15 \ 
  --dataset.single_task=&lt;span class="hljs-string"&gt;"Prepare and hand surgical instruments to surgeon"&lt;/span&gt; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For simulation-based data collection:&lt;/p&gt;
&lt;p&gt;&lt;img alt="so100-healthcare-sim-demo" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/lerobot-blog/nvidia-healthcare/lerobotxnvidia-healthcare-sim-demo.gif" /&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m simulation.environments.teleoperation_record \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 \ 
  --teleop_device=keyboard


python -m simulation.environments.teleoperation_record \ 
  --port=&amp;lt;your_leader_arm_port_id&amp;gt; \ 
  --enable_cameras \ 
  --record \ 
  --dataset_path=/path/to/save/dataset.hdf5 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Simulation Teleoperation Controls
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;For users without physical SO-ARM101 hardware, the workflow provides keyboard-based teleoperation with the following joint controls:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Joint 1 (shoulder_pan): Q (+) / U (-)&lt;/li&gt;
&lt;li&gt;Joint 2 (shoulder_lift): W (+) / I (-)&lt;/li&gt;
&lt;li&gt;Joint 3 (elbow_flex): E (+) / O (-)&lt;/li&gt;
&lt;li&gt;Joint 4 (wrist_flex): A (+) / J (-)&lt;/li&gt;
&lt;li&gt;Joint 5 (wrist_roll): S (+) / K (-)&lt;/li&gt;
&lt;li&gt;Joint 6 (gripper): D (+) / L (-)&lt;/li&gt;
&lt;li&gt;R Key: Reset recording environment&lt;/li&gt;
&lt;li&gt;N Key: Mark episode as successful&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Model Training Pipeline
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;After collecting both simulation and real-world data, convert and combine datasets for training:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-bash"&gt;
python -m training.hdf5_to_lerobot \ 
  --repo_id=surgical_assistance_dataset \ 
  --hdf5_path=/path/to/your/sim_dataset.hdf5 \ 
  --task_description=&lt;span class="hljs-string"&gt;"Autonomous surgical instrument handling and preparation"&lt;/span&gt; 


python -m training.gr00t_n1_5.train \ 
  --dataset_path /path/to/your/surgical_assistance_dataset \ 
  --output_dir /path/to/surgical_checkpoints \ 
  --data_config so100_dualcam 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The trained model processes natural language instructions such as "Prepare the scalpel for the surgeon" or "Hand me the forceps" and executes the corresponding robotic actions. With LeRobot latest release (0.4.0) you will be able to fine-tune Gr00t N1.5 natively in LeRobot!&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		End-to-End Sim Collect–Train–Eval Pipelines
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Simulation is most powerful when it's part of a loop: collect → train → evaluate → deploy.&lt;/p&gt;
&lt;p&gt;With v0.3, IsaacLab supports this full pipeline:&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Generate Synthetic Data in Simulation
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Teleoperate robots using keyboard or hardware controllers&lt;/li&gt;
&lt;li&gt;Capture multi-camera observations, robot states, and actions&lt;/li&gt;
&lt;li&gt;Create diverse datasets with edge cases impossible to collect safely in real environments&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Train and Evaluate Policies
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Deep integration with Isaac Lab's RL framework for PPO training&lt;/li&gt;
&lt;li&gt;Parallel environments (thousands of simulations simultaneously)&lt;/li&gt;
&lt;li&gt;Built-in trajectory analysis and success metrics&lt;/li&gt;
&lt;li&gt;Statistical validation across varied scenarios&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Convert Models to TensorRT
	&lt;/span&gt;
&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Automatic optimization for production deployment&lt;/li&gt;
&lt;li&gt;Support for dynamic shapes and multi-camera inference&lt;/li&gt;
&lt;li&gt;Benchmarking tools to verify real-time performance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This reduces time from experiment to deployment and makes sim2real a practical part of daily development.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Getting Started
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Isaac for Healthcare SO-ARM Starter Workflow is available now. To get started:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Clone the repository: &lt;code&gt;git clone https://github.com/isaac-for-healthcare/i4h-workflows.git&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Choose a workflow: Start with the SO-ARM Starter Workflow for surgical assistance or explore other workflows&lt;/li&gt;
&lt;li&gt;Run the setup: Each workflow includes an automated setup script (e.g., &lt;code&gt;tools/env_setup_so_arm_starter.sh&lt;/code&gt;)&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h3&gt;

&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/lerobotxnvidia-healthcare</guid><pubDate>Wed, 29 Oct 2025 00:00:00 +0000</pubDate></item><item><title>‘Silicon Valley’ star Thomas Middleditch makes a surprise appearance at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/10/28/silicon-valley-star-thomas-middleditch-makes-a-surprise-appearance-at-techcrunch-disrupt-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/04/kumail-nanjiani-thomas-middleditch-martin-starr-zach-woods-photo-cred-john-p-johnson-for-hbo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you were wandering the Expo Hall at TechCrunch Disrupt 2025, or watching our pitch stage earlier Tuesday, you might have noticed a familiar face from Pied Piper. Thomas Middleditch, who starred in HBO’s popular “Silicon Valley” show that prominently featured Disrupt back in 2014, had a planned takeover of Australian startup (and Battlefield 200 competitor) Othelia’s presentation at the pitch showcase stage.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can take a look at his full rundown below, including the actual pitch for Othelia’s mission to build a Cursor-like platform for storytellers.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Middleditch, amid being pitched, photographed, and mildly swarmed at the Expo hall, also took some time to chat with us about his POV on the conference, AI, and how he uses AI platforms for his own Improv With Robots YouTube channel.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/04/kumail-nanjiani-thomas-middleditch-martin-starr-zach-woods-photo-cred-john-p-johnson-for-hbo.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;If you were wandering the Expo Hall at TechCrunch Disrupt 2025, or watching our pitch stage earlier Tuesday, you might have noticed a familiar face from Pied Piper. Thomas Middleditch, who starred in HBO’s popular “Silicon Valley” show that prominently featured Disrupt back in 2014, had a planned takeover of Australian startup (and Battlefield 200 competitor) Othelia’s presentation at the pitch showcase stage.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can take a look at his full rundown below, including the actual pitch for Othelia’s mission to build a Cursor-like platform for storytellers.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Middleditch, amid being pitched, photographed, and mildly swarmed at the Expo hall, also took some time to chat with us about his POV on the conference, AI, and how he uses AI platforms for his own Improv With Robots YouTube channel.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/10/28/silicon-valley-star-thomas-middleditch-makes-a-surprise-appearance-at-techcrunch-disrupt-2025/</guid><pubDate>Wed, 29 Oct 2025 00:00:18 +0000</pubDate></item></channel></rss>