<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Thu, 04 Dec 2025 06:35:38 +0000</lastBuildDate><item><title>MIT engineers design an aerial microrobot that can fly as fast as a bumblebee (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/mit-engineers-design-aerial-microrobot-fly-like-bumblebee-1203</link><description>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;In the future, tiny flying robots could be deployed to aid in the search for survivors trapped beneath the rubble after a devastating earthquake. Like real insects, these robots could flit through tight spaces larger robots can’t reach, while simultaneously dodging stationary obstacles and pieces of falling rubble.&lt;/p&gt;&lt;p&gt;So far, aerial microrobots have only been able to fly slowly along smooth trajectories, far from the swift, agile flight of real insects — until now.&lt;/p&gt;&lt;p&gt;MIT researchers have demonstrated aerial microrobots that can fly with speed and agility that is comparable to their biological counterparts. A collaborative team designed a new AI-based controller for the robotic bug that enabled it to follow gymnastic flight paths, such as executing continuous body flips.&lt;/p&gt;&lt;p&gt;With a two-part control scheme that combines high performance with computational efficiency, the robot’s speed and acceleration increased by about 450 percent and 250 percent, respectively, compared to the researchers’ best previous demonstrations.&lt;/p&gt;&lt;p&gt;The speedy robot was agile enough to complete 10 consecutive somersaults in 11 seconds, even when wind disturbances threatened to push it off course.&lt;/p&gt;&lt;figure class="align-center"&gt;
&lt;img alt="Animation of a flying, flipping microrobot" height="338" src="https://news.mit.edu/sites/default/files/images/inline/MIT-Microrobot-demo-05-press.gif" width="600" /&gt;
&lt;figcaption&gt;A microrobot flips 10 times in 11 seconds.&lt;p&gt;Credit: Courtesy of the&amp;nbsp;Soft and Micro Robotics Laboratory&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“We want to be able to use these robots in scenarios that more traditional quad copter robots would have trouble flying into, but that insects could navigate. Now, with our bioinspired control framework, the flight performance of our robot is comparable to insects in terms of speed, acceleration, and the pitching angle. This is quite an exciting step toward that future goal,” says Kevin Chen, an associate professor in the Department of Electrical Engineering and Computer Science (EECS), head of the Soft and Micro Robotics Laboratory within the Research Laboratory of Electronics (RLE), and co-senior author of a paper on the robot.&lt;/p&gt;&lt;p&gt;Chen is joined on the paper by co-lead authors Yi-Hsuan Hsiao, an EECS MIT graduate student; Andrea Tagliabue PhD ’24; and Owen Matteson, a graduate student in the Department of Aeronautics and Astronautics (AeroAstro); as well as EECS graduate student Suhan Kim; Tong Zhao MEng ’23; and co-senior author Jonathan P. How, the Ford Professor of Engineering in the Department of Aeronautics and Astronautics and a principal investigator in the Laboratory for Information and Decision Systems (LIDS). The research appears today in &lt;em&gt;Science Advances&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;An AI controller&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Chen’s group has been building robotic insects for more than five years.&lt;/p&gt;&lt;p&gt;They recently developed a&amp;nbsp;more durable version of their tiny robot, a microcassette-sized device that weighs less than a paperclip. The new version utilizes larger, flapping wings that enable more agile movements. They are powered by a set of squishy artificial muscles that flap the wings at an extremely fast rate.&lt;/p&gt;&lt;p&gt;But the controller — the “brain” of the robot that determines its position and tells it where to fly — was hand-tuned by a human, limiting the robot’s performance.&lt;/p&gt;&lt;p&gt;For the robot to fly quickly and aggressively like a real insect, it needed a more robust controller that could account for uncertainty and perform complex optimizations quickly.&lt;/p&gt;&lt;p&gt;Such a controller would be too computationally intensive to be deployed in real time, especially with the complicated aerodynamics of the lightweight robot.&lt;/p&gt;&lt;p&gt;To overcome this challenge, Chen’s group joined forces with How’s team and, together, they crafted a two-step, AI-driven control scheme that provides the robustness necessary for complex, rapid maneuvers, and the computational efficiency needed for real-time deployment.&lt;/p&gt;&lt;p&gt;“The hardware advances pushed the controller so there was more we could do on the software side, but at the same time, as the controller developed, there was more they could do with the hardware. As Kevin’s team demonstrates new capabilities, we demonstrate that we can utilize them,” How says.&lt;/p&gt;&lt;p&gt;For the first step, the team built what is known as a model-predictive controller. This type of powerful controller uses a dynamic, mathematical model to predict the behavior of the robot and plan the optimal series of actions to safely follow a trajectory.&lt;/p&gt;&lt;p&gt;While computationally intensive, it can plan challenging maneuvers like aerial somersaults, rapid turns, and aggressive body tilting. This high-performance planner is also designed to consider constraints on the force and torque the robot could apply, which is essential for avoiding collisions.&lt;/p&gt;&lt;p&gt;For instance, to perform multiple flips in a row, the robot would need to decelerate in such a way that its initial conditions are exactly right for doing the flip again.&lt;/p&gt;&lt;p&gt;“If small errors creep in, and you try to repeat that flip 10 times with those small errors, the robot will just crash. We need to have robust flight control,” How says.&lt;/p&gt;&lt;p&gt;They use this expert planner to train a “policy” based on a deep-learning model, to control the robot in real time, through a process called imitation learning. A policy is the robot’s decision-making engine, which tells the robot where and how to fly.&lt;/p&gt;&lt;p&gt;Essentially, the imitation-learning process compresses the powerful controller into a computationally efficient AI model that can run very fast.&lt;/p&gt;&lt;p&gt;The key was having a smart way to create just enough training data, which would teach the policy everything it needs to know for aggressive maneuvers.&lt;/p&gt;&lt;p&gt;“The robust training method is the secret sauce of this technique,” How explains.&lt;/p&gt;&lt;p&gt;The AI-driven policy takes robot positions as inputs and outputs control commands in real time, such as thrust force and torques.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Insect-like performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In their experiments, this two-step approach enabled the insect-scale robot to fly 447 percent faster while exhibiting a 255 percent increase in acceleration. The robot was able to complete 10 somersaults in 11 seconds, and the tiny robot never strayed more than 4 or 5 centimeters off its planned trajectory.&lt;/p&gt;&lt;p&gt;“This work demonstrates that soft and microrobots, traditionally limited in speed, can now leverage advanced control algorithms to achieve agility approaching that of natural insects and larger robots, opening up new opportunities for multimodal locomotion,” says Hsiao.&lt;/p&gt;&lt;p&gt;The researchers were also able to demonstrate saccade movement, which occurs when insects pitch very aggressively, fly rapidly to a certain position, and then pitch the other way to stop. This rapid acceleration and deceleration help insects localize themselves and see clearly.&lt;/p&gt;&lt;p&gt;“This bio-mimicking flight behavior could help us in the future when we start putting cameras and sensors on board the robot,” Chen says.&lt;/p&gt;&lt;p&gt;Adding sensors and cameras so the microrobots can fly outdoors, without being attached to a complex motion capture system, will be a major area of future work.&lt;/p&gt;&lt;p&gt;The researchers also want to study how onboard sensors could help the robots avoid colliding with one another or coordinate navigation.&lt;/p&gt;&lt;p&gt;“For the micro-robotics community, I hope this paper signals a paradigm shift by showing that we can develop a new control architecture that is high-performing and efficient at the same time,” says Chen.&lt;/p&gt;&lt;p&gt;“This work is especially impressive because these robots still perform precise flips and fast turns despite the large uncertainties that come from relatively large fabrication tolerances in small-scale manufacturing, wind gusts of more than 1 meter per second, and even its power tether wrapping around the robot as it performs repeated flips,” says Sarah Bergbreiter, a professor of mechanical engineering at Carnegie Mellon University, who was not involved with this work.&lt;/p&gt;&lt;p&gt;“Although the controller currently runs on an external computer rather than onboard the robot, the authors demonstrate that similar, but less precise, control policies may be feasible even with the more limited computation available on an insect-scale robot. This is exciting because it points toward future insect-scale robots with agility approaching that of their biological counterparts,” she adds.&lt;/p&gt;&lt;p&gt;This research is funded, in part, by the National Science Foundation (NSF), the Office of Naval Research, Air Force Office of Scientific Research, MathWorks, and the Zakhartchenko Fellowship.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;In the future, tiny flying robots could be deployed to aid in the search for survivors trapped beneath the rubble after a devastating earthquake. Like real insects, these robots could flit through tight spaces larger robots can’t reach, while simultaneously dodging stationary obstacles and pieces of falling rubble.&lt;/p&gt;&lt;p&gt;So far, aerial microrobots have only been able to fly slowly along smooth trajectories, far from the swift, agile flight of real insects — until now.&lt;/p&gt;&lt;p&gt;MIT researchers have demonstrated aerial microrobots that can fly with speed and agility that is comparable to their biological counterparts. A collaborative team designed a new AI-based controller for the robotic bug that enabled it to follow gymnastic flight paths, such as executing continuous body flips.&lt;/p&gt;&lt;p&gt;With a two-part control scheme that combines high performance with computational efficiency, the robot’s speed and acceleration increased by about 450 percent and 250 percent, respectively, compared to the researchers’ best previous demonstrations.&lt;/p&gt;&lt;p&gt;The speedy robot was agile enough to complete 10 consecutive somersaults in 11 seconds, even when wind disturbances threatened to push it off course.&lt;/p&gt;&lt;figure class="align-center"&gt;
&lt;img alt="Animation of a flying, flipping microrobot" height="338" src="https://news.mit.edu/sites/default/files/images/inline/MIT-Microrobot-demo-05-press.gif" width="600" /&gt;
&lt;figcaption&gt;A microrobot flips 10 times in 11 seconds.&lt;p&gt;Credit: Courtesy of the&amp;nbsp;Soft and Micro Robotics Laboratory&lt;/p&gt;&lt;/figcaption&gt;
&lt;/figure&gt;
        

      &lt;/div&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;“We want to be able to use these robots in scenarios that more traditional quad copter robots would have trouble flying into, but that insects could navigate. Now, with our bioinspired control framework, the flight performance of our robot is comparable to insects in terms of speed, acceleration, and the pitching angle. This is quite an exciting step toward that future goal,” says Kevin Chen, an associate professor in the Department of Electrical Engineering and Computer Science (EECS), head of the Soft and Micro Robotics Laboratory within the Research Laboratory of Electronics (RLE), and co-senior author of a paper on the robot.&lt;/p&gt;&lt;p&gt;Chen is joined on the paper by co-lead authors Yi-Hsuan Hsiao, an EECS MIT graduate student; Andrea Tagliabue PhD ’24; and Owen Matteson, a graduate student in the Department of Aeronautics and Astronautics (AeroAstro); as well as EECS graduate student Suhan Kim; Tong Zhao MEng ’23; and co-senior author Jonathan P. How, the Ford Professor of Engineering in the Department of Aeronautics and Astronautics and a principal investigator in the Laboratory for Information and Decision Systems (LIDS). The research appears today in &lt;em&gt;Science Advances&lt;/em&gt;.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;An AI controller&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Chen’s group has been building robotic insects for more than five years.&lt;/p&gt;&lt;p&gt;They recently developed a&amp;nbsp;more durable version of their tiny robot, a microcassette-sized device that weighs less than a paperclip. The new version utilizes larger, flapping wings that enable more agile movements. They are powered by a set of squishy artificial muscles that flap the wings at an extremely fast rate.&lt;/p&gt;&lt;p&gt;But the controller — the “brain” of the robot that determines its position and tells it where to fly — was hand-tuned by a human, limiting the robot’s performance.&lt;/p&gt;&lt;p&gt;For the robot to fly quickly and aggressively like a real insect, it needed a more robust controller that could account for uncertainty and perform complex optimizations quickly.&lt;/p&gt;&lt;p&gt;Such a controller would be too computationally intensive to be deployed in real time, especially with the complicated aerodynamics of the lightweight robot.&lt;/p&gt;&lt;p&gt;To overcome this challenge, Chen’s group joined forces with How’s team and, together, they crafted a two-step, AI-driven control scheme that provides the robustness necessary for complex, rapid maneuvers, and the computational efficiency needed for real-time deployment.&lt;/p&gt;&lt;p&gt;“The hardware advances pushed the controller so there was more we could do on the software side, but at the same time, as the controller developed, there was more they could do with the hardware. As Kevin’s team demonstrates new capabilities, we demonstrate that we can utilize them,” How says.&lt;/p&gt;&lt;p&gt;For the first step, the team built what is known as a model-predictive controller. This type of powerful controller uses a dynamic, mathematical model to predict the behavior of the robot and plan the optimal series of actions to safely follow a trajectory.&lt;/p&gt;&lt;p&gt;While computationally intensive, it can plan challenging maneuvers like aerial somersaults, rapid turns, and aggressive body tilting. This high-performance planner is also designed to consider constraints on the force and torque the robot could apply, which is essential for avoiding collisions.&lt;/p&gt;&lt;p&gt;For instance, to perform multiple flips in a row, the robot would need to decelerate in such a way that its initial conditions are exactly right for doing the flip again.&lt;/p&gt;&lt;p&gt;“If small errors creep in, and you try to repeat that flip 10 times with those small errors, the robot will just crash. We need to have robust flight control,” How says.&lt;/p&gt;&lt;p&gt;They use this expert planner to train a “policy” based on a deep-learning model, to control the robot in real time, through a process called imitation learning. A policy is the robot’s decision-making engine, which tells the robot where and how to fly.&lt;/p&gt;&lt;p&gt;Essentially, the imitation-learning process compresses the powerful controller into a computationally efficient AI model that can run very fast.&lt;/p&gt;&lt;p&gt;The key was having a smart way to create just enough training data, which would teach the policy everything it needs to know for aggressive maneuvers.&lt;/p&gt;&lt;p&gt;“The robust training method is the secret sauce of this technique,” How explains.&lt;/p&gt;&lt;p&gt;The AI-driven policy takes robot positions as inputs and outputs control commands in real time, such as thrust force and torques.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Insect-like performance&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In their experiments, this two-step approach enabled the insect-scale robot to fly 447 percent faster while exhibiting a 255 percent increase in acceleration. The robot was able to complete 10 somersaults in 11 seconds, and the tiny robot never strayed more than 4 or 5 centimeters off its planned trajectory.&lt;/p&gt;&lt;p&gt;“This work demonstrates that soft and microrobots, traditionally limited in speed, can now leverage advanced control algorithms to achieve agility approaching that of natural insects and larger robots, opening up new opportunities for multimodal locomotion,” says Hsiao.&lt;/p&gt;&lt;p&gt;The researchers were also able to demonstrate saccade movement, which occurs when insects pitch very aggressively, fly rapidly to a certain position, and then pitch the other way to stop. This rapid acceleration and deceleration help insects localize themselves and see clearly.&lt;/p&gt;&lt;p&gt;“This bio-mimicking flight behavior could help us in the future when we start putting cameras and sensors on board the robot,” Chen says.&lt;/p&gt;&lt;p&gt;Adding sensors and cameras so the microrobots can fly outdoors, without being attached to a complex motion capture system, will be a major area of future work.&lt;/p&gt;&lt;p&gt;The researchers also want to study how onboard sensors could help the robots avoid colliding with one another or coordinate navigation.&lt;/p&gt;&lt;p&gt;“For the micro-robotics community, I hope this paper signals a paradigm shift by showing that we can develop a new control architecture that is high-performing and efficient at the same time,” says Chen.&lt;/p&gt;&lt;p&gt;“This work is especially impressive because these robots still perform precise flips and fast turns despite the large uncertainties that come from relatively large fabrication tolerances in small-scale manufacturing, wind gusts of more than 1 meter per second, and even its power tether wrapping around the robot as it performs repeated flips,” says Sarah Bergbreiter, a professor of mechanical engineering at Carnegie Mellon University, who was not involved with this work.&lt;/p&gt;&lt;p&gt;“Although the controller currently runs on an external computer rather than onboard the robot, the authors demonstrate that similar, but less precise, control policies may be feasible even with the more limited computation available on an insect-scale robot. This is exciting because it points toward future insect-scale robots with agility approaching that of their biological counterparts,” she adds.&lt;/p&gt;&lt;p&gt;This research is funded, in part, by the National Science Foundation (NSF), the Office of Naval Research, Air Force Office of Scientific Research, MathWorks, and the Zakhartchenko Fellowship.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/mit-engineers-design-aerial-microrobot-fly-like-bumblebee-1203</guid><pubDate>Wed, 03 Dec 2025 19:00:00 +0000</pubDate></item><item><title>VCs deploy ‘kingmaking’ strategy to crown AI winners in their infancy (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/03/vcs-deploy-kingmaking-strategy-to-crown-ai-winners-in-their-infancy/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/03/GettyImages-1366296426.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In early October, DualEntry, an AI enterprise resource planning (ERP) startup, announced a $90 million Series A round led by Lightspeed and Khosla Ventures, valuing the one-year-old business at $415 million. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company seeks to replace legacy software like Oracle NetSuite with its offering that can automate routine tasks and provide predictive insights. The massive funding round from top-tier VCs signaled that the startup is likely experiencing phenomenal revenue growth. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, one VC who declined to invest told TechCrunch that DualEntry’s annual recurring revenue (ARR) was just around $400,000 when he reviewed the deal in August. DualEntry’s co-founder, Santiago Nestares, denies that number. When asked about revenue when the deal closed, Nestares said it was “considerably higher than that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even so, an extremely handsome valuation relative to revenue is becoming an increasingly common investment strategy among top-tier VC firms. The tactic is known as “kingmaking.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This approach involves deploying massive funding into one startup in a competitive category, aiming to overwhelm rivals by granting the chosen company a bank-account advantage so significant that it creates the appearance of market dominance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kingmaking isn’t new, but its timing has shifted dramatically.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Venture capitalists have always evaluated a set of competitors and then made a bet on who they think the winner is going to be in a category. What’s different is that it’s happening much earlier,” said Jeremy Kaufmann, a partner at Scale Venture Partners.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This early aggressive&lt;strong&gt; &lt;/strong&gt;funding contrasts with the last investment cycle.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The 2010s version of this was just called ‘capital as a weapon,’” said David Peterson, partner at Angular Ventures. He pointed out that massive funding into Uber and Lyft was a canonical example of this, but the capital weaponization for the ride-sharing companies didn’t begin until they reached their Series C or D rounds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with Uber vs. Lyft, investors in DualEntry’s competitors Rillet and Campfire are evidently just as eager to see their bets succeed with the help of substantive capital. In early August, Rillet raised a $70 million Series B led by a16z and Iconiq, just two months after the company closed a $25 million Series A led by Sequoia.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similarly, Campfire AI had two back-to-back funding rounds. In October, it grabbed a $65 million Series B, just a couple of months after announcing a $35 million Series A round led by Accel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI ERP is just one of the several AI application categories where startups are raising funding in rapid succession. “There’s no new data between rounds. Series Bs happen 27-60 days after Series As regularly,” Jaya Gupta a partner at Foundation Capital, posted on X last month. Besides AI ERP, she wrote that she sees this pattern in categories such as IT service management and SOC compliance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some startups like Cursor or Lovable have reportedly grown at a breakneck pace between their back-to-back rounds, several VCs told TechCrunch that’s not the case for all. AI ERPs and several other categories of startups that raised multiple rounds in 2025 still have ARRs in the single-digit millions, these investors said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although not all VCs agree that kingmaking is a sound investment strategy, there are reasons why offering large amounts of capital could be beneficial even when the startup maintains a modest burn rate. For instance, well-funded startups are perceived as more likely to survive by large enterprise buyers, making them the preferred vendor for significant software purchases. That’s a strategy that helped legal AI startup Harvey attract large law firm customers, investors say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, history shows that massive capitalization offers no guarantee of success, with notable failures, including the logistics company Convoy and the bankruptcy reorg of scooter company Bird.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But those precedents don’t faze major VC firms. They prefer to bet on a category that seems like a good case for AI, and they would rather invest early because, as Peterson put it: “Everybody has fully internalized the lesson of the power law. In the 2010s, companies could grow faster and be bigger than almost anybody had realized. You couldn’t have overpaid if you were an early Uber investor.”&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. &lt;/em&gt;&lt;strong&gt;&lt;em&gt;This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/03/GettyImages-1366296426.jpg?resize=1200,801" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In early October, DualEntry, an AI enterprise resource planning (ERP) startup, announced a $90 million Series A round led by Lightspeed and Khosla Ventures, valuing the one-year-old business at $415 million. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company seeks to replace legacy software like Oracle NetSuite with its offering that can automate routine tasks and provide predictive insights. The massive funding round from top-tier VCs signaled that the startup is likely experiencing phenomenal revenue growth. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;However, one VC who declined to invest told TechCrunch that DualEntry’s annual recurring revenue (ARR) was just around $400,000 when he reviewed the deal in August. DualEntry’s co-founder, Santiago Nestares, denies that number. When asked about revenue when the deal closed, Nestares said it was “considerably higher than that.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Even so, an extremely handsome valuation relative to revenue is becoming an increasingly common investment strategy among top-tier VC firms. The tactic is known as “kingmaking.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This approach involves deploying massive funding into one startup in a competitive category, aiming to overwhelm rivals by granting the chosen company a bank-account advantage so significant that it creates the appearance of market dominance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kingmaking isn’t new, but its timing has shifted dramatically.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Venture capitalists have always evaluated a set of competitors and then made a bet on who they think the winner is going to be in a category. What’s different is that it’s happening much earlier,” said Jeremy Kaufmann, a partner at Scale Venture Partners.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;This early aggressive&lt;strong&gt; &lt;/strong&gt;funding contrasts with the last investment cycle.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The 2010s version of this was just called ‘capital as a weapon,’” said David Peterson, partner at Angular Ventures. He pointed out that massive funding into Uber and Lyft was a canonical example of this, but the capital weaponization for the ride-sharing companies didn’t begin until they reached their Series C or D rounds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As with Uber vs. Lyft, investors in DualEntry’s competitors Rillet and Campfire are evidently just as eager to see their bets succeed with the help of substantive capital. In early August, Rillet raised a $70 million Series B led by a16z and Iconiq, just two months after the company closed a $25 million Series A led by Sequoia.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similarly, Campfire AI had two back-to-back funding rounds. In October, it grabbed a $65 million Series B, just a couple of months after announcing a $35 million Series A round led by Accel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI ERP is just one of the several AI application categories where startups are raising funding in rapid succession. “There’s no new data between rounds. Series Bs happen 27-60 days after Series As regularly,” Jaya Gupta a partner at Foundation Capital, posted on X last month. Besides AI ERP, she wrote that she sees this pattern in categories such as IT service management and SOC compliance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While some startups like Cursor or Lovable have reportedly grown at a breakneck pace between their back-to-back rounds, several VCs told TechCrunch that’s not the case for all. AI ERPs and several other categories of startups that raised multiple rounds in 2025 still have ARRs in the single-digit millions, these investors said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Although not all VCs agree that kingmaking is a sound investment strategy, there are reasons why offering large amounts of capital could be beneficial even when the startup maintains a modest burn rate. For instance, well-funded startups are perceived as more likely to survive by large enterprise buyers, making them the preferred vendor for significant software purchases. That’s a strategy that helped legal AI startup Harvey attract large law firm customers, investors say.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, history shows that massive capitalization offers no guarantee of success, with notable failures, including the logistics company Convoy and the bankruptcy reorg of scooter company Bird.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But those precedents don’t faze major VC firms. They prefer to bet on a category that seems like a good case for AI, and they would rather invest early because, as Peterson put it: “Everybody has fully internalized the lesson of the power law. In the 2010s, companies could grow faster and be bigger than almost anybody had realized. You couldn’t have overpaid if you were an early Uber investor.”&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. &lt;/em&gt;&lt;strong&gt;&lt;em&gt;This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/03/vcs-deploy-kingmaking-strategy-to-crown-ai-winners-in-their-infancy/</guid><pubDate>Wed, 03 Dec 2025 20:24:12 +0000</pubDate></item><item><title>WordPress’s vibe-coding experiment, Telex, has already been put to real-world use (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/03/wordpresss-vibe-coding-experiment-telex-has-already-been-put-to-real-world-use/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;WordPress’s experimental AI development tool, Telex, has already been put to real-world use, only months after its September debut. At the company’s annual “State of the Word” event on Tuesday in San Francisco, WordPress project co-founder and Automattic CEO Matt Mullenweg shared several examples where Telex had been used within a working WordPress shop to do things like create price comparisons, price calculators, and pull in real-time business hours plus a map link to a retail store, among other examples.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Telex, which Mullenweg previously described as a “v0 or Lovable, but specifically for WordPress,” is essentially the publishing platform’s attempt to build its own vibe-coding tool for the AI era. The software allows developers to generate Gutenberg blocks — the modular bits of text, images, columns, and more — that make up a WordPress website.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the software is still labeled as an experiment, Mullenweg was able to demonstrate several real-world examples that had been built by community creator Nick Hamze. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the first example, Mullenweg showed off a pricing comparison tool built with Telex, noting that these sorts of rich, interactive web elements were something that a developer used to have to custom-build but could now be created in a few seconds.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072424" height="389" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.48.59-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In another demo, a developer used Telex to add real-time store hours, a phone number, and a link to get directions to the header block of their WordPress site. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072423" height="371" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.50.42-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Telex was also shown being used to create a carousel of partner logos on a business’s site, a custom pricing tool, a Google Calendar integration, and a grid for posts on a WordPress homepage, where each post’s card on the site had the same height.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072422" height="373" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.52.28-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Again, things that you used to have to, like, hire developers, do custom software like this would have cost thousands, tens of thousands of dollars to build, even just years ago. We’re now able to do in a browser for pennies,” said Mullenweg. “It’s kind of insane.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072420" height="377" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.55.31-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another developer, Tammie Lister, used Telex to create a new Gutenberg block every day in the month of October, creating things like a playable, ASCII version of Tetris and a trick-or-treat block for Halloween.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an email to TechCrunch, Hamze touted Telex’s capabilities, saying, “the thing that blows my mind and should blow yours is I’m not a developer. I can’t write a single line of code, but I can describe what I want to Telex, and it can make it for me. That freedom is intoxicating, and I’m all in on AI,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think as long as people think of these tools as ‘developer’ tools, they are missing the point on what they can really accomplish, which is letting regular folks do things they never could have done before,” Hamze added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Telex demos were discussed alongside other AI-focused initiatives at WordPress, including architectural developments, like the Abilities API and MCP adapter. The former defines what WordPress can do in a way that AI systems can interpret, the company explained, while the latter exposes those abilities so any MCP-compatible tool can understand and use them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This adapter pattern means WordPress can participate in AI workflows without duplicating logic or creating separate integrations for every AI platform,” Mullenweg told event attendees. “So you can now connect a WordPress installation to popular tools like Claude, Copilot, and many other platforms that support MCP.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, he noted that developers were already using AI in their everyday workflows through tools like Cursor, Claude Code, and other next-generation CLIs. This, Mullenweg said, “means you can refactor projects, search code bases, automate tasks, [and] run scripts with WP CLI alongside the AI agent.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mullenweg said that, in 2026, WordPress would introduce some benchmarks and evaluations that AI models can use to test on WordPress tasks, like changing plugins, editing text, or even manipulating the WordPress interface using browser agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after initial publication with a comment from Hamze.&lt;/em&gt;&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. &lt;/em&gt;&lt;strong&gt;&lt;em&gt;This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;WordPress’s experimental AI development tool, Telex, has already been put to real-world use, only months after its September debut. At the company’s annual “State of the Word” event on Tuesday in San Francisco, WordPress project co-founder and Automattic CEO Matt Mullenweg shared several examples where Telex had been used within a working WordPress shop to do things like create price comparisons, price calculators, and pull in real-time business hours plus a map link to a retail store, among other examples.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Telex, which Mullenweg previously described as a “v0 or Lovable, but specifically for WordPress,” is essentially the publishing platform’s attempt to build its own vibe-coding tool for the AI era. The software allows developers to generate Gutenberg blocks — the modular bits of text, images, columns, and more — that make up a WordPress website.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the software is still labeled as an experiment, Mullenweg was able to demonstrate several real-world examples that had been built by community creator Nick Hamze. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In the first example, Mullenweg showed off a pricing comparison tool built with Telex, noting that these sorts of rich, interactive web elements were something that a developer used to have to custom-build but could now be created in a few seconds.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072424" height="389" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.48.59-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In another demo, a developer used Telex to add real-time store hours, a phone number, and a link to get directions to the header block of their WordPress site. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072423" height="371" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.50.42-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Telex was also shown being used to create a carousel of partner logos on a business’s site, a custom pricing tool, a Google Calendar integration, and a grid for posts on a WordPress homepage, where each post’s card on the site had the same height.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072422" height="373" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.52.28-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word &lt;span class="screen-reader-text"&gt;(opens in a new window)&lt;/span&gt;&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Again, things that you used to have to, like, hire developers, do custom software like this would have cost thousands, tens of thousands of dollars to build, even just years ago. We’re now able to do in a browser for pennies,” said Mullenweg. “It’s kind of insane.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3072420" height="377" src="https://techcrunch.com/wp-content/uploads/2025/12/wp-2025-12-03-at-2.55.31-PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;WordPress State of the Word&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Another developer, Tammie Lister, used Telex to create a new Gutenberg block every day in the month of October, creating things like a playable, ASCII version of Tetris and a trick-or-treat block for Halloween.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In an email to TechCrunch, Hamze touted Telex’s capabilities, saying, “the thing that blows my mind and should blow yours is I’m not a developer. I can’t write a single line of code, but I can describe what I want to Telex, and it can make it for me. That freedom is intoxicating, and I’m all in on AI,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think as long as people think of these tools as ‘developer’ tools, they are missing the point on what they can really accomplish, which is letting regular folks do things they never could have done before,” Hamze added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Telex demos were discussed alongside other AI-focused initiatives at WordPress, including architectural developments, like the Abilities API and MCP adapter. The former defines what WordPress can do in a way that AI systems can interpret, the company explained, while the latter exposes those abilities so any MCP-compatible tool can understand and use them.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This adapter pattern means WordPress can participate in AI workflows without duplicating logic or creating separate integrations for every AI platform,” Mullenweg told event attendees. “So you can now connect a WordPress installation to popular tools like Claude, Copilot, and many other platforms that support MCP.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition, he noted that developers were already using AI in their everyday workflows through tools like Cursor, Claude Code, and other next-generation CLIs. This, Mullenweg said, “means you can refactor projects, search code bases, automate tasks, [and] run scripts with WP CLI alongside the AI agent.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Mullenweg said that, in 2026, WordPress would introduce some benchmarks and evaluations that AI models can use to test on WordPress tasks, like changing plugins, editing text, or even manipulating the WordPress interface using browser agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after initial publication with a comment from Hamze.&lt;/em&gt;&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. &lt;/em&gt;&lt;strong&gt;&lt;em&gt;This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/03/wordpresss-vibe-coding-experiment-telex-has-already-been-put-to-real-world-use/</guid><pubDate>Wed, 03 Dec 2025 20:36:47 +0000</pubDate></item><item><title>Republicans drop Trump-ordered block on state AI laws from defense bill (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/12/republicans-once-again-thwart-trumps-push-to-block-state-ai-laws/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “Widespread and powerful movement” keeps Trump from blocking state AI laws.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2238395456-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2238395456-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Win McNamee / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A Donald Trump-backed push has failed to wedge a federal measure that would block states from passing AI laws for a decade into the National Defense Authorization Act (NDAA).&lt;/p&gt;
&lt;p&gt;House Majority Leader Steve Scalise (R-La.) told reporters Tuesday that a sect of Republicans is now “looking at other places” to potentially pass the measure. Other Republicans opposed including the AI preemption in the defense bill, The Hill reported, joining critics who see value in allowing states to quickly regulate AI risks as they arise.&lt;/p&gt;
&lt;p&gt;For months, Trump has pressured the Republican-led Congress to block state AI laws that the president claims could bog down innovation as AI firms waste time and resources complying with a patchwork of state laws. But Republicans have continually failed to unite behind Trump’s command, first voting against including a similar measure in the “Big Beautiful” budget bill and then this week failing to negotiate a solution to pass the NDAA measure.&lt;/p&gt;
&lt;p&gt;Among Republican lawmakers pushing back this week were Rep. Marjorie Taylor Greene (R-Ga.), Arkansas Gov. Sarah Huckabee Sanders, and Florida Gov. Ron DeSantis, The Hill reported.&lt;/p&gt;
&lt;p&gt;According to Scalise, the effort to block state AI laws is not over, but Republicans caved to backlash over including it in the defense bill, ultimately deciding that the NDAA “wasn’t the best place” for the measure “to fit.” Republicans will continue “looking at other places” to advance the measure, Scalise said, emphasizing that “interest” remains high, because “you know, you’ve seen the president talk about it.”&lt;/p&gt;
&lt;p&gt;“We MUST have one Federal Standard instead of a patchwork of 50 State Regulatory Regimes,” Trump wrote on Truth Social last month. “If we don’t, then China will easily catch us in the AI race. Put it in the NDAA, or pass a separate Bill, and nobody will ever be able to compete with America.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If Congress bombs the assignment to find another way to pass the measure, Trump will likely release an executive order to enforce the policy. Republicans in Congress had dissuaded Trump from releasing a draft of that order, requesting time to find legislation where they believed an AI moratorium could pass.&lt;/p&gt;
&lt;h2&gt;“Widespread” movement blocked Trump’s demand&lt;/h2&gt;
&lt;p&gt;Celebrating the removal of the measure from the NDAA, a bipartisan group that lobbies for AI safety laws, Americans for Responsible Innovation (ARI), noted that Republicans didn’t just face pressure from members of their own party.&lt;/p&gt;
&lt;p&gt;“The controversial proposal had faced backlash from a nationwide, bipartisan coalition of state lawmakers, parents, faith leaders, unions, whistleblowers, and other public advocates,” an ARI press release said.&lt;/p&gt;
&lt;p&gt;This “widespread and powerful” movement “clapped back” at Republicans’ latest “rushed attempt to sneak preemption through Congress,” Brad Carson, ARI’s president, said, because “Americans want safeguards that protect kids, workers, and families, not a rules-free zone for Big Tech.”&lt;/p&gt;
&lt;p&gt;Senate Majority Leader John Thune (R-SD) called the measure “controversial,” The Hill reported, suggesting that a compromise that the White House is currently working on would potentially preserve some of states’ rights to regulate some areas of AI since “you know, both sides are kind of dug in.”&lt;/p&gt;
&lt;h2&gt;$150 million war over states’ rights to regulate AI&lt;/h2&gt;
&lt;p&gt;Perhaps the clearest sign that both sides “are kind of dug in” is a $150 million AI lobbying war that Forbes profiled last month.&lt;/p&gt;
&lt;p&gt;ARI is a dominant group on one side of this war, using funding from “safety-focused” and “effective altruism-aligned” donor networks to support state AI laws that ARI expects can be passed much faster than federal regulations to combat emerging risks.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The major player on the other side, Forbes reported, is Leading the Future (LTF), which is “backed by some of Silicon Valley’s largest investors” who want to block state laws and prefer a federal framework for AI regulation.&lt;/p&gt;
&lt;p&gt;Top priorities for ARI and like-minded groups include protecting kids from dangerous AI models, preventing AI from supercharging crime, protecting against national security threats, and getting ahead of “long-term frontier-model risks,” Forbes reported.&lt;/p&gt;
&lt;p&gt;But while some Republicans have pushed for compromises that protect states’ rights to pass laws shielding kids or preventing fraud, Trump’s opposition to AI safety laws like New York’s “RAISE Act” seems unlikely to wane as the White House mulls weakening the federal preemption.&lt;/p&gt;
&lt;p&gt;Quite the opposite, a Democrat and author the RAISE Act, Alex Bores, has become LTF’s prime target to defeat in 2026, Politico reported. LTF plans to invest many millions in ads to block Bores’ Congressional bid, CNBC reported.&lt;/p&gt;
&lt;p&gt;New York lawmakers passed the RAISE Act this summer, but it’s still waiting for New York’s Democratic governor, Kathy Hochul, to sign it into law. If that happens—potentially by the end of this year—big tech companies like Google and OpenAI will have to submit risk disclosures and safety assessments or else face fines up to $30 million.&lt;/p&gt;
&lt;p&gt;LTF leaders, Zac Moffatt and Josh Vlasto, have accused Bores of “pushing “ideological and politically motivated legislation that would ‘handcuff’ the US and its ability to lead in AI,” Forbes reported. But Bores told Ars that even the tech industry groups spending hundreds of thousands of dollars opposing his law have reported that tech giants would only have to hire one additional person to comply with the law. To him, that shows how “simple” it would be for AI firms to comply with many state laws.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To LTF, whose donors include Marc Andreessen and OpenAI cofounder Greg Brockman, defeating Bores would keep the opposition out of Congress, where it could be easier to meddle with industry dreams that AI won’t be heavily regulated. Scalise argued Tuesday that the AI preemption is necessary to promote an open marketplace, because “AI is where a lot of new massive investment is going” and “we want that money to be invested in America.”&lt;/p&gt;
&lt;p&gt;“And when you see some states starting to put a patchwork of limitations, that’s why it’s come to the federal government’s attention to allow for an open marketplace, so you don’t have limitations that hurt innovation,” Scalise said.&lt;/p&gt;
&lt;p&gt;Bores told Ars that he agrees that a federal law would be superior to a patchwork of state laws, but AI is moving “too quickly,” and “New York had to take action to protect New Yorkers.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Why Bores’ bill has GOP so spooked&lt;/h2&gt;
&lt;p&gt;With a bachelor’s degree in computer science and prior work as an engineer at Palantir, Bores hopes to make it to Congress to help bridge bipartisan gaps and drive innovation in the US. He told Ars that the RAISE Act is not intended to block AI innovation but to “be a first step that deals with the absolute worst possible outcomes” until Congress is done deliberating a federal framework.&lt;/p&gt;
&lt;p&gt;Bores emphasized that stakeholders in the tech industry helped shape the RAISE Act, which he described as “a limited bill that is focused on the most extreme risks.”&lt;/p&gt;
&lt;p&gt;“I would never be the one to say that once the RAISE Act is signed, we’ve solved the problems of AI,” Bores told Ars. Instead, it’s meant to help states combat risks that can’t be undone, such as bad actors using AI to build “a bioweapon or doing an automated crime spree that results in billions of dollars in damage.” The bill defines “critical harm” as “the death or serious injury of 100 people or at least $1 billion in damages,” setting a seemingly high bar for the types of doomsday scenarios that AI firms would have to plan for.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bores agrees with Trump-aligned critics who advocate that the US should “regulate just how people use” AI, “not the development of the technology itself.” But he told Ars that Republicans’ efforts to block states from regulating the models themselves are “a silly way to think about risk,” since “there’s certain catastrophic incidents where if you just said, ‘well, we’ll just sue the person afterwards,’ no one would be satisfied by that resolution.”&lt;/p&gt;
&lt;p&gt;Whether Hochul will sign the RAISE Act has yet to be seen. Earlier this year, California Governor Gavin Newsom vetoed a similar law that the AI industry worried would rock their bottom lines by requiring a “kill switch” in case AI models went off the rails. Newsom did, however, sign a less extreme measure, the Transparency in Frontier Artificial Intelligence Act. And other states, including Colorado and Illinois, have passed similarly broad AI transparency laws providing consumer and employee protections.&lt;/p&gt;
&lt;p&gt;Bores told Ars in mid-November that he’d had informal talks with Hochul about possible changes to the RAISE Act, but she had not yet begun the formal process of proposing amendments. The clock is seemingly ticking, though, as Hochul has to take action on the bill by the end of the year, and once it reaches her desk, she has 10 days to sign it.&lt;/p&gt;
&lt;p&gt;Whether Hochul signs the law or not, Bores will likely continue to face opposition over authoring the bill, as he runs to represent New York’s 12th Congressional District in 2026. With a history of passing bipartisan bills in his state, he’s hoping to be elected so he can work with lawmakers across the aisle to pass other far-reaching tech regulations.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meanwhile, Trump may face pressure to delay an executive order requiring AI preemption, Forbes reported, as “AI’s economic impact and labor displacement” are “rising as voter concerns” ahead of the midterm elections. Public First, a bipartisan initiative aligned with ARI, has said that 97 percent of Americans want AI safety rules, Forbes reported.&lt;/p&gt;
&lt;p&gt;Like Bores, ARI plans to keep pushing a bipartisan movement that could scramble Republicans from ever unifying behind Trump’s message that state AI laws risk throttling US innovation and endangering national security, should a less-regulated AI industry in China race ahead.&lt;/p&gt;
&lt;p&gt;To maintain momentum, ARI created a tracker showing opposition to federal preemption of state AI laws. Among recent commenters logged was Andrew Gounardes, a Democrat and state senator in New York—where Bores noted a poll found that 84 percent of residents supported the RAISE Act, only 8 percent opposed, and 8 percent were undecided. Gounardes joined critics on the far right, like Steve Bannon, who warned that federal preemption was a big gift for Big Tech. AI firms and the venture capitalist lobbyists “don’t want any regulation whatsoever,” Gounardes argued.&lt;/p&gt;
&lt;p&gt;“They say they support a national standard, but in reality, it’s just cheaper for them to buy off Congress to do nothing than it is to try and buy off 50 state legislatures,” Gounardes said.&lt;/p&gt;
&lt;p&gt;Bores expects that his experience in the tech industry could help Congress avoid that fate while his policies like the RAISE Act could sway voters who “don’t want Trump mega-donors writing all tech policy,” he wrote on X.&lt;/p&gt;
&lt;p&gt;“I am someone with a master’s in computer science, two patents, and nearly a decade working in tech,” Bores told CNBC. “If they are scared of people who understand their business regulating their business, they are telling on themselves.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “Widespread and powerful movement” keeps Trump from blocking state AI laws.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2238395456-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2238395456-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Win McNamee / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;A Donald Trump-backed push has failed to wedge a federal measure that would block states from passing AI laws for a decade into the National Defense Authorization Act (NDAA).&lt;/p&gt;
&lt;p&gt;House Majority Leader Steve Scalise (R-La.) told reporters Tuesday that a sect of Republicans is now “looking at other places” to potentially pass the measure. Other Republicans opposed including the AI preemption in the defense bill, The Hill reported, joining critics who see value in allowing states to quickly regulate AI risks as they arise.&lt;/p&gt;
&lt;p&gt;For months, Trump has pressured the Republican-led Congress to block state AI laws that the president claims could bog down innovation as AI firms waste time and resources complying with a patchwork of state laws. But Republicans have continually failed to unite behind Trump’s command, first voting against including a similar measure in the “Big Beautiful” budget bill and then this week failing to negotiate a solution to pass the NDAA measure.&lt;/p&gt;
&lt;p&gt;Among Republican lawmakers pushing back this week were Rep. Marjorie Taylor Greene (R-Ga.), Arkansas Gov. Sarah Huckabee Sanders, and Florida Gov. Ron DeSantis, The Hill reported.&lt;/p&gt;
&lt;p&gt;According to Scalise, the effort to block state AI laws is not over, but Republicans caved to backlash over including it in the defense bill, ultimately deciding that the NDAA “wasn’t the best place” for the measure “to fit.” Republicans will continue “looking at other places” to advance the measure, Scalise said, emphasizing that “interest” remains high, because “you know, you’ve seen the president talk about it.”&lt;/p&gt;
&lt;p&gt;“We MUST have one Federal Standard instead of a patchwork of 50 State Regulatory Regimes,” Trump wrote on Truth Social last month. “If we don’t, then China will easily catch us in the AI race. Put it in the NDAA, or pass a separate Bill, and nobody will ever be able to compete with America.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;If Congress bombs the assignment to find another way to pass the measure, Trump will likely release an executive order to enforce the policy. Republicans in Congress had dissuaded Trump from releasing a draft of that order, requesting time to find legislation where they believed an AI moratorium could pass.&lt;/p&gt;
&lt;h2&gt;“Widespread” movement blocked Trump’s demand&lt;/h2&gt;
&lt;p&gt;Celebrating the removal of the measure from the NDAA, a bipartisan group that lobbies for AI safety laws, Americans for Responsible Innovation (ARI), noted that Republicans didn’t just face pressure from members of their own party.&lt;/p&gt;
&lt;p&gt;“The controversial proposal had faced backlash from a nationwide, bipartisan coalition of state lawmakers, parents, faith leaders, unions, whistleblowers, and other public advocates,” an ARI press release said.&lt;/p&gt;
&lt;p&gt;This “widespread and powerful” movement “clapped back” at Republicans’ latest “rushed attempt to sneak preemption through Congress,” Brad Carson, ARI’s president, said, because “Americans want safeguards that protect kids, workers, and families, not a rules-free zone for Big Tech.”&lt;/p&gt;
&lt;p&gt;Senate Majority Leader John Thune (R-SD) called the measure “controversial,” The Hill reported, suggesting that a compromise that the White House is currently working on would potentially preserve some of states’ rights to regulate some areas of AI since “you know, both sides are kind of dug in.”&lt;/p&gt;
&lt;h2&gt;$150 million war over states’ rights to regulate AI&lt;/h2&gt;
&lt;p&gt;Perhaps the clearest sign that both sides “are kind of dug in” is a $150 million AI lobbying war that Forbes profiled last month.&lt;/p&gt;
&lt;p&gt;ARI is a dominant group on one side of this war, using funding from “safety-focused” and “effective altruism-aligned” donor networks to support state AI laws that ARI expects can be passed much faster than federal regulations to combat emerging risks.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The major player on the other side, Forbes reported, is Leading the Future (LTF), which is “backed by some of Silicon Valley’s largest investors” who want to block state laws and prefer a federal framework for AI regulation.&lt;/p&gt;
&lt;p&gt;Top priorities for ARI and like-minded groups include protecting kids from dangerous AI models, preventing AI from supercharging crime, protecting against national security threats, and getting ahead of “long-term frontier-model risks,” Forbes reported.&lt;/p&gt;
&lt;p&gt;But while some Republicans have pushed for compromises that protect states’ rights to pass laws shielding kids or preventing fraud, Trump’s opposition to AI safety laws like New York’s “RAISE Act” seems unlikely to wane as the White House mulls weakening the federal preemption.&lt;/p&gt;
&lt;p&gt;Quite the opposite, a Democrat and author the RAISE Act, Alex Bores, has become LTF’s prime target to defeat in 2026, Politico reported. LTF plans to invest many millions in ads to block Bores’ Congressional bid, CNBC reported.&lt;/p&gt;
&lt;p&gt;New York lawmakers passed the RAISE Act this summer, but it’s still waiting for New York’s Democratic governor, Kathy Hochul, to sign it into law. If that happens—potentially by the end of this year—big tech companies like Google and OpenAI will have to submit risk disclosures and safety assessments or else face fines up to $30 million.&lt;/p&gt;
&lt;p&gt;LTF leaders, Zac Moffatt and Josh Vlasto, have accused Bores of “pushing “ideological and politically motivated legislation that would ‘handcuff’ the US and its ability to lead in AI,” Forbes reported. But Bores told Ars that even the tech industry groups spending hundreds of thousands of dollars opposing his law have reported that tech giants would only have to hire one additional person to comply with the law. To him, that shows how “simple” it would be for AI firms to comply with many state laws.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To LTF, whose donors include Marc Andreessen and OpenAI cofounder Greg Brockman, defeating Bores would keep the opposition out of Congress, where it could be easier to meddle with industry dreams that AI won’t be heavily regulated. Scalise argued Tuesday that the AI preemption is necessary to promote an open marketplace, because “AI is where a lot of new massive investment is going” and “we want that money to be invested in America.”&lt;/p&gt;
&lt;p&gt;“And when you see some states starting to put a patchwork of limitations, that’s why it’s come to the federal government’s attention to allow for an open marketplace, so you don’t have limitations that hurt innovation,” Scalise said.&lt;/p&gt;
&lt;p&gt;Bores told Ars that he agrees that a federal law would be superior to a patchwork of state laws, but AI is moving “too quickly,” and “New York had to take action to protect New Yorkers.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Why Bores’ bill has GOP so spooked&lt;/h2&gt;
&lt;p&gt;With a bachelor’s degree in computer science and prior work as an engineer at Palantir, Bores hopes to make it to Congress to help bridge bipartisan gaps and drive innovation in the US. He told Ars that the RAISE Act is not intended to block AI innovation but to “be a first step that deals with the absolute worst possible outcomes” until Congress is done deliberating a federal framework.&lt;/p&gt;
&lt;p&gt;Bores emphasized that stakeholders in the tech industry helped shape the RAISE Act, which he described as “a limited bill that is focused on the most extreme risks.”&lt;/p&gt;
&lt;p&gt;“I would never be the one to say that once the RAISE Act is signed, we’ve solved the problems of AI,” Bores told Ars. Instead, it’s meant to help states combat risks that can’t be undone, such as bad actors using AI to build “a bioweapon or doing an automated crime spree that results in billions of dollars in damage.” The bill defines “critical harm” as “the death or serious injury of 100 people or at least $1 billion in damages,” setting a seemingly high bar for the types of doomsday scenarios that AI firms would have to plan for.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bores agrees with Trump-aligned critics who advocate that the US should “regulate just how people use” AI, “not the development of the technology itself.” But he told Ars that Republicans’ efforts to block states from regulating the models themselves are “a silly way to think about risk,” since “there’s certain catastrophic incidents where if you just said, ‘well, we’ll just sue the person afterwards,’ no one would be satisfied by that resolution.”&lt;/p&gt;
&lt;p&gt;Whether Hochul will sign the RAISE Act has yet to be seen. Earlier this year, California Governor Gavin Newsom vetoed a similar law that the AI industry worried would rock their bottom lines by requiring a “kill switch” in case AI models went off the rails. Newsom did, however, sign a less extreme measure, the Transparency in Frontier Artificial Intelligence Act. And other states, including Colorado and Illinois, have passed similarly broad AI transparency laws providing consumer and employee protections.&lt;/p&gt;
&lt;p&gt;Bores told Ars in mid-November that he’d had informal talks with Hochul about possible changes to the RAISE Act, but she had not yet begun the formal process of proposing amendments. The clock is seemingly ticking, though, as Hochul has to take action on the bill by the end of the year, and once it reaches her desk, she has 10 days to sign it.&lt;/p&gt;
&lt;p&gt;Whether Hochul signs the law or not, Bores will likely continue to face opposition over authoring the bill, as he runs to represent New York’s 12th Congressional District in 2026. With a history of passing bipartisan bills in his state, he’s hoping to be elected so he can work with lawmakers across the aisle to pass other far-reaching tech regulations.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meanwhile, Trump may face pressure to delay an executive order requiring AI preemption, Forbes reported, as “AI’s economic impact and labor displacement” are “rising as voter concerns” ahead of the midterm elections. Public First, a bipartisan initiative aligned with ARI, has said that 97 percent of Americans want AI safety rules, Forbes reported.&lt;/p&gt;
&lt;p&gt;Like Bores, ARI plans to keep pushing a bipartisan movement that could scramble Republicans from ever unifying behind Trump’s message that state AI laws risk throttling US innovation and endangering national security, should a less-regulated AI industry in China race ahead.&lt;/p&gt;
&lt;p&gt;To maintain momentum, ARI created a tracker showing opposition to federal preemption of state AI laws. Among recent commenters logged was Andrew Gounardes, a Democrat and state senator in New York—where Bores noted a poll found that 84 percent of residents supported the RAISE Act, only 8 percent opposed, and 8 percent were undecided. Gounardes joined critics on the far right, like Steve Bannon, who warned that federal preemption was a big gift for Big Tech. AI firms and the venture capitalist lobbyists “don’t want any regulation whatsoever,” Gounardes argued.&lt;/p&gt;
&lt;p&gt;“They say they support a national standard, but in reality, it’s just cheaper for them to buy off Congress to do nothing than it is to try and buy off 50 state legislatures,” Gounardes said.&lt;/p&gt;
&lt;p&gt;Bores expects that his experience in the tech industry could help Congress avoid that fate while his policies like the RAISE Act could sway voters who “don’t want Trump mega-donors writing all tech policy,” he wrote on X.&lt;/p&gt;
&lt;p&gt;“I am someone with a master’s in computer science, two patents, and nearly a decade working in tech,” Bores told CNBC. “If they are scared of people who understand their business regulating their business, they are telling on themselves.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/12/republicans-once-again-thwart-trumps-push-to-block-state-ai-laws/</guid><pubDate>Wed, 03 Dec 2025 21:06:34 +0000</pubDate></item><item><title>Gemini 3 Pro scores 69% trust in blinded testing up from 16% for Gemini 2.5: The case for evaluating AI on real-world trust, not academic benchmarks (AI | VentureBeat)</title><link>https://venturebeat.com/ai/gemini-3-pro-scores-69-trust-in-blinded-testing-up-from-16-for-gemini-2-5</link><description>[unable to retrieve full-text content]&lt;p&gt;Just a few short weeks ago, Google debuted its&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt; &lt;u&gt;Gemini 3&lt;/u&gt;&lt;/a&gt; model, claiming it scored a leadership position in multiple AI benchmarks. But the challenge with vendor-provided benchmarks is that they are just that — vendor-provided. &lt;/p&gt;&lt;p&gt;A new vendor-neutral evaluation from&lt;a href="https://www.prolific.com/"&gt; &lt;u&gt;Prolific&lt;/u&gt;&lt;/a&gt;, however, puts Gemini 3 at the top of the leaderboard. This isn&amp;#x27;t on a set of academic benchmarks; rather, it&amp;#x27;s on a set of real-world attributes that actual users and organizations care about. &lt;/p&gt;&lt;p&gt;Prolific was founded by researchers at the University of Oxford. The company delivers high-quality, reliable human data to power rigorous research and ethical AI development. The company&amp;#x27;s “&lt;a href="https://huggingface.co/spaces/ProlificAI/humaine-leaderboard"&gt;&lt;u&gt;HUMAINE benchmark&lt;/u&gt;&lt;/a&gt;” applies this approach by using representative human sampling and blind testing to rigorously compare AI models across a variety of user scenarios, measuring not just technical performance but also user trust, adaptability and communication style.&lt;/p&gt;&lt;p&gt;The latest HUMAINE test evaluated 26,000 users in a blind test of models. In the evaluation, Gemini 3 Pro&amp;#x27;s trust score surged from 16% to 69%, the highest ever recorded by Prolific. Gemini 3 now ranks number one overall in trust, ethics and safety 69% of the time across demographic subgroups, compared to its predecessor Gemini 2.5 Pro, which held the top spot only 16% of the time.&lt;/p&gt;&lt;p&gt;Overall, Gemini 3 ranked first in three of four evaluation categories: performance and reasoning, interaction and adaptiveness and trust and safety. It lost only on communication style, where DeepSeek V3 topped preferences at 43%. The HUMAINE test also showed that Gemini 3 performed consistently well across 22 different demographic user groups, including variations in age, sex, ethnicity and political orientation. The evaluation also found that users are now five times more likely to choose the model in head-to-head blind comparisons.&lt;/p&gt;&lt;p&gt;But the ranking matters less than &lt;i&gt;why &lt;/i&gt;it won.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s the consistency across a very wide range of different use cases, and a personality and a style that appeals across a wide range of different user types,&amp;quot; Phelim Bradley, co-founder and CEO of Prolific, told VentureBeat. &amp;quot;Although in some specific instances, other models are preferred by either small subgroups or on a particular conversation type, it&amp;#x27;s the breadth of knowledge and the flexibility of the model across a range of different use cases and audience types that allowed it to win this particular benchmark.&amp;quot;&lt;/p&gt;&lt;h2&gt;How blinded testing reveals what academic benchmarks miss&lt;/h2&gt;&lt;p&gt;HUMAINE&amp;#x27;s methodology exposes gaps in how the industry evaluates models. Users interact with two models simultaneously in multi-turn conversations. They don&amp;#x27;t know which vendors power each response. They discuss whatever topics matter to them, not predetermined test questions.&lt;/p&gt;&lt;p&gt;It&amp;#x27;s the sample itself that matters. HUMAINE uses representative sampling across U.S. and UK populations, controlling for age, sex, ethnicity and political orientation. This reveals something static benchmarks can&amp;#x27;t capture: Model performance varies by audience.&lt;/p&gt;&lt;p&gt;&amp;quot;If you take an AI leaderboard, the majority of them still could have a fairly static list,&amp;quot; Bradley said. &amp;quot;But for us, if you control for the audience, we end up with a slightly different leaderboard, whether you&amp;#x27;re looking at a left-leaning sample, right-leaning sample, U.S., UK. And I think age was actually the most different stated condition in our experiment.&amp;quot;&lt;/p&gt;&lt;p&gt;For enterprises deploying AI across diverse employee populations, this matters. A model that performs well for one demographic may underperform for another.&lt;/p&gt;&lt;p&gt;The methodology also addresses a fundamental question in AI evaluation: Why use human judges at all when AI could evaluate itself? Bradley noted that his firm does use AI judges in certain use cases, although he stressed that human evaluation is still the critical factor.&lt;/p&gt;&lt;p&gt;&amp;quot;We see the biggest benefit coming from smart orchestration of both LLM judge and human data, both have strengths and weaknesses, that, when smartly combined, do better together,&amp;quot; said Bradley. &amp;quot;But we still think that human data is where the alpha is. We&amp;#x27;re still extremely bullish that human data and human intelligence is required to be in the loop.&amp;quot;&lt;/p&gt;&lt;h2&gt;What trust means in AI evaluation&lt;/h2&gt;&lt;p&gt;Trust, ethics and safety measures user confidence in reliability, factual accuracy and responsible behavior. In HUMAINE&amp;#x27;s methodology, trust isn&amp;#x27;t a vendor claim or a technical metric — it&amp;#x27;s what users report after blinded conversations with competing models.&lt;/p&gt;&lt;p&gt;The 69% figure represents probability across demographic groups. This consistency matters more than aggregate scores because organizations can serve diverse populations.&lt;/p&gt;&lt;p&gt;&amp;quot;There was no awareness that they were using Gemini in this scenario,&amp;quot; Bradley said. &amp;quot;It was based only on the blinded multi-turn response.&amp;quot;&lt;/p&gt;&lt;p&gt;This separates perceived trust from earned trust. Users judged model outputs without knowing which vendor produced them, eliminating Google&amp;#x27;s brand advantage. For customer-facing deployments where the AI vendor remains invisible to end users, this distinction matters.&lt;/p&gt;&lt;h2&gt;What enterprises should do now&lt;/h2&gt;&lt;p&gt;One of the critical things that enterprises should do now when considering different models is embrace an evaluation framework that works.&lt;/p&gt;&lt;p&gt;&amp;quot;It is increasingly challenging to evaluate models exclusively based on vibes,&amp;quot; Bradley said. &amp;quot;I think increasingly we need more rigorous, scientific approaches to truly understand how these models are performing.&amp;quot;&lt;/p&gt;&lt;p&gt;The HUMAINE data provides a framework: Test for consistency across use cases and user demographics, not just peak performance on specific tasks. Blind the testing to separate model quality from brand perception. Use representative samples that match your actual user population. Plan for continuous evaluation as models change.&lt;/p&gt;&lt;p&gt;For enterprises looking to deploy AI at scale, this means moving beyond &amp;quot;which model is best&amp;quot; to &amp;quot;which model is best for our specific use case, user demographics and required attributes.&amp;quot;&lt;/p&gt;&lt;p&gt; The rigor of representative sampling and blind testing provides the data to make that determination — something technical benchmarks and vibes-based evaluation cannot deliver.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;Just a few short weeks ago, Google debuted its&lt;a href="https://venturebeat.com/ai/google-unveils-gemini-3-claiming-the-lead-in-math-science-multimodal-and"&gt; &lt;u&gt;Gemini 3&lt;/u&gt;&lt;/a&gt; model, claiming it scored a leadership position in multiple AI benchmarks. But the challenge with vendor-provided benchmarks is that they are just that — vendor-provided. &lt;/p&gt;&lt;p&gt;A new vendor-neutral evaluation from&lt;a href="https://www.prolific.com/"&gt; &lt;u&gt;Prolific&lt;/u&gt;&lt;/a&gt;, however, puts Gemini 3 at the top of the leaderboard. This isn&amp;#x27;t on a set of academic benchmarks; rather, it&amp;#x27;s on a set of real-world attributes that actual users and organizations care about. &lt;/p&gt;&lt;p&gt;Prolific was founded by researchers at the University of Oxford. The company delivers high-quality, reliable human data to power rigorous research and ethical AI development. The company&amp;#x27;s “&lt;a href="https://huggingface.co/spaces/ProlificAI/humaine-leaderboard"&gt;&lt;u&gt;HUMAINE benchmark&lt;/u&gt;&lt;/a&gt;” applies this approach by using representative human sampling and blind testing to rigorously compare AI models across a variety of user scenarios, measuring not just technical performance but also user trust, adaptability and communication style.&lt;/p&gt;&lt;p&gt;The latest HUMAINE test evaluated 26,000 users in a blind test of models. In the evaluation, Gemini 3 Pro&amp;#x27;s trust score surged from 16% to 69%, the highest ever recorded by Prolific. Gemini 3 now ranks number one overall in trust, ethics and safety 69% of the time across demographic subgroups, compared to its predecessor Gemini 2.5 Pro, which held the top spot only 16% of the time.&lt;/p&gt;&lt;p&gt;Overall, Gemini 3 ranked first in three of four evaluation categories: performance and reasoning, interaction and adaptiveness and trust and safety. It lost only on communication style, where DeepSeek V3 topped preferences at 43%. The HUMAINE test also showed that Gemini 3 performed consistently well across 22 different demographic user groups, including variations in age, sex, ethnicity and political orientation. The evaluation also found that users are now five times more likely to choose the model in head-to-head blind comparisons.&lt;/p&gt;&lt;p&gt;But the ranking matters less than &lt;i&gt;why &lt;/i&gt;it won.&lt;/p&gt;&lt;p&gt;&amp;quot;It&amp;#x27;s the consistency across a very wide range of different use cases, and a personality and a style that appeals across a wide range of different user types,&amp;quot; Phelim Bradley, co-founder and CEO of Prolific, told VentureBeat. &amp;quot;Although in some specific instances, other models are preferred by either small subgroups or on a particular conversation type, it&amp;#x27;s the breadth of knowledge and the flexibility of the model across a range of different use cases and audience types that allowed it to win this particular benchmark.&amp;quot;&lt;/p&gt;&lt;h2&gt;How blinded testing reveals what academic benchmarks miss&lt;/h2&gt;&lt;p&gt;HUMAINE&amp;#x27;s methodology exposes gaps in how the industry evaluates models. Users interact with two models simultaneously in multi-turn conversations. They don&amp;#x27;t know which vendors power each response. They discuss whatever topics matter to them, not predetermined test questions.&lt;/p&gt;&lt;p&gt;It&amp;#x27;s the sample itself that matters. HUMAINE uses representative sampling across U.S. and UK populations, controlling for age, sex, ethnicity and political orientation. This reveals something static benchmarks can&amp;#x27;t capture: Model performance varies by audience.&lt;/p&gt;&lt;p&gt;&amp;quot;If you take an AI leaderboard, the majority of them still could have a fairly static list,&amp;quot; Bradley said. &amp;quot;But for us, if you control for the audience, we end up with a slightly different leaderboard, whether you&amp;#x27;re looking at a left-leaning sample, right-leaning sample, U.S., UK. And I think age was actually the most different stated condition in our experiment.&amp;quot;&lt;/p&gt;&lt;p&gt;For enterprises deploying AI across diverse employee populations, this matters. A model that performs well for one demographic may underperform for another.&lt;/p&gt;&lt;p&gt;The methodology also addresses a fundamental question in AI evaluation: Why use human judges at all when AI could evaluate itself? Bradley noted that his firm does use AI judges in certain use cases, although he stressed that human evaluation is still the critical factor.&lt;/p&gt;&lt;p&gt;&amp;quot;We see the biggest benefit coming from smart orchestration of both LLM judge and human data, both have strengths and weaknesses, that, when smartly combined, do better together,&amp;quot; said Bradley. &amp;quot;But we still think that human data is where the alpha is. We&amp;#x27;re still extremely bullish that human data and human intelligence is required to be in the loop.&amp;quot;&lt;/p&gt;&lt;h2&gt;What trust means in AI evaluation&lt;/h2&gt;&lt;p&gt;Trust, ethics and safety measures user confidence in reliability, factual accuracy and responsible behavior. In HUMAINE&amp;#x27;s methodology, trust isn&amp;#x27;t a vendor claim or a technical metric — it&amp;#x27;s what users report after blinded conversations with competing models.&lt;/p&gt;&lt;p&gt;The 69% figure represents probability across demographic groups. This consistency matters more than aggregate scores because organizations can serve diverse populations.&lt;/p&gt;&lt;p&gt;&amp;quot;There was no awareness that they were using Gemini in this scenario,&amp;quot; Bradley said. &amp;quot;It was based only on the blinded multi-turn response.&amp;quot;&lt;/p&gt;&lt;p&gt;This separates perceived trust from earned trust. Users judged model outputs without knowing which vendor produced them, eliminating Google&amp;#x27;s brand advantage. For customer-facing deployments where the AI vendor remains invisible to end users, this distinction matters.&lt;/p&gt;&lt;h2&gt;What enterprises should do now&lt;/h2&gt;&lt;p&gt;One of the critical things that enterprises should do now when considering different models is embrace an evaluation framework that works.&lt;/p&gt;&lt;p&gt;&amp;quot;It is increasingly challenging to evaluate models exclusively based on vibes,&amp;quot; Bradley said. &amp;quot;I think increasingly we need more rigorous, scientific approaches to truly understand how these models are performing.&amp;quot;&lt;/p&gt;&lt;p&gt;The HUMAINE data provides a framework: Test for consistency across use cases and user demographics, not just peak performance on specific tasks. Blind the testing to separate model quality from brand perception. Use representative samples that match your actual user population. Plan for continuous evaluation as models change.&lt;/p&gt;&lt;p&gt;For enterprises looking to deploy AI at scale, this means moving beyond &amp;quot;which model is best&amp;quot; to &amp;quot;which model is best for our specific use case, user demographics and required attributes.&amp;quot;&lt;/p&gt;&lt;p&gt; The rigor of representative sampling and blind testing provides the data to make that determination — something technical benchmarks and vibes-based evaluation cannot deliver.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/gemini-3-pro-scores-69-trust-in-blinded-testing-up-from-16-for-gemini-2-5</guid><pubDate>Wed, 03 Dec 2025 22:00:00 +0000</pubDate></item><item><title>Andy Jassy says Amazon’s Nvidia competitor chip is already a multibillion-dollar business (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/03/andy-jassy-says-amazons-nvidia-competitor-chip-is-already-a-multi-billion-dollar-business/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/GettyImages-1415078085.jpg?resize=1200,721" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Can any company, big or small, really topple Nvidia’s AI chip dominance? Maybe not. But there are hundreds of billions of dollars of revenue for those who can even peel off a chunk of it for themselves, Amazon CEO Andy Jassy said this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As expected, the company revealed at the AWS re:Invent conference the next generation of its Nvidia-competitor AI chip, Trainium3, which is 4x faster yet uses less power than the current Trainium2. Jassy revealed a few tidbits about the current Trainium in a post on X that shows why the company is so bullish on the chip.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He said the Trainium2 business “has substantial traction, is a multi-billion-dollar revenue run-rate business, has 1M+ chips in production, and 100K+ companies using it as the majority of Bedrock usage today.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bedrock is Amazon’s AI app development tool that allows companies to pick and choose among many AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jassy said Amazon’s AI chip is winning among the company’s enormous roster of cloud customers because it “has price-performance advantages over other GPU options that are compelling.” In other words, he believes it works better and costs less than those “other GPUs” out there on the market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is, of course, Amazon’s classic MO, offering its own homegrown tech at lower prices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, AWS CEO Matt Garman offered even more insight in an interview with CRN, about one customer responsible for a big chunk of those billions in revenue: No shock here, it’s Anthropic.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve seen some enormous traction from Trainium2, particularly from our partners at Anthropic who we’ve announced Project Rainier, where there’s over 500,000 Trainium2 chips helping them build the next generations of models for Claude,” Garman said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Project Rainier is Amazon’s most ambitious AI cluster of servers, spread across multiple data centers in the U.S. and built to serve Anthropic’s skyrocketing needs. It came online in October. Amazon is, of course, a major investor in Anthropic. In exchange, Anthropic made AWS its primary model training partner, even though Anthropic is now also offered on Microsoft’s cloud via Nvidia’s chips. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now also using AWS in addition to Microsoft’s cloud. But the OpenAI partnership couldn’t have contributed much to Trainium’s revenue because AWS is running it on Nvidia chips and systems, the cloud giant said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Indeed, only a few U.S. companies like Google, Microsoft, Amazon, and Meta have all the engineering pieces — silicon chip design expertise, homegrown high-speed interconnect. and networking technology — to even attempt true competition with Nvidia. (Remember, Nvidia cornered the market on one major high-performance networking tech in 2019 when CEO Jensen Huang outbid Intel and Microsoft to buy InfiniBand hardware maker Mellanox.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On top of that, AI models and software built to be served up by Nvidia’s chips also rely on Nvidia’s proprietary Compute Unified Device Architecture (CUDA) software. CUDA allows the apps to use the GPUs for parallel processing compute, among other tasks. Just like the Intel versus SPARC chip war of yesterday, it’s no small thing to rewrite an AI app for a non-CUDA chip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Amazon may have a plan for that. As we previously reported, the next generation of its AI chip, Trainium4, will be built to interoperate with Nvidia’s GPUs in the same system. Whether that helps peel more business away from Nvidia or simply reinforces its dominance, but on AWS’s cloud, remains to be seen. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It may not matter to Amazon. If it is already on track to make multibillion dollars from the Trainium2 chip, and the next generation will be that much better, it may be winner enough.&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. &lt;/em&gt;&lt;strong&gt;&lt;em&gt;This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/GettyImages-1415078085.jpg?resize=1200,721" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Can any company, big or small, really topple Nvidia’s AI chip dominance? Maybe not. But there are hundreds of billions of dollars of revenue for those who can even peel off a chunk of it for themselves, Amazon CEO Andy Jassy said this week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As expected, the company revealed at the AWS re:Invent conference the next generation of its Nvidia-competitor AI chip, Trainium3, which is 4x faster yet uses less power than the current Trainium2. Jassy revealed a few tidbits about the current Trainium in a post on X that shows why the company is so bullish on the chip.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;He said the Trainium2 business “has substantial traction, is a multi-billion-dollar revenue run-rate business, has 1M+ chips in production, and 100K+ companies using it as the majority of Bedrock usage today.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bedrock is Amazon’s AI app development tool that allows companies to pick and choose among many AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jassy said Amazon’s AI chip is winning among the company’s enormous roster of cloud customers because it “has price-performance advantages over other GPU options that are compelling.” In other words, he believes it works better and costs less than those “other GPUs” out there on the market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That is, of course, Amazon’s classic MO, offering its own homegrown tech at lower prices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, AWS CEO Matt Garman offered even more insight in an interview with CRN, about one customer responsible for a big chunk of those billions in revenue: No shock here, it’s Anthropic.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve seen some enormous traction from Trainium2, particularly from our partners at Anthropic who we’ve announced Project Rainier, where there’s over 500,000 Trainium2 chips helping them build the next generations of models for Claude,” Garman said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Project Rainier is Amazon’s most ambitious AI cluster of servers, spread across multiple data centers in the U.S. and built to serve Anthropic’s skyrocketing needs. It came online in October. Amazon is, of course, a major investor in Anthropic. In exchange, Anthropic made AWS its primary model training partner, even though Anthropic is now also offered on Microsoft’s cloud via Nvidia’s chips. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now also using AWS in addition to Microsoft’s cloud. But the OpenAI partnership couldn’t have contributed much to Trainium’s revenue because AWS is running it on Nvidia chips and systems, the cloud giant said.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Indeed, only a few U.S. companies like Google, Microsoft, Amazon, and Meta have all the engineering pieces — silicon chip design expertise, homegrown high-speed interconnect. and networking technology — to even attempt true competition with Nvidia. (Remember, Nvidia cornered the market on one major high-performance networking tech in 2019 when CEO Jensen Huang outbid Intel and Microsoft to buy InfiniBand hardware maker Mellanox.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On top of that, AI models and software built to be served up by Nvidia’s chips also rely on Nvidia’s proprietary Compute Unified Device Architecture (CUDA) software. CUDA allows the apps to use the GPUs for parallel processing compute, among other tasks. Just like the Intel versus SPARC chip war of yesterday, it’s no small thing to rewrite an AI app for a non-CUDA chip.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, Amazon may have a plan for that. As we previously reported, the next generation of its AI chip, Trainium4, will be built to interoperate with Nvidia’s GPUs in the same system. Whether that helps peel more business away from Nvidia or simply reinforces its dominance, but on AWS’s cloud, remains to be seen. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It may not matter to Amazon. If it is already on track to make multibillion dollars from the Trainium2 chip, and the next generation will be that much better, it may be winner enough.&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. &lt;/em&gt;&lt;strong&gt;&lt;em&gt;This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/03/andy-jassy-says-amazons-nvidia-competitor-chip-is-already-a-multi-billion-dollar-business/</guid><pubDate>Wed, 03 Dec 2025 22:01:13 +0000</pubDate></item><item><title>From Waveforms to Wisdom: The New Benchmark for Auditory Intelligence (The latest research from Google)</title><link>https://research.google/blog/from-waveforms-to-wisdom-the-new-benchmark-for-auditory-intelligence/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Sound is a critical part of multimodal perception. For a system — be it a voice assistant, a next-generation security monitor, or an autonomous agent — to behave naturally, it must demonstrate a full spectrum of auditory capabilities. These capabilities include transcription, classification, retrieval, reasoning, segmentation, clustering, reranking, and reconstruction.&lt;/p&gt;&lt;p&gt;These diverse functions rely on transforming raw sound into an intermediate representation, or embedding. But research into improving the auditory capabilities of multimodal perception models has been fragmented, and there remain important unanswered questions: How do we compare performance across domains like human speech and bioacoustics? What is the &lt;i&gt;true&lt;/i&gt; performance potential we are leaving on the table? And could a single, general-purpose sound embedding serve as the foundation for all these capabilities?&lt;/p&gt;&lt;p&gt;To investigate these queries and accelerate progress toward robust machine sound intelligence, we created the Massive Sound Embedding Benchmark (MSEB), presented at NeurIPS 2025.&lt;/p&gt;&lt;p&gt;MSEB provides the necessary structure to answer these questions by:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Standardizing evaluation for a comprehensive suite of eight real-world capabilities that we believe every human-like intelligent system must possess.&lt;/li&gt;&lt;li&gt;Providing an open and extensible framework that allows researchers to seamlessly integrate and evaluate any model type — from conventional downstream uni-modal models to cascade models to end-to-end multimodal embedding models.&lt;/li&gt;&lt;li&gt;Establishing clear performance goals to objectively highlight research opportunities beyond current state-of-the-art approaches.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Our initial experiments confirm that current sound representations are far from universal, revealing substantial performance "headroom” (i.e., maximum improvement possible) across all eight tasks.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Sound is a critical part of multimodal perception. For a system — be it a voice assistant, a next-generation security monitor, or an autonomous agent — to behave naturally, it must demonstrate a full spectrum of auditory capabilities. These capabilities include transcription, classification, retrieval, reasoning, segmentation, clustering, reranking, and reconstruction.&lt;/p&gt;&lt;p&gt;These diverse functions rely on transforming raw sound into an intermediate representation, or embedding. But research into improving the auditory capabilities of multimodal perception models has been fragmented, and there remain important unanswered questions: How do we compare performance across domains like human speech and bioacoustics? What is the &lt;i&gt;true&lt;/i&gt; performance potential we are leaving on the table? And could a single, general-purpose sound embedding serve as the foundation for all these capabilities?&lt;/p&gt;&lt;p&gt;To investigate these queries and accelerate progress toward robust machine sound intelligence, we created the Massive Sound Embedding Benchmark (MSEB), presented at NeurIPS 2025.&lt;/p&gt;&lt;p&gt;MSEB provides the necessary structure to answer these questions by:&lt;/p&gt;&lt;ul&gt;&lt;li&gt;Standardizing evaluation for a comprehensive suite of eight real-world capabilities that we believe every human-like intelligent system must possess.&lt;/li&gt;&lt;li&gt;Providing an open and extensible framework that allows researchers to seamlessly integrate and evaluate any model type — from conventional downstream uni-modal models to cascade models to end-to-end multimodal embedding models.&lt;/li&gt;&lt;li&gt;Establishing clear performance goals to objectively highlight research opportunities beyond current state-of-the-art approaches.&lt;/li&gt;&lt;/ul&gt;&lt;p&gt;Our initial experiments confirm that current sound representations are far from universal, revealing substantial performance "headroom” (i.e., maximum improvement possible) across all eight tasks.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/from-waveforms-to-wisdom-the-new-benchmark-for-auditory-intelligence/</guid><pubDate>Wed, 03 Dec 2025 22:47:00 +0000</pubDate></item><item><title>[NEW] Meta poaches Apple design exec Alan Dye to lead new creative studio in Reality Labs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/03/meta-poaches-apple-design-exec-alan-dye-to-lead-new-creative-studio-in-reality-labs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/AppleEvent.SEP07Keynote.Alan_.Dye_.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Alan Dye, the design executive who led Apple’s user interface team for the last decade, is leaving the company to join Meta, according to a report from Bloomberg’s Mark Gurman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a significant hire for Meta, as the company makes a push toward consumer devices like smart glasses and virtual reality headsets. Dye will focus on improving AI features in these devices and report directly to Chief Technology Officer Andrew Bosworth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At Apple, Dye will be replaced by Steve Lemay, who has had “a key role in the design of every major Apple interface since 1999,” according to a statement Apple CEO Tim Cook gave Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It seems that Meta is recruiting from its competitors to help the company compete in the AI race, as Meta also poached researchers from OpenAI this summer. (Allegedly, Meta CEO Mark Zuckerberg hand-delivered homemade soup to an OpenAI employee in a recruitment push; OpenAI chief research officer Mark Chen said that he has since delivered his own soup to promising Meta recruits.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after the news broke of Dye’s departure, Zuckerberg announced a new creative studio within Reality Labs that would be led by Dye. There, he’ll be joined by Billy Sorrentino, another former Apple designer who led interface design across Reality Labs; Joshua To, who led interface design across Reality Labs; Meta’s industrial design team, led by Pete Bristol; and its metaverse design and art teams led by Jason Rubin.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg said the studio would “bring together design, fashion, and technology to define the next generation of our products and experiences.”  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our idea is to treat intelligence as a new design material and imagine what becomes possible when it is abundant, capable, and human-centered,” the Meta CEO wrote on Threads. “We plan to elevate design within Meta, and pull together a talented group with a combination of craft, creative vision, systems thinking, and deep experience building iconic products that bridge hardware and software.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after publication with additional information about Meta’s plans.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/09/AppleEvent.SEP07Keynote.Alan_.Dye_.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Alan Dye, the design executive who led Apple’s user interface team for the last decade, is leaving the company to join Meta, according to a report from Bloomberg’s Mark Gurman.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a significant hire for Meta, as the company makes a push toward consumer devices like smart glasses and virtual reality headsets. Dye will focus on improving AI features in these devices and report directly to Chief Technology Officer Andrew Bosworth.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;At Apple, Dye will be replaced by Steve Lemay, who has had “a key role in the design of every major Apple interface since 1999,” according to a statement Apple CEO Tim Cook gave Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It seems that Meta is recruiting from its competitors to help the company compete in the AI race, as Meta also poached researchers from OpenAI this summer. (Allegedly, Meta CEO Mark Zuckerberg hand-delivered homemade soup to an OpenAI employee in a recruitment push; OpenAI chief research officer Mark Chen said that he has since delivered his own soup to promising Meta recruits.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shortly after the news broke of Dye’s departure, Zuckerberg announced a new creative studio within Reality Labs that would be led by Dye. There, he’ll be joined by Billy Sorrentino, another former Apple designer who led interface design across Reality Labs; Joshua To, who led interface design across Reality Labs; Meta’s industrial design team, led by Pete Bristol; and its metaverse design and art teams led by Jason Rubin.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg said the studio would “bring together design, fashion, and technology to define the next generation of our products and experiences.”  &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our idea is to treat intelligence as a new design material and imagine what becomes possible when it is abundant, capable, and human-centered,” the Meta CEO wrote on Threads. “We plan to elevate design within Meta, and pull together a talented group with a combination of craft, creative vision, systems thinking, and deep experience building iconic products that bridge hardware and software.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after publication with additional information about Meta’s plans.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/03/meta-poaches-apple-design-exec-alan-dye-to-lead-new-creative-studio-in-reality-labs/</guid><pubDate>Wed, 03 Dec 2025 23:37:26 +0000</pubDate></item><item><title>All the biggest news from AWS’ big tech show re:Invent 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/03/all-the-biggest-news-from-aws-big-tech-show-reinvent-2025/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2179195367.jpg?resize=1200,746" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ annual tech conference AWS re:Invent has wrapped up another day with a deluge of product news and keynotes — plus the obligatory customer success stories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The unsurprising theme is AI for the enterprise. This year it’s all about upgrades that give customers greater control to customize AI agents, including one that AWS claims can learn from you and then work independently for days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS re:Invent 2025, which runs through December 5, started with a keynote from AWS CEO Matt Garman, who leaned into the idea that AI agents can unlock the “true value” of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI assistants are starting to give way to AI agents that can perform tasks and automate on your behalf,” he said during the December 2 keynote. “This is where we’re starting to see material business returns from your AI investments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On December 3, the conference pressed on with its AI agents messaging, as well as deeper dives into customer stories. Swami Sivasubramanian, vice president of Agentic AI at AWS, gave one of the keynote talks. To say he was bullish is perhaps understating the vibe. &lt;/p&gt;&lt;p&gt;“We are living in times of great change,” Sivasubramanian said during the talk. “For the first time in history, we can describe what we want to accomplish in natural language, and agents generate the plan. They write the code, call the necessary tools, and execute the complete solution. Agents give you the freedom to build without limits, accelerating how quickly you can go from idea to impact in a big way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI agent news promises to be a persistent presence throughout AWS re:Invent 2025, there were other announcements, too. Here is a roundup of the ones that got our attention. TechCrunch will update this article, with the newest insights at the top, through the end of AWS re:Invent. Be sure to check back.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-doubling-down-on-llms"&gt;Doubling down on LLMs&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced more tools for enterprise customers to create their own models. Specifically, AWS said it is adding new capabilities for both Amazon Bedrock and Amazon SageMaker AI to make building custom LLMs easier. &lt;/p&gt;&lt;p&gt;For instance, AWS is bringing serverless model customization to SageMaker, which allows developers to start building a model without needing to think about compute resources or infrastructure. The serverless model customization can be accessed through either a self-guided path or by prompting an AI agent.&lt;/p&gt;&lt;p&gt;AWS also announced Reinforcement Fine Tuning in Bedrock, which allows developers to choose a preset workflow or reward system and have Bedrock run their customization process automatically from start to finish.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-andy-jassy-shares-some-numbers"&gt;Andy Jassy shares some numbers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon CEO Andy Jassy took to social media platform X to expound on AWS chief Matt Garman’s keynote speech. The message: The current generation of its Nvidia-competitor AI chip Trainium2 is already bringing in loads of cash.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His comments were tied to the reveal of its next-generation chip, Trainium3, and meant to forecast a promising revenue future for the product.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-database-savings-arrives"&gt;Database savings arrives&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tucked among the dozens of announcements is one item that is already getting cheers: Discounts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Specifically, AWS said it was launching Database Savings Plans, which help customers reduce database costs by up to 35% when they commit to a consistent amount of usage ($/hour) over a one-year term. The company said the savings will automatically apply each hour to eligible usage across supported database services, and any additional usage beyond the commitment is billed at on-demand rates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Corey Quinn, chief cloud economist at Duckbill, summed it up well in his blog post, “Six years of complaining finally pays off.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-can-t-get-a-better-deal-than-free-amazon-hopes"&gt;Can’t get a better deal than free, Amazon hopes  &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Is there any way for another AI coding tool to win the hearts of startup founders? Amazon hopes a year’s worth of credits, for free, will do the trick for its offering, Kiro. The company will be giving away credits to Kiro Pro+ to qualified startups that apply for the deal before the end of the month. However, only early-stage startups in certain countries are eligible.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-training-chip-and-nvidia-compatibility"&gt;An AI training chip and Nvidia compatibility&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS introduced a new version of its AI training chip called Trainium3 along with an AI system called UltraServer that runs it. The TL;DR: This upgraded chip comes with some impressive specs, including a promise of up to 4x performance gains for both AI training and inference while lowering energy use by 40%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also provided a teaser. The company already has Trainium4 in development, which will be able to work with Nvidia’s chips.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expanded-agentcore-capabilities"&gt;Expanded AgentCore capabilities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced new features in its AgentCore AI agent building platform. One feature of note is Policy in AgentCore, which gives developers the ability to more easily set boundaries for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that agents will now be able to log and remember things about their users. Plus it announced that it will help its customers evaluate agents through 13 prebuilt evaluation systems.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-nonstop-ai-agent-worker-bee"&gt;A nonstop AI agent worker bee&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS announced three new AI agents (there is that term again) called “Frontier agents,” including one called “Kiro autonomous agent” that writes code and is designed to learn how a team likes to work so it can operate largely on its own for hours or days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Another of these new agents handles security processes like code reviews, and the third does DevOps tasks such&amp;nbsp;as preventing incidents&amp;nbsp;when pushing new code live. Preview versions of the agents are available now.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-new-nova-models-and-services"&gt;New Nova models and services&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is rolling out four new AI models within its Nova AI model family — three of which are text generating and one that can create text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a new service called Nova Forge that allows AWS cloud customers to access pre-trained, mid-trained, or post-trained models that they can then top off by training on their own proprietary data. AWS’s big pitch is flexibility and customization.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-lyft-s-argument-for-ai-agents"&gt;Lyft’s argument for AI agents&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The ride-hailing company was among many AWS customers that piped up during the event to share their success stories and evidence of how products affected their business. Lyft is using Anthropic’s Claude model via Amazon Bedrock to create an AI agent that handles driver and rider questions and issues. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said this AI agent has reduced average resolution time by 87%. Lyft also said it has seen a 70% increase in driver usage of the AI agent this year. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-factory-for-the-private-data-center"&gt;An AI Factory for the private data center&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also announced “AI Factories” that allow big corporations and governments to run AWS AI systems in their own data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system was designed in partnership with Nvidia and includes both Nvidia’s tech and AWS’s. While companies that use it can stock it with Nvidia GPUs, they can also opt for Amazon’s newest homegrown AI chip, the Trainium3. The system is Amazon’s way of addressing data sovereignty, or the need of governments and many companies to control their data and not share it, even to use AI.&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2179195367.jpg?resize=1200,746" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon Web Services’ annual tech conference AWS re:Invent has wrapped up another day with a deluge of product news and keynotes — plus the obligatory customer success stories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The unsurprising theme is AI for the enterprise. This year it’s all about upgrades that give customers greater control to customize AI agents, including one that AWS claims can learn from you and then work independently for days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;AWS re:Invent 2025, which runs through December 5, started with a keynote from AWS CEO Matt Garman, who leaned into the idea that AI agents can unlock the “true value” of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI assistants are starting to give way to AI agents that can perform tasks and automate on your behalf,” he said during the December 2 keynote. “This is where we’re starting to see material business returns from your AI investments.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On December 3, the conference pressed on with its AI agents messaging, as well as deeper dives into customer stories. Swami Sivasubramanian, vice president of Agentic AI at AWS, gave one of the keynote talks. To say he was bullish is perhaps understating the vibe. &lt;/p&gt;&lt;p&gt;“We are living in times of great change,” Sivasubramanian said during the talk. “For the first time in history, we can describe what we want to accomplish in natural language, and agents generate the plan. They write the code, call the necessary tools, and execute the complete solution. Agents give you the freedom to build without limits, accelerating how quickly you can go from idea to impact in a big way.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While AI agent news promises to be a persistent presence throughout AWS re:Invent 2025, there were other announcements, too. Here is a roundup of the ones that got our attention. TechCrunch will update this article, with the newest insights at the top, through the end of AWS re:Invent. Be sure to check back.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-doubling-down-on-llms"&gt;Doubling down on LLMs&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced more tools for enterprise customers to create their own models. Specifically, AWS said it is adding new capabilities for both Amazon Bedrock and Amazon SageMaker AI to make building custom LLMs easier. &lt;/p&gt;&lt;p&gt;For instance, AWS is bringing serverless model customization to SageMaker, which allows developers to start building a model without needing to think about compute resources or infrastructure. The serverless model customization can be accessed through either a self-guided path or by prompting an AI agent.&lt;/p&gt;&lt;p&gt;AWS also announced Reinforcement Fine Tuning in Bedrock, which allows developers to choose a preset workflow or reward system and have Bedrock run their customization process automatically from start to finish.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-andy-jassy-shares-some-numbers"&gt;Andy Jassy shares some numbers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon CEO Andy Jassy took to social media platform X to expound on AWS chief Matt Garman’s keynote speech. The message: The current generation of its Nvidia-competitor AI chip Trainium2 is already bringing in loads of cash.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;His comments were tied to the reveal of its next-generation chip, Trainium3, and meant to forecast a promising revenue future for the product.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-database-savings-arrives"&gt;Database savings arrives&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Tucked among the dozens of announcements is one item that is already getting cheers: Discounts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Specifically, AWS said it was launching Database Savings Plans, which help customers reduce database costs by up to 35% when they commit to a consistent amount of usage ($/hour) over a one-year term. The company said the savings will automatically apply each hour to eligible usage across supported database services, and any additional usage beyond the commitment is billed at on-demand rates.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Corey Quinn, chief cloud economist at Duckbill, summed it up well in his blog post, “Six years of complaining finally pays off.”&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-can-t-get-a-better-deal-than-free-amazon-hopes"&gt;Can’t get a better deal than free, Amazon hopes  &lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Is there any way for another AI coding tool to win the hearts of startup founders? Amazon hopes a year’s worth of credits, for free, will do the trick for its offering, Kiro. The company will be giving away credits to Kiro Pro+ to qualified startups that apply for the deal before the end of the month. However, only early-stage startups in certain countries are eligible.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-training-chip-and-nvidia-compatibility"&gt;An AI training chip and Nvidia compatibility&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS introduced a new version of its AI training chip called Trainium3 along with an AI system called UltraServer that runs it. The TL;DR: This upgraded chip comes with some impressive specs, including a promise of up to 4x performance gains for both AI training and inference while lowering energy use by 40%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also provided a teaser. The company already has Trainium4 in development, which will be able to work with Nvidia’s chips.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-expanded-agentcore-capabilities"&gt;Expanded AgentCore capabilities&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS announced new features in its AgentCore AI agent building platform. One feature of note is Policy in AgentCore, which gives developers the ability to more easily set boundaries for AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AWS also announced that agents will now be able to log and remember things about their users. Plus it announced that it will help its customers evaluate agents through 13 prebuilt evaluation systems.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-a-nonstop-ai-agent-worker-bee"&gt;A nonstop AI agent worker bee&lt;/h2&gt;

&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AWS announced three new AI agents (there is that term again) called “Frontier agents,” including one called “Kiro autonomous agent” that writes code and is designed to learn how a team likes to work so it can operate largely on its own for hours or days.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Another of these new agents handles security processes like code reviews, and the third does DevOps tasks such&amp;nbsp;as preventing incidents&amp;nbsp;when pushing new code live. Preview versions of the agents are available now.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-new-nova-models-and-services"&gt;New Nova models and services&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;AWS is rolling out four new AI models within its Nova AI model family — three of which are text generating and one that can create text and images.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also announced a new service called Nova Forge that allows AWS cloud customers to access pre-trained, mid-trained, or post-trained models that they can then top off by training on their own proprietary data. AWS’s big pitch is flexibility and customization.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-lyft-s-argument-for-ai-agents"&gt;Lyft’s argument for AI agents&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The ride-hailing company was among many AWS customers that piped up during the event to share their success stories and evidence of how products affected their business. Lyft is using Anthropic’s Claude model via Amazon Bedrock to create an AI agent that handles driver and rider questions and issues. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said this AI agent has reduced average resolution time by 87%. Lyft also said it has seen a 70% increase in driver usage of the AI agent this year. &lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-an-ai-factory-for-the-private-data-center"&gt;An AI Factory for the private data center&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon also announced “AI Factories” that allow big corporations and governments to run AWS AI systems in their own data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The system was designed in partnership with Nvidia and includes both Nvidia’s tech and AWS’s. While companies that use it can stock it with Nvidia GPUs, they can also opt for Amazon’s newest homegrown AI chip, the Trainium3. The system is Amazon’s way of addressing data sovereignty, or the need of governments and many companies to control their data and not share it, even to use AI.&lt;/p&gt;



&lt;!-- Add a placeholder for the Twitch embed --&gt;


&lt;!-- Load the Twitch embed script --&gt;

&lt;!-- Create a Twitch.Player object. This will render within the placeholder div --&gt;


&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Check out the latest reveals on everything from agentic AI and cloud infrastructure to security and much more from the flagship Amazon Web Services event in Las Vegas. This video is brought to you in partnership with AWS.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/03/all-the-biggest-news-from-aws-big-tech-show-reinvent-2025/</guid><pubDate>Wed, 03 Dec 2025 23:43:25 +0000</pubDate></item><item><title>[NEW] A smarter way for large language models to think about hard problems (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/smarter-way-large-language-models-think-about-hard-problems-1204</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/MIT-RewardModel-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;To make large language models (LLMs) more accurate when answering harder questions, researchers can let the model spend more time thinking about potential solutions.&lt;/p&gt;&lt;p&gt;But common&amp;nbsp;approaches that give LLMs this capability set a fixed computational budget for every problem, regardless of how complex it is. This means the LLM might waste computational resources on simpler questions or be unable to tackle intricate problems that require more reasoning.&lt;/p&gt;&lt;p&gt;To address this, MIT researchers developed a smarter way to allocate computational effort as the LLM solves a problem. Their method enables the model to dynamically adjust its computational budget based on the difficulty of the question and the likelihood that each partial solution will lead to the correct answer.&lt;/p&gt;&lt;p&gt;The researchers found that their new approach enabled LLMs to use as little as one-half the computation as existing methods, while&amp;nbsp;achieving&amp;nbsp;comparable accuracy on a range of questions with varying difficulties. In addition, their method allows smaller, less resource-intensive LLMs to perform as well as or even better than larger models on complex problems.&lt;/p&gt;&lt;p&gt;By improving the reliability and efficiency of LLMs, especially when they tackle complex reasoning tasks, this technique could reduce the energy consumption of generative AI systems and enable the use of LLMs in more high-stakes and time-sensitive applications.&lt;/p&gt;&lt;p&gt;“The computational cost of inference has quickly become a major bottleneck for frontier model providers, and they are actively trying to find ways to improve computational efficiency per&amp;nbsp;user queries. For instance, the recent GPT-5.1 release highlights the efficacy of the ‘adaptive reasoning’ approach our paper proposes. By endowing the models with the ability to know what they don’t know, we can enable them to spend more compute on the hardest problems and most promising solution paths, and use far fewer tokens on easy ones. That makes reasoning both more reliable and far more efficient,” says Navid Azizan, the Alfred H. and Jean M. Hayes Career Development Assistant Professor in the Department of Mechanical Engineering and the Institute for Data, Systems, and Society (IDSS), a principal investigator of the Laboratory for Information and Decision Systems (LIDS), and the&amp;nbsp;senior author of a paper on this technique.&lt;/p&gt;&lt;p&gt;Azizan is joined on the paper by lead author Young-Jin Park, a LIDS/MechE graduate student; Kristjan Greenewald, a research scientist in the MIT-IBM Watson AI Lab; Kaveh Alim, an IDSS graduate student; and Hao Wang, a research scientist at the MIT-IBM Watson AI Lab and the Red Hat AI Innovation Team. The research is being presented this week at the Conference on Neural Information Processing Systems.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Computation for contemplation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A recent approach called inference-time scaling lets a large language model take more time to reason about difficult problems.&lt;/p&gt;&lt;p&gt;Using inference-time scaling, the LLM might generate multiple solution attempts at once or explore different reasoning paths, then choose the best ones to pursue from those candidates.&lt;/p&gt;&lt;p&gt;A separate model, known as a process reward model (PRM), scores each potential solution or reasoning path. The LLM uses these scores to identify the most promising ones.&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;Typical inference-time scaling approaches assign a fixed amount of computation for the LLM to break the problem down and reason about the steps.&lt;/p&gt;&lt;p&gt;Instead, the researchers’ method, known as instance-adaptive scaling, dynamically adjusts the number of potential solutions or reasoning steps based on how likely they are to succeed, as the model wrestles with the problem.&lt;/p&gt;&lt;p&gt;“This is how humans solve problems. We come up with some partial solutions and then decide, should I go further with any of these, or stop and revise, or even go back to my previous step and continue solving the problem from there?” Wang explains.&lt;/p&gt;&lt;p&gt;To do this, the framework uses the PRM to estimate the difficulty of the question, helping the LLM assess how much computational budget to utilize for generating and reasoning about potential solutions.&lt;/p&gt;&lt;p&gt;At every step in the model’s reasoning process, the PRM looks at the question and partial answers and evaluates how promising each one is for getting to the right solution. If the LLM is more confident, it can reduce the number of potential solutions or reasoning trajectories to pursue, saving computational resources.&lt;/p&gt;&lt;p&gt;But the researchers found that existing PRMs often overestimate the model’s probability of success.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Overcoming overconfidence&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“If we were to just trust current PRMs, which often overestimate the chance of success, our system would reduce the computational budget too aggressively. So we first had to find a way to better calibrate PRMs to make inference-time scaling more efficient and reliable,” Park says.&lt;/p&gt;&lt;p&gt;The researchers introduced a calibration method that enables PRMs to generate a range of probability scores rather than a single value. In this way, the PRM creates more reliable uncertainty estimates that better reflect the true probability of success.&lt;/p&gt;&lt;p&gt;With a well-calibrated PRM, their instance-adaptive scaling framework can use the probability scores to effectively reduce computation while maintaining the accuracy of the model’s outputs.&lt;/p&gt;&lt;p&gt;When they compared their method to standard inference-time scaling approaches on a series of mathematical reasoning tasks, it utilized less computation to solve each problem while achieving similar&amp;nbsp;accuracy.&lt;/p&gt;&lt;p&gt;“The beauty of our approach is that this adaptation happens on the fly, as the problem is being solved, rather than happening all at once at the beginning of the process,” says Greenewald.&lt;/p&gt;&lt;p&gt;In the future, the researchers are interested in applying this technique to other applications, such as code generation and AI agents. They are also planning to explore additional uses for their PRM calibration method, like for&amp;nbsp;reinforcement learning and fine-tuning.&lt;/p&gt;&lt;p&gt;“Human employees learn on the job — some CEOs even started as interns — but today’s agents remain largely static pieces of probabilistic software. Work like this paper is an important step toward changing that: helping agents understand what they don’t know and building mechanisms for continual self-improvement. These capabilities are essential if we want agents that can operate safely, adapt to new situations, and deliver consistent results at scale,” says Akash Srivastava, director and chief architect of Core AI at IBM Software, who was not involved with this work.&lt;/p&gt;&lt;p&gt;This work was funded, in part, by the MIT-IBM Watson AI Lab, the MIT-Amazon Science Hub, the MIT-Google Program for Computing Innovation, and MathWorks.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202512/MIT-RewardModel-01-press.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;To make large language models (LLMs) more accurate when answering harder questions, researchers can let the model spend more time thinking about potential solutions.&lt;/p&gt;&lt;p&gt;But common&amp;nbsp;approaches that give LLMs this capability set a fixed computational budget for every problem, regardless of how complex it is. This means the LLM might waste computational resources on simpler questions or be unable to tackle intricate problems that require more reasoning.&lt;/p&gt;&lt;p&gt;To address this, MIT researchers developed a smarter way to allocate computational effort as the LLM solves a problem. Their method enables the model to dynamically adjust its computational budget based on the difficulty of the question and the likelihood that each partial solution will lead to the correct answer.&lt;/p&gt;&lt;p&gt;The researchers found that their new approach enabled LLMs to use as little as one-half the computation as existing methods, while&amp;nbsp;achieving&amp;nbsp;comparable accuracy on a range of questions with varying difficulties. In addition, their method allows smaller, less resource-intensive LLMs to perform as well as or even better than larger models on complex problems.&lt;/p&gt;&lt;p&gt;By improving the reliability and efficiency of LLMs, especially when they tackle complex reasoning tasks, this technique could reduce the energy consumption of generative AI systems and enable the use of LLMs in more high-stakes and time-sensitive applications.&lt;/p&gt;&lt;p&gt;“The computational cost of inference has quickly become a major bottleneck for frontier model providers, and they are actively trying to find ways to improve computational efficiency per&amp;nbsp;user queries. For instance, the recent GPT-5.1 release highlights the efficacy of the ‘adaptive reasoning’ approach our paper proposes. By endowing the models with the ability to know what they don’t know, we can enable them to spend more compute on the hardest problems and most promising solution paths, and use far fewer tokens on easy ones. That makes reasoning both more reliable and far more efficient,” says Navid Azizan, the Alfred H. and Jean M. Hayes Career Development Assistant Professor in the Department of Mechanical Engineering and the Institute for Data, Systems, and Society (IDSS), a principal investigator of the Laboratory for Information and Decision Systems (LIDS), and the&amp;nbsp;senior author of a paper on this technique.&lt;/p&gt;&lt;p&gt;Azizan is joined on the paper by lead author Young-Jin Park, a LIDS/MechE graduate student; Kristjan Greenewald, a research scientist in the MIT-IBM Watson AI Lab; Kaveh Alim, an IDSS graduate student; and Hao Wang, a research scientist at the MIT-IBM Watson AI Lab and the Red Hat AI Innovation Team. The research is being presented this week at the Conference on Neural Information Processing Systems.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Computation for contemplation&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;A recent approach called inference-time scaling lets a large language model take more time to reason about difficult problems.&lt;/p&gt;&lt;p&gt;Using inference-time scaling, the LLM might generate multiple solution attempts at once or explore different reasoning paths, then choose the best ones to pursue from those candidates.&lt;/p&gt;&lt;p&gt;A separate model, known as a process reward model (PRM), scores each potential solution or reasoning path. The LLM uses these scores to identify the most promising ones.&amp;nbsp; &amp;nbsp; &amp;nbsp;&lt;/p&gt;&lt;p&gt;Typical inference-time scaling approaches assign a fixed amount of computation for the LLM to break the problem down and reason about the steps.&lt;/p&gt;&lt;p&gt;Instead, the researchers’ method, known as instance-adaptive scaling, dynamically adjusts the number of potential solutions or reasoning steps based on how likely they are to succeed, as the model wrestles with the problem.&lt;/p&gt;&lt;p&gt;“This is how humans solve problems. We come up with some partial solutions and then decide, should I go further with any of these, or stop and revise, or even go back to my previous step and continue solving the problem from there?” Wang explains.&lt;/p&gt;&lt;p&gt;To do this, the framework uses the PRM to estimate the difficulty of the question, helping the LLM assess how much computational budget to utilize for generating and reasoning about potential solutions.&lt;/p&gt;&lt;p&gt;At every step in the model’s reasoning process, the PRM looks at the question and partial answers and evaluates how promising each one is for getting to the right solution. If the LLM is more confident, it can reduce the number of potential solutions or reasoning trajectories to pursue, saving computational resources.&lt;/p&gt;&lt;p&gt;But the researchers found that existing PRMs often overestimate the model’s probability of success.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Overcoming overconfidence&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;“If we were to just trust current PRMs, which often overestimate the chance of success, our system would reduce the computational budget too aggressively. So we first had to find a way to better calibrate PRMs to make inference-time scaling more efficient and reliable,” Park says.&lt;/p&gt;&lt;p&gt;The researchers introduced a calibration method that enables PRMs to generate a range of probability scores rather than a single value. In this way, the PRM creates more reliable uncertainty estimates that better reflect the true probability of success.&lt;/p&gt;&lt;p&gt;With a well-calibrated PRM, their instance-adaptive scaling framework can use the probability scores to effectively reduce computation while maintaining the accuracy of the model’s outputs.&lt;/p&gt;&lt;p&gt;When they compared their method to standard inference-time scaling approaches on a series of mathematical reasoning tasks, it utilized less computation to solve each problem while achieving similar&amp;nbsp;accuracy.&lt;/p&gt;&lt;p&gt;“The beauty of our approach is that this adaptation happens on the fly, as the problem is being solved, rather than happening all at once at the beginning of the process,” says Greenewald.&lt;/p&gt;&lt;p&gt;In the future, the researchers are interested in applying this technique to other applications, such as code generation and AI agents. They are also planning to explore additional uses for their PRM calibration method, like for&amp;nbsp;reinforcement learning and fine-tuning.&lt;/p&gt;&lt;p&gt;“Human employees learn on the job — some CEOs even started as interns — but today’s agents remain largely static pieces of probabilistic software. Work like this paper is an important step toward changing that: helping agents understand what they don’t know and building mechanisms for continual self-improvement. These capabilities are essential if we want agents that can operate safely, adapt to new situations, and deliver consistent results at scale,” says Akash Srivastava, director and chief architect of Core AI at IBM Software, who was not involved with this work.&lt;/p&gt;&lt;p&gt;This work was funded, in part, by the MIT-IBM Watson AI Lab, the MIT-Amazon Science Hub, the MIT-Google Program for Computing Innovation, and MathWorks.&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/smarter-way-large-language-models-think-about-hard-problems-1204</guid><pubDate>Thu, 04 Dec 2025 05:00:00 +0000</pubDate></item></channel></rss>