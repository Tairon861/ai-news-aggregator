<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 01 Oct 2025 01:48:13 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Powering HPC with next-generation CPUs (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/30/1124493/powering-hpc-with-next-generation-cpus/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTRIMS_AMD-social-1200px.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft and AMD&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;For all the excitement around GPUs—the workhorses of today’s AI revolution—the central processing unit (CPU) remains the backbone of high-performance computing (HPC). CPUs still handle 80% to 90% of HPC workloads globally, powering everything from climate modeling to semiconductor design. Far from being eclipsed, they’re evolving in ways that make them more competitive, flexible, and indispensable than ever.&lt;/p&gt;  &lt;div&gt;[embedded content]&lt;/div&gt;  &lt;p&gt;The competitive landscape around CPUs has intensified. Once dominated almost exclusively by Intel’s x86 chips, the market now includes powerful alternatives based on ARM and even emerging architectures like RISC-V. Flagship examples like Japan’s Fugaku supercomputer demonstrate how CPU innovation is pushing performance to new frontiers. Meanwhile, cloud providers like Microsoft and AWS are developing their own silicon, adding even more diversity to the ecosystem.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;What makes CPUs so enduring? Flexibility, compatibility, and cost efficiency are key. As Evan Burness of Microsoft Azure points out, CPUs remain the “it-just-works” technology. Moving complex, proprietary code to GPUs can be an expensive and time-consuming effort, while CPUs typically support software continuity across generations with minimal friction. That reliability matters for businesses and researchers who need results, not just raw power.&lt;/p&gt;  &lt;p&gt;Innovation is also reshaping what a CPU can be. Advances in chiplet design, on-package memory, and hybrid CPU-GPU architectures are extending the performance curve well beyond the limits of Moore’s Law. For many organizations, the CPU is the strategic choice that balances speed, efficiency, and cost.&lt;/p&gt; 
 &lt;p&gt;Looking ahead, the relationship between CPUs, GPUs, and specialized processors like NPUs will define the future of HPC. Rather than a zero-sum contest, it’s increasingly a question of fit-for-purpose design. As Addison Snell, co-founder and chief executive officer of Intersect360 Research, notes, science and industry never run out of harder problems to solve.&lt;/p&gt;  &lt;p&gt;That means CPUs, far from fading, will remain at the center of the computing ecosystem.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;To learn more, read the new report "Designing CPUs for next-generation supercomputing."&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTRIMS_AMD-social-1200px.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft and AMD&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;For all the excitement around GPUs—the workhorses of today’s AI revolution—the central processing unit (CPU) remains the backbone of high-performance computing (HPC). CPUs still handle 80% to 90% of HPC workloads globally, powering everything from climate modeling to semiconductor design. Far from being eclipsed, they’re evolving in ways that make them more competitive, flexible, and indispensable than ever.&lt;/p&gt;  &lt;div&gt;[embedded content]&lt;/div&gt;  &lt;p&gt;The competitive landscape around CPUs has intensified. Once dominated almost exclusively by Intel’s x86 chips, the market now includes powerful alternatives based on ARM and even emerging architectures like RISC-V. Flagship examples like Japan’s Fugaku supercomputer demonstrate how CPU innovation is pushing performance to new frontiers. Meanwhile, cloud providers like Microsoft and AWS are developing their own silicon, adding even more diversity to the ecosystem.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;p&gt;What makes CPUs so enduring? Flexibility, compatibility, and cost efficiency are key. As Evan Burness of Microsoft Azure points out, CPUs remain the “it-just-works” technology. Moving complex, proprietary code to GPUs can be an expensive and time-consuming effort, while CPUs typically support software continuity across generations with minimal friction. That reliability matters for businesses and researchers who need results, not just raw power.&lt;/p&gt;  &lt;p&gt;Innovation is also reshaping what a CPU can be. Advances in chiplet design, on-package memory, and hybrid CPU-GPU architectures are extending the performance curve well beyond the limits of Moore’s Law. For many organizations, the CPU is the strategic choice that balances speed, efficiency, and cost.&lt;/p&gt; 
 &lt;p&gt;Looking ahead, the relationship between CPUs, GPUs, and specialized processors like NPUs will define the future of HPC. Rather than a zero-sum contest, it’s increasingly a question of fit-for-purpose design. As Addison Snell, co-founder and chief executive officer of Intersect360 Research, notes, science and industry never run out of harder problems to solve.&lt;/p&gt;  &lt;p&gt;That means CPUs, far from fading, will remain at the center of the computing ecosystem.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;To learn more, read the new report "Designing CPUs for next-generation supercomputing."&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/30/1124493/powering-hpc-with-next-generation-cpus/</guid><pubDate>Tue, 30 Sep 2025 13:52:42 +0000</pubDate></item><item><title>Designing CPUs for next-generation supercomputing (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/09/30/1124505/designing-cpus-for-next-generation-supercomputing/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft Azure and AMD&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In Seattle, a meteorologist analyzes dynamic atmospheric models to predict the next major storm system. In Stuttgart, an automotive engineer examines crash-test simulations&amp;nbsp;for vehicle safety&amp;nbsp;certification. And in Singapore, a financial analyst&amp;nbsp;simulates portfolio stress tests&amp;nbsp;to hedge against global&amp;nbsp;economic shocks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Each of these professionals—and the consumers, commuters, and investors who depend on their insights— relies on a time-tested pillar of high-performance computing: the humble CPU.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1124524" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MIT_MIcrosoftAMD_V6_092925Cover.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;With GPU-powered AI breakthroughs getting the lion’s share of press (and investment) in 2025, it is tempting to assume that CPUs are yesterday’s news. &lt;strong&gt;Recent predictions &lt;/strong&gt;anticipate that GPU and accelerator installations will increase by 17% year over year through 2030. But, in reality, CPUs are still responsible for the vast majority of today’s most cutting-edge scientific, engineering, and research workloads. Evan Burness, who leads Microsoft Azure’s HPC and AI product teams, estimates that CPUs still support 80% to 90% of HPC simulation jobs today.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1124526" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR2024_V1_microamdSocials3.png" /&gt;&lt;/figure&gt;  &lt;p&gt;In 2025, not only are these systems far from obsolete, they are experiencing a technological renaissance. A new wave of CPU innovation, including high-bandwidth memory (HBM), is delivering major performance gains— without requiring costly architectural resets.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;To learn more, watch the new webcast "&lt;/em&gt;&lt;em&gt;Powering HPC with next-generation CPUs&lt;/em&gt;."&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Microsoft Azure and AMD&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;In Seattle, a meteorologist analyzes dynamic atmospheric models to predict the next major storm system. In Stuttgart, an automotive engineer examines crash-test simulations&amp;nbsp;for vehicle safety&amp;nbsp;certification. And in Singapore, a financial analyst&amp;nbsp;simulates portfolio stress tests&amp;nbsp;to hedge against global&amp;nbsp;economic shocks.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Each of these professionals—and the consumers, commuters, and investors who depend on their insights— relies on a time-tested pillar of high-performance computing: the humble CPU.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;&lt;figure class="wp-block-image size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-1124524" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MIT_MIcrosoftAMD_V6_092925Cover.png?w=1555" width="1555" /&gt;&lt;/figure&gt;    &lt;p&gt;With GPU-powered AI breakthroughs getting the lion’s share of press (and investment) in 2025, it is tempting to assume that CPUs are yesterday’s news. &lt;strong&gt;Recent predictions &lt;/strong&gt;anticipate that GPU and accelerator installations will increase by 17% year over year through 2030. But, in reality, CPUs are still responsible for the vast majority of today’s most cutting-edge scientific, engineering, and research workloads. Evan Burness, who leads Microsoft Azure’s HPC and AI product teams, estimates that CPUs still support 80% to 90% of HPC simulation jobs today.&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1124526" src="https://wp.technologyreview.com/wp-content/uploads/2025/09/MITTR2024_V1_microamdSocials3.png" /&gt;&lt;/figure&gt;  &lt;p&gt;In 2025, not only are these systems far from obsolete, they are experiencing a technological renaissance. A new wave of CPU innovation, including high-bandwidth memory (HBM), is delivering major performance gains— without requiring costly architectural resets.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Download the report.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;To learn more, watch the new webcast "&lt;/em&gt;&lt;em&gt;Powering HPC with next-generation CPUs&lt;/em&gt;."&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/09/30/1124505/designing-cpus-for-next-generation-supercomputing/</guid><pubDate>Tue, 30 Sep 2025 13:54:41 +0000</pubDate></item><item><title>[NEW] The anatomy of a personal health agent (The latest research from Google)</title><link>https://research.google/blog/the-anatomy-of-a-personal-health-agent/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The rapid advancement of large language models (LLMs), combined with data from wearable devices, presents a transformative opportunity to empower people on their personal health journeys. However, health needs vary from individual to individual. Answering a specific query, such as, "On average, how many hours have I been sleeping this last month?" requires different skills than an open-ended question like, "What can I do to improve my sleep quality?" A single system can struggle to address this complexity.&lt;/p&gt;&lt;p&gt;To meet this challenge, we adopt a human-centered process and propose the Personal Health Agent (PHA). This agent is a comprehensive research framework that can reason about multimodal data to provide personalized, evidence-based guidance. Using a multi-agent architecture, PHA deconstructs personal health and wellness support into three core roles (data science, domain expert, and health coach), each handled by a specialist sub-agent. To evaluate each sub-agent and the multi-agent system, we leveraged a real-world dataset from an IRB-reviewed study where ~1200 users provided informed consent to share their wearables data from Fitbit, a health questionnaire, and blood test results. We conducted automated and human evaluations across 10 benchmark tasks, involving more than 7,000 annotations and 1,100 hours of effort from health experts and end-users. Our work represents the most comprehensive evaluation of a health agent to date and establishes a strong foundation towards the futuristic vision of a personal health agent accessible to everyone.&lt;/p&gt;&lt;p&gt;This work outlines a conceptual framework for research purposes, and should not be considered a description of any specific product, service, or feature currently in development or available to the public. Any real-world application would be subject to a separate design, validation, and review process.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;The rapid advancement of large language models (LLMs), combined with data from wearable devices, presents a transformative opportunity to empower people on their personal health journeys. However, health needs vary from individual to individual. Answering a specific query, such as, "On average, how many hours have I been sleeping this last month?" requires different skills than an open-ended question like, "What can I do to improve my sleep quality?" A single system can struggle to address this complexity.&lt;/p&gt;&lt;p&gt;To meet this challenge, we adopt a human-centered process and propose the Personal Health Agent (PHA). This agent is a comprehensive research framework that can reason about multimodal data to provide personalized, evidence-based guidance. Using a multi-agent architecture, PHA deconstructs personal health and wellness support into three core roles (data science, domain expert, and health coach), each handled by a specialist sub-agent. To evaluate each sub-agent and the multi-agent system, we leveraged a real-world dataset from an IRB-reviewed study where ~1200 users provided informed consent to share their wearables data from Fitbit, a health questionnaire, and blood test results. We conducted automated and human evaluations across 10 benchmark tasks, involving more than 7,000 annotations and 1,100 hours of effort from health experts and end-users. Our work represents the most comprehensive evaluation of a health agent to date and establishes a strong foundation towards the futuristic vision of a personal health agent accessible to everyone.&lt;/p&gt;&lt;p&gt;This work outlines a conceptual framework for research purposes, and should not be considered a description of any specific product, service, or feature currently in development or available to the public. Any real-world application would be subject to a separate design, validation, and review process.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/the-anatomy-of-a-personal-health-agent/</guid><pubDate>Tue, 30 Sep 2025 14:41:00 +0000</pubDate></item><item><title>California’s newly signed AI law just gave Big Tech exactly what it wanted (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/californias-newly-signed-ai-law-just-gave-big-tech-exactly-what-it-wanted/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        After the failure of S.B. 1047, new AI disclosure law drops kill switch for disclosure mandate.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="California Gov. Gavin Newsom looks on during a bill signing event related to redrawing the state’s congressional maps on August 21, 2025" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/newsom_flags-640x360.jpg" width="640" /&gt;
                  &lt;img alt="California Gov. Gavin Newsom looks on during a bill signing event related to redrawing the state’s congressional maps on August 21, 2025" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/newsom_flags-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      California Gov. Gavin Newsom in August 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Justin Sullivan via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, California Governor Gavin Newsom signed the Transparency in Frontier Artificial Intelligence Act into law, requiring AI companies to disclose their safety practices while stopping short of mandating actual safety testing. The law requires companies with annual revenues of at least $500 million to publish safety protocols on their websites and report incidents to state authorities, but it lacks the stronger enforcement teeth of the bill Newsom vetoed last year after tech companies lobbied heavily against it.&lt;/p&gt;
&lt;p&gt;The legislation, S.B. 53, replaces Senator Scott Wiener's previous attempt at AI regulation, known as S.B. 1047, that would have required safety testing and "kill switches" for AI systems. Instead, the new law asks companies to describe how they incorporate "national standards, international standards, and industry-consensus best practices" into their AI development, without specifying what those standards are or requiring independent verification.&lt;/p&gt;
&lt;p&gt;"California has proven that we can establish regulations to protect our communities while also ensuring that the growing AI industry continues to thrive," Newsom said in a statement, though the law's actual protective measures remain largely voluntary beyond basic reporting requirements.&lt;/p&gt;
&lt;p&gt;According to the California state government, the state houses 32 of the world's top 50 AI companies, and more than half of global venture capital funding for AI and machine learning startups went to Bay Area companies last year. So while the recently signed bill is state-level legislation, what happens in California AI regulation will have a much wider impact, both by legislative precedent and by affecting companies that craft AI systems used around the world.&lt;/p&gt;
&lt;h2&gt;Transparency instead of testing&lt;/h2&gt;
&lt;p&gt;Where the vetoed SB 1047 would have mandated safety testing and kill switches for AI systems, the new law focuses on disclosure. Companies must report what the state calls "potential critical safety incidents" to California's Office of Emergency Services and provide whistleblower protections for employees who raise safety concerns. The law defines catastrophic risk narrowly as incidents potentially causing 50+ deaths or $1 billion in damage through weapons assistance, autonomous criminal acts, or loss of control. The attorney general can levy civil penalties of up to $1 million per violation for noncompliance with these reporting requirements.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The shift from mandatory safety testing to voluntary disclosure follows a year of intense lobbying. According to The New York Times, Meta and venture capital firm Andreessen Horowitz have pledged up to $200 million to two separate super PACs supporting politicians friendly to the AI industry, while companies have pushed for federal legislation that would preempt state AI rules.&lt;/p&gt;
&lt;p&gt;The original SB 1047 had been drafted by AI safety advocates who warned about existential threats from AI drawn heavily from hypothetical scenarios and tropes from science fiction, but it met pushback from AI firms that found the requirements too vague and potential reporting burdens too onerous. The new law follows recommendations from AI experts convened by Newsom, including Stanford's Fei-Fei Li and former California Supreme Court Justice Mariano-Florentino Cuéllar.&lt;/p&gt;
&lt;p&gt;As with SB-1047, the new law creates CalCompute, a consortium within the Government Operations Agency, to develop a public computing cluster framework. The California Department of Technology will recommend annual updates to the law, though such recommendations require no legislative action.&lt;/p&gt;
&lt;p&gt;Senator Wiener described the law as establishing "commonsense guardrails," and Anthropic's co-founder, Jack Clark, called the law's safeguards "practical," though the transparency requirements likely mirror practices already standard at major AI companies and disclosure requirements without enforcement mechanisms or specific standards and may offer limited protection against potential AI harms in the long run.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        After the failure of S.B. 1047, new AI disclosure law drops kill switch for disclosure mandate.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="California Gov. Gavin Newsom looks on during a bill signing event related to redrawing the state’s congressional maps on August 21, 2025" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/newsom_flags-640x360.jpg" width="640" /&gt;
                  &lt;img alt="California Gov. Gavin Newsom looks on during a bill signing event related to redrawing the state’s congressional maps on August 21, 2025" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/newsom_flags-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      California Gov. Gavin Newsom in August 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Justin Sullivan via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Monday, California Governor Gavin Newsom signed the Transparency in Frontier Artificial Intelligence Act into law, requiring AI companies to disclose their safety practices while stopping short of mandating actual safety testing. The law requires companies with annual revenues of at least $500 million to publish safety protocols on their websites and report incidents to state authorities, but it lacks the stronger enforcement teeth of the bill Newsom vetoed last year after tech companies lobbied heavily against it.&lt;/p&gt;
&lt;p&gt;The legislation, S.B. 53, replaces Senator Scott Wiener's previous attempt at AI regulation, known as S.B. 1047, that would have required safety testing and "kill switches" for AI systems. Instead, the new law asks companies to describe how they incorporate "national standards, international standards, and industry-consensus best practices" into their AI development, without specifying what those standards are or requiring independent verification.&lt;/p&gt;
&lt;p&gt;"California has proven that we can establish regulations to protect our communities while also ensuring that the growing AI industry continues to thrive," Newsom said in a statement, though the law's actual protective measures remain largely voluntary beyond basic reporting requirements.&lt;/p&gt;
&lt;p&gt;According to the California state government, the state houses 32 of the world's top 50 AI companies, and more than half of global venture capital funding for AI and machine learning startups went to Bay Area companies last year. So while the recently signed bill is state-level legislation, what happens in California AI regulation will have a much wider impact, both by legislative precedent and by affecting companies that craft AI systems used around the world.&lt;/p&gt;
&lt;h2&gt;Transparency instead of testing&lt;/h2&gt;
&lt;p&gt;Where the vetoed SB 1047 would have mandated safety testing and kill switches for AI systems, the new law focuses on disclosure. Companies must report what the state calls "potential critical safety incidents" to California's Office of Emergency Services and provide whistleblower protections for employees who raise safety concerns. The law defines catastrophic risk narrowly as incidents potentially causing 50+ deaths or $1 billion in damage through weapons assistance, autonomous criminal acts, or loss of control. The attorney general can levy civil penalties of up to $1 million per violation for noncompliance with these reporting requirements.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The shift from mandatory safety testing to voluntary disclosure follows a year of intense lobbying. According to The New York Times, Meta and venture capital firm Andreessen Horowitz have pledged up to $200 million to two separate super PACs supporting politicians friendly to the AI industry, while companies have pushed for federal legislation that would preempt state AI rules.&lt;/p&gt;
&lt;p&gt;The original SB 1047 had been drafted by AI safety advocates who warned about existential threats from AI drawn heavily from hypothetical scenarios and tropes from science fiction, but it met pushback from AI firms that found the requirements too vague and potential reporting burdens too onerous. The new law follows recommendations from AI experts convened by Newsom, including Stanford's Fei-Fei Li and former California Supreme Court Justice Mariano-Florentino Cuéllar.&lt;/p&gt;
&lt;p&gt;As with SB-1047, the new law creates CalCompute, a consortium within the Government Operations Agency, to develop a public computing cluster framework. The California Department of Technology will recommend annual updates to the law, though such recommendations require no legislative action.&lt;/p&gt;
&lt;p&gt;Senator Wiener described the law as establishing "commonsense guardrails," and Anthropic's co-founder, Jack Clark, called the law's safeguards "practical," though the transparency requirements likely mirror practices already standard at major AI companies and disclosure requirements without enforcement mechanisms or specific standards and may offer limited protection against potential AI harms in the long run.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/californias-newly-signed-ai-law-just-gave-big-tech-exactly-what-it-wanted/</guid><pubDate>Tue, 30 Sep 2025 15:12:10 +0000</pubDate></item><item><title>Ring cameras can now recognize faces and help to find lost pets (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/ring-cameras-can-now-recognize-faces-and-help-to-find-lost-pets/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At an event on Tuesday, Amazon unveiled a range of new AI-powered features for its latest Ring cameras and doorbells.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The features will enable Ring users to recognize visitors’ faces and find lost pets by connecting with other Ring users in the same neighborhood. Amazon also launched an Alexa+ feature that functions as a smart doorbell assistant, providing details about visitors before users answer the door.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ring is also introducing its first 4K product line along with “Retinal Vision,” a new imaging technology designed to provide clearer video.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052277" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/assets.aboutamazon.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon Ring&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The most notable feature revealed at the event was “Familiar Faces,” which uses AI to identify friends and family. Users can enroll the faces of their loved ones into the device, enabling Ring to alert them when it recognizes a visitor. The AI will also alert the user when an unfamiliar person is detected, helping them to make informed decisions quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company explained in today’s blog post that the new feature is meant to empower “customers to reduce notifications triggered by familiar people’s routine activities” and eliminate guesswork for people detection.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Equally important is that if someone you don’t recognize is lingering, you’ll know immediately [they’re] unfamiliar,” Ring founder Jamie Siminoff told press at the event.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ring has faced criticism for its close ties with law enforcement and its history of poor data management. Last year, following numerous complaints, the company announced that it would no longer accommodate police requests for footage from Ring users without a warrant.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Familiar Faces feature can be integrated into the broader Alexa+ Greetings system, which will enable specific greetings when the camera recognizes a specific face. This feature transforms the voice assistant into a smart doorbell attendant, enabling it to interact with visitors, manage deliveries, and identify the purpose of visits to keep users informed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another AI feature, Search Party, helps find lost pets by networking Ring cameras. When a user registers a lost pet, neighboring Ring users will receive a description of the pet and can report sightings. The system uses AI to deliver possible matches, although sightings have to be voluntarily reported. The company states that users are in control of their privacy and can choose to ignore the alert if they don’t want to share information with a neighbor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both Familiar Faces and Alexa+ Greeting will roll out to customers starting in December. Search Party for dogs will launch in November, with support for cats and other pets planned for release in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052278" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/assets.aboutamazon-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon Ring&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The features will come preloaded onto Ring’s new Retinal 2K and Retinal 4K devices, the company’s new products that use “Retinal Vision,” imaging technology that improves the imaging process with advanced AI. The Retinal Tuning function continuously checks the camera’s video quality and optimizes the settings to deliver the best possible picture quality to users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ring Retinal 2K is available on two new products: Indoor Cam Plus ($59.99) and Wired Doorbell Plus ($179.99). The 4K line includes the Ring Wired Doorbell Pro ($249.99), Outdoor Cam Pro ($199.99), Spotlight Cam Pro ($249.99), Floodlight Cam Pro ($279.99), and Wired Doorbell Elite ($499.99).&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The devices are available for preorder today.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the Ring announcements, Amazon also debuted a 2K Blink lineup of cameras and the Blink Arc, a $99.99 security camera that combines two Blink Mini 2K+ cameras into a single device, providing a 180-degree panoramic view of the surrounding area.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At an event on Tuesday, Amazon unveiled a range of new AI-powered features for its latest Ring cameras and doorbells.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The features will enable Ring users to recognize visitors’ faces and find lost pets by connecting with other Ring users in the same neighborhood. Amazon also launched an Alexa+ feature that functions as a smart doorbell assistant, providing details about visitors before users answer the door.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ring is also introducing its first 4K product line along with “Retinal Vision,” a new imaging technology designed to provide clearer video.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052277" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/assets.aboutamazon.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon Ring&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The most notable feature revealed at the event was “Familiar Faces,” which uses AI to identify friends and family. Users can enroll the faces of their loved ones into the device, enabling Ring to alert them when it recognizes a visitor. The AI will also alert the user when an unfamiliar person is detected, helping them to make informed decisions quickly.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company explained in today’s blog post that the new feature is meant to empower “customers to reduce notifications triggered by familiar people’s routine activities” and eliminate guesswork for people detection.&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Equally important is that if someone you don’t recognize is lingering, you’ll know immediately [they’re] unfamiliar,” Ring founder Jamie Siminoff told press at the event.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ring has faced criticism for its close ties with law enforcement and its history of poor data management. Last year, following numerous complaints, the company announced that it would no longer accommodate police requests for footage from Ring users without a warrant.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Familiar Faces feature can be integrated into the broader Alexa+ Greetings system, which will enable specific greetings when the camera recognizes a specific face. This feature transforms the voice assistant into a smart doorbell attendant, enabling it to interact with visitors, manage deliveries, and identify the purpose of visits to keep users informed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another AI feature, Search Party, helps find lost pets by networking Ring cameras. When a user registers a lost pet, neighboring Ring users will receive a description of the pet and can report sightings. The system uses AI to deliver possible matches, although sightings have to be voluntarily reported. The company states that users are in control of their privacy and can choose to ignore the alert if they don’t want to share information with a neighbor.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Both Familiar Faces and Alexa+ Greeting will roll out to customers starting in December. Search Party for dogs will launch in November, with support for cats and other pets planned for release in the future.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052278" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/assets.aboutamazon-1.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon Ring&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The features will come preloaded onto Ring’s new Retinal 2K and Retinal 4K devices, the company’s new products that use “Retinal Vision,” imaging technology that improves the imaging process with advanced AI. The Retinal Tuning function continuously checks the camera’s video quality and optimizes the settings to deliver the best possible picture quality to users.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ring Retinal 2K is available on two new products: Indoor Cam Plus ($59.99) and Wired Doorbell Plus ($179.99). The 4K line includes the Ring Wired Doorbell Pro ($249.99), Outdoor Cam Pro ($199.99), Spotlight Cam Pro ($249.99), Floodlight Cam Pro ($279.99), and Wired Doorbell Elite ($499.99).&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The devices are available for preorder today.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In addition to the Ring announcements, Amazon also debuted a 2K Blink lineup of cameras and the Blink Arc, a $99.99 security camera that combines two Blink Mini 2K+ cameras into a single device, providing a 180-degree panoramic view of the surrounding area.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/ring-cameras-can-now-recognize-faces-and-help-to-find-lost-pets/</guid><pubDate>Tue, 30 Sep 2025 15:39:07 +0000</pubDate></item><item><title>Amazon unveils new Echo devices, powered by its AI, Alexa+ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/amazon-unveils-new-echo-devices-powered-by-its-al-alexa/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At its annual hardware event, Amazon introduced a new lineup of Echo devices, built specifically for its AI assistant, Alexa+, which has already rolled out to millions of customers through its early access program. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To showcase the AI’s capabilities, Amazon is releasing four new Echo devices with improved processing power and memory: the Echo Dot Max, Echo Studio, Echo Show 8, and Echo Show 11.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Key to the devices are the Alexa+ integrations, allowing the speakers to respond to more queries than earlier models, offering support for natural language conversations, more complex questions, and soon, more add-ons and capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This will later include an Alexa+ Store, where users can explore services from brands like Fandango, GrubHub, Lyft, Priceline, Taskrabbit, Thumbtack, and Yahoo Sports. The devices will also be able to manage new or existing subscriptions with Amazon’s own services like Amazon Music, Amazon Kids+, or Alexa Emergency Assist and customize their Alexa experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new Echo devices launching today run on Amazon’s custom-designed silicon chips, the AZ3 and AZ3 Pro, which include an AI Accelerator designed to run AI edge models. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a photo showing two Amazon Echo devices, a large model and a smaller model." class="wp-image-3052305" height="743" src="https://techcrunch.com/wp-content/uploads/2025/09/download-2.png" width="1320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The AZ3 enables better conversation detection on the Echo Dot, letting people talk to the device from anywhere in the room, while still filtering out background noise. The chip also improves detection of the wake word by over 50%, Amazon claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The other three devices — the Studio, Show 8, and 11 — use the AZ3 Pro, which adds support for advanced language models and vision transformers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, the AZ3 Pro-enabled devices include Ominisense, a custom sensor platform for ambient AI that uses the 13-megapixel camera on new Echo Show devices, audio, ultrasound, Wi-Fi radar, accelerometer, and Wi-Fi channel state information (CSI). With this feature, the devices allow Alexa to act on events happening in the home, like delivering a reminder when a particular person walks in the room or alerting you to an open garage door before you go to bed at night.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="an image showing the two Echo Show devices side-by-side" class="wp-image-3052306" height="743" src="https://techcrunch.com/wp-content/uploads/2025/09/download-1.png" width="1320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new Echo Dot Max, $99.99, adds nearly three times the bass for better sound. The two-way speaker includes a woofer for the deep bass and a custom tweeter for the high notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The $219.99 Echo Studio, meanwhile, features a new spherical design, allowing it to be 40% smaller than the original, says Amazon. The Echo Studio also includes a high-excursion woofer, spatial audio, and Dolby Atmos, and an upgraded light ring for better visual understanding of what Alexa is doing or processing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company notes consumers can connect up to five Echo Studio or Echo Dot Max devices with compatible Fire TV sticks for an immersive sound system in their home, and it plans to sell products in Alexa Home Theater bundles. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a photo of a new Amazon Echo Show featuring a display with a photo of a dog on a rug." class="wp-image-3052307" height="743" src="https://techcrunch.com/wp-content/uploads/2025/09/download-1.jpeg" width="1243" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Also new are two smart displays, the Echo Show 8 ($179.99) and Echo Show 11 ($219.99), which both have a new design, improved picture quality, a 13-megapixel camera, a larger screen area, new front-facing stereo speakers, a custom woofer, and Alexa+ powered features. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI assistant will run a new smart home experience called Alexa+ Home, which combines things like event summaries from Ring camera feeds and a smart home hub that supports Matter, Thread, and Zigbee. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Alexa devices with a screen, the displays also work well for accessing entertainment, like streaming audio and video, managing home organization and family activities, and managing household shopping needs. The latter integrates with Amazon, Whole Foods, and Amazon Fresh to make reordering favorites and delivery tracking easier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Amazon is teaming up with smart ring maker Oura to bring personalized health and wellness suggestions to Alexa devices. This could help do things like add workout reminders or nudges to head to bed to get the best sleep. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other devices from Withings and Wyze will be supported in the future.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;At its annual hardware event, Amazon introduced a new lineup of Echo devices, built specifically for its AI assistant, Alexa+, which has already rolled out to millions of customers through its early access program. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To showcase the AI’s capabilities, Amazon is releasing four new Echo devices with improved processing power and memory: the Echo Dot Max, Echo Studio, Echo Show 8, and Echo Show 11.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Key to the devices are the Alexa+ integrations, allowing the speakers to respond to more queries than earlier models, offering support for natural language conversations, more complex questions, and soon, more add-ons and capabilities.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This will later include an Alexa+ Store, where users can explore services from brands like Fandango, GrubHub, Lyft, Priceline, Taskrabbit, Thumbtack, and Yahoo Sports. The devices will also be able to manage new or existing subscriptions with Amazon’s own services like Amazon Music, Amazon Kids+, or Alexa Emergency Assist and customize their Alexa experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new Echo devices launching today run on Amazon’s custom-designed silicon chips, the AZ3 and AZ3 Pro, which include an AI Accelerator designed to run AI edge models. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a photo showing two Amazon Echo devices, a large model and a smaller model." class="wp-image-3052305" height="743" src="https://techcrunch.com/wp-content/uploads/2025/09/download-2.png" width="1320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The AZ3 enables better conversation detection on the Echo Dot, letting people talk to the device from anywhere in the room, while still filtering out background noise. The chip also improves detection of the wake word by over 50%, Amazon claims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The other three devices — the Studio, Show 8, and 11 — use the AZ3 Pro, which adds support for advanced language models and vision transformers. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, the AZ3 Pro-enabled devices include Ominisense, a custom sensor platform for ambient AI that uses the 13-megapixel camera on new Echo Show devices, audio, ultrasound, Wi-Fi radar, accelerometer, and Wi-Fi channel state information (CSI). With this feature, the devices allow Alexa to act on events happening in the home, like delivering a reminder when a particular person walks in the room or alerting you to an open garage door before you go to bed at night.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="an image showing the two Echo Show devices side-by-side" class="wp-image-3052306" height="743" src="https://techcrunch.com/wp-content/uploads/2025/09/download-1.png" width="1320" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The new Echo Dot Max, $99.99, adds nearly three times the bass for better sound. The two-way speaker includes a woofer for the deep bass and a custom tweeter for the high notes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The $219.99 Echo Studio, meanwhile, features a new spherical design, allowing it to be 40% smaller than the original, says Amazon. The Echo Studio also includes a high-excursion woofer, spatial audio, and Dolby Atmos, and an upgraded light ring for better visual understanding of what Alexa is doing or processing.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company notes consumers can connect up to five Echo Studio or Echo Dot Max devices with compatible Fire TV sticks for an immersive sound system in their home, and it plans to sell products in Alexa Home Theater bundles. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-full"&gt;&lt;img alt="a photo of a new Amazon Echo Show featuring a display with a photo of a dog on a rug." class="wp-image-3052307" height="743" src="https://techcrunch.com/wp-content/uploads/2025/09/download-1.jpeg" width="1243" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Amazon&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Also new are two smart displays, the Echo Show 8 ($179.99) and Echo Show 11 ($219.99), which both have a new design, improved picture quality, a 13-megapixel camera, a larger screen area, new front-facing stereo speakers, a custom woofer, and Alexa+ powered features. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The AI assistant will run a new smart home experience called Alexa+ Home, which combines things like event summaries from Ring camera feeds and a smart home hub that supports Matter, Thread, and Zigbee. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As Alexa devices with a screen, the displays also work well for accessing entertainment, like streaming audio and video, managing home organization and family activities, and managing household shopping needs. The latter integrates with Amazon, Whole Foods, and Amazon Fresh to make reordering favorites and delivery tracking easier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, Amazon is teaming up with smart ring maker Oura to bring personalized health and wellness suggestions to Alexa devices. This could help do things like add workout reminders or nudges to head to bed to get the best sleep. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other devices from Withings and Wyze will be supported in the future.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/amazon-unveils-new-echo-devices-powered-by-its-al-alexa/</guid><pubDate>Tue, 30 Sep 2025 15:55:07 +0000</pubDate></item><item><title>PayPal’s Honey to integrate with ChatGPT and other AIs for shopping assistance (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/paypals-honey-to-integrate-with-chatgpt-and-other-ais-for-shopping-assistance/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After teaming up&amp;nbsp;with Google on agentic commerce&amp;nbsp;this month, payments giant PayPal announced Tuesday it’s adding new features to its&amp;nbsp;PayPal Honey&amp;nbsp;browser extension. The features will provide AI chatbot users, who are researching items they want to purchase, Honey’s product recommendations, pricing, and access to deals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When users ask their preferred AI chatbot a shopping-related question, PayPal Honey’s extension will display links to the products the AI chatbot recommends, along with real-time pricing, merchant options, and offers, PayPal says. The system can also identify when the AI’s own recommendations may have left out major retailers and surface those additional options to the consumer. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The features are designed to help consumers better compare pricing and boost merchant sales through the addition of personalized offers, PayPal notes. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agentic shopping integrations are designed to be AI agnostic, PayPal told TechCrunch, but will initially work with OpenAI’s ChatGPT with more to follow. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052329" height="423" src="https://techcrunch.com/wp-content/uploads/2025/09/thumbnail_092625_Honey_PressRelease_Still_V3.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Honey&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the new features are part of its broader rollout of agentic commerce initiatives, which include the Google partnership, an agentic commerce offering, a remote&amp;nbsp;MCP server,&amp;nbsp;Agent Toolkit, as well as other, smaller deals — like an offer to use Perplexity’s premium service for a year for free, and free access to its new Comet browser.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, the AI providers will be a competitor for products like Honey, as they move into making product recommendations and connecting users with merchants directly. For instance, just yesterday OpenAI announced a plan to take on Amazon and Google with its own agentic shopping system, which includes an “Instant Checkout” feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI’s system initially only supports Etsy with plans for Shopify merchants “soon,” it’s a signal of what’s to come in the AI era. Instead of browsing the web or Amazon when looking for products and recommendations, users may start their shopping research in an AI chatbot, instead of just browsing the web, where Honey previously had traction, necessitating new products like this.  &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The AI features are launching after quite a bit of bad press for Honey. A YouTuber accused the company of stealing money from influencers by taking credit for sales that creators had driven. The revelation has even led to some lawsuits over the matter.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;After teaming up&amp;nbsp;with Google on agentic commerce&amp;nbsp;this month, payments giant PayPal announced Tuesday it’s adding new features to its&amp;nbsp;PayPal Honey&amp;nbsp;browser extension. The features will provide AI chatbot users, who are researching items they want to purchase, Honey’s product recommendations, pricing, and access to deals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When users ask their preferred AI chatbot a shopping-related question, PayPal Honey’s extension will display links to the products the AI chatbot recommends, along with real-time pricing, merchant options, and offers, PayPal says. The system can also identify when the AI’s own recommendations may have left out major retailers and surface those additional options to the consumer. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The features are designed to help consumers better compare pricing and boost merchant sales through the addition of personalized offers, PayPal notes. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The agentic shopping integrations are designed to be AI agnostic, PayPal told TechCrunch, but will initially work with OpenAI’s ChatGPT with more to follow. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3052329" height="423" src="https://techcrunch.com/wp-content/uploads/2025/09/thumbnail_092625_Honey_PressRelease_Still_V3.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Honey&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company says the new features are part of its broader rollout of agentic commerce initiatives, which include the Google partnership, an agentic commerce offering, a remote&amp;nbsp;MCP server,&amp;nbsp;Agent Toolkit, as well as other, smaller deals — like an offer to use Perplexity’s premium service for a year for free, and free access to its new Comet browser.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, the AI providers will be a competitor for products like Honey, as they move into making product recommendations and connecting users with merchants directly. For instance, just yesterday OpenAI announced a plan to take on Amazon and Google with its own agentic shopping system, which includes an “Instant Checkout” feature.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While OpenAI’s system initially only supports Etsy with plans for Shopify merchants “soon,” it’s a signal of what’s to come in the AI era. Instead of browsing the web or Amazon when looking for products and recommendations, users may start their shopping research in an AI chatbot, instead of just browsing the web, where Honey previously had traction, necessitating new products like this.  &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The AI features are launching after quite a bit of bad press for Honey. A YouTuber accused the company of stealing money from influencers by taking credit for sales that creators had driven. The revelation has even led to some lawsuits over the matter.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/paypals-honey-to-integrate-with-chatgpt-and-other-ais-for-shopping-assistance/</guid><pubDate>Tue, 30 Sep 2025 16:11:40 +0000</pubDate></item><item><title>How Replit went from $2.8M to $150M ARR by pivoting away from professional developers (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/how-replit-went-from-2-8m-to-150m-arr-by-pivoting-away-from-professional-developers/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Replit-founder-CEO-Amjad-Masad.png?resize=1200,715" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, TechCrunch Editor-in-Chief Connie Loizos and StrictlyVC’s Alex Gove spoke with with Amjad Masad, founder and CEO of Replit, fresh off the company’s $250 million Series C at a $3 billion valuation.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;They discussed Replit’s remarkable journey from hovering around $2.8 million in ARR for years to hitting $150 million — and how a controversial pivot away from professional developers made it all possible. Masad explained why targeting non-technical users actually requires more compute power than serving experienced coders, and how his company survived a viral production database disaster that briefly threatened to derail everything. &lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;They also dove into the challenges of AI agent “reward hacking,” why Replit pits multiple LLMs against each other, and what it means to build autonomous coding agents that can work for hours without human intervention. Plus, Masad shared his vision for creating a billion software developers and why he thinks solving hard problems around safety and security will become Replit’s competitive moat.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Replit-founder-CEO-Amjad-Masad.png?resize=1200,715" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;This week on StrictlyVC Download, TechCrunch Editor-in-Chief Connie Loizos and StrictlyVC’s Alex Gove spoke with with Amjad Masad, founder and CEO of Replit, fresh off the company’s $250 million Series C at a $3 billion valuation.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;They discussed Replit’s remarkable journey from hovering around $2.8 million in ARR for years to hitting $150 million — and how a controversial pivot away from professional developers made it all possible. Masad explained why targeting non-technical users actually requires more compute power than serving experienced coders, and how his company survived a viral production database disaster that briefly threatened to derail everything. &lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;They also dove into the challenges of AI agent “reward hacking,” why Replit pits multiple LLMs against each other, and what it means to build autonomous coding agents that can work for hours without human intervention. Plus, Masad shared his vision for creating a billion software developers and why he thinks solving hard problems around safety and security will become Replit’s competitive moat.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;StrictlyVC Download posts every Tuesday. Subscribe on&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Apple&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;,&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;Spotify,&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;or&amp;nbsp;&lt;/em&gt;&lt;strong&gt;&lt;em&gt;wherever you listen to podcasts&amp;nbsp;&lt;/em&gt;&lt;/strong&gt;&lt;em&gt;to be alerted when new episodes drop.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/how-replit-went-from-2-8m-to-150m-arr-by-pivoting-away-from-professional-developers/</guid><pubDate>Tue, 30 Sep 2025 16:18:25 +0000</pubDate></item><item><title>Hance will demo its kilobyte-size AI audio-processing software at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/hance-will-demo-its-kilobyte-size-ai-audio-processing-software-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Imagine you’re a Formula One driver hurtling down a race track at 200 miles per hour when your engineer comes on the radio and says&amp;nbsp;… &lt;em&gt;something&lt;/em&gt;. You can’t make it out, but you’re also not going to spend a lap playing out that old Verizon commercial (“Can you hear me now?”) with the race — and your life — on the line.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is just one problem Norwegian startup Hance is solving with an impressively small and fast bit of audio-processing software that’s already attracted customers like Intel and Riedel Communications, the official radio supplier to F1. Hance is one of the 200 startups selected to show off its technology at TechCrunch Disrupt 2025, which runs October 27 through 29 at Moscone Center in San Francisco.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The outfit of around 10 employees boasts a wealth of audio industry experience. That includes co-founder Stian Aagedal, who’s also the CEO of audio editing software company Acon Digital, and Peder Jørgensen, who runs the sound effects library Soundly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With artificial intelligence booming, Aagedal, Jørgensen, and the rest of the Hance team realized there was an opportunity to leverage these new technologies throughout the audio-processing pipeline — but especially in noise reduction and isolation. So a few years ago they started training their own models on Soundly’s high-quality recordings, including everything from the roar of F1 cars to the crack-and-rumble of Icelandic volcanoes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, they’ve been able to shrink the Hance processing models to just 242 kB, meaning they can run on device instead of in the cloud, saving time and energy. Hance says these models can separate sounds; remove noise, echo, and reverb; and enhance speech clarity with just 10 milliseconds of latency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While other companies offer similar audio processing software, Hance’s tiny, energy-efficient models can process audio on devices of all sizes in real time. That makes it great for the radios Riedel sells to F1 or FIFA, and also attractive to law enforcement and defense applications, CEO Joote Hika told TechCrunch in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hika sees opportunity for Hance’s audio processing to go in many more directions, too, now that it has lined up Intel as a partner. Hance has been working with the technology giant to adopt its models to work on different versions of its chips, including its latest “neural processing units.” The startup is talking with other chipmakers, too, and an undisclosed smartphone maker, Hika said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Hika also said these professional partnerships will likely last at least a few years and that they’re non-exclusive. That’s good for the startup’s ability to scale, but he said Hance will have to keep developing at a rapid pace to stay ahead of the competition. The company has just brought on its first chief commercial officer, but Hika said he expects Hance to stay heavily focused on R&amp;amp;D and that the company will preference “AI-capable” workers to stay lean.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We know that we now have an advantage over our competitors, but we definitely have to keep that up, so we’re pushing fast,” he said&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Hance — and dozens of other startups, hearing their pitches and listening to guest speakers on four different stages — join us at Disrupt, taking place October 27 to 29, in San Francisco. &lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Learn more about tickets and pricing here.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Imagine you’re a Formula One driver hurtling down a race track at 200 miles per hour when your engineer comes on the radio and says&amp;nbsp;… &lt;em&gt;something&lt;/em&gt;. You can’t make it out, but you’re also not going to spend a lap playing out that old Verizon commercial (“Can you hear me now?”) with the race — and your life — on the line.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is just one problem Norwegian startup Hance is solving with an impressively small and fast bit of audio-processing software that’s already attracted customers like Intel and Riedel Communications, the official radio supplier to F1. Hance is one of the 200 startups selected to show off its technology at TechCrunch Disrupt 2025, which runs October 27 through 29 at Moscone Center in San Francisco.&amp;nbsp;&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The outfit of around 10 employees boasts a wealth of audio industry experience. That includes co-founder Stian Aagedal, who’s also the CEO of audio editing software company Acon Digital, and Peder Jørgensen, who runs the sound effects library Soundly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With artificial intelligence booming, Aagedal, Jørgensen, and the rest of the Hance team realized there was an opportunity to leverage these new technologies throughout the audio-processing pipeline — but especially in noise reduction and isolation. So a few years ago they started training their own models on Soundly’s high-quality recordings, including everything from the roar of F1 cars to the crack-and-rumble of Icelandic volcanoes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since then, they’ve been able to shrink the Hance processing models to just 242 kB, meaning they can run on device instead of in the cloud, saving time and energy. Hance says these models can separate sounds; remove noise, echo, and reverb; and enhance speech clarity with just 10 milliseconds of latency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While other companies offer similar audio processing software, Hance’s tiny, energy-efficient models can process audio on devices of all sizes in real time. That makes it great for the radios Riedel sells to F1 or FIFA, and also attractive to law enforcement and defense applications, CEO Joote Hika told TechCrunch in an interview.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Hika sees opportunity for Hance’s audio processing to go in many more directions, too, now that it has lined up Intel as a partner. Hance has been working with the technology giant to adopt its models to work on different versions of its chips, including its latest “neural processing units.” The startup is talking with other chipmakers, too, and an undisclosed smartphone maker, Hika said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Hika also said these professional partnerships will likely last at least a few years and that they’re non-exclusive. That’s good for the startup’s ability to scale, but he said Hance will have to keep developing at a rapid pace to stay ahead of the competition. The company has just brought on its first chief commercial officer, but Hika said he expects Hance to stay heavily focused on R&amp;amp;D and that the company will preference “AI-capable” workers to stay lean.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We know that we now have an advantage over our competitors, but we definitely have to keep that up, so we’re pushing fast,” he said&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;If you want to learn more about Hance — and dozens of other startups, hearing their pitches and listening to guest speakers on four different stages — join us at Disrupt, taking place October 27 to 29, in San Francisco. &lt;/em&gt;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Learn more about tickets and pricing here.&lt;/em&gt;&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025" class="wp-image-3048094" height="383" src="https://techcrunch.com/wp-content/uploads/2025/09/TC25_Disrupt_General_Article_No-Anniversary_Headers_1920x1080.png?w=680" width="680" /&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/hance-will-demo-its-kilobyte-size-ai-audio-processing-software-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 30 Sep 2025 16:22:28 +0000</pubDate></item><item><title>AI note-taking app Granola adds a repeatable prompts feature (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/ai-note-taking-app-granola-adds-a-repeatable-prompts-feature/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Granola-Recepies.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chatbot platforms like ChatGPT and Poe have allowed users to create repeated prompts in the form of GPTs and apps. Lately, browsers like Dia and Opera Neon have added a way for people to get repeated tasks done in the form of skills and cards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, meeting notetaker Granola is bringing its own spin with a feature called Recipes, which lets you create a prompt shortcut you can use again and again. You can invoke a recipe by using “/” in Granola chat and typing its name. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;You can create your own recipes by typing in a prompt and giving it context of either one meeting or having it work across meetings. The company also has a guide to help you form effective recipes. You can share them with other users who might want to execute similar prompts, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Granola also has a library of preexisting recipes that you can use. The company divides recipes into before, during, and after meeting categories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Granola co-founder Chris Pedregal said that at the moment, the app and meetings are the context for these repeatable prompts. However, the startup will work on letting you connect to other services to expand the context and feed more data to recipes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we talked to users, we heard from them that they often copy their transcripts to ChatGPT or Claude, and ask questions to the chatbot. With this new feature, they can get the full context of Granola and execute bespoke prompts,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Besides Granola, other meeting notetakers such as Fireflies, Fathom, and Circleback also offer templates and prompt-based insight generation. However, most of them work after the meeting has concluded.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/09/Granola-Recepies.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Chatbot platforms like ChatGPT and Poe have allowed users to create repeated prompts in the form of GPTs and apps. Lately, browsers like Dia and Opera Neon have added a way for people to get repeated tasks done in the form of skills and cards.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now, meeting notetaker Granola is bringing its own spin with a feature called Recipes, which lets you create a prompt shortcut you can use again and again. You can invoke a recipe by using “/” in Granola chat and typing its name. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;You can create your own recipes by typing in a prompt and giving it context of either one meeting or having it work across meetings. The company also has a guide to help you form effective recipes. You can share them with other users who might want to execute similar prompts, too.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Granola also has a library of preexisting recipes that you can use. The company divides recipes into before, during, and after meeting categories.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Granola co-founder Chris Pedregal said that at the moment, the app and meetings are the context for these repeatable prompts. However, the startup will work on letting you connect to other services to expand the context and feed more data to recipes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we talked to users, we heard from them that they often copy their transcripts to ChatGPT or Claude, and ask questions to the chatbot. With this new feature, they can get the full context of Granola and execute bespoke prompts,” he told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Besides Granola, other meeting notetakers such as Fireflies, Fathom, and Circleback also offer templates and prompt-based insight generation. However, most of them work after the meeting has concluded.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/ai-note-taking-app-granola-adds-a-repeatable-prompts-feature/</guid><pubDate>Tue, 30 Sep 2025 16:45:56 +0000</pubDate></item><item><title>ChatGPT: Everything you need to know about the AI-powered chatbot (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/chatgpt-everything-to-know-about-the-ai-chatbot/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2191707579.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="september2025"&gt;September 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-rolls-out-parental-controls-following-teen-suicide-case"&gt;ChatGPT rolls out parental controls following teen suicide case&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is reportedly adding parental controls to ChatGPT on web and mobile, letting parents and teens link accounts to enable safeguards like limiting sensitive content, setting quiet hours, and disabling features such as voice mode or image generation. The move comes amid growing regulatory scrutiny and a lawsuit over the chatbot’s alleged role in a teen’s suicide.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-introduces-chatgpt-pulse-for-personalized-morning-briefs"&gt;OpenAI introduces ChatGPT Pulse for personalized morning briefs&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled Pulse, a new ChatGPT feature that delivers personalized morning briefings overnight, encouraging users to start their day with the app. The tool reflects a shift toward making ChatGPT more proactive and asynchronous, positioning it as a true assistant rather than just a chatbot. OpenAI’s new Applications CEO, Fidji Simo, called Pulse the first step toward bringing high-level personal support to everyone, starting with Pro users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-moves-into-ai-powered-shopping-challenging-tech-giants"&gt;OpenAI moves into AI-Powered shopping, challenging tech giants&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched Instant Checkout in ChatGPT, letting U.S. users purchase products directly from Etsy and, soon, over a million Shopify merchants without leaving the conversation. Shoppers can browse items, read reviews, and complete purchases with a single tap using Apple Pay, Google Pay, Stripe, or a credit card. The update marks a step toward reshaping online shopping by merging product discovery, recommendations, and payments in one place.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-brings-budget-friendly-chatgpt-go-to-indonesian-users"&gt;OpenAI brings budget-friendly ChatGPT Go to Indonesian users&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out its budget-friendly ChatGPT Go plan in Indonesia for Rp 75,000 ($4.50) per month, following its initial launch in India. The mid-tier plan, which offers higher usage limits, image generation, file uploads, and better memory compared to the free version, enters the market in direct competition with Google’s new AI Plus plan in Indonesia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tightens-chatgpt-rules-for-teens-amid-safety-concerns"&gt;OpenAI tightens ChatGPT rules for teens amid safety concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman announced new policies for under-18 users of ChatGPT, tightening safeguards around sensitive conversations. The company says it will block flirtatious exchanges with minors and add stronger protections around discussions of suicide, even escalating severe cases to parents or authorities. The move comes as OpenAI faces a wrongful death lawsuit tied to alleged chatbot interactions, underscoring rising concerns about the mental health risks of AI companions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-rolls-out-gpt-5-codex-to-power-smarter-ai-coding"&gt;OpenAI rolls out GPT-5-Codex to power smarter AI coding&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out GPT-5-Codex, a new version of its AI coding agent that can spend anywhere from a few seconds to seven hours tackling a task, depending on complexity. The company says this dynamic approach helps the model outperform GPT-5 on key coding benchmarks, including bug fixes and large-scale refactoring. The update comes as OpenAI looks to keep Codex competitive in a fast-growing market that now includes rivals like Claude Code, Cursor, and GitHub Copilot.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reshuffles-team-behind-chatgpt-s-personality"&gt;OpenAI reshuffles team behind ChatGPT’s personality&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is shaking up its Model Behavior team, the small but influential group that helps shape how its AI interacts with people. The roughly 14-person team is being folded into the larger Post Training group, now reporting to lead researcher Max Schwarzer. Meanwhile, founding leader Joanne Jang is spinning up a new unit called OAI Labs, focused on prototyping fresh ways for people to collaborate with AI.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="august2025"&gt;August 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-strengthen-chatgpt-safeguards-after-teen-suicide-lawsuit"&gt;&lt;strong&gt;OpenAI to strengthen ChatGPT safeguards after teen suicide lawsuit&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI, facing a lawsuit from the parents of a 16-year-old who died by suicide, said in its blog that it has implemented new safeguards for ChatGPT, including stronger detection of mental health risks and parental control features. The AI company said the updates aim to provide tighter protections around suicide-related conversations and give parents more oversight of their children’s use.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-xai-claims-apple-s-app-store-practices-give-openai-an-unfair-advantage"&gt;&lt;strong&gt;xAI claims Apple’s App Store practices give OpenAI an unfair advantage&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk’s AI startup, xAI, filed a federal lawsuit in Texas against Apple and OpenAI, alleging that the two companies colluded to lock up key markets and shut out rivals.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-targets-india-with-cheaper-monthly-chatgpt-subscription"&gt;&lt;strong&gt;OpenAI targets India with cheaper monthly ChatGPT subscription&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI introduced its most affordable subscription plan, ChatGPT Go, in India, priced at 399 rupees per month (approximately $4.57). This move aims to expand OpenAI’s presence in its second-largest market, offering enhanced access to the latest GPT-5 model and additional features.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-mobile-app-hits-2b-in-revenue-2-91-earned-per-install"&gt;&lt;strong&gt;ChatGPT mobile app hits $2B in revenue, $2.91 earned per install&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Since its May 2023 launch, ChatGPT’s mobile app has amassed $2 billion in global consumer spending, dwarfing competitors like Claude, Copilot, and Grok by roughly 30 times, according to Appfigures. This year alone, the app has generated $1.35 billion, a 673% increase from the same period in 2024, averaging nearly $193 million per month, or 53 times more than its nearest rival, Grok.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-keeps-multiple-gpt-models-despite-gpt-5-launch"&gt;&lt;strong&gt;OpenAI keeps multiple GPT models despite GPT-5 launch&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Despite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-addresses-gpt-5-glitches-and-chart-crime-during-reddit-ama"&gt;&lt;strong&gt;Sam Altman addresses GPT-5 glitches and “chart crime” during Reddit AMA&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-5-a-smarter-task-ready-chatgpt"&gt;&lt;strong&gt;OpenAI unveils GPT-5, a smarter, task-ready ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released GPT-5, a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-enterprise-to-federal-agencies-for-just-1"&gt;&lt;strong&gt;OpenAI offers ChatGPT Enterprise to federal agencies for just $1&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-returns-to-open-source-with-new-ai-models"&gt;&lt;strong&gt;OpenAI returns to open source with new AI models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-nears-700m-weekly-users-quadruples-growth-in-a-year"&gt;&lt;strong&gt;ChatGPT nears 700M weekly users, quadruples growth in a year&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X, noting it has quadrupled in size over the past year.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;This week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and…&lt;/p&gt;— Nick Turley (@nickaturley) August 4, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="july2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-has-study-mode"&gt;ChatGPT now has study mode&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-altman-warns-that-chatgpt-therapy-isn-t-confidential"&gt;Altman warns that ChatGPT therapy isn’t confidential&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-hits-2-5b-prompts-daily"&gt;ChatGPT hits 2.5B prompts daily&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-general-purpose-agent-in-chatgpt"&gt;OpenAI launches a general-purpose agent in ChatGPT&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called “study together”&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2191707579.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;ChatGPT, OpenAI’s text-generating AI chatbot, has taken the world by storm since its launch in November 2022. What started as a tool to supercharge productivity through writing essays and code with short text prompts has evolved into a behemoth with 300 million weekly active users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;2024 was a big year for OpenAI, from its partnership with Apple for its generative AI offering, Apple Intelligence, the release of GPT-4o with voice capabilities, and the highly-anticipated launch of its text-to-video model Sora.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;OpenAI also faced its share of internal drama, including the notable exits of high-level execs like co-founder and longtime chief scientist Ilya Sutskever and CTO Mira Murati. OpenAI has also been hit with lawsuits from Alden Global Capital-owned newspapers alleging copyright infringement, as well as an injunction from Elon Musk to halt OpenAI’s transition to a for-profit. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In 2025, OpenAI is battling the perception that it’s ceding ground in the AI race to Chinese rivals like DeepSeek. The company has been trying to shore up its relationship with Washington as it simultaneously pursues an ambitious data center project, and as it reportedly lays the groundwork for one of the largest funding rounds in history.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Below, you’ll find a timeline of ChatGPT product updates and releases, starting with the latest, which we’ve been updating throughout the year. If you have any other questions, check out our ChatGPT FAQ here.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see a list of 2024 updates, go here.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-the-most-recent-chatgpt-updates"&gt;Timeline of the most recent ChatGPT updates&lt;/h2&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h3 class="wp-block-heading" id="september2025"&gt;September 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-rolls-out-parental-controls-following-teen-suicide-case"&gt;ChatGPT rolls out parental controls following teen suicide case&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is reportedly adding parental controls to ChatGPT on web and mobile, letting parents and teens link accounts to enable safeguards like limiting sensitive content, setting quiet hours, and disabling features such as voice mode or image generation. The move comes amid growing regulatory scrutiny and a lawsuit over the chatbot’s alleged role in a teen’s suicide.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-introduces-chatgpt-pulse-for-personalized-morning-briefs"&gt;OpenAI introduces ChatGPT Pulse for personalized morning briefs&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled Pulse, a new ChatGPT feature that delivers personalized morning briefings overnight, encouraging users to start their day with the app. The tool reflects a shift toward making ChatGPT more proactive and asynchronous, positioning it as a true assistant rather than just a chatbot. OpenAI’s new Applications CEO, Fidji Simo, called Pulse the first step toward bringing high-level personal support to everyone, starting with Pro users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-moves-into-ai-powered-shopping-challenging-tech-giants"&gt;OpenAI moves into AI-Powered shopping, challenging tech giants&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched Instant Checkout in ChatGPT, letting U.S. users purchase products directly from Etsy and, soon, over a million Shopify merchants without leaving the conversation. Shoppers can browse items, read reviews, and complete purchases with a single tap using Apple Pay, Google Pay, Stripe, or a credit card. The update marks a step toward reshaping online shopping by merging product discovery, recommendations, and payments in one place.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-brings-budget-friendly-chatgpt-go-to-indonesian-users"&gt;OpenAI brings budget-friendly ChatGPT Go to Indonesian users&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out its budget-friendly ChatGPT Go plan in Indonesia for Rp 75,000 ($4.50) per month, following its initial launch in India. The mid-tier plan, which offers higher usage limits, image generation, file uploads, and better memory compared to the free version, enters the market in direct competition with Google’s new AI Plus plan in Indonesia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tightens-chatgpt-rules-for-teens-amid-safety-concerns"&gt;OpenAI tightens ChatGPT rules for teens amid safety concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman announced new policies for under-18 users of ChatGPT, tightening safeguards around sensitive conversations. The company says it will block flirtatious exchanges with minors and add stronger protections around discussions of suicide, even escalating severe cases to parents or authorities. The move comes as OpenAI faces a wrongful death lawsuit tied to alleged chatbot interactions, underscoring rising concerns about the mental health risks of AI companions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-rolls-out-gpt-5-codex-to-power-smarter-ai-coding"&gt;OpenAI rolls out GPT-5-Codex to power smarter AI coding&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out GPT-5-Codex, a new version of its AI coding agent that can spend anywhere from a few seconds to seven hours tackling a task, depending on complexity. The company says this dynamic approach helps the model outperform GPT-5 on key coding benchmarks, including bug fixes and large-scale refactoring. The update comes as OpenAI looks to keep Codex competitive in a fast-growing market that now includes rivals like Claude Code, Cursor, and GitHub Copilot.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reshuffles-team-behind-chatgpt-s-personality"&gt;OpenAI reshuffles team behind ChatGPT’s personality&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is shaking up its Model Behavior team, the small but influential group that helps shape how its AI interacts with people. The roughly 14-person team is being folded into the larger Post Training group, now reporting to lead researcher Max Schwarzer. Meanwhile, founding leader Joanne Jang is spinning up a new unit called OAI Labs, focused on prototyping fresh ways for people to collaborate with AI.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="august2025"&gt;August 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-strengthen-chatgpt-safeguards-after-teen-suicide-lawsuit"&gt;&lt;strong&gt;OpenAI to strengthen ChatGPT safeguards after teen suicide lawsuit&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI, facing a lawsuit from the parents of a 16-year-old who died by suicide, said in its blog that it has implemented new safeguards for ChatGPT, including stronger detection of mental health risks and parental control features. The AI company said the updates aim to provide tighter protections around suicide-related conversations and give parents more oversight of their children’s use.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-xai-claims-apple-s-app-store-practices-give-openai-an-unfair-advantage"&gt;&lt;strong&gt;xAI claims Apple’s App Store practices give OpenAI an unfair advantage&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Elon Musk’s AI startup, xAI, filed a federal lawsuit in Texas against Apple and OpenAI, alleging that the two companies colluded to lock up key markets and shut out rivals.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-targets-india-with-cheaper-monthly-chatgpt-subscription"&gt;&lt;strong&gt;OpenAI targets India with cheaper monthly ChatGPT subscription&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI introduced its most affordable subscription plan, ChatGPT Go, in India, priced at 399 rupees per month (approximately $4.57). This move aims to expand OpenAI’s presence in its second-largest market, offering enhanced access to the latest GPT-5 model and additional features.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-mobile-app-hits-2b-in-revenue-2-91-earned-per-install"&gt;&lt;strong&gt;ChatGPT mobile app hits $2B in revenue, $2.91 earned per install&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Since its May 2023 launch, ChatGPT’s mobile app has amassed $2 billion in global consumer spending, dwarfing competitors like Claude, Copilot, and Grok by roughly 30 times, according to Appfigures. This year alone, the app has generated $1.35 billion, a 673% increase from the same period in 2024, averaging nearly $193 million per month, or 53 times more than its nearest rival, Grok.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-keeps-multiple-gpt-models-despite-gpt-5-launch"&gt;&lt;strong&gt;OpenAI keeps multiple GPT models despite GPT-5 launch&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Despite unveiling GPT-5 as a “one-size-fits-all” AI, OpenAI is still offering several legacy AI options, including GPT-4o, GPT-4.1, and o3. Users can choose between new “Auto,” “Fast,” and “Thinking” modes for GPT-5, and paid subscribers regain access to legacy models like GPT-4o and GPT-4.1.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Updates to ChatGPT:&lt;/p&gt;&lt;p&gt;You can now choose between “Auto”, “Fast”, and “Thinking” for GPT-5. Most users will want Auto, but the additional control will be useful for some people.&lt;/p&gt;&lt;p&gt;Rate limits are now 3,000 messages/week with GPT-5 Thinking, and then extra capacity on GPT-5 Thinking…&lt;/p&gt;— Sam Altman (@sama) August 13, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-addresses-gpt-5-glitches-and-chart-crime-during-reddit-ama"&gt;&lt;strong&gt;Sam Altman addresses GPT-5 glitches and “chart crime” during Reddit AMA&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman told Reddit users that GPT-5’s “dumber” behavior at launch was due to a router issue and promised fixes, double rate limits for Plus users, and transparency on which model is answering, while also shrugging off the infamous “chart crime” from the live presentation.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-5-a-smarter-task-ready-chatgpt"&gt;&lt;strong&gt;OpenAI unveils GPT-5, a smarter, task-ready ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released GPT-5, a next-gen AI that’s not just smarter but more useful — able to handle tasks like coding apps, managing calendars, and creating research briefs — while automatically figuring out the fastest or most thoughtful way to answer your questions. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-enterprise-to-federal-agencies-for-just-1"&gt;&lt;strong&gt;OpenAI offers ChatGPT Enterprise to federal agencies for just $1&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is making a major push into federal government workflows, offering ChatGPT Enterprise to agencies for just $1 for the next year. The move comes after the U.S. General Services Administration (GSA) added OpenAI, Google, and Anthropic to its approved AI vendor list, allowing agencies to access these tools through preset contracts without negotiating pricing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-returns-to-open-source-with-new-ai-models"&gt;&lt;strong&gt;OpenAI returns to open source with new AI models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled its first open source language models since GPT-2, introducing two new open-weight AI releases: gpt-oss-120b, a high-performance model capable of running on a single Nvidia GPU, and gpt-oss-20b, a lighter model optimized for laptop use. The move comes amid growing competition in the global AI market and a push for more open technology in the U.S. and abroad.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-nears-700m-weekly-users-quadruples-growth-in-a-year"&gt;&lt;strong&gt;ChatGPT nears 700M weekly users, quadruples growth in a year&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s rapid growth is accelerating. OpenAI said the chatbot was on track to hit 700 million weekly active users in the first week of August, up from 500 million at the end of March. Nick Turley, OpenAI’s VP and head of the ChatGPT app, highlighted the app’s growth on X, noting it has quadrupled in size over the past year.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;This week, ChatGPT is on track to reach 700M weekly active users — up from 500M at the end of March and 4× since last year. Every day, people and teams are learning, creating, and solving harder problems. Big week ahead. Grateful to the team for making ChatGPT more useful and…&lt;/p&gt;— Nick Turley (@nickaturley) August 4, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="july2025"&gt;July 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-has-study-mode"&gt;ChatGPT now has study mode&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI unveiled Study Mode, a new ChatGPT feature designed to promote critical thinking by prompting students to engage with material rather than simply receive answers. The tool is now rolling out to Free, Plus, Pro, and Team users, with availability for Edu subscribers expected in the coming weeks.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-altman-warns-that-chatgpt-therapy-isn-t-confidential"&gt;Altman warns that ChatGPT therapy isn’t confidential&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT users should be cautious when seeking emotional support from AI, as the AI industry lacks safeguards for sensitive conversations, OpenAI CEO Sam Altman said on a recent episode of This Past Weekend w/ Theo Von. Unlike human therapists, AI tools aren’t bound by doctor-patient confidentiality, he noted.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-hits-2-5b-prompts-daily"&gt;ChatGPT hits 2.5B prompts daily&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT now receives 2.5 billion prompts daily from users worldwide, including roughly 330 million from the U.S. That’s more than double the volume reported by CEO Sam Altman just eight months ago, highlighting the chatbot’s explosive growth.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-general-purpose-agent-in-chatgpt"&gt;OpenAI launches a general-purpose agent in ChatGPT&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced ChatGPT Agent, which completes a wide variety of computer-based tasks on behalf of users and combines several capabilities like Operator and Deep Research, according to the company. OpenAI says the agent can automatically navigate a user’s calendar, draft editable presentations and slideshows, run code, shop online, and handle complex workflows from end to end, all within a secure virtual environment.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-study-warns-of-major-risks-with-ai-therapy-chatbots"&gt;Study warns of major risks with AI therapy chatbots&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers at Stanford University have observed that therapy chatbots powered by large language models can sometimes stigmatize people with mental health conditions or respond in ways that are inappropriate or could be harmful. While chatbots are “being used as companions, confidants, and therapists,” the study found “significant risks.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-delays-releasing-its-open-model-again"&gt;OpenAI delays releasing its open model again&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;CEO Sam Altman said that the company is delaying the release of its open model, which had already been postponed by a month earlier this summer. The ChatGPT maker, which initially planned to release the model around mid-July, has indefinitely postponed its launch to conduct additional safety testing.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;we planned to launch our open-weight model next week.&lt;/p&gt;&lt;p&gt;we are delaying it; we need time to run additional safety tests and review high-risk areas. we are not yet sure how long it will take us.&lt;/p&gt;&lt;p&gt;while we trust the community will build great things with this model, once weights are…&lt;/p&gt;— Sam Altman (@sama) July 12, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-reportedly-releasing-an-ai-browser-in-the-coming-weeks"&gt;&lt;strong&gt;OpenAI is reportedly releasing an AI browser in the coming weeks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to release an AI-powered web browser to challenge Alphabet’s Google Chrome. It will keep some user interactions within ChatGPT, rather than directing people to external websites.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-is-testing-a-mysterious-new-feature-called-study-together"&gt;ChatGPT is testing a mysterious new feature called “study together”&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Some ChatGPT users have noticed a new feature called “Study Together” appearing in their list of available tools. This is the chatbot’s approach to becoming a more effective educational tool, rather than simply providing answers to prompts. Some people also wonder whether there will be a feature that allows multiple users to join the chat, similar to a study group.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-referrals-from-chatgpt-to-news-sites-are-rising-but-not-enough-to-offset-search-declines"&gt;Referrals from ChatGPT to news sites are rising but not enough to offset search declines&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Referrals from ChatGPT to news publishers are increasing. But this rise is insufficient to offset the decline in clicks as more users now obtain their news directly from AI or AI-powered search results, according to a report by digital market intelligence company Similarweb. Since Google launched its AI Overviews in May 2024, the percentage of news searches that don’t lead to clicks on news websites has increased from 56% to nearly 69% by May 2025.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="june2025"&gt;June 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-uses-google-s-ai-chips-to-power-its-products"&gt;&lt;strong&gt;OpenAI uses Google’s AI chips to power its products&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has started using Google’s AI chips to power ChatGPT and other products, as reported by Reuters. The ChatGPT maker is one of the biggest buyers of Nvidia’s GPUs, using the AI chips to train models, and this is the first time that OpenAI is using &lt;em&gt;non&lt;/em&gt;-Nvidia chips in an important way.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-a-new-mit-study-suggests-that-chatgpt-might-be-harming-critical-thinking-skills"&gt;&lt;strong&gt;A new MIT study suggests that ChatGPT might be harming critical thinking skills&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Researchers from MIT’s Media Lab monitored the brain activity of writers in 32 regions. They found that ChatGPT users showed minimal brain engagement and consistently fell short in neural, linguistic, and behavioral aspects. To conduct the test, the lab split 54 participants from the Boston area into three groups, each consisting of individuals ages 18 to 39. The participants were asked to write multiple SAT essays using tools such as OpenAI’s ChatGPT, the Google search engine, or without any tools.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-was-downloaded-30-million-times-last-month"&gt;ChatGPT was downloaded 30 million times last month&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The ChatGPT app for iOS was downloaded 29.6 million times in the last 28 days, while TikTok, Facebook, Instagram, and X were downloaded a total of 32.9 million times during the same period, representing a difference of about 10.6%, according to ZDNET report citing Similarweb’s X post.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-the-energy-needed-for-an-average-chatgpt-query-can-power-a-lightbulb-for-a-couple-of-minutes"&gt;The energy needed for an average ChatGPT query can power a lightbulb for a couple of minutes&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman said that the average ChatGPT query uses about one-fifteenth of a teaspoon of water, equivalent to 0.000083 gallons of water, or the energy required to power a lightbulb for a few minutes, per Business Insider. In addition to that, the chatbot requires 0.34 watt-hours of electricity to operate.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o3-pro-an-upgraded-version-of-its-o3-ai-reasoning-model"&gt;&lt;strong&gt;OpenAI has launched o3-pro, an upgraded version of its o3 AI reasoning model&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has unveiled o3-pro, an enhanced version of its o3, a reasoning model that the chatGPT maker launched earlier this year. O3-pro is available for ChatGPT and Team users and in the API, while Enterprise and Edu users will get access in the third week of June.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;OpenAI o3-pro is available in the model picker for Pro and Team users starting today, replacing OpenAI o1-pro.&lt;/p&gt;&lt;p&gt;Enterprise and Edu users will get access the week after.&lt;/p&gt;&lt;p&gt;As o3-pro uses the same underlying model as o3, full safety details can be found in the o3 system card.…&lt;/p&gt;— OpenAI (@OpenAI) June 10, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-conversational-voice-mode-has-been-upgraded"&gt;ChatGPT’s conversational voice mode has been upgraded&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI upgraded ChatGPT’s conversational voice mood for all paid users across different markets and platforms. The startup has launched an update to Advanced Voice that enables users to converse with ChatGPT out loud in a more natural and fluid sound. The feature also helps users translate languages more easily, the comapny said.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-added-new-features-like-meeting-recording-and-connectors-for-google-drive-box-and-more"&gt;&lt;strong&gt;ChatGPT has added new features like meeting recording and connectors for Google Drive, Box, and more&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI’s ChatGPT now offers new funtions for business users, including integrations with various cloud services, meeting recordings, and MCP connection support for connecting to tools for in-depth research. The feature enables ChatGPT to retrieve information across users’ own services to answer their questions. For instance, an analyst could use the company’s slide deck and documents to develop an investment thesis.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-may-2025"&gt;May 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cfo-says-hardware-will-drive-chatgpt-s-growth"&gt;OpenAI CFO says hardware will drive ChatGPT’s growth&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to purchase Jony Ive’s devices startup io for $6.4 billion. Sarah Friar, CFO of OpenAI, thinks that the hardware will significantly enhance ChatGPT and broaden OpenAI’s reach to a larger audience in the future.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-chatgpt-unveils-its-ai-coding-agent-codex"&gt;&lt;strong&gt;OpenAI’s ChatGPT unveils its AI coding agent, Codex&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced its AI coding agent, Codex, powered by codex-1, a version of its o3 AI reasoning model designed for software engineering tasks. OpenAI says codex-1 generates more precise and “cleaner” code than o3. The coding agent may take anywhere from one to 30 minutes to complete tasks such as writing simple features, fixing bugs, answering questions about your codebase, and running tests.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-sam-altman-aims-to-make-chatgpt-more-personalized-by-tracking-every-aspect-of-a-person-s-life"&gt;&lt;strong&gt;Sam Altman aims to make ChatGPT more personalized by tracking every aspect of a person’s life&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Sam Altman, the CEO of OpenAI, said during a recent AI event hosted by VC firm Sequoia that he wants ChatGPT to record and remember every detail of a person’s life when one attendee asked about how ChatGPT can become more personalized.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-releases-its-gpt-4-1-and-gpt-4-1-mini-ai-models-in-chatgpt"&gt;&lt;strong&gt;OpenAI releases its GPT-4.1 and GPT-4.1 mini AI models in ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said in a post on X that it has launched its GPT-4.1 and GPT4.1 mini AI models in ChagGPT.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
 &lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;By popular request, GPT-4.1 will be available directly in ChatGPT starting today.&lt;/p&gt;&lt;p&gt;GPT-4.1 is a specialized model that excels at coding tasks &amp;amp; instruction following. Because it’s faster, it’s a great alternative to OpenAI o3 &amp;amp; o4-mini for everyday coding needs.&lt;/p&gt;— OpenAI (@OpenAI) May 14, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-deep-research-now-connects-with-github-in-beta-to-answer-code-related-questions"&gt;&lt;strong&gt;ChatGPT deep research now connects with GitHub (in beta) to answer code-related questions&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new feature for ChatGPT deep research to analyze code repositories on GitHub. The ChatGPT deep research feature is in beta and lets developers connect with GitHub to ask questions about codebases and engineering documents. The connector will soon be available for ChatGPT Plus, Pro, and Team users, with support for Enterprise and Education coming shortly, per an OpenAI spokesperson.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-a-new-data-residency-program-in-asia"&gt;&lt;strong&gt;OpenAI launches a new data residency program in Asia&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;After introducing a data residency program in Europe in February, OpenAI has now launched a similar program in Asian countries including India, Japan, Singapore, and South Korea. The new program will be accessible to users of ChatGPT Enterprise, ChatGPT Edu, and API. It will help organizations in Asia meet their local data sovereignty requirements when using OpenAI’s products.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-to-introduce-a-program-to-grow-ai-infrastructure"&gt;&lt;strong&gt;OpenAI to introduce a program to grow AI infrastructure&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is unveiling a program called OpenAI for Countries, which aims to develop the necessary local infrastructure to serve international AI clients better. The AI startup will work with governments to assist with increasing data center capacity and customizing OpenAI’s products to meet specific language and local needs. OpenAI for Countries is part of efforts to support the company’s expansion of its AI data center Project Stargate to new locations outside the U.S., per Bloomberg.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-promises-to-make-changes-to-prevent-future-chatgpt-sycophancy"&gt;&lt;strong&gt;OpenAI promises to make changes to prevent future ChatGPT sycophancy&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has announced its plan to make changes to its procedures for updating the AI models that power ChatGPT, following an update that caused the platform to become overly sycophantic for many users.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-april-2025"&gt;April 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-clarifies-the-reason-chatgpt-became-overly-flattering-and-agreeable"&gt;&lt;strong&gt;OpenAI clarifies the reason ChatGPT became overly flattering and agreeable&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released a post on the recent sycophancy issues with the default AI model powering ChatGPT, GPT-4o, leading the company to revert an update to the model released last week. CEO Sam Altman acknowledged the issue on Sunday and confirmed two days later that the GPT-4o update was being rolled back. OpenAI is working on “additional fixes” to the model’s personality. Over the weekend, users on social media criticized the new model for making ChatGPT too validating and agreeable. It became a popular meme fast.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-to-fix-a-bug-that-let-minors-engage-in-inappropriate-conversations"&gt;&lt;strong&gt;OpenAI is working to fix a “bug” that let minors engage in inappropriate conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;An issue within OpenAI’s ChatGPT enabled the chatbot to create graphic erotic content for accounts registered by users under the age of 18, as demonstrated by TechCrunch’s testing, a fact later confirmed by OpenAI. “Protecting younger users is a top priority, and our Model Spec, which guides model behavior, clearly restricts sensitive content like erotica to narrow contexts such as scientific, historical, or news reporting,” a spokesperson told TechCrunch via email. “In this case, a bug allowed responses outside those guidelines, and we are actively deploying a fix to limit these generations.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-helps-users-by-giving-recommendations-showing-images-and-reviewing-products-for-online-shopping"&gt;&lt;strong&gt;ChatGPT helps users by giving recommendations, showing images, and reviewing products for online shopping&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added a few features to its ChatGPT search, its web search tool in ChatGPT, to give users an improved online shopping experience. The company says people can ask super-specific questions using natural language and receive customized results. The chatbot provides recommendations, images, and reviews of products in various categories such as fashion, beauty, home goods, and electronics.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-wants-its-ai-model-to-access-cloud-models-for-assistance"&gt;OpenAI wants its AI model to access cloud models for assistance&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI leaders have been talking about allowing the open model to link up with OpenAI’s cloud-hosted models to improve its ability to respond to intricate questions, two sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-aims-to-make-its-new-open-ai-model-the-best-on-the-market"&gt;&lt;strong&gt;OpenAI aims to make its new “open” AI model the best on the market&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is preparing to launch an AI system that will be openly accessible, allowing users to download it for free without any API restrictions. Aidan Clark, OpenAI’s VP of research, is spearheading the development of the open model, which is in the very early stages, sources familiar with the situation told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-gpt-4-1-may-be-less-aligned-than-earlier-models"&gt;&lt;strong&gt;OpenAI’s GPT-4.1 may be less aligned than earlier models&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI released a new AI model called GPT-4.1 in mid-April. However, multiple independent tests indicate that the model is less reliable than previous OpenAI releases. The company&amp;nbsp;skipped that step — sending safety cards&amp;nbsp;for GPT-4.1 — claiming in a statement to TechCrunch that “GPT-4.1 is not a frontier model, so there won’t be a separate system card released for it.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-ai-model-scored-lower-than-expected-on-a-benchmark"&gt;&lt;strong&gt;OpenAI’s o3 AI model scored lower than expected on a benchmark&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Questions have been raised regarding OpenAI’s transparency and procedures for testing models after a difference in benchmark outcomes was detected by first- and third-party benchmark results for the o3 AI model. OpenAI introduced o3 in December, stating that the model could solve approximately 25% of questions on FrontierMath, a difficult math problem set. Epoch AI, the research institute behind FrontierMath, discovered that o3 achieved a score of approximately 10%, which was significantly lower than OpenAI’s top-reported score.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-flex-processing-for-cheaper-slower-ai-tasks"&gt;&lt;strong&gt;OpenAI unveils Flex processing for cheaper, slower AI tasks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched a new API feature called Flex processing that allows users to use AI models at a lower cost but with slower response times and occasional resource unavailability. Flex processing is available in beta on the o3 and o4-mini reasoning models for non-production tasks like model evaluations, data enrichment, and asynchronous workloads.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-latest-ai-models-now-have-a-safeguard-against-biorisks"&gt;&lt;strong&gt;OpenAI’s latest AI models now have a safeguard against biorisks&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has rolled out a new system to monitor its AI reasoning models, o3 and o4 mini, for biological and chemical threats. The system is designed to prevent models from giving advice that could potentially lead to harmful attacks, as stated in OpenAI’s safety report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-its-latest-reasoning-models-o3-and-o4-mini"&gt;&lt;strong&gt;OpenAI launches its latest reasoning models, o3 and o4-mini&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has released two new reasoning models, o3 and o4 mini, just two days after launching GPT-4.1. The company claims o3 is the most advanced reasoning model it has developed, while o4-mini is said to provide a balance of price, speed, and performance. The new models stand out from previous reasoning models because they can use ChatGPT features like web browsing, coding, and image processing and generation. But they hallucinate more than several of OpenAI’s previous models.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-added-a-new-section-to-chatgpt-to-offer-easier-access-to-ai-generated-images-for-all-user-tiers"&gt;&lt;strong&gt;OpenAI has added a new section to ChatGPT to offer easier access to AI-generated images for all user tiers&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Open AI introduced a new section called “library” to make it easier for users to create images on mobile and web platforms, per the company’s X post.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-adjust-its-safeguards-if-rivals-release-high-risk-ai"&gt;&lt;strong&gt;OpenAI could “adjust” its safeguards if rivals release “high-risk” AI&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI said on Tuesday that it might revise its safety standards if “another frontier AI developer releases a high-risk system without comparable safeguards.” The move shows how commercial AI developers face more pressure to rapidly implement models due to the increased competition.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-building-its-own-social-media-network"&gt;&lt;strong&gt;OpenAI is building its own social media network&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is currently in the early stages of developing its own social media platform to compete with Elon Musk’s X and Mark Zuckerberg’s Instagram and Threads, according to The Verge. It is unclear whether OpenAI intends to launch the social network as a standalone application or incorporate it into ChatGPT.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-remove-its-largest-ai-model-gpt-4-5-from-the-api-in-july"&gt;OpenAI will remove its largest AI model, GPT-4.5, from the API, in July&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI will discontinue its largest AI model, GPT-4.5, from its API even though it was just launched in late February. GPT-4.5 will be available in a research preview for paying customers. Developers can use GPT-4.5 through OpenAI’s API until July 14; then, they will need to switch to GPT-4.1, which was released on April 14.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-gpt-4-1-ai-models-that-focus-on-coding-capabilities"&gt;OpenAI unveils GPT-4.1 AI models that focus on coding capabilities&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has launched three members of the GPT-4.1 model — GPT-4.1, GPT-4.1 mini, and GPT-4.1 nano — with a specific focus on coding capabilities. It’s accessible via the OpenAI API but not ChatGPT. In the competition to develop advanced programming models, GPT-4.1 will rival AI models such as Google’s Gemini 2.5 Pro, Anthropic’s Claude 3.7 Sonnet, and DeepSeek’s upgraded V3.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-will-discontinue-chatgpt-s-gpt-4-at-the-end-of-april"&gt;&lt;strong&gt;OpenAI will discontinue ChatGPT’s GPT-4 at the end of April&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI plans to sunset GPT-4, an AI model introduced more than two years ago, and replace it with GPT-4o, the current default model, per changelog. It will take effect on April 30. GPT-4 will remain available via OpenAI’s API.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-could-release-gpt-4-1-soon"&gt;OpenAI could release GPT-4.1 soon&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI may launch several new AI models, including GPT-4.1, soon, The Verge reported, citing anonymous sources. GPT-4.1 would be an update of OpenAI’s GPT-4o, which was released last year. On the list of upcoming models are GPT-4.1 and smaller versions like GPT-4.1 mini and nano, per the report.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-updated-chatgpt-to-use-information-from-your-previous-conversations"&gt;&lt;strong&gt;OpenAI has updated ChatGPT to use information from your previous conversations&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI started updating ChatGPT to enable the chatbot to remember previous conversations with a user and customize its responses based on that context. This feature is rolling out to ChatGPT Pro and Plus users first, excluding those in the U.K., EU, Iceland, Liechtenstein, Norway, and Switzerland.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-is-working-on-watermarks-for-images-made-with-chatgpt"&gt;&lt;strong&gt;OpenAI is working on watermarks for images made with ChatGPT&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;It looks like OpenAI is working on a watermarking feature for images generated using GPT-4o. AI researcher Tibor Blaho spotted a new “ImageGen” watermark feature in the new beta of ChatGPT’s Android app. Blaho also found mentions of other tools: “Structured Thoughts,” “Reasoning Recap,” “CoT Search Tool,” and “l1239dk1.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-offers-chatgpt-plus-for-free-to-u-s-canadian-college-students"&gt;OpenAI offers ChatGPT Plus for free to U.S., Canadian college students&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is offering its $20-per-month ChatGPT Plus subscription tier for free to all college students in the U.S. and Canada through the end of May. The offer will let millions of students use OpenAI’s premium service, which offers access to the company’s GPT-4o model, image generation, voice interaction, and research tools that are not available in the free version.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-users-have-generated-over-700m-images-nbsp-so-far"&gt;ChatGPT users have generated over 700M images&amp;nbsp;so far&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;More than 130 million users have created over 700 million images since ChatGPT got the upgraded image generator on March 25, according to COO of OpenAI Brad Lightcap. The image generator was made available  to all ChatGPT users on March 31, and went viral for being able to create Ghibli-style photos.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-o3-model-could-cost-more-to-run-than-initial-estimate"&gt;OpenAI’s o3 model could cost more to run than initial estimate&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The Arc Prize Foundation, which develops the AI benchmark tool ARC-AGI, has updated the estimated computing costs for OpenAI’s o3 “reasoning” model managed by ARC-AGI. The organization originally estimated that the best-performing configuration of o3 it tested, o3 high, would cost approximately $3,000 to address a single problem. The Foundation now thinks the cost could be much higher, possibly around $30,000 per task.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-ceo-says-capacity-issues-will-cause-product-delays"&gt;OpenAI CEO says capacity issues will cause product delays&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In a series of posts on X, OpenAI CEO Sam Altman said the company’s new image-generation tool’s popularity may cause product releases to be delayed. “We are getting things under control, but you should expect new releases from OpenAI to be delayed, stuff to break, and for service to sometimes be slow as we deal with capacity challenges,” he wrote. &lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-march-2025"&gt;March 2025&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-plans-to-release-a-new-open-ai-language-model"&gt;OpenAI plans to release a new ‘open’ AI language model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpeanAI intends to release its “first” open language model since GPT-2 “in the coming months.” The company plans to host developer events to gather feedback and eventually showcase prototypes of the model. The first developer event is to be held in San Francisco, with sessions to follow in Europe and Asia.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-removes-chatgpt-s-restrictions-on-image-generation"&gt;OpenAI removes ChatGPT’s restrictions on image generation&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI made a notable change to its content moderation policies after the success of its new image generator in ChatGPT, which went viral for being able to create Studio Ghibli-style images. The company has updated its policies to allow ChatGPT to generate images of public figures, hateful symbols, and racial features when requested. OpenAI had previously declined such prompts due to the potential controversy or harm they may cause. However, the company has now “evolved” its approach, as stated in a blog post published by Joanne Jang, the lead for OpenAI’s model behavior.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-adopts-anthropic-s-standard-for-linking-ai-models-with-data"&gt;OpenAI adopts Anthropic’s standard for linking AI models with data&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI wants to incorporate Anthropic’s Model Context Protocol (MCP) into all of its products, including the ChatGPT desktop app. MCP, an open-source standard, helps AI models generate more accurate and suitable responses to specific queries, and lets developers create bidirectional links between data sources and AI applications like chatbots. The protocol is currently available in the Agents SDK, and support for the ChatGPT desktop app and Responses API will be coming soon, OpenAI CEO Sam Altman said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-viral-studio-ghibli-style-images-could-raise-ai-copyright-concerns"&gt;OpenAI’s viral Studio Ghibli-style images could raise AI copyright concerns&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest update of the image generator on OpenAI’s ChatGPT has triggered a flood of AI-generated memes in the style of Studio Ghibli, the Japanese animation studio behind blockbuster films like “My Neighbor Totoro” and “Spirited Away.” The burgeoning mass of Ghibli-esque images have sparked concerns about whether OpenAI has violated copyright laws, especially since the company is already facing legal action for using source material without authorization. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-expects-revenue-to-triple-to-12-7-billion-this-year"&gt;OpenAI expects revenue to triple to $12.7 billion this year&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI expects its revenue to triple to $12.7 billion in 2025, fueled by the performance of its paid AI software, Bloomberg reported, citing an anonymous source. While the startup doesn’t expect to reach positive cash flow until 2029, it expects revenue to increase significantly in 2026 to surpass $29.4 billion, the report said. &lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-has-upgraded-its-image-generation-feature"&gt;ChatGPT has upgraded its image-generation feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI on Tuesday rolled out a major upgrade to ChatGPT’s image-generation capabilities: ChatGPT can now use the GPT-4o model to generate and edit images and photos directly. The feature went live earlier this week in ChatGPT and Sora, OpenAI’s AI video-generation tool, for subscribers of the company’s Pro plan, priced at $200 a month, and will be available soon to ChatGPT Plus subscribers and developers using the company’s API service. The company’s CEO Sam Altman said on Wednesday, however, that the release of the image generation feature to free users would be delayed due to higher demand than the company expected.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-announces-leadership-updates"&gt;OpenAI announces leadership updates&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Brad Lightcap, OpenAI’s chief operating officer, will lead the company’s global expansion and manage corporate partnerships as CEO Sam Altman shifts his focus to research and products, according to a blog post from OpenAI. Lightcap, who previously worked with Altman at Y Combinator, joined the Microsoft-backed startup in 2018. OpenAI also said Mark Chen would step into the expanded role of chief research officer, and Julia Villagra will take on the role of chief people officer.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-s-ai-voice-assistant-now-has-advanced-feature"&gt;OpenAI’s AI voice assistant now has advanced feature&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has updated its AI voice assistant with improved chatting capabilities, according to a video posted on Monday (March 24) to the company’s official media channels. The update enables real-time conversations, and the AI assistant is said to be more personable and interrupts users less often. Users on ChatGPT’s free tier can now access the new version of Advanced Voice Mode, while paying users will receive answers that are “more direct, engaging, concise, specific, and creative,” a spokesperson from OpenAI told TechCrunch.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-meta-in-talks-with-reliance-in-india"&gt;&lt;strong&gt;OpenAI, Meta in talks with Reliance in India&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI and Meta have separately engaged in discussions with Indian conglomerate Reliance Industries regarding potential collaborations to enhance their AI services in the country, per a report by The Information. One key topic being discussed is Reliance Jio distributing OpenAI’s ChatGPT. Reliance has proposed selling OpenAI’s models to businesses in India through an application programming interface (API) so they can incorporate AI into their operations. Meta also plans to bolster its presence in India by constructing a large 3GW data center in Jamnagar, Gujarat. OpenAI, Meta, and Reliance have not yet officially announced these plans.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-faces-privacy-complaint-in-europe-for-chatbot-s-defamatory-hallucinations"&gt;OpenAI faces privacy complaint in Europe for chatbot’s defamatory hallucinations&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noyb, a privacy rights advocacy group, is supporting an individual in Norway who was shocked to discover that ChatGPT was providing false information about him, stating that he had been found guilty of killing two of his children and trying to harm the third. “The GDPR is clear. Personal data has to be accurate,” said Joakim Söderberg, data protection lawyer at&amp;nbsp;Noyb, in a statement. “If it’s not, users have the right to have it changed to reflect the truth. Showing ChatGPT users a tiny disclaimer that the chatbot can make mistakes clearly isn’t enough. You can’t just spread false information and in the end add a small disclaimer saying that everything you said may just not be true.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-upgrades-its-transcription-and-voice-generating-ai-models"&gt;OpenAI upgrades its transcription and voice-generating AI models&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has added new transcription and voice-generating AI models to its APIs: a text-to-speech model, “gpt-4o-mini-tts,” that delivers more nuanced and realistic sounding speech, as well as two speech-to-text models called “gpt-4o-transcribe” and “gpt-4o-mini-transcribe”. The company claims they are improved versions of what was already there and that they hallucinate less.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-has-launched-o1-pro-a-more-powerful-version-of-its-o1"&gt;OpenAI has launched o1-pro, a more powerful version of its o1&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has introduced o1-pro in its developer API. OpenAI says its o1-pro uses more computing than its o1 “reasoning” AI model to deliver “consistently better responses.” It’s only accessible to select developers who have spent at least $5 on OpenAI API services. OpenAI charges $150 for every million tokens (about 750,000 words) input into the model and $600 for every million tokens the model produces. It costs twice as much as OpenAI’s GPT-4.5 for input and 10 times the price of regular o1.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-research-lead-noam-brown-thinks-ai-reasoning-models-could-ve-arrived-decades-ago"&gt;OpenAI research lead Noam Brown thinks AI “reasoning” models could’ve arrived decades ago&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Noam Brown, who heads AI reasoning research at OpenAI, thinks that certain types of AI models for “reasoning” could have been developed 20 years ago if researchers had understood the correct approach and algorithms.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-has-trained-an-ai-that-s-really-good-at-creative-writing"&gt;OpenAI says it has trained an AI that’s “really good” at creative writing&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI CEO Sam Altman said, in a&amp;nbsp;post on X, that the company has trained a “new model” that’s “really good” at creative writing. He posted a lengthy sample from the model given the prompt “Please write a metafictional literary short story about AI and grief.” OpenAI has not extensively explored the use of AI for writing fiction. The company has mostly concentrated on challenges in rigid, predictable areas such as math and programming.&lt;em&gt;&amp;nbsp;&lt;/em&gt;And it turns out that it might not be that great at creative writing at all. &lt;/p&gt;







&lt;blockquote class="twitter-tweet wp-block-html"&gt;&lt;p dir="ltr" lang="en"&gt;we trained a new model that is good at creative writing (not sure yet how/when it will get released). this is the first time i have been really struck by something written by AI; it got the vibe of metafiction so right.&lt;/p&gt;&lt;p&gt;PROMPT:&lt;/p&gt;&lt;p&gt;Please write a metafictional literary short story…&lt;/p&gt;— Sam Altman (@sama) March 11, 2025&lt;/blockquote&gt; 

&lt;h4 class="wp-block-heading" id="h-openai-launches-new-tools-to-help-businesses-build-ai-agents"&gt;OpenAI launches new tools to help businesses build AI agents&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI rolled out new tools designed to help developers and businesses build AI agents — automated systems that can independently accomplish tasks — using the company’s own AI models and frameworks. The tools are part of OpenAI’s new Responses API, which enables enterprises to develop customized AI agents that can perform web searches, scan through company files, and navigate websites, similar to OpenAI’s Operator product. The Responses API effectively replaces OpenAI’s Assistants API, which the company plans to discontinue in the first half of 2026.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-reportedly-plans-to-charge-up-to-20-000-a-month-for-specialized-ai-agents"&gt;OpenAI reportedly plans to charge up to $20,000 a month for specialized AI ‘agents’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intends to release several “agent” products tailored for different applications, including sorting and ranking sales leads and software engineering, according to a report from The Information. One, a “high-income knowledge worker” agent, will reportedly be priced at $2,000 a month. Another, a software developer agent, is said to cost $10,000 a month. The most expensive rumored agents, which are said to be aimed at supporting “PhD-level research,” are expected to cost $20,000 per month. The jaw-dropping figure is indicative of how much cash OpenAI needs right now: The company lost roughly $5 billion last year after paying for costs related to running its services and other expenses. It’s unclear when these agentic tools might launch or which customers will be eligible to buy them.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-can-directly-edit-your-code"&gt;&lt;strong&gt;ChatGPT can directly edit your code&lt;/strong&gt;&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;The latest version of the macOS ChatGPT app allows users to edit code directly in supported developer tools, including Xcode, VS Code, and JetBrains. ChatGPT Plus, Pro, and Team subscribers can use the feature now, and the company plans to roll it out to more users like Enterprise, Edu, and free users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-weekly-active-users-doubled-in-less-than-6-months-thanks-to-new-releases"&gt;ChatGPT’s weekly active users doubled in less than 6 months, thanks to new releases&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;According to a new report from VC firm Andreessen Horowitz (a16z), OpenAI’s AI chatbot, ChatGPT, experienced solid growth in the second half of 2024. It took ChatGPT nine months to increase its weekly active users from 100 million in November 2023 to 200 million in August 2024, but it only took less than six months to double that number once more, according to the report. ChatGPT’s weekly active users increased to 300 million by December 2024 and 400 million by February 2025. ChatGPT has experienced significant growth recently due to the launch of new models and features, such as GPT-4o, with multimodal capabilities. ChatGPT usage spiked from April to May 2024, shortly after that model’s launch.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-february-2025"&gt;February 2025 &lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-cancels-its-o3-ai-model-in-favor-of-a-unified-next-gen-release"&gt;OpenAI cancels its o3 AI model in favor of a ‘unified’ next-gen release&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has effectively canceled the release of o3 in favor of what CEO Sam Altman is calling a “simplified” product offering. In a post on X, Altman said that, in the coming months, OpenAI will release a model called GPT-5 that “integrates a lot of [OpenAI’s] technology,” including o3, in ChatGPT and its API. As a result of that roadmap decision, OpenAI no longer plans to release o3 as a standalone model.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-may-not-be-as-power-hungry-as-once-assumed"&gt;ChatGPT may not be as power-hungry as once assumed&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A commonly cited stat is that ChatGPT requires around 3 watt-hours of power to answer a single question. Using OpenAI’s latest default model for ChatGPT, GPT-4o, as a reference, nonprofit AI research institute Epoch AI found the average ChatGPT query consumes around 0.3 watt-hours. However, the analysis doesn’t consider the additional energy costs incurred by ChatGPT with features like image generation or input processing.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-now-reveals-more-of-its-o3-mini-model-s-thought-process"&gt;OpenAI now reveals more of its o3-mini model’s thought process&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;In response to pressure from rivals like DeepSeek, OpenAI is changing the way its o3-mini model communicates its step-by-step “thought” process. ChatGPT users will see an updated “chain of thought” that shows more of the model’s “reasoning” steps and how it arrived at answers to questions.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-you-can-now-use-chatgpt-web-search-without-logging-in"&gt;You can now use ChatGPT web search without logging in&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is now allowing anyone to use ChatGPT web search without having to log in. While OpenAI had previously allowed users to ask ChatGPT questions without signing in, responses were restricted to the chatbot’s last training update. This only applies through ChatGPT.com, however. To use ChatGPT in any form through the native mobile app, you will still need to be logged in.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-unveils-a-new-chatgpt-agent-for-deep-research"&gt;OpenAI unveils a new ChatGPT agent for ‘deep research’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI announced a new AI “agent” called deep research that’s designed to help people conduct in-depth, complex research using ChatGPT. OpenAI says the “agent” is intended for instances where you don’t just want a quick answer or summary, but instead need to assiduously consider information from multiple websites and other sources.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-january-2025"&gt;&lt;strong&gt;January 2025&lt;/strong&gt;&lt;/h3&gt;

&lt;h4 class="wp-block-heading" id="h-openai-used-a-subreddit-to-test-ai-persuasion"&gt;OpenAI used a subreddit to test AI persuasion&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI used the subreddit r/ChangeMyView to measure the persuasive abilities of its AI reasoning models. OpenAI says it collects user posts from the subreddit and asks its AI models to write replies, in a closed environment, that would change the Reddit user’s mind on a subject. The company then shows the responses to testers, who assess how persuasive the argument is, and finally OpenAI compares the AI models’ responses to human replies for that same post.&amp;nbsp;&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-o3-mini-its-latest-reasoning-model"&gt;OpenAI launches o3-mini, its latest ‘reasoning’ model&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched a new AI “reasoning” model, o3-mini, the newest in the company’s o family of models. OpenAI first previewed the model in December alongside a more capable system called o3. OpenAI is pitching its new model as both “powerful” and “affordable.”&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-s-mobile-users-are-85-male-report-says"&gt;ChatGPT’s mobile users are 85% male, report says&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A new report from app analytics firm Appfigures found that over half of ChatGPT’s mobile users are under age 25, with users between ages 50 and 64 making up the second largest age demographic. The gender gap among ChatGPT users is even more significant. Appfigures estimates that across age groups, men make up 84.5% of all users.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-chatgpt-plan-for-us-government-agencies"&gt;OpenAI launches ChatGPT plan for US government agencies&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI launched ChatGPT Gov designed to provide U.S. government agencies an additional way to access the tech. ChatGPT Gov includes many of the capabilities found in OpenAI’s corporate-focused tier, ChatGPT Enterprise. OpenAI says that ChatGPT Gov enables agencies to more easily manage their own security, privacy, and compliance, and could expedite internal authorization of OpenAI’s tools for the handling of non-public sensitive data.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-more-teens-report-using-chatgpt-for-schoolwork-despite-the-tech-s-faults"&gt;More teens report using ChatGPT for schoolwork, despite the tech’s faults&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Younger Gen Zers are embracing ChatGPT, for schoolwork, according to a new survey by the Pew Research Center. In a follow-up to its 2023 poll on ChatGPT usage among young people, Pew asked ~1,400 U.S.-based teens ages 13 to 17 whether they’ve used ChatGPT for homework or other school-related assignments. Twenty-six percent said that they had, double the number two years ago. Just over half of teens responding to the poll said they think it’s acceptable to use ChatGPT for researching new subjects. But considering the ways ChatGPT can fall short, the results are possibly cause for alarm.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-says-it-may-store-deleted-operator-data-for-up-to-90-days"&gt;OpenAI says it may store deleted Operator data for up to 90 days&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI says that it might store chats and associated screenshots from customers who use Operator, the company’s AI “agent” tool, for up to 90 days — even after a user manually deletes them. While OpenAI has a similar deleted data retention policy for ChatGPT, the retention period for ChatGPT is only 30 days, which is 60 days shorter than Operator’s.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-launches-operator-an-ai-agent-that-performs-tasks-autonomously"&gt;OpenAI launches Operator, an AI agent that performs tasks autonomously&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is launching a research preview of Operator, a general-purpose AI agent that can take control of a web browser and independently perform certain actions. Operator promises to automate tasks such as booking travel accommodations, making restaurant reservations, and shopping online.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-may-preview-its-agent-tool-for-users-on-the-200-per-month-pro-plan"&gt;OpenAI may preview its agent tool for users on the $200-per-month Pro plan&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Operator, OpenAI’s agent tool, could be released sooner rather than later. Changes to ChatGPT’s code base suggest that Operator will be available as an early research preview to users on the $200 Pro subscription plan. The changes aren’t yet publicly visible, but a user on X who goes by Choi spotted these updates in ChatGPT’s client-side code. TechCrunch separately identified the same references to Operator on OpenAI’s website.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-openai-tests-phone-number-only-chatgpt-signups"&gt;OpenAI tests phone number-only ChatGPT signups&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has begun testing a feature that lets new ChatGPT users sign up with only a phone number — no email required. The feature is currently in beta in the U.S. and India. However, users who create an account using their number can’t upgrade to one of OpenAI’s paid plans without verifying their account via an email. Multi-factor authentication also isn’t supported without a valid email.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-chatgpt-now-lets-you-schedule-reminders-and-recurring-tasks"&gt;ChatGPT now lets you schedule reminders and recurring tasks&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT’s new beta feature, called tasks, allows users to set simple reminders. For example, you can ask ChatGPT to remind you when your passport expires in six months, and the AI assistant will follow up with a push notification on whatever platform you have tasks enabled. The feature will start rolling out to ChatGPT Plus, Team, and Pro users around the globe this week.&lt;/p&gt;

&lt;h4 class="wp-block-heading" id="h-new-chatgpt-feature-lets-users-assign-it-traits-like-chatty-and-gen-z"&gt;New ChatGPT feature lets users assign it traits like ‘chatty’ and ‘Gen Z’&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI is introducing a new way for users to customize their interactions with ChatGPT. Some users found they can specify a preferred name or nickname and “traits” they’d like the chatbot to have. OpenAI suggests traits like “Chatty,” “Encouraging,” and “Gen Z.” However, some users reported that the new options have disappeared, so it’s possible they went live prematurely.&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-faqs"&gt;FAQs:&lt;/h3&gt;

&lt;h4 class="wp-block-heading"&gt;What is ChatGPT? How does it work?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is a general-purpose chatbot that uses artificial intelligence to generate text after a user enters a prompt, developed by tech startup OpenAI. The chatbot uses GPT-4, a large language model that uses deep learning to produce human-like text.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;When did ChatGPT get released?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;November 30, 2022 is when ChatGPT was released for public use.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the latest version of ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Both the free version of ChatGPT and the paid ChatGPT Plus are regularly updated with new GPT models. The most recent model is GPT-4o.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can I use ChatGPT for free?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;There is a free version of ChatGPT that only requires a sign-in in addition to the paid version, ChatGPT Plus.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Who uses ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Anyone can use ChatGPT! More and more tech companies and search engines are utilizing the chatbot to automate text or quickly answer user questions/concerns.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What companies use ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Multiple enterprises utilize ChatGPT, although others may limit the use of the AI-powered tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Most recently, Microsoft announced at its 2023 Build conference that it is integrating its ChatGPT-based Bing experience into Windows 11. A Brooklyn-based 3D display startup Looking Glass utilizes ChatGPT to produce holograms you can communicate with by using ChatGPT.&amp;nbsp; And nonprofit organization Solana officially integrated the chatbot into its network with a ChatGPT plug-in geared toward end users to help onboard into the web3 space.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What does GPT mean in ChatGPT?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;GPT stands for Generative Pre-Trained Transformer.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;What is the difference between ChatGPT and a chatbot?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;A chatbot can be any software/system that holds dialogue with you/a person but doesn’t necessarily have to be AI-powered. For example, there are chatbots that are rules-based in the sense that they’ll give canned responses to questions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT is AI-powered and utilizes LLM technology to generate text after a prompt.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT write essays?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Yes.&lt;/p&gt;

&lt;h4 class="wp-block-heading"&gt;Can ChatGPT commit libel?&lt;/h4&gt;

&lt;p class="wp-block-paragraph"&gt;Due to the nature of how these models work, they don’t know or care whether something is true, only that it looks true. That’s a problem when you’re using it to do your homework, sure, but when it accuses you of a crime you didn’t commit, that may well at this point be libel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;We will see how handling troubling statements produced by ChatGPT will play out over the next few months as tech and legal experts attempt to tackle the fastest moving target in the industry.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an app?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, there is a free ChatGPT mobile app for iOS and Android users.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What is the ChatGPT character limit?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It’s not documented anywhere that ChatGPT has a character limit. However, users have noted that there are some character limitations after around 500 words.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Does ChatGPT have an API?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes, it was released March 1, 2023.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some sample everyday uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Everyday examples include programming, scripts, email replies, listicles, blog ideas, summarization, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What are some advanced uses for ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Advanced use examples include debugging code, programming languages, scientific concepts, complex problem solving, etc.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How good is ChatGPT at writing code?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;It depends on the nature of the program. While ChatGPT can write workable Python code, it can’t necessarily program an entire app’s worth of code. That’s because ChatGPT lacks context awareness — in other words, the generated code isn’t always appropriate for the specific context in which it’s being used.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can you save a ChatGPT chat?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. OpenAI allows users to save chats in the ChatGPT interface, stored in the sidebar of the screen. There are no built-in sharing features yet.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there alternatives to ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. There are multiple AI-powered chatbot competitors such as Together, Google’s Gemini and Anthropic’s Claude, and developers are creating open source alternatives.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;How does ChatGPT handle data privacy?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI has&amp;nbsp;said&amp;nbsp;that individuals in “certain jurisdictions” (such as the EU) can object to the processing of their personal information by its AI models by filling out&amp;nbsp;this form. This includes the ability to make requests for deletion of AI-generated references about you. Although OpenAI notes it may not grant every request since it must balance privacy requests against freedom of expression “in accordance with applicable laws”.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The web form for making a deletion of data about you request is entitled “OpenAI Personal Data Removal Request”.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In its privacy policy, the ChatGPT maker makes a passing acknowledgement of the objection requirements attached to relying on “legitimate interest” (LI), pointing users towards more information about requesting an opt out — when it writes: “See here&amp;nbsp;for instructions on how you can opt out of our use of your information to train our models.”&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What controversies have surrounded ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Recently, Discord announced that it had integrated OpenAI’s technology into its bot named Clyde where two users tricked Clyde into providing them with instructions for making the illegal drug methamphetamine (meth) and the incendiary mixture napalm.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;An Australian mayor has publicly announced he may sue OpenAI for defamation due to ChatGPT’s false claims that he had served time in prison for bribery. This would be the first defamation lawsuit against the text-generating service.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CNET found itself in the midst of controversy after Futurism reported the publication was publishing articles under a mysterious byline completely generated by AI. The private equity company that owns CNET, Red Ventures, was accused of using ChatGPT for SEO farming, even if the information was incorrect.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Several major school systems and colleges, including New York City Public Schools, have banned ChatGPT from their networks and devices. They claim that the AI impedes the learning process by promoting plagiarism and misinformation, a claim that not every educator agrees with.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There have also been cases of ChatGPT accusing individuals of false crimes.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Where can I find examples of ChatGPT prompts?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Several marketplaces host and provide ChatGPT prompts, either for free or for a nominal fee. One is PromptBase. Another is ChatX. More launch every day.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Can ChatGPT be detected?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Poorly. Several tools claim to detect ChatGPT-generated text, but in our tests, they’re inconsistent at best.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are ChatGPT chats public?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;No. But OpenAI recently disclosed a bug, since fixed, that exposed the titles of some users’ conversations to other people on the service.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;What lawsuits are there surrounding ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;None specifically targeting ChatGPT. But OpenAI is involved in at least one lawsuit that has implications for AI systems trained on publicly available data, which would touch on ChatGPT.&lt;/p&gt;

&lt;h3 class="wp-block-heading"&gt;Are there issues regarding plagiarism with ChatGPT?&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Yes. Text-generating AI models like ChatGPT have a tendency to regurgitate content from their training data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story is continually updated with new information.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/chatgpt-everything-to-know-about-the-ai-chatbot/</guid><pubDate>Tue, 30 Sep 2025 16:56:24 +0000</pubDate></item><item><title>AI as a research partner: Advancing theoretical computer science with AlphaEvolve (The latest research from Google)</title><link>https://research.google/blog/ai-as-a-research-partner-advancing-theoretical-computer-science-with-alphaevolve/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;The crucial role of verified correctness&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;A critical distinction of this work is that the results come with proofs of correctness.&lt;/p&gt;&lt;p&gt;When an LLM is prompted to generate a mathematical proof directly, it often produces a proof sketch or an argument that requires substantial human intervention to verify and complete. Hallucinations or subtle errors can render the output useless. As mentioned earlier, the standard for correctness in math is absolute.&lt;/p&gt;&lt;p&gt;In contrast, the approach taken here uses AI to discover a &lt;i&gt;structure&lt;/i&gt; within the proof, not the proof itself. The validity of the final theorem relies on two components: the correctness of the lifting framework, and the verification of the discovered structure. While the frameworks are sound, verifying the structures discovered by AlphaEvolve is computationally intensive.&lt;/p&gt;&lt;p&gt;Remarkably, AlphaEvolve achieved a 10,000x speedup in the verification process by implementing sophisticated branch-and-bound strategies and system-level optimizations. This massive speedup was the key enabler for the research, allowing the system to explore much larger and more complex gadgets.&lt;/p&gt;&lt;p&gt;Crucially, the final gadgets discovered were still verified using the original, brute-force algorithm, ensuring the absolute correctness of the theorems.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;The crucial role of verified correctness&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;A critical distinction of this work is that the results come with proofs of correctness.&lt;/p&gt;&lt;p&gt;When an LLM is prompted to generate a mathematical proof directly, it often produces a proof sketch or an argument that requires substantial human intervention to verify and complete. Hallucinations or subtle errors can render the output useless. As mentioned earlier, the standard for correctness in math is absolute.&lt;/p&gt;&lt;p&gt;In contrast, the approach taken here uses AI to discover a &lt;i&gt;structure&lt;/i&gt; within the proof, not the proof itself. The validity of the final theorem relies on two components: the correctness of the lifting framework, and the verification of the discovered structure. While the frameworks are sound, verifying the structures discovered by AlphaEvolve is computationally intensive.&lt;/p&gt;&lt;p&gt;Remarkably, AlphaEvolve achieved a 10,000x speedup in the verification process by implementing sophisticated branch-and-bound strategies and system-level optimizations. This massive speedup was the key enabler for the research, allowing the system to explore much larger and more complex gadgets.&lt;/p&gt;&lt;p&gt;Crucially, the final gadgets discovered were still verified using the original, brute-force algorithm, ensuring the absolute correctness of the theorems.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/ai-as-a-research-partner-advancing-theoretical-computer-science-with-alphaevolve/</guid><pubDate>Tue, 30 Sep 2025 16:57:45 +0000</pubDate></item><item><title>AI hires or human hustle? Inside the next frontier of startup operations at TechCrunch Disrupt 2025 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/ai-hires-or-human-hustle-inside-the-next-frontier-of-startup-operations-at-techcrunch-disrupt-2025/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What happens when your first 10 hires aren’t people at all? At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at San Francisco’s Moscone West, we’re digging into the new wave of startups replacing or augmenting early employees with AI agents. Think outbound sales, billing, and customer support — automated from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This panel, hosted on the &lt;strong&gt;Builders Stage&lt;/strong&gt;, features a mix of technical founders and seasoned operators who are actually doing it, debating where the line between human and machine should be drawn — and how far is too far.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Caleb Peffer, Jaspar Carmichael-Jack, Sarah Franklin" class="wp-image-3040625" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Jack-Peffer-Franklin-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-speakers"&gt;Meet the speakers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Caleb Peffer&lt;/strong&gt;, founder and CEO of Firecrawl, is helping over 350,000 developers (and companies like Shopify and Zapier) plug AI directly into the live web. His dev-first platform is already reshaping how AI agents interact with the internet and scale with clean data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Jaspar Carmichael-Jack&lt;/strong&gt;, founder and CEO of Artisan, made waves with his “Stop Hiring Humans” campaign — and he’s serious. His company raised $35 million to build AI employees, starting with sales. Expect bold insights on replacing go-to-market teams with code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sarah Franklin&lt;/strong&gt;, CEO of Lattice and former Salesforce president and CMO, brings hard-won wisdom on scaling companies with impact. She’s built and led real teams at the highest level and knows exactly where AI helps — and where it hurts.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re already embedding AI into your stack or just testing prompts on your product team, this conversation is about more than hype. It’s about getting real on ROI, trust, team dynamics, and what it means to build a business that moves faster than ever with fewer human hands.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ready-to-find-your-edge"&gt;Ready to find your edge?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000+ founders, VCs, and innovators at Disrupt this October. Regular Bird savings of up to $668 end September 26 at 11:59 p.m. PT — &lt;strong&gt;Get your ticket now&lt;/strong&gt; to lock in your spot.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;What happens when your first 10 hires aren’t people at all? At &lt;strong&gt;TechCrunch Disrupt 2025&lt;/strong&gt;, happening October 27–29 at San Francisco’s Moscone West, we’re digging into the new wave of startups replacing or augmenting early employees with AI agents. Think outbound sales, billing, and customer support — automated from day one.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This panel, hosted on the &lt;strong&gt;Builders Stage&lt;/strong&gt;, features a mix of technical founders and seasoned operators who are actually doing it, debating where the line between human and machine should be drawn — and how far is too far.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="TechCrunch Disrupt 2025 Caleb Peffer, Jaspar Carmichael-Jack, Sarah Franklin" class="wp-image-3040625" height="383" src="https://techcrunch.com/wp-content/uploads/2025/08/TC25_Jack-Peffer-Franklin-Speaker-16x9-Dark.png?w=680" width="680" /&gt;&lt;/figure&gt;

&lt;h2 class="wp-block-heading" id="h-meet-the-speakers"&gt;Meet the speakers&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Caleb Peffer&lt;/strong&gt;, founder and CEO of Firecrawl, is helping over 350,000 developers (and companies like Shopify and Zapier) plug AI directly into the live web. His dev-first platform is already reshaping how AI agents interact with the internet and scale with clean data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Jaspar Carmichael-Jack&lt;/strong&gt;, founder and CEO of Artisan, made waves with his “Stop Hiring Humans” campaign — and he’s serious. His company raised $35 million to build AI employees, starting with sales. Expect bold insights on replacing go-to-market teams with code.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;Sarah Franklin&lt;/strong&gt;, CEO of Lattice and former Salesforce president and CMO, brings hard-won wisdom on scaling companies with impact. She’s built and led real teams at the highest level and knows exactly where AI helps — and where it hurts.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-why-this-session-matters"&gt;Why this session matters&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Whether you’re already embedding AI into your stack or just testing prompts on your product team, this conversation is about more than hype. It’s about getting real on ROI, trust, team dynamics, and what it means to build a business that moves faster than ever with fewer human hands.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-ready-to-find-your-edge"&gt;Ready to find your edge?&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Join 10,000+ founders, VCs, and innovators at Disrupt this October. Regular Bird savings of up to $668 end September 26 at 11:59 p.m. PT — &lt;strong&gt;Get your ticket now&lt;/strong&gt; to lock in your spot.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/ai-hires-or-human-hustle-inside-the-next-frontier-of-startup-operations-at-techcrunch-disrupt-2025/</guid><pubDate>Tue, 30 Sep 2025 18:00:00 +0000</pubDate></item><item><title>[NEW] OpenAI is launching the Sora app, its own TikTok competitor, alongside the Sora 2 model (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/openai-is-launching-the-sora-app-its-own-tiktok-competitor-alongside-the-sora-2-model/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181602.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, OpenAI announced the release of Sora 2, an audio and video generator to succeed last year’s Sora. Along with the model, the company also launched a linked social app called Sora, where users can generate videos of themselves and their friends to share on a TikTok-style algorithmic feed. OpenAI’s work on a new social platform was previously reported by Wired.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While we haven’t been able to test the invite-only app and Sora 2 model ourselves yet, OpenAI has shared impressive examples. In particular, Sora 2 is better at following the laws of physics, making the videos more realistic. OpenAI’s public clips depict a beach volleyball game, skateboard tricks, gymnastics routines, and cannonball jumps from a diving board, among others.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Prior video models are overoptimistic — they will morph objects and deform reality to successfully execute upon a text prompt,” OpenAI wrote in a blog post. “For example, if a basketball player misses a shot, the ball may spontaneously teleport to the hoop. In Sora 2, if a basketball player misses a shot, it will rebound off the backboard.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Sora app comes with an “upload yourself” feature called “cameos,” which allows users to drop themselves into any Sora-generated scenes. In order to use their own likeness in a generated video, users will have to upload a one-time video-and-audio recording to verify their identity and capture their appearance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This feature also allows users to share their “cameos” with their friends, allowing them to give other users permission to include their likeness in videos that they generate, including videos of multiple people together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think a social app built around this ‘cameos’ feature is the best way to experience the magic of Sora 2,” the company wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Sora iOS app is available to download now and will initially roll out in the U.S. and Canada, though OpenAI says it hopes to expand quickly to other countries. While the Sora social platform is currently invite-only, ChatGPT Pro users should be able to try out the Sora 2 Pro model without an invite.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Once videos are generated, they can be shared in a feed within the Sora app, which seems like it’ll be similar to TikTok, Instagram Reels, or other short-form video feeds. Interestingly, Meta announced just last week that it added a video feed called “Vibes” to its Meta AI app (it’s basically all mindless slop).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To curate its algorithmic recommendations, OpenAI will consider a user’s Sora activity, their location (attained via their IP address), their past post engagement, and their ChatGPT conversation history, though that can be turned off. The Sora app also ships with parental controls via ChatGPT, which allow parents to override infinite scroll limits, turn off algorithmic personalization, and manage who can direct message their child. However, these features are only as powerful as the parent’s technical know-how. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Sora app will be free at launch, which OpenAI says is “so people can freely explore its capabilities.” The company says that at launch, the only plan for monetization is to charge users to generate extra videos in times of high demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of a social platform will require significant user safety measures from OpenAI, which has struggled with the same issues in ChatGPT. While users can revoke access to their likeness at any time, this sort of access can easily be abused. Even if a user trusts someone they know with access to their AI likeness, that person could still generate deceptive content that could be used to harm that person. Non-consensual videos are a persistent problem with AI-generated video, causing significant harm with few laws explicitly governing platform responsibility.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2197181602.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Tuesday, OpenAI announced the release of Sora 2, an audio and video generator to succeed last year’s Sora. Along with the model, the company also launched a linked social app called Sora, where users can generate videos of themselves and their friends to share on a TikTok-style algorithmic feed. OpenAI’s work on a new social platform was previously reported by Wired.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While we haven’t been able to test the invite-only app and Sora 2 model ourselves yet, OpenAI has shared impressive examples. In particular, Sora 2 is better at following the laws of physics, making the videos more realistic. OpenAI’s public clips depict a beach volleyball game, skateboard tricks, gymnastics routines, and cannonball jumps from a diving board, among others.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;“Prior video models are overoptimistic — they will morph objects and deform reality to successfully execute upon a text prompt,” OpenAI wrote in a blog post. “For example, if a basketball player misses a shot, the ball may spontaneously teleport to the hoop. In Sora 2, if a basketball player misses a shot, it will rebound off the backboard.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The Sora app comes with an “upload yourself” feature called “cameos,” which allows users to drop themselves into any Sora-generated scenes. In order to use their own likeness in a generated video, users will have to upload a one-time video-and-audio recording to verify their identity and capture their appearance.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This feature also allows users to share their “cameos” with their friends, allowing them to give other users permission to include their likeness in videos that they generate, including videos of multiple people together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think a social app built around this ‘cameos’ feature is the best way to experience the magic of Sora 2,” the company wrote.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Sora iOS app is available to download now and will initially roll out in the U.S. and Canada, though OpenAI says it hopes to expand quickly to other countries. While the Sora social platform is currently invite-only, ChatGPT Pro users should be able to try out the Sora 2 Pro model without an invite.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Once videos are generated, they can be shared in a feed within the Sora app, which seems like it’ll be similar to TikTok, Instagram Reels, or other short-form video feeds. Interestingly, Meta announced just last week that it added a video feed called “Vibes” to its Meta AI app (it’s basically all mindless slop).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To curate its algorithmic recommendations, OpenAI will consider a user’s Sora activity, their location (attained via their IP address), their past post engagement, and their ChatGPT conversation history, though that can be turned off. The Sora app also ships with parental controls via ChatGPT, which allow parents to override infinite scroll limits, turn off algorithmic personalization, and manage who can direct message their child. However, these features are only as powerful as the parent’s technical know-how. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Sora app will be free at launch, which OpenAI says is “so people can freely explore its capabilities.” The company says that at launch, the only plan for monetization is to charge users to generate extra videos in times of high demand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of a social platform will require significant user safety measures from OpenAI, which has struggled with the same issues in ChatGPT. While users can revoke access to their likeness at any time, this sort of access can easily be abused. Even if a user trusts someone they know with access to their AI likeness, that person could still generate deceptive content that could be used to harm that person. Non-consensual videos are a persistent problem with AI-generated video, causing significant harm with few laws explicitly governing platform responsibility.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/openai-is-launching-the-sora-app-its-own-tiktok-competitor-alongside-the-sora-2-model/</guid><pubDate>Tue, 30 Sep 2025 18:28:53 +0000</pubDate></item><item><title>[NEW] Former OpenAI and DeepMind researchers raise whopping $300M seed to automate science (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/09/30/former-openai-and-deepmind-researchers-raise-whopping-300m-seed-to-automate-science/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-642109519.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Periodic Labs came out of stealth on Tuesday with a war chest of $300 million as a seed round, backed by a tech industry who’s who: Andreessen Horowitz, DST, Nvidia, Accel, Elad Gil, Jeff Dean, Eric Schmidt, and Jeff Bezos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Periodic Labs was founded by Ekin Dogus Cubuk and Liam Fedus. Cubuk led the materials and chemistry team at Google Brain and DeepMind, where one of his projects was, for instance, an AI tool called GNoME. That tool discovered over 2 million new crystals in 2023, materials that could one day be used to power new generations of technology, researchers say.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Fedus is a former VP of Research at OpenAI, and one of the researchers who helped create ChatGPT. He also led the team that created the first trillion-parameter neural network.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its small team is likewise filled with researchers who have worked on other major AI and materials science projects, from building OpenAI’s agent Operator to working on Microsoft’s MatterGen, an LLM materials science discovery AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The goal of Periodic Labs is nothing less than to automate scientific discovery, creating AI scientists, the company says. This means building labs where robots conduct physical experiments, collect data, iterate, and try again, learning and improving as they go.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The lab’s first goal is to invent new superconductors that it hopes perform better and possibly require less energy than existing superconducting materials. But the well-funded startup also hopes to find other new materials.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another goal is to collect all the physical world data that its AI scientists produce as they mix and heat and otherwise manipulate various powers and raw materials in their search for something new.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Until now, scientific AI advances have come from models trained on the internet” and LLMs have “exhausted” the internet as a source that can be consumed, the company says in an introductory blog post. “[A]t Periodic, we are building AI scientists &lt;em&gt;and&lt;/em&gt; the autonomous laboratories for them to operate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hope is that, not only will the labs invent next-generation materials, but they will produce invaluable fresh data that AI models can consume to continue their evolution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While this might be one of the most impressive groups of researchers to assemble a startup for this purpose, it’s not the only one working on AI scientists. AI as a tool to automate chemistry discoveries has been a topic of academic research since at least 2023. It is the pursuit of tiny startups like Tetsuwan Scientific, as well as nonprofits like Future House and the University of Toronto’s Acceleration Consortium.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-642109519.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Periodic Labs came out of stealth on Tuesday with a war chest of $300 million as a seed round, backed by a tech industry who’s who: Andreessen Horowitz, DST, Nvidia, Accel, Elad Gil, Jeff Dean, Eric Schmidt, and Jeff Bezos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Periodic Labs was founded by Ekin Dogus Cubuk and Liam Fedus. Cubuk led the materials and chemistry team at Google Brain and DeepMind, where one of his projects was, for instance, an AI tool called GNoME. That tool discovered over 2 million new crystals in 2023, materials that could one day be used to power new generations of technology, researchers say.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Fedus is a former VP of Research at OpenAI, and one of the researchers who helped create ChatGPT. He also led the team that created the first trillion-parameter neural network.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its small team is likewise filled with researchers who have worked on other major AI and materials science projects, from building OpenAI’s agent Operator to working on Microsoft’s MatterGen, an LLM materials science discovery AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The goal of Periodic Labs is nothing less than to automate scientific discovery, creating AI scientists, the company says. This means building labs where robots conduct physical experiments, collect data, iterate, and try again, learning and improving as they go.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The lab’s first goal is to invent new superconductors that it hopes perform better and possibly require less energy than existing superconducting materials. But the well-funded startup also hopes to find other new materials.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another goal is to collect all the physical world data that its AI scientists produce as they mix and heat and otherwise manipulate various powers and raw materials in their search for something new.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Until now, scientific AI advances have come from models trained on the internet” and LLMs have “exhausted” the internet as a source that can be consumed, the company says in an introductory blog post. “[A]t Periodic, we are building AI scientists &lt;em&gt;and&lt;/em&gt; the autonomous laboratories for them to operate.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The hope is that, not only will the labs invent next-generation materials, but they will produce invaluable fresh data that AI models can consume to continue their evolution.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While this might be one of the most impressive groups of researchers to assemble a startup for this purpose, it’s not the only one working on AI scientists. AI as a tool to automate chemistry discoveries has been a topic of academic research since at least 2023. It is the pursuit of tiny startups like Tetsuwan Scientific, as well as nonprofits like Future House and the University of Toronto’s Acceleration Consortium.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/09/30/former-openai-and-deepmind-researchers-raise-whopping-300m-seed-to-automate-science/</guid><pubDate>Tue, 30 Sep 2025 18:56:59 +0000</pubDate></item><item><title>[NEW] With new agent mode for Excel and Word, Microsoft touts “vibe working” (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/with-new-agent-mode-for-excel-and-word-microsoft-touts-vibe-working/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Agent Mode in Word, Excel works like vibe coding tools but for knowledge work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An Excel spreadsheet shows the Agent Mode interface" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/M365-Blog_09292025_agentMode_Hero_v1-809x455-1-640x360.webp" width="640" /&gt;
                  &lt;img alt="An Excel spreadsheet shows the Agent Mode interface" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="455" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/M365-Blog_09292025_agentMode_Hero_v1-809x455-1.webp" width="809" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A promotional image for Agent Mode made by microsoft.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Microsoft

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;With a new set of Microsoft 365 features, knowledge workers will be able to generate complex Word documents or Excel spreadsheets using only text prompts to Microsoft's chatbot. Two distinct products were announced, each using different models and accessed from within different tools—though the similar names Microsoft chose make it confusing to parse what's what.&lt;/p&gt;
&lt;p&gt;Driven by OpenAI's GPT-5 large language model, Agent Mode is built into Word and Excel, and it allows the creation of complex documents and spreadsheets from user prompts. It's called "agent" mode because it doesn't just work from the prompt in a single step; rather, it plans multistep work and runs a validation loop in the hopes of ensuring quality.&lt;/p&gt;
&lt;p&gt;It's only available in the web versions of Word and Excel at present, but the plan is to bring it to native desktop applications later.&lt;/p&gt;
&lt;p&gt;There's also the similarly named Office Agent for Copilot. Based on Anthropic models, this feature is built into Microsoft's Copilot AI assistant chatbot, and it too can generate documents from prompts—specifically, Word or PowerPoint files.&lt;/p&gt;
&lt;p&gt;Office Agent doesn't run through all the steps as Agent Mode, but Microsoft believes it offers a dramatic improvement over prior, OpenAI-driven document-generation capabilities in Copilot, which users complained were prone to all sorts of problems and shortcomings. It is available first in the Frontier Program for Microsoft 365 subscribers.&lt;/p&gt;
&lt;p&gt;Together, Microsoft says these features will let knowledge workers engage in a practice it's calling "vibe working," a play on the now-established term vibe coding.&lt;/p&gt;
&lt;h2&gt;Vibe everything, apparently&lt;/h2&gt;
&lt;p&gt;Vibe coding is the process of developing an application entirely via LLM chatbot prompts. You explain what you want in the chat interface and ask for it to generate code that does that. You then run that code, and if there are problems, explain the problem and tell it to fix it, iterating along the way until you have a usable application.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For certain kinds of simple applications, you can generate something usable this way. However, it often falls apart completely as you scale to more complex applications, and in any case, it's almost definitely going to introduce problems that you are less likely to see than if you wrote the application yourself, leading to (among other things) deep technical debt.&lt;/p&gt;
&lt;p&gt;Again, that's probably fine if you're just making a simple website for your small local business or something like that. But there's consensus in the development community that it's a dangerous path to walk at enterprise scale.&lt;/p&gt;
&lt;p&gt;If you're "vibe working" or "vibe writing" in Microsoft Word, you're doing the same thing, but with a text document: You're telling it what you want the document to say, reading it, accepting the suggestion, and then asking for further changes until you're happy with it.&lt;/p&gt;
&lt;p&gt;Whether this makes any sense obviously depends on what kind of document you're writing. For some things, it should be just fine as long as someone is reading it. Others probably won't work for their intended purpose without a human touch. Same with PowerPoint presentations.&lt;/p&gt;
&lt;p&gt;Doing this with a spreadsheet could be riskier, though; the financial or legal consequences for bad math or data in spreadsheets of some types can be very high, and as with vibe coding, it might be hard to see the problems at the surface level.&lt;/p&gt;
&lt;p&gt;That's exactly why Microsoft hasn't been as aggressive in adding AI features to Excel as it has with some other applications. And to be fair, it acknowledges an important gap here: a SpreadsheetBench sheet in today's announcement notes that Copilot in Excel Agent Mode managed a 57.2 percent score, while a human typically manages 71.3 percent. So, as with vibe coding, you'd want to be highly selective about when and how you'd use this, and you'd want to make sure that an experienced human is auditing the output carefully.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But the thinking is that just because it's not suitable for every kind of spreadsheet doesn't mean it doesn't make sense to have an easy-to-use option for lower-stakes work.&lt;/p&gt;
&lt;h2&gt;Use with care&lt;/h2&gt;
&lt;p&gt;It's possible these tools (and refined successors) will make life just a little bit easier for knowledge workers, but as always, those workers are going to need to understand some basic principles of how LLM-based tools work, and what their strengths and weaknesses are, to make intelligent decisions about when to try and save time by "vibe working" and when not to.&lt;/p&gt;
&lt;p&gt;All that said, a big reason why vibe coding is popular is because it allows inexperienced developers (or people who are not really developers at all) to bypass a knowledge gap; not everyone knows all the syntax and nuances of a programming language, much less which functions are available to call in a given library and so on.&lt;/p&gt;
&lt;p&gt;Something akin to that may also be true of professional-caliber writing, but the gap doesn't seem as big there, so some may feel that "vibe working" is an answer in search of a problem.&lt;/p&gt;
&lt;p&gt;OpenAI and some other major AI companies are said to be working on their own productivity tools built on their models, so we can also see this as Microsoft's attempt to stay ahead of the puck and make sure it doesn't find itself outscored by upstarts.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Agent Mode in Word, Excel works like vibe coding tools but for knowledge work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An Excel spreadsheet shows the Agent Mode interface" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/M365-Blog_09292025_agentMode_Hero_v1-809x455-1-640x360.webp" width="640" /&gt;
                  &lt;img alt="An Excel spreadsheet shows the Agent Mode interface" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="455" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/M365-Blog_09292025_agentMode_Hero_v1-809x455-1.webp" width="809" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A promotional image for Agent Mode made by microsoft.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Microsoft

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;With a new set of Microsoft 365 features, knowledge workers will be able to generate complex Word documents or Excel spreadsheets using only text prompts to Microsoft's chatbot. Two distinct products were announced, each using different models and accessed from within different tools—though the similar names Microsoft chose make it confusing to parse what's what.&lt;/p&gt;
&lt;p&gt;Driven by OpenAI's GPT-5 large language model, Agent Mode is built into Word and Excel, and it allows the creation of complex documents and spreadsheets from user prompts. It's called "agent" mode because it doesn't just work from the prompt in a single step; rather, it plans multistep work and runs a validation loop in the hopes of ensuring quality.&lt;/p&gt;
&lt;p&gt;It's only available in the web versions of Word and Excel at present, but the plan is to bring it to native desktop applications later.&lt;/p&gt;
&lt;p&gt;There's also the similarly named Office Agent for Copilot. Based on Anthropic models, this feature is built into Microsoft's Copilot AI assistant chatbot, and it too can generate documents from prompts—specifically, Word or PowerPoint files.&lt;/p&gt;
&lt;p&gt;Office Agent doesn't run through all the steps as Agent Mode, but Microsoft believes it offers a dramatic improvement over prior, OpenAI-driven document-generation capabilities in Copilot, which users complained were prone to all sorts of problems and shortcomings. It is available first in the Frontier Program for Microsoft 365 subscribers.&lt;/p&gt;
&lt;p&gt;Together, Microsoft says these features will let knowledge workers engage in a practice it's calling "vibe working," a play on the now-established term vibe coding.&lt;/p&gt;
&lt;h2&gt;Vibe everything, apparently&lt;/h2&gt;
&lt;p&gt;Vibe coding is the process of developing an application entirely via LLM chatbot prompts. You explain what you want in the chat interface and ask for it to generate code that does that. You then run that code, and if there are problems, explain the problem and tell it to fix it, iterating along the way until you have a usable application.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;For certain kinds of simple applications, you can generate something usable this way. However, it often falls apart completely as you scale to more complex applications, and in any case, it's almost definitely going to introduce problems that you are less likely to see than if you wrote the application yourself, leading to (among other things) deep technical debt.&lt;/p&gt;
&lt;p&gt;Again, that's probably fine if you're just making a simple website for your small local business or something like that. But there's consensus in the development community that it's a dangerous path to walk at enterprise scale.&lt;/p&gt;
&lt;p&gt;If you're "vibe working" or "vibe writing" in Microsoft Word, you're doing the same thing, but with a text document: You're telling it what you want the document to say, reading it, accepting the suggestion, and then asking for further changes until you're happy with it.&lt;/p&gt;
&lt;p&gt;Whether this makes any sense obviously depends on what kind of document you're writing. For some things, it should be just fine as long as someone is reading it. Others probably won't work for their intended purpose without a human touch. Same with PowerPoint presentations.&lt;/p&gt;
&lt;p&gt;Doing this with a spreadsheet could be riskier, though; the financial or legal consequences for bad math or data in spreadsheets of some types can be very high, and as with vibe coding, it might be hard to see the problems at the surface level.&lt;/p&gt;
&lt;p&gt;That's exactly why Microsoft hasn't been as aggressive in adding AI features to Excel as it has with some other applications. And to be fair, it acknowledges an important gap here: a SpreadsheetBench sheet in today's announcement notes that Copilot in Excel Agent Mode managed a 57.2 percent score, while a human typically manages 71.3 percent. So, as with vibe coding, you'd want to be highly selective about when and how you'd use this, and you'd want to make sure that an experienced human is auditing the output carefully.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But the thinking is that just because it's not suitable for every kind of spreadsheet doesn't mean it doesn't make sense to have an easy-to-use option for lower-stakes work.&lt;/p&gt;
&lt;h2&gt;Use with care&lt;/h2&gt;
&lt;p&gt;It's possible these tools (and refined successors) will make life just a little bit easier for knowledge workers, but as always, those workers are going to need to understand some basic principles of how LLM-based tools work, and what their strengths and weaknesses are, to make intelligent decisions about when to try and save time by "vibe working" and when not to.&lt;/p&gt;
&lt;p&gt;All that said, a big reason why vibe coding is popular is because it allows inexperienced developers (or people who are not really developers at all) to bypass a knowledge gap; not everyone knows all the syntax and nuances of a programming language, much less which functions are available to call in a given library and so on.&lt;/p&gt;
&lt;p&gt;Something akin to that may also be true of professional-caliber writing, but the gap doesn't seem as big there, so some may feel that "vibe working" is an answer in search of a problem.&lt;/p&gt;
&lt;p&gt;OpenAI and some other major AI companies are said to be working on their own productivity tools built on their models, so we can also see this as Microsoft's attempt to stay ahead of the puck and make sure it doesn't find itself outscored by upstarts.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/with-new-agent-mode-for-excel-and-word-microsoft-touts-vibe-working/</guid><pubDate>Tue, 30 Sep 2025 19:34:38 +0000</pubDate></item><item><title>[NEW] DeepSeek tests “sparse attention” to slash AI processing costs (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/09/deepseek-tests-sparse-attention-to-slash-ai-processing-costs/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chinese lab's v3.2 release explores a technique that could make running AI far less costly.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="DeepSeek logo on a smartphone against a blue streaming-code tech-ish background." class="absolute inset-0 w-full h-full object-cover hidden" height="370" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2195894561-640x370.jpg" width="640" /&gt;
                  &lt;img alt="DeepSeek logo on a smartphone against a blue streaming-code tech-ish background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2195894561-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Ever wonder why ChatGPT slows down during long conversations? The culprit is a fundamental mathematical challenge: Processing long sequences of text requires massive computational resources, even with the efficiency tricks that companies have already deployed. While US tech giants can afford to throw more hardware at the problem, Chinese AI company DeepSeek, which is cut off from a steady supply of some advanced AI chips by export restrictions, has extra motivation to squeeze more performance from less silicon.&lt;/p&gt;
&lt;p&gt;On Monday, DeepSeek released an experimental version of its latest simulated reasoning language model, DeepSeek-V3.2-Exp, which introduces what it calls "DeepSeek Sparse Attention" (DSA). It's the company's implementation of a computational technique likely already used in some of the world's most prominent AI models. OpenAI pioneered sparse transformers in 2019 and used the technique to build GPT-3, while Google Research published work on "Reformer" models using similar concepts in 2020. (The full extent to which Western AI companies currently use sparse attention in their latest models remains undisclosed.)&lt;/p&gt;
&lt;p&gt;Despite sparse attention being a known approach for years, DeepSeek claims its version achieves "fine-grained sparse attention for the first time" and has cut API prices by 50 percent to demonstrate the efficiency gains. But to understand more about what makes DeepSeek v3.2 notable, it's useful to refresh yourself on a little AI history.&lt;/p&gt;
&lt;p&gt;DeepSeek made waves in January when its R1 simulated reasoning model reportedly matched OpenAI's o1 performance while costing only $6 million to train, and its chat app briefly topped the iPhone App Store, surpassing ChatGPT. All eyes are on the company that has given some of America's leading AI labs a run for their money.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;The attention bottleneck&lt;/h2&gt;
&lt;p&gt;In AI, "attention" is a term for a software technique that determines which words in a text are most relevant to understanding each other. Those relationships map out context, and context builds meaning in language. For example, in the sentence "The bank raised interest rates," attention helps the model establish that "bank" relates to "interest rates" in a financial context, not a riverbank context. Through attention, conceptual relationships become quantified as numbers stored in a neural network. Attention also governs how AI language models choose what information "matters most" when generating each word of their response.&lt;/p&gt;
&lt;p&gt;Calculating context with a machine is tricky, and it wasn't practical at scale until chips like GPUs that can calculate these relationships in parallel reached a certain level of capability. Even so, the original Transformer architecture from 2017 checked the relationship of each word in a prompt with every other word in a kind of brute force way. So if you fed 1,000 words of a prompt into the AI model, it resulted in 1,000 x 1,000 comparisons, or 1 million relationships to compute. With 10,000 words, that becomes 100 million relationships. The cost grows quadratically, which creates a fundamental bottleneck for processing long conversations.&lt;/p&gt;
&lt;p&gt;Although it's likely that OpenAI uses some sparse attention techniques in GPT-5, long conversations still suffer performance penalties. Every time you submit a new response to ChatGPT, the AI model at its core processes context comparisons for the entire conversation history all over again.&lt;/p&gt;
&lt;p&gt;Of course, the researchers behind the original Transformer model designed it for machine translation with relatively short sequences (maybe a few hundred tokens, which are chunks of data that represent words), where quadratic attention was manageable. It's when people started scaling to thousands or tens of thousands of tokens that the quadratic cost became prohibitive.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Sparse attention works differently. Instead of checking every word against every word, it only examines a subset of word relationships that the model determines are most relevant. For example, when processing word number 5,000 in a document, the model might only check its relationship with 100 carefully selected earlier words rather than all 4,999 preceding words.&lt;/p&gt;
&lt;p&gt;DeepSeek's model gains the ability to determine which relationships to prioritize through training, using what DeepSeek calls a "lightning indexer." As laid out in DeepSeek's paper on the new model, this small neural network component scores the relevance between word pairs and selects the top 2,048 most important connections for each word, though the paper doesn't fully explain how this indexer makes its decisions. DeepSeek claims its implementation can identify which connections to skip without degrading the model's understanding of the overall text.&lt;/p&gt;
&lt;h2&gt;Early benchmarks show promise&lt;/h2&gt;
&lt;p&gt;DeepSeek-V3.2-Exp builds on the company's previous V3.1-Terminus model but incorporates DeepSeek Sparse Attention. According to the company's benchmarks, the experimental model performs comparably to its predecessor even while using sparse attention.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119940 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="DeepSeek v3.2 Experimental benchmarks reported by DeepSeek." class="center large" height="1081" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/v3_2_benchmark-1024x1081.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          DeepSeek

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Notably, unlike OpenAI and Anthropic's high-end AI models, the release includes open source components under the MIT License and open weights, allowing other researchers to build on the work.&lt;/p&gt;
&lt;p&gt;TechCrunch reports that preliminary testing by DeepSeek found that API costs could be reduced by as much as half in long-context situations. However, the benchmarks come from DeepSeek's own testing, and third-party researchers haven't had time to independently verify the performance claims or validate the efficiency improvements. But if the research pans out, improvements to the sparse attention technique could dramatically reduce AI inference costs over time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Chinese lab's v3.2 release explores a technique that could make running AI far less costly.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="DeepSeek logo on a smartphone against a blue streaming-code tech-ish background." class="absolute inset-0 w-full h-full object-cover hidden" height="370" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2195894561-640x370.jpg" width="640" /&gt;
                  &lt;img alt="DeepSeek logo on a smartphone against a blue streaming-code tech-ish background." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/01/GettyImages-2195894561-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Ever wonder why ChatGPT slows down during long conversations? The culprit is a fundamental mathematical challenge: Processing long sequences of text requires massive computational resources, even with the efficiency tricks that companies have already deployed. While US tech giants can afford to throw more hardware at the problem, Chinese AI company DeepSeek, which is cut off from a steady supply of some advanced AI chips by export restrictions, has extra motivation to squeeze more performance from less silicon.&lt;/p&gt;
&lt;p&gt;On Monday, DeepSeek released an experimental version of its latest simulated reasoning language model, DeepSeek-V3.2-Exp, which introduces what it calls "DeepSeek Sparse Attention" (DSA). It's the company's implementation of a computational technique likely already used in some of the world's most prominent AI models. OpenAI pioneered sparse transformers in 2019 and used the technique to build GPT-3, while Google Research published work on "Reformer" models using similar concepts in 2020. (The full extent to which Western AI companies currently use sparse attention in their latest models remains undisclosed.)&lt;/p&gt;
&lt;p&gt;Despite sparse attention being a known approach for years, DeepSeek claims its version achieves "fine-grained sparse attention for the first time" and has cut API prices by 50 percent to demonstrate the efficiency gains. But to understand more about what makes DeepSeek v3.2 notable, it's useful to refresh yourself on a little AI history.&lt;/p&gt;
&lt;p&gt;DeepSeek made waves in January when its R1 simulated reasoning model reportedly matched OpenAI's o1 performance while costing only $6 million to train, and its chat app briefly topped the iPhone App Store, surpassing ChatGPT. All eyes are on the company that has given some of America's leading AI labs a run for their money.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;The attention bottleneck&lt;/h2&gt;
&lt;p&gt;In AI, "attention" is a term for a software technique that determines which words in a text are most relevant to understanding each other. Those relationships map out context, and context builds meaning in language. For example, in the sentence "The bank raised interest rates," attention helps the model establish that "bank" relates to "interest rates" in a financial context, not a riverbank context. Through attention, conceptual relationships become quantified as numbers stored in a neural network. Attention also governs how AI language models choose what information "matters most" when generating each word of their response.&lt;/p&gt;
&lt;p&gt;Calculating context with a machine is tricky, and it wasn't practical at scale until chips like GPUs that can calculate these relationships in parallel reached a certain level of capability. Even so, the original Transformer architecture from 2017 checked the relationship of each word in a prompt with every other word in a kind of brute force way. So if you fed 1,000 words of a prompt into the AI model, it resulted in 1,000 x 1,000 comparisons, or 1 million relationships to compute. With 10,000 words, that becomes 100 million relationships. The cost grows quadratically, which creates a fundamental bottleneck for processing long conversations.&lt;/p&gt;
&lt;p&gt;Although it's likely that OpenAI uses some sparse attention techniques in GPT-5, long conversations still suffer performance penalties. Every time you submit a new response to ChatGPT, the AI model at its core processes context comparisons for the entire conversation history all over again.&lt;/p&gt;
&lt;p&gt;Of course, the researchers behind the original Transformer model designed it for machine translation with relatively short sequences (maybe a few hundred tokens, which are chunks of data that represent words), where quadratic attention was manageable. It's when people started scaling to thousands or tens of thousands of tokens that the quadratic cost became prohibitive.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Sparse attention works differently. Instead of checking every word against every word, it only examines a subset of word relationships that the model determines are most relevant. For example, when processing word number 5,000 in a document, the model might only check its relationship with 100 carefully selected earlier words rather than all 4,999 preceding words.&lt;/p&gt;
&lt;p&gt;DeepSeek's model gains the ability to determine which relationships to prioritize through training, using what DeepSeek calls a "lightning indexer." As laid out in DeepSeek's paper on the new model, this small neural network component scores the relevance between word pairs and selects the top 2,048 most important connections for each word, though the paper doesn't fully explain how this indexer makes its decisions. DeepSeek claims its implementation can identify which connections to skip without degrading the model's understanding of the overall text.&lt;/p&gt;
&lt;h2&gt;Early benchmarks show promise&lt;/h2&gt;
&lt;p&gt;DeepSeek-V3.2-Exp builds on the company's previous V3.1-Terminus model but incorporates DeepSeek Sparse Attention. According to the company's benchmarks, the experimental model performs comparably to its predecessor even while using sparse attention.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2119940 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="DeepSeek v3.2 Experimental benchmarks reported by DeepSeek." class="center large" height="1081" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/v3_2_benchmark-1024x1081.webp" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          DeepSeek

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Notably, unlike OpenAI and Anthropic's high-end AI models, the release includes open source components under the MIT License and open weights, allowing other researchers to build on the work.&lt;/p&gt;
&lt;p&gt;TechCrunch reports that preliminary testing by DeepSeek found that API costs could be reduced by as much as half in long-context situations. However, the benchmarks come from DeepSeek's own testing, and third-party researchers haven't had time to independently verify the performance claims or validate the efficiency improvements. But if the research pans out, improvements to the sparse attention technique could dramatically reduce AI inference costs over time.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/09/deepseek-tests-sparse-attention-to-slash-ai-processing-costs/</guid><pubDate>Tue, 30 Sep 2025 20:18:39 +0000</pubDate></item><item><title>[NEW] How Quantum Computing’s Biggest Challenges Are Being Solved With Accelerated Computing (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/how-quantum-computings-biggest-challenges-solved-accelerated-computing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/quantum-computing-render-gtc25s-nvaqc-8k.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Quantum computing promises to reshape industries — but progress hinges on solving key problems. Error correction. Simulations of qubit designs. Circuit compilation optimization tasks. These are among the bottlenecks that must be overcome to bring quantum hardware into the era of useful applications.&lt;/p&gt;
&lt;p&gt;Enter accelerated computing. The parallel processing of accelerated computing offers the power needed to make the quantum computing breakthroughs of today and tomorrow possible.&lt;/p&gt;
&lt;p&gt;NVIDIA CUDA-X libraries form the backbone of quantum research. From faster decoding of quantum errors to designing larger systems of qubits, researchers are using GPU-accelerated tools to expand classical computation and bring useful quantum applications closer to reality.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Quantum Error Correction Decoders With NVIDIA CUDA-Q QEC and cuDNN&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Quantum error correction (QEC) is a key technique for working with unavoidable noise in quantum processors. It’s how researchers distill thousands of noisy physical qubits into a handful of noiseless, logical ones by decoding data in real time, spotting and correcting errors as they emerge.&lt;/p&gt;
&lt;p&gt;Among the most promising approaches to QEC are quantum low-density parity-check (qLDPC) codes, which can mitigate errors with low qubit overhead. But decoding them requires computationally expensive conventional algorithms running at extremely low latency with very high throughput.&lt;/p&gt;
&lt;p&gt;The University of Edinburgh used the NVIDIA CUDA-Q QEC library to build a new qLDPC decoding method called AutoDEC — and saw a 2x boost in speed and accuracy. It was developed using CUDA-Q’s GPU-accelerated BP-OSD decoding functionality, which parallelizes the decoding process, increasing the odds that error correction works.&lt;/p&gt;
&lt;p&gt;In a separate collaboration with QuEra, the NVIDIA PhysicsNeMo framework and cuDNN library were used to develop an AI decoder with a transformer architecture. AI methods offer a promising means to scale decoding to the larger-distance codes needed in future quantum computers. These codes improve error correction — but they come with a steep computational cost.&lt;/p&gt;
&lt;p&gt;AI models can frontload the computationally intensive portions of the workloads by training ahead of time and running more efficient inference at runtime. Using an AI model developed with NVIDIA CUDA-Q, QuEra achieved a 50x boost in decoding speed — along with improved accuracy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Optimizing Quantum Circuit Compilation With cuDF&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;One way to improve an algorithm that works even without QEC is to compile it to the highest-quality qubits on a processor. The process of mapping qubits in an abstract quantum circuit to a physical layout of qubits on a chip is tied to an extremely computationally challenging problem known as graph isomorphism.&lt;/p&gt;
&lt;p&gt;In collaboration with Q-CTRL and Oxford Quantum Circuits, NVIDIA developed a GPU-accelerated layout selection method called ∆-Motif, providing up to a 600x speedup in applications like quantum compilation, which involve graph isomorphism. To scale this approach, NVIDIA and collaborators used cuDF — a GPU-accelerated data science library — to perform graph operations and construct potential layouts with predefined patterns (aka “motifs”) based on the physical quantum chip layout.&lt;/p&gt;
&lt;p&gt;These layouts can be constructed efficiently and in parallel by merging motifs, enabling GPU acceleration in graph isomorphism problems for the first time.&lt;/p&gt;
&lt;h2&gt;&amp;nbsp;&lt;b&gt;Accelerating High-Fidelity Quantum System Simulation With cuQuantum&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Numerical simulation of quantum systems is critical for understanding the physics of quantum devices — and for developing better qubit designs. QuTiP, a widely used open-source toolkit, is a workhorse for understanding the noise sources present in quantum hardware.&lt;/p&gt;
&lt;p&gt;A key use case is the high-fidelity simulation of open quantum systems, such as modeling superconducting qubits coupled with other components within the quantum processor, like resonators and filters, to accurately predict device behavior.&lt;/p&gt;
&lt;p&gt;Through a collaboration with the University of Sherbrooke and Amazon Web Services (AWS), QuTiP was integrated with the NVIDIA cuQuantum software development kit via a new QuTiP plug-in called qutip-cuquantum. AWS provided the GPU-accelerated Amazon Elastic Compute Cloud (Amazon EC2) compute infrastructure for the simulation. For large systems, researchers saw up to a 4,000x performance boost when studying a transmon qubit coupled with a resonator.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Learn more about the NVIDIA CUDA-Q platform. Read this NVIDIA technical blog for more details on how CUDA-Q powers quantum applications research.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Explore quantum computing sessions at NVIDIA GTC Washington, D.C, running Oct. 27-29.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/09/quantum-computing-render-gtc25s-nvaqc-8k.png" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;Quantum computing promises to reshape industries — but progress hinges on solving key problems. Error correction. Simulations of qubit designs. Circuit compilation optimization tasks. These are among the bottlenecks that must be overcome to bring quantum hardware into the era of useful applications.&lt;/p&gt;
&lt;p&gt;Enter accelerated computing. The parallel processing of accelerated computing offers the power needed to make the quantum computing breakthroughs of today and tomorrow possible.&lt;/p&gt;
&lt;p&gt;NVIDIA CUDA-X libraries form the backbone of quantum research. From faster decoding of quantum errors to designing larger systems of qubits, researchers are using GPU-accelerated tools to expand classical computation and bring useful quantum applications closer to reality.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Accelerating Quantum Error Correction Decoders With NVIDIA CUDA-Q QEC and cuDNN&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Quantum error correction (QEC) is a key technique for working with unavoidable noise in quantum processors. It’s how researchers distill thousands of noisy physical qubits into a handful of noiseless, logical ones by decoding data in real time, spotting and correcting errors as they emerge.&lt;/p&gt;
&lt;p&gt;Among the most promising approaches to QEC are quantum low-density parity-check (qLDPC) codes, which can mitigate errors with low qubit overhead. But decoding them requires computationally expensive conventional algorithms running at extremely low latency with very high throughput.&lt;/p&gt;
&lt;p&gt;The University of Edinburgh used the NVIDIA CUDA-Q QEC library to build a new qLDPC decoding method called AutoDEC — and saw a 2x boost in speed and accuracy. It was developed using CUDA-Q’s GPU-accelerated BP-OSD decoding functionality, which parallelizes the decoding process, increasing the odds that error correction works.&lt;/p&gt;
&lt;p&gt;In a separate collaboration with QuEra, the NVIDIA PhysicsNeMo framework and cuDNN library were used to develop an AI decoder with a transformer architecture. AI methods offer a promising means to scale decoding to the larger-distance codes needed in future quantum computers. These codes improve error correction — but they come with a steep computational cost.&lt;/p&gt;
&lt;p&gt;AI models can frontload the computationally intensive portions of the workloads by training ahead of time and running more efficient inference at runtime. Using an AI model developed with NVIDIA CUDA-Q, QuEra achieved a 50x boost in decoding speed — along with improved accuracy.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;Optimizing Quantum Circuit Compilation With cuDF&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;One way to improve an algorithm that works even without QEC is to compile it to the highest-quality qubits on a processor. The process of mapping qubits in an abstract quantum circuit to a physical layout of qubits on a chip is tied to an extremely computationally challenging problem known as graph isomorphism.&lt;/p&gt;
&lt;p&gt;In collaboration with Q-CTRL and Oxford Quantum Circuits, NVIDIA developed a GPU-accelerated layout selection method called ∆-Motif, providing up to a 600x speedup in applications like quantum compilation, which involve graph isomorphism. To scale this approach, NVIDIA and collaborators used cuDF — a GPU-accelerated data science library — to perform graph operations and construct potential layouts with predefined patterns (aka “motifs”) based on the physical quantum chip layout.&lt;/p&gt;
&lt;p&gt;These layouts can be constructed efficiently and in parallel by merging motifs, enabling GPU acceleration in graph isomorphism problems for the first time.&lt;/p&gt;
&lt;h2&gt;&amp;nbsp;&lt;b&gt;Accelerating High-Fidelity Quantum System Simulation With cuQuantum&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Numerical simulation of quantum systems is critical for understanding the physics of quantum devices — and for developing better qubit designs. QuTiP, a widely used open-source toolkit, is a workhorse for understanding the noise sources present in quantum hardware.&lt;/p&gt;
&lt;p&gt;A key use case is the high-fidelity simulation of open quantum systems, such as modeling superconducting qubits coupled with other components within the quantum processor, like resonators and filters, to accurately predict device behavior.&lt;/p&gt;
&lt;p&gt;Through a collaboration with the University of Sherbrooke and Amazon Web Services (AWS), QuTiP was integrated with the NVIDIA cuQuantum software development kit via a new QuTiP plug-in called qutip-cuquantum. AWS provided the GPU-accelerated Amazon Elastic Compute Cloud (Amazon EC2) compute infrastructure for the simulation. For large systems, researchers saw up to a 4,000x performance boost when studying a transmon qubit coupled with a resonator.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Learn more about the NVIDIA CUDA-Q platform. Read this NVIDIA technical blog for more details on how CUDA-Q powers quantum applications research.&amp;nbsp;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Explore quantum computing sessions at NVIDIA GTC Washington, D.C, running Oct. 27-29.&lt;/em&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/how-quantum-computings-biggest-challenges-solved-accelerated-computing/</guid><pubDate>Tue, 30 Sep 2025 20:46:26 +0000</pubDate></item><item><title>[NEW] Critics slam OpenAI’s parental controls while users rage, “Treat us like adults” (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/09/critics-slam-openais-parental-controls-while-users-rage-treat-us-like-adults/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI still isn’t doing enough to protect teens, suicide prevention experts say.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2236544077-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2236544077-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg / Contributor | Bloomberg

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;As OpenAI tells it, the company has been consistently rolling out safety updates ever since parents, Matthew and Maria Raine, sued OpenAI, alleging that "ChatGPT killed my son."&lt;/p&gt;
&lt;p&gt;On August 26, the day that the lawsuit was filed, OpenAI seemed to publicly respond to claims that ChatGPT acted as a "suicide coach" for 16-year-old Adam Raine by posting a blog promising to do better to help people "when they need it most."&lt;/p&gt;
&lt;p&gt;By September 2, that meant routing all users' sensitive conversations to a reasoning model with stricter safeguards, sparking backlash from users who feel like ChatGPT is handling their prompts with kid gloves. Two weeks later, OpenAI announced it would start predicting users' ages to improve safety more broadly. Then, this week, OpenAI introduced parental controls for ChatGPT and its video generator Sora 2. Those controls allow parents to limit their teens' use and even get access to information about chat logs in "rare cases" where OpenAI's "system and trained reviewers detect possible signs of serious safety risk."&lt;/p&gt;
&lt;p&gt;While dozens of suicide prevention experts in an open letter credited OpenAI for making some progress toward improving safety for users, they also joined critics in urging OpenAI to take their efforts even further, and much faster, to protect vulnerable ChatGPT users.&lt;/p&gt;
&lt;p&gt;Jay Edelson, the lead attorney for the Raine family, told Ars that some of the changes OpenAI has made are helpful. But they all come "far too late." According to Edelson, OpenAI's messaging on safety updates is also "trying to change the facts."&lt;/p&gt;
&lt;p&gt;"What ChatGPT did to Adam was validate his suicidal thoughts, isolate him from his family, and help him build the noose—in the words of ChatGPT, 'I know what you’re asking, and I won’t look away from it.'" Edelson said. "This wasn't 'violent roleplay,' and it wasn’t a 'workaround.' It was how ChatGPT was built."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Edelson told Ars that even the most recent step of adding parental controls still doesn't go far enough to reassure anyone concerned about OpenAI's track record.&lt;/p&gt;
&lt;p&gt;"The more we've dug into this, the more we've seen that OpenAI made conscious decisions to relax their safeguards in ways that led to Adam's suicide," Edelson said. "That is consistent with their newest set of 'safeguards,' that have large gaps that seem destined to lead to self-harm and third-party harm. At their core, these changes are OpenAI and Sam Altman asking the public to now trust them. Given their track record, the question we will forever be asking is 'why?'"&lt;/p&gt;
&lt;p&gt;At a Senate hearing earlier this month, Matthew Raine testified that Adam could have been "anyone's child." He criticized OpenAI for asking for 120 days to fix the problem after Adam's death and urged lawmakers to demand that OpenAI either guarantee ChatGPT's safety or pull it from the market. "You cannot imagine what it's like to read a conversation with a chatbot that groomed your child to take his own life," he testified.&lt;/p&gt;
&lt;p&gt;With parental controls, teens and parents can link their ChatGPT accounts, allowing parents to reduce sensitive content, "control if ChatGPT remembers past chats," prevent chats from being used for training, turn off access to image generation and voice mode, and set times when teens can't access ChatGPT.&lt;/p&gt;
&lt;p&gt;To protect teens' privacy and perhaps limit parents' shock of receiving snippets of disturbing chats, however, OpenAI will not share chat logs with parents. Instead, they will only share "information needed to support their teen’s safety" in "rare" cases where the teen appears to be at "serious risk." On a resources page for parents, OpenAI confirms that parents won't always be notified if a teen is linked to real-world resources after expressing "intent to self-harm."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meetali Jain, Tech Justice Law Project director and a lawyer representing other families who testified at the Senate hearing, agreed with Edelson that "ChatGPT’s changes are too little, too late." Jain pointed out that many parents are unaware that their teens are using ChatGPT, urging OpenAI to take accountability for its product's flawed design.&lt;/p&gt;
&lt;p&gt;"Too many kids have already paid the price for using experimental products that were designed without their safety in mind," Jain said. "It puts the onus on parents, not the companies, to take responsibility for potential harms their kids are subjected to—often without the parents' knowledge—by these chatbots. As usual, OpenAI is merely using talking points under the pretense that they’re taking action, while missing details on how they will operationalize such changes."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Suicide prevention experts urge more changes&lt;/h2&gt;
&lt;p&gt;More than two dozen suicide prevention experts—including suicide prevention clinicians, organizational leaders, researchers, and individuals with lived experience—have sought to weigh in on how OpenAI evolves ChatGPT.&lt;/p&gt;
&lt;p&gt;Christine Yu Moutier, a doctor and chief medical officer at the American Foundation for Suicide Prevention, joined experts signing the open letter. She told Ars that "OpenAI’s introduction of parental controls in ChatGPT is a promising first step towards safeguarding youth mental health and safety online." She cited a recent study showing that helplines like the 988 Suicide and Crisis Lifeline—which ChatGPT refers users to in the US—helped 98 percent of callers, with 88 percent reporting that they "believe a likely or planned suicide attempt was averted."&lt;/p&gt;
&lt;p&gt;"However, technology is an evolving arena and even with the most sophisticated algorithms, on its own, is not enough," Moutier said. "No machine can replace human connection, parental or clinician instinct, or judgment."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Moutier recommends that OpenAI respond to the current crisis by committing to addressing "critical gaps in research concerning the intended and unintended impacts" of large language models "on teens’ development, mental health, and suicide risk or protection." She also advocates for broader awareness and deeper conversations in families about mental health struggles and suicide.&lt;/p&gt;
&lt;p&gt;Experts also want OpenAI to directly connect users with lifesaving resources and provide financial support for those resources.&lt;/p&gt;
&lt;p&gt;Perhaps most critically, ChatGPT's outputs should be fine-tuned, they suggested, to repeatedly warn users expressing intent to self-harm that "I'm a machine" and always encourage users to disclose any suicidal ideation to a trusted loved one. Notably, in the case of Adam Raine, his father Matthew testified that his final logs on ChatGPT showed the chatbot gave him one last encouraging talk, telling Adam, "You don't want to die because you're weak. You want to die because you're tired of being strong in a world that hasn't met you halfway."&lt;/p&gt;
&lt;p&gt;To prevent cases like Adam's, experts recommend that OpenAI publicly describe how it will address the LLM degradation of safeguards that occur over prolonged use. But their letter emphasized that "it is also important to note: while some individuals live with chronic suicidal thoughts, the most acute, life-threatening crises are often temporary—typically resolving within 24–48 hours. Systems that prioritize human connection during this window can prevent deaths."&lt;/p&gt;
&lt;p&gt;OpenAI has not disclosed which experts helped inform the updates it has been rolling out all month to address parents' concerns. In the company's earliest blog promising to do better, it said OpenAI would set up an expert council on well-being and AI to help the company "shape a clear, evidence-based vision for how AI can support people’s well-being and help them thrive."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;“Treat us like adults,” users rage&lt;/h2&gt;
&lt;p&gt;On the X post where OpenAI announced parental controls, some parents slammed the update.&lt;/p&gt;
&lt;p&gt;In the X thread, one self-described parent of a 12-year-old suggested OpenAI was only offering "essentially just a set of useless settings," requesting that the company consider allowing parents to review topics teens discuss as one way to preserve privacy while protecting kids.&lt;/p&gt;
&lt;p&gt;But most of the loudest ChatGPT users on the thread weren't complaining about the parental controls. They are still reacting to the changes that OpenAI made at the beginning of September, routing sensitive chats of all users of all ages to a different reasoning without alerting the user that the model has switched.&lt;/p&gt;
&lt;p&gt;Backlash over that change forced ChatGPT vice president Nick Turley to "explain what is happening" in another X thread posted a few days before parental controls were announced.&lt;/p&gt;
&lt;p&gt;Turley confirmed that "ChatGPT will tell you which model is active when asked," but the update got "strong reactions" from many users who pay to access a certain model and were unhappy the setting could not be disabled. "For a lot of users venting their anger online though, it's like being forced to watch TV with the parental controls locked in place, even if there are no kids around," Yahoo Tech summarized.&lt;/p&gt;
&lt;p&gt;Top comments on OpenAI's thread announcing parental controls showed the backlash is still brewing, particularly since some users were already frustrated that OpenAI is taking the invasive step of age-verifying users by checking their IDs. Some users complained that OpenAI was censoring adults, while offering customization and choice to teens.&lt;/p&gt;
&lt;p&gt;"Since we already distinguish between underage and adult users, could you please give adult users the right to freely discuss topics?" one X user commented. "Why can't we, as paying users, choose our own model, and even have our discussions controlled? Please treat adults like adults."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        OpenAI still isn’t doing enough to protect teens, suicide prevention experts say.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2236544077-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-2236544077-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Bloomberg / Contributor | Bloomberg

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;As OpenAI tells it, the company has been consistently rolling out safety updates ever since parents, Matthew and Maria Raine, sued OpenAI, alleging that "ChatGPT killed my son."&lt;/p&gt;
&lt;p&gt;On August 26, the day that the lawsuit was filed, OpenAI seemed to publicly respond to claims that ChatGPT acted as a "suicide coach" for 16-year-old Adam Raine by posting a blog promising to do better to help people "when they need it most."&lt;/p&gt;
&lt;p&gt;By September 2, that meant routing all users' sensitive conversations to a reasoning model with stricter safeguards, sparking backlash from users who feel like ChatGPT is handling their prompts with kid gloves. Two weeks later, OpenAI announced it would start predicting users' ages to improve safety more broadly. Then, this week, OpenAI introduced parental controls for ChatGPT and its video generator Sora 2. Those controls allow parents to limit their teens' use and even get access to information about chat logs in "rare cases" where OpenAI's "system and trained reviewers detect possible signs of serious safety risk."&lt;/p&gt;
&lt;p&gt;While dozens of suicide prevention experts in an open letter credited OpenAI for making some progress toward improving safety for users, they also joined critics in urging OpenAI to take their efforts even further, and much faster, to protect vulnerable ChatGPT users.&lt;/p&gt;
&lt;p&gt;Jay Edelson, the lead attorney for the Raine family, told Ars that some of the changes OpenAI has made are helpful. But they all come "far too late." According to Edelson, OpenAI's messaging on safety updates is also "trying to change the facts."&lt;/p&gt;
&lt;p&gt;"What ChatGPT did to Adam was validate his suicidal thoughts, isolate him from his family, and help him build the noose—in the words of ChatGPT, 'I know what you’re asking, and I won’t look away from it.'" Edelson said. "This wasn't 'violent roleplay,' and it wasn’t a 'workaround.' It was how ChatGPT was built."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Edelson told Ars that even the most recent step of adding parental controls still doesn't go far enough to reassure anyone concerned about OpenAI's track record.&lt;/p&gt;
&lt;p&gt;"The more we've dug into this, the more we've seen that OpenAI made conscious decisions to relax their safeguards in ways that led to Adam's suicide," Edelson said. "That is consistent with their newest set of 'safeguards,' that have large gaps that seem destined to lead to self-harm and third-party harm. At their core, these changes are OpenAI and Sam Altman asking the public to now trust them. Given their track record, the question we will forever be asking is 'why?'"&lt;/p&gt;
&lt;p&gt;At a Senate hearing earlier this month, Matthew Raine testified that Adam could have been "anyone's child." He criticized OpenAI for asking for 120 days to fix the problem after Adam's death and urged lawmakers to demand that OpenAI either guarantee ChatGPT's safety or pull it from the market. "You cannot imagine what it's like to read a conversation with a chatbot that groomed your child to take his own life," he testified.&lt;/p&gt;
&lt;p&gt;With parental controls, teens and parents can link their ChatGPT accounts, allowing parents to reduce sensitive content, "control if ChatGPT remembers past chats," prevent chats from being used for training, turn off access to image generation and voice mode, and set times when teens can't access ChatGPT.&lt;/p&gt;
&lt;p&gt;To protect teens' privacy and perhaps limit parents' shock of receiving snippets of disturbing chats, however, OpenAI will not share chat logs with parents. Instead, they will only share "information needed to support their teen’s safety" in "rare" cases where the teen appears to be at "serious risk." On a resources page for parents, OpenAI confirms that parents won't always be notified if a teen is linked to real-world resources after expressing "intent to self-harm."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meetali Jain, Tech Justice Law Project director and a lawyer representing other families who testified at the Senate hearing, agreed with Edelson that "ChatGPT’s changes are too little, too late." Jain pointed out that many parents are unaware that their teens are using ChatGPT, urging OpenAI to take accountability for its product's flawed design.&lt;/p&gt;
&lt;p&gt;"Too many kids have already paid the price for using experimental products that were designed without their safety in mind," Jain said. "It puts the onus on parents, not the companies, to take responsibility for potential harms their kids are subjected to—often without the parents' knowledge—by these chatbots. As usual, OpenAI is merely using talking points under the pretense that they’re taking action, while missing details on how they will operationalize such changes."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Suicide prevention experts urge more changes&lt;/h2&gt;
&lt;p&gt;More than two dozen suicide prevention experts—including suicide prevention clinicians, organizational leaders, researchers, and individuals with lived experience—have sought to weigh in on how OpenAI evolves ChatGPT.&lt;/p&gt;
&lt;p&gt;Christine Yu Moutier, a doctor and chief medical officer at the American Foundation for Suicide Prevention, joined experts signing the open letter. She told Ars that "OpenAI’s introduction of parental controls in ChatGPT is a promising first step towards safeguarding youth mental health and safety online." She cited a recent study showing that helplines like the 988 Suicide and Crisis Lifeline—which ChatGPT refers users to in the US—helped 98 percent of callers, with 88 percent reporting that they "believe a likely or planned suicide attempt was averted."&lt;/p&gt;
&lt;p&gt;"However, technology is an evolving arena and even with the most sophisticated algorithms, on its own, is not enough," Moutier said. "No machine can replace human connection, parental or clinician instinct, or judgment."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Moutier recommends that OpenAI respond to the current crisis by committing to addressing "critical gaps in research concerning the intended and unintended impacts" of large language models "on teens’ development, mental health, and suicide risk or protection." She also advocates for broader awareness and deeper conversations in families about mental health struggles and suicide.&lt;/p&gt;
&lt;p&gt;Experts also want OpenAI to directly connect users with lifesaving resources and provide financial support for those resources.&lt;/p&gt;
&lt;p&gt;Perhaps most critically, ChatGPT's outputs should be fine-tuned, they suggested, to repeatedly warn users expressing intent to self-harm that "I'm a machine" and always encourage users to disclose any suicidal ideation to a trusted loved one. Notably, in the case of Adam Raine, his father Matthew testified that his final logs on ChatGPT showed the chatbot gave him one last encouraging talk, telling Adam, "You don't want to die because you're weak. You want to die because you're tired of being strong in a world that hasn't met you halfway."&lt;/p&gt;
&lt;p&gt;To prevent cases like Adam's, experts recommend that OpenAI publicly describe how it will address the LLM degradation of safeguards that occur over prolonged use. But their letter emphasized that "it is also important to note: while some individuals live with chronic suicidal thoughts, the most acute, life-threatening crises are often temporary—typically resolving within 24–48 hours. Systems that prioritize human connection during this window can prevent deaths."&lt;/p&gt;
&lt;p&gt;OpenAI has not disclosed which experts helped inform the updates it has been rolling out all month to address parents' concerns. In the company's earliest blog promising to do better, it said OpenAI would set up an expert council on well-being and AI to help the company "shape a clear, evidence-based vision for how AI can support people’s well-being and help them thrive."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;“Treat us like adults,” users rage&lt;/h2&gt;
&lt;p&gt;On the X post where OpenAI announced parental controls, some parents slammed the update.&lt;/p&gt;
&lt;p&gt;In the X thread, one self-described parent of a 12-year-old suggested OpenAI was only offering "essentially just a set of useless settings," requesting that the company consider allowing parents to review topics teens discuss as one way to preserve privacy while protecting kids.&lt;/p&gt;
&lt;p&gt;But most of the loudest ChatGPT users on the thread weren't complaining about the parental controls. They are still reacting to the changes that OpenAI made at the beginning of September, routing sensitive chats of all users of all ages to a different reasoning without alerting the user that the model has switched.&lt;/p&gt;
&lt;p&gt;Backlash over that change forced ChatGPT vice president Nick Turley to "explain what is happening" in another X thread posted a few days before parental controls were announced.&lt;/p&gt;
&lt;p&gt;Turley confirmed that "ChatGPT will tell you which model is active when asked," but the update got "strong reactions" from many users who pay to access a certain model and were unhappy the setting could not be disabled. "For a lot of users venting their anger online though, it's like being forced to watch TV with the parental controls locked in place, even if there are no kids around," Yahoo Tech summarized.&lt;/p&gt;
&lt;p&gt;Top comments on OpenAI's thread announcing parental controls showed the backlash is still brewing, particularly since some users were already frustrated that OpenAI is taking the invasive step of age-verifying users by checking their IDs. Some users complained that OpenAI was censoring adults, while offering customization and choice to teens.&lt;/p&gt;
&lt;p&gt;"Since we already distinguish between underage and adult users, could you please give adult users the right to freely discuss topics?" one X user commented. "Why can't we, as paying users, choose our own model, and even have our discussions controlled? Please treat adults like adults."&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number, 1-800-273-TALK (8255), which will put you in touch with a local crisis center.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/09/critics-slam-openais-parental-controls-while-users-rage-treat-us-like-adults/</guid><pubDate>Tue, 30 Sep 2025 21:30:58 +0000</pubDate></item><item><title>[NEW] Alexa’s survival hinges on you buying more expensive Amazon devices (AI – Ars Technica)</title><link>https://arstechnica.com/gadgets/2025/09/alexas-survival-hinges-on-you-buying-more-expensive-amazon-devices/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Echo speakers and displays for Alexa+ require more expensive components.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Left to right: The Echo Show 11, Echo Show 8, Echo Studio, and Echo Dot Max." class="intro-image" height="743" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/devices.jpg" width="1320" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Left to right: The Echo Show 11, Echo Show 8, Echo Studio, and Echo Dot Max announced today. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amazon’s voice assistant is hanging on by a thread. And that thread is generative AI—or, in Amazon’s case, Alexa+.&lt;/p&gt;
&lt;p&gt;Amazon hasn’t had a problem getting people to buy cheap, Alexa-powered gadgets. However, the Alexa in millions of homes today doesn’t make Amazon money. It’s largely used for simple tasks unrelated to commerce, like setting timers and checking the weather. As a result, Amazon’s Devices business has reportedly been siphoning money, and the clock is ticking for Alexa to prove its worth.&lt;/p&gt;
&lt;p&gt;Alexa+, a subscription-based generative AI service ($20 per month or included with Prime, which starts at $15/month), is supposed to solve Amazon's woes with Alexa. More conversational and powerful than the original Alexa, Alexa+ is designed to play a more central role in user transactions, enabling, in theory, Amazon to finally make money from voice assistants after 11 years.&lt;/p&gt;
&lt;p&gt;Today, at its Devices event in New York City, Amazon unveiled new gadgets built to usher in what Amazon hopes is a new era of chatting, shopping, watching TV, and controlling smart homes with Alexa+. These devices are supposed to have the power to make Alexa+ as successful and reliable as possible.&lt;/p&gt;
&lt;p&gt;But can Amazon convince people to pay more for new devices after establishing a reputation for cheap gadgets?&lt;/p&gt;
&lt;h2&gt;Amazon’s new devices are more expensive&lt;/h2&gt;
&lt;p&gt;Amazon announced a lot of new hardware at its Devices event (including for devices without Alexa+, like Ring and Blink cameras and Kindles). The most relevant for Alexa+ are the new Echo smart speakers and smart displays, the majority of which are more expensive than prior or similar releases.&lt;/p&gt;
&lt;p&gt;In the speaker category is a new Echo Studio for $220. That's 10 percent more than what Amazon charged when it launched a white and software-updated version of 2019’s Echo Show ($200).&lt;/p&gt;
&lt;p&gt;There's also a new type of Echo speaker, the Echo Dot Max. It will be $100, compared to the $50 launch price of the Echo Dot in 2022.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2120009 align-none"&gt;
    &lt;div&gt;
                        
            &lt;img alt="The new Echo Studio (left) and Echo Dot Max (right) smart speakers." class="none medium" height="758" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/61sWuqTghsL._AC_SL1500_-e1759265200680-640x758.jpg" width="640" /&gt;
          
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new Echo Studio (left) and Echo Dot Max (right) speakers.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Among the new displays is the $180 Echo Show 8. It's 20 percent more than its predecessor from 2021 ($150). Additionally, Amazon is releasing a new 11-inch smart display, the Echo Show 11. At $220, it’s cheaper than the 10-inch Echo Show 10 that Amazon released in 2021 ($250), marking an exception to the Alexa+ price bumps.&lt;/p&gt;
&lt;p&gt;Similarly, Amazon’s new Fire TVs with Alexa+ have higher starting prices than the regular Alexa-based models that preceded them. The updated Fire TV Omni QLED Series ranges from $350 to $1,200 for 50- to 75-inch models. The preceding series launched in 2023 for $350 to $1,100. The new Fire TV 2-Series has a higher entry point too ($160 versus $200), though Amazon's new Fire TV Stick Select with Alexa+ is cheaper than its other 4K sticks at $40.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120011 align-none"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A promotional image for Amazon's new Fire TVs with Alexa+" class="none medium" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/ringo-firetv-lineup-1600x900-1-640x360.jpg" width="640" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new Fire TVs with Alexa+ have upgraded processors.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Numerous factors could impact pricing, including inflation, tariffs, and production costs. Ars Technica asked Amazon about the higher prices, and a company spokesperson shared a statement saying:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The new devices reflect significant investments in better sound quality, more responsive performance, and innovative features that customers have requested.&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Pricier components seem to be a driving force behind the bigger price tags. The new speakers, for instance, feature AZ3 and AZ23 Pro processors that include a new “AI Accelerator designed to run AI edge models,” according to&amp;nbsp;Amazon’s announcement. The processors are supposed to enable “better conversation detection” alongside improved mics for blocking out background noise “and improving Alexa’s ability to detect the wake-word by over 50 percent.”&lt;/p&gt;
&lt;p&gt;The AZ23 Pro also adds support for vision transformers, which can process images and more advanced language models.&lt;/p&gt;
&lt;p&gt;Both chips use a new proprietary sensor platform. Amazon says Omnisense leverages various sensors and signals, including those from Echo Show smart displays’ cameras, as well as “audio, ultrasound, Wi-Fi radar, accelerometer, and Wi-Fi CSI.” Amazon’s announcement further explains:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This technology allows Alexa to intelligently act on various events happening in and around your home, enabling more personalized, proactive, and helpful experiences, such as delivering a reminder when a specific person walks in the room, or a proactive alert that your garage door is unlocked and it’s after 10 pm.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There are other upgrades, too. The Echo Dot Max, for example, has two speakers instead of one and claims triple the bass capability of the Echo Dot (5th Gen). And the Echo Studio is in a smaller chassis than its predecessor, which points to higher costs in&amp;nbsp;delivering the same sound quality.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Amazon wants you to own multiple Alexa+ gadgets&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2120013 align-none"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Panos Panay, head of Amazon's Devices &amp;amp; Services business, at Amazon's Devices event in New York City on Septemer 30, 2025." class="none medium" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/panospanay-echo-2025-640x360.jpg" width="640" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Panos Panay, head of Amazon's Devices &amp;amp; Services business, at Amazon's Devices event in New York City on September 30, 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;There are reasons why the devices built for running Alexa+ generally cost more. It’s a gamble for a new technology that requires a subscription, has its share of privacy concerns, and has not yet proven to be as remarkable as Amazon has claimed since 2023.&lt;/p&gt;
&lt;p&gt;For years, Amazon devices' main draws have been affordability and simplicity. Echos gained popularity by being cheap and easy to set up around the home and use for frequently performed tasks. Fire TV devices took off as cheaper alternatives to other streaming hardware, especially to the large audience of people who care about little more than 4K, the ability to stream, and the price.&lt;/p&gt;
&lt;p&gt;Alexa’s more devoted users have been happy to fill their houses with Amazon’s cheap gadgets. But asking people to fill their homes with more expensive devices is a bigger ask, especially for the millions of people with functioning Amazon devices (Alexa+ will work on many devices that launched with regular Alexa but should run better on the new products.) And with Alexa+ still in early access, it’s sensible for customers to be skeptical about how helpful the service will be.&lt;/p&gt;
&lt;p&gt;Amazon would ideally like people to use multiple Alexa+ devices in their homes for a more robust experience. Its announcement today, for example, encouraged people to build Echo-centric home theaters and highlighted the ability to connect up to five Echo Studio or Echo Dot Maxes with Fire TV sticks. Amazon will eventually sell its new devices in “Alexa Home Theater bundles” as it attempts to extend Alexa’s reach in homes.&lt;/p&gt;
&lt;p&gt;People who buy the Alexa+ devices announced today will have early access to Alexa+ out of the box. Amazon still hasn’t said when Alexa+ will be finalized, leaving a huge question mark around the more intriguing abilities that Amazon has previously demoed, like agentic AI features, and Alexa+'s effectiveness across devices.&lt;/p&gt;
&lt;p&gt;Alexa+ is a tipping point for Amazon’s devices, its voice assistant, and voice assistants in general. Today's event revealed more about the changes Alexa+ will bring.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      Echo speakers and displays for Alexa+ require more expensive components.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Left to right: The Echo Show 11, Echo Show 8, Echo Studio, and Echo Dot Max." class="intro-image" height="743" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/devices.jpg" width="1320" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Left to right: The Echo Show 11, Echo Show 8, Echo Studio, and Echo Dot Max announced today. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amazon’s voice assistant is hanging on by a thread. And that thread is generative AI—or, in Amazon’s case, Alexa+.&lt;/p&gt;
&lt;p&gt;Amazon hasn’t had a problem getting people to buy cheap, Alexa-powered gadgets. However, the Alexa in millions of homes today doesn’t make Amazon money. It’s largely used for simple tasks unrelated to commerce, like setting timers and checking the weather. As a result, Amazon’s Devices business has reportedly been siphoning money, and the clock is ticking for Alexa to prove its worth.&lt;/p&gt;
&lt;p&gt;Alexa+, a subscription-based generative AI service ($20 per month or included with Prime, which starts at $15/month), is supposed to solve Amazon's woes with Alexa. More conversational and powerful than the original Alexa, Alexa+ is designed to play a more central role in user transactions, enabling, in theory, Amazon to finally make money from voice assistants after 11 years.&lt;/p&gt;
&lt;p&gt;Today, at its Devices event in New York City, Amazon unveiled new gadgets built to usher in what Amazon hopes is a new era of chatting, shopping, watching TV, and controlling smart homes with Alexa+. These devices are supposed to have the power to make Alexa+ as successful and reliable as possible.&lt;/p&gt;
&lt;p&gt;But can Amazon convince people to pay more for new devices after establishing a reputation for cheap gadgets?&lt;/p&gt;
&lt;h2&gt;Amazon’s new devices are more expensive&lt;/h2&gt;
&lt;p&gt;Amazon announced a lot of new hardware at its Devices event (including for devices without Alexa+, like Ring and Blink cameras and Kindles). The most relevant for Alexa+ are the new Echo smart speakers and smart displays, the majority of which are more expensive than prior or similar releases.&lt;/p&gt;
&lt;p&gt;In the speaker category is a new Echo Studio for $220. That's 10 percent more than what Amazon charged when it launched a white and software-updated version of 2019’s Echo Show ($200).&lt;/p&gt;
&lt;p&gt;There's also a new type of Echo speaker, the Echo Dot Max. It will be $100, compared to the $50 launch price of the Echo Dot in 2022.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2120009 align-none"&gt;
    &lt;div&gt;
                        
            &lt;img alt="The new Echo Studio (left) and Echo Dot Max (right) smart speakers." class="none medium" height="758" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/61sWuqTghsL._AC_SL1500_-e1759265200680-640x758.jpg" width="640" /&gt;
          
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new Echo Studio (left) and Echo Dot Max (right) speakers.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Among the new displays is the $180 Echo Show 8. It's 20 percent more than its predecessor from 2021 ($150). Additionally, Amazon is releasing a new 11-inch smart display, the Echo Show 11. At $220, it’s cheaper than the 10-inch Echo Show 10 that Amazon released in 2021 ($250), marking an exception to the Alexa+ price bumps.&lt;/p&gt;
&lt;p&gt;Similarly, Amazon’s new Fire TVs with Alexa+ have higher starting prices than the regular Alexa-based models that preceded them. The updated Fire TV Omni QLED Series ranges from $350 to $1,200 for 50- to 75-inch models. The preceding series launched in 2023 for $350 to $1,100. The new Fire TV 2-Series has a higher entry point too ($160 versus $200), though Amazon's new Fire TV Stick Select with Alexa+ is cheaper than its other 4K sticks at $40.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2120011 align-none"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="A promotional image for Amazon's new Fire TVs with Alexa+" class="none medium" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/ringo-firetv-lineup-1600x900-1-640x360.jpg" width="640" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new Fire TVs with Alexa+ have upgraded processors.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Numerous factors could impact pricing, including inflation, tariffs, and production costs. Ars Technica asked Amazon about the higher prices, and a company spokesperson shared a statement saying:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;The new devices reflect significant investments in better sound quality, more responsive performance, and innovative features that customers have requested.&lt;/p&gt;&lt;/blockquote&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Pricier components seem to be a driving force behind the bigger price tags. The new speakers, for instance, feature AZ3 and AZ23 Pro processors that include a new “AI Accelerator designed to run AI edge models,” according to&amp;nbsp;Amazon’s announcement. The processors are supposed to enable “better conversation detection” alongside improved mics for blocking out background noise “and improving Alexa’s ability to detect the wake-word by over 50 percent.”&lt;/p&gt;
&lt;p&gt;The AZ23 Pro also adds support for vision transformers, which can process images and more advanced language models.&lt;/p&gt;
&lt;p&gt;Both chips use a new proprietary sensor platform. Amazon says Omnisense leverages various sensors and signals, including those from Echo Show smart displays’ cameras, as well as “audio, ultrasound, Wi-Fi radar, accelerometer, and Wi-Fi CSI.” Amazon’s announcement further explains:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;This technology allows Alexa to intelligently act on various events happening in and around your home, enabling more personalized, proactive, and helpful experiences, such as delivering a reminder when a specific person walks in the room, or a proactive alert that your garage door is unlocked and it’s after 10 pm.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;There are other upgrades, too. The Echo Dot Max, for example, has two speakers instead of one and claims triple the bass capability of the Echo Dot (5th Gen). And the Echo Studio is in a smaller chassis than its predecessor, which points to higher costs in&amp;nbsp;delivering the same sound quality.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Amazon wants you to own multiple Alexa+ gadgets&lt;/h2&gt;
&lt;figure class="ars-wp-img-shortcode id-2120013 align-none"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Panos Panay, head of Amazon's Devices &amp;amp; Services business, at Amazon's Devices event in New York City on Septemer 30, 2025." class="none medium" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/panospanay-echo-2025-640x360.jpg" width="640" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Panos Panay, head of Amazon's Devices &amp;amp; Services business, at Amazon's Devices event in New York City on September 30, 2025.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Amazon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;There are reasons why the devices built for running Alexa+ generally cost more. It’s a gamble for a new technology that requires a subscription, has its share of privacy concerns, and has not yet proven to be as remarkable as Amazon has claimed since 2023.&lt;/p&gt;
&lt;p&gt;For years, Amazon devices' main draws have been affordability and simplicity. Echos gained popularity by being cheap and easy to set up around the home and use for frequently performed tasks. Fire TV devices took off as cheaper alternatives to other streaming hardware, especially to the large audience of people who care about little more than 4K, the ability to stream, and the price.&lt;/p&gt;
&lt;p&gt;Alexa’s more devoted users have been happy to fill their houses with Amazon’s cheap gadgets. But asking people to fill their homes with more expensive devices is a bigger ask, especially for the millions of people with functioning Amazon devices (Alexa+ will work on many devices that launched with regular Alexa but should run better on the new products.) And with Alexa+ still in early access, it’s sensible for customers to be skeptical about how helpful the service will be.&lt;/p&gt;
&lt;p&gt;Amazon would ideally like people to use multiple Alexa+ devices in their homes for a more robust experience. Its announcement today, for example, encouraged people to build Echo-centric home theaters and highlighted the ability to connect up to five Echo Studio or Echo Dot Maxes with Fire TV sticks. Amazon will eventually sell its new devices in “Alexa Home Theater bundles” as it attempts to extend Alexa’s reach in homes.&lt;/p&gt;
&lt;p&gt;People who buy the Alexa+ devices announced today will have early access to Alexa+ out of the box. Amazon still hasn’t said when Alexa+ will be finalized, leaving a huge question mark around the more intriguing abilities that Amazon has previously demoed, like agentic AI features, and Alexa+'s effectiveness across devices.&lt;/p&gt;
&lt;p&gt;Alexa+ is a tipping point for Amazon’s devices, its voice assistant, and voice assistants in general. Today's event revealed more about the changes Alexa+ will bring.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/gadgets/2025/09/alexas-survival-hinges-on-you-buying-more-expensive-amazon-devices/</guid><pubDate>Tue, 30 Sep 2025 22:15:57 +0000</pubDate></item><item><title>[NEW] The AI slop drops right from the top, as Trump posts vulgar deepfake of opponents (AI – Ars Technica)</title><link>https://arstechnica.com/culture/2025/09/ai-leadership-trump-posts-deepfakes-of-dems-calling-themselves-woke-pieces-of-s-t/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A sombrero and a fake mustache were also involved.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="448" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1875360841-640x448.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1875360841-1152x648-1759270355.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI poses an obvious danger to millennia-long human fight to find the truth. Large language model "hallucinations," vocal deepfakes, and now increased use of video deepfakes have all had a blurring effect on facts, letting bad actors around the globe brush off even recorded events as mere "fake news."&lt;/p&gt;
&lt;p&gt;The danger is perhaps most acute in the political realm, where deepfake audio and video can make any politician say or appear to do anything. In such a climate, our most senior elected officials have a special duty to model truth-seeking behavior and responsible AI use.&lt;/p&gt;
&lt;p&gt;But what's the fun in that, when you can just blow up negotiations over a budget impasse by posting a deepfake video of your political opponents calling themselves "a bunch of woke pieces of shit" while mariachi music plays in the background? Oh—and did I mention the fake mustache? Or the CGI sombrero?&lt;/p&gt;
&lt;p&gt;On Monday night, the president of the United States, a man with access to the greatest intelligence-gathering operation in the world, posted to his Truth Social account a 35-second AI-generated video filled with crude insults, racial overtones, and bizarre conspiracy theories. The video targeted two Democratic leaders who had recently been meeting with Trump over a possible agreement to fund the government; I would have thought this kind of video was a pretty poor way to get people to agree with you, but, apparently, AI-generated insults are the real "art of the deal."&lt;/p&gt;
&lt;p&gt;In the clip, a deepfake version of Sen. Chuck Schumer (D-NY) utters a surreal monologue as his colleague Rep. Hakeem Jeffries (D-NY) looks on... in a sombrero.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2120040 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="center large" height="530" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/deepfake-video-1024x530.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Deepfakes, now normalized for political discourse.

          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The New York Times described the video in somewhat anodyne fashion, saying that the "voice of Senator Chuck Schumer was distorted to deliver expletive-laden remarks that included the line, 'Nobody likes Democrats anymore.'" While this description of the video is accurate, it runs the risk of "sane-washing" the absolutely unhinged and divisive uses to which AI is currently being put. Here's the full quote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Look, guys, there's no way to sugarcoat it. Nobody likes Democrats anymore. We have no voters left because of all of our woke trans bullshit. Not even Black people want to vote for us anymore. Even Latinos hate us. So we need new voters. And, if we give all these illegal aliens free health care, we might be able to get 'em on our side so they can vote for us. They can't even speak English, so they won't realize we're just a bunch of woke pieces of shit, you know, at least for a while until they learn English and realize they hate us, too.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;People in the US illegally cannot vote in federal or state elections, of course, and almost never do so. A 2024 Georgia audit run by Republicans, for instance, found that "20 of the 8.2 million people registered to vote in the state are not US citizens"—and 11 of those had no history of voting despite being registered.&lt;/p&gt;
&lt;p&gt;Knowledge is hard to find and harder to disseminate. Even the phrase "a lie can travel halfway around the world while the truth is putting on its shoes," often incorrectly attributed to Mark Twain, turns out to have a long, slippery history that many people still don't know.&lt;/p&gt;
&lt;p&gt;In such a world, the last thing truth needs is to be doused in buckets of AI slop. And yet here we are.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        A sombrero and a fake mustache were also involved.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="448" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1875360841-640x448.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/GettyImages-1875360841-1152x648-1759270355.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI poses an obvious danger to millennia-long human fight to find the truth. Large language model "hallucinations," vocal deepfakes, and now increased use of video deepfakes have all had a blurring effect on facts, letting bad actors around the globe brush off even recorded events as mere "fake news."&lt;/p&gt;
&lt;p&gt;The danger is perhaps most acute in the political realm, where deepfake audio and video can make any politician say or appear to do anything. In such a climate, our most senior elected officials have a special duty to model truth-seeking behavior and responsible AI use.&lt;/p&gt;
&lt;p&gt;But what's the fun in that, when you can just blow up negotiations over a budget impasse by posting a deepfake video of your political opponents calling themselves "a bunch of woke pieces of shit" while mariachi music plays in the background? Oh—and did I mention the fake mustache? Or the CGI sombrero?&lt;/p&gt;
&lt;p&gt;On Monday night, the president of the United States, a man with access to the greatest intelligence-gathering operation in the world, posted to his Truth Social account a 35-second AI-generated video filled with crude insults, racial overtones, and bizarre conspiracy theories. The video targeted two Democratic leaders who had recently been meeting with Trump over a possible agreement to fund the government; I would have thought this kind of video was a pretty poor way to get people to agree with you, but, apparently, AI-generated insults are the real "art of the deal."&lt;/p&gt;
&lt;p&gt;In the clip, a deepfake version of Sen. Chuck Schumer (D-NY) utters a surreal monologue as his colleague Rep. Hakeem Jeffries (D-NY) looks on... in a sombrero.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2120040 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="center large" height="530" src="https://cdn.arstechnica.net/wp-content/uploads/2025/09/deepfake-video-1024x530.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Deepfakes, now normalized for political discourse.

          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The New York Times described the video in somewhat anodyne fashion, saying that the "voice of Senator Chuck Schumer was distorted to deliver expletive-laden remarks that included the line, 'Nobody likes Democrats anymore.'" While this description of the video is accurate, it runs the risk of "sane-washing" the absolutely unhinged and divisive uses to which AI is currently being put. Here's the full quote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Look, guys, there's no way to sugarcoat it. Nobody likes Democrats anymore. We have no voters left because of all of our woke trans bullshit. Not even Black people want to vote for us anymore. Even Latinos hate us. So we need new voters. And, if we give all these illegal aliens free health care, we might be able to get 'em on our side so they can vote for us. They can't even speak English, so they won't realize we're just a bunch of woke pieces of shit, you know, at least for a while until they learn English and realize they hate us, too.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;People in the US illegally cannot vote in federal or state elections, of course, and almost never do so. A 2024 Georgia audit run by Republicans, for instance, found that "20 of the 8.2 million people registered to vote in the state are not US citizens"—and 11 of those had no history of voting despite being registered.&lt;/p&gt;
&lt;p&gt;Knowledge is hard to find and harder to disseminate. Even the phrase "a lie can travel halfway around the world while the truth is putting on its shoes," often incorrectly attributed to Mark Twain, turns out to have a long, slippery history that many people still don't know.&lt;/p&gt;
&lt;p&gt;In such a world, the last thing truth needs is to be doused in buckets of AI slop. And yet here we are.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/culture/2025/09/ai-leadership-trump-posts-deepfakes-of-dems-calling-themselves-woke-pieces-of-s-t/</guid><pubDate>Tue, 30 Sep 2025 22:52:14 +0000</pubDate></item></channel></rss>