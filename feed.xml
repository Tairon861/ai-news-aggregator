<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 07 Nov 2025 06:33:07 +0000</lastBuildDate><item><title> ()</title><link>https://deepmind.com/blog/feed/basic/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://deepmind.com/blog/feed/basic/</guid></item><item><title>Bombshell report exposes how Meta relied on scam ad profits to fund AI (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/11/bombshell-report-exposes-how-meta-relied-on-scam-ad-profits-to-fund-ai/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Meta goosed its revenue by targeting users likely to click on scam ads, docs show.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="433" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2196626975-640x433.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2196626975-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Justin Sullivan / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Internal documents have revealed that Meta has projected it earns billions from ignoring scam ads that its platforms then targeted to users most likely to click on them.&lt;/p&gt;
&lt;p&gt;In a lengthy report, Reuters exposed five years of Meta practices and failures that allowed scammers to take advantage of users of Facebook, Instagram, and WhatsApp.&lt;/p&gt;
&lt;p&gt;Documents showed that internally, Meta was hesitant to abruptly remove accounts, even those considered some of the “scammiest scammers,” out of concern that a drop in revenue could diminish resources needed for artificial intelligence growth.&lt;/p&gt;
&lt;p&gt;Instead of promptly removing bad actors, Meta allowed “high value accounts” to “accrue more than 500 strikes without Meta shutting them down,” Reuters reported. The more strikes a bad actor accrued, the more Meta could charge to run ads, as Meta’s documents showed the company “penalized” scammers by charging higher ad rates. Meanwhile, Meta acknowledged in documents that its systems helped scammers target users most likely to click on their ads.&lt;/p&gt;
&lt;p&gt;“Users who click on scam ads are likely to see more of them because of Meta’s ad-personalization system, which tries to deliver ads based on a user’s interests,” Reuters reported.&lt;/p&gt;
&lt;p&gt;Internally, Meta estimates that users across its apps in total encounter 15 billion “high risk” scam ads a day. That’s on top of 22 billion organic scam attempts that Meta users are exposed to daily, a 2024 document showed. Last year, the company projected that about $16 billion, which represents about 10 percent of its revenue, would come from scam ads.&lt;/p&gt;
&lt;p&gt;“High risk” scam ads strive to sell users on fake products or investment schemes, Reuters noted. Some common scams in this category that mislead users include selling banned medical products, or promoting sketchy entities, like linking to illegal online casinos. However, Meta is most concerned about “imposter” ads, which impersonate celebrities or big brands that Meta fears may halt advertising or engagement on its apps if such scams aren’t quickly stopped.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Hey it’s me,” one scam advertisement using Elon Musk’s photo read. “I have a gift for you text me.” Another using Donald Trump’s photo claimed the US president was offering $710 to every American as “tariff relief.” Perhaps most depressingly, a third posed as a real law firm, offering advice on how to avoid falling victim to online scams.&lt;/p&gt;
&lt;p&gt;Meta removed these particular ads after Reuters flagged them, but in 2024, Meta earned about $7 billion from “high risk” ads like these alone, Reuters reported.&lt;/p&gt;
&lt;p&gt;Sandeep Abraham, a former Meta safety investigator who now runs consultancy firm Risky Business Solutions as a fraud examiner, told Reuters that regulators should intervene.&lt;/p&gt;
&lt;p&gt;“If regulators wouldn’t tolerate banks profiting from fraud, they shouldn’t tolerate it in tech,” Abraham said.&lt;/p&gt;
&lt;h2&gt;Meta won’t disclose how much it made off scam ads&lt;/h2&gt;
&lt;p&gt;Meta spokesperson Andy Stone told Reuters that its collection of documents—which were created between 2021 and 2025 by Meta’s finance, lobbying, engineering, and safety divisions—“present a selective view that distorts Meta’s approach to fraud and scams.”&lt;/p&gt;
&lt;p&gt;Stone claimed that Meta’s estimate that it would earn 10 percent of its 2024 revenue from scam ads was “rough and overly-inclusive.” He suggested the actual amount Meta earned was much lower but declined to specify the true amount. He also said that Meta’s most recent investor disclosures note that scam ads “adversely affect” Meta’s revenue.&lt;/p&gt;
&lt;p&gt;“We aggressively fight fraud and scams because people on our platforms don’t want this content, legitimate advertisers don’t want it, and we don’t want it either,” Stone said.&lt;/p&gt;
&lt;p&gt;Despite those efforts, this spring, Meta’s safety team “estimated that the company’s platforms were involved in a third of all successful scams in the US,” Reuters reported. In other internal documents around the same time, Meta staff concluded that “it is easier to advertise scams on Meta platforms than Google,” acknowledging that Meta’s rivals were better at “weeding out fraud.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As Meta tells it, though seemingly dismal, these documents came amid vast improvements in its fraud protections. Stone told Reuters that “over the past 18 months, we have reduced user reports of scam ads globally by 58 percent and, so far in 2025, we’ve removed more than 134 million pieces of scam ad content,” Stone said.&lt;/p&gt;
&lt;p&gt;According to Reuters, the problem may be the pace Meta sets in combating scammers. In 2023, Meta laid off “everyone who worked on the team handling advertiser concerns about brand-rights issues,” then ordered safety staffers to limit use of computing resources to devote more resources to virtual reality and AI. A 2024 document showed Meta recommended a “moderate” approach to enforcement, plotting to reduce revenue “attributable to scams, illegal gambling and prohibited goods” by 1–3 percentage points each year since 2024, supposedly slashing it in half by 2027. More recently, a 2025 document showed Meta continues to weigh how “abrupt reductions of scam advertising revenue could affect its business projections.”&lt;/p&gt;
&lt;p&gt;Eventually, Meta “substantially expanded” its teams that track scam ads, Stone told Reuters. But Meta also took steps to ensure they didn’t take too hard a hit while needing vast resources—$72 billion—to invest in AI, Reuters reported.&lt;/p&gt;
&lt;p&gt;For example, in February, Meta told “the team responsible for vetting questionable advertisers” that they weren’t “allowed to take actions that could cost Meta more than 0.15 percent of the company’s total revenue,” Reuters reported. That’s any scam account worth about $135 million, Reuters noted. Stone pushed back, saying that the team was never given “a hard limit” on what the manager described as “specific revenue guardrails.”&lt;/p&gt;
&lt;p&gt;“Let’s be cautious,” the team’s manager wrote, warning that Meta didn’t want to lose revenue by blocking “benign” ads mistakenly swept up in enforcement.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Meta should donate scam ad profits, ex-exec says&lt;/h2&gt;
&lt;p&gt;Documents showed that Meta prioritized taking action when it risked regulatory fines, although revenue from scam ads was worth roughly three times the highest fines it could face. Possibly, Meta most feared that officials would require disgorgement of ill-gotten gains, rather than fines.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta appeared to be less likely to ramp up enforcement from police requests. Documents showed that police in Singapore flagged “146 examples of scams targeting that country’s users last fall,” Reuters reported. Only 23 percent violated Meta’s policies, while the rest only “violate the spirit of the policy, but not the letter,” a Meta presentation said.&lt;/p&gt;
&lt;p&gt;Scams that Meta failed to flag offered promotions like crypto scams, fake concert tickets, or deals “too good to be true,” like 80 percent off a desirable item from a high-fashion brand. Meta also looked past fake job ads that claimed to be hiring for Big Tech companies.&lt;/p&gt;
&lt;p&gt;Rob Leathern previously led Meta’s business integrity unit that worked to prevent scam ads but left in 2020. He told Wired that it’s hard to “know how bad it’s gotten or what the current state is” since Meta and other social media platforms don’t provide outside researchers access to large random samples of ads.&lt;/p&gt;
&lt;p&gt;With such access, researchers like Leathern and Rob Goldman, Meta’s former vice president of ads, could provide “scorecards” showing how well different platforms work to combat scams. Together, Leathern and Goldman launched a nonprofit called CollectiveMetrics.org in hopes of “bringing more transparency to digital advertising in order to fight deceptive ads,” Wired reported.&lt;/p&gt;
&lt;p&gt;“I want there to be more transparency. I want third parties, researchers, academics, nonprofits, whoever, to be able to actually assess how good of a job these platforms are doing at stopping scams and fraud,” Leathern told Wired. “We’d like to move to actual measurement of the problem and help foster an understanding.”&lt;/p&gt;
&lt;p&gt;Another meaningful step that Leathern thinks companies like Meta should take to protect users would be to notify users when Meta discovers that they clicked on a scam ad—rather than targeting them with more scam ads, as Reuters suggested was Meta’s practice.&lt;/p&gt;
&lt;p&gt;“These scammers aren’t getting people’s money on day one, typically. So there’s a window to take action,” he said, recommending that platforms donate ill-gotten gains from running scam ads to “fund nonprofits to educate people about how to recognize these kinds of scams or problems.”&lt;/p&gt;
&lt;p&gt;“There’s lots that could be done with funds that come from these bad guys,” Leathern said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Meta goosed its revenue by targeting users likely to click on scam ads, docs show.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="433" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2196626975-640x433.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/GettyImages-2196626975-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Justin Sullivan / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Internal documents have revealed that Meta has projected it earns billions from ignoring scam ads that its platforms then targeted to users most likely to click on them.&lt;/p&gt;
&lt;p&gt;In a lengthy report, Reuters exposed five years of Meta practices and failures that allowed scammers to take advantage of users of Facebook, Instagram, and WhatsApp.&lt;/p&gt;
&lt;p&gt;Documents showed that internally, Meta was hesitant to abruptly remove accounts, even those considered some of the “scammiest scammers,” out of concern that a drop in revenue could diminish resources needed for artificial intelligence growth.&lt;/p&gt;
&lt;p&gt;Instead of promptly removing bad actors, Meta allowed “high value accounts” to “accrue more than 500 strikes without Meta shutting them down,” Reuters reported. The more strikes a bad actor accrued, the more Meta could charge to run ads, as Meta’s documents showed the company “penalized” scammers by charging higher ad rates. Meanwhile, Meta acknowledged in documents that its systems helped scammers target users most likely to click on their ads.&lt;/p&gt;
&lt;p&gt;“Users who click on scam ads are likely to see more of them because of Meta’s ad-personalization system, which tries to deliver ads based on a user’s interests,” Reuters reported.&lt;/p&gt;
&lt;p&gt;Internally, Meta estimates that users across its apps in total encounter 15 billion “high risk” scam ads a day. That’s on top of 22 billion organic scam attempts that Meta users are exposed to daily, a 2024 document showed. Last year, the company projected that about $16 billion, which represents about 10 percent of its revenue, would come from scam ads.&lt;/p&gt;
&lt;p&gt;“High risk” scam ads strive to sell users on fake products or investment schemes, Reuters noted. Some common scams in this category that mislead users include selling banned medical products, or promoting sketchy entities, like linking to illegal online casinos. However, Meta is most concerned about “imposter” ads, which impersonate celebrities or big brands that Meta fears may halt advertising or engagement on its apps if such scams aren’t quickly stopped.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Hey it’s me,” one scam advertisement using Elon Musk’s photo read. “I have a gift for you text me.” Another using Donald Trump’s photo claimed the US president was offering $710 to every American as “tariff relief.” Perhaps most depressingly, a third posed as a real law firm, offering advice on how to avoid falling victim to online scams.&lt;/p&gt;
&lt;p&gt;Meta removed these particular ads after Reuters flagged them, but in 2024, Meta earned about $7 billion from “high risk” ads like these alone, Reuters reported.&lt;/p&gt;
&lt;p&gt;Sandeep Abraham, a former Meta safety investigator who now runs consultancy firm Risky Business Solutions as a fraud examiner, told Reuters that regulators should intervene.&lt;/p&gt;
&lt;p&gt;“If regulators wouldn’t tolerate banks profiting from fraud, they shouldn’t tolerate it in tech,” Abraham said.&lt;/p&gt;
&lt;h2&gt;Meta won’t disclose how much it made off scam ads&lt;/h2&gt;
&lt;p&gt;Meta spokesperson Andy Stone told Reuters that its collection of documents—which were created between 2021 and 2025 by Meta’s finance, lobbying, engineering, and safety divisions—“present a selective view that distorts Meta’s approach to fraud and scams.”&lt;/p&gt;
&lt;p&gt;Stone claimed that Meta’s estimate that it would earn 10 percent of its 2024 revenue from scam ads was “rough and overly-inclusive.” He suggested the actual amount Meta earned was much lower but declined to specify the true amount. He also said that Meta’s most recent investor disclosures note that scam ads “adversely affect” Meta’s revenue.&lt;/p&gt;
&lt;p&gt;“We aggressively fight fraud and scams because people on our platforms don’t want this content, legitimate advertisers don’t want it, and we don’t want it either,” Stone said.&lt;/p&gt;
&lt;p&gt;Despite those efforts, this spring, Meta’s safety team “estimated that the company’s platforms were involved in a third of all successful scams in the US,” Reuters reported. In other internal documents around the same time, Meta staff concluded that “it is easier to advertise scams on Meta platforms than Google,” acknowledging that Meta’s rivals were better at “weeding out fraud.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As Meta tells it, though seemingly dismal, these documents came amid vast improvements in its fraud protections. Stone told Reuters that “over the past 18 months, we have reduced user reports of scam ads globally by 58 percent and, so far in 2025, we’ve removed more than 134 million pieces of scam ad content,” Stone said.&lt;/p&gt;
&lt;p&gt;According to Reuters, the problem may be the pace Meta sets in combating scammers. In 2023, Meta laid off “everyone who worked on the team handling advertiser concerns about brand-rights issues,” then ordered safety staffers to limit use of computing resources to devote more resources to virtual reality and AI. A 2024 document showed Meta recommended a “moderate” approach to enforcement, plotting to reduce revenue “attributable to scams, illegal gambling and prohibited goods” by 1–3 percentage points each year since 2024, supposedly slashing it in half by 2027. More recently, a 2025 document showed Meta continues to weigh how “abrupt reductions of scam advertising revenue could affect its business projections.”&lt;/p&gt;
&lt;p&gt;Eventually, Meta “substantially expanded” its teams that track scam ads, Stone told Reuters. But Meta also took steps to ensure they didn’t take too hard a hit while needing vast resources—$72 billion—to invest in AI, Reuters reported.&lt;/p&gt;
&lt;p&gt;For example, in February, Meta told “the team responsible for vetting questionable advertisers” that they weren’t “allowed to take actions that could cost Meta more than 0.15 percent of the company’s total revenue,” Reuters reported. That’s any scam account worth about $135 million, Reuters noted. Stone pushed back, saying that the team was never given “a hard limit” on what the manager described as “specific revenue guardrails.”&lt;/p&gt;
&lt;p&gt;“Let’s be cautious,” the team’s manager wrote, warning that Meta didn’t want to lose revenue by blocking “benign” ads mistakenly swept up in enforcement.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Meta should donate scam ad profits, ex-exec says&lt;/h2&gt;
&lt;p&gt;Documents showed that Meta prioritized taking action when it risked regulatory fines, although revenue from scam ads was worth roughly three times the highest fines it could face. Possibly, Meta most feared that officials would require disgorgement of ill-gotten gains, rather than fines.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Meta appeared to be less likely to ramp up enforcement from police requests. Documents showed that police in Singapore flagged “146 examples of scams targeting that country’s users last fall,” Reuters reported. Only 23 percent violated Meta’s policies, while the rest only “violate the spirit of the policy, but not the letter,” a Meta presentation said.&lt;/p&gt;
&lt;p&gt;Scams that Meta failed to flag offered promotions like crypto scams, fake concert tickets, or deals “too good to be true,” like 80 percent off a desirable item from a high-fashion brand. Meta also looked past fake job ads that claimed to be hiring for Big Tech companies.&lt;/p&gt;
&lt;p&gt;Rob Leathern previously led Meta’s business integrity unit that worked to prevent scam ads but left in 2020. He told Wired that it’s hard to “know how bad it’s gotten or what the current state is” since Meta and other social media platforms don’t provide outside researchers access to large random samples of ads.&lt;/p&gt;
&lt;p&gt;With such access, researchers like Leathern and Rob Goldman, Meta’s former vice president of ads, could provide “scorecards” showing how well different platforms work to combat scams. Together, Leathern and Goldman launched a nonprofit called CollectiveMetrics.org in hopes of “bringing more transparency to digital advertising in order to fight deceptive ads,” Wired reported.&lt;/p&gt;
&lt;p&gt;“I want there to be more transparency. I want third parties, researchers, academics, nonprofits, whoever, to be able to actually assess how good of a job these platforms are doing at stopping scams and fraud,” Leathern told Wired. “We’d like to move to actual measurement of the problem and help foster an understanding.”&lt;/p&gt;
&lt;p&gt;Another meaningful step that Leathern thinks companies like Meta should take to protect users would be to notify users when Meta discovers that they clicked on a scam ad—rather than targeting them with more scam ads, as Reuters suggested was Meta’s practice.&lt;/p&gt;
&lt;p&gt;“These scammers aren’t getting people’s money on day one, typically. So there’s a window to take action,” he said, recommending that platforms donate ill-gotten gains from running scam ads to “fund nonprofits to educate people about how to recognize these kinds of scams or problems.”&lt;/p&gt;
&lt;p&gt;“There’s lots that could be done with funds that come from these bad guys,” Leathern said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/11/bombshell-report-exposes-how-meta-relied-on-scam-ad-profits-to-fund-ai/</guid><pubDate>Thu, 06 Nov 2025 19:25:43 +0000</pubDate></item><item><title>Sora for Android saw nearly half a million installs on its first day (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/sora-for-android-saw-nearly-half-a-million-installs-on-its-first-day/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-app-GettyImages-2240278671.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sora’s Android launch is off to an auspicious start. On its first day on the Google Play Store, the AI video app from ChatGPT maker OpenAI saw an estimated 470,000 downloads across the markets where it was available, according to new estimates from app intelligence provider Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That makes the Android launch more than 4x the size of the iOS launch, with 327% more installs (360,000) — but the firm notes that’s not an apples-to-apples comparison.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On iOS, Sora was only available in the U.S. and Canada, and it was invite-only. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora on Android, however, is available in the U.S., Canada, Japan, South Korea, Taiwan, Thailand, and Vietnam, and OpenAI dropped the invite requirement in late October for its top markets.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;You can now get into the Sora app without an invite code in the US, Canada, Japan, and Korea.&lt;/p&gt;&lt;p&gt;Limited time only.&lt;/p&gt;— OpenAI (@OpenAI) October 29, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app was a breakout hit following its debut, despite its earlier exclusive status. The iOS app hit over a million installs within its first week and quickly jumped to the top of the App Store. Today, it’s still ranking as the No. 4 app on the U.S. App Store’s iPhone Top Free Charts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Sora, users leverage AI to make videos using prompts. These videos can also include the users and their friends animated by AI, via a feature known as Cameos. Videos are scrollable in a TikTok-like vertical feed, so you can see what other people are making with the technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Appfigures has also revised its earlier estimates for first-day iOS downloads of the Sora app. Originally, its models said the app saw around 56,000 day-one downloads. Now that more time has passed, the model can more accurately predict that the figure was closer to 110,000, with about 69,300 of those being U.S. installs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By comparison, the Sora Android app saw approximately 296,000 U.S.-based installs, out of the 470,000 total, indicating there’s still interest in the AI video maker, even after the initial iOS launch buzz wore off.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora also competes with Meta AI, which released its mobile app to European users today, following its earlier U.S. debut.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/10/sora-app-GettyImages-2240278671.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Sora’s Android launch is off to an auspicious start. On its first day on the Google Play Store, the AI video app from ChatGPT maker OpenAI saw an estimated 470,000 downloads across the markets where it was available, according to new estimates from app intelligence provider Appfigures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That makes the Android launch more than 4x the size of the iOS launch, with 327% more installs (360,000) — but the firm notes that’s not an apples-to-apples comparison.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On iOS, Sora was only available in the U.S. and Canada, and it was invite-only. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora on Android, however, is available in the U.S., Canada, Japan, South Korea, Taiwan, Thailand, and Vietnam, and OpenAI dropped the invite requirement in late October for its top markets.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;You can now get into the Sora app without an invite code in the US, Canada, Japan, and Korea.&lt;/p&gt;&lt;p&gt;Limited time only.&lt;/p&gt;— OpenAI (@OpenAI) October 29, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app was a breakout hit following its debut, despite its earlier exclusive status. The iOS app hit over a million installs within its first week and quickly jumped to the top of the App Store. Today, it’s still ranking as the No. 4 app on the U.S. App Store’s iPhone Top Free Charts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Sora, users leverage AI to make videos using prompts. These videos can also include the users and their friends animated by AI, via a feature known as Cameos. Videos are scrollable in a TikTok-like vertical feed, so you can see what other people are making with the technology.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Appfigures has also revised its earlier estimates for first-day iOS downloads of the Sora app. Originally, its models said the app saw around 56,000 day-one downloads. Now that more time has passed, the model can more accurately predict that the figure was closer to 110,000, with about 69,300 of those being U.S. installs.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;By comparison, the Sora Android app saw approximately 296,000 U.S.-based installs, out of the 470,000 total, indicating there’s still interest in the AI video maker, even after the initial iOS launch buzz wore off.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sora also competes with Meta AI, which released its mobile app to European users today, following its earlier U.S. debut.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/sora-for-android-saw-nearly-half-a-million-installs-on-its-first-day/</guid><pubDate>Thu, 06 Nov 2025 19:48:39 +0000</pubDate></item><item><title>Sam Altman says he doesn’t want the government to bail out OpenAI if it fails (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/sam-altman-says-he-doesnt-want-the-government-to-bail-out-openai-if-it-fails/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/Graveyard-with-dollar-signs.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI execs have been fielding plenty of questions about how they expect to pay for the $1.4 trillion worth of data center build-outs and usage commitments they’ve accrued this year, given that their revenue — while rising rapidly — is a $20 billion annual run rate, CEO Sam Altman said Thursday in a post on X. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman’s comments came in response to comments made by OpenAI CFO Sarah Friar — which she quickly walked back. Speaking at a Wall Street Journal event on Wednesday, Friar said she wanted the U.S. government to “backstop” her company’s infrastructure loans. This, she explained, would make the company’s loans cheaper and help ensure it could always be using the latest, greatest chip.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A backstopped loan is when the government guarantees it so if the company defaults, taxpayers pick up the bill. Lenders tend to reward low-risk loans like that with better terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Friar said that using older chips, which compute-constrained OpenAI must do, makes financing options more affordable, but that the company’s goal is to always put its state-of-the-art models on the latest, greatest chips. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So how to pay for this revolving door of chips? She said the company is looking for an “ecosystem” to help, including banks, PE firms and, she hoped, the government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked what she wanted the government to do, she said, “… the backstop, the guarantee that allows the financing to happen. That can really drop the cost of the financing but also increase the loan-to-value, so the amount of debt that you can take on top of an equity portion.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She also implied that such talks, particularly in the U.S., were already in the works saying, “I think we’re seeing that. The U.S. government, in particular has been incredibly forward-leaning, has really understood that AI is almost a national strategic asset.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;After The Wall Street Journal published the clip of her discussing this desire for a federal backstop, and plenty of X users with big followers scoffed at the idea, Friar quickly walked back her comments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I want to clarify my comments earlier today. OpenAI is not seeking a government backstop for our infrastructure commitments. I used the word ‘backstop’ and it muddied the point,” she posted on LinkedIn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Trump’s AI czar David Sacks weighed in. Sacks (who is a big Silicon Valley VC himself), wrote on X the U.S. has no plans to bail out any AI company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There will be no federal bailout for AI. The U.S. has at least 5 major frontier model companies. If one fails, others will take its place,” he posted, adding that what the government wants to do is make “permitting and power generation easier.” While not naming her, he also forgave Friar for “clarifying” her stance.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;There will be no federal bailout for AI. The U.S. has at least 5 major frontier model companies. If one fails, others will take its place.&lt;/p&gt;— David Sacks (@DavidSacks) November 6, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In the wake of this, Altman wrote a lengthy post on X echoing Sacks’ sentiments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We do not have or want government guarantees for OpenAI datacenters. We believe that governments should not pick winners or losers, and that taxpayers should not bail out companies that make bad business decisions or otherwise lose in the market,” he wrote. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also clarified that the backstopped loans have been discussed — but not for his company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The one area where we have discussed loan guarantees is as part of supporting the buildout of semiconductor fabs in the US, where we and other companies have responded to the government’s call and where we would be happy to help (though we did not formally apply).”&lt;/p&gt;&lt;p&gt;It is hard to fault Friar for floating the idea. She’s right that such a guarantee would make her financing job easier, even if, as Sacks wrote in his string, the idea of asking for a taxpayer-funded bailout is “ridiculous.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As she’s now heard a resounding public “no” from someone she’d need in her corner for that idea, she and OpenAI CEO Sam Altman can expect plenty more questions about how they expect to pay for their $1 trillion buildout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, Altman seems braced for just such a thing. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We expect to end this year above $20 billion in annualized revenue run rate and grow to hundreds of billion by 2030. We are looking at commitments of about $1.4 trillion over the next 8 years,” he wrote, adding that the company feels good about it’s “prospects” especially its enterprise offering, new consumer devices, and robotics. &lt;br /&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/Graveyard-with-dollar-signs.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI execs have been fielding plenty of questions about how they expect to pay for the $1.4 trillion worth of data center build-outs and usage commitments they’ve accrued this year, given that their revenue — while rising rapidly — is a $20 billion annual run rate, CEO Sam Altman said Thursday in a post on X. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman’s comments came in response to comments made by OpenAI CFO Sarah Friar — which she quickly walked back. Speaking at a Wall Street Journal event on Wednesday, Friar said she wanted the U.S. government to “backstop” her company’s infrastructure loans. This, she explained, would make the company’s loans cheaper and help ensure it could always be using the latest, greatest chip.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;A backstopped loan is when the government guarantees it so if the company defaults, taxpayers pick up the bill. Lenders tend to reward low-risk loans like that with better terms.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Friar said that using older chips, which compute-constrained OpenAI must do, makes financing options more affordable, but that the company’s goal is to always put its state-of-the-art models on the latest, greatest chips. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So how to pay for this revolving door of chips? She said the company is looking for an “ecosystem” to help, including banks, PE firms and, she hoped, the government.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When asked what she wanted the government to do, she said, “… the backstop, the guarantee that allows the financing to happen. That can really drop the cost of the financing but also increase the loan-to-value, so the amount of debt that you can take on top of an equity portion.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She also implied that such talks, particularly in the U.S., were already in the works saying, “I think we’re seeing that. The U.S. government, in particular has been incredibly forward-leaning, has really understood that AI is almost a national strategic asset.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;After The Wall Street Journal published the clip of her discussing this desire for a federal backstop, and plenty of X users with big followers scoffed at the idea, Friar quickly walked back her comments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I want to clarify my comments earlier today. OpenAI is not seeking a government backstop for our infrastructure commitments. I used the word ‘backstop’ and it muddied the point,” she posted on LinkedIn.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Thursday, Trump’s AI czar David Sacks weighed in. Sacks (who is a big Silicon Valley VC himself), wrote on X the U.S. has no plans to bail out any AI company.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“There will be no federal bailout for AI. The U.S. has at least 5 major frontier model companies. If one fails, others will take its place,” he posted, adding that what the government wants to do is make “permitting and power generation easier.” While not naming her, he also forgave Friar for “clarifying” her stance.&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;There will be no federal bailout for AI. The U.S. has at least 5 major frontier model companies. If one fails, others will take its place.&lt;/p&gt;— David Sacks (@DavidSacks) November 6, 2025&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In the wake of this, Altman wrote a lengthy post on X echoing Sacks’ sentiments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We do not have or want government guarantees for OpenAI datacenters. We believe that governments should not pick winners or losers, and that taxpayers should not bail out companies that make bad business decisions or otherwise lose in the market,” he wrote. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also clarified that the backstopped loans have been discussed — but not for his company.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The one area where we have discussed loan guarantees is as part of supporting the buildout of semiconductor fabs in the US, where we and other companies have responded to the government’s call and where we would be happy to help (though we did not formally apply).”&lt;/p&gt;&lt;p&gt;It is hard to fault Friar for floating the idea. She’s right that such a guarantee would make her financing job easier, even if, as Sacks wrote in his string, the idea of asking for a taxpayer-funded bailout is “ridiculous.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As she’s now heard a resounding public “no” from someone she’d need in her corner for that idea, she and OpenAI CEO Sam Altman can expect plenty more questions about how they expect to pay for their $1 trillion buildout.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, Altman seems braced for just such a thing. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We expect to end this year above $20 billion in annualized revenue run rate and grow to hundreds of billion by 2030. We are looking at commitments of about $1.4 trillion over the next 8 years,” he wrote, adding that the company feels good about it’s “prospects” especially its enterprise offering, new consumer devices, and robotics. &lt;br /&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/sam-altman-says-he-doesnt-want-the-government-to-bail-out-openai-if-it-fails/</guid><pubDate>Thu, 06 Nov 2025 20:06:36 +0000</pubDate></item><item><title>Amazon launches an AI-powered Kindle Translate service for e-book authors (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/amazon-launches-an-ai-powered-kindle-translate-service-for-ebook-authors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/amazon-kindle-stock-image-GettyImages-1202535978.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon announced on Thursday the launch of Kindle Translate, an AI-powered translation service designed for authors using Kindle Direct Publishing to broaden their reach. The service initially translates text between English and Spanish and from German to English, as it’s still operating in beta. More languages will be supported over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The retail giant noted less than 5% of titles on Amazon are available in more than one language, suggesting there’s a big opportunity for AI translations.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Of course, AI isn’t perfect, which means it could introduce errors into the text. To address this, Amazon allows authors to preview their translations before publishing if desired. If the author is not using the service to simply speed up translating their work into another language they speak, this ability to check the AI’s work won’t do them much good; they’d still need a human translator to review the AI output if they wanted to ensure the best accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;(Amazon claims its AI translations are “automatically evaluated for accuracy” before publication, but it doesn’t detail what steps are involved with this part of the process.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says authors can manage and access their translations from the Kindle Direct Publishing portal, where they can choose the languages, set prices, and publish their translated work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Readers, meanwhile, will see AI-translated works clearly labeled as “Kindle Translate” titles and will be able to preview samples of the translation. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kindle Translate competes with many other AI-powered translation services and tools on the market, whose pricing can vary and which offer broader support for more languages. There are also open source tools. Some people in the industry criticize the use of AI in this way, saying that human translators are better at capturing nuance — particularly in fiction and other literary works. But AI is improving on this front and will likely continue to get better over time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;At present, Kindle’s translation service is being offered for free, according to Amazon’s announcement, which quotes an early tester who praised this aspect of the service, saying that indie authors have struggled to find a “cost-effective and trustworthy solution.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon says translations are eligible to be enrolled in other programs, like KDP Select, and are included in its Kindle Unlimited subscription service. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/amazon-kindle-stock-image-GettyImages-1202535978.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon announced on Thursday the launch of Kindle Translate, an AI-powered translation service designed for authors using Kindle Direct Publishing to broaden their reach. The service initially translates text between English and Spanish and from German to English, as it’s still operating in beta. More languages will be supported over time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The retail giant noted less than 5% of titles on Amazon are available in more than one language, suggesting there’s a big opportunity for AI translations.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Of course, AI isn’t perfect, which means it could introduce errors into the text. To address this, Amazon allows authors to preview their translations before publishing if desired. If the author is not using the service to simply speed up translating their work into another language they speak, this ability to check the AI’s work won’t do them much good; they’d still need a human translator to review the AI output if they wanted to ensure the best accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;(Amazon claims its AI translations are “automatically evaluated for accuracy” before publication, but it doesn’t detail what steps are involved with this part of the process.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company says authors can manage and access their translations from the Kindle Direct Publishing portal, where they can choose the languages, set prices, and publish their translated work.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Readers, meanwhile, will see AI-translated works clearly labeled as “Kindle Translate” titles and will be able to preview samples of the translation. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kindle Translate competes with many other AI-powered translation services and tools on the market, whose pricing can vary and which offer broader support for more languages. There are also open source tools. Some people in the industry criticize the use of AI in this way, saying that human translators are better at capturing nuance — particularly in fiction and other literary works. But AI is improving on this front and will likely continue to get better over time.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;At present, Kindle’s translation service is being offered for free, according to Amazon’s announcement, which quotes an early tester who praised this aspect of the service, saying that indie authors have struggled to find a “cost-effective and trustworthy solution.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon says translations are eligible to be enrolled in other programs, like KDP Select, and are included in its Kindle Unlimited subscription service. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/amazon-launches-an-ai-powered-kindle-translate-service-for-ebook-authors/</guid><pubDate>Thu, 06 Nov 2025 20:22:48 +0000</pubDate></item><item><title>Gemini Deep Research comes to Google Finance, backed by prediction market data (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/11/gemini-deep-research-comes-to-google-finance-backed-by-prediction-market-data/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Deep Research and predictions based on Kalshi and Polymarket data are coming soon to Google Finance.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Finance_AI-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Finance_AI-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google has announced new features in the popular Google Finance platform, and it leans heavily on Google’s tried-and-true strategy of more AI in more places. This builds on Google’s last Finance update, which added a Gemini-based chatbot. Now, Google is adding Gemini Deep Research to the site, which will allow users to ask much more complex questions. You can also ask questions about the future, backed by new betting market data sources.&lt;/p&gt;
&lt;p&gt;The update, which is rolling out over the next several weeks, will add a Deep Research option to the Finance chatbot. The company claims that with the more powerful AI, users will be able to generate “fully cited” research reports on a given topic in just a few minutes. So you can expect an experience similar to Deep Research in the Gemini app—you give it a prompt, and then you come back later to see the result.&lt;/p&gt;
&lt;p&gt;You probably won’t want to bother with Deep Research on simple queries—there are faster, easier ways to get that done. Google suggests using Deep Research on more complex things, like the doozy below.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2126052 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Deep Search in Finance" class="fullwidth full" height="451" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/DeepSearch.jpg" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Everyone will be able to run at least a few Deep Research reports in Finance. There is an unclear limit, but users with AI Pro and AI Ultra subscriptions will enjoy higher Deep Research limits. Google has a cap on Deep Research in the Gemini app, which may or may not be the same. There, free users only get five Deep Research jobs per month. AI Pro gets 20 reports per day, and AI Ultra gets a whopping 200 per day. Given the time it takes to generate even one, it may be difficult to use that many.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Bet on it&lt;/h2&gt;
&lt;p&gt;Financial markets can turn on a dime, and AI can’t predict the future. However, Google seems to think that people make smart predictions in aggregate when there’s money on the line. That’s why, as part of the Finance update, Google has partnered with Kalshi and Polymarket, the current leaders in online prediction markets.&lt;/p&gt;
&lt;p&gt;These platforms let people place bets on, well, just about anything. If you have a hunch when Google will release Gemini 3.0, when the government shutdown will end, or the number of Tweets Elon Musk will post this month, you can place a wager on it. Maybe you’ll earn money, but more likely, you’ll lose it—only 12.7 percent of crypto wallets on Polymarket show profits.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2126053 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Google Finance prediction markets" class="fullwidth full" height="529" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Finance_adds_AI_features_.width-1000.format-webp.webp" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google says it will get fresh prediction data from both sites, which will allow Gemini to speculate on the future with “the wisdom of crowds.” Google suggests you could type “What will GDP growth be for 2025?” into the search box. Finance will pull the latest probabilities from Kalshi and Polymarket to generate a response that could include graphs and charts based on people’s bets. Naturally, Google does not make promises as to the accuracy of these predictions.&lt;/p&gt;
&lt;p&gt;The new AI features of Google Finance are coming to all US users in the next few weeks, and starting this week, the service will make its debut in India. Likewise, the predictions market data will arrive in the next couple of weeks. If that’s not fast enough, you can opt-in to get early access via the Google Labs page.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Deep Research and predictions based on Kalshi and Polymarket data are coming soon to Google Finance.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Finance_AI-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Finance_AI-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Google has announced new features in the popular Google Finance platform, and it leans heavily on Google’s tried-and-true strategy of more AI in more places. This builds on Google’s last Finance update, which added a Gemini-based chatbot. Now, Google is adding Gemini Deep Research to the site, which will allow users to ask much more complex questions. You can also ask questions about the future, backed by new betting market data sources.&lt;/p&gt;
&lt;p&gt;The update, which is rolling out over the next several weeks, will add a Deep Research option to the Finance chatbot. The company claims that with the more powerful AI, users will be able to generate “fully cited” research reports on a given topic in just a few minutes. So you can expect an experience similar to Deep Research in the Gemini app—you give it a prompt, and then you come back later to see the result.&lt;/p&gt;
&lt;p&gt;You probably won’t want to bother with Deep Research on simple queries—there are faster, easier ways to get that done. Google suggests using Deep Research on more complex things, like the doozy below.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2126052 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Deep Search in Finance" class="fullwidth full" height="451" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/DeepSearch.jpg" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Everyone will be able to run at least a few Deep Research reports in Finance. There is an unclear limit, but users with AI Pro and AI Ultra subscriptions will enjoy higher Deep Research limits. Google has a cap on Deep Research in the Gemini app, which may or may not be the same. There, free users only get five Deep Research jobs per month. AI Pro gets 20 reports per day, and AI Ultra gets a whopping 200 per day. Given the time it takes to generate even one, it may be difficult to use that many.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Bet on it&lt;/h2&gt;
&lt;p&gt;Financial markets can turn on a dime, and AI can’t predict the future. However, Google seems to think that people make smart predictions in aggregate when there’s money on the line. That’s why, as part of the Finance update, Google has partnered with Kalshi and Polymarket, the current leaders in online prediction markets.&lt;/p&gt;
&lt;p&gt;These platforms let people place bets on, well, just about anything. If you have a hunch when Google will release Gemini 3.0, when the government shutdown will end, or the number of Tweets Elon Musk will post this month, you can place a wager on it. Maybe you’ll earn money, but more likely, you’ll lose it—only 12.7 percent of crypto wallets on Polymarket show profits.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2126053 align-fullwidth"&gt;
    &lt;div&gt;
                        &lt;img alt="Google Finance prediction markets" class="fullwidth full" height="529" src="https://cdn.arstechnica.net/wp-content/uploads/2025/11/Google_Finance_adds_AI_features_.width-1000.format-webp.webp" width="1000" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google says it will get fresh prediction data from both sites, which will allow Gemini to speculate on the future with “the wisdom of crowds.” Google suggests you could type “What will GDP growth be for 2025?” into the search box. Finance will pull the latest probabilities from Kalshi and Polymarket to generate a response that could include graphs and charts based on people’s bets. Naturally, Google does not make promises as to the accuracy of these predictions.&lt;/p&gt;
&lt;p&gt;The new AI features of Google Finance are coming to all US users in the next few weeks, and starting this week, the service will make its debut in India. Likewise, the predictions market data will arrive in the next couple of weeks. If that’s not fast enough, you can opt-in to get early access via the Google Labs page.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/11/gemini-deep-research-comes-to-google-finance-backed-by-prediction-market-data/</guid><pubDate>Thu, 06 Nov 2025 20:39:15 +0000</pubDate></item><item><title>Sam Altman says OpenAI has $20B ARR and about $1.4 trillion in data center commitments (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/sam-altman-says-openai-has-20b-arr-and-about-1-4-trillion-in-data-center-commitments/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Rarely has a month gone by in 2025 without OpenAI signing another multibillion-dollar data center deal. In a lengthy post on X on Thursday, OpenAI CEO Sam Altman publicly clarified the totals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We expect to end this year above $20 billion in annualized revenue run rate and grow to hundreds of billion by 2030. We are looking at commitments of about $1.4 trillion over the next 8 years,” he wrote.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the post was largely a response to a brouhaha over comments his CFO made, and quickly walked back, concerning government-backstopped loans, Altman also listed a number of future business plans he believes will generate significant revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said OpenAI has an upcoming enterprise offering. Earlier this week, OpenAI said it already had a million business customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He named consumer devices and robotics. In May,&amp;nbsp;OpenAI acquired Jony Ive’s io, and they are reportedly working on a palm-sized AI device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman mentioned scientific discovery as an upcoming business. Not much is known about it yet, except that OpenAI VP Kevin Weil&amp;nbsp;mentioned a newly launched OpenAI for Science some months ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also said OpenAI could become a cloud computing provider: “We are also looking at ways to more directly sell compute capacity to other companies (and people); we are pretty sure the world is going to need a lot of ‘AI cloud’, and we are excited to offer this.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That’s a bold idea for a company that doesn’t yet have its own network of data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond revenue, Altman noted that the company may also pay for its needs the old-fashioned way: selling more equity or taking on more loans.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Rarely has a month gone by in 2025 without OpenAI signing another multibillion-dollar data center deal. In a lengthy post on X on Thursday, OpenAI CEO Sam Altman publicly clarified the totals.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We expect to end this year above $20 billion in annualized revenue run rate and grow to hundreds of billion by 2030. We are looking at commitments of about $1.4 trillion over the next 8 years,” he wrote.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While the post was largely a response to a brouhaha over comments his CFO made, and quickly walked back, concerning government-backstopped loans, Altman also listed a number of future business plans he believes will generate significant revenue.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He said OpenAI has an upcoming enterprise offering. Earlier this week, OpenAI said it already had a million business customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He named consumer devices and robotics. In May,&amp;nbsp;OpenAI acquired Jony Ive’s io, and they are reportedly working on a palm-sized AI device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman mentioned scientific discovery as an upcoming business. Not much is known about it yet, except that OpenAI VP Kevin Weil&amp;nbsp;mentioned a newly launched OpenAI for Science some months ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Altman also said OpenAI could become a cloud computing provider: “We are also looking at ways to more directly sell compute capacity to other companies (and people); we are pretty sure the world is going to need a lot of ‘AI cloud’, and we are excited to offer this.” &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That’s a bold idea for a company that doesn’t yet have its own network of data centers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Beyond revenue, Altman noted that the company may also pay for its needs the old-fashioned way: selling more equity or taking on more loans.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/sam-altman-says-openai-has-20b-arr-and-about-1-4-trillion-in-data-center-commitments/</guid><pubDate>Thu, 06 Nov 2025 21:18:06 +0000</pubDate></item><item><title>Charting the future of AI, from safer answers to faster thinking (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/charting-the-future-of-ai-from-safer-answers-to-faster-thinking-1106</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-IBM-summer-interns-2025.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Adoption of new tools and technologies occurs when users largely perceive them as reliable, accessible, and an improvement over the available methods and workflows for the cost. Five PhD students from the inaugural class of the MIT-IBM Watson AI Lab Summer Program are utilizing state-of-the-art resources, alleviating AI pain points, and creating new features and capabilities to promote AI usefulness and deployment — from learning when to trust a model that predicts another’s accuracy to more effectively reasoning over knowledge bases. Together, the efforts from the students and their mentors form a through-line, where practical and technically rigorous research leads to more dependable and valuable models across domains.&lt;/p&gt;&lt;p&gt;Building probes, routers, new attention mechanisms, synthetic datasets, and program-synthesis pipelines, the students’ work spans safety, inference efficiency, multimodal data, and knowledge-grounded reasoning. Their techniques emphasize scaling and integration, with impact always in sight.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Learning to trust, and when&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MIT math graduate student Andrey Bryutkin’s research prioritizes the trustworthiness of models. He seeks out internal structures within problems, such as equations governing a system and conservation laws, to understand how to leverage them to produce more dependable and robust solutions. Armed with this and working with the lab, Bryutkin developed a method to peer into the nature of large learning models (LLMs) behaviors. Together with the lab’s Veronika Thost of IBM Research and Marzyeh Ghassemi — associate professor and the Germeshausen Career Development Professor in the MIT Department of Electrical Engineering and Computer Science (EECS) and a member of the Institute of Medical Engineering Sciences and the Laboratory for Information and Decision Systems — Bryutkin explored the “uncertainty of uncertainty” of LLMs.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Classically, tiny feed-forward neural networks two-to-three layers deep, called probes, are trained alongside LLMs and employed to flag untrustworthy answers from the larger model to developers; however, these classifiers can also produce false negatives and only provide point estimates, which don’t offer much information about when the LLM is failing. Investigating safe/unsafe prompts and question-answer tasks, the MIT-IBM team used prompt-label pairs, as well as the hidden states like activation vectors and last tokens from an LLM, to measure gradient scores, sensitivity to prompts, and out-of-distribution data to determine how reliable the probe was and learn areas of data that are difficult to predict. Their method also helps identify potential labeling noise. This is a critical function, as the trustworthiness of AI systems depends entirely on the quality and accuracy of the labeled data&amp;nbsp;they are built upon.&amp;nbsp;More accurate and consistent probes are especially important for domains with critical data in applications like IBM’s Granite Guardian family of models.&lt;/p&gt;&lt;p&gt;Another way to ensure trustworthy responses to queries from an LLM is to augment them with external, trusted knowledge bases to eliminate hallucinations. For structured data, such as social media connections, financial transactions, or corporate databases, knowledge graphs (KG) are natural fits; however, communications between the LLM and KGs often use fixed, multi-agent pipelines that are computationally inefficient and expensive. Addressing this, physics graduate student Jinyeop Song, along with lab researchers Yada Zhu of IBM Research and EECS Associate Professor Julian Shun created a single-agent, multi-turn, reinforcement learning framework that streamlines this process. Here, the group designed an API server hosting Freebase and Wikidata KGs, which consist of general web-based knowledge data, and a LLM agent that issues targeted retrieval actions to fetch pertinent information from the server. Then, through continuous back-and-forth, the agent appends the gathered data from the KGs to the context and responds to the query. Crucially, the system uses reinforcement learning to train itself to deliver answers that strike a balance between accuracy and completeness. The framework pairs an API server with a single reinforcement learning agent to orchestrate data-grounded reasoning with improved accuracy, transparency, efficiency, and transferability.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Spending computation wisely&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The timeliness and completeness of a model’s response carry similar weight to the importance of its accuracy. This is especially true for handling long input texts and those where elements, like the subject of a story, evolve over time, so EECS graduate student Songlin Yang is re-engineering what models can handle at each step of inference. Focusing on transformer limitations, like those in LLMs, the lab’s Rameswar Panda of IBM Research and Yoon Kim, the NBX Professor and associate professor in EECS, joined Yang to develop next-generation language model architectures beyond transformers.&lt;/p&gt;&lt;p&gt;Transformers face two key limitations: high computational complexity in long-sequence modeling due to the softmax attention mechanism, and limited expressivity resulting from the weak inductive bias of RoPE (rotary positional encoding). This means that as the input length doubles, the computational cost quadruples. RoPE allows transformers to understand the sequence order of tokens (i.e., words); however, it does not do a good job capturing internal state changes over time, like variable values, and is limited to the sequence lengths seen during training.&lt;/p&gt;&lt;p&gt;To address this, the MIT-IBM team explored theoretically grounded yet hardware-efficient algorithms. As an alternative to softmax attention, they adopted linear attention, reducing the quadratic complexity that limits the feasible sequence length. They also investigated hybrid architectures that combine softmax and linear attention to strike a better balance between computational efficiency and performance.&lt;/p&gt;&lt;p&gt;Increasing expressivity, they replaced RoPE with a dynamic reflective positional encoding based on the Householder transform. This approach enables richer positional interactions for deeper understanding of sequential information, while maintaining fast and efficient computation. The MIT-IBM team’s advancement reduces the need for transformers to break problems into many steps, instead enabling them to handle more complex subproblems with fewer inference tokens.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Visions anew&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Visual data contain multitudes that the human brain can quickly parse, internalize, and then imitate. Using vision-language models (VLMs), two graduate students are exploring ways to do this through code.&lt;/p&gt;&lt;p&gt;Over the past two summers and under the advisement of Aude Oliva, MIT director of the MIT-IBM Watson AI Lab and a senior research scientist in the Computer Science and Artificial Intelligence Laboratory; and IBM Research’s Rogerio Feris, Dan Gutfreund, and Leonid Karlinsky (now at Xero), Jovana Kondic of EECS has explored visual document understanding, specifically charts. These contain elements, such as data points, legends, and axes labels, that require optical character recognition and numerical reasoning, which models still struggle with. In order to facilitate the performance on tasks such as these, Kondic’s group set out to create a large, open-source, synthetic chart dataset from code that could be used for training and benchmarking.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With their prototype, ChartGen, the researchers created a pipeline that passes seed chart images through a VLM, which is prompted to read the chart and generate a Python script that was likely used to create the chart in the first place. The LLM component of the framework then iteratively augments the code from many charts to ultimately produce over 200,000 unique pairs of charts and their codes, spanning nearly 30 chart types, as well as supporting data and annotation like descriptions and question-answer pairs about the charts. The team is further expanding their dataset, helping to enable critical multimodal understanding to data visualizations for enterprise applications like financial and scientific reports, blogs, and more.&lt;/p&gt;&lt;p&gt;Instead of charts, EECS graduate student Leonardo Hernandez Cano has his eyes on digital design, specifically visual texture generation for CAD applications and the goal of discovering efficient ways to enable to capabilities in VLMs. Teaming up with the lab groups led by Armando Solar-Lezama, EECS professor and Distinguished Professor of Computing in the MIT Schwarzman College of Computing, and IBM Research’s Nathan Fulton, Hernandez Cano created a program synthesis system that learns to refine code on its own. The system starts with a texture description given by a user in the form of an image. It then generates an initial Python program, which produces visual textures, and iteratively refines the code with the goal of finding a program that produces a texture that matches the target description, learning to search for new programs from the data that the system itself produces. Through these refinements, the novel program can create visualizations with the desired luminosity, color, iridescence, etc., mimicking real materials.&lt;/p&gt;&lt;p&gt;When viewed together, these projects, and the people behind them, are making a cohesive push toward more robust and practical artificial intelligence. By tackling the core challenges of reliability, efficiency, and multimodal reasoning, the work paves the way for AI systems that are not only more powerful, but also more dependable and cost-effective, for real-world enterprise and scientific applications.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202510/MIT-IBM-summer-interns-2025.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Adoption of new tools and technologies occurs when users largely perceive them as reliable, accessible, and an improvement over the available methods and workflows for the cost. Five PhD students from the inaugural class of the MIT-IBM Watson AI Lab Summer Program are utilizing state-of-the-art resources, alleviating AI pain points, and creating new features and capabilities to promote AI usefulness and deployment — from learning when to trust a model that predicts another’s accuracy to more effectively reasoning over knowledge bases. Together, the efforts from the students and their mentors form a through-line, where practical and technically rigorous research leads to more dependable and valuable models across domains.&lt;/p&gt;&lt;p&gt;Building probes, routers, new attention mechanisms, synthetic datasets, and program-synthesis pipelines, the students’ work spans safety, inference efficiency, multimodal data, and knowledge-grounded reasoning. Their techniques emphasize scaling and integration, with impact always in sight.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Learning to trust, and when&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;MIT math graduate student Andrey Bryutkin’s research prioritizes the trustworthiness of models. He seeks out internal structures within problems, such as equations governing a system and conservation laws, to understand how to leverage them to produce more dependable and robust solutions. Armed with this and working with the lab, Bryutkin developed a method to peer into the nature of large learning models (LLMs) behaviors. Together with the lab’s Veronika Thost of IBM Research and Marzyeh Ghassemi — associate professor and the Germeshausen Career Development Professor in the MIT Department of Electrical Engineering and Computer Science (EECS) and a member of the Institute of Medical Engineering Sciences and the Laboratory for Information and Decision Systems — Bryutkin explored the “uncertainty of uncertainty” of LLMs.&amp;nbsp;&lt;/p&gt;&lt;p&gt;Classically, tiny feed-forward neural networks two-to-three layers deep, called probes, are trained alongside LLMs and employed to flag untrustworthy answers from the larger model to developers; however, these classifiers can also produce false negatives and only provide point estimates, which don’t offer much information about when the LLM is failing. Investigating safe/unsafe prompts and question-answer tasks, the MIT-IBM team used prompt-label pairs, as well as the hidden states like activation vectors and last tokens from an LLM, to measure gradient scores, sensitivity to prompts, and out-of-distribution data to determine how reliable the probe was and learn areas of data that are difficult to predict. Their method also helps identify potential labeling noise. This is a critical function, as the trustworthiness of AI systems depends entirely on the quality and accuracy of the labeled data&amp;nbsp;they are built upon.&amp;nbsp;More accurate and consistent probes are especially important for domains with critical data in applications like IBM’s Granite Guardian family of models.&lt;/p&gt;&lt;p&gt;Another way to ensure trustworthy responses to queries from an LLM is to augment them with external, trusted knowledge bases to eliminate hallucinations. For structured data, such as social media connections, financial transactions, or corporate databases, knowledge graphs (KG) are natural fits; however, communications between the LLM and KGs often use fixed, multi-agent pipelines that are computationally inefficient and expensive. Addressing this, physics graduate student Jinyeop Song, along with lab researchers Yada Zhu of IBM Research and EECS Associate Professor Julian Shun created a single-agent, multi-turn, reinforcement learning framework that streamlines this process. Here, the group designed an API server hosting Freebase and Wikidata KGs, which consist of general web-based knowledge data, and a LLM agent that issues targeted retrieval actions to fetch pertinent information from the server. Then, through continuous back-and-forth, the agent appends the gathered data from the KGs to the context and responds to the query. Crucially, the system uses reinforcement learning to train itself to deliver answers that strike a balance between accuracy and completeness. The framework pairs an API server with a single reinforcement learning agent to orchestrate data-grounded reasoning with improved accuracy, transparency, efficiency, and transferability.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Spending computation wisely&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The timeliness and completeness of a model’s response carry similar weight to the importance of its accuracy. This is especially true for handling long input texts and those where elements, like the subject of a story, evolve over time, so EECS graduate student Songlin Yang is re-engineering what models can handle at each step of inference. Focusing on transformer limitations, like those in LLMs, the lab’s Rameswar Panda of IBM Research and Yoon Kim, the NBX Professor and associate professor in EECS, joined Yang to develop next-generation language model architectures beyond transformers.&lt;/p&gt;&lt;p&gt;Transformers face two key limitations: high computational complexity in long-sequence modeling due to the softmax attention mechanism, and limited expressivity resulting from the weak inductive bias of RoPE (rotary positional encoding). This means that as the input length doubles, the computational cost quadruples. RoPE allows transformers to understand the sequence order of tokens (i.e., words); however, it does not do a good job capturing internal state changes over time, like variable values, and is limited to the sequence lengths seen during training.&lt;/p&gt;&lt;p&gt;To address this, the MIT-IBM team explored theoretically grounded yet hardware-efficient algorithms. As an alternative to softmax attention, they adopted linear attention, reducing the quadratic complexity that limits the feasible sequence length. They also investigated hybrid architectures that combine softmax and linear attention to strike a better balance between computational efficiency and performance.&lt;/p&gt;&lt;p&gt;Increasing expressivity, they replaced RoPE with a dynamic reflective positional encoding based on the Householder transform. This approach enables richer positional interactions for deeper understanding of sequential information, while maintaining fast and efficient computation. The MIT-IBM team’s advancement reduces the need for transformers to break problems into many steps, instead enabling them to handle more complex subproblems with fewer inference tokens.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Visions anew&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Visual data contain multitudes that the human brain can quickly parse, internalize, and then imitate. Using vision-language models (VLMs), two graduate students are exploring ways to do this through code.&lt;/p&gt;&lt;p&gt;Over the past two summers and under the advisement of Aude Oliva, MIT director of the MIT-IBM Watson AI Lab and a senior research scientist in the Computer Science and Artificial Intelligence Laboratory; and IBM Research’s Rogerio Feris, Dan Gutfreund, and Leonid Karlinsky (now at Xero), Jovana Kondic of EECS has explored visual document understanding, specifically charts. These contain elements, such as data points, legends, and axes labels, that require optical character recognition and numerical reasoning, which models still struggle with. In order to facilitate the performance on tasks such as these, Kondic’s group set out to create a large, open-source, synthetic chart dataset from code that could be used for training and benchmarking.&amp;nbsp;&lt;/p&gt;&lt;p&gt;With their prototype, ChartGen, the researchers created a pipeline that passes seed chart images through a VLM, which is prompted to read the chart and generate a Python script that was likely used to create the chart in the first place. The LLM component of the framework then iteratively augments the code from many charts to ultimately produce over 200,000 unique pairs of charts and their codes, spanning nearly 30 chart types, as well as supporting data and annotation like descriptions and question-answer pairs about the charts. The team is further expanding their dataset, helping to enable critical multimodal understanding to data visualizations for enterprise applications like financial and scientific reports, blogs, and more.&lt;/p&gt;&lt;p&gt;Instead of charts, EECS graduate student Leonardo Hernandez Cano has his eyes on digital design, specifically visual texture generation for CAD applications and the goal of discovering efficient ways to enable to capabilities in VLMs. Teaming up with the lab groups led by Armando Solar-Lezama, EECS professor and Distinguished Professor of Computing in the MIT Schwarzman College of Computing, and IBM Research’s Nathan Fulton, Hernandez Cano created a program synthesis system that learns to refine code on its own. The system starts with a texture description given by a user in the form of an image. It then generates an initial Python program, which produces visual textures, and iteratively refines the code with the goal of finding a program that produces a texture that matches the target description, learning to search for new programs from the data that the system itself produces. Through these refinements, the novel program can create visualizations with the desired luminosity, color, iridescence, etc., mimicking real materials.&lt;/p&gt;&lt;p&gt;When viewed together, these projects, and the people behind them, are making a cohesive push toward more robust and practical artificial intelligence. By tackling the core challenges of reliability, efficiency, and multimodal reasoning, the work paves the way for AI systems that are not only more powerful, but also more dependable and cost-effective, for real-world enterprise and scientific applications.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/charting-the-future-of-ai-from-safer-answers-to-faster-thinking-1106</guid><pubDate>Thu, 06 Nov 2025 21:40:00 +0000</pubDate></item><item><title>Laude Institute announces first batch of ‘Slingshots’ AI grants (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/11/06/laude-institute-announces-first-batch-of-slingshots-ai-grants/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Laude-Slingshots-One.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, the Laude Institute announced its first batch of Slingshots grants, aimed at “advancing the science and practice of artificial intelligence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Designed as an accelerator for researchers, the Slingshots program is meant to provide resources that would be unavailable in most academic settings, whether it’s funding, compute power, or product and engineering support. In exchange, the recipients pledge to produce some final work product, whether it’s a startup, an open source codebase, or another type of artifact.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The initial cohort is 15 projects, with a particular focus on the difficult problem of AI evaluation. Some of those projects will be familiar to TechCrunch readers, including the command-line coding benchmark Terminal Bench and the latest version of the long-running ARC-AGI project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others take a fresh approach to a long-established evaluation problem. Formula Code, built by researchers at Caltech and UT Austin, aims to produce an evaluation of AI agents’ ability to optimize existing code, while the Columbia-based BizBench proposes a comprehensive benchmark for “white-collar AI agents.” Other grants explore new structures for reinforcement learning or model compression.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SWE-Bench co-founder John Boda Yang is also part of the cohort, as leader of the new CodeClash project. Inspired by the success of SWE-Bench, CodeClash will assess code through a dynamic competition-based framework, which Yang hopes will&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I do think people continuing to evaluate on core third-party benchmarks drives progress,” Yang told TechCrunch. “I’m a little bit worried about a future where benchmarks just become specific to companies.” &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/11/Laude-Slingshots-One.jpeg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, the Laude Institute announced its first batch of Slingshots grants, aimed at “advancing the science and practice of artificial intelligence.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Designed as an accelerator for researchers, the Slingshots program is meant to provide resources that would be unavailable in most academic settings, whether it’s funding, compute power, or product and engineering support. In exchange, the recipients pledge to produce some final work product, whether it’s a startup, an open source codebase, or another type of artifact.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The initial cohort is 15 projects, with a particular focus on the difficult problem of AI evaluation. Some of those projects will be familiar to TechCrunch readers, including the command-line coding benchmark Terminal Bench and the latest version of the long-running ARC-AGI project.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Others take a fresh approach to a long-established evaluation problem. Formula Code, built by researchers at Caltech and UT Austin, aims to produce an evaluation of AI agents’ ability to optimize existing code, while the Columbia-based BizBench proposes a comprehensive benchmark for “white-collar AI agents.” Other grants explore new structures for reinforcement learning or model compression.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SWE-Bench co-founder John Boda Yang is also part of the cohort, as leader of the new CodeClash project. Inspired by the success of SWE-Bench, CodeClash will assess code through a dynamic competition-based framework, which Yang hopes will&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I do think people continuing to evaluate on core third-party benchmarks drives progress,” Yang told TechCrunch. “I’m a little bit worried about a future where benchmarks just become specific to companies.” &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/11/06/laude-institute-announces-first-batch-of-slingshots-ai-grants/</guid><pubDate>Thu, 06 Nov 2025 21:55:05 +0000</pubDate></item></channel></rss>