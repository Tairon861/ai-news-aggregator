<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Wed, 17 Dec 2025 01:48:36 +0000</lastBuildDate><item><title>Zoom says it aced AI’s hardest exam. Critics say it copied off its neighbors. (AI | VentureBeat)</title><link>https://venturebeat.com/ai/zoom-says-it-aced-ais-hardest-exam-critics-say-it-copied-off-its-neighbors</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.zoom.com/"&gt;Zoom Video Communications&lt;/a&gt;, the company best known for keeping remote workers connected during the pandemic, announced last week that it had achieved the highest score ever recorded on one of artificial intelligence&amp;#x27;s most demanding tests — a claim that sent ripples of surprise, skepticism, and genuine curiosity through the technology industry.&lt;/p&gt;&lt;p&gt;The San Jose-based company said its AI system scored &lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough/?utm_source=social&amp;amp;utm_medium=organic-social"&gt;48.1 percent&lt;/a&gt; on the &lt;a href="https://agi.safe.ai/"&gt;Humanity&amp;#x27;s Last Exam&lt;/a&gt;, a benchmark designed by subject-matter experts worldwide to stump even the most advanced AI models. That result edges out Google&amp;#x27;s &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;Gemini 3 Pro&lt;/a&gt;, which held the previous record at 45.8 percent.&lt;/p&gt;&lt;p&gt;&amp;quot;Zoom has achieved a new state-of-the-art result on the challenging Humanity&amp;#x27;s Last Exam full-set benchmark, scoring 48.1%, which represents a substantial 2.3% improvement over the previous SOTA result,&amp;quot; wrote Xuedong Huang, Zoom&amp;#x27;s chief technology officer, in a &lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough"&gt;blog pos&lt;/a&gt;t.&lt;/p&gt;&lt;p&gt;The announcement raises a provocative question that has consumed AI watchers for days: How did a video conferencing company — one with no public history of training large language models — suddenly vault past &lt;a href="https://www.google.com/?zx=1765849295623&amp;amp;no_sw_cr=1"&gt;Google&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt; on a benchmark built to measure the frontiers of machine intelligence?&lt;/p&gt;&lt;p&gt;The answer reveals as much about where AI is headed as it does about Zoom&amp;#x27;s own technical ambitions. And depending on whom you ask, it&amp;#x27;s either an ingenious demonstration of practical engineering or a hollow claim that appropriates credit for others&amp;#x27; work.&lt;/p&gt;&lt;p&gt;&lt;b&gt;How Zoom built an AI traffic controller instead of training its own model&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Zoom did not train its own large language model. Instead, the company developed what it calls a &amp;quot;&lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough"&gt;federated AI approach&lt;/a&gt;&amp;quot; — a system that routes queries to multiple existing models from OpenAI, Google, and Anthropic, then uses proprietary software to select, combine, and refine their outputs.&lt;/p&gt;&lt;p&gt;At the heart of this system sits what Zoom calls its &amp;quot;&lt;a href="https://www.zoom.com/en/blog/federated-ai-approach-best-quality-for-most-popular-features/"&gt;Z-scorer&lt;/a&gt;,&amp;quot; a mechanism that evaluates responses from different models and chooses the best one for any given task. The company pairs this with what it describes as an &amp;quot;explore-verify-federate strategy,&amp;quot; an agentic workflow that balances exploratory reasoning with verification across multiple AI systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Our federated approach combines Zoom&amp;#x27;s own small language models with advanced open-source and closed-source models,&amp;quot; Huang wrote. The framework &amp;quot;orchestrates diverse models to generate, challenge, and refine reasoning through dialectical collaboration.&amp;quot;&lt;/p&gt;&lt;p&gt;In simpler terms: Zoom built a sophisticated traffic controller for AI, not the AI itself.&lt;/p&gt;&lt;p&gt;This distinction matters enormously in an industry where bragging rights — and billions in valuation — often hinge on who can claim the most capable model. The major AI laboratories spend hundreds of millions of dollars training frontier systems on vast computing clusters. Zoom&amp;#x27;s achievement, by contrast, appears to rest on clever integration of those existing systems.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI researchers are divided over what counts as real innovation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The response from the AI community was swift and sharply divided.&lt;/p&gt;&lt;p&gt;&lt;a href="https://x.com/maxrumpf"&gt;Max Rumpf&lt;/a&gt;, an AI engineer who says he has trained state-of-the-art language models, posted a pointed critique on social media. &amp;quot;Zoom strung together API calls to Gemini, GPT, Claude et al. and slightly improved on a benchmark that delivers no value for their customers,&amp;quot; he wrote. &amp;quot;They then claim SOTA.&amp;quot;&lt;/p&gt;&lt;p&gt;Rumpf did not dismiss the technical approach itself. Using multiple models for different tasks, he noted, is &amp;quot;actually quite smart and most applications should do this.&amp;quot; He pointed to Sierra, an AI customer service company, as an example of this multi-model strategy executed effectively.&lt;/p&gt;&lt;p&gt;His objection was more specific: &amp;quot;They did not train the model, but obfuscate this fact in the tweet. The injustice of taking credit for the work of others sits deeply with people.&amp;quot;&lt;/p&gt;&lt;p&gt;But other observers saw the achievement differently. &lt;a href="https://x.com/hzhu_/status/1999930478946820539"&gt;Hongcheng Zhu&lt;/a&gt;, a developer, offered a more measured assessment: &amp;quot;To top an AI eval, you will most likely need model federation, like what Zoom did. An analogy is that every Kaggle competitor knows you have to ensemble models to win a contest.&amp;quot;&lt;/p&gt;&lt;p&gt;The comparison to &lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; — the competitive data science platform where combining multiple models is standard practice among winning teams — reframes Zoom&amp;#x27;s approach as industry best practice rather than sleight of hand. Academic research has long established that ensemble methods routinely outperform individual models.&lt;/p&gt;&lt;p&gt;Still, the debate exposed a fault line in how the industry understands progress. &lt;a href="https://x.com/AIMachineDream"&gt;Ryan Pream&lt;/a&gt;, founder of Exoria AI, was dismissive: &amp;quot;Zoom are just creating a harness around another LLM and reporting that. It is just noise.&amp;quot; Another commenter captured the sheer unexpectedness of the news: &amp;quot;That the video conferencing app ZOOM developed a SOTA model that achieved 48% HLE was not on my bingo card.&amp;quot;&lt;/p&gt;&lt;p&gt;Perhaps the most pointed critique concerned priorities. Rumpf argued that Zoom could have directed its resources toward problems its customers actually face. &amp;quot;Retrieval over call transcripts is not &amp;#x27;solved&amp;#x27; by SOTA LLMs,&amp;quot; he wrote. &amp;quot;I figure Zoom&amp;#x27;s users would care about this much more than HLE.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The Microsoft veteran betting his reputation on a different kind of AI&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;If Zoom&amp;#x27;s benchmark result seemed to come from nowhere, its chief technology officer did not.&lt;/p&gt;&lt;p&gt;Xuedong Huang &lt;a href="https://venturebeat.com/ai/inside-zooms-ai-evolution-from-basic-meeting-tools-to-agentic-productivity-platform-powered-by-llms-and-slms"&gt;joined Zoom from Microsoft&lt;/a&gt;, where he spent decades building the company&amp;#x27;s AI capabilities. He founded Microsoft&amp;#x27;s speech technology group in 1993 and led teams that achieved what the company described as human parity in speech recognition, machine translation, natural language understanding, and computer vision.&lt;/p&gt;&lt;p&gt;Huang holds a Ph.D. in electrical engineering from the University of Edinburgh. He is an elected member of the &lt;a href="https://www.nae.edu/"&gt;National Academy of Engineering&lt;/a&gt; and the &lt;a href="https://www.amacad.org/person/xuedong-huang"&gt;American Academy of Arts and Sciences&lt;/a&gt;, as well as a fellow of both the &lt;a href="https://www.ieee.org/"&gt;IEEE&lt;/a&gt; and the &lt;a href="https://www.acm.org/"&gt;ACM&lt;/a&gt;. His credentials place him among the most accomplished AI executives in the industry.&lt;/p&gt;&lt;p&gt;His presence at Zoom signals that the company&amp;#x27;s AI ambitions are serious, even if its methods differ from the research laboratories that dominate headlines. In his tweet celebrating the benchmark result, Huang framed the achievement as validation of Zoom&amp;#x27;s strategy: &amp;quot;We have unlocked stronger capabilities in exploration, reasoning, and multi-model collaboration, surpassing the performance limits of any single model.&amp;quot;&lt;/p&gt;&lt;p&gt;That final clause — &amp;quot;surpassing the performance limits of any single model&amp;quot; — may be the most significant. Huang is not claiming Zoom built a better model. He is claiming Zoom built a better system for using models.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the test designed to stump the world&amp;#x27;s smartest machines&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The benchmark at the center of this controversy, &lt;a href="https://agi.safe.ai/"&gt;Humanity&amp;#x27;s Last Exam&lt;/a&gt;, was designed to be exceptionally difficult. Unlike earlier tests that AI systems learned to game through pattern matching, HLE presents problems that require genuine understanding, multi-step reasoning, and the synthesis of information across complex domains.&lt;/p&gt;&lt;p&gt;The exam draws on questions from experts around the world, spanning fields from advanced mathematics to philosophy to specialized scientific knowledge. A score of 48.1 percent might sound unimpressive to anyone accustomed to school grading curves, but in the context of HLE, it represents the current ceiling of machine performance.&lt;/p&gt;&lt;p&gt;&amp;quot;This benchmark was developed by subject-matter experts globally and has become a crucial metric for measuring AI&amp;#x27;s progress toward human-level performance on challenging intellectual tasks,&amp;quot; &lt;a href="https://www.zoom.com/en/blog/federated-ai-approach-best-quality-for-most-popular-features/"&gt;Zoom’s announcement noted&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s improvement of 2.3 percentage points over Google&amp;#x27;s previous best may appear modest in isolation. But in competitive benchmarking, where gains often come in fractions of a percent, such a jump commands attention.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Zoom&amp;#x27;s approach reveals about the future of enterprise AI&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zoom&amp;#x27;s approach carries implications that extend well beyond benchmark leaderboards. The company is signaling a vision for enterprise AI that differs fundamentally from the model-centric strategies pursued by &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;, and &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Rather than betting everything on building the single most capable model, Zoom is positioning itself as an orchestration layer — a company that can integrate the best capabilities from multiple providers and deliver them through products that businesses already use every day.&lt;/p&gt;&lt;p&gt;This strategy hedges against a critical uncertainty in the AI market: no one knows which model will be best next month, let alone next year. By building infrastructure that can swap between providers, Zoom avoids vendor lock-in while theoretically offering customers the best available AI for any given task.&lt;/p&gt;&lt;p&gt;The announcement of &lt;a href="https://openai.com/index/introducing-gpt-5-2/"&gt;OpenAI&amp;#x27;s GPT-5.2&lt;/a&gt; the following day underscored this dynamic. OpenAI&amp;#x27;s own communications named Zoom as a partner that had evaluated the new model&amp;#x27;s performance &amp;quot;across their AI workloads and saw measurable gains across the board.&amp;quot; Zoom, in other words, is both a customer of the frontier labs and now a competitor on their benchmarks — using their own technology.&lt;/p&gt;&lt;p&gt;This arrangement may prove sustainable. The major model providers have every incentive to sell API access widely, even to companies that might aggregate their outputs. The more interesting question is whether Zoom&amp;#x27;s orchestration capabilities constitute genuine intellectual property or merely sophisticated prompt engineering that others could replicate.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The real test arrives when Zoom&amp;#x27;s 300 million users start asking questions&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zoom titled its announcement section on industry relations &amp;quot;&lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough/"&gt;A Collaborative Future&lt;/a&gt;,&amp;quot; and Huang struck notes of gratitude throughout. &amp;quot;The future of AI is collaborative, not competitive,&amp;quot; he wrote. &amp;quot;By combining the best innovations from across the industry with our own research breakthroughs, we create solutions that are greater than the sum of their parts.&amp;quot;&lt;/p&gt;&lt;p&gt;This framing positions Zoom as a beneficent integrator, bringing together the industry&amp;#x27;s best work for the benefit of enterprise customers. Critics see something else: a company claiming the prestige of an AI laboratory without doing the foundational research that earns it.&lt;/p&gt;&lt;p&gt;The debate will likely be settled not by leaderboards but by products. When &lt;a href="https://news.zoom.com/zoom-launches-ai-companion-3-0/"&gt;AI Companion 3.0 &lt;/a&gt;reaches Zoom&amp;#x27;s hundreds of millions of users in the coming months, they will render their own verdict — not on benchmarks they have never heard of, but on whether the meeting summary actually captured what mattered, whether the action items made sense, whether the AI saved them time or wasted it.&lt;/p&gt;&lt;p&gt;In the end, Zoom&amp;#x27;s most provocative claim may not be that it topped a benchmark. It may be the implicit argument that in the age of AI, the best model is not the one you build — it&amp;#x27;s the one you know how to use.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://www.zoom.com/"&gt;Zoom Video Communications&lt;/a&gt;, the company best known for keeping remote workers connected during the pandemic, announced last week that it had achieved the highest score ever recorded on one of artificial intelligence&amp;#x27;s most demanding tests — a claim that sent ripples of surprise, skepticism, and genuine curiosity through the technology industry.&lt;/p&gt;&lt;p&gt;The San Jose-based company said its AI system scored &lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough/?utm_source=social&amp;amp;utm_medium=organic-social"&gt;48.1 percent&lt;/a&gt; on the &lt;a href="https://agi.safe.ai/"&gt;Humanity&amp;#x27;s Last Exam&lt;/a&gt;, a benchmark designed by subject-matter experts worldwide to stump even the most advanced AI models. That result edges out Google&amp;#x27;s &lt;a href="https://blog.google/products/gemini/gemini-3/"&gt;Gemini 3 Pro&lt;/a&gt;, which held the previous record at 45.8 percent.&lt;/p&gt;&lt;p&gt;&amp;quot;Zoom has achieved a new state-of-the-art result on the challenging Humanity&amp;#x27;s Last Exam full-set benchmark, scoring 48.1%, which represents a substantial 2.3% improvement over the previous SOTA result,&amp;quot; wrote Xuedong Huang, Zoom&amp;#x27;s chief technology officer, in a &lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough"&gt;blog pos&lt;/a&gt;t.&lt;/p&gt;&lt;p&gt;The announcement raises a provocative question that has consumed AI watchers for days: How did a video conferencing company — one with no public history of training large language models — suddenly vault past &lt;a href="https://www.google.com/?zx=1765849295623&amp;amp;no_sw_cr=1"&gt;Google&lt;/a&gt;, &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, and &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt; on a benchmark built to measure the frontiers of machine intelligence?&lt;/p&gt;&lt;p&gt;The answer reveals as much about where AI is headed as it does about Zoom&amp;#x27;s own technical ambitions. And depending on whom you ask, it&amp;#x27;s either an ingenious demonstration of practical engineering or a hollow claim that appropriates credit for others&amp;#x27; work.&lt;/p&gt;&lt;p&gt;&lt;b&gt;How Zoom built an AI traffic controller instead of training its own model&lt;/b&gt;&lt;/p&gt;&lt;p&gt;Zoom did not train its own large language model. Instead, the company developed what it calls a &amp;quot;&lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough"&gt;federated AI approach&lt;/a&gt;&amp;quot; — a system that routes queries to multiple existing models from OpenAI, Google, and Anthropic, then uses proprietary software to select, combine, and refine their outputs.&lt;/p&gt;&lt;p&gt;At the heart of this system sits what Zoom calls its &amp;quot;&lt;a href="https://www.zoom.com/en/blog/federated-ai-approach-best-quality-for-most-popular-features/"&gt;Z-scorer&lt;/a&gt;,&amp;quot; a mechanism that evaluates responses from different models and chooses the best one for any given task. The company pairs this with what it describes as an &amp;quot;explore-verify-federate strategy,&amp;quot; an agentic workflow that balances exploratory reasoning with verification across multiple AI systems.&lt;/p&gt;&lt;p&gt;&amp;quot;Our federated approach combines Zoom&amp;#x27;s own small language models with advanced open-source and closed-source models,&amp;quot; Huang wrote. The framework &amp;quot;orchestrates diverse models to generate, challenge, and refine reasoning through dialectical collaboration.&amp;quot;&lt;/p&gt;&lt;p&gt;In simpler terms: Zoom built a sophisticated traffic controller for AI, not the AI itself.&lt;/p&gt;&lt;p&gt;This distinction matters enormously in an industry where bragging rights — and billions in valuation — often hinge on who can claim the most capable model. The major AI laboratories spend hundreds of millions of dollars training frontier systems on vast computing clusters. Zoom&amp;#x27;s achievement, by contrast, appears to rest on clever integration of those existing systems.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI researchers are divided over what counts as real innovation&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The response from the AI community was swift and sharply divided.&lt;/p&gt;&lt;p&gt;&lt;a href="https://x.com/maxrumpf"&gt;Max Rumpf&lt;/a&gt;, an AI engineer who says he has trained state-of-the-art language models, posted a pointed critique on social media. &amp;quot;Zoom strung together API calls to Gemini, GPT, Claude et al. and slightly improved on a benchmark that delivers no value for their customers,&amp;quot; he wrote. &amp;quot;They then claim SOTA.&amp;quot;&lt;/p&gt;&lt;p&gt;Rumpf did not dismiss the technical approach itself. Using multiple models for different tasks, he noted, is &amp;quot;actually quite smart and most applications should do this.&amp;quot; He pointed to Sierra, an AI customer service company, as an example of this multi-model strategy executed effectively.&lt;/p&gt;&lt;p&gt;His objection was more specific: &amp;quot;They did not train the model, but obfuscate this fact in the tweet. The injustice of taking credit for the work of others sits deeply with people.&amp;quot;&lt;/p&gt;&lt;p&gt;But other observers saw the achievement differently. &lt;a href="https://x.com/hzhu_/status/1999930478946820539"&gt;Hongcheng Zhu&lt;/a&gt;, a developer, offered a more measured assessment: &amp;quot;To top an AI eval, you will most likely need model federation, like what Zoom did. An analogy is that every Kaggle competitor knows you have to ensemble models to win a contest.&amp;quot;&lt;/p&gt;&lt;p&gt;The comparison to &lt;a href="https://www.kaggle.com/"&gt;Kaggle&lt;/a&gt; — the competitive data science platform where combining multiple models is standard practice among winning teams — reframes Zoom&amp;#x27;s approach as industry best practice rather than sleight of hand. Academic research has long established that ensemble methods routinely outperform individual models.&lt;/p&gt;&lt;p&gt;Still, the debate exposed a fault line in how the industry understands progress. &lt;a href="https://x.com/AIMachineDream"&gt;Ryan Pream&lt;/a&gt;, founder of Exoria AI, was dismissive: &amp;quot;Zoom are just creating a harness around another LLM and reporting that. It is just noise.&amp;quot; Another commenter captured the sheer unexpectedness of the news: &amp;quot;That the video conferencing app ZOOM developed a SOTA model that achieved 48% HLE was not on my bingo card.&amp;quot;&lt;/p&gt;&lt;p&gt;Perhaps the most pointed critique concerned priorities. Rumpf argued that Zoom could have directed its resources toward problems its customers actually face. &amp;quot;Retrieval over call transcripts is not &amp;#x27;solved&amp;#x27; by SOTA LLMs,&amp;quot; he wrote. &amp;quot;I figure Zoom&amp;#x27;s users would care about this much more than HLE.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The Microsoft veteran betting his reputation on a different kind of AI&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;If Zoom&amp;#x27;s benchmark result seemed to come from nowhere, its chief technology officer did not.&lt;/p&gt;&lt;p&gt;Xuedong Huang &lt;a href="https://venturebeat.com/ai/inside-zooms-ai-evolution-from-basic-meeting-tools-to-agentic-productivity-platform-powered-by-llms-and-slms"&gt;joined Zoom from Microsoft&lt;/a&gt;, where he spent decades building the company&amp;#x27;s AI capabilities. He founded Microsoft&amp;#x27;s speech technology group in 1993 and led teams that achieved what the company described as human parity in speech recognition, machine translation, natural language understanding, and computer vision.&lt;/p&gt;&lt;p&gt;Huang holds a Ph.D. in electrical engineering from the University of Edinburgh. He is an elected member of the &lt;a href="https://www.nae.edu/"&gt;National Academy of Engineering&lt;/a&gt; and the &lt;a href="https://www.amacad.org/person/xuedong-huang"&gt;American Academy of Arts and Sciences&lt;/a&gt;, as well as a fellow of both the &lt;a href="https://www.ieee.org/"&gt;IEEE&lt;/a&gt; and the &lt;a href="https://www.acm.org/"&gt;ACM&lt;/a&gt;. His credentials place him among the most accomplished AI executives in the industry.&lt;/p&gt;&lt;p&gt;His presence at Zoom signals that the company&amp;#x27;s AI ambitions are serious, even if its methods differ from the research laboratories that dominate headlines. In his tweet celebrating the benchmark result, Huang framed the achievement as validation of Zoom&amp;#x27;s strategy: &amp;quot;We have unlocked stronger capabilities in exploration, reasoning, and multi-model collaboration, surpassing the performance limits of any single model.&amp;quot;&lt;/p&gt;&lt;p&gt;That final clause — &amp;quot;surpassing the performance limits of any single model&amp;quot; — may be the most significant. Huang is not claiming Zoom built a better model. He is claiming Zoom built a better system for using models.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the test designed to stump the world&amp;#x27;s smartest machines&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;The benchmark at the center of this controversy, &lt;a href="https://agi.safe.ai/"&gt;Humanity&amp;#x27;s Last Exam&lt;/a&gt;, was designed to be exceptionally difficult. Unlike earlier tests that AI systems learned to game through pattern matching, HLE presents problems that require genuine understanding, multi-step reasoning, and the synthesis of information across complex domains.&lt;/p&gt;&lt;p&gt;The exam draws on questions from experts around the world, spanning fields from advanced mathematics to philosophy to specialized scientific knowledge. A score of 48.1 percent might sound unimpressive to anyone accustomed to school grading curves, but in the context of HLE, it represents the current ceiling of machine performance.&lt;/p&gt;&lt;p&gt;&amp;quot;This benchmark was developed by subject-matter experts globally and has become a crucial metric for measuring AI&amp;#x27;s progress toward human-level performance on challenging intellectual tasks,&amp;quot; &lt;a href="https://www.zoom.com/en/blog/federated-ai-approach-best-quality-for-most-popular-features/"&gt;Zoom’s announcement noted&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s improvement of 2.3 percentage points over Google&amp;#x27;s previous best may appear modest in isolation. But in competitive benchmarking, where gains often come in fractions of a percent, such a jump commands attention.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Zoom&amp;#x27;s approach reveals about the future of enterprise AI&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zoom&amp;#x27;s approach carries implications that extend well beyond benchmark leaderboards. The company is signaling a vision for enterprise AI that differs fundamentally from the model-centric strategies pursued by &lt;a href="https://openai.com/"&gt;OpenAI&lt;/a&gt;, &lt;a href="https://www.anthropic.com/"&gt;Anthropic&lt;/a&gt;, and &lt;a href="https://www.google.com/"&gt;Google&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;Rather than betting everything on building the single most capable model, Zoom is positioning itself as an orchestration layer — a company that can integrate the best capabilities from multiple providers and deliver them through products that businesses already use every day.&lt;/p&gt;&lt;p&gt;This strategy hedges against a critical uncertainty in the AI market: no one knows which model will be best next month, let alone next year. By building infrastructure that can swap between providers, Zoom avoids vendor lock-in while theoretically offering customers the best available AI for any given task.&lt;/p&gt;&lt;p&gt;The announcement of &lt;a href="https://openai.com/index/introducing-gpt-5-2/"&gt;OpenAI&amp;#x27;s GPT-5.2&lt;/a&gt; the following day underscored this dynamic. OpenAI&amp;#x27;s own communications named Zoom as a partner that had evaluated the new model&amp;#x27;s performance &amp;quot;across their AI workloads and saw measurable gains across the board.&amp;quot; Zoom, in other words, is both a customer of the frontier labs and now a competitor on their benchmarks — using their own technology.&lt;/p&gt;&lt;p&gt;This arrangement may prove sustainable. The major model providers have every incentive to sell API access widely, even to companies that might aggregate their outputs. The more interesting question is whether Zoom&amp;#x27;s orchestration capabilities constitute genuine intellectual property or merely sophisticated prompt engineering that others could replicate.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The real test arrives when Zoom&amp;#x27;s 300 million users start asking questions&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zoom titled its announcement section on industry relations &amp;quot;&lt;a href="https://www.zoom.com/en/blog/humanitys-last-exam-zoom-ai-breakthrough/"&gt;A Collaborative Future&lt;/a&gt;,&amp;quot; and Huang struck notes of gratitude throughout. &amp;quot;The future of AI is collaborative, not competitive,&amp;quot; he wrote. &amp;quot;By combining the best innovations from across the industry with our own research breakthroughs, we create solutions that are greater than the sum of their parts.&amp;quot;&lt;/p&gt;&lt;p&gt;This framing positions Zoom as a beneficent integrator, bringing together the industry&amp;#x27;s best work for the benefit of enterprise customers. Critics see something else: a company claiming the prestige of an AI laboratory without doing the foundational research that earns it.&lt;/p&gt;&lt;p&gt;The debate will likely be settled not by leaderboards but by products. When &lt;a href="https://news.zoom.com/zoom-launches-ai-companion-3-0/"&gt;AI Companion 3.0 &lt;/a&gt;reaches Zoom&amp;#x27;s hundreds of millions of users in the coming months, they will render their own verdict — not on benchmarks they have never heard of, but on whether the meeting summary actually captured what mattered, whether the action items made sense, whether the AI saved them time or wasted it.&lt;/p&gt;&lt;p&gt;In the end, Zoom&amp;#x27;s most provocative claim may not be that it topped a benchmark. It may be the implicit argument that in the age of AI, the best model is not the one you build — it&amp;#x27;s the one you know how to use.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/zoom-says-it-aced-ais-hardest-exam-critics-say-it-copied-off-its-neighbors</guid><pubDate>Tue, 16 Dec 2025 14:00:00 +0000</pubDate></item><item><title>Zencoder drops Zenflow, a free AI orchestration tool that pits Claude against OpenAI’s models to catch coding errors (AI | VentureBeat)</title><link>https://venturebeat.com/ai/zencoder-drops-zenflow-a-free-ai-orchestration-tool-that-pits-claude-against</link><description>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt;, the Silicon Valley startup that builds AI-powered coding agents, released a free desktop application on Monday that it says will fundamentally change how software engineers interact with artificial intelligence — moving the industry beyond the freewheeling era of &amp;quot;vibe coding&amp;quot; toward a more disciplined, verifiable approach to AI-assisted development.&lt;/p&gt;&lt;p&gt;The product, called &lt;a href="https://zencoder.ai/zenflow"&gt;Zenflow&lt;/a&gt;, introduces what the company describes as an &amp;quot;AI orchestration layer&amp;quot; that coordinates multiple AI agents to plan, implement, test, and review code in structured workflows. The launch is Zencoder&amp;#x27;s most ambitious attempt yet to differentiate itself in an increasingly crowded market dominated by tools like &lt;a href="https://cursor.com/agents"&gt;Cursor&lt;/a&gt;, &lt;a href="https://github.com/features/copilot"&gt;GitHub Copilot&lt;/a&gt;, and coding agents built directly by AI giants &lt;a href="https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://chatgpt.com/features/codex"&gt;OpenAI&lt;/a&gt;, and &lt;a href="https://developers.googleblog.com/build-with-google-antigravity-our-new-agentic-development-platform/"&gt;Google&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Chat UIs were fine for copilots, but they break down when you try to scale,&amp;quot; said Andrew Filev, Zencoder&amp;#x27;s chief executive, in an exclusive interview with VentureBeat. &amp;quot;Teams are hitting a wall where speed without structure creates technical debt. Zenflow replaces &amp;#x27;Prompt Roulette&amp;#x27; with an engineering assembly line where agents plan, implement, and, crucially, verify each other&amp;#x27;s work.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement arrives at a critical moment for enterprise software development. Companies across industries have poured billions of dollars into AI coding tools over the past two years, hoping to dramatically accelerate their engineering output. Yet the promised productivity revolution has largely failed to materialize at scale.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI coding tools have failed to deliver on their 10x productivity promise&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Filev, who previously founded and sold the project management company &lt;a href="https://techcrunch.com/2021/01/19/citrix-is-acquiring-wrike-from-vista-for-2-25b/"&gt;Wrike to Citrix&lt;/a&gt;, pointed to a growing disconnect between AI coding hype and reality. While vendors have promised tenfold productivity gains, rigorous studies — including research from Stanford University — consistently show improvements closer to 20 percent.&lt;/p&gt;&lt;p&gt;&amp;quot;If you talk to real engineering leaders, I don&amp;#x27;t remember a single conversation where somebody vibe coded themselves to 2x or 5x or 10x productivity on serious engineering production,&amp;quot; Filev said. &amp;quot;The typical number you would hear would be about 20 percent.&amp;quot;&lt;/p&gt;&lt;p&gt;The problem, according to Filev, lies not with the AI models themselves but with how developers interact with them. The standard approach of typing requests into a chat interface and hoping for usable code works well for simple tasks but falls apart on complex enterprise projects.&lt;/p&gt;&lt;p&gt;Zencoder&amp;#x27;s internal engineering team claims to have cracked a different approach. Filev said the company now operates at roughly twice the velocity it achieved 12 months ago, not primarily because AI models improved, but because the team restructured its development processes.&lt;/p&gt;&lt;p&gt;&amp;quot;We had to change our process and use a variety of different best practices,&amp;quot; he said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the four pillars that power Zencoder&amp;#x27;s AI orchestration platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zenflow organizes its approach around four core capabilities that Zencoder argues any serious AI orchestration platform must support.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Structured workflows&lt;/b&gt; replace ad-hoc prompting with repeatable sequences (plan, implement, test, review) that agents follow consistently. Filev drew parallels to his experience building Wrike, noting that individual to-do lists rarely scale across organizations, while defined workflows create predictable outcomes.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Spec-driven development&lt;/b&gt; requires AI agents to first generate a technical specification, then create a step-by-step plan, and only then write code. The approach became so effective that frontier AI labs including Anthropic and OpenAI have since trained their models to follow it automatically. The specification anchors agents to clear requirements, preventing what Zencoder calls &amp;quot;iteration drift,&amp;quot; or the tendency for AI-generated code to gradually diverge from the original intent.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Multi-agent verification&lt;/b&gt; deploys different AI models to critique each other&amp;#x27;s work. Because AI models from the same family tend to share blind spots, Zencoder routes verification tasks across model providers, asking Claude to review code written by OpenAI&amp;#x27;s models, or vice versa.&lt;/p&gt;&lt;p&gt;&amp;quot;Think of it as a second opinion from a doctor,&amp;quot; Filev told VentureBeat. &amp;quot;With the right pipeline, we see results on par with what you&amp;#x27;d expect from Claude 5 or GPT-6. You&amp;#x27;re getting the benefit of a next-generation model today.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Parallel execution&lt;/b&gt; lets developers run multiple AI agents simultaneously in isolated sandboxes, preventing them from interfering with each other&amp;#x27;s work. The interface provides a command center for monitoring this fleet, a significant departure from the current practice of managing multiple terminal windows.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How verification solves AI coding&amp;#x27;s biggest reliability problem&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zencoder&amp;#x27;s emphasis on verification addresses one of the most persistent criticisms of AI-generated code: its tendency to produce &amp;quot;&lt;a href="https://www.cnbc.com/2025/12/15/merriam-webster-declares-slop-word-of-the-year-nod-to-growth-of-ai.html"&gt;slop&lt;/a&gt;,&amp;quot; or code that appears correct but fails in production or degrades over successive iterations.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s internal research found that developers who skip verification often fall into what Filev called a &amp;quot;death loop.&amp;quot; An AI agent completes a task successfully, but the developer, reluctant to review unfamiliar code, moves on without understanding what was written. When subsequent tasks fail, the developer lacks the context to fix problems manually and instead keeps prompting the AI for solutions.&lt;/p&gt;&lt;p&gt;&amp;quot;They literally spend more than a day in that death loop,&amp;quot; Filev said. &amp;quot;That&amp;#x27;s why the productivity is not 2x, because they were running at 3x first, and then they wasted the whole day.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://zencoder.ai/zenflow"&gt;multi-agent verification&lt;/a&gt; approach also gives Zencoder an unusual competitive advantage over the frontier AI labs themselves. While Anthropic, OpenAI, and Google each optimize their own models, Zencoder can mix and match across providers to reduce bias.&lt;/p&gt;&lt;p&gt;&amp;quot;This is a rare situation where we have an edge on the frontier labs,&amp;quot; Filev said. &amp;quot;Most of the time they have an edge on us, but this is a rare case.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Zencoder faces steep competition from AI giants and well-funded startups&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt; enters the AI orchestration market at a moment of intense competition. The company has positioned itself as a model-agnostic platform, supporting major providers including Anthropic, OpenAI, and Google Gemini. In September, Zencoder expanded its platform to let developers use command-line coding agents from any provider within its interface.&lt;/p&gt;&lt;p&gt;That strategy reflects a pragmatic acknowledgment that developers increasingly maintain relationships with multiple AI providers rather than committing exclusively to one. Zencoder&amp;#x27;s universal platform approach lets it serve as the orchestration layer regardless of which underlying models a company prefers.&lt;/p&gt;&lt;p&gt;The company also emphasizes enterprise readiness, touting &lt;a href="https://secureframe.com/blog/soc-2-type-ii"&gt;SOC 2 Type II&lt;/a&gt;, &lt;a href="https://www.iso.org/standard/27001"&gt;ISO 27001&lt;/a&gt;, and &lt;a href="https://www.iso.org/standard/42001"&gt;ISO 42001&lt;/a&gt; certifications along with GDPR compliance. These credentials matter for regulated industries like financial services and healthcare, where compliance requirements can block adoption of consumer-oriented AI tools.&lt;/p&gt;&lt;p&gt;But &lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt; faces formidable competition from multiple directions. &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt; and &lt;a href="https://windsurf.com/"&gt;Windsurf&lt;/a&gt; have built dedicated AI-first code editors with devoted user bases. &lt;a href="https://github.com/features/copilot"&gt;GitHub Copilot&lt;/a&gt; benefits from Microsoft&amp;#x27;s distribution muscle and deep integration with the world&amp;#x27;s largest code repository. And the frontier AI labs continue expanding their own coding capabilities.&lt;/p&gt;&lt;p&gt;Filev dismissed concerns about competition from the AI labs, arguing that smaller players like Zencoder can move faster on user experience innovation.&lt;/p&gt;&lt;p&gt;&amp;quot;I&amp;#x27;m sure they will come to the same conclusion, and they&amp;#x27;re smart and moving fast, so I&amp;#x27;m sure they will catch up fairly quickly,&amp;quot; he said. &amp;quot;That&amp;#x27;s why I said in the next six to 12 months, you&amp;#x27;re going to see a lot of this propagating through the whole space.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The case for adopting AI orchestration now instead of waiting for better models&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Technical executives weighing AI coding investments face a difficult timing question: Should they adopt orchestration tools now, or wait for frontier AI labs to build these capabilities natively into their models?&lt;/p&gt;&lt;p&gt;Filev argued that waiting carries significant competitive risk.&lt;/p&gt;&lt;p&gt;&amp;quot;Right now, everybody is under pressure to deliver more in less time, and everybody expects engineering leaders to deliver results from AI,&amp;quot; he said. &amp;quot;As a founder and CEO, I do not expect 20 percent from my VP of engineering. I expect 2x.&amp;quot;&lt;/p&gt;&lt;p&gt;He also questioned whether the major AI labs will prioritize orchestration capabilities when their core business remains model development.&lt;/p&gt;&lt;p&gt;&amp;quot;In the ideal world, frontier labs should be building the best-ever models and competing with each other, and Zencoders and Cursors need to build the best-ever UI and UX application layer on top of those models,&amp;quot; Filev said. &amp;quot;I don&amp;#x27;t see a world where OpenAI will offer you our code verifier, or vice versa.&amp;quot;&lt;/p&gt;&lt;p&gt;Zenflow launches as a &lt;a href="https://zencoder.ai/zenflow"&gt;free desktop application&lt;/a&gt;, with updated plugins available for &lt;a href="https://code.visualstudio.com/"&gt;Visual Studio Code&lt;/a&gt; and &lt;a href="https://www.jetbrains.com/"&gt;JetBrains&lt;/a&gt; integrated development environments. The product supports what Zencoder calls &amp;quot;dynamic workflows,&amp;quot; meaning the system automatically adjusts process complexity based on whether a human is actively monitoring and on the difficulty of the task at hand.&lt;/p&gt;&lt;p&gt;Zencoder said internal testing showed that replacing standard prompting with Zenflow&amp;#x27;s orchestration layer improved code correctness by approximately 20 percent on average.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Zencoder&amp;#x27;s bet on orchestration reveals about the future of AI coding&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt; frames &lt;a href="https://zencoder.ai/zenflow"&gt;Zenflow&lt;/a&gt; as the first product in what it expects to become a significant new software category. The company believes every vendor focused on AI coding will eventually arrive at similar conclusions about the need for orchestration tools.&lt;/p&gt;&lt;p&gt;&amp;quot;I think the next six to 12 months will be all about orchestration,&amp;quot; Filev predicted. &amp;quot;A lot of organizations will finally reach that 2x. Not 10x yet, but at least the 2x they were promised a year ago.&amp;quot;&lt;/p&gt;&lt;p&gt;Rather than competing head-to-head with frontier AI labs on model quality, Zencoder is betting that the application layer (the software that helps developers actually use these models effectively) will determine winners and losers.&lt;/p&gt;&lt;p&gt;It is, Filev suggested, a familiar pattern from technology history.&lt;/p&gt;&lt;p&gt;&amp;quot;This is very similar to what I observed when I started Wrike,&amp;quot; he said. &amp;quot;As work went digital, people relied on email and spreadsheets to manage everything, and neither could keep up.&amp;quot;&lt;/p&gt;&lt;p&gt;The same dynamic, he argued, now applies to AI coding. Chat interfaces were designed for conversation, not for orchestrating complex engineering workflows. Whether Zencoder can establish itself as the essential layer between developers and AI models before the giants build their own solutions remains an open question.&lt;/p&gt;&lt;p&gt;But Filev seems comfortable with the race. The last time he spotted a gap between how people worked and the tools they had to work with, he built a company worth over a billion dollars.&lt;/p&gt;&lt;p&gt;Zenflow is available immediately as a free download at &lt;a href="http://zencoder.ai/zenflow"&gt;zencoder.ai/zenflow&lt;/a&gt;.&lt;/p&gt;</description><content:encoded>[unable to retrieve full-text content]&lt;p&gt;&lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt;, the Silicon Valley startup that builds AI-powered coding agents, released a free desktop application on Monday that it says will fundamentally change how software engineers interact with artificial intelligence — moving the industry beyond the freewheeling era of &amp;quot;vibe coding&amp;quot; toward a more disciplined, verifiable approach to AI-assisted development.&lt;/p&gt;&lt;p&gt;The product, called &lt;a href="https://zencoder.ai/zenflow"&gt;Zenflow&lt;/a&gt;, introduces what the company describes as an &amp;quot;AI orchestration layer&amp;quot; that coordinates multiple AI agents to plan, implement, test, and review code in structured workflows. The launch is Zencoder&amp;#x27;s most ambitious attempt yet to differentiate itself in an increasingly crowded market dominated by tools like &lt;a href="https://cursor.com/agents"&gt;Cursor&lt;/a&gt;, &lt;a href="https://github.com/features/copilot"&gt;GitHub Copilot&lt;/a&gt;, and coding agents built directly by AI giants &lt;a href="https://www.anthropic.com/engineering/building-agents-with-the-claude-agent-sdk"&gt;Anthropic&lt;/a&gt;, &lt;a href="https://chatgpt.com/features/codex"&gt;OpenAI&lt;/a&gt;, and &lt;a href="https://developers.googleblog.com/build-with-google-antigravity-our-new-agentic-development-platform/"&gt;Google&lt;/a&gt;.&lt;/p&gt;&lt;p&gt;&amp;quot;Chat UIs were fine for copilots, but they break down when you try to scale,&amp;quot; said Andrew Filev, Zencoder&amp;#x27;s chief executive, in an exclusive interview with VentureBeat. &amp;quot;Teams are hitting a wall where speed without structure creates technical debt. Zenflow replaces &amp;#x27;Prompt Roulette&amp;#x27; with an engineering assembly line where agents plan, implement, and, crucially, verify each other&amp;#x27;s work.&amp;quot;&lt;/p&gt;&lt;p&gt;The announcement arrives at a critical moment for enterprise software development. Companies across industries have poured billions of dollars into AI coding tools over the past two years, hoping to dramatically accelerate their engineering output. Yet the promised productivity revolution has largely failed to materialize at scale.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Why AI coding tools have failed to deliver on their 10x productivity promise&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Filev, who previously founded and sold the project management company &lt;a href="https://techcrunch.com/2021/01/19/citrix-is-acquiring-wrike-from-vista-for-2-25b/"&gt;Wrike to Citrix&lt;/a&gt;, pointed to a growing disconnect between AI coding hype and reality. While vendors have promised tenfold productivity gains, rigorous studies — including research from Stanford University — consistently show improvements closer to 20 percent.&lt;/p&gt;&lt;p&gt;&amp;quot;If you talk to real engineering leaders, I don&amp;#x27;t remember a single conversation where somebody vibe coded themselves to 2x or 5x or 10x productivity on serious engineering production,&amp;quot; Filev said. &amp;quot;The typical number you would hear would be about 20 percent.&amp;quot;&lt;/p&gt;&lt;p&gt;The problem, according to Filev, lies not with the AI models themselves but with how developers interact with them. The standard approach of typing requests into a chat interface and hoping for usable code works well for simple tasks but falls apart on complex enterprise projects.&lt;/p&gt;&lt;p&gt;Zencoder&amp;#x27;s internal engineering team claims to have cracked a different approach. Filev said the company now operates at roughly twice the velocity it achieved 12 months ago, not primarily because AI models improved, but because the team restructured its development processes.&lt;/p&gt;&lt;p&gt;&amp;quot;We had to change our process and use a variety of different best practices,&amp;quot; he said.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Inside the four pillars that power Zencoder&amp;#x27;s AI orchestration platform&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zenflow organizes its approach around four core capabilities that Zencoder argues any serious AI orchestration platform must support.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Structured workflows&lt;/b&gt; replace ad-hoc prompting with repeatable sequences (plan, implement, test, review) that agents follow consistently. Filev drew parallels to his experience building Wrike, noting that individual to-do lists rarely scale across organizations, while defined workflows create predictable outcomes.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Spec-driven development&lt;/b&gt; requires AI agents to first generate a technical specification, then create a step-by-step plan, and only then write code. The approach became so effective that frontier AI labs including Anthropic and OpenAI have since trained their models to follow it automatically. The specification anchors agents to clear requirements, preventing what Zencoder calls &amp;quot;iteration drift,&amp;quot; or the tendency for AI-generated code to gradually diverge from the original intent.&lt;/p&gt;&lt;p&gt;&lt;b&gt;Multi-agent verification&lt;/b&gt; deploys different AI models to critique each other&amp;#x27;s work. Because AI models from the same family tend to share blind spots, Zencoder routes verification tasks across model providers, asking Claude to review code written by OpenAI&amp;#x27;s models, or vice versa.&lt;/p&gt;&lt;p&gt;&amp;quot;Think of it as a second opinion from a doctor,&amp;quot; Filev told VentureBeat. &amp;quot;With the right pipeline, we see results on par with what you&amp;#x27;d expect from Claude 5 or GPT-6. You&amp;#x27;re getting the benefit of a next-generation model today.&amp;quot;&lt;/p&gt;&lt;p&gt;&lt;b&gt;Parallel execution&lt;/b&gt; lets developers run multiple AI agents simultaneously in isolated sandboxes, preventing them from interfering with each other&amp;#x27;s work. The interface provides a command center for monitoring this fleet, a significant departure from the current practice of managing multiple terminal windows.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;How verification solves AI coding&amp;#x27;s biggest reliability problem&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Zencoder&amp;#x27;s emphasis on verification addresses one of the most persistent criticisms of AI-generated code: its tendency to produce &amp;quot;&lt;a href="https://www.cnbc.com/2025/12/15/merriam-webster-declares-slop-word-of-the-year-nod-to-growth-of-ai.html"&gt;slop&lt;/a&gt;,&amp;quot; or code that appears correct but fails in production or degrades over successive iterations.&lt;/p&gt;&lt;p&gt;The company&amp;#x27;s internal research found that developers who skip verification often fall into what Filev called a &amp;quot;death loop.&amp;quot; An AI agent completes a task successfully, but the developer, reluctant to review unfamiliar code, moves on without understanding what was written. When subsequent tasks fail, the developer lacks the context to fix problems manually and instead keeps prompting the AI for solutions.&lt;/p&gt;&lt;p&gt;&amp;quot;They literally spend more than a day in that death loop,&amp;quot; Filev said. &amp;quot;That&amp;#x27;s why the productivity is not 2x, because they were running at 3x first, and then they wasted the whole day.&amp;quot;&lt;/p&gt;&lt;p&gt;The &lt;a href="https://zencoder.ai/zenflow"&gt;multi-agent verification&lt;/a&gt; approach also gives Zencoder an unusual competitive advantage over the frontier AI labs themselves. While Anthropic, OpenAI, and Google each optimize their own models, Zencoder can mix and match across providers to reduce bias.&lt;/p&gt;&lt;p&gt;&amp;quot;This is a rare situation where we have an edge on the frontier labs,&amp;quot; Filev said. &amp;quot;Most of the time they have an edge on us, but this is a rare case.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;Zencoder faces steep competition from AI giants and well-funded startups&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt; enters the AI orchestration market at a moment of intense competition. The company has positioned itself as a model-agnostic platform, supporting major providers including Anthropic, OpenAI, and Google Gemini. In September, Zencoder expanded its platform to let developers use command-line coding agents from any provider within its interface.&lt;/p&gt;&lt;p&gt;That strategy reflects a pragmatic acknowledgment that developers increasingly maintain relationships with multiple AI providers rather than committing exclusively to one. Zencoder&amp;#x27;s universal platform approach lets it serve as the orchestration layer regardless of which underlying models a company prefers.&lt;/p&gt;&lt;p&gt;The company also emphasizes enterprise readiness, touting &lt;a href="https://secureframe.com/blog/soc-2-type-ii"&gt;SOC 2 Type II&lt;/a&gt;, &lt;a href="https://www.iso.org/standard/27001"&gt;ISO 27001&lt;/a&gt;, and &lt;a href="https://www.iso.org/standard/42001"&gt;ISO 42001&lt;/a&gt; certifications along with GDPR compliance. These credentials matter for regulated industries like financial services and healthcare, where compliance requirements can block adoption of consumer-oriented AI tools.&lt;/p&gt;&lt;p&gt;But &lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt; faces formidable competition from multiple directions. &lt;a href="https://cursor.com/"&gt;Cursor&lt;/a&gt; and &lt;a href="https://windsurf.com/"&gt;Windsurf&lt;/a&gt; have built dedicated AI-first code editors with devoted user bases. &lt;a href="https://github.com/features/copilot"&gt;GitHub Copilot&lt;/a&gt; benefits from Microsoft&amp;#x27;s distribution muscle and deep integration with the world&amp;#x27;s largest code repository. And the frontier AI labs continue expanding their own coding capabilities.&lt;/p&gt;&lt;p&gt;Filev dismissed concerns about competition from the AI labs, arguing that smaller players like Zencoder can move faster on user experience innovation.&lt;/p&gt;&lt;p&gt;&amp;quot;I&amp;#x27;m sure they will come to the same conclusion, and they&amp;#x27;re smart and moving fast, so I&amp;#x27;m sure they will catch up fairly quickly,&amp;quot; he said. &amp;quot;That&amp;#x27;s why I said in the next six to 12 months, you&amp;#x27;re going to see a lot of this propagating through the whole space.&amp;quot;&lt;/p&gt;&lt;h2&gt;&lt;b&gt;The case for adopting AI orchestration now instead of waiting for better models&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;Technical executives weighing AI coding investments face a difficult timing question: Should they adopt orchestration tools now, or wait for frontier AI labs to build these capabilities natively into their models?&lt;/p&gt;&lt;p&gt;Filev argued that waiting carries significant competitive risk.&lt;/p&gt;&lt;p&gt;&amp;quot;Right now, everybody is under pressure to deliver more in less time, and everybody expects engineering leaders to deliver results from AI,&amp;quot; he said. &amp;quot;As a founder and CEO, I do not expect 20 percent from my VP of engineering. I expect 2x.&amp;quot;&lt;/p&gt;&lt;p&gt;He also questioned whether the major AI labs will prioritize orchestration capabilities when their core business remains model development.&lt;/p&gt;&lt;p&gt;&amp;quot;In the ideal world, frontier labs should be building the best-ever models and competing with each other, and Zencoders and Cursors need to build the best-ever UI and UX application layer on top of those models,&amp;quot; Filev said. &amp;quot;I don&amp;#x27;t see a world where OpenAI will offer you our code verifier, or vice versa.&amp;quot;&lt;/p&gt;&lt;p&gt;Zenflow launches as a &lt;a href="https://zencoder.ai/zenflow"&gt;free desktop application&lt;/a&gt;, with updated plugins available for &lt;a href="https://code.visualstudio.com/"&gt;Visual Studio Code&lt;/a&gt; and &lt;a href="https://www.jetbrains.com/"&gt;JetBrains&lt;/a&gt; integrated development environments. The product supports what Zencoder calls &amp;quot;dynamic workflows,&amp;quot; meaning the system automatically adjusts process complexity based on whether a human is actively monitoring and on the difficulty of the task at hand.&lt;/p&gt;&lt;p&gt;Zencoder said internal testing showed that replacing standard prompting with Zenflow&amp;#x27;s orchestration layer improved code correctness by approximately 20 percent on average.&lt;/p&gt;&lt;h2&gt;&lt;b&gt;What Zencoder&amp;#x27;s bet on orchestration reveals about the future of AI coding&lt;/b&gt;&lt;/h2&gt;&lt;p&gt;&lt;a href="https://zencoder.ai/"&gt;Zencoder&lt;/a&gt; frames &lt;a href="https://zencoder.ai/zenflow"&gt;Zenflow&lt;/a&gt; as the first product in what it expects to become a significant new software category. The company believes every vendor focused on AI coding will eventually arrive at similar conclusions about the need for orchestration tools.&lt;/p&gt;&lt;p&gt;&amp;quot;I think the next six to 12 months will be all about orchestration,&amp;quot; Filev predicted. &amp;quot;A lot of organizations will finally reach that 2x. Not 10x yet, but at least the 2x they were promised a year ago.&amp;quot;&lt;/p&gt;&lt;p&gt;Rather than competing head-to-head with frontier AI labs on model quality, Zencoder is betting that the application layer (the software that helps developers actually use these models effectively) will determine winners and losers.&lt;/p&gt;&lt;p&gt;It is, Filev suggested, a familiar pattern from technology history.&lt;/p&gt;&lt;p&gt;&amp;quot;This is very similar to what I observed when I started Wrike,&amp;quot; he said. &amp;quot;As work went digital, people relied on email and spreadsheets to manage everything, and neither could keep up.&amp;quot;&lt;/p&gt;&lt;p&gt;The same dynamic, he argued, now applies to AI coding. Chat interfaces were designed for conversation, not for orchestrating complex engineering workflows. Whether Zencoder can establish itself as the essential layer between developers and AI models before the giants build their own solutions remains an open question.&lt;/p&gt;&lt;p&gt;But Filev seems comfortable with the race. The last time he spotted a gap between how people worked and the tools they had to work with, he built a company worth over a billion dollars.&lt;/p&gt;&lt;p&gt;Zenflow is available immediately as a free download at &lt;a href="http://zencoder.ai/zenflow"&gt;zencoder.ai/zenflow&lt;/a&gt;.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://venturebeat.com/ai/zencoder-drops-zenflow-a-free-ai-orchestration-tool-that-pits-claude-against</guid><pubDate>Tue, 16 Dec 2025 14:00:00 +0000</pubDate></item><item><title>Adobe Firefly now supports prompt-based video editing, adds more third-party models (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/16/adobe-firefly-now-supports-prompt-based-video-editing-adds-more-third-party-models/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe is updating its AI video-generation app, Firefly, with a new video editor that supports precise prompt-based edits, as well as adding new third-party models for image and video generation, including Black Forest Labs’ FLUX.2 and Topaz Astra. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Until now, Firefly only supported prompt-based generation, so you would have to recreate the entire clip if any part of the video was not to your liking. With the new editor, you can use text prompts to edit video elements, colors, and camera angles, and we also get a new timeline view that lets you adjust frames, sounds, and other characteristics easily.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company first announced the new video editor in October in private beta, and now it is rolling out to all users.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3076355" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Firefly-Video-Editor-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that using Runway’s Aleph model, users can give Firefly specific instructions, such as “Change the sky to overcast and lower the contrast” or “Zoom in slightly on the main subject.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And with Adobe’s own Firefly Video model, users can now do stuff like upload a start frame and a reference video of a camera motion and tell it to recreate that camera angle for the video they’re working on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also said users can now use the Topaz Labs’ Astra model to upscale videos to 1080p or 4K. Black Forest Labs’ FLUX.2 image generation model is coming to the app, too, along with a collaborative boards feature. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said FLUX.2 will be available on Firefly across platforms immediately, and Adobe Express users will be able to use FLUX.2 from January.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3076354" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Topaz-Astra-Video-Upscaling.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With competitors releasing new models for image and video generation, Adobe wants to lure users into engaging with its app more. Along with new updates to the Firefly app, the company said subscribers of the Firefly Pro, Firefly Premium, 7,000-credit, and 50,000-credit plans will get unlimited generations from all image models and the Adobe Firefly Video Model in the Firefly app until January 15.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe has made a ton of changes to its Firefly models and apps this year. In February, the company launched a subscription that let users access various levels of image and video generation; then it launched a new Firefly web app along with mobile apps later in the year, and has added support for more third-party models within the Firefly app.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Adobe is updating its AI video-generation app, Firefly, with a new video editor that supports precise prompt-based edits, as well as adding new third-party models for image and video generation, including Black Forest Labs’ FLUX.2 and Topaz Astra. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Until now, Firefly only supported prompt-based generation, so you would have to recreate the entire clip if any part of the video was not to your liking. With the new editor, you can use text prompts to edit video elements, colors, and camera angles, and we also get a new timeline view that lets you adjust frames, sounds, and other characteristics easily.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company first announced the new video editor in October in private beta, and now it is rolling out to all users.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large is-resized"&gt;&lt;img alt="alt" class="wp-image-3076355" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Firefly-Video-Editor-2.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The company said that using Runway’s Aleph model, users can give Firefly specific instructions, such as “Change the sky to overcast and lower the contrast” or “Zoom in slightly on the main subject.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;And with Adobe’s own Firefly Video model, users can now do stuff like upload a start frame and a reference video of a camera motion and tell it to recreate that camera angle for the video they’re working on.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also said users can now use the Topaz Labs’ Astra model to upscale videos to 1080p or 4K. Black Forest Labs’ FLUX.2 image generation model is coming to the app, too, along with a collaborative boards feature. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company said FLUX.2 will be available on Firefly across platforms immediately, and Adobe Express users will be able to use FLUX.2 from January.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3076354" height="680" src="https://techcrunch.com/wp-content/uploads/2025/12/Topaz-Astra-Video-Upscaling.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Adobe&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;With competitors releasing new models for image and video generation, Adobe wants to lure users into engaging with its app more. Along with new updates to the Firefly app, the company said subscribers of the Firefly Pro, Firefly Premium, 7,000-credit, and 50,000-credit plans will get unlimited generations from all image models and the Adobe Firefly Video Model in the Firefly app until January 15.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Adobe has made a ton of changes to its Firefly models and apps this year. In February, the company launched a subscription that let users access various levels of image and video generation; then it launched a new Firefly web app along with mobile apps later in the year, and has added support for more third-party models within the Firefly app.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/16/adobe-firefly-now-supports-prompt-based-video-editing-adds-more-third-party-models/</guid><pubDate>Tue, 16 Dec 2025 14:00:00 +0000</pubDate></item><item><title>Databricks raises $4B at $134B valuation as its AI business heats up (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/16/databricks-raises-4b-at-134b-valuation-as-its-ai-business-heats-up/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/tc-databricks-only-1600x900-1.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The IPO window may have cracked open, but it seems some former startups have no intention of going public. Makes sense, in a way: IPOs were traditionally a way to raise money, and if you can manage to raise ungodly amounts without having to put your company through public scrutiny, why do it?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks is proving that point: The data intelligence company has just raised more than $4 billion in a Series L funding round at a $134 billion valuation — up 34% from the $100 billion valuation that it achieved just three months ago.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is Databricks’ third major venture fundraise in less than a year, and it comes as the company focuses on building products that address the needs of the AI revolution: a database for AI agents, an AI agent platform, and apps that let companies build and deploy data and AI applications. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is investing heavily in its database for AI agents, known as Lakebase, which is based on the open source database Postgres (enabled by the $1 billion acquisition of a startup called Neon), and is aimed at corporate developers’ vibe-coding projects. Meanwhile, its AI agent platform, Agent Bricks, is aimed at helping businesses build and deploy AI agents that can tap into their data. The company has also struck hefty deals worth hundreds of millions with AI labs Anthropic and OpenAI to offer their models within its enterprise products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Series L rounds aren’t really common, but the fact that Databricks has managed to raise venture funding at ever-increasing valuations (it was valued at $60 billion around this time last year) indicates how strongly investors believe in the power of helping companies use data to fuel their AI efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, Databricks on Tuesday said it now generates run-rate revenue of more than $4.8 billion, up 55% from a year earlier, of which more than $1 billion came from its AI products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The parallel rise of vibe coding and generative AI is accelerating the development of data-intelligent applications in the enterprise. Databricks will use this new capital to help customers build AI apps and agents on their proprietary data, leveraging Lakebase as the system of record, Databricks Apps as the user experience layer, and Agent Bricks to power multi-agent systems,” the company said in a press release.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Wall Street Journal reports that the company will also use the new money to add thousands of new jobs in Asia, Europe, and Latin America, as well as bring on more AI researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Enterprises are rapidly reimagining how they build intelligent applications, and the convergence of generative AI with new coding paradigms is opening the door to entirely new workloads,” Databricks’ co-founder and CEO Ali Ghodsi said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was led by Insight Partners, Fidelity, and J.P. Morgan Asset Management. Andreessen Horowitz, BlackRock, Blackstone, Coatue, GIC, MGX, NEA, Ontario Teachers Pension Plan, Robinhood Ventures, T. Rowe Price Associates, Temasek, Thrive Capital, and Winslow Capital also participated.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/tc-databricks-only-1600x900-1.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The IPO window may have cracked open, but it seems some former startups have no intention of going public. Makes sense, in a way: IPOs were traditionally a way to raise money, and if you can manage to raise ungodly amounts without having to put your company through public scrutiny, why do it?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Databricks is proving that point: The data intelligence company has just raised more than $4 billion in a Series L funding round at a $134 billion valuation — up 34% from the $100 billion valuation that it achieved just three months ago.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;This is Databricks’ third major venture fundraise in less than a year, and it comes as the company focuses on building products that address the needs of the AI revolution: a database for AI agents, an AI agent platform, and apps that let companies build and deploy data and AI applications. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is investing heavily in its database for AI agents, known as Lakebase, which is based on the open source database Postgres (enabled by the $1 billion acquisition of a startup called Neon), and is aimed at corporate developers’ vibe-coding projects. Meanwhile, its AI agent platform, Agent Bricks, is aimed at helping businesses build and deploy AI agents that can tap into their data. The company has also struck hefty deals worth hundreds of millions with AI labs Anthropic and OpenAI to offer their models within its enterprise products.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Series L rounds aren’t really common, but the fact that Databricks has managed to raise venture funding at ever-increasing valuations (it was valued at $60 billion around this time last year) indicates how strongly investors believe in the power of helping companies use data to fuel their AI efforts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Indeed, Databricks on Tuesday said it now generates run-rate revenue of more than $4.8 billion, up 55% from a year earlier, of which more than $1 billion came from its AI products. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The parallel rise of vibe coding and generative AI is accelerating the development of data-intelligent applications in the enterprise. Databricks will use this new capital to help customers build AI apps and agents on their proprietary data, leveraging Lakebase as the system of record, Databricks Apps as the user experience layer, and Agent Bricks to power multi-agent systems,” the company said in a press release.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Wall Street Journal reports that the company will also use the new money to add thousands of new jobs in Asia, Europe, and Latin America, as well as bring on more AI researchers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Enterprises are rapidly reimagining how they build intelligent applications, and the convergence of generative AI with new coding paradigms is opening the door to entirely new workloads,” Databricks’ co-founder and CEO Ali Ghodsi said in a statement.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The round was led by Insight Partners, Fidelity, and J.P. Morgan Asset Management. Andreessen Horowitz, BlackRock, Blackstone, Coatue, GIC, MGX, NEA, Ontario Teachers Pension Plan, Robinhood Ventures, T. Rowe Price Associates, Temasek, Thrive Capital, and Winslow Capital also participated.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/16/databricks-raises-4b-at-134b-valuation-as-its-ai-business-heats-up/</guid><pubDate>Tue, 16 Dec 2025 14:39:20 +0000</pubDate></item><item><title>Creating psychological safety in the AI era (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/12/16/1125899/creating-psychological-safety-in-the-ai-era/</link><description>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Infosys Topaz&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Rolling out enterprise-grade AI means climbing two steep cliffs at once. First, understanding and implementing the tech itself. And second, creating the cultural conditions where employees can maximize its value. While the technical hurdles are signiﬁcant, the human element can be even more consequential; fear and ambiguity can stall momentum of even the most promising initiatives.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1125914" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Cover-MITTRI-Infosys-Creating-psychological-safety-in-the-AI-era.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;Psychological safety—feeling free to express opinions and take calculated risks without worrying about career repercussions1—is essential for successful AI adoption. In psychologically safe workspaces, employees are empowered to challenge assumptions and raise concerns about new tools without fear of reprisal. This is nothing short of a necessity when introducing a nascent and profoundly powerful technology that still lacks established best practices.&lt;br /&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“Psychological safety is mandatory in this new era of AI,” says Rafee Tarafdar, executive vice president and chief technology officer at Infosys. “The tech itself is evolving so fast—companies have to experiment, and some things will fail. There needs to be a safety net.”&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;To gauge how psychological safety influences success with enterprise-level AI, MIT Technology Review Insights conducted a survey of 500 business leaders. The ﬁndings reveal high self-reported levels of psychological safety, but also suggest that fear still has a foothold. Anecdotally, industry experts highlight a reason for the disconnect between rhetoric and reality: while organizations may promote a safe to experiment message publicly, deeper cultural undercurrents can counteract that intent. &lt;/p&gt; 
 &lt;p&gt;Building psychological safety requires a coordinated, systems-level approach, and human resources (HR) alone cannot deliver such transformation. Instead, enterprises must deeply embed psychological safety into their collaboration processes.&lt;br /&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126105" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Infosys-Social-Card-2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Key ﬁndings for this report include:&lt;/p&gt; 
 &lt;ul class="wp-block-list"&gt; &lt;li&gt;Companies with experiment-friendly cultures have greater success with AI projects. The majority of executives surveyed (83%) believe a company culture that prioritizes psychological safety measurably improves the success of AI initiatives. Four in ﬁve leaders agree that organizations fostering such safety are more successful at adopting AI, and 84% have observed connections between psychological safety and tangible AI outcomes.&lt;/li&gt;    &lt;li&gt;Psychological barriers are proving to be greater obstacles to enterprise AI adoption than technological challenges. Encouragingly, nearly three-quarters (73%) of respondents indicated they feel safe to provide honest feedback and express opinions freely in their workplace. Still, a signiﬁcant share (22%) admit they’ve hesitated to lead an AI project because they might be blamed if it misﬁres.&lt;/li&gt;    &lt;li&gt;Achieving psychological safety is a moving target for many organizations. Fewer than half of leaders (39%) rate their organization’s current level of psychological safety as “very high.” Another 48%report a “moderate” degree of it. This may mean that some enterprises are pursuing AI adoption on cultural foundations that are not yet fully stable.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;em&gt;Download the report&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In partnership with&lt;/span&gt;Infosys Topaz&lt;/p&gt;&lt;span class="image__wrapper--373a87c0cefdc42b3a8bd26457571412"&gt;&lt;span class=" lazy-load-image-background opacity"&gt;&lt;span class="image__img--e1a73f503bf0f4a3d2504e1d64ea29cb imgLazyLoaded"&gt;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;figcaption class="image__meta--16eb0f8dde685315ba1d77ae67c89391"&gt;&lt;/figcaption&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Rolling out enterprise-grade AI means climbing two steep cliffs at once. First, understanding and implementing the tech itself. And second, creating the cultural conditions where employees can maximize its value. While the technical hurdles are signiﬁcant, the human element can be even more consequential; fear and ambiguity can stall momentum of even the most promising initiatives.&lt;/p&gt;  &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1125914" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Cover-MITTRI-Infosys-Creating-psychological-safety-in-the-AI-era.png?w=1556" width="1556" /&gt;&lt;/figure&gt;  &lt;p&gt;Psychological safety—feeling free to express opinions and take calculated risks without worrying about career repercussions1—is essential for successful AI adoption. In psychologically safe workspaces, employees are empowered to challenge assumptions and raise concerns about new tools without fear of reprisal. This is nothing short of a necessity when introducing a nascent and profoundly powerful technology that still lacks established best practices.&lt;br /&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt;  &lt;p&gt;“Psychological safety is mandatory in this new era of AI,” says Rafee Tarafdar, executive vice president and chief technology officer at Infosys. “The tech itself is evolving so fast—companies have to experiment, and some things will fail. There needs to be a safety net.”&lt;br /&gt;&lt;/p&gt;  &lt;p&gt;To gauge how psychological safety influences success with enterprise-level AI, MIT Technology Review Insights conducted a survey of 500 business leaders. The ﬁndings reveal high self-reported levels of psychological safety, but also suggest that fear still has a foothold. Anecdotally, industry experts highlight a reason for the disconnect between rhetoric and reality: while organizations may promote a safe to experiment message publicly, deeper cultural undercurrents can counteract that intent. &lt;/p&gt; 
 &lt;p&gt;Building psychological safety requires a coordinated, systems-level approach, and human resources (HR) alone cannot deliver such transformation. Instead, enterprises must deeply embed psychological safety into their collaboration processes.&lt;br /&gt;&lt;/p&gt;  &lt;figure class="wp-block-image size-full"&gt;&lt;img alt="alt" class="wp-image-1126105" src="https://wp.technologyreview.com/wp-content/uploads/2025/10/Infosys-Social-Card-2.png" /&gt;&lt;/figure&gt;  &lt;p&gt;Key ﬁndings for this report include:&lt;/p&gt; 
 &lt;ul class="wp-block-list"&gt; &lt;li&gt;Companies with experiment-friendly cultures have greater success with AI projects. The majority of executives surveyed (83%) believe a company culture that prioritizes psychological safety measurably improves the success of AI initiatives. Four in ﬁve leaders agree that organizations fostering such safety are more successful at adopting AI, and 84% have observed connections between psychological safety and tangible AI outcomes.&lt;/li&gt;    &lt;li&gt;Psychological barriers are proving to be greater obstacles to enterprise AI adoption than technological challenges. Encouragingly, nearly three-quarters (73%) of respondents indicated they feel safe to provide honest feedback and express opinions freely in their workplace. Still, a signiﬁcant share (22%) admit they’ve hesitated to lead an AI project because they might be blamed if it misﬁres.&lt;/li&gt;    &lt;li&gt;Achieving psychological safety is a moving target for many organizations. Fewer than half of leaders (39%) rate their organization’s current level of psychological safety as “very high.” Another 48%report a “moderate” degree of it. This may mean that some enterprises are pursuing AI adoption on cultural foundations that are not yet fully stable.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;&lt;em&gt;Download the report&lt;/em&gt;.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/12/16/1125899/creating-psychological-safety-in-the-ai-era/</guid><pubDate>Tue, 16 Dec 2025 15:00:00 +0000</pubDate></item><item><title>What AI search tools mean for the future of SEO specialists (AI News)</title><link>https://www.artificialintelligence-news.com/news/what-ai-search-tools-mean-for-the-future-of-seo-specialists/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/Picture1-2.jpg" /&gt;&lt;/div&gt;&lt;p&gt;AI search engines and generative AI tools are certainly transforming how people discover information online. Far from making SEO specialists obsolete, the shift highlights clearly why skilled human optimisers remain more important than ever.&lt;/p&gt;&lt;p&gt;As generative AI search tools reshape the digital landscape, many wonder whether traditional SEO has reached the end. Despite AI’s growing influence, the fundamentals of discoverability, authority, clarity, and trust remain vital. The rise of AI-powered search makes the role of SEO specialists more important than before, ensuring content not only reaches audiences but resonates authentically. A digital environment shaped by automation still depends heavily on human expertise, especially when credibility is at stake.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-ai-expands-rather-than-replaces-the-work-of-seo-specialists"&gt;Why AI expands rather than replaces the work of SEO specialists&lt;/h3&gt;&lt;p&gt;The assumption that AI will replace SEO specialists ignores how modern search works. AI expands what optimisation can achieve, but it does not eliminate the need for skilled human oversight. Traditional ranking signals like site structure, depth of information, internal linking and authority continue to influence visibility, even in AI-driven answer engines. This means content must still be crafted with intent, clarity, and expertise.&lt;/p&gt;&lt;p&gt;AI-powered search engines prioritise well-structured, trustworthy information, reinforcing the importance of thoughtful optimisation. In this brand new landscape, SEO now spans two parallel environments: classic search engines and AI-generated answer systems. Competing effectively in both requires strategic thinking, careful content planning, and a nuanced understanding of user intent: areas where human specialists excel, beyond what AI can replicate.&lt;/p&gt;&lt;p&gt;Agencies like Brath, which presents SEO as one of the most profitable long-term marketing channels when executed with technical precision and strategic insight, clearly understand this reality. Its service model remains grounded in proven disciplines: technical improvements, keyword strategy, content refinement, and authority building. Rather than leaning on automation, it demonstrates that sustainable SEO relies on human expertise, methodical analysis, and consistent optimisation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-human-insight-still-drives-strategy-in-an-ai-powered-search-world"&gt;Human insight still drives strategy in an AI-powered search world&lt;/h3&gt;&lt;p&gt;AI excels at processing data, but it still falls short when deeper context, cultural awareness, and nuanced decision-making are required. SEO is more than a technical exercise; it is a strategic craft rooted in understanding people, their motivations, expectations, and the subtle differences in how they search for answers. The human dimension is something AI cannot replicate.&lt;/p&gt;&lt;p&gt;Specialists bring an understanding of why search behaviour shifts, how tone influences trust, and which narratives resonate in different industries. They also grasp how economic cycles, news events, and regulations affect user queries and engagement patterns. AI can identify patterns, but it cannot interpret them fully or determine which insights align with brand values or long-term goals.&lt;/p&gt;&lt;p&gt;The increasing emphasis on E-E-A-T signals, Experience, Expertise, Authoritativeness and Trustworthiness, further reinforces this need for human guidance. An algorithm cannot fabricate authentic authority. It must be demonstrated through lived experience, credibility, and careful communication. SEO specialists ensure that these qualities are baked into every page and every message, guiding brands through an increasingly complex search environment where trust matters more than ever.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-seo-specialists-use-ai-to-deliver-faster-smarter-optimisation"&gt;How SEO specialists use AI to deliver faster, smarter optimisation&lt;/h3&gt;&lt;p&gt;Where AI shines is in support, not replacement. Modern SEO specialists use AI tools to automate repetitive tasks, accelerate data analysis, and uncover patterns at scale. AI can rapidly produce initial keyword lists, identify technical issues, or generate draft structures for content. These capabilities shorten production timelines and free specialists to focus on the strategic, creative, and high-value decisions that define effective optimisation.&lt;/p&gt;&lt;p&gt;The balanced approach enables better outcomes. AI handles the heavy lifting, while human specialists interpret the results, refine the strategy, and ensure everything aligns with the brand’s goals, tone, and audience requirements. It is this combination of speed and discernment that shapes the future of SEO.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-creative-and-analytical-skills-ai-cannot-replicate"&gt;The creative and analytical skills AI cannot replicate&lt;/h3&gt;&lt;p&gt;Even the most advanced AI tools cannot fully replicate creativity, intuition, or emotional intelligence. SEO specialists draw on analytical skills and creative insight to produce content that stands out in competitive digital markets. AI can propose phrasing, but it cannot determine when a message needs personality, authority, or nuance to feel trustworthy.&lt;/p&gt;&lt;p&gt;In industries where reputation matters, like fintech, finance, healthcare, law, and education, human-shaped content is essential. Users want reassurance that the guidance they read comes from people with real expertise. AI-generated content often lacks the depth or subtlety needed to build that trust.&lt;/p&gt;&lt;p&gt;Human specialists also excel at interpreting data in context. They understand how search intent connects to behaviour, how content influences perception, and how messaging supports or undermines brand identity. Their ability to connect analytical insights with emotional resonance is something AI simply cannot achieve.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-building-the-next-generation-of-seo-careers-in-an-ai-enhanced-industry"&gt;Building the next generation of SEO careers in an AI-enhanced industry&lt;/h3&gt;&lt;p&gt;AI is not shrinking the field of SEO; it is expanding it. The next generation of SEO professionals will blend human-centred strategy with AI-assisted efficiency. Modern SEO requires fluency in multiple areas: data interpretation, UX thinking, structured content, behavioural insights, content design, and now, AI tool management.&lt;/p&gt;&lt;p&gt;Specialists who embrace both disciplines will lead the industry forward. Their work will become more strategic, more aligned with long-term business value, and more influential as search becomes increasingly complex and multi-modal.&lt;/p&gt;&lt;p&gt;AI may automate tasks, but strategy, creativity, judgement, and trust-building remain human strengths. And as AI transforms how search tools interpret information, those strengths will only become more essential. SEO is not disappearing. It is evolving into a richer, more strategic, and more human discipline.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Pexels&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2025/12/Picture1-2.jpg" /&gt;&lt;/div&gt;&lt;p&gt;AI search engines and generative AI tools are certainly transforming how people discover information online. Far from making SEO specialists obsolete, the shift highlights clearly why skilled human optimisers remain more important than ever.&lt;/p&gt;&lt;p&gt;As generative AI search tools reshape the digital landscape, many wonder whether traditional SEO has reached the end. Despite AI’s growing influence, the fundamentals of discoverability, authority, clarity, and trust remain vital. The rise of AI-powered search makes the role of SEO specialists more important than before, ensuring content not only reaches audiences but resonates authentically. A digital environment shaped by automation still depends heavily on human expertise, especially when credibility is at stake.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-why-ai-expands-rather-than-replaces-the-work-of-seo-specialists"&gt;Why AI expands rather than replaces the work of SEO specialists&lt;/h3&gt;&lt;p&gt;The assumption that AI will replace SEO specialists ignores how modern search works. AI expands what optimisation can achieve, but it does not eliminate the need for skilled human oversight. Traditional ranking signals like site structure, depth of information, internal linking and authority continue to influence visibility, even in AI-driven answer engines. This means content must still be crafted with intent, clarity, and expertise.&lt;/p&gt;&lt;p&gt;AI-powered search engines prioritise well-structured, trustworthy information, reinforcing the importance of thoughtful optimisation. In this brand new landscape, SEO now spans two parallel environments: classic search engines and AI-generated answer systems. Competing effectively in both requires strategic thinking, careful content planning, and a nuanced understanding of user intent: areas where human specialists excel, beyond what AI can replicate.&lt;/p&gt;&lt;p&gt;Agencies like Brath, which presents SEO as one of the most profitable long-term marketing channels when executed with technical precision and strategic insight, clearly understand this reality. Its service model remains grounded in proven disciplines: technical improvements, keyword strategy, content refinement, and authority building. Rather than leaning on automation, it demonstrates that sustainable SEO relies on human expertise, methodical analysis, and consistent optimisation.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-human-insight-still-drives-strategy-in-an-ai-powered-search-world"&gt;Human insight still drives strategy in an AI-powered search world&lt;/h3&gt;&lt;p&gt;AI excels at processing data, but it still falls short when deeper context, cultural awareness, and nuanced decision-making are required. SEO is more than a technical exercise; it is a strategic craft rooted in understanding people, their motivations, expectations, and the subtle differences in how they search for answers. The human dimension is something AI cannot replicate.&lt;/p&gt;&lt;p&gt;Specialists bring an understanding of why search behaviour shifts, how tone influences trust, and which narratives resonate in different industries. They also grasp how economic cycles, news events, and regulations affect user queries and engagement patterns. AI can identify patterns, but it cannot interpret them fully or determine which insights align with brand values or long-term goals.&lt;/p&gt;&lt;p&gt;The increasing emphasis on E-E-A-T signals, Experience, Expertise, Authoritativeness and Trustworthiness, further reinforces this need for human guidance. An algorithm cannot fabricate authentic authority. It must be demonstrated through lived experience, credibility, and careful communication. SEO specialists ensure that these qualities are baked into every page and every message, guiding brands through an increasingly complex search environment where trust matters more than ever.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-how-seo-specialists-use-ai-to-deliver-faster-smarter-optimisation"&gt;How SEO specialists use AI to deliver faster, smarter optimisation&lt;/h3&gt;&lt;p&gt;Where AI shines is in support, not replacement. Modern SEO specialists use AI tools to automate repetitive tasks, accelerate data analysis, and uncover patterns at scale. AI can rapidly produce initial keyword lists, identify technical issues, or generate draft structures for content. These capabilities shorten production timelines and free specialists to focus on the strategic, creative, and high-value decisions that define effective optimisation.&lt;/p&gt;&lt;p&gt;The balanced approach enables better outcomes. AI handles the heavy lifting, while human specialists interpret the results, refine the strategy, and ensure everything aligns with the brand’s goals, tone, and audience requirements. It is this combination of speed and discernment that shapes the future of SEO.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-creative-and-analytical-skills-ai-cannot-replicate"&gt;The creative and analytical skills AI cannot replicate&lt;/h3&gt;&lt;p&gt;Even the most advanced AI tools cannot fully replicate creativity, intuition, or emotional intelligence. SEO specialists draw on analytical skills and creative insight to produce content that stands out in competitive digital markets. AI can propose phrasing, but it cannot determine when a message needs personality, authority, or nuance to feel trustworthy.&lt;/p&gt;&lt;p&gt;In industries where reputation matters, like fintech, finance, healthcare, law, and education, human-shaped content is essential. Users want reassurance that the guidance they read comes from people with real expertise. AI-generated content often lacks the depth or subtlety needed to build that trust.&lt;/p&gt;&lt;p&gt;Human specialists also excel at interpreting data in context. They understand how search intent connects to behaviour, how content influences perception, and how messaging supports or undermines brand identity. Their ability to connect analytical insights with emotional resonance is something AI simply cannot achieve.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-building-the-next-generation-of-seo-careers-in-an-ai-enhanced-industry"&gt;Building the next generation of SEO careers in an AI-enhanced industry&lt;/h3&gt;&lt;p&gt;AI is not shrinking the field of SEO; it is expanding it. The next generation of SEO professionals will blend human-centred strategy with AI-assisted efficiency. Modern SEO requires fluency in multiple areas: data interpretation, UX thinking, structured content, behavioural insights, content design, and now, AI tool management.&lt;/p&gt;&lt;p&gt;Specialists who embrace both disciplines will lead the industry forward. Their work will become more strategic, more aligned with long-term business value, and more influential as search becomes increasingly complex and multi-modal.&lt;/p&gt;&lt;p&gt;AI may automate tasks, but strategy, creativity, judgement, and trust-building remain human strengths. And as AI transforms how search tools interpret information, those strengths will only become more essential. SEO is not disappearing. It is evolving into a richer, more strategic, and more human discipline.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Pexels&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/what-ai-search-tools-mean-for-the-future-of-seo-specialists/</guid><pubDate>Tue, 16 Dec 2025 15:49:59 +0000</pubDate></item><item><title>Google tests an email-based productivity assistant (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/16/google-tests-an-email-based-productivity-assistant/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/CC_Keyword_01-1.jpeg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Productivity is one space where companies keep wanting to experiment with AI assistants in the hope that they will save time for users, and as a result, they will want to use those assistants more. Google today launched one such experimental email-based assistant called CC through a Google Labs experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CC, which is powered by Gemini, can connect with your account, such as Gmail, Google Drive, and Google Calendar, and provide you with a daily brief via email. This “Your Day Ahead” email makes users aware of their tasks, summarizes their calendar, and provides key updates for the day from these accounts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;You can also reply to or email CC at any time with requests such as adding to-dos, teaching it to your preferences, remembering notes, or searching for information. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the moment, CC is available to AI Pro and Ultra users in the U.S. and Canada who are 18 or above. The company said that the assistant is only available to consumer Google accounts at the moment and not Workspace accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are several examples of AI-powered email-based briefs and assistants. Sequoia-backed Mindy, which now works in the creator and marketing space, started as an email assistant. Other meeting notetakers like Read AI and Fireflies also send users a daily brief, but they might not have context from email and Drive. Huxe, an audio app created by former Google NotebookLM makers, creates a daily brief in the form of a podcast with data from your email, calendar, and news preferences.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/CC_Keyword_01-1.jpeg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Productivity is one space where companies keep wanting to experiment with AI assistants in the hope that they will save time for users, and as a result, they will want to use those assistants more. Google today launched one such experimental email-based assistant called CC through a Google Labs experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CC, which is powered by Gemini, can connect with your account, such as Gmail, Google Drive, and Google Calendar, and provide you with a daily brief via email. This “Your Day Ahead” email makes users aware of their tasks, summarizes their calendar, and provides key updates for the day from these accounts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;You can also reply to or email CC at any time with requests such as adding to-dos, teaching it to your preferences, remembering notes, or searching for information. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the moment, CC is available to AI Pro and Ultra users in the U.S. and Canada who are 18 or above. The company said that the assistant is only available to consumer Google accounts at the moment and not Workspace accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There are several examples of AI-powered email-based briefs and assistants. Sequoia-backed Mindy, which now works in the creator and marketing space, started as an email assistant. Other meeting notetakers like Read AI and Fireflies also send users a daily brief, but they might not have context from email and Drive. Huxe, an audio app created by former Google NotebookLM makers, creates a daily brief in the form of a podcast with data from your email, calendar, and news preferences.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/16/google-tests-an-email-based-productivity-assistant/</guid><pubDate>Tue, 16 Dec 2025 18:00:00 +0000</pubDate></item><item><title>Uber Eats alum lands $14M seed from a16z to fix WhatsApp chaos for LatAm’s doctors (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/16/uber-eats-alum-lands-14m-seed-from-a16z-to-fix-whatsapp-chaos-for-latams-doctors/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Caroline-Merin-horizontal-headshot.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Caroline Merin, who spent nearly a decade developing on-demand services as the first Latin American general manager for Uber Eats and later the COO of Rappi, recognized how badly healthcare tech lagged behind. While patients expected doctors to respond as quickly as their delivery apps, most medical professionals on the continent are forced to rely on WhatsApp for all patient communication.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I thought, as a patient, especially as an American, how incredible that I can text my doctor on WhatsApp, and they’ll respond,” she told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Merin also realized just how overwhelming this communication method had become for physicians. “A doctor who sees 20 patients during the day, gets home, has 100 messages and is expected to answer immediately and remember who the patient is without the health record in front of them,” she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merin, who had long been interested in building her own startup, saw an opportunity to improve doctors’ communication challenges. So, two years ago, she launched Leona Health, an AI-copilot integrated with doctors’ WhatsApp accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, Leona revealed that it raised $14 million in seed funding led by Andreessen Horowitz, with participation from General Catalyst; Accel; Maven Clinic CEO Kate Ryder; Nubank CEO David Vélez; and Rappi CEO Simón Borrero. The startup also announced that its service is now available to doctors in 14 Latin American countries across 22 medical specialties.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Leona, patients continue to send messages on WhatsApp, but doctors receive and manage that communication through the startup’s mobile app. The app sorts all messages in order of priority, suggests responses, and allows other team members (like doctors or nurses) to reply to patients on the doctor’s behalf.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup will also soon launch a fully autonomous agent that will handle conversational scheduling and simple intake.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Solving the WhatsApp communication challenge in Latin America is critical because, according to Merin, patients in Latin America often choose their doctors based on their willingness to communicate using this channel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These poor doctors, they’re receiving requests for very serious medical consults to, ‘I need a letter for my kids’ school,’ or, ‘I want a receipt for my appointment last week,’” Merin said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since these messages can arrive in the evenings and on weekends, physicians are often forced to monitor their WhatsApp around the clock. Leona solves this by immediately alerting doctors only to the most serious health requests and allowing them to deprioritize more routine or administrative questions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The idea is to help the doctor regain time,” Merin said. “We’re hearing from our users that they’re saving two to three hours a day by using Leona.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Leona is starting by serving Latin America, the company’s long-term mission is to expand its services to other geographies, where, unlike in the U.S., patients also demand and are permitted to communicate with their doctors via WhatsApp, rather than through electronic medical records systems like Epic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leona’s team of 13 is currently split between Mexico City and Silicon Valley, where, according to Merin, the best AI engineers are located.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Caroline-Merin-horizontal-headshot.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Caroline Merin, who spent nearly a decade developing on-demand services as the first Latin American general manager for Uber Eats and later the COO of Rappi, recognized how badly healthcare tech lagged behind. While patients expected doctors to respond as quickly as their delivery apps, most medical professionals on the continent are forced to rely on WhatsApp for all patient communication.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I thought, as a patient, especially as an American, how incredible that I can text my doctor on WhatsApp, and they’ll respond,” she told TechCrunch.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But Merin also realized just how overwhelming this communication method had become for physicians. “A doctor who sees 20 patients during the day, gets home, has 100 messages and is expected to answer immediately and remember who the patient is without the health record in front of them,” she said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Merin, who had long been interested in building her own startup, saw an opportunity to improve doctors’ communication challenges. So, two years ago, she launched Leona Health, an AI-copilot integrated with doctors’ WhatsApp accounts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On Tuesday, Leona revealed that it raised $14 million in seed funding led by Andreessen Horowitz, with participation from General Catalyst; Accel; Maven Clinic CEO Kate Ryder; Nubank CEO David Vélez; and Rappi CEO Simón Borrero. The startup also announced that its service is now available to doctors in 14 Latin American countries across 22 medical specialties.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With Leona, patients continue to send messages on WhatsApp, but doctors receive and manage that communication through the startup’s mobile app. The app sorts all messages in order of priority, suggests responses, and allows other team members (like doctors or nurses) to reply to patients on the doctor’s behalf.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup will also soon launch a fully autonomous agent that will handle conversational scheduling and simple intake.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Solving the WhatsApp communication challenge in Latin America is critical because, according to Merin, patients in Latin America often choose their doctors based on their willingness to communicate using this channel.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These poor doctors, they’re receiving requests for very serious medical consults to, ‘I need a letter for my kids’ school,’ or, ‘I want a receipt for my appointment last week,’” Merin said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Since these messages can arrive in the evenings and on weekends, physicians are often forced to monitor their WhatsApp around the clock. Leona solves this by immediately alerting doctors only to the most serious health requests and allowing them to deprioritize more routine or administrative questions.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The idea is to help the doctor regain time,” Merin said. “We’re hearing from our users that they’re saving two to three hours a day by using Leona.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Leona is starting by serving Latin America, the company’s long-term mission is to expand its services to other geographies, where, unlike in the U.S., patients also demand and are permitted to communicate with their doctors via WhatsApp, rather than through electronic medical records systems like Epic.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Leona’s team of 13 is currently split between Mexico City and Silicon Valley, where, according to Merin, the best AI engineers are located.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/16/uber-eats-alum-lands-14m-seed-from-a16z-to-fix-whatsapp-chaos-for-latams-doctors/</guid><pubDate>Tue, 16 Dec 2025 18:11:58 +0000</pubDate></item><item><title>OpenAI continues on its ‘code red’ warpath with new image generation model (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/16/openai-continues-on-its-code-red-warpath-with-new-image-generation-model/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is rolling out a new version of ChatGPT Images that promises better instruction-following, more precise editing, and up to 4x faster image generation speeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new model, dubbed GPT Image 1.5, is available starting Tuesday to all ChatGPT users and via the API. It’s the latest escalation in the competition with Google’s Gemini after OpenAI CEO Sam Altman last month declared a “code red” in a leaked internal memo. The memo detailed OpenAI’s plans to regain its position as the AI leader after Google had begun to take market share following the release of Gemini 3, its latest flagship model, and Nano Banana Pro, the newest version of Google’s viral image generator — both of which have topped the LMArena leaderboard across multiple benchmarks.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google maintains its lead even after OpenAI responded to its success last week with the launch of GPT-5.2, pitching it as its most advanced model yet for developers and everyday professional use. OpenAI had reportedly been planning to release a new image generator in early January, accelerating those plans with this week’s announcement. Its last image model release was GPT Image 1 in April.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT Image 1.5 arrives as image and video generators advance beyond prototypes and gain more production-ready capabilities. Like Nano Banana Pro, ChatGPT Image offers post-production features, providing more granular edit controls to maintain visual consistency, like facial likeness, lighting, composition, and color tone across edits.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3076523" height="453" src="https://techcrunch.com/wp-content/uploads/2025/12/skating-2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The same image depicted above with different edits to showcase GPT Image 1.5’s improved instruction-following&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Most GenAI image tools are bad at iteration, so this would be a huge step up. Asked for a specific change, like “adjust the facial expression” or “make lighting colder,” models will often reinterpret the entire image, leading to a lack of consistency.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update isn’t just about new features. ChatGPT images will also now be accessible via a dedicated entry point in the ChatGPT sidebar that works “more like a creative studio,” Fidji Simo, OpenAI’s CEO of applications, wrote in a blog post Tuesday.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The new image viewing and editing screens make it easier to create images that match your vision or get inspiration from trending prompts and preset filters,” Simo wrote.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;On top of the new image generator, OpenAI is introducing new ways to improve the ChatGPT experience with more visual elements. The plan is to make search queries display more visuals with clear sources, which could be helpful for tasks like converting measurements or checking sports scores, per Simo.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you’re creating, you should be able to see and shape the thing you’re making. When visuals tell a story better than words alone, ChatGPT should include them,” Simo wrote. “When you need a quick answer or the next step lives in another tool, it should be right there. As we do this, we can keep closing the distance between what’s in your mind and your ability to bring it to life.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;OpenAI is rolling out a new version of ChatGPT Images that promises better instruction-following, more precise editing, and up to 4x faster image generation speeds.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The new model, dubbed GPT Image 1.5, is available starting Tuesday to all ChatGPT users and via the API. It’s the latest escalation in the competition with Google’s Gemini after OpenAI CEO Sam Altman last month declared a “code red” in a leaked internal memo. The memo detailed OpenAI’s plans to regain its position as the AI leader after Google had begun to take market share following the release of Gemini 3, its latest flagship model, and Nano Banana Pro, the newest version of Google’s viral image generator — both of which have topped the LMArena leaderboard across multiple benchmarks.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Google maintains its lead even after OpenAI responded to its success last week with the launch of GPT-5.2, pitching it as its most advanced model yet for developers and everyday professional use. OpenAI had reportedly been planning to release a new image generator in early January, accelerating those plans with this week’s announcement. Its last image model release was GPT Image 1 in April.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;GPT Image 1.5 arrives as image and video generators advance beyond prototypes and gain more production-ready capabilities. Like Nano Banana Pro, ChatGPT Image offers post-production features, providing more granular edit controls to maintain visual consistency, like facial likeness, lighting, composition, and color tone across edits.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" class="wp-image-3076523" height="453" src="https://techcrunch.com/wp-content/uploads/2025/12/skating-2.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;The same image depicted above with different edits to showcase GPT Image 1.5’s improved instruction-following&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;OpenAI&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Most GenAI image tools are bad at iteration, so this would be a huge step up. Asked for a specific change, like “adjust the facial expression” or “make lighting colder,” models will often reinterpret the entire image, leading to a lack of consistency.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The update isn’t just about new features. ChatGPT images will also now be accessible via a dedicated entry point in the ChatGPT sidebar that works “more like a creative studio,” Fidji Simo, OpenAI’s CEO of applications, wrote in a blog post Tuesday.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The new image viewing and editing screens make it easier to create images that match your vision or get inspiration from trending prompts and preset filters,” Simo wrote.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;On top of the new image generator, OpenAI is introducing new ways to improve the ChatGPT experience with more visual elements. The plan is to make search queries display more visuals with clear sources, which could be helpful for tasks like converting measurements or checking sports scores, per Simo.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When you’re creating, you should be able to see and shape the thing you’re making. When visuals tell a story better than words alone, ChatGPT should include them,” Simo wrote. “When you need a quick answer or the next step lives in another tool, it should be right there. As we do this, we can keep closing the distance between what’s in your mind and your ability to bring it to life.”&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;/figure&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/16/openai-continues-on-its-code-red-warpath-with-new-image-generation-model/</guid><pubDate>Tue, 16 Dec 2025 18:22:50 +0000</pubDate></item><item><title>Meta’s AI glasses can now help you hear conversations better (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/16/metas-ai-glasses-can-now-help-you-hear-conversations-better/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Conversation-Focus_Social-Share.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Tuesday an update to its AI glasses that will allow you to better hear people talking when you’re in a noisy environment. The feature will initially become available on Ray-Ban Meta and Oakley Meta HSTN smart glasses in the U.S. and Canada, the company says. In addition, the glasses are getting another update that lets you use Spotify to play a song that matches what’s in your current view.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if you’re looking at an album cover, the glasses could play a song by that artist. Or if you’re looking at your Christmas tree with a pile of gifts, you could play holiday music. This addition is more of a gimmick, of course, but it demonstrates how Meta is thinking about connecting what people see with actions they can take in their apps.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The conversation-focus feature, meanwhile, seems more practical. First announced at Meta’s Connect conference earlier this year, the feature uses the AI glasses’ open-ear speakers to amplify the voice of the person you’re talking to. Meta says smart glasses wearers will also be able to adjust the amplification level by swiping the right temple of their glasses, or via the device settings. This will allow them to set the level more precisely to match their current environment, whether that’s a busy restaurant or bar, club, commuter train, or anything else.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How well the feature works, of course, will still need to be tested. However, the idea of using smart accessories as tools to help with hearing isn’t limited to Meta. Apple’s AirPods already offer a Conversation Boost feature designed to help you focus on the person you’re talking to, and the Pro models more recently added support for a clinical-grade Hearing Aid feature as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the conversation-focus feature is limited to the U.S. and Canada, the Spotify feature is offered in English in a larger number of markets, including Australia, Austria, Belgium, Brazil, Canada, Denmark, Finland, France, Germany, India, Ireland, Italy, Mexico, Norway, Spain, Sweden, the United Arab Emirates, the U.K., and the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The software update (v21) will first become available to those who are enrolled in Meta’s Early Access Program, which requires first joining a waitlist and being approved. It will later roll out more broadly.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/12/Conversation-Focus_Social-Share.webp?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta announced on Tuesday an update to its AI glasses that will allow you to better hear people talking when you’re in a noisy environment. The feature will initially become available on Ray-Ban Meta and Oakley Meta HSTN smart glasses in the U.S. and Canada, the company says. In addition, the glasses are getting another update that lets you use Spotify to play a song that matches what’s in your current view.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For instance, if you’re looking at an album cover, the glasses could play a song by that artist. Or if you’re looking at your Christmas tree with a pile of gifts, you could play holiday music. This addition is more of a gimmick, of course, but it demonstrates how Meta is thinking about connecting what people see with actions they can take in their apps.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The conversation-focus feature, meanwhile, seems more practical. First announced at Meta’s Connect conference earlier this year, the feature uses the AI glasses’ open-ear speakers to amplify the voice of the person you’re talking to. Meta says smart glasses wearers will also be able to adjust the amplification level by swiping the right temple of their glasses, or via the device settings. This will allow them to set the level more precisely to match their current environment, whether that’s a busy restaurant or bar, club, commuter train, or anything else.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;How well the feature works, of course, will still need to be tested. However, the idea of using smart accessories as tools to help with hearing isn’t limited to Meta. Apple’s AirPods already offer a Conversation Boost feature designed to help you focus on the person you’re talking to, and the Pro models more recently added support for a clinical-grade Hearing Aid feature as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the conversation-focus feature is limited to the U.S. and Canada, the Spotify feature is offered in English in a larger number of markets, including Australia, Austria, Belgium, Brazil, Canada, Denmark, Finland, France, Germany, India, Ireland, Italy, Mexico, Norway, Spain, Sweden, the United Arab Emirates, the U.K., and the U.S.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The software update (v21) will first become available to those who are enrolled in Meta’s Early Access Program, which requires first joining a waitlist and being approved. It will later roll out more broadly.&lt;/p&gt;


&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/16/metas-ai-glasses-can-now-help-you-hear-conversations-better/</guid><pubDate>Tue, 16 Dec 2025 18:30:55 +0000</pubDate></item><item><title>[NEW] DoorDash rolls out Zesty, an AI social app for discovering new restaurants (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/12/16/doordash-rolls-out-zesty-an-ai-social-app-for-discovering-new-restaurants/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;DoorDash is launching a new AI-powered social app that’s designed to help users quickly find local restaurants. The app, called Zesty, is initially available in the San Francisco Bay Area and New York.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the app, DoorDash is branching out beyond food delivery and stepping into the social and discovery space. The idea behind the app is to get rid of the need to read a bunch of different reviews, look up different menus, or browse TikTok when looking for a new place to eat.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Once people open the app and sign in with their DoorDash accounts, they can ask an AI chatbot for personalized recommendations based on what they’re looking for. In an Instagram promo post, the company shared that users can type prompts like, “A low-key dinner in Williamsburg that’s actually good for introverts” to find specific recommendations. Users will also see suggested prompts, such as “Brunch spots good for groups,” and “Romantic dinner with a vintage feel.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DoorDash co-founder Andy Fang wrote in an X post that the app aggregates info across DoorDash, Google Maps, TikTok, and more to “curate the best suggestions from the web.” &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3076579" height="492" src="https://techcrunch.com/wp-content/uploads/2025/12/zesty-app_1cdb40.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zesty&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app also learns your tastes to figure out what you do and don’t like. Once you come across a recommendation you’re interested in, you can save it and share it with others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can view and share photos and comments about restaurants they’ve visited, discover content from others, and follow people just like on any social network. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At DoorDash, we’re always looking for new ways to help people connect with the best of their communities,” a DoorDash spokesperson confirmed to TechCrunch. “We’re piloting an app called Zesty to make it easier to discover great nearby restaurants, coffee shops, bars, and more through personalized search and social sharing. We’re excited to learn from early testers as we keep shaping what local discovery can look like.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;News of the app’s launch was first reported by Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, some people may not want to download a whole new app to find new restaurants when they could simply use Google. For people who have already embedded AI into their daily lives, they may already be using services like ChatGPT and Gemini to discover new restaurants. However, the app could be a welcome launch for people who want to be part of a social network that’s all about discovering new restaurants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of the new app marks DoorDash’s latest effort to branch beyond delivery services, as the company earlier this year launched features that allow customers to make reservations for in-person dining and earn in-store rewards. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;DoorDash is launching a new AI-powered social app that’s designed to help users quickly find local restaurants. The app, called Zesty, is initially available in the San Francisco Bay Area and New York.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With the app, DoorDash is branching out beyond food delivery and stepping into the social and discovery space. The idea behind the app is to get rid of the need to read a bunch of different reviews, look up different menus, or browse TikTok when looking for a new place to eat.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Once people open the app and sign in with their DoorDash accounts, they can ask an AI chatbot for personalized recommendations based on what they’re looking for. In an Instagram promo post, the company shared that users can type prompts like, “A low-key dinner in Williamsburg that’s actually good for introverts” to find specific recommendations. Users will also see suggested prompts, such as “Brunch spots good for groups,” and “Romantic dinner with a vintage feel.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;DoorDash co-founder Andy Fang wrote in an X post that the app aggregates info across DoorDash, Google Maps, TikTok, and more to “curate the best suggestions from the web.” &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3076579" height="492" src="https://techcrunch.com/wp-content/uploads/2025/12/zesty-app_1cdb40.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Zesty&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The app also learns your tastes to figure out what you do and don’t like. Once you come across a recommendation you’re interested in, you can save it and share it with others.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Users can view and share photos and comments about restaurants they’ve visited, discover content from others, and follow people just like on any social network. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“At DoorDash, we’re always looking for new ways to help people connect with the best of their communities,” a DoorDash spokesperson confirmed to TechCrunch. “We’re piloting an app called Zesty to make it easier to discover great nearby restaurants, coffee shops, bars, and more through personalized search and social sharing. We’re excited to learn from early testers as we keep shaping what local discovery can look like.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;News of the app’s launch was first reported by Bloomberg.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, some people may not want to download a whole new app to find new restaurants when they could simply use Google. For people who have already embedded AI into their daily lives, they may already be using services like ChatGPT and Gemini to discover new restaurants. However, the app could be a welcome launch for people who want to be part of a social network that’s all about discovering new restaurants.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The launch of the new app marks DoorDash’s latest effort to branch beyond delivery services, as the company earlier this year launched features that allow customers to make reservations for in-person dining and earn in-store rewards. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/12/16/doordash-rolls-out-zesty-an-ai-social-app-for-discovering-new-restaurants/</guid><pubDate>Tue, 16 Dec 2025 18:48:43 +0000</pubDate></item><item><title>[NEW] Senators count the shady ways data centers pass energy costs on to Americans (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/12/shady-data-center-deals-doom-americans-to-higher-energy-bills-senators-say/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Senators demand Big Tech pay upfront for data center spikes in electricity bills.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249021916-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249021916-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A technician works at an Amazon Web Services AI data center that senators seek to probe in New Carlisle, Indiana.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Handout / Handout | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Senators launched a probe Tuesday demanding that tech companies explain exactly how they plan to prevent data center projects from increasing electricity bills in communities where prices are already skyrocketing.&lt;/p&gt;
&lt;p&gt;In letters to seven AI firms, Senators Elizabeth Warren (D-Mass.), Chris Van Hollen (D-Md.), and Richard Blumenthal (D-Conn.) cited a study estimating that “electricity prices have increased by as much as 267 percent in the past five years” in “areas located near significant data center activity.”&lt;/p&gt;
&lt;p&gt;Prices increase, senators noted, when utility companies build out extra infrastructure to meet data centers’ energy demands—which can amount to one customer suddenly consuming as much power as an entire city. They also increase when demand for local power outweighs supply. In some cases, residents are blindsided by higher bills, not even realizing a data center project was approved, because tech companies seem intent on dodging backlash and frequently do not allow terms of deals to be publicly disclosed.&lt;/p&gt;
&lt;p&gt;AI firms “ask public officials to sign non-disclosure agreements (NDAs) preventing them from sharing information with their constituents, operate through what appear to be shell companies to mask the real owner of the data center, and require that landowners sign NDAs as part of the land sale while telling them only that a ‘Fortune 100 company’ is planning an ‘industrial development’ seemingly in an attempt to hide the very existence of the data center,” senators wrote.&lt;/p&gt;
&lt;p&gt;States like Virginia with the highest concentration of data centers could see average electricity prices increase by another 25 percent by 2030, senators noted. But price increases aren’t limited to the states allegedly striking shady deals with tech companies and greenlighting data center projects, they said. “Interconnected and interstate power grids can lead to a data center built in one state raising costs for residents of a neighboring state,” senators reported.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Under fire for supposedly only pretending to care about keeping neighbors’ costs low were Amazon, Google, Meta, Microsoft, Equinix, Digital Realty, and CoreWeave. Senators accused firms of paying “lip service,” claiming that they would do everything in their power to avoid increasing residential electricity costs, while actively lobbying to pass billions in costs on to their neighbors.&lt;/p&gt;
&lt;p&gt;For example, Amazon publicly claimed it would “make sure” it would cover costs so they wouldn’t be passed on. But it’s also a member of an industry lobbying group, the Data Center Coalition, that “has opposed state regulatory decisions requiring data center companies to pay a higher percentage of costs upfront,” senators wrote. And Google made similar statements, despite having an executive who opposed a regulatory solution that would set data centers into their own “rate class”—and therefore responsible for grid improvement costs that could not be passed on to other customers—on the grounds that it was supposedly “discriminatory.”&lt;/p&gt;
&lt;p&gt;“The current, socialized model of electricity ratepaying,” senators explained—where costs are shared across all users—”was not designed for an era where just one customer requires the same amount of electricity as some of the largest cities in America.”&lt;/p&gt;
&lt;p&gt;Particularly problematic, senators emphasized, were reports that tech firms were getting discounts on energy costs as utility companies competed for their business, while prices went up for their neighbors.&lt;/p&gt;
&lt;p&gt;Ars contacted all firms targeted by lawmakers. Four did not respond. Microsoft and Meta declined to comment. Digital Realty told Ars that it “looks forward to working with all elected officials to continue to invest in the digital infrastructure required to support America’s leadership in technology, which underpins modern life and creates high-paying jobs.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Regulatory pressure likely to increase as bills go up&lt;/h2&gt;
&lt;p&gt;Senators are likely exploring whether to pass legislation that would help combat price increases that they say cause average Americans to struggle to keep the lights on. They’ve asked tech companies to respond to their biggest questions about data center projects by January 12, 2026.&lt;/p&gt;
&lt;p&gt;Among their top questions, senators wanted to know about firms’ internal projections looking forward with data center projects. That includes sharing their projected energy use through 2030, as well as the “impact of your AI data centers on regional utility costs.” Companies are also expected to explain how “internal projections of data center energy consumption” justify any “opposition to the creation of a distinct data center rate class.”&lt;/p&gt;
&lt;p&gt;Additionally, senators asked firms to outline steps they’ve taken to prevent passing on costs to neighbors and details of any impact studies companies have conducted.&lt;/p&gt;
&lt;p&gt;Likely to raise the most eyebrows, however, would be answers to questions about “tax deductions or other financial incentives” tech firms have received from city and state governments. Those numbers would be interesting to compare with other information senators demanded that companies share, detailing how much they’ve spent on lobbying and advocacy for data centers. Senators appear keen to know how much tech companies are paying to avoid covering a proportionate amount of infrastructure costs.&lt;/p&gt;
&lt;p&gt;“To protect consumers, data centers must pay a greater share of the costs upfront for future energy usage and updates to the electrical grid provided specifically to accommodate data centers’ energy needs,” senators wrote.&lt;/p&gt;
&lt;p&gt;Requiring upfront payment is especially critical, senators noted, since some tech firms have abandoned data center projects, leaving local customers to bear the costs of infrastructure changes without utility companies ever generating any revenue. Communities must also consider that AI firms’ projected energy demand could severely dip if enterprise demand for AI falls short of expectations, AI capabilities “plateau” and trigger widespread indifference, AI companies shift strategies “away from scaling computer power,” or chip companies “find innovative ways to make AI more energy-efficient.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“If data centers end up providing less business to the utility companies than anticipated, consumers could be left with massive electricity bills as utility companies recoup billions in new infrastructure costs, with nothing to show for it,” senators wrote.&lt;/p&gt;
&lt;p&gt;Already, Utah, Oregon, and Ohio have passed laws “creating a separate class of utility customer for data centers which includes basic financial safeguards such as upfront payments and longer contract length,” senators noted, and Virginia is notably weighing a similar law.&lt;/p&gt;
&lt;p&gt;At least one study, The New York Times noted, suggested that data centers may have recently helped reduce electricity costs by spreading the costs of upgrades over more customers, but those outcomes varied by state and could not account for future AI demand.&lt;/p&gt;
&lt;p&gt;“It remains unclear whether broader, sustained load growth will increase long-run average costs and prices,” Lawrence Berkeley National Laboratory researchers concluded. “In some cases, spikes in load growth can result in significant, near-term retail price increase.”&lt;/p&gt;
&lt;p&gt;Until companies prove they’re paying their fair share, senators expect electricity bills to keep climbing, particularly in vulnerable areas. That will likely only increase pressure for regulators to intervene, the director of the Electricity Law Initiative at the Harvard Law School Environmental and Energy Law Program, Ari Peskoe, suggested in September.&lt;/p&gt;
&lt;p&gt;“The utility business model is all about spreading costs of system expansion to everyone, because we all benefit from a reliable, robust electricity system,” Peskoe said. “But when it’s a single consumer that is using so much energy—basically that of an entire city—and when that new city happens to be owned by the wealthiest corporations in the world, I think it’s time to look at the fundamental assumptions of utility regulation and make sure that these facilities are really paying for all of the infrastructure costs to connect them to the system and to power them.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Senators demand Big Tech pay upfront for data center spikes in electricity bills.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249021916-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/12/GettyImages-2249021916-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A technician works at an Amazon Web Services AI data center that senators seek to probe in New Carlisle, Indiana.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Handout / Handout | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Senators launched a probe Tuesday demanding that tech companies explain exactly how they plan to prevent data center projects from increasing electricity bills in communities where prices are already skyrocketing.&lt;/p&gt;
&lt;p&gt;In letters to seven AI firms, Senators Elizabeth Warren (D-Mass.), Chris Van Hollen (D-Md.), and Richard Blumenthal (D-Conn.) cited a study estimating that “electricity prices have increased by as much as 267 percent in the past five years” in “areas located near significant data center activity.”&lt;/p&gt;
&lt;p&gt;Prices increase, senators noted, when utility companies build out extra infrastructure to meet data centers’ energy demands—which can amount to one customer suddenly consuming as much power as an entire city. They also increase when demand for local power outweighs supply. In some cases, residents are blindsided by higher bills, not even realizing a data center project was approved, because tech companies seem intent on dodging backlash and frequently do not allow terms of deals to be publicly disclosed.&lt;/p&gt;
&lt;p&gt;AI firms “ask public officials to sign non-disclosure agreements (NDAs) preventing them from sharing information with their constituents, operate through what appear to be shell companies to mask the real owner of the data center, and require that landowners sign NDAs as part of the land sale while telling them only that a ‘Fortune 100 company’ is planning an ‘industrial development’ seemingly in an attempt to hide the very existence of the data center,” senators wrote.&lt;/p&gt;
&lt;p&gt;States like Virginia with the highest concentration of data centers could see average electricity prices increase by another 25 percent by 2030, senators noted. But price increases aren’t limited to the states allegedly striking shady deals with tech companies and greenlighting data center projects, they said. “Interconnected and interstate power grids can lead to a data center built in one state raising costs for residents of a neighboring state,” senators reported.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Under fire for supposedly only pretending to care about keeping neighbors’ costs low were Amazon, Google, Meta, Microsoft, Equinix, Digital Realty, and CoreWeave. Senators accused firms of paying “lip service,” claiming that they would do everything in their power to avoid increasing residential electricity costs, while actively lobbying to pass billions in costs on to their neighbors.&lt;/p&gt;
&lt;p&gt;For example, Amazon publicly claimed it would “make sure” it would cover costs so they wouldn’t be passed on. But it’s also a member of an industry lobbying group, the Data Center Coalition, that “has opposed state regulatory decisions requiring data center companies to pay a higher percentage of costs upfront,” senators wrote. And Google made similar statements, despite having an executive who opposed a regulatory solution that would set data centers into their own “rate class”—and therefore responsible for grid improvement costs that could not be passed on to other customers—on the grounds that it was supposedly “discriminatory.”&lt;/p&gt;
&lt;p&gt;“The current, socialized model of electricity ratepaying,” senators explained—where costs are shared across all users—”was not designed for an era where just one customer requires the same amount of electricity as some of the largest cities in America.”&lt;/p&gt;
&lt;p&gt;Particularly problematic, senators emphasized, were reports that tech firms were getting discounts on energy costs as utility companies competed for their business, while prices went up for their neighbors.&lt;/p&gt;
&lt;p&gt;Ars contacted all firms targeted by lawmakers. Four did not respond. Microsoft and Meta declined to comment. Digital Realty told Ars that it “looks forward to working with all elected officials to continue to invest in the digital infrastructure required to support America’s leadership in technology, which underpins modern life and creates high-paying jobs.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Regulatory pressure likely to increase as bills go up&lt;/h2&gt;
&lt;p&gt;Senators are likely exploring whether to pass legislation that would help combat price increases that they say cause average Americans to struggle to keep the lights on. They’ve asked tech companies to respond to their biggest questions about data center projects by January 12, 2026.&lt;/p&gt;
&lt;p&gt;Among their top questions, senators wanted to know about firms’ internal projections looking forward with data center projects. That includes sharing their projected energy use through 2030, as well as the “impact of your AI data centers on regional utility costs.” Companies are also expected to explain how “internal projections of data center energy consumption” justify any “opposition to the creation of a distinct data center rate class.”&lt;/p&gt;
&lt;p&gt;Additionally, senators asked firms to outline steps they’ve taken to prevent passing on costs to neighbors and details of any impact studies companies have conducted.&lt;/p&gt;
&lt;p&gt;Likely to raise the most eyebrows, however, would be answers to questions about “tax deductions or other financial incentives” tech firms have received from city and state governments. Those numbers would be interesting to compare with other information senators demanded that companies share, detailing how much they’ve spent on lobbying and advocacy for data centers. Senators appear keen to know how much tech companies are paying to avoid covering a proportionate amount of infrastructure costs.&lt;/p&gt;
&lt;p&gt;“To protect consumers, data centers must pay a greater share of the costs upfront for future energy usage and updates to the electrical grid provided specifically to accommodate data centers’ energy needs,” senators wrote.&lt;/p&gt;
&lt;p&gt;Requiring upfront payment is especially critical, senators noted, since some tech firms have abandoned data center projects, leaving local customers to bear the costs of infrastructure changes without utility companies ever generating any revenue. Communities must also consider that AI firms’ projected energy demand could severely dip if enterprise demand for AI falls short of expectations, AI capabilities “plateau” and trigger widespread indifference, AI companies shift strategies “away from scaling computer power,” or chip companies “find innovative ways to make AI more energy-efficient.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“If data centers end up providing less business to the utility companies than anticipated, consumers could be left with massive electricity bills as utility companies recoup billions in new infrastructure costs, with nothing to show for it,” senators wrote.&lt;/p&gt;
&lt;p&gt;Already, Utah, Oregon, and Ohio have passed laws “creating a separate class of utility customer for data centers which includes basic financial safeguards such as upfront payments and longer contract length,” senators noted, and Virginia is notably weighing a similar law.&lt;/p&gt;
&lt;p&gt;At least one study, The New York Times noted, suggested that data centers may have recently helped reduce electricity costs by spreading the costs of upgrades over more customers, but those outcomes varied by state and could not account for future AI demand.&lt;/p&gt;
&lt;p&gt;“It remains unclear whether broader, sustained load growth will increase long-run average costs and prices,” Lawrence Berkeley National Laboratory researchers concluded. “In some cases, spikes in load growth can result in significant, near-term retail price increase.”&lt;/p&gt;
&lt;p&gt;Until companies prove they’re paying their fair share, senators expect electricity bills to keep climbing, particularly in vulnerable areas. That will likely only increase pressure for regulators to intervene, the director of the Electricity Law Initiative at the Harvard Law School Environmental and Energy Law Program, Ari Peskoe, suggested in September.&lt;/p&gt;
&lt;p&gt;“The utility business model is all about spreading costs of system expansion to everyone, because we all benefit from a reliable, robust electricity system,” Peskoe said. “But when it’s a single consumer that is using so much energy—basically that of an entire city—and when that new city happens to be owned by the wealthiest corporations in the world, I think it’s time to look at the fundamental assumptions of utility regulation and make sure that these facilities are really paying for all of the infrastructure costs to connect them to the system and to power them.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/12/shady-data-center-deals-doom-americans-to-higher-energy-bills-senators-say/</guid><pubDate>Tue, 16 Dec 2025 20:25:57 +0000</pubDate></item></channel></rss>