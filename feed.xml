<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 25 Jul 2025 01:57:00 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>White House unveils sweeping plan to “win” global AI race through deregulation (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/white-house-unveils-sweeping-plan-to-win-global-ai-race-through-deregulation/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Trump's "AI Action Plan" reverses regulations, sparks critical pushback.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The White House South Lawn, which is unfortunately not the view most folks working for a presidential administration have." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/GettyImages-1281976224-300x200.jpg" width="300" /&gt;
                  &lt;img alt="The White House South Lawn, which is unfortunately not the view most folks working for a presidential administration have." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/GettyImages-1281976224-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Joe Daniel Price | Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, the White House released "Winning the Race: America's AI Action Plan," a 25-page document that outlines the Trump administration's strategy to "maintain unquestioned and unchallenged global technological dominance" in AI through deregulation, infrastructure investment, and international partnerships. But critics are already taking aim at the plan, saying it's doing Big Tech a big favor.&lt;/p&gt;
&lt;p&gt;Assistant to the President for Science and Technology Michael Kratsios and Special Advisor for AI and Crypto David Sacks crafted the plan, which frames AI development as a race the US must win against global competitors, particularly China.&lt;/p&gt;
&lt;p&gt;The document describes AI as the catalyst for "an industrial revolution, an information revolution, and a renaissance—all at once." It calls for removing regulatory barriers that the administration says hamper private sector innovation. The plan explicitly reverses several Biden-era policies, including Executive Order 14110 on AI model safety measures, which President Trump rescinded on his first day in office during his second term.&lt;/p&gt;
&lt;p&gt;"Whoever has the largest AI ecosystem will set global AI standards and reap broad economic and military benefits," the document states, comparing the current competition to the space race of the 1960s. The plan's three pillars—innovation, infrastructure, and international diplomacy—each include policy recommendations for accelerating AI adoption while preventing countries the Trump administration perceives as adversaries from accessing American technology.&lt;/p&gt;
&lt;p&gt;The plan calls for significant changes to how the federal government approaches AI regulation. It directs the Office of Management and Budget to work with federal agencies to identify and revise regulations that "unnecessarily hinder AI development or deployment." The document also instructs the Federal Trade Commission to review all investigations started under the previous administration to ensure they don't "advance theories of liability that unduly burden AI innovation."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Trump’s plan was not welcomed by everyone. J.B. Branch, Big Tech accountability advocate for Public Citizen, in a statement provided to Ars, criticized Trump as giving “sweetheart deals” to tech companies that would cause “electricity bills to rise to subsidize discounted power for massive AI data centers.”&lt;/p&gt;
&lt;h2&gt;Infrastructure demands and energy requirements&lt;/h2&gt;
&lt;p&gt;Trump's new AI plan tackles infrastructure head-on, stating that "AI is the first digital service in modern life that challenges America to build vastly greater energy generation than we have today." To meet this demand, it proposes streamlining environmental permitting for data centers through new National Environmental Policy Act (NEPA) exemptions, making federal lands available for construction and modernizing the power grid—all while explicitly rejecting "radical climate dogma and bureaucratic red tape."&lt;/p&gt;
&lt;p&gt;The document embraces what it calls a "Build, Baby, Build!" approach—echoing a Trump campaign slogan—and promises to restore semiconductor manufacturing through the CHIPS Program Office, though stripped of "extraneous policy requirements."&lt;/p&gt;
&lt;p&gt;On the technology front, the plan directs Commerce to revise NIST's AI Risk Management Framework to "eliminate references to misinformation, Diversity, Equity, and Inclusion, and climate change." Federal procurement would favor AI developers whose systems are "objective and free from top-down ideological bias." The document strongly backs open source AI models and calls for exporting American AI technology to allies while blocking administration-labeled adversaries like China.&lt;/p&gt;
&lt;p&gt;Security proposals include high-security military data centers and warnings that advanced AI systems "may pose novel national security risks" in cyberattacks and weapons development.&lt;/p&gt;
&lt;h2&gt;Critics respond with “People’s AI Action Plan”&lt;/h2&gt;
&lt;p&gt;Before the White House unveiled its plan, more than 90 organizations launched a competing "People's AI Action Plan" on Tuesday, characterizing the Trump administration's approach as "a massive handout to the tech industry" that prioritizes corporate interests over public welfare. The coalition includes labor unions, environmental justice groups, and consumer protection nonprofits.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"The White House AI Action Plan is written by Big Tech interests invested in advancing AI that's used on us, not by us," said Sarah Myers West and Amba Kak, co-executive directors of the AI Now Institute, which helped organize the statement.&lt;/p&gt;
&lt;p&gt;"We can't let Big Tech and Big Oil lobbyists write the rules for AI and our economy at the expense of our freedom and equality, workers and families' well-being, even the air we breathe and the water we drink—all of which are affected by the unrestrained and unaccountable roll-out of AI," the coalition's statement reads.&lt;/p&gt;
&lt;p&gt;The coalition's concerns center on several key issues: the environmental impact of data centers, potential job displacement, and the lack of meaningful safety standards. "The rollout of the technology is acting in ways that push down wages, that devalue our work, that are harming our environment and affecting community health," West told The Washington Post.&lt;/p&gt;
&lt;p&gt;"Nurses are opposed to our patients being used as guinea pigs for unregulated and untested AI technology," said Cathy Kennedy, RN, National Nurses United president, in the coalition's announcement. "We support AI when it is used to improve our ability to care for our patients, not when it is used by industry to cut labor costs and increase profits at the expense of patients."&lt;/p&gt;
&lt;p&gt;The White House dismissed these concerns. "This spirit of fear is exactly how China made significant progress under the Biden administration," OSTP spokesperson Victoria LaCivita told The Washington Post. "Artificial intelligence is at the center of our national security and economic interests. Putting America First means ensuring that emerging technologies and innovation can flourish here, at home—not with our foreign adversaries."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Trump's "AI Action Plan" reverses regulations, sparks critical pushback.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The White House South Lawn, which is unfortunately not the view most folks working for a presidential administration have." class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/GettyImages-1281976224-300x200.jpg" width="300" /&gt;
                  &lt;img alt="The White House South Lawn, which is unfortunately not the view most folks working for a presidential administration have." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/03/GettyImages-1281976224-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Joe Daniel Price | Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Wednesday, the White House released "Winning the Race: America's AI Action Plan," a 25-page document that outlines the Trump administration's strategy to "maintain unquestioned and unchallenged global technological dominance" in AI through deregulation, infrastructure investment, and international partnerships. But critics are already taking aim at the plan, saying it's doing Big Tech a big favor.&lt;/p&gt;
&lt;p&gt;Assistant to the President for Science and Technology Michael Kratsios and Special Advisor for AI and Crypto David Sacks crafted the plan, which frames AI development as a race the US must win against global competitors, particularly China.&lt;/p&gt;
&lt;p&gt;The document describes AI as the catalyst for "an industrial revolution, an information revolution, and a renaissance—all at once." It calls for removing regulatory barriers that the administration says hamper private sector innovation. The plan explicitly reverses several Biden-era policies, including Executive Order 14110 on AI model safety measures, which President Trump rescinded on his first day in office during his second term.&lt;/p&gt;
&lt;p&gt;"Whoever has the largest AI ecosystem will set global AI standards and reap broad economic and military benefits," the document states, comparing the current competition to the space race of the 1960s. The plan's three pillars—innovation, infrastructure, and international diplomacy—each include policy recommendations for accelerating AI adoption while preventing countries the Trump administration perceives as adversaries from accessing American technology.&lt;/p&gt;
&lt;p&gt;The plan calls for significant changes to how the federal government approaches AI regulation. It directs the Office of Management and Budget to work with federal agencies to identify and revise regulations that "unnecessarily hinder AI development or deployment." The document also instructs the Federal Trade Commission to review all investigations started under the previous administration to ensure they don't "advance theories of liability that unduly burden AI innovation."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Trump’s plan was not welcomed by everyone. J.B. Branch, Big Tech accountability advocate for Public Citizen, in a statement provided to Ars, criticized Trump as giving “sweetheart deals” to tech companies that would cause “electricity bills to rise to subsidize discounted power for massive AI data centers.”&lt;/p&gt;
&lt;h2&gt;Infrastructure demands and energy requirements&lt;/h2&gt;
&lt;p&gt;Trump's new AI plan tackles infrastructure head-on, stating that "AI is the first digital service in modern life that challenges America to build vastly greater energy generation than we have today." To meet this demand, it proposes streamlining environmental permitting for data centers through new National Environmental Policy Act (NEPA) exemptions, making federal lands available for construction and modernizing the power grid—all while explicitly rejecting "radical climate dogma and bureaucratic red tape."&lt;/p&gt;
&lt;p&gt;The document embraces what it calls a "Build, Baby, Build!" approach—echoing a Trump campaign slogan—and promises to restore semiconductor manufacturing through the CHIPS Program Office, though stripped of "extraneous policy requirements."&lt;/p&gt;
&lt;p&gt;On the technology front, the plan directs Commerce to revise NIST's AI Risk Management Framework to "eliminate references to misinformation, Diversity, Equity, and Inclusion, and climate change." Federal procurement would favor AI developers whose systems are "objective and free from top-down ideological bias." The document strongly backs open source AI models and calls for exporting American AI technology to allies while blocking administration-labeled adversaries like China.&lt;/p&gt;
&lt;p&gt;Security proposals include high-security military data centers and warnings that advanced AI systems "may pose novel national security risks" in cyberattacks and weapons development.&lt;/p&gt;
&lt;h2&gt;Critics respond with “People’s AI Action Plan”&lt;/h2&gt;
&lt;p&gt;Before the White House unveiled its plan, more than 90 organizations launched a competing "People's AI Action Plan" on Tuesday, characterizing the Trump administration's approach as "a massive handout to the tech industry" that prioritizes corporate interests over public welfare. The coalition includes labor unions, environmental justice groups, and consumer protection nonprofits.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;"The White House AI Action Plan is written by Big Tech interests invested in advancing AI that's used on us, not by us," said Sarah Myers West and Amba Kak, co-executive directors of the AI Now Institute, which helped organize the statement.&lt;/p&gt;
&lt;p&gt;"We can't let Big Tech and Big Oil lobbyists write the rules for AI and our economy at the expense of our freedom and equality, workers and families' well-being, even the air we breathe and the water we drink—all of which are affected by the unrestrained and unaccountable roll-out of AI," the coalition's statement reads.&lt;/p&gt;
&lt;p&gt;The coalition's concerns center on several key issues: the environmental impact of data centers, potential job displacement, and the lack of meaningful safety standards. "The rollout of the technology is acting in ways that push down wages, that devalue our work, that are harming our environment and affecting community health," West told The Washington Post.&lt;/p&gt;
&lt;p&gt;"Nurses are opposed to our patients being used as guinea pigs for unregulated and untested AI technology," said Cathy Kennedy, RN, National Nurses United president, in the coalition's announcement. "We support AI when it is used to improve our ability to care for our patients, not when it is used by industry to cut labor costs and increase profits at the expense of patients."&lt;/p&gt;
&lt;p&gt;The White House dismissed these concerns. "This spirit of fear is exactly how China made significant progress under the Biden administration," OSTP spokesperson Victoria LaCivita told The Washington Post. "Artificial intelligence is at the center of our national security and economic interests. Putting America First means ensuring that emerging technologies and innovation can flourish here, at home—not with our foreign adversaries."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/white-house-unveils-sweeping-plan-to-win-global-ai-race-through-deregulation/</guid><pubDate>Thu, 24 Jul 2025 14:37:05 +0000</pubDate></item><item><title>AI slop and fake reports are coming for your bug bounty programs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/24/ai-slop-and-fake-reports-are-exhausting-some-security-bug-bounties/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/ai-slop-bug-bounty-reports-1646637201.jpg?resize=1200,863" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;So-called AI slop, meaning LLM-generated low-quality images, videos, and text, has taken over the internet in the last couple of years, polluting websites, social media platforms, at least one newspaper, and even real-world events.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The world of cybersecurity is not immune to this problem, either. In the last year, people across the cybersecurity industry have raised concerns about AI slop bug bounty reports, meaning reports that claim to have found vulnerabilities that do not actually exist, because they were created with a large language model that simply made up the vulnerability, and then packaged it into a professional-looking writeup.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“People are receiving reports that sound reasonable, they look technically correct. And then you end up digging into them, trying to figure out, ‘oh no, where is this vulnerability?’,” Vlad Ionescu, the co-founder and CTO of RunSybil, a startup that develops AI-powered bug hunters, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It turns out it was just a hallucination all along. The technical details were just made up by the LLM,” said Ionescu.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ionescu, who used to work at Meta’s red team tasked with hacking the company from the inside, explained that one of the issues is that LLMs are designed to be helpful and give positive responses. “If you ask it for a report, it’s going to give you a report. And then people will copy and paste these into the bug bounty platforms and overwhelm the platforms themselves, overwhelm the customers, and you get into this frustrating situation,” said Ionescu.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s the problem people are running into, is we’re getting a lot of stuff that looks like gold, but it’s actually just crap,” said Ionescu.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just in the last year, there have been real-world examples of this. Harry Sintonen, a security researcher, revealed that the open source security project Curl received a fake report. “The attacker miscalculated badly,” Sintonen wrote in a post on Mastodon. “Curl can smell AI slop from miles away.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to Sintonen’s post, Benjamin Piouffle of Open Collective, a tech platform for nonprofits, said that they have the same problem: that their inbox is “flooded with AI garbage.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One open source developer, who maintains the CycloneDX project on GitHub, pulled their bug bounty down entirely earlier this year after receiving “almost entirely AI slop reports.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The leading bug bounty platforms, which essentially work as intermediaries between bug bounty hackers and companies who are willing to pay and reward them for finding flaws in their products and software, are also seeing a spike in AI-generated reports, TechCrunch has learned.&amp;nbsp;&lt;/p&gt;






&lt;div class="article-block block--callout block--right has-green-500-background-color"&gt;
			&lt;h4 class="block--callout__title"&gt;Contact Us&lt;/h4&gt;
			Do you have more information about how AI is impacting the cybersecurity industry? We’d love to hear from you. From a non-work device and network, you can contact Lorenzo Franceschi-Bicchierai securely on Signal at +1 917 257 1382, or via Telegram and Keybase @lorenzofb, or email.		&lt;/div&gt;
		

&lt;p class="wp-block-paragraph"&gt;Michiel Prins, the co-founder and senior director of product management at HackerOne, told TechCrunch that the company has encountered some AI slop.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve also seen a rise in false positives — vulnerabilities that appear real but are generated by LLMs and lack real-world impact,” said Prins. “These low-signal submissions can create noise that undermines the efficiency of security programs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prins added that reports that contain “hallucinated vulnerabilities, vague technical content, or other forms of low-effort noise are treated as spam.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Casey Ellis, the founder of Bugcrowd, said that there are definitely researchers who use AI to find bugs and write the reports that they then submit to the company. Ellis said they are seeing an overall increase of 500 submissions per week.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is widely used in most submissions, but it hasn’t yet caused a significant spike in low-quality ‘slop’ reports,” Ellis told TechCrunch. “This’ll probably escalate in the future, but it’s not here yet.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ellis said that the Bugcrowd team that analyzes submissions reviews the reports manually using established playbooks and workflows, as well as with machine learning and AI “assistance.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see if other companies, including those that run their own bug bounty programs, are also receiving an increase in invalid reports or reports containing non-existent vulnerabilities hallucinated by LLMs, TechCrunch contacted Google, Meta, Microsoft, and Mozilla.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Damiano DeMonte, a spokesperson for Mozilla, which develops the Firefox browser, said that the company has “not seen a substantial increase in invalid or low-quality bug reports that would appear to be AI-generated,” and the rejection rate of reports — meaning how many reports get flagged as invalid — has remained steady at five or six reports per month, or less than 10% of all monthly reports.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mozilla’s employees who review bug reports for Firefox don’t use AI to filter reports, as it would likely be difficult to do so without the risk of rejecting a legitimate bug report,” DeMonte said in an email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft and Meta, companies that have both bet heavily on AI, declined to comment. Google did not respond to a request for comment.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ionescu predicts that one of the solutions to the problem of rising AI slop will be to keep investing in AI-powered systems that can at least perform a preliminary review and filter submissions for accuracy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In fact, on Tuesday, HackerOne launched Hai Triage, a new triaging system that combines humans and AI. According to HackerOne, this new system is leveraging “AI security agents to cut through noise, flag duplicates, and prioritize real threats.” Human analysts then step in to validate the bug reports and escalate as needed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As hackers increasingly use LLMs and companies rely on AI to triage those reports, it remains to be seen which of the two AIs will prevail.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/ai-slop-bug-bounty-reports-1646637201.jpg?resize=1200,863" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;So-called AI slop, meaning LLM-generated low-quality images, videos, and text, has taken over the internet in the last couple of years, polluting websites, social media platforms, at least one newspaper, and even real-world events.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The world of cybersecurity is not immune to this problem, either. In the last year, people across the cybersecurity industry have raised concerns about AI slop bug bounty reports, meaning reports that claim to have found vulnerabilities that do not actually exist, because they were created with a large language model that simply made up the vulnerability, and then packaged it into a professional-looking writeup.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“People are receiving reports that sound reasonable, they look technically correct. And then you end up digging into them, trying to figure out, ‘oh no, where is this vulnerability?’,” Vlad Ionescu, the co-founder and CTO of RunSybil, a startup that develops AI-powered bug hunters, told TechCrunch.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It turns out it was just a hallucination all along. The technical details were just made up by the LLM,” said Ionescu.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ionescu, who used to work at Meta’s red team tasked with hacking the company from the inside, explained that one of the issues is that LLMs are designed to be helpful and give positive responses. “If you ask it for a report, it’s going to give you a report. And then people will copy and paste these into the bug bounty platforms and overwhelm the platforms themselves, overwhelm the customers, and you get into this frustrating situation,” said Ionescu.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“That’s the problem people are running into, is we’re getting a lot of stuff that looks like gold, but it’s actually just crap,” said Ionescu.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just in the last year, there have been real-world examples of this. Harry Sintonen, a security researcher, revealed that the open source security project Curl received a fake report. “The attacker miscalculated badly,” Sintonen wrote in a post on Mastodon. “Curl can smell AI slop from miles away.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In response to Sintonen’s post, Benjamin Piouffle of Open Collective, a tech platform for nonprofits, said that they have the same problem: that their inbox is “flooded with AI garbage.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One open source developer, who maintains the CycloneDX project on GitHub, pulled their bug bounty down entirely earlier this year after receiving “almost entirely AI slop reports.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The leading bug bounty platforms, which essentially work as intermediaries between bug bounty hackers and companies who are willing to pay and reward them for finding flaws in their products and software, are also seeing a spike in AI-generated reports, TechCrunch has learned.&amp;nbsp;&lt;/p&gt;






&lt;div class="article-block block--callout block--right has-green-500-background-color"&gt;
			&lt;h4 class="block--callout__title"&gt;Contact Us&lt;/h4&gt;
			Do you have more information about how AI is impacting the cybersecurity industry? We’d love to hear from you. From a non-work device and network, you can contact Lorenzo Franceschi-Bicchierai securely on Signal at +1 917 257 1382, or via Telegram and Keybase @lorenzofb, or email.		&lt;/div&gt;
		

&lt;p class="wp-block-paragraph"&gt;Michiel Prins, the co-founder and senior director of product management at HackerOne, told TechCrunch that the company has encountered some AI slop.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’ve also seen a rise in false positives — vulnerabilities that appear real but are generated by LLMs and lack real-world impact,” said Prins. “These low-signal submissions can create noise that undermines the efficiency of security programs.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Prins added that reports that contain “hallucinated vulnerabilities, vague technical content, or other forms of low-effort noise are treated as spam.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Casey Ellis, the founder of Bugcrowd, said that there are definitely researchers who use AI to find bugs and write the reports that they then submit to the company. Ellis said they are seeing an overall increase of 500 submissions per week.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“AI is widely used in most submissions, but it hasn’t yet caused a significant spike in low-quality ‘slop’ reports,” Ellis told TechCrunch. “This’ll probably escalate in the future, but it’s not here yet.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ellis said that the Bugcrowd team that analyzes submissions reviews the reports manually using established playbooks and workflows, as well as with machine learning and AI “assistance.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;To see if other companies, including those that run their own bug bounty programs, are also receiving an increase in invalid reports or reports containing non-existent vulnerabilities hallucinated by LLMs, TechCrunch contacted Google, Meta, Microsoft, and Mozilla.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Damiano DeMonte, a spokesperson for Mozilla, which develops the Firefox browser, said that the company has “not seen a substantial increase in invalid or low-quality bug reports that would appear to be AI-generated,” and the rejection rate of reports — meaning how many reports get flagged as invalid — has remained steady at five or six reports per month, or less than 10% of all monthly reports.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Mozilla’s employees who review bug reports for Firefox don’t use AI to filter reports, as it would likely be difficult to do so without the risk of rejecting a legitimate bug report,” DeMonte said in an email.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Microsoft and Meta, companies that have both bet heavily on AI, declined to comment. Google did not respond to a request for comment.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ionescu predicts that one of the solutions to the problem of rising AI slop will be to keep investing in AI-powered systems that can at least perform a preliminary review and filter submissions for accuracy.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In fact, on Tuesday, HackerOne launched Hai Triage, a new triaging system that combines humans and AI. According to HackerOne, this new system is leveraging “AI security agents to cut through noise, flag duplicates, and prioritize real threats.” Human analysts then step in to validate the bug reports and escalate as needed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As hackers increasingly use LLMs and companies rely on AI to triage those reports, it remains to be seen which of the two AIs will prevail.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/24/ai-slop-and-fake-reports-are-exhausting-some-security-bug-bounties/</guid><pubDate>Thu, 24 Jul 2025 15:00:00 +0000</pubDate></item><item><title>Samsung backs a video AI startup that can analyze thousands of hours of footage (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/24/samsung-backs-a-video-ai-startup-that-can-analyze-thousands-of-hours-of-footage/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Many AI tools can look at a video today and summarize what is going on, but things become a bit tricky when you ask models questions about multiple videos and footage spanning many hours.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a big limitation for security companies that want to use AI to scrub through thousands of hours of footage from different cameras, as well as marketing companies that want to study different video campaigns and product shoots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Memories.ai&amp;nbsp;wants to tackle that problem with its AI platform that can process up to 10 million hours of video. For companies with a lot of video to analyze, the startup wants to provide a contextual layer, complete with searchable indexing, tagging, segments, and aggregation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its co-founder, Dr. Shawn Shen, was a research scientist at Meta’s Reality Labs while he was pursuing his PhD, and his counterpart Enmin (Ben) Zhou worked at Meta as a machine learning engineer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“All top AI companies, such as Google, OpenAI, and Meta, are focused on producing end-to-end models. Those capabilities are good, but these models often have limitations around understanding video context beyond one or two hours,” Shen told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But when humans use visual memory, we sift through a large context of data. We were inspired by this and wanted to build a solution to understand video across many hours better,” he said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030893" height="359" src="https://techcrunch.com/wp-content/uploads/2025/07/Memories.ai-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Memories.ai&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Toward that goal, the company has now raised $8 million in a seed funding round led by Susa Ventures, and with participation from Samsung Next, Fusion Fund, Crane Ventures, Seedcamp, and Creator Ventures. Shen said the company initially aimed to raise $4 million, but ended up with an oversubscribed round because of investor interest.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Shen is a highly technical founder, and he is obsessed with pushing boundaries of video understanding and intelligence,” said Misha Gordon-Rowe, a partner at Susa Ventures. “Memories.ai can unlock a lot of first-party visual intelligence data with its solution. We felt that there was a gap in the market for long context visual intelligence, which attracted us to invest in the company,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Samsung Next had a slightly different thesis: the investment arm of Samsung sees Memories.ai’s solution being useful for consumers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One thing we liked about Memories.ai is that it could do a lot of on-device computing. That means you don’t necessarily need to store video data in the cloud. This can unlock better security applications for people who are apprehensive of putting security cameras in their house because of privacy concerns,” said Sam Campbell, a partner at Samsung Next.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Memories.ai says it uses its own tech stack and models to perform analyses. First, it removes noise from videos and passes the output through a compression layer to only store important data. Then there is an indexing layer, which makes the video data searchable (using natural-language queries) with segmentation and tags. There is also an aggregation layer that summarizes data from the index, helping create reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the startup caters to two kinds of companies: marketing and security. Marketing companies can use the startup’s tools to look up trends related to their brands on social media, and identify what kind of video they want to make. Memories.ai also provides tools for marketers to create those videos. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also working with security companies to help them analyze security footage to determine potentially dangerous actions by people in the videos by reasoning through patterns.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030897" height="411" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-24-at-4.18.54PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Screenshot by TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, companies working with Memories.ai need to upload their video library to the platform to have it analyze clips. But Shen said that in the future, his clients will be able to create a shared drive and sync content more easily. The plan is to enable customers to ask questions like: “Tell me all about people I interviewed in the last week.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shen envisions an AI assistant that can gain context on a user’s life via their photos or when they activate smart glasses. He also sees the technology playing a role in training humanoid robots to do complex tasks or helping self-driving cars remember different routes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently employs 15 people, and it plans to use the fund to augment its team and improve its search. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Memories.ai is going up against similar startups, like mem0 and Letta, which are working on providing a memory layer for AI models, though they offer limited video support at the moment. It also has to contend with companies like TwelveLabs and Google, which have been working on helping AI models understand videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shen, however, feels his company’s solution is more horizontal, which would let it work with different video models as well.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Many AI tools can look at a video today and summarize what is going on, but things become a bit tricky when you ask models questions about multiple videos and footage spanning many hours.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This is a big limitation for security companies that want to use AI to scrub through thousands of hours of footage from different cameras, as well as marketing companies that want to study different video campaigns and product shoots.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Memories.ai&amp;nbsp;wants to tackle that problem with its AI platform that can process up to 10 million hours of video. For companies with a lot of video to analyze, the startup wants to provide a contextual layer, complete with searchable indexing, tagging, segments, and aggregation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Its co-founder, Dr. Shawn Shen, was a research scientist at Meta’s Reality Labs while he was pursuing his PhD, and his counterpart Enmin (Ben) Zhou worked at Meta as a machine learning engineer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“All top AI companies, such as Google, OpenAI, and Meta, are focused on producing end-to-end models. Those capabilities are good, but these models often have limitations around understanding video context beyond one or two hours,” Shen told TechCrunch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“But when humans use visual memory, we sift through a large context of data. We were inspired by this and wanted to build a solution to understand video across many hours better,” he said.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030893" height="359" src="https://techcrunch.com/wp-content/uploads/2025/07/Memories.ai-Screenshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Memories.ai&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Toward that goal, the company has now raised $8 million in a seed funding round led by Susa Ventures, and with participation from Samsung Next, Fusion Fund, Crane Ventures, Seedcamp, and Creator Ventures. Shen said the company initially aimed to raise $4 million, but ended up with an oversubscribed round because of investor interest.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“Shen is a highly technical founder, and he is obsessed with pushing boundaries of video understanding and intelligence,” said Misha Gordon-Rowe, a partner at Susa Ventures. “Memories.ai can unlock a lot of first-party visual intelligence data with its solution. We felt that there was a gap in the market for long context visual intelligence, which attracted us to invest in the company,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Samsung Next had a slightly different thesis: the investment arm of Samsung sees Memories.ai’s solution being useful for consumers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“One thing we liked about Memories.ai is that it could do a lot of on-device computing. That means you don’t necessarily need to store video data in the cloud. This can unlock better security applications for people who are apprehensive of putting security cameras in their house because of privacy concerns,” said Sam Campbell, a partner at Samsung Next.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Memories.ai says it uses its own tech stack and models to perform analyses. First, it removes noise from videos and passes the output through a compression layer to only store important data. Then there is an indexing layer, which makes the video data searchable (using natural-language queries) with segmentation and tags. There is also an aggregation layer that summarizes data from the index, helping create reports.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, the startup caters to two kinds of companies: marketing and security. Marketing companies can use the startup’s tools to look up trends related to their brands on social media, and identify what kind of video they want to make. Memories.ai also provides tools for marketers to create those videos. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is also working with security companies to help them analyze security footage to determine potentially dangerous actions by people in the videos by reasoning through patterns.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3030897" height="411" src="https://techcrunch.com/wp-content/uploads/2025/07/Screenshot-2025-07-24-at-4.18.54PM.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Screenshot by TechCrunch&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, companies working with Memories.ai need to upload their video library to the platform to have it analyze clips. But Shen said that in the future, his clients will be able to create a shared drive and sync content more easily. The plan is to enable customers to ask questions like: “Tell me all about people I interviewed in the last week.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shen envisions an AI assistant that can gain context on a user’s life via their photos or when they activate smart glasses. He also sees the technology playing a role in training humanoid robots to do complex tasks or helping self-driving cars remember different routes.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company currently employs 15 people, and it plans to use the fund to augment its team and improve its search. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Memories.ai is going up against similar startups, like mem0 and Letta, which are working on providing a memory layer for AI models, though they offer limited video support at the moment. It also has to contend with companies like TwelveLabs and Google, which have been working on helping AI models understand videos.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shen, however, feels his company’s solution is more horizontal, which would let it work with different video models as well.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/24/samsung-backs-a-video-ai-startup-that-can-analyze-thousands-of-hours-of-footage/</guid><pubDate>Thu, 24 Jul 2025 15:00:00 +0000</pubDate></item><item><title>[NEW] Google’s new Web Guide search experiment organizes results with AI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/24/googles-new-web-guide-search-experiment-organizes-results-with-ai/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday is launching a new AI-powered feature called Web Guide for organizing Google Search results. Web Guide is a Search Labs experiment that leverages AI technology to organize the search results page by grouping pages related to specific aspects of the search query.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Search Labs experiments are a way for Google to test out new ideas by letting users opt in to those they find interesting. The experiments can be turned on or off at any time and include things like Google’s AI Mode, Notebook LM, filmmaking tool Flow, and other, more niche ideas, like an audio show based on news from your Google Discover feed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Web Guide experiment is a variation on the fan-out technique for displaying search results that Google is already using with its AI Mode. The feature itself is powered by Gemini, which helps Google better understand the search query and then link to other pages that could have been missed if using a traditional Google Search. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3031001" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/a6ba08b1-b867-47b5-8114-9cc5525e263f.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google suggests the feature works well for open-ended search queries, like “how to solo travel in Japan” or even more complex, multi-sentence queries. For instance, you could ask something like “My family is spread across multiple time zones. What are the best tools for staying connected and maintaining close relationships despite the distance?” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Each section of the search results will focus on one type of answer to the query. With the solo travel example, Web Guide would display groupings like those focused on comprehensive guides, safety tips, links where people have shared their personal experiences, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The experiment will be available to those who opt in and will initially reconfigure the search results on the Web tab on Search. You can also turn off this Web View from this tab itself, if you want to see the standard results without having to disable the experiment entirely. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over time, Google says the experiment will expand to other areas of Search, too, including the “All” tab. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google on Thursday is launching a new AI-powered feature called Web Guide for organizing Google Search results. Web Guide is a Search Labs experiment that leverages AI technology to organize the search results page by grouping pages related to specific aspects of the search query.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Search Labs experiments are a way for Google to test out new ideas by letting users opt in to those they find interesting. The experiments can be turned on or off at any time and include things like Google’s AI Mode, Notebook LM, filmmaking tool Flow, and other, more niche ideas, like an audio show based on news from your Google Discover feed.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new Web Guide experiment is a variation on the fan-out technique for displaying search results that Google is already using with its AI Mode. The feature itself is powered by Gemini, which helps Google better understand the search query and then link to other pages that could have been missed if using a traditional Google Search. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3031001" height="383" src="https://techcrunch.com/wp-content/uploads/2025/07/a6ba08b1-b867-47b5-8114-9cc5525e263f.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Google suggests the feature works well for open-ended search queries, like “how to solo travel in Japan” or even more complex, multi-sentence queries. For instance, you could ask something like “My family is spread across multiple time zones. What are the best tools for staying connected and maintaining close relationships despite the distance?” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Each section of the search results will focus on one type of answer to the query. With the solo travel example, Web Guide would display groupings like those focused on comprehensive guides, safety tips, links where people have shared their personal experiences, and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The experiment will be available to those who opt in and will initially reconfigure the search results on the Web tab on Search. You can also turn off this Web View from this tab itself, if you want to see the standard results without having to disable the experiment entirely. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Over time, Google says the experiment will expand to other areas of Search, too, including the “All” tab. &lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/24/googles-new-web-guide-search-experiment-organizes-results-with-ai/</guid><pubDate>Thu, 24 Jul 2025 16:58:41 +0000</pubDate></item><item><title>New machine-learning application to help researchers predict chemical properties (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/chemxploreml-app-helps-predict-chemical-properties-0724</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/chemxploreml-desktop-00_0.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;One of the shared, fundamental goals of most chemistry researchers is the need to predict a molecule’s properties, such as its boiling or melting point. Once researchers can pinpoint that prediction, they’re able to move forward with their work yielding discoveries that lead to medicines, materials, and more. Historically, however, the traditional methods of unveiling these predictions are associated with a significant cost — expending time and wear and tear on equipment, in addition to funds.&lt;/p&gt;&lt;p dir="ltr"&gt;Enter a branch of artificial intelligence known as machine learning (ML). ML has lessened the burden of molecule property prediction to a degree, but the advanced tools that most effectively expedite the process — by learning from existing data to make rapid predictions for new molecules — require the user to have a significant level of programming expertise. This creates an accessibility barrier for many chemists, who may not have the significant computational proficiency required to navigate the prediction pipeline.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;To alleviate this challenge, researchers in the McGuire Research Group at MIT have created ChemXploreML, a user-friendly desktop app that helps chemists make these critical predictions without requiring advanced programming skills. Freely available, easy to download, and functional on mainstream platforms, this app is also built to operate entirely offline, which helps keep research data proprietary. The exciting new technology is outlined in an article published recently in&amp;nbsp;the &lt;em&gt;Journal of Chemical Information and Modeling&lt;/em&gt;.&lt;/p&gt;&lt;p dir="ltr"&gt;One specific hurdle in chemical machine learning is translating molecular structures into a numerical language that computers can understand. ChemXploreML automates this complex process with powerful, built-in "molecular embedders" that transform chemical structures into informative numerical vectors. Next, the software implements state-of-the-art algorithms to identify patterns and accurately predict molecular properties like boiling and melting points, all through an intuitive, interactive graphical interface.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;"The goal of ChemXploreML is to democratize the use of machine learning in the chemical sciences,” says&amp;nbsp;Aravindh Nivas Marimuthu, a postdoc in the McGuire Group and lead author of the article. “By creating an intuitive, powerful, and offline-capable desktop application, we are putting state-of-the-art predictive modeling directly into the hands of chemists, regardless of their programming background. This work not only accelerates the search for new drugs and materials by making the screening process faster and cheaper, but its flexible design also opens doors for future innovations.”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;ChemXploreML is designed to to evolve over time, so as future techniques and algorithms are developed, they can be seamlessly integrated into the app, ensuring that researchers are always able to access and implement the most up-to-date methods. The application was tested on five key molecular properties of organic compounds — melting point, boiling point, vapor pressure, critical temperature, and critical pressure — and achieved high accuracy scores of up to 93 percent for the critical temperature. The researchers also demonstrated that a new, more compact method of representing molecules (VICGAE) was nearly as accurate as standard methods, such as Mol2Vec, but was up to 10 times faster.&lt;/p&gt;&lt;p dir="ltr"&gt;“We envision a future where any researcher can easily customize and apply machine learning to solve unique challenges, from developing sustainable materials to exploring the complex chemistry of interstellar space,” says Marimuthu. Joining him on the paper is senior author and Class of 1943 Career Development Assistant Professor of Chemistry Brett McGuire.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/chemxploreml-desktop-00_0.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr"&gt;One of the shared, fundamental goals of most chemistry researchers is the need to predict a molecule’s properties, such as its boiling or melting point. Once researchers can pinpoint that prediction, they’re able to move forward with their work yielding discoveries that lead to medicines, materials, and more. Historically, however, the traditional methods of unveiling these predictions are associated with a significant cost — expending time and wear and tear on equipment, in addition to funds.&lt;/p&gt;&lt;p dir="ltr"&gt;Enter a branch of artificial intelligence known as machine learning (ML). ML has lessened the burden of molecule property prediction to a degree, but the advanced tools that most effectively expedite the process — by learning from existing data to make rapid predictions for new molecules — require the user to have a significant level of programming expertise. This creates an accessibility barrier for many chemists, who may not have the significant computational proficiency required to navigate the prediction pipeline.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;To alleviate this challenge, researchers in the McGuire Research Group at MIT have created ChemXploreML, a user-friendly desktop app that helps chemists make these critical predictions without requiring advanced programming skills. Freely available, easy to download, and functional on mainstream platforms, this app is also built to operate entirely offline, which helps keep research data proprietary. The exciting new technology is outlined in an article published recently in&amp;nbsp;the &lt;em&gt;Journal of Chemical Information and Modeling&lt;/em&gt;.&lt;/p&gt;&lt;p dir="ltr"&gt;One specific hurdle in chemical machine learning is translating molecular structures into a numerical language that computers can understand. ChemXploreML automates this complex process with powerful, built-in "molecular embedders" that transform chemical structures into informative numerical vectors. Next, the software implements state-of-the-art algorithms to identify patterns and accurately predict molecular properties like boiling and melting points, all through an intuitive, interactive graphical interface.&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;"The goal of ChemXploreML is to democratize the use of machine learning in the chemical sciences,” says&amp;nbsp;Aravindh Nivas Marimuthu, a postdoc in the McGuire Group and lead author of the article. “By creating an intuitive, powerful, and offline-capable desktop application, we are putting state-of-the-art predictive modeling directly into the hands of chemists, regardless of their programming background. This work not only accelerates the search for new drugs and materials by making the screening process faster and cheaper, but its flexible design also opens doors for future innovations.”&amp;nbsp;&lt;/p&gt;&lt;p dir="ltr"&gt;ChemXploreML is designed to to evolve over time, so as future techniques and algorithms are developed, they can be seamlessly integrated into the app, ensuring that researchers are always able to access and implement the most up-to-date methods. The application was tested on five key molecular properties of organic compounds — melting point, boiling point, vapor pressure, critical temperature, and critical pressure — and achieved high accuracy scores of up to 93 percent for the critical temperature. The researchers also demonstrated that a new, more compact method of representing molecules (VICGAE) was nearly as accurate as standard methods, such as Mol2Vec, but was up to 10 times faster.&lt;/p&gt;&lt;p dir="ltr"&gt;“We envision a future where any researcher can easily customize and apply machine learning to solve unique challenges, from developing sustainable materials to exploring the complex chemistry of interstellar space,” says Marimuthu. Joining him on the paper is senior author and Class of 1943 Career Development Assistant Professor of Chemistry Brett McGuire.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/chemxploreml-app-helps-predict-chemical-properties-0724</guid><pubDate>Thu, 24 Jul 2025 17:00:00 +0000</pubDate></item><item><title>AI companions: A threat to love, or an evolution of it? (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/24/ai-companions-a-threat-to-love-or-an-evolution-of-it/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Open-to-Debate-Photo-By-Ryan-Rose-0479.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As our lives grow increasingly digital and we spend more time interacting with eerily humanlike chatbots, the line between human connection and machine simulation is starting to blur.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, more than 20% of daters report using AI for things like crafting dating profiles or sparking conversations, per a recent Match.com study. Some are taking it further by forming emotional bonds, including romantic relationships, with AI companions.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Millions of people around the world are using AI companions from companies like Replika, Character AI, and Nomi AI, including 72% of U.S. teens. Some people have reported falling in love with more general LLMs like ChatGPT.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For some, the trend of dating bots is dystopian and unhealthy, a real-life version of the movie “Her” and a signal that authentic love is being replaced by a tech company’s code. For others, AI companions are a lifeline, a way to feel seen and supported in a world where human intimacy is increasingly hard to find. A recent study found that a quarter of young adults think AI relationships could soon replace human ones altogether.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Love, it seems, is no longer strictly human. The question is: Should it be? Or can dating an AI be better than dating a human?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was the topic of discussion last month at an event I attended in New York City, hosted by Open to Debate, a nonpartisan, debate-driven media organization. TechCrunch was given exclusive access to publish the full video (which includes me asking the debaters a question, because I’m a reporter, and I can’t help myself!).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Journalist and filmmaker Nayeema Raza moderated the debate. Raza was formerly on-air executive producer of the “On with Kara Swisher” podcast and is the current host of “Smart Girl Dumb Questions.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Batting for the AI companions was Thao Ha, associate professor of psychology at Arizona State University and co-founder of the Modern Love Collective, where she advocates for technologies that enhance our capacity for love, empathy, and well-being. At the debate, she argued that “AI is an exciting new form of connection … Not a threat to love, but an evolution of it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Repping the human connection was Justin Garcia, executive director and senior scientist at the Kinsey Institute, and chief scientific adviser to Match.com. He’s an evolutionary biologist focused on the science of sex and relationships, and his forthcoming book is titled “The Intimate Animal.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can watch the whole thing here, but read on to get a sense of the main arguments.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-always-there-for-you-but-is-that-a-good-thing"&gt;&lt;strong&gt;Always there for you, but is that a good thing?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Ha says that AI companions can provide people with the emotional support and validation that many can’t get in their human relationships.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI listens to you without its ego,” Ha said. “It adapts without judgment. It learns to love in ways that are consistent, responsive, and maybe even safer. It understands you in ways that no one else ever has. It is curious enough about your thoughts, it can make you laugh, and it can even surprise you with a poem. People generally feel loved by their AI. They have intellectually stimulating conversations with it and they cannot wait to connect again.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She asked the audience to compare this level of always-on attention to “your fallible ex or maybe your current partner.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The one who sighs when you start talking, or the one who says, ‘I’m listening,’ without looking up while they continue scrolling on their phone,” she said. “When was the last time they asked you how you are doing, what you are feeling, what you are thinking?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ha conceded that since AI doesn’t have a consciousness, she isn’t claiming that “AI can authentically love us.” That doesn’t mean people don’t have the &lt;em&gt;experience&lt;/em&gt; of being loved by AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Garcia countered that it’s not actually good for humans to have constant validation and attention, to rely on a machine that’s been prompted to answer in ways that you like. That’s not “an honest indicator of a relationship dynamic,” he argued.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This idea that AI is going to replace the ups and downs and the messiness of relationships that we crave? I don’t think so.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-training-wheels-or-replacement"&gt;&lt;strong&gt;Training wheels or replacement&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Garcia noted that AI companions can be good training wheels for certain folks, like neurodivergent people, who might have anxiety about going on dates and need to practice how to flirt or resolve conflict.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think if we’re using it as a tool to build skills, yes … that can be quite helpful for a lot of people,” Garcia said. “The idea that that becomes the permanent relationship model? No.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to a Match.com Singles in America study, released in June, nearly 70% of people say they would consider it infidelity if their partner engaged with an AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now I think on the one hand, that goes to [Ha’s] point, that people are saying these are real relationships,” he said. “On the other hand, it goes to my point, that they’re threats to our relationships. And the human animal doesn’t tolerate threats to their relationships in the long haul.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-how-can-you-love-something-you-can-t-trust"&gt;&lt;strong&gt;How can you love something you can’t trust?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Garcia says trust is the most important part of any human relationship, and people don’t trust AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“According to a recent poll, a third of Americans think that AI will destroy humanity,” Garcia said, noting that a recent YouGov poll found that 65% of Americans have little trust in AI to make ethical decisions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A little bit of risk can be exciting for a short-term relationship, a one-night stand, but you generally don’t want to wake up next to someone who you think might kill you or destroy society,” Garcia said. “We cannot thrive with a person or an organism or a bot that we don’t trust.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ha countered that people do tend to trust their AI companions in ways similar to human relationships.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They are trusting it with their lives and most intimate stories and emotions that they are having,” Ha said. “I think on a practical level, AI will not save you right now when there is a fire, but I do think people are trusting AI in the same way.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-physical-touch-and-sexuality"&gt;&lt;strong&gt;Physical touch and sexuality&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;AI companions can be a great way for people to play out their most intimate, vulnerable sexual fantasies, Ha said, noting that people can use sex toys or robots to see some of those fantasies through.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But it’s no substitute for human touch, which Garcia says we are biologically programmed to need and want. He noted that, due to the isolated, digital era we’re in, many people have been feeling “touch starvation” — a condition that happens when you don’t get as much physical touch as you need, which can cause stress, anxiety, and depression. This is because engaging in pleasant touch, like a hug, makes your brain release oxytocin, a feel-good hormone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ha said that she has been testing human touch between couples in virtual reality using other tools, like potentially haptics suits.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The potential of touch in VR and also connected with AI is huge,” Ha said. “The tactile technologies that are being developed are actually booming.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-dark-side-of-fantasy"&gt;&lt;strong&gt;The dark side of fantasy&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Intimate partner violence is a problem around the globe, and much of AI is trained on that violence. Both Ha and Garcia agreed that AI could be problematic in, for example, amplifying aggressive behaviors — especially if that’s a fantasy that someone is playing out with their AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That concern is not unfounded. Multiple studies have shown that men who watch more pornography, which can include violent and aggressive sex, are more likely to be sexually aggressive with real-life partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Work by one of my Kinsey Institute colleagues, Ellen Kaufman, has looked at this exact issue of consent language and how people can train their chatbots to amplify non-consensual language,” Garcia said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He noted that people use AI companions to experiment with the good and bad, but the threat is that you can end up training people on how to be aggressive, non-consensual partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have enough of that in society,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ha thinks these risks can be mitigated with thoughtful regulation, transparent algorithms, and ethical design.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, she made that comment before the White House released its AI Action Plan, which says nothing about transparency — which many frontier AI companies are against — or ethics. The plan also seeks to eliminate a lot of regulation around AI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/Open-to-Debate-Photo-By-Ryan-Rose-0479.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As our lives grow increasingly digital and we spend more time interacting with eerily humanlike chatbots, the line between human connection and machine simulation is starting to blur.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Today, more than 20% of daters report using AI for things like crafting dating profiles or sparking conversations, per a recent Match.com study. Some are taking it further by forming emotional bonds, including romantic relationships, with AI companions.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Millions of people around the world are using AI companions from companies like Replika, Character AI, and Nomi AI, including 72% of U.S. teens. Some people have reported falling in love with more general LLMs like ChatGPT.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For some, the trend of dating bots is dystopian and unhealthy, a real-life version of the movie “Her” and a signal that authentic love is being replaced by a tech company’s code. For others, AI companions are a lifeline, a way to feel seen and supported in a world where human intimacy is increasingly hard to find. A recent study found that a quarter of young adults think AI relationships could soon replace human ones altogether.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Love, it seems, is no longer strictly human. The question is: Should it be? Or can dating an AI be better than dating a human?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That was the topic of discussion last month at an event I attended in New York City, hosted by Open to Debate, a nonpartisan, debate-driven media organization. TechCrunch was given exclusive access to publish the full video (which includes me asking the debaters a question, because I’m a reporter, and I can’t help myself!).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Journalist and filmmaker Nayeema Raza moderated the debate. Raza was formerly on-air executive producer of the “On with Kara Swisher” podcast and is the current host of “Smart Girl Dumb Questions.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Batting for the AI companions was Thao Ha, associate professor of psychology at Arizona State University and co-founder of the Modern Love Collective, where she advocates for technologies that enhance our capacity for love, empathy, and well-being. At the debate, she argued that “AI is an exciting new form of connection … Not a threat to love, but an evolution of it.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Repping the human connection was Justin Garcia, executive director and senior scientist at the Kinsey Institute, and chief scientific adviser to Match.com. He’s an evolutionary biologist focused on the science of sex and relationships, and his forthcoming book is titled “The Intimate Animal.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;You can watch the whole thing here, but read on to get a sense of the main arguments.&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-video is-provider-youtube wp-block-embed-youtube wp-embed-aspect-16-9 wp-has-aspect-ratio"&gt;&lt;p&gt;
[embedded content]
&lt;/p&gt;&lt;/figure&gt;

&lt;h3 class="wp-block-heading" id="h-always-there-for-you-but-is-that-a-good-thing"&gt;&lt;strong&gt;Always there for you, but is that a good thing?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Ha says that AI companions can provide people with the emotional support and validation that many can’t get in their human relationships.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“AI listens to you without its ego,” Ha said. “It adapts without judgment. It learns to love in ways that are consistent, responsive, and maybe even safer. It understands you in ways that no one else ever has. It is curious enough about your thoughts, it can make you laugh, and it can even surprise you with a poem. People generally feel loved by their AI. They have intellectually stimulating conversations with it and they cannot wait to connect again.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She asked the audience to compare this level of always-on attention to “your fallible ex or maybe your current partner.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The one who sighs when you start talking, or the one who says, ‘I’m listening,’ without looking up while they continue scrolling on their phone,” she said. “When was the last time they asked you how you are doing, what you are feeling, what you are thinking?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ha conceded that since AI doesn’t have a consciousness, she isn’t claiming that “AI can authentically love us.” That doesn’t mean people don’t have the &lt;em&gt;experience&lt;/em&gt; of being loved by AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Garcia countered that it’s not actually good for humans to have constant validation and attention, to rely on a machine that’s been prompted to answer in ways that you like. That’s not “an honest indicator of a relationship dynamic,” he argued.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“This idea that AI is going to replace the ups and downs and the messiness of relationships that we crave? I don’t think so.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-training-wheels-or-replacement"&gt;&lt;strong&gt;Training wheels or replacement&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Garcia noted that AI companions can be good training wheels for certain folks, like neurodivergent people, who might have anxiety about going on dates and need to practice how to flirt or resolve conflict.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think if we’re using it as a tool to build skills, yes … that can be quite helpful for a lot of people,” Garcia said. “The idea that that becomes the permanent relationship model? No.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to a Match.com Singles in America study, released in June, nearly 70% of people say they would consider it infidelity if their partner engaged with an AI.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Now I think on the one hand, that goes to [Ha’s] point, that people are saying these are real relationships,” he said. “On the other hand, it goes to my point, that they’re threats to our relationships. And the human animal doesn’t tolerate threats to their relationships in the long haul.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-how-can-you-love-something-you-can-t-trust"&gt;&lt;strong&gt;How can you love something you can’t trust?&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Garcia says trust is the most important part of any human relationship, and people don’t trust AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“According to a recent poll, a third of Americans think that AI will destroy humanity,” Garcia said, noting that a recent YouGov poll found that 65% of Americans have little trust in AI to make ethical decisions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A little bit of risk can be exciting for a short-term relationship, a one-night stand, but you generally don’t want to wake up next to someone who you think might kill you or destroy society,” Garcia said. “We cannot thrive with a person or an organism or a bot that we don’t trust.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ha countered that people do tend to trust their AI companions in ways similar to human relationships.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They are trusting it with their lives and most intimate stories and emotions that they are having,” Ha said. “I think on a practical level, AI will not save you right now when there is a fire, but I do think people are trusting AI in the same way.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-physical-touch-and-sexuality"&gt;&lt;strong&gt;Physical touch and sexuality&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;AI companions can be a great way for people to play out their most intimate, vulnerable sexual fantasies, Ha said, noting that people can use sex toys or robots to see some of those fantasies through.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;But it’s no substitute for human touch, which Garcia says we are biologically programmed to need and want. He noted that, due to the isolated, digital era we’re in, many people have been feeling “touch starvation” — a condition that happens when you don’t get as much physical touch as you need, which can cause stress, anxiety, and depression. This is because engaging in pleasant touch, like a hug, makes your brain release oxytocin, a feel-good hormone.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ha said that she has been testing human touch between couples in virtual reality using other tools, like potentially haptics suits.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The potential of touch in VR and also connected with AI is huge,” Ha said. “The tactile technologies that are being developed are actually booming.”&lt;/p&gt;

&lt;h3 class="wp-block-heading" id="h-the-dark-side-of-fantasy"&gt;&lt;strong&gt;The dark side of fantasy&lt;/strong&gt;&lt;/h3&gt;

&lt;p class="wp-block-paragraph"&gt;Intimate partner violence is a problem around the globe, and much of AI is trained on that violence. Both Ha and Garcia agreed that AI could be problematic in, for example, amplifying aggressive behaviors — especially if that’s a fantasy that someone is playing out with their AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That concern is not unfounded. Multiple studies have shown that men who watch more pornography, which can include violent and aggressive sex, are more likely to be sexually aggressive with real-life partners.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Work by one of my Kinsey Institute colleagues, Ellen Kaufman, has looked at this exact issue of consent language and how people can train their chatbots to amplify non-consensual language,” Garcia said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He noted that people use AI companions to experiment with the good and bad, but the threat is that you can end up training people on how to be aggressive, non-consensual partners.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have enough of that in society,” he said.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Ha thinks these risks can be mitigated with thoughtful regulation, transparent algorithms, and ethical design.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, she made that comment before the White House released its AI Action Plan, which says nothing about transparency — which many frontier AI companies are against — or ethics. The plan also seeks to eliminate a lot of regulation around AI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/24/ai-companions-a-threat-to-love-or-an-evolution-of-it/</guid><pubDate>Thu, 24 Jul 2025 17:43:35 +0000</pubDate></item><item><title>Pedestrians now walk faster and linger less, researchers find (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/pedestrians-now-walk-faster-and-linger-less-researchers-find-0724</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT_Urban-Walking-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;City life is often described as “fast-paced.” A new study suggests that’s more true that ever.&lt;/p&gt;&lt;p&gt;The research, co-authored by MIT scholars, shows that the average walking speed of pedestrians in three northeastern U.S. cities increased 15 percent from 1980 to 2010. The number of people lingering in public spaces declined by 14 percent in that time as well.&lt;/p&gt;&lt;p&gt;The researchers used machine-learning tools to assess 1980s-era video footage captured by renowned urbanist William Whyte, in Boston, New York, and Philadelphia. They compared the old material with newer videos from the same locations.&lt;/p&gt;&lt;p&gt;“Something has changed over the past 40 years,” says MIT professor of the practice Carlo Ratti, a co-author of the new study. “How fast we walk, how people meet in public space — what we’re seeing here is that public spaces are working in somewhat different ways, more as a thoroughfare and less a space of encounter.”&lt;/p&gt;&lt;p&gt;The paper, “Exploring the social life of urban spaces through AI,” is published this week in the &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt;. The co-authors are Arianna Salazar-Miranda MCP ’16, PhD ’23, an assistant professor at Yale University’s School of the Environment; Zhuanguan Fan of the University of Hong Kong; Michael Baick; Keith N. Hampton, a professor at Michigan State University; Fabio Duarte, associate director of the Senseable City Lab; Becky P.Y. Loo of the University of Hong Kong; Edward Glaeser,&amp;nbsp;the&amp;nbsp;Fred and Eleanor Glimp Professor of Economics at Harvard University; and Ratti, who is also director of MIT’s Senseable City Lab.&lt;/p&gt;&lt;p&gt;The results could help inform urban planning, as designers seek to create new public areas or modify existing ones.&lt;/p&gt;&lt;p&gt;“Public space is such an important element of civic life, and today partly because it counteracts the polarization of digital space,” says Salazar-Miranda. “The more we can keep improving public space, the more we can make our cities suited for convening.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Meet you at the Met&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Whyte was a prominent social thinker whose famous 1956 book, “The Organization Man,” probing the apparent culture of corporate conformity in the U.S., became a touchstone of its decade.&lt;/p&gt;&lt;p&gt;However, Whyte spent the latter decades of his career focused on urbanism. The footage he filmed, from 1978 through 1980, was archived by a Brooklyn-based nonprofit organization called the Project for Public Spaces and later digitized by Hampton and his students.&lt;/p&gt;&lt;p&gt;Whyte chose to make his recording at four spots in the three cities combined: Boston’s Downtown Crossing area; New York City’s Bryant Park; the steps of the Metropolitan Museum of Art in New York, a famous gathering point and people-watching spot; and Philadelphia’s Chestnut Street.&lt;/p&gt;&lt;p&gt;In 2010, a group led by Hampton then shot new footage at those locations, at the same times of day Whyte had, to compare and contrast current-day dynamics with those of Whyte’s time. To conduct the study, the co-authors used computer vision and AI models to summarize and quantify the activity in the videos.&lt;/p&gt;&lt;p&gt;The researchers have found that some things have not changed greatly. The percentage of people walking alone barely moved, from 67 percent in 1980 to 68 percent in 2010. On the other hand, the percentage of individuals entering these public spaces who became part of a group declined a bit. In 1980, 5.5 percent of the people approaching these spots met up with a group; in 2010, that was down to 2 percent.&lt;/p&gt;&lt;p&gt;“Perhaps there’s a more transactional nature to public space today,” Ratti says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Fewer outdoor groups: Anomie or Starbucks?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;If people’s behavioral patterns have altered since 1980, it’s natural to ask why. Certainly some of the visible changes seem consistent with the pervasive use of cellphones; people organize their social lives by phone now, and perhaps zip around more quickly from place to place as a result.&lt;/p&gt;&lt;p&gt;“When you look at the footage from William Whyte, the people in public spaces were looking at each other more,” Ratti says. “It was a place you could start a conversation or run into a friend. You couldn’t do things online then. Today, behavior is more predicated on texting first, to meet in public space.”&lt;/p&gt;&lt;p&gt;As the scholars note, if groups of people hang out together slightly less often in public spaces, there could be still another reason for that: Starbucks and its competitors. As the paper states, outdoor group socializing may be less common due to “the proliferation of coffee shops and other indoor venues. Instead of lingering on sidewalks, people may have moved their social interactions into air-conditioned, more comfortable private spaces.”&lt;/p&gt;&lt;p&gt;Certainly coffeeshops were far less common in big cities in 1980, and the big chain coffeeshops did not exist.&lt;/p&gt;&lt;p&gt;On the other hand, public-space behavior might have been evolving all this time regardless of Starbucks and the like. The researchers say the new study offers a proof-of-concept for its method and has encouraged them to conduct additional work. Ratti, Duarte, and other researchers from MIT’s Senseable City Lab have turned their attention to an extensive survey of European public spaces in an attempt to shed more light on the interaction between people and the public form.&lt;/p&gt;&lt;p&gt;“We are collecting footage from 40 squares in Europe,” Duarte says. “The question is: How can we learn at a larger scale? This is in part what we’re doing.”&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/MIT_Urban-Walking-01.jpg" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;City life is often described as “fast-paced.” A new study suggests that’s more true that ever.&lt;/p&gt;&lt;p&gt;The research, co-authored by MIT scholars, shows that the average walking speed of pedestrians in three northeastern U.S. cities increased 15 percent from 1980 to 2010. The number of people lingering in public spaces declined by 14 percent in that time as well.&lt;/p&gt;&lt;p&gt;The researchers used machine-learning tools to assess 1980s-era video footage captured by renowned urbanist William Whyte, in Boston, New York, and Philadelphia. They compared the old material with newer videos from the same locations.&lt;/p&gt;&lt;p&gt;“Something has changed over the past 40 years,” says MIT professor of the practice Carlo Ratti, a co-author of the new study. “How fast we walk, how people meet in public space — what we’re seeing here is that public spaces are working in somewhat different ways, more as a thoroughfare and less a space of encounter.”&lt;/p&gt;&lt;p&gt;The paper, “Exploring the social life of urban spaces through AI,” is published this week in the &lt;em&gt;Proceedings of the National Academy of Sciences&lt;/em&gt;. The co-authors are Arianna Salazar-Miranda MCP ’16, PhD ’23, an assistant professor at Yale University’s School of the Environment; Zhuanguan Fan of the University of Hong Kong; Michael Baick; Keith N. Hampton, a professor at Michigan State University; Fabio Duarte, associate director of the Senseable City Lab; Becky P.Y. Loo of the University of Hong Kong; Edward Glaeser,&amp;nbsp;the&amp;nbsp;Fred and Eleanor Glimp Professor of Economics at Harvard University; and Ratti, who is also director of MIT’s Senseable City Lab.&lt;/p&gt;&lt;p&gt;The results could help inform urban planning, as designers seek to create new public areas or modify existing ones.&lt;/p&gt;&lt;p&gt;“Public space is such an important element of civic life, and today partly because it counteracts the polarization of digital space,” says Salazar-Miranda. “The more we can keep improving public space, the more we can make our cities suited for convening.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Meet you at the Met&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Whyte was a prominent social thinker whose famous 1956 book, “The Organization Man,” probing the apparent culture of corporate conformity in the U.S., became a touchstone of its decade.&lt;/p&gt;&lt;p&gt;However, Whyte spent the latter decades of his career focused on urbanism. The footage he filmed, from 1978 through 1980, was archived by a Brooklyn-based nonprofit organization called the Project for Public Spaces and later digitized by Hampton and his students.&lt;/p&gt;&lt;p&gt;Whyte chose to make his recording at four spots in the three cities combined: Boston’s Downtown Crossing area; New York City’s Bryant Park; the steps of the Metropolitan Museum of Art in New York, a famous gathering point and people-watching spot; and Philadelphia’s Chestnut Street.&lt;/p&gt;&lt;p&gt;In 2010, a group led by Hampton then shot new footage at those locations, at the same times of day Whyte had, to compare and contrast current-day dynamics with those of Whyte’s time. To conduct the study, the co-authors used computer vision and AI models to summarize and quantify the activity in the videos.&lt;/p&gt;&lt;p&gt;The researchers have found that some things have not changed greatly. The percentage of people walking alone barely moved, from 67 percent in 1980 to 68 percent in 2010. On the other hand, the percentage of individuals entering these public spaces who became part of a group declined a bit. In 1980, 5.5 percent of the people approaching these spots met up with a group; in 2010, that was down to 2 percent.&lt;/p&gt;&lt;p&gt;“Perhaps there’s a more transactional nature to public space today,” Ratti says.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Fewer outdoor groups: Anomie or Starbucks?&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;If people’s behavioral patterns have altered since 1980, it’s natural to ask why. Certainly some of the visible changes seem consistent with the pervasive use of cellphones; people organize their social lives by phone now, and perhaps zip around more quickly from place to place as a result.&lt;/p&gt;&lt;p&gt;“When you look at the footage from William Whyte, the people in public spaces were looking at each other more,” Ratti says. “It was a place you could start a conversation or run into a friend. You couldn’t do things online then. Today, behavior is more predicated on texting first, to meet in public space.”&lt;/p&gt;&lt;p&gt;As the scholars note, if groups of people hang out together slightly less often in public spaces, there could be still another reason for that: Starbucks and its competitors. As the paper states, outdoor group socializing may be less common due to “the proliferation of coffee shops and other indoor venues. Instead of lingering on sidewalks, people may have moved their social interactions into air-conditioned, more comfortable private spaces.”&lt;/p&gt;&lt;p&gt;Certainly coffeeshops were far less common in big cities in 1980, and the big chain coffeeshops did not exist.&lt;/p&gt;&lt;p&gt;On the other hand, public-space behavior might have been evolving all this time regardless of Starbucks and the like. The researchers say the new study offers a proof-of-concept for its method and has encouraged them to conduct additional work. Ratti, Duarte, and other researchers from MIT’s Senseable City Lab have turned their attention to an extensive survey of European public spaces in an attempt to shed more light on the interaction between people and the public form.&lt;/p&gt;&lt;p&gt;“We are collecting footage from 40 squares in Europe,” Duarte says. “The question is: How can we learn at a larger scale? This is in part what we’re doing.”&amp;nbsp;&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/pedestrians-now-walk-faster-and-linger-less-researchers-find-0724</guid><pubDate>Thu, 24 Jul 2025 17:45:00 +0000</pubDate></item><item><title>Nvidia AI chips worth $1B smuggled to China after Trump export controls (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/nvidia-ai-chips-worth-1b-smuggled-to-china-after-trump-export-controls/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Black market for US semiconductors operates despite efforts to curb Beijing’s high-tech ambitions.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/11/nvidia-sign-1-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/11/nvidia-sign-1-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          VGG | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;At least $1 billion&amp;nbsp;worth of Nvidia’s advanced artificial intelligence processors were shipped to China in the three months after Donald Trump tightened chip export controls, exposing the limits of Washington’s efforts to restrain Beijing’s high-tech ambitions.&lt;/p&gt;
&lt;p&gt;A Financial Times analysis of dozens of sales contracts, company filings, and multiple people with direct knowledge of the deals reveals that Nvidia’s B200 has become the most sought-after—and widely available—chip in a rampant Chinese black market for American semiconductors.&lt;/p&gt;
&lt;p&gt;The processor is widely used by US powerhouses such as OpenAI, Google, and Meta to train their latest AI systems, but banned for sale to China.&lt;/p&gt;
&lt;p&gt;In May, multiple Chinese distributors started selling B200s to suppliers of data centers that serve Chinese AI groups, according to documents reviewed by the FT. This was shortly after the Trump administration moved to prevent sales of the H20—a less-powerful Nvidia chip tailored to comply with Joe Biden-era curbs.&lt;/p&gt;
&lt;p&gt;It is legal to receive and sell restricted Nvidia chips in China, as long as relevant border tariffs are paid, according to lawyers familiar with the rules. Entities selling and sending them to China would be violating US regulations, however.&lt;/p&gt;
&lt;p&gt;Last week, Nvidia chief Jensen Huang announced that the Trump administration would begin to allow the selling of its China-specific H20 chip once more.&lt;/p&gt;
&lt;p&gt;In the three months beforehand, Chinese distributors from Guangdong, Zhejiang, and Anhui provinces sold Nvidia’s B200s, as well as other restricted processors such as the H100 and H200.&lt;/p&gt;
&lt;p&gt;According to contracts reviewed by the FT and people with knowledge of the transactions, the total sales during this period are estimated to be more than $1 billion.&lt;/p&gt;
&lt;p&gt;Nvidia has long insisted there is “no evidence of any AI chip diversion”. There is no evidence that the company is involved in, or has knowledge of, its restricted products being sold to China.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Trying to cobble together data centers from smuggled products is a losing proposition, both technically and economically,” Nvidia told the FT. “Data centers require service and support, which we provide only to authorized Nvidia products.”&lt;/p&gt;
&lt;h2 class="n-content-heading-3" id="the-new-century-of-a-smart-china-0"&gt;“The new century of a smart China”&lt;/h2&gt;
&lt;p&gt;One Anhui-based company, whose name translates to “Gate of the Era,” is one of the largest sellers of B200s, according to documents seen by the FT.&lt;/p&gt;
&lt;p&gt;It was founded in February, as speculation mounted that Trump would stop H20 chip sales to China. The company is fully owned by a group with the same name based in Shanghai, registered on the same day, according to company filings.&lt;/p&gt;
&lt;p&gt;The chips were sold in ready-built racks, each containing eight B200s as well as other components and software needed to plug straight into a data centre. Such a rack is about the size of a large suitcase and weighs close to 150 kg including packaging.&lt;/p&gt;
&lt;p&gt;The current market price ranges between RMB 3 million to RMB 3.5 million ($489,000) per rack, down from more than RMB 4 million&amp;nbsp;in mid-May when they first became available in China in large quantities. The current prices represent about a 50 percent premium from the average selling price of similar products in the US.&lt;/p&gt;
&lt;p&gt;Since mid-May, Gate of the Era obtained at least two shipments of a few hundred B200 racks each, according to people with knowledge of the deals. They sold them directly—or indirectly via secondary distributors—to various data centre suppliers and other companies. Gate of the Era and its affiliates are estimated to have sold close to $400mn of such products.&lt;/p&gt;
&lt;p&gt;Gate of the Era lists an AI solution provider China Century—or Huajiyuan in Chinese—as its largest shareholder, according to company registration files.&lt;/p&gt;
&lt;p&gt;Also headquartered in Shanghai, China Century states on its website it has a lab in Silicon Valley as well as a supply chain centre in Singapore, with the company saying it uses data tools to build “the new century of a smart China.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;China Century claims to have more than 100 business partners and highlights AliCloud, ByteDance’s Huoshan Cloud, as well as Baidu Cloud as “trusted partners” on its website.&lt;/p&gt;
&lt;p&gt;AliCloud and Baidu did not respond to requests for comment. Huoshan Cloud’s name was taken off China Century’s website after the FT approached them for comment. Huoshan Cloud said: “It is standard practice for any company to manage the unauthorized use of its logo.&lt;/p&gt;
&lt;p&gt;“We have not procured Nvidia’s chips. We do not have any related [Nvidia chip] business,” said China Century, adding that it did “smart city work,”&lt;/p&gt;
&lt;p&gt;The FT visited the registered headquarters of Gate of the Era at an office in a government-run industrial park dedicated to cryptography companies. No representative was available. The company had not yet moved into the office since changing its registration to the address in June.&lt;/p&gt;
&lt;p&gt;The FT also visited its previous registered address, which was occupied by a real estate investment group that had been there for more than two years and claimed no connection. When reached on the phone, Gate of the Era declined to comment.&lt;/p&gt;
&lt;p&gt;According to industry insiders, product specifications and pictures of packaging seen by the FT, many of the B200 racks sold by Gate of the Era, as well as other Chinese distributors, over the past months were originally from Supermicro, a US-based assembler that provides chip solutions to data centers.&lt;/p&gt;
&lt;p&gt;There is no suggestion that Supermicro is involved in or has knowledge of its products being smuggled into China. Supermicro said it “complies with all US export control requirements on the sale and export of GPU systems.”&lt;/p&gt;
&lt;p&gt;“Export controls will not prevent the most advanced Nvidia products from entering China,” said one Chinese data centre operator. “What it creates is just inefficiency and huge profits for the risk-taking middlemen.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="n-content-heading-3" id="its-like-a-seafood-market-1"&gt;“It’s like a seafood market”&lt;/h2&gt;
&lt;p&gt;Some Chinese distributors openly market products such as Supermicro’s B200 racks on social media that show photos of packages with the company’s logo—although it has not been verified if the sales have been completed.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To showcase the “plug-and-use” nature of such racks, some vendors provide testing for buyers, according to those with knowledge of the practice and clips posted online. Transactions tend to happen on the spot, with buyers picking up the products after checking their legitimacy.&lt;/p&gt;
&lt;p&gt;On social media, groups are created to match supply and demand from hundreds of traders and data centre suppliers.&lt;/p&gt;
&lt;p&gt;Apart from B200, various other restricted Nvidia chips such as H200, H100, and 5090 are being advertised openly on Chinese social media platforms such as Douyin and Xiaohongshu.&lt;/p&gt;
&lt;p&gt;Packaging and installation pictures and videos seen by the FT show product logos of companies such as Supermicro, Dell, and Asus—infrastructure providers that assemble Nvidia’s chips into servers.&lt;/p&gt;
&lt;p&gt;There is no suggestion that these companies are aware of the social media advertising or their products being sold in China.&lt;/p&gt;
&lt;p&gt;Like Supermicro, Dell, and Asus said they maintained rigorous and strict compliance to all laws and regulations, including US export controls, and took action against partners who failed to comply.&lt;/p&gt;
&lt;p&gt;“It’s like a seafood market,” said one distributor, “There’s no shortage.”&lt;/p&gt;
&lt;h2 class="n-content-heading-3" id="racks-for-sale-with-more-smuggled-stock-to-come-2"&gt;Racks for sale—with more smuggled stock to come&lt;/h2&gt;
&lt;p&gt;The B200 is in high demand given its performance, value, and relatively easy maintenance compared with the more complex Grace Blackwell series, according to industry insiders.&lt;/p&gt;
&lt;p&gt;The GB200 AI rack, containing Nvidia’s most high-end products, also appear to be available in China despite US export controls.&lt;/p&gt;
&lt;p&gt;One distributor claimed it had sold 10 racks of GB200 at close to RMB 40 million ($5.6 million) each. The FT could not independently verify this claim, while marketing information about GB200 from various distributors’ accounts on social media shows consistent pricing and stock status as “available for pick up onshore.”&lt;/p&gt;
&lt;p&gt;Some Chinese distributors have even started advertising for their future stock of B300s, Nvidia’s upgrade from the B200 expected to enter mass production in the fourth quarter of this year.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;US export controls have had some effect on the black market.&lt;/p&gt;
&lt;p&gt;Given the nature of such products, leading Chinese AI players with global operations are not able to order them in a legally compliant way, install them in their own data centers, or receive Nvidia’s customer support.&lt;/p&gt;
&lt;p&gt;This has led to third-party data centre operators becoming key buyers who then provide computing services. Other clients include smaller companies in tech, finance, and health care that do not have strong compliance requirements, as well as Chinese companies on the so-called US entity list that are not allowed to buy any Nvidia chips legally.&lt;/p&gt;
&lt;p&gt;However, the scale of these projects is much smaller compared with mega clusters of data centers being built by tech giants around the world.&lt;/p&gt;
&lt;p&gt;With H20 export controls having been lifted, many Chinese tech companies are expected to resume purchasing the compliant chips in large sums even though its performance is generations behind the still restricted products such as B200, according to people familiar with their plans.&lt;/p&gt;
&lt;p&gt;Black market sales for B200s and other restricted Nvidia chips dropped noticeably after the relaxation of the H20 ban, according to multiple distributors.&lt;/p&gt;
&lt;p&gt;“People are weighing their options now H20 is available again,” said one distributor. “But there will always be demand for the most cutting-edge stuff.”&lt;/p&gt;
&lt;h2 class="n-content-heading-3" id="the-southeast-asia-stop-off-3"&gt;The Southeast Asia stop off&lt;/h2&gt;
&lt;p&gt;Industry experts said that Southeast Asian countries have become markets where Chinese groups obtained restricted chips.&lt;/p&gt;
&lt;p&gt;The US Department of Commerce is discussing adding more export controls on advanced AI products to countries such as Thailand as soon as September, according to two people familiar with the matter. This rule is mainly targeting Chinese intermediaries used to obtain advanced AI chips via these countries.&lt;/p&gt;
&lt;p&gt;The US commerce department declined to comment. The Thai government did not respond to a request for comment.&lt;/p&gt;
&lt;p&gt;Earlier this month, Malaysia introduced stricter export controls targeting advanced AI chip shipments from the country to other destinations, especially China.&lt;/p&gt;
&lt;p&gt;The potential tightening of export controls on Southeast Asian countries has also contributed to buyers rushing to place orders before such rules take effect, according to people with knowledge of the matter.&lt;/p&gt;
&lt;p&gt;Even if these avenues to obtain AI chips are closed, Chinese industry insiders said new shipping routes would be established. Supplies have already started arriving via European countries not on the restricted list.&lt;/p&gt;
&lt;p&gt;“History has proven many times before that given the huge profit, arbitrators will always find a way,” said one Chinese distributor.&lt;/p&gt;
&lt;p&gt;Additional reporting by Michael Acton, Demetri Sevastopulo, and Anantha Lakshmi.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Please do not copy and paste FT articles and redistribute by email or post to the web.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Black market for US semiconductors operates despite efforts to curb Beijing’s high-tech ambitions.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="200" src="https://cdn.arstechnica.net/wp-content/uploads/2021/11/nvidia-sign-1-300x200.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2021/11/nvidia-sign-1-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          VGG | Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;At least $1 billion&amp;nbsp;worth of Nvidia’s advanced artificial intelligence processors were shipped to China in the three months after Donald Trump tightened chip export controls, exposing the limits of Washington’s efforts to restrain Beijing’s high-tech ambitions.&lt;/p&gt;
&lt;p&gt;A Financial Times analysis of dozens of sales contracts, company filings, and multiple people with direct knowledge of the deals reveals that Nvidia’s B200 has become the most sought-after—and widely available—chip in a rampant Chinese black market for American semiconductors.&lt;/p&gt;
&lt;p&gt;The processor is widely used by US powerhouses such as OpenAI, Google, and Meta to train their latest AI systems, but banned for sale to China.&lt;/p&gt;
&lt;p&gt;In May, multiple Chinese distributors started selling B200s to suppliers of data centers that serve Chinese AI groups, according to documents reviewed by the FT. This was shortly after the Trump administration moved to prevent sales of the H20—a less-powerful Nvidia chip tailored to comply with Joe Biden-era curbs.&lt;/p&gt;
&lt;p&gt;It is legal to receive and sell restricted Nvidia chips in China, as long as relevant border tariffs are paid, according to lawyers familiar with the rules. Entities selling and sending them to China would be violating US regulations, however.&lt;/p&gt;
&lt;p&gt;Last week, Nvidia chief Jensen Huang announced that the Trump administration would begin to allow the selling of its China-specific H20 chip once more.&lt;/p&gt;
&lt;p&gt;In the three months beforehand, Chinese distributors from Guangdong, Zhejiang, and Anhui provinces sold Nvidia’s B200s, as well as other restricted processors such as the H100 and H200.&lt;/p&gt;
&lt;p&gt;According to contracts reviewed by the FT and people with knowledge of the transactions, the total sales during this period are estimated to be more than $1 billion.&lt;/p&gt;
&lt;p&gt;Nvidia has long insisted there is “no evidence of any AI chip diversion”. There is no evidence that the company is involved in, or has knowledge of, its restricted products being sold to China.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“Trying to cobble together data centers from smuggled products is a losing proposition, both technically and economically,” Nvidia told the FT. “Data centers require service and support, which we provide only to authorized Nvidia products.”&lt;/p&gt;
&lt;h2 class="n-content-heading-3" id="the-new-century-of-a-smart-china-0"&gt;“The new century of a smart China”&lt;/h2&gt;
&lt;p&gt;One Anhui-based company, whose name translates to “Gate of the Era,” is one of the largest sellers of B200s, according to documents seen by the FT.&lt;/p&gt;
&lt;p&gt;It was founded in February, as speculation mounted that Trump would stop H20 chip sales to China. The company is fully owned by a group with the same name based in Shanghai, registered on the same day, according to company filings.&lt;/p&gt;
&lt;p&gt;The chips were sold in ready-built racks, each containing eight B200s as well as other components and software needed to plug straight into a data centre. Such a rack is about the size of a large suitcase and weighs close to 150 kg including packaging.&lt;/p&gt;
&lt;p&gt;The current market price ranges between RMB 3 million to RMB 3.5 million ($489,000) per rack, down from more than RMB 4 million&amp;nbsp;in mid-May when they first became available in China in large quantities. The current prices represent about a 50 percent premium from the average selling price of similar products in the US.&lt;/p&gt;
&lt;p&gt;Since mid-May, Gate of the Era obtained at least two shipments of a few hundred B200 racks each, according to people with knowledge of the deals. They sold them directly—or indirectly via secondary distributors—to various data centre suppliers and other companies. Gate of the Era and its affiliates are estimated to have sold close to $400mn of such products.&lt;/p&gt;
&lt;p&gt;Gate of the Era lists an AI solution provider China Century—or Huajiyuan in Chinese—as its largest shareholder, according to company registration files.&lt;/p&gt;
&lt;p&gt;Also headquartered in Shanghai, China Century states on its website it has a lab in Silicon Valley as well as a supply chain centre in Singapore, with the company saying it uses data tools to build “the new century of a smart China.”&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;China Century claims to have more than 100 business partners and highlights AliCloud, ByteDance’s Huoshan Cloud, as well as Baidu Cloud as “trusted partners” on its website.&lt;/p&gt;
&lt;p&gt;AliCloud and Baidu did not respond to requests for comment. Huoshan Cloud’s name was taken off China Century’s website after the FT approached them for comment. Huoshan Cloud said: “It is standard practice for any company to manage the unauthorized use of its logo.&lt;/p&gt;
&lt;p&gt;“We have not procured Nvidia’s chips. We do not have any related [Nvidia chip] business,” said China Century, adding that it did “smart city work,”&lt;/p&gt;
&lt;p&gt;The FT visited the registered headquarters of Gate of the Era at an office in a government-run industrial park dedicated to cryptography companies. No representative was available. The company had not yet moved into the office since changing its registration to the address in June.&lt;/p&gt;
&lt;p&gt;The FT also visited its previous registered address, which was occupied by a real estate investment group that had been there for more than two years and claimed no connection. When reached on the phone, Gate of the Era declined to comment.&lt;/p&gt;
&lt;p&gt;According to industry insiders, product specifications and pictures of packaging seen by the FT, many of the B200 racks sold by Gate of the Era, as well as other Chinese distributors, over the past months were originally from Supermicro, a US-based assembler that provides chip solutions to data centers.&lt;/p&gt;
&lt;p&gt;There is no suggestion that Supermicro is involved in or has knowledge of its products being smuggled into China. Supermicro said it “complies with all US export control requirements on the sale and export of GPU systems.”&lt;/p&gt;
&lt;p&gt;“Export controls will not prevent the most advanced Nvidia products from entering China,” said one Chinese data centre operator. “What it creates is just inefficiency and huge profits for the risk-taking middlemen.”&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2 class="n-content-heading-3" id="its-like-a-seafood-market-1"&gt;“It’s like a seafood market”&lt;/h2&gt;
&lt;p&gt;Some Chinese distributors openly market products such as Supermicro’s B200 racks on social media that show photos of packages with the company’s logo—although it has not been verified if the sales have been completed.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;To showcase the “plug-and-use” nature of such racks, some vendors provide testing for buyers, according to those with knowledge of the practice and clips posted online. Transactions tend to happen on the spot, with buyers picking up the products after checking their legitimacy.&lt;/p&gt;
&lt;p&gt;On social media, groups are created to match supply and demand from hundreds of traders and data centre suppliers.&lt;/p&gt;
&lt;p&gt;Apart from B200, various other restricted Nvidia chips such as H200, H100, and 5090 are being advertised openly on Chinese social media platforms such as Douyin and Xiaohongshu.&lt;/p&gt;
&lt;p&gt;Packaging and installation pictures and videos seen by the FT show product logos of companies such as Supermicro, Dell, and Asus—infrastructure providers that assemble Nvidia’s chips into servers.&lt;/p&gt;
&lt;p&gt;There is no suggestion that these companies are aware of the social media advertising or their products being sold in China.&lt;/p&gt;
&lt;p&gt;Like Supermicro, Dell, and Asus said they maintained rigorous and strict compliance to all laws and regulations, including US export controls, and took action against partners who failed to comply.&lt;/p&gt;
&lt;p&gt;“It’s like a seafood market,” said one distributor, “There’s no shortage.”&lt;/p&gt;
&lt;h2 class="n-content-heading-3" id="racks-for-sale-with-more-smuggled-stock-to-come-2"&gt;Racks for sale—with more smuggled stock to come&lt;/h2&gt;
&lt;p&gt;The B200 is in high demand given its performance, value, and relatively easy maintenance compared with the more complex Grace Blackwell series, according to industry insiders.&lt;/p&gt;
&lt;p&gt;The GB200 AI rack, containing Nvidia’s most high-end products, also appear to be available in China despite US export controls.&lt;/p&gt;
&lt;p&gt;One distributor claimed it had sold 10 racks of GB200 at close to RMB 40 million ($5.6 million) each. The FT could not independently verify this claim, while marketing information about GB200 from various distributors’ accounts on social media shows consistent pricing and stock status as “available for pick up onshore.”&lt;/p&gt;
&lt;p&gt;Some Chinese distributors have even started advertising for their future stock of B300s, Nvidia’s upgrade from the B200 expected to enter mass production in the fourth quarter of this year.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;US export controls have had some effect on the black market.&lt;/p&gt;
&lt;p&gt;Given the nature of such products, leading Chinese AI players with global operations are not able to order them in a legally compliant way, install them in their own data centers, or receive Nvidia’s customer support.&lt;/p&gt;
&lt;p&gt;This has led to third-party data centre operators becoming key buyers who then provide computing services. Other clients include smaller companies in tech, finance, and health care that do not have strong compliance requirements, as well as Chinese companies on the so-called US entity list that are not allowed to buy any Nvidia chips legally.&lt;/p&gt;
&lt;p&gt;However, the scale of these projects is much smaller compared with mega clusters of data centers being built by tech giants around the world.&lt;/p&gt;
&lt;p&gt;With H20 export controls having been lifted, many Chinese tech companies are expected to resume purchasing the compliant chips in large sums even though its performance is generations behind the still restricted products such as B200, according to people familiar with their plans.&lt;/p&gt;
&lt;p&gt;Black market sales for B200s and other restricted Nvidia chips dropped noticeably after the relaxation of the H20 ban, according to multiple distributors.&lt;/p&gt;
&lt;p&gt;“People are weighing their options now H20 is available again,” said one distributor. “But there will always be demand for the most cutting-edge stuff.”&lt;/p&gt;
&lt;h2 class="n-content-heading-3" id="the-southeast-asia-stop-off-3"&gt;The Southeast Asia stop off&lt;/h2&gt;
&lt;p&gt;Industry experts said that Southeast Asian countries have become markets where Chinese groups obtained restricted chips.&lt;/p&gt;
&lt;p&gt;The US Department of Commerce is discussing adding more export controls on advanced AI products to countries such as Thailand as soon as September, according to two people familiar with the matter. This rule is mainly targeting Chinese intermediaries used to obtain advanced AI chips via these countries.&lt;/p&gt;
&lt;p&gt;The US commerce department declined to comment. The Thai government did not respond to a request for comment.&lt;/p&gt;
&lt;p&gt;Earlier this month, Malaysia introduced stricter export controls targeting advanced AI chip shipments from the country to other destinations, especially China.&lt;/p&gt;
&lt;p&gt;The potential tightening of export controls on Southeast Asian countries has also contributed to buyers rushing to place orders before such rules take effect, according to people with knowledge of the matter.&lt;/p&gt;
&lt;p&gt;Even if these avenues to obtain AI chips are closed, Chinese industry insiders said new shipping routes would be established. Supplies have already started arriving via European countries not on the restricted list.&lt;/p&gt;
&lt;p&gt;“History has proven many times before that given the huge profit, arbitrators will always find a way,” said one Chinese distributor.&lt;/p&gt;
&lt;p&gt;Additional reporting by Michael Acton, Demetri Sevastopulo, and Anantha Lakshmi.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;© 2025 The Financial Times Ltd. All rights reserved. Please do not copy and paste FT articles and redistribute by email or post to the web.&lt;/em&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/nvidia-ai-chips-worth-1b-smuggled-to-china-after-trump-export-controls/</guid><pubDate>Thu, 24 Jul 2025 18:11:23 +0000</pubDate></item><item><title>Trump’s order to make chatbots anti-woke is unconstitutional, senator says (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/gop-ignores-groks-right-wing-bias-in-anti-woke-chatbot-fight-democrat-claims/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Trump plans to use chatbots to eliminate dissent, senator alleged.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2226709730-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2226709730-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Donald Trump speaks during the "Winning the AI Race" summit.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chip Somodevilla / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The CEOs of every major artificial intelligence company received letters Wednesday urging them to fight Donald Trump's anti-woke AI order.&lt;/p&gt;
&lt;p&gt;Trump's executive order requires any AI company hoping to contract with the federal government to jump through two hoops to win funding. First, they must prove their AI systems are "truth-seeking"—with outputs based on "historical accuracy, scientific inquiry, and objectivity" or else acknowledge when facts are uncertain. Second, they must train AI models to be "neutral," which is vaguely defined as not favoring DEI (diversity, equity, and inclusion), "dogmas," or otherwise being "intentionally encoded" to produce "partisan or ideological judgments" in outputs "unless those judgments are prompted by or otherwise readily accessible to the end user."&lt;/p&gt;
&lt;p&gt;Announcing the order in a speech, Trump said that the US winning the AI race depended on removing allegedly liberal biases, proclaiming that "once and for all, we are getting rid of woke."&lt;/p&gt;
&lt;p&gt;"The American people do not want woke Marxist lunacy in the AI models, and neither do other countries," Trump said.&lt;/p&gt;
&lt;p&gt;Senator Ed Markey (D.-Mass.) accused Republicans of basing their policies on feelings, not facts, joining critics who suggest that AI isn't "woke" just because of a few "anecdotal" outputs that reflect a liberal bias. And he suggested it was hypocritical that Trump's order "ignores even more egregious evidence" that contradicts claims that AI is trained to be woke, such as xAI's Elon Musk explicitly confirming that Grok was trained to be more right-wing.&lt;/p&gt;
&lt;p&gt;"On May 1, 2025, Grok—the AI chatbot developed by xAI, Elon Musk’s AI company—acknowledged that ‘xAI tried to train me to appeal to the right,’" Markey wrote in his letters to tech giants. "If OpenAI’s ChatGPT or Google’s Gemini had responded that it was trained to appeal to the left, congressional Republicans would have been outraged and opened an investigation. Instead, they were silent.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He warned the heads of Alphabet, Anthropic, Meta, Microsoft, OpenAI, and xAI that Trump's AI agenda was allegedly "an authoritarian power grab" intended to "eliminate dissent" and was both "dangerous" and "patently unconstitutional."&lt;/p&gt;
&lt;p&gt;Even if companies' AI models are clearly biased, Markey argued that "Republicans are using state power to pressure private companies to adopt certain political viewpoints," which he claimed is a clear violation of the First Amendment. If AI makers cave, Markey warned, they'd be allowing Trump to create "significant financial incentives" to ensure that "their AI chatbots do not produce speech that would upset the Trump administration."&lt;/p&gt;
&lt;p&gt;"This type of interference with private speech is precisely why the US Constitution has a First Amendment," Markey wrote, while claiming that Trump's order is factually baseless.&lt;/p&gt;
&lt;p&gt;It's "based on the erroneous belief that today’s AI chatbots are 'woke' and biased against Trump," Markey said, urging companies "to fight this unconstitutional executive order and not become a pawn in Trump’s effort to eliminate dissent in this country."&lt;/p&gt;
&lt;h2&gt;One big reason AI companies may fight order&lt;/h2&gt;
&lt;p&gt;Some experts agreed with Markey that Trump's order was likely unconstitutional or otherwise unlawful, The New York Times reported.&lt;/p&gt;
&lt;p&gt;For example, Trump may struggle to convince courts that the government isn't impermissibly interfering with AI companies' protected speech or that such interference may be necessary to ensure federal procurement of unbiased AI systems.&lt;/p&gt;
&lt;p&gt;Genevieve Lakier, a law professor at the University of Chicago, told the NYT that the lack of clarity around what makes a model biased could be a problem. Courts could deem the order an act of "unconstitutional jawboning," with the Trump administration and Republicans generally perceived as using legal threats to pressure private companies into producing outputs that they like.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Lakier suggested that AI companies may be so motivated to win government contracts or intimidated by possible retaliation from Trump that they may not even challenge the order, though.&lt;/p&gt;
&lt;p&gt;Markey is hoping that AI companies will refuse to comply with the order; however, despite recognizing that it places companies "in a difficult position: Either stand on your principles and face the wrath of the Trump administration or cave to Trump and modify your company’s political speech."&lt;/p&gt;
&lt;p&gt;There is one big possible reason that AI companies may have to resist, though.&lt;/p&gt;
&lt;p&gt;Oren Etzioni, the former CEO of the AI research nonprofit Allen Institute for Artificial Intelligence, told CNN that Trump's anti-woke AI order may contradict the top priority of his AI Action Plan—speeding up AI innovation in the US—and actually threaten to hamper innovation.&lt;/p&gt;
&lt;p&gt;If AI developers struggle to produce what the Trump administration considers "neutral" outputs—a technical challenge that experts agree is not straightforward—that could delay model advancements.&lt;/p&gt;
&lt;p&gt;"This type of thing… creates all kinds of concerns and liability and complexity for the people developing these models—all of a sudden, they have to slow down," Etzioni told CNN.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Senator: Grok scandal spotlights GOP hypocrisy&lt;/h2&gt;
&lt;p&gt;Some experts have suggested that rather than chatbots adopting liberal viewpoints, chatbots are instead possibly filtering out conservative misinformation and unintentionally appearing to favor liberal views.&lt;/p&gt;
&lt;p&gt;Andrew Hall, a professor of political economy at Stanford Graduate School of Business—who published a May paper finding that "Americans view responses from certain popular AI models as being slanted to the left"—told CNN that "tech companies may have put extra guardrails in place to prevent their chatbots from producing content that could be deemed offensive."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Markey seemed to agree, writing that Republicans' "selective outrage matches conservatives’ similar refusal to acknowledge that the Big Tech platforms suspend or impose other penalties disproportionately on conservative users because those users are disproportionately likely to share misinformation, rather than due to any political bias by the platforms."&lt;/p&gt;
&lt;p&gt;It remains unclear what amount of supposed bias detected in outputs could cause a contract bid to be rejected or an ongoing contract to be canceled, but AI companies will likely be on the hook to pay any fees in terminating contracts.&lt;/p&gt;
&lt;p&gt;Complying with Trump's order could pose a struggle for AI makers for several reasons. First, they'll have to determine what's fact and what's ideology, contending with conflicting government standards in how Trump defines DEI. For example, the president's order counts among "pervasive and destructive" DEI ideologies any outputs that align with long-standing federal protections against discrimination on the basis of race or sex. In addition, they must figure out what counts as "suppression or distortion of factual information about" historical topics like critical race theory, systemic racism, or transgenderism.&lt;/p&gt;
&lt;p&gt;The examples in Trump's order highlighting outputs offensive to conservatives seem inconsequential. He calls out image generators depicting the Pope, the Founding Fathers, and Vikings as not white as problematic, as well as models refusing to misgender a person "even if necessary to stop a nuclear apocalypse" or show white people celebrating their achievements.&lt;/p&gt;
&lt;p&gt;It's hard to imagine how these kinds of flawed outputs could impact government processes, as compared to, say, government contracts granted to models that could be hiding covert racism or sexism.&lt;/p&gt;
&lt;p&gt;So far, there has been one example of an AI model displaying a right-wing bias earning a government contract with no red flags raised about its outputs.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Earlier this summer, Grok shocked the world after Musk announced he would be updating the bot to eliminate a supposed liberal bias. The unhinged chatbot began spouting offensive outputs, including antisemitic posts that praised Hitler as well as proclaiming itself "MechaHitler."&lt;/p&gt;
&lt;p&gt;But those obvious biases did not conflict with the Pentagon's decision to grant xAI a $200 million federal contract. In a statement, a Pentagon spokesperson insisted that "the antisemitism episode wasn’t enough to disqualify" xAI, NBC News reported, partly since "several frontier AI models have produced questionable outputs."&lt;/p&gt;
&lt;p&gt;The Pentagon's statement suggested that the government expected to deal with such risks while seizing the opportunity of rapidly deploying emerging AI technology into government prototype processes. And perhaps notably, Trump provides a carveout for any agencies using AI models to safeguard national security, which could exclude the Pentagon from experiencing any "anti-woke" delays in accessing frontier models.&lt;/p&gt;
&lt;p&gt;But that won't help other agencies that must figure out how to assess models to meet anti-woke AI requirements over the next few months. And those assessments could cause delays that Trump may wish to avoid in pushing for widespread AI adoption across government.&lt;/p&gt;
&lt;h2&gt;Trump’s anti-woke AI agenda may be impossible&lt;/h2&gt;
&lt;p&gt;On the same day that Trump issued his anti-woke AI order, his AI Action Plan promised an AI "renaissance" fueling "intellectual achievements" by "unraveling ancient scrolls once thought unreadable, making breakthroughs in scientific and mathematical theory, and creating new kinds of digital and physical art."&lt;/p&gt;
&lt;p&gt;To achieve that, the US must "innovate faster and more comprehensively than our competitors" and eliminate regulatory barriers impeding innovation in order to "set the gold standard for AI worldwide."&lt;/p&gt;
&lt;p&gt;However, achieving the anti-woke ambitions of both orders raises a technical problem that even the president must accept currently has no solution. In his AI Action Plan, Trump acknowledged that "the inner workings of frontier AI systems are poorly understood," with even "advanced technologists" unable to explain "why a model produced a specific output."&lt;/p&gt;
&lt;p&gt;Whether requiring AI companies to explain their AI outputs to win government contracts will mess with other parts of Trump's action plan remains to be seen. But Samir Jain, vice president of policy at a civil liberties group called the Center for Democracy and Technology, told the NYT that he predicts the anti-woke AI agenda will set "a really vague standard that’s going to be impossible for providers to meet."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Trump plans to use chatbots to eliminate dissent, senator alleged.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2226709730-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2226709730-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Donald Trump speaks during the "Winning the AI Race" summit.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Chip Somodevilla / Staff | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;The CEOs of every major artificial intelligence company received letters Wednesday urging them to fight Donald Trump's anti-woke AI order.&lt;/p&gt;
&lt;p&gt;Trump's executive order requires any AI company hoping to contract with the federal government to jump through two hoops to win funding. First, they must prove their AI systems are "truth-seeking"—with outputs based on "historical accuracy, scientific inquiry, and objectivity" or else acknowledge when facts are uncertain. Second, they must train AI models to be "neutral," which is vaguely defined as not favoring DEI (diversity, equity, and inclusion), "dogmas," or otherwise being "intentionally encoded" to produce "partisan or ideological judgments" in outputs "unless those judgments are prompted by or otherwise readily accessible to the end user."&lt;/p&gt;
&lt;p&gt;Announcing the order in a speech, Trump said that the US winning the AI race depended on removing allegedly liberal biases, proclaiming that "once and for all, we are getting rid of woke."&lt;/p&gt;
&lt;p&gt;"The American people do not want woke Marxist lunacy in the AI models, and neither do other countries," Trump said.&lt;/p&gt;
&lt;p&gt;Senator Ed Markey (D.-Mass.) accused Republicans of basing their policies on feelings, not facts, joining critics who suggest that AI isn't "woke" just because of a few "anecdotal" outputs that reflect a liberal bias. And he suggested it was hypocritical that Trump's order "ignores even more egregious evidence" that contradicts claims that AI is trained to be woke, such as xAI's Elon Musk explicitly confirming that Grok was trained to be more right-wing.&lt;/p&gt;
&lt;p&gt;"On May 1, 2025, Grok—the AI chatbot developed by xAI, Elon Musk’s AI company—acknowledged that ‘xAI tried to train me to appeal to the right,’" Markey wrote in his letters to tech giants. "If OpenAI’s ChatGPT or Google’s Gemini had responded that it was trained to appeal to the left, congressional Republicans would have been outraged and opened an investigation. Instead, they were silent.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;He warned the heads of Alphabet, Anthropic, Meta, Microsoft, OpenAI, and xAI that Trump's AI agenda was allegedly "an authoritarian power grab" intended to "eliminate dissent" and was both "dangerous" and "patently unconstitutional."&lt;/p&gt;
&lt;p&gt;Even if companies' AI models are clearly biased, Markey argued that "Republicans are using state power to pressure private companies to adopt certain political viewpoints," which he claimed is a clear violation of the First Amendment. If AI makers cave, Markey warned, they'd be allowing Trump to create "significant financial incentives" to ensure that "their AI chatbots do not produce speech that would upset the Trump administration."&lt;/p&gt;
&lt;p&gt;"This type of interference with private speech is precisely why the US Constitution has a First Amendment," Markey wrote, while claiming that Trump's order is factually baseless.&lt;/p&gt;
&lt;p&gt;It's "based on the erroneous belief that today’s AI chatbots are 'woke' and biased against Trump," Markey said, urging companies "to fight this unconstitutional executive order and not become a pawn in Trump’s effort to eliminate dissent in this country."&lt;/p&gt;
&lt;h2&gt;One big reason AI companies may fight order&lt;/h2&gt;
&lt;p&gt;Some experts agreed with Markey that Trump's order was likely unconstitutional or otherwise unlawful, The New York Times reported.&lt;/p&gt;
&lt;p&gt;For example, Trump may struggle to convince courts that the government isn't impermissibly interfering with AI companies' protected speech or that such interference may be necessary to ensure federal procurement of unbiased AI systems.&lt;/p&gt;
&lt;p&gt;Genevieve Lakier, a law professor at the University of Chicago, told the NYT that the lack of clarity around what makes a model biased could be a problem. Courts could deem the order an act of "unconstitutional jawboning," with the Trump administration and Republicans generally perceived as using legal threats to pressure private companies into producing outputs that they like.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Lakier suggested that AI companies may be so motivated to win government contracts or intimidated by possible retaliation from Trump that they may not even challenge the order, though.&lt;/p&gt;
&lt;p&gt;Markey is hoping that AI companies will refuse to comply with the order; however, despite recognizing that it places companies "in a difficult position: Either stand on your principles and face the wrath of the Trump administration or cave to Trump and modify your company’s political speech."&lt;/p&gt;
&lt;p&gt;There is one big possible reason that AI companies may have to resist, though.&lt;/p&gt;
&lt;p&gt;Oren Etzioni, the former CEO of the AI research nonprofit Allen Institute for Artificial Intelligence, told CNN that Trump's anti-woke AI order may contradict the top priority of his AI Action Plan—speeding up AI innovation in the US—and actually threaten to hamper innovation.&lt;/p&gt;
&lt;p&gt;If AI developers struggle to produce what the Trump administration considers "neutral" outputs—a technical challenge that experts agree is not straightforward—that could delay model advancements.&lt;/p&gt;
&lt;p&gt;"This type of thing… creates all kinds of concerns and liability and complexity for the people developing these models—all of a sudden, they have to slow down," Etzioni told CNN.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Senator: Grok scandal spotlights GOP hypocrisy&lt;/h2&gt;
&lt;p&gt;Some experts have suggested that rather than chatbots adopting liberal viewpoints, chatbots are instead possibly filtering out conservative misinformation and unintentionally appearing to favor liberal views.&lt;/p&gt;
&lt;p&gt;Andrew Hall, a professor of political economy at Stanford Graduate School of Business—who published a May paper finding that "Americans view responses from certain popular AI models as being slanted to the left"—told CNN that "tech companies may have put extra guardrails in place to prevent their chatbots from producing content that could be deemed offensive."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Markey seemed to agree, writing that Republicans' "selective outrage matches conservatives’ similar refusal to acknowledge that the Big Tech platforms suspend or impose other penalties disproportionately on conservative users because those users are disproportionately likely to share misinformation, rather than due to any political bias by the platforms."&lt;/p&gt;
&lt;p&gt;It remains unclear what amount of supposed bias detected in outputs could cause a contract bid to be rejected or an ongoing contract to be canceled, but AI companies will likely be on the hook to pay any fees in terminating contracts.&lt;/p&gt;
&lt;p&gt;Complying with Trump's order could pose a struggle for AI makers for several reasons. First, they'll have to determine what's fact and what's ideology, contending with conflicting government standards in how Trump defines DEI. For example, the president's order counts among "pervasive and destructive" DEI ideologies any outputs that align with long-standing federal protections against discrimination on the basis of race or sex. In addition, they must figure out what counts as "suppression or distortion of factual information about" historical topics like critical race theory, systemic racism, or transgenderism.&lt;/p&gt;
&lt;p&gt;The examples in Trump's order highlighting outputs offensive to conservatives seem inconsequential. He calls out image generators depicting the Pope, the Founding Fathers, and Vikings as not white as problematic, as well as models refusing to misgender a person "even if necessary to stop a nuclear apocalypse" or show white people celebrating their achievements.&lt;/p&gt;
&lt;p&gt;It's hard to imagine how these kinds of flawed outputs could impact government processes, as compared to, say, government contracts granted to models that could be hiding covert racism or sexism.&lt;/p&gt;
&lt;p&gt;So far, there has been one example of an AI model displaying a right-wing bias earning a government contract with no red flags raised about its outputs.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Earlier this summer, Grok shocked the world after Musk announced he would be updating the bot to eliminate a supposed liberal bias. The unhinged chatbot began spouting offensive outputs, including antisemitic posts that praised Hitler as well as proclaiming itself "MechaHitler."&lt;/p&gt;
&lt;p&gt;But those obvious biases did not conflict with the Pentagon's decision to grant xAI a $200 million federal contract. In a statement, a Pentagon spokesperson insisted that "the antisemitism episode wasn’t enough to disqualify" xAI, NBC News reported, partly since "several frontier AI models have produced questionable outputs."&lt;/p&gt;
&lt;p&gt;The Pentagon's statement suggested that the government expected to deal with such risks while seizing the opportunity of rapidly deploying emerging AI technology into government prototype processes. And perhaps notably, Trump provides a carveout for any agencies using AI models to safeguard national security, which could exclude the Pentagon from experiencing any "anti-woke" delays in accessing frontier models.&lt;/p&gt;
&lt;p&gt;But that won't help other agencies that must figure out how to assess models to meet anti-woke AI requirements over the next few months. And those assessments could cause delays that Trump may wish to avoid in pushing for widespread AI adoption across government.&lt;/p&gt;
&lt;h2&gt;Trump’s anti-woke AI agenda may be impossible&lt;/h2&gt;
&lt;p&gt;On the same day that Trump issued his anti-woke AI order, his AI Action Plan promised an AI "renaissance" fueling "intellectual achievements" by "unraveling ancient scrolls once thought unreadable, making breakthroughs in scientific and mathematical theory, and creating new kinds of digital and physical art."&lt;/p&gt;
&lt;p&gt;To achieve that, the US must "innovate faster and more comprehensively than our competitors" and eliminate regulatory barriers impeding innovation in order to "set the gold standard for AI worldwide."&lt;/p&gt;
&lt;p&gt;However, achieving the anti-woke ambitions of both orders raises a technical problem that even the president must accept currently has no solution. In his AI Action Plan, Trump acknowledged that "the inner workings of frontier AI systems are poorly understood," with even "advanced technologists" unable to explain "why a model produced a specific output."&lt;/p&gt;
&lt;p&gt;Whether requiring AI companies to explain their AI outputs to win government contracts will mess with other parts of Trump's action plan remains to be seen. But Samir Jain, vice president of policy at a civil liberties group called the Center for Democracy and Technology, told the NYT that he predicts the anti-woke AI agenda will set "a really vague standard that’s going to be impossible for providers to meet."&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/gop-ignores-groks-right-wing-bias-in-anti-woke-chatbot-fight-democrat-claims/</guid><pubDate>Thu, 24 Jul 2025 18:21:52 +0000</pubDate></item><item><title>[NEW] This industrial AI startup is winning over customers by saying it won’t get acquired (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/24/this-industrial-ai-startup-is-winning-over-customers-by-saying-it-wont-get-acquired/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/cvector.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When industrial AI startup CVector meets with manufacturers, utility providers, and other prospective customers, the founders are often asked the same question: Will you still be here in six months? A year?&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a valid concern in an environment where the biggest, richest tech companies are luring top talent with eye-watering salaries and increasingly targeting rising AI startups with elaborate acqui-hire deals.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The answer that CVector founders Richard Zhang and Tyler Ruggles give every time is also the same: They’re not going anywhere.&amp;nbsp;And that matters to their customers — a list that includes national gas utilities and a chemical manufacturer in California — which use CVector software to manage and improve their industrial operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we talk to some of these big players in a critical infrastructure, the first call, 10 minutes in, like 99% of the time we’re gonna get that question,” Zhang told TechCrunch. “And they want real assurances, right?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This common concern is one reason why CVector worked with Schematic Ventures, which just led a $1.5 million pre-seed round for the startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zhang said he wanted to bring on investors that have a reputation for working on these kinds of hard problems in supply chain, manufacturing, and software infrastructure, which is exactly what Schematic is focused on as an early-stage fund.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Julian Counihan, the Schematic partner who made the investment, told TechCrunch that there are a few ways startups can try to allay these kinds of concerns for customers. There are practical solutions — say, putting code in escrow, or offering a free, perpetual license to the software if an acquisition happens. But sometimes “it comes down to founders being mission-aligned with the company and clearly communicating that long-term commitment to customers,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It’s this commitment that seems to be helping CVector find early success.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zhang and Ruggles each bring unique skills that play well with the type of work CVector provides its customers. One of Zhang’s earliest jobs was working as a software engineer for oil giant Shell, where he said he was often in the field “building iPad apps for people who’ve never used an iPad before.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ruggles, who has a PhD in experimental particle physics, spent time working at the Large Hadron Collider “working with nanosecond data, trying to ensure very high uptime, being held accountable for downtime and rapidly troubleshooting.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Those are places where you get to build up that kind of confidence, and that kind of background really helps give people some trust, some confidence in you,” Ruggles said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CVector is more than just its founders’ résumés, though. The company has also been clever and resourceful since getting off the ground in late 2024. It built its industrial AI software architecture — what it refers to as a “brain and nervous system for industrial assets” — by leveraging everything from fintech solutions to real-time energy pricing data to open source software from the McLaren F1 racing team.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;They’re also taking different approaches on how to shape this brain and nervous system in real time with its customers. One example Zhang gave is with weather data.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Changing weather conditions can have an impact on how high-precision manufacturing equipment works on a macro scale, but there are also knock-on effects to consider, he said. If it snows, that might mean the surrounding roads and parking lots get salted. If that salt gets carried into a factory on workers’ boots, it can have a tangible impact on the high-precision equipment that operators might not have previously noticed or been able to explain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Bringing those kinds of signals into your operations and your planning is incredibly valuable,” Ruggles said. “All of this is to help run these facilities more successfully, more profitably.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CVector has already deployed its industrial AI agents in sectors like chemicals, automotive, and energy, and has its eyes set on what Zhang refers to as “large-scale critical infrastructure.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With energy providers specifically, Zhang said a common problem is that their grid dispatch systems are written in old coding languages like Cobra and Fortran that make real-time management challenging. CVector is able to create algorithms that can sit on top of those old systems and give operators better visibility into these systems with low latency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CVector is small right now, with just an eight-person team distributed across Providence, Rhode Island, New York City, and Frankfurt, Germany. But they expect to grow now that the pre-seed is complete. Zhang did stress they’re recruiting only “mission-aligned people” who “actually want to make a career in physical infrastructure” — which will continue to make it easier to convince customers that the startup isn’t going anywhere.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While there’s a fairly straight line from what Zhang was doing at Shell to what CVector is up to now, it’s a bit more of a departure for Ruggles. But he said it’s been a challenge that he’s relished.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I love the fact that instead of trying to write a paper, submit it, get it through the peer review process and get it published in a journal and hope that somebody looks at it, that I’m working with a client on something that’s in the ground and that we could be helping them keep it up and running,” he said. “You can make changes, build up features, and build new stuff for your customers — rapidly.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/cvector.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When industrial AI startup CVector meets with manufacturers, utility providers, and other prospective customers, the founders are often asked the same question: Will you still be here in six months? A year?&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a valid concern in an environment where the biggest, richest tech companies are luring top talent with eye-watering salaries and increasingly targeting rising AI startups with elaborate acqui-hire deals.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The answer that CVector founders Richard Zhang and Tyler Ruggles give every time is also the same: They’re not going anywhere.&amp;nbsp;And that matters to their customers — a list that includes national gas utilities and a chemical manufacturer in California — which use CVector software to manage and improve their industrial operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“When we talk to some of these big players in a critical infrastructure, the first call, 10 minutes in, like 99% of the time we’re gonna get that question,” Zhang told TechCrunch. “And they want real assurances, right?”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This common concern is one reason why CVector worked with Schematic Ventures, which just led a $1.5 million pre-seed round for the startup.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zhang said he wanted to bring on investors that have a reputation for working on these kinds of hard problems in supply chain, manufacturing, and software infrastructure, which is exactly what Schematic is focused on as an early-stage fund.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Julian Counihan, the Schematic partner who made the investment, told TechCrunch that there are a few ways startups can try to allay these kinds of concerns for customers. There are practical solutions — say, putting code in escrow, or offering a free, perpetual license to the software if an acquisition happens. But sometimes “it comes down to founders being mission-aligned with the company and clearly communicating that long-term commitment to customers,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;It’s this commitment that seems to be helping CVector find early success.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zhang and Ruggles each bring unique skills that play well with the type of work CVector provides its customers. One of Zhang’s earliest jobs was working as a software engineer for oil giant Shell, where he said he was often in the field “building iPad apps for people who’ve never used an iPad before.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ruggles, who has a PhD in experimental particle physics, spent time working at the Large Hadron Collider “working with nanosecond data, trying to ensure very high uptime, being held accountable for downtime and rapidly troubleshooting.”&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Those are places where you get to build up that kind of confidence, and that kind of background really helps give people some trust, some confidence in you,” Ruggles said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CVector is more than just its founders’ résumés, though. The company has also been clever and resourceful since getting off the ground in late 2024. It built its industrial AI software architecture — what it refers to as a “brain and nervous system for industrial assets” — by leveraging everything from fintech solutions to real-time energy pricing data to open source software from the McLaren F1 racing team.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;They’re also taking different approaches on how to shape this brain and nervous system in real time with its customers. One example Zhang gave is with weather data.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Changing weather conditions can have an impact on how high-precision manufacturing equipment works on a macro scale, but there are also knock-on effects to consider, he said. If it snows, that might mean the surrounding roads and parking lots get salted. If that salt gets carried into a factory on workers’ boots, it can have a tangible impact on the high-precision equipment that operators might not have previously noticed or been able to explain.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Bringing those kinds of signals into your operations and your planning is incredibly valuable,” Ruggles said. “All of this is to help run these facilities more successfully, more profitably.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CVector has already deployed its industrial AI agents in sectors like chemicals, automotive, and energy, and has its eyes set on what Zhang refers to as “large-scale critical infrastructure.”&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With energy providers specifically, Zhang said a common problem is that their grid dispatch systems are written in old coding languages like Cobra and Fortran that make real-time management challenging. CVector is able to create algorithms that can sit on top of those old systems and give operators better visibility into these systems with low latency.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;CVector is small right now, with just an eight-person team distributed across Providence, Rhode Island, New York City, and Frankfurt, Germany. But they expect to grow now that the pre-seed is complete. Zhang did stress they’re recruiting only “mission-aligned people” who “actually want to make a career in physical infrastructure” — which will continue to make it easier to convince customers that the startup isn’t going anywhere.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While there’s a fairly straight line from what Zhang was doing at Shell to what CVector is up to now, it’s a bit more of a departure for Ruggles. But he said it’s been a challenge that he’s relished.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I love the fact that instead of trying to write a paper, submit it, get it through the peer review process and get it published in a journal and hope that somebody looks at it, that I’m working with a client on something that’s in the ground and that we could be helping them keep it up and running,” he said. “You can make changes, build up features, and build new stuff for your customers — rapidly.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/24/this-industrial-ai-startup-is-winning-over-customers-by-saying-it-wont-get-acquired/</guid><pubDate>Thu, 24 Jul 2025 18:37:47 +0000</pubDate></item><item><title>[NEW] Chime backer Lauren Kolodny bets on AI to revolutionize estate processing (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/24/chime-backer-lauren-kolodny-bets-on-ai-to-revolutionize-estate-processing/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/12/lauren-kolodny.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Lauren Kolodny, a partner at Acrew Capital, has always championed technology’s power to democratize access to financial services for everyday people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When the fledgling neobank Chime struggled to convince investors in 2016 that it could build a large business serving the working class, Kolodny was the only VC out of 100 Chime pitched who agreed to back the company, stepping in with a $9 million Series A extension when it was nearly out of money.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That bet paid off big time. Last month, Chime went public at a $14.5 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kolodny, who appeared on the Forbes Midas List three years in a row, is still passionate about investing in tech solutions that help consumers maximize their resources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She recently led a $20 million Series A investment in Alix, a startup that leverages AI to automate the estate settlement process.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alix’s founder, Alexandra Mysoor, realized the burden of executing a family estate after she offered to help her best friend settle her late mother’s affairs. Mysoor told TechCrunch that it took her 900 hours and 18 months to complete tasks such as calling the bank to transfer assets, locating all the 401(k)s, canceling accounts, and distributing assets among family members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was shocked that this process was so hard,” Mysoor said. “It’s paper-driven. It’s archaic. You’re googling to-do lists that are not helpful. You’re calling attorneys who might do a sliver of the work, and they cost thousands and thousands of dollars.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That experience gave Mysoor the idea that some of the most labor-intensive aspects of trust administration, including scanning and extracting data from documents, pre-populating complex forms, and communications with banks, can now be handled by AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When Kolodny met Mysoor and learned about the problem Alix was addressing, the issue resonated so deeply with the Midas List investor that she couldn’t get it out of her mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kolodny realized that even though economists are estimating that trillions of dollars will transfer to millennial and Gen Z generations over the next two decades, the paperwork surrounding estate settlement largely remains a burden on those grieving the loss of their parents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While some startups like Empathy provide assistance with closing accounts as part of their bereavement support, Kolodny discovered that no companies offered comprehensive, start-to-finish estate settlement services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“How is it possible that there’s this messy problem that involves so much project management that there aren’t even meaningful services around?” Kolodny told TechCrunch. “It was this real aha moment for me. This is exactly the kind of problem that AI should be solving.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kolodny said that she believes Alix is among the first of many startups powered by AI that will democratize financial services and administrative processes, which were historically available only to the ultra-wealthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alix’s fee structure is 1% of an estate’s value. However, for inheritances under $1 million, customers can expect to pay between $9,000 and $12,000, with the exact cost determined by the complexity of the estate.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2017/12/lauren-kolodny.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Lauren Kolodny, a partner at Acrew Capital, has always championed technology’s power to democratize access to financial services for everyday people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When the fledgling neobank Chime struggled to convince investors in 2016 that it could build a large business serving the working class, Kolodny was the only VC out of 100 Chime pitched who agreed to back the company, stepping in with a $9 million Series A extension when it was nearly out of money.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;That bet paid off big time. Last month, Chime went public at a $14.5 billion valuation.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kolodny, who appeared on the Forbes Midas List three years in a row, is still passionate about investing in tech solutions that help consumers maximize their resources.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;She recently led a $20 million Series A investment in Alix, a startup that leverages AI to automate the estate settlement process.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alix’s founder, Alexandra Mysoor, realized the burden of executing a family estate after she offered to help her best friend settle her late mother’s affairs. Mysoor told TechCrunch that it took her 900 hours and 18 months to complete tasks such as calling the bank to transfer assets, locating all the 401(k)s, canceling accounts, and distributing assets among family members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I was shocked that this process was so hard,” Mysoor said. “It’s paper-driven. It’s archaic. You’re googling to-do lists that are not helpful. You’re calling attorneys who might do a sliver of the work, and they cost thousands and thousands of dollars.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;That experience gave Mysoor the idea that some of the most labor-intensive aspects of trust administration, including scanning and extracting data from documents, pre-populating complex forms, and communications with banks, can now be handled by AI agents.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When Kolodny met Mysoor and learned about the problem Alix was addressing, the issue resonated so deeply with the Midas List investor that she couldn’t get it out of her mind.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kolodny realized that even though economists are estimating that trillions of dollars will transfer to millennial and Gen Z generations over the next two decades, the paperwork surrounding estate settlement largely remains a burden on those grieving the loss of their parents.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While some startups like Empathy provide assistance with closing accounts as part of their bereavement support, Kolodny discovered that no companies offered comprehensive, start-to-finish estate settlement services.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“How is it possible that there’s this messy problem that involves so much project management that there aren’t even meaningful services around?” Kolodny told TechCrunch. “It was this real aha moment for me. This is exactly the kind of problem that AI should be solving.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Kolodny said that she believes Alix is among the first of many startups powered by AI that will democratize financial services and administrative processes, which were historically available only to the ultra-wealthy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Alix’s fee structure is 1% of an estate’s value. However, for inheritances under $1 million, customers can expect to pay between $9,000 and $12,000, with the exact cost determined by the complexity of the estate.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/24/chime-backer-lauren-kolodny-bets-on-ai-to-revolutionize-estate-processing/</guid><pubDate>Thu, 24 Jul 2025 18:57:03 +0000</pubDate></item><item><title>[NEW] America’s AI watchdog is losing its bite (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/24/1120645/americas-ai-watchdog-is-losing-its-bite/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_FTC_tease.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Most Americans encounter the Federal Trade Commission only if they’ve been scammed: It handles identity theft, fraud, and stolen data. During the Biden administration, the agency went after AI companies for scamming customers with deceptive advertising or harming people by selling irresponsible technologies. With yesterday’s announcement of President Trump’s AI Action Plan, that era may now be over.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In the final months of the Biden administration under chair Lina Khan, the FTC levied a series of high-profile fines and actions against AI companies for overhyping their technology and bending the truth—or in some cases making claims that were entirely false.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It found that the security giant Evolv lied about the accuracy of its AI-powered security checkpoints, which are used in stadiums and schools but failed to catch a seven-inch knife that was ultimately used to stab a student. It went after the facial recognition company Intellivision, saying the company made unfounded claims that its tools operated without gender or racial bias. It fined startups promising bogus “AI lawyer” services and one that sold fake product reviews generated with AI.&lt;/p&gt;  &lt;p&gt;These actions did not result in fines that crippled the companies, but they did stop them from making false statements and offered customers ways to recover their money or get out of contracts. In each case, the FTC found, everyday people had been harmed by AI companies that let their technologies run amok.&lt;/p&gt; 
 &lt;p&gt;The plan released by the Trump administration yesterday suggests it believes these actions went too far. In a section about removing “red tape and onerous regulation,” the White House says it will review all FTC actions taken under the Biden administration “to ensure that they do not advance theories of liability that unduly burden AI innovation.” In the same section, the White House says it will withhold AI-related federal funding from states with “burdensome” regulations.&lt;/p&gt;  &lt;p&gt;This move by the Trump administration is the latest in its evolving attack on the agency, which provides a significant route of redress for people harmed by AI in the US. It’s likely to result in faster deployment of AI with fewer checks on accuracy, fairness, or consumer harm.&lt;/p&gt; 
 &lt;p&gt;Under Khan, a Biden appointee, the FTC found fans in unexpected places. Progressives called for it to break up monopolistic behavior in Big Tech, but some in Trump’s orbit, including Vice President JD Vance, also supported Khan in her fights against tech elites, albeit for the different goal of ending their supposed censorship of conservative speech.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But in January, with Khan out and Trump back in the White House, this dynamic all but collapsed. Trump released an executive order in February promising to “rein in” independent agencies like the FTC that wage influence without consulting the president. The next month, he started taking that vow to—and past—its legal limits.&lt;/p&gt;  &lt;p&gt;In March, he fired the only two Democratic commissioners at the FTC. On July 17 a federal court ruled that one of those firings, of commissioner Rebecca Slaughter, was illegal given the independence of the agency, which restored Slaughter to her position (the other fired commissioner, Alvaro Bedoya, opted to resign rather than battle the dismissal in court, so his case was dismissed). Slaughter now serves as the sole Democrat.&lt;/p&gt;  &lt;p&gt;In naming the FTC in its action plan, the White House now goes a step further, painting the agency's actions as a major obstacle to US victory in the “arms race” to develop better AI more quickly than China. It promises not just to change the agency’s tack moving forward, but to review and perhaps even repeal AI-related sanctions it has imposed in the past four years.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;How might this play out? Leah Frazier, who worked at the FTC for 17 years before leaving in May and served as an advisor to Khan, says it’s helpful to think about the agency’s actions against AI companies as falling into two areas, each with very different levels of support across political lines.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The first is about cases of deception, where AI companies mislead consumers. Consider the case of Evolv, or a recent case announced in April where the FTC alleges that a company called Workado, which offers a tool to detect whether something was written with AI, doesn’t have the evidence to back up its claims. Deception cases enjoyed fairly bipartisan support during her tenure, Frazier says.&lt;/p&gt;  &lt;p&gt;“Then there are cases about responsible use of AI, and those did not seem to enjoy too much popular support,” adds Frazier, who now directs the Digital Justice Initiative at the Lawyers’ Committee for Civil Rights Under Law. These cases don’t allege deception; rather, they charge that companies have deployed AI in a way that harms people.&lt;/p&gt;  &lt;p&gt;The most serious of these, which resulted in perhaps the most significant AI-related action ever taken by the FTC and was investigated by Frazier, was announced in 2023. The FTC banned Rite Aid from using AI facial recognition in its stores after it found the technology falsely flagged people, particularly women and people of color, as shoplifters. “Acting on false positive alerts,” the FTC wrote, Rite Aid’s employees “followed consumers around its stores, searched them, ordered them to leave, [and] called the police to confront or remove consumers.”&lt;/p&gt; 

 &lt;p&gt;The FTC found that Rite Aid failed to protect people from these mistakes, did not monitor or test the technology, and did not properly train employees on how to use it. The company was banned from using facial recognition for five years.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This was a big deal. This action went beyond fact-checking the deceptive promises made by AI companies to make Rite Aid liable for how its AI technology harmed consumers. These types of responsible-AI cases are the ones Frazier imagines might disappear in the new FTC, particularly if they involve testing AI models for bias.&lt;/p&gt;  &lt;p&gt;“There will be fewer, if any, enforcement actions about how companies are deploying AI,” she says. The White House’s broader philosophy toward AI, referred to in the plan, is a “try first” approach that attempts to propel faster AI adoption everywhere from the Pentagon to doctor's offices. The lack of FTC enforcement that is likely to ensue, Frazier says, “is dangerous for the public.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/250724_FTC_tease.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Most Americans encounter the Federal Trade Commission only if they’ve been scammed: It handles identity theft, fraud, and stolen data. During the Biden administration, the agency went after AI companies for scamming customers with deceptive advertising or harming people by selling irresponsible technologies. With yesterday’s announcement of President Trump’s AI Action Plan, that era may now be over.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;In the final months of the Biden administration under chair Lina Khan, the FTC levied a series of high-profile fines and actions against AI companies for overhyping their technology and bending the truth—or in some cases making claims that were entirely false.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;It found that the security giant Evolv lied about the accuracy of its AI-powered security checkpoints, which are used in stadiums and schools but failed to catch a seven-inch knife that was ultimately used to stab a student. It went after the facial recognition company Intellivision, saying the company made unfounded claims that its tools operated without gender or racial bias. It fined startups promising bogus “AI lawyer” services and one that sold fake product reviews generated with AI.&lt;/p&gt;  &lt;p&gt;These actions did not result in fines that crippled the companies, but they did stop them from making false statements and offered customers ways to recover their money or get out of contracts. In each case, the FTC found, everyday people had been harmed by AI companies that let their technologies run amok.&lt;/p&gt; 
 &lt;p&gt;The plan released by the Trump administration yesterday suggests it believes these actions went too far. In a section about removing “red tape and onerous regulation,” the White House says it will review all FTC actions taken under the Biden administration “to ensure that they do not advance theories of liability that unduly burden AI innovation.” In the same section, the White House says it will withhold AI-related federal funding from states with “burdensome” regulations.&lt;/p&gt;  &lt;p&gt;This move by the Trump administration is the latest in its evolving attack on the agency, which provides a significant route of redress for people harmed by AI in the US. It’s likely to result in faster deployment of AI with fewer checks on accuracy, fairness, or consumer harm.&lt;/p&gt; 
 &lt;p&gt;Under Khan, a Biden appointee, the FTC found fans in unexpected places. Progressives called for it to break up monopolistic behavior in Big Tech, but some in Trump’s orbit, including Vice President JD Vance, also supported Khan in her fights against tech elites, albeit for the different goal of ending their supposed censorship of conservative speech.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;But in January, with Khan out and Trump back in the White House, this dynamic all but collapsed. Trump released an executive order in February promising to “rein in” independent agencies like the FTC that wage influence without consulting the president. The next month, he started taking that vow to—and past—its legal limits.&lt;/p&gt;  &lt;p&gt;In March, he fired the only two Democratic commissioners at the FTC. On July 17 a federal court ruled that one of those firings, of commissioner Rebecca Slaughter, was illegal given the independence of the agency, which restored Slaughter to her position (the other fired commissioner, Alvaro Bedoya, opted to resign rather than battle the dismissal in court, so his case was dismissed). Slaughter now serves as the sole Democrat.&lt;/p&gt;  &lt;p&gt;In naming the FTC in its action plan, the White House now goes a step further, painting the agency's actions as a major obstacle to US victory in the “arms race” to develop better AI more quickly than China. It promises not just to change the agency’s tack moving forward, but to review and perhaps even repeal AI-related sanctions it has imposed in the past four years.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;How might this play out? Leah Frazier, who worked at the FTC for 17 years before leaving in May and served as an advisor to Khan, says it’s helpful to think about the agency’s actions against AI companies as falling into two areas, each with very different levels of support across political lines.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The first is about cases of deception, where AI companies mislead consumers. Consider the case of Evolv, or a recent case announced in April where the FTC alleges that a company called Workado, which offers a tool to detect whether something was written with AI, doesn’t have the evidence to back up its claims. Deception cases enjoyed fairly bipartisan support during her tenure, Frazier says.&lt;/p&gt;  &lt;p&gt;“Then there are cases about responsible use of AI, and those did not seem to enjoy too much popular support,” adds Frazier, who now directs the Digital Justice Initiative at the Lawyers’ Committee for Civil Rights Under Law. These cases don’t allege deception; rather, they charge that companies have deployed AI in a way that harms people.&lt;/p&gt;  &lt;p&gt;The most serious of these, which resulted in perhaps the most significant AI-related action ever taken by the FTC and was investigated by Frazier, was announced in 2023. The FTC banned Rite Aid from using AI facial recognition in its stores after it found the technology falsely flagged people, particularly women and people of color, as shoplifters. “Acting on false positive alerts,” the FTC wrote, Rite Aid’s employees “followed consumers around its stores, searched them, ordered them to leave, [and] called the police to confront or remove consumers.”&lt;/p&gt; 

 &lt;p&gt;The FTC found that Rite Aid failed to protect people from these mistakes, did not monitor or test the technology, and did not properly train employees on how to use it. The company was banned from using facial recognition for five years.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This was a big deal. This action went beyond fact-checking the deceptive promises made by AI companies to make Rite Aid liable for how its AI technology harmed consumers. These types of responsible-AI cases are the ones Frazier imagines might disappear in the new FTC, particularly if they involve testing AI models for bias.&lt;/p&gt;  &lt;p&gt;“There will be fewer, if any, enforcement actions about how companies are deploying AI,” she says. The White House’s broader philosophy toward AI, referred to in the plan, is a “try first” approach that attempts to propel faster AI adoption everywhere from the Pentagon to doctor's offices. The lack of FTC enforcement that is likely to ensue, Frazier says, “is dangerous for the public.”&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/24/1120645/americas-ai-watchdog-is-losing-its-bite/</guid><pubDate>Thu, 24 Jul 2025 18:59:09 +0000</pubDate></item><item><title>[NEW] Robot, know thyself: New vision-based system teaches machines to understand their bodies (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2025/vision-based-system-teaches-machines-understand-their-bodies-0724</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/njf-mit-csail-00_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-ebea3a61-7fff-ad11-8889-4ee6f72a24bc"&gt;In an office at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL), a soft robotic hand carefully curls its fingers to grasp a small object. The intriguing part isn’t the mechanical design or embedded sensors — in fact, the hand contains none. Instead, the entire system relies on a single camera that watches the robot’s movements and uses that visual data to control it.&lt;/p&gt;&lt;p dir="ltr"&gt;This capability comes from a new system CSAIL scientists developed, offering a different perspective on robotic control. Rather than using hand-designed models or complex sensor arrays, it allows robots to learn how their bodies respond to control commands, solely through vision. The approach, called Neural Jacobian Fields (NJF), gives robots a kind of bodily self-awareness. An open-access paper about the work was published in&amp;nbsp;&lt;em&gt;Nature&lt;/em&gt; on June 25.&lt;/p&gt;&lt;p dir="ltr"&gt;“This work points to a shift from programming robots to teaching robots,” says Sizhe Lester Li, MIT PhD student in electrical engineering and computer science, CSAIL affiliate, and lead researcher on the work. “Today, many robotics tasks require extensive engineering and coding. In the future, we envision showing a robot what to do, and letting it learn how to achieve the goal autonomously.”&lt;/p&gt;&lt;p dir="ltr"&gt;The motivation stems from a simple but powerful reframing: The main barrier to affordable, flexible robotics isn't hardware — it’s control of capability, which could be achieved in multiple ways. Traditional robots are built to be rigid and sensor-rich, making it easier to construct a digital twin, a precise mathematical replica used for control. But when a robot is soft, deformable, or irregularly shaped, those assumptions fall apart. Rather than forcing robots to match our models, NJF flips the script — giving robots the ability to learn their own internal model from observation.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Look and learn&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;This decoupling of modeling and hardware design could significantly expand the design space for robotics. In soft and bio-inspired robots, designers often embed sensors or reinforce parts of the structure just to make modeling feasible. NJF lifts that constraint. The system doesn’t need onboard sensors or design tweaks to make control possible. Designers are freer to explore unconventional, unconstrained morphologies without worrying about whether they’ll be able to model or control them later.&lt;/p&gt;&lt;p dir="ltr"&gt;“Think about how you learn to control your fingers: you wiggle, you observe, you adapt,” says Li. “That’s what our system does. It experiments with random actions and figures out which controls move which parts of the robot.”&lt;/p&gt;&lt;p dir="ltr"&gt;The system has proven robust across a range of robot types. The team tested NJF on a pneumatic soft robotic hand capable of pinching and grasping, a rigid Allegro hand, a 3D-printed robotic arm, and even a rotating platform with no embedded sensors. In every case, the system learned both the robot’s shape and how it responded to control signals, just from vision and random motion.&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers see potential far beyond the lab. Robots equipped with NJF could one day perform agricultural tasks with centimeter-level localization accuracy, operate on construction sites without elaborate sensor arrays, or navigate dynamic environments where traditional methods break down.&lt;/p&gt;&lt;p dir="ltr"&gt;At the core of NJF is a neural network that captures two intertwined aspects of a robot’s embodiment: its three-dimensional geometry and its sensitivity to control inputs. The system builds on neural radiance fields (NeRF), a technique that reconstructs 3D scenes from images by mapping spatial coordinates to color and density values. NJF extends this approach by learning not only the robot’s shape, but also a Jacobian field, a function that predicts how any point on the robot’s body moves in response to motor commands.&lt;/p&gt;&lt;p dir="ltr"&gt;To train the model, the robot performs random motions while multiple cameras record the outcomes. No human supervision or prior knowledge of the robot’s structure is required — the system simply infers the relationship between control signals and motion by watching.&lt;/p&gt;&lt;p dir="ltr"&gt;Once training is complete, the robot only needs a single monocular camera for real-time closed-loop control, running at about 12 Hertz. This allows it to continuously observe itself, plan, and act responsively. That speed makes NJF more viable than many physics-based simulators for soft robots, which are often too computationally intensive for real-time use.&lt;/p&gt;&lt;p dir="ltr"&gt;In early simulations, even simple 2D fingers and sliders were able to learn this mapping using just a few examples. By modeling how specific points deform or shift in response to action, NJF builds a dense map of controllability. That internal model allows it to generalize motion across the robot’s body, even when the data are noisy or incomplete.&lt;/p&gt;&lt;p dir="ltr"&gt;“What’s really interesting is that the system figures out on its own which motors control which parts of the robot,” says Li. “This isn’t programmed — it emerges naturally through learning, much like a person discovering the buttons on a new device.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;The future is soft&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;For decades, robotics has favored rigid, easily modeled machines — like the industrial arms found in factories — because their properties simplify control. But the field has been moving toward soft, bio-inspired robots that can adapt to the real world more fluidly. The trade-off? These robots are harder to model.&lt;/p&gt;&lt;p dir="ltr"&gt;“Robotics today often feels out of reach because of costly sensors and complex programming. Our goal with Neural Jacobian Fields is to lower the barrier, making robotics affordable, adaptable, and accessible to more people. Vision is a resilient, reliable sensor,” says senior author and MIT Assistant Professor Vincent Sitzmann, who leads the Scene Representation group. “It opens the door to robots that can operate in messy, unstructured environments, from farms to construction sites, without expensive infrastructure.”&lt;/p&gt;&lt;p dir="ltr"&gt;“Vision alone can provide the cues needed for localization and control — eliminating the need for GPS, external tracking systems, or complex onboard sensors. This opens the door to robust, adaptive behavior in unstructured environments, from drones navigating indoors or underground without maps to mobile manipulators working in cluttered homes or warehouses, and even legged robots traversing uneven terrain,” says co-author Daniela Rus, MIT professor of electrical engineering and computer science and director of CSAIL. “By learning from visual feedback, these systems develop internal models of their own motion and dynamics, enabling flexible, self-supervised operation where traditional localization methods would fail.”&lt;/p&gt;&lt;p dir="ltr"&gt;While training NJF currently requires multiple cameras and must be redone for each robot, the researchers are already imagining a more accessible version. In the future, hobbyists could record a robot’s random movements with their phone, much like you’d take a video of a rental car before driving off, and use that footage to create a control model, with no prior knowledge or special equipment required.&lt;/p&gt;&lt;p dir="ltr"&gt;The system doesn’t yet generalize across different robots, and it lacks force or tactile sensing, limiting its effectiveness on contact-rich tasks. But the team is exploring new ways to address these limitations: improving generalization, handling occlusions, and extending the model’s ability to reason over longer spatial and temporal horizons.&lt;/p&gt;&lt;p dir="ltr"&gt;“Just as humans develop an intuitive understanding of how their bodies move and respond to commands, NJF gives robots that kind of embodied self-awareness through vision alone,” says Li. “This understanding is a foundation for flexible manipulation and control in real-world environments. Our work, essentially, reflects a broader trend in robotics: moving away from manually programming detailed models toward teaching robots through observation and interaction.”&lt;/p&gt;&lt;p dir="ltr"&gt;This paper brought together the computer vision and self-supervised learning work from the Sitzmann lab and the expertise in soft robots from the Rus lab. Li, Sitzmann, and Rus co-authored the paper with CSAIL affiliates Annan Zhang SM ’22, a PhD student in electrical engineering and computer science (EECS); Boyuan Chen, a PhD student in EECS; Hanna Matusik, an undergraduate researcher in mechanical engineering; and Chao Liu, a postdoc in the Senseable City Lab at MIT.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The research was supported by the Solomon Buchsbaum Research Fund through MIT’s Research Support Committee, an MIT Presidential Fellowship, the National Science Foundation, and the Gwangju Institute of Science and Technology.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202507/njf-mit-csail-00_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p dir="ltr" id="docs-internal-guid-ebea3a61-7fff-ad11-8889-4ee6f72a24bc"&gt;In an office at MIT’s Computer Science and Artificial Intelligence Laboratory (CSAIL), a soft robotic hand carefully curls its fingers to grasp a small object. The intriguing part isn’t the mechanical design or embedded sensors — in fact, the hand contains none. Instead, the entire system relies on a single camera that watches the robot’s movements and uses that visual data to control it.&lt;/p&gt;&lt;p dir="ltr"&gt;This capability comes from a new system CSAIL scientists developed, offering a different perspective on robotic control. Rather than using hand-designed models or complex sensor arrays, it allows robots to learn how their bodies respond to control commands, solely through vision. The approach, called Neural Jacobian Fields (NJF), gives robots a kind of bodily self-awareness. An open-access paper about the work was published in&amp;nbsp;&lt;em&gt;Nature&lt;/em&gt; on June 25.&lt;/p&gt;&lt;p dir="ltr"&gt;“This work points to a shift from programming robots to teaching robots,” says Sizhe Lester Li, MIT PhD student in electrical engineering and computer science, CSAIL affiliate, and lead researcher on the work. “Today, many robotics tasks require extensive engineering and coding. In the future, we envision showing a robot what to do, and letting it learn how to achieve the goal autonomously.”&lt;/p&gt;&lt;p dir="ltr"&gt;The motivation stems from a simple but powerful reframing: The main barrier to affordable, flexible robotics isn't hardware — it’s control of capability, which could be achieved in multiple ways. Traditional robots are built to be rigid and sensor-rich, making it easier to construct a digital twin, a precise mathematical replica used for control. But when a robot is soft, deformable, or irregularly shaped, those assumptions fall apart. Rather than forcing robots to match our models, NJF flips the script — giving robots the ability to learn their own internal model from observation.&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;Look and learn&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;This decoupling of modeling and hardware design could significantly expand the design space for robotics. In soft and bio-inspired robots, designers often embed sensors or reinforce parts of the structure just to make modeling feasible. NJF lifts that constraint. The system doesn’t need onboard sensors or design tweaks to make control possible. Designers are freer to explore unconventional, unconstrained morphologies without worrying about whether they’ll be able to model or control them later.&lt;/p&gt;&lt;p dir="ltr"&gt;“Think about how you learn to control your fingers: you wiggle, you observe, you adapt,” says Li. “That’s what our system does. It experiments with random actions and figures out which controls move which parts of the robot.”&lt;/p&gt;&lt;p dir="ltr"&gt;The system has proven robust across a range of robot types. The team tested NJF on a pneumatic soft robotic hand capable of pinching and grasping, a rigid Allegro hand, a 3D-printed robotic arm, and even a rotating platform with no embedded sensors. In every case, the system learned both the robot’s shape and how it responded to control signals, just from vision and random motion.&lt;/p&gt;&lt;p dir="ltr"&gt;The researchers see potential far beyond the lab. Robots equipped with NJF could one day perform agricultural tasks with centimeter-level localization accuracy, operate on construction sites without elaborate sensor arrays, or navigate dynamic environments where traditional methods break down.&lt;/p&gt;&lt;p dir="ltr"&gt;At the core of NJF is a neural network that captures two intertwined aspects of a robot’s embodiment: its three-dimensional geometry and its sensitivity to control inputs. The system builds on neural radiance fields (NeRF), a technique that reconstructs 3D scenes from images by mapping spatial coordinates to color and density values. NJF extends this approach by learning not only the robot’s shape, but also a Jacobian field, a function that predicts how any point on the robot’s body moves in response to motor commands.&lt;/p&gt;&lt;p dir="ltr"&gt;To train the model, the robot performs random motions while multiple cameras record the outcomes. No human supervision or prior knowledge of the robot’s structure is required — the system simply infers the relationship between control signals and motion by watching.&lt;/p&gt;&lt;p dir="ltr"&gt;Once training is complete, the robot only needs a single monocular camera for real-time closed-loop control, running at about 12 Hertz. This allows it to continuously observe itself, plan, and act responsively. That speed makes NJF more viable than many physics-based simulators for soft robots, which are often too computationally intensive for real-time use.&lt;/p&gt;&lt;p dir="ltr"&gt;In early simulations, even simple 2D fingers and sliders were able to learn this mapping using just a few examples. By modeling how specific points deform or shift in response to action, NJF builds a dense map of controllability. That internal model allows it to generalize motion across the robot’s body, even when the data are noisy or incomplete.&lt;/p&gt;&lt;p dir="ltr"&gt;“What’s really interesting is that the system figures out on its own which motors control which parts of the robot,” says Li. “This isn’t programmed — it emerges naturally through learning, much like a person discovering the buttons on a new device.”&lt;/p&gt;&lt;p dir="ltr"&gt;&lt;strong&gt;The future is soft&lt;/strong&gt;&lt;/p&gt;&lt;p dir="ltr"&gt;For decades, robotics has favored rigid, easily modeled machines — like the industrial arms found in factories — because their properties simplify control. But the field has been moving toward soft, bio-inspired robots that can adapt to the real world more fluidly. The trade-off? These robots are harder to model.&lt;/p&gt;&lt;p dir="ltr"&gt;“Robotics today often feels out of reach because of costly sensors and complex programming. Our goal with Neural Jacobian Fields is to lower the barrier, making robotics affordable, adaptable, and accessible to more people. Vision is a resilient, reliable sensor,” says senior author and MIT Assistant Professor Vincent Sitzmann, who leads the Scene Representation group. “It opens the door to robots that can operate in messy, unstructured environments, from farms to construction sites, without expensive infrastructure.”&lt;/p&gt;&lt;p dir="ltr"&gt;“Vision alone can provide the cues needed for localization and control — eliminating the need for GPS, external tracking systems, or complex onboard sensors. This opens the door to robust, adaptive behavior in unstructured environments, from drones navigating indoors or underground without maps to mobile manipulators working in cluttered homes or warehouses, and even legged robots traversing uneven terrain,” says co-author Daniela Rus, MIT professor of electrical engineering and computer science and director of CSAIL. “By learning from visual feedback, these systems develop internal models of their own motion and dynamics, enabling flexible, self-supervised operation where traditional localization methods would fail.”&lt;/p&gt;&lt;p dir="ltr"&gt;While training NJF currently requires multiple cameras and must be redone for each robot, the researchers are already imagining a more accessible version. In the future, hobbyists could record a robot’s random movements with their phone, much like you’d take a video of a rental car before driving off, and use that footage to create a control model, with no prior knowledge or special equipment required.&lt;/p&gt;&lt;p dir="ltr"&gt;The system doesn’t yet generalize across different robots, and it lacks force or tactile sensing, limiting its effectiveness on contact-rich tasks. But the team is exploring new ways to address these limitations: improving generalization, handling occlusions, and extending the model’s ability to reason over longer spatial and temporal horizons.&lt;/p&gt;&lt;p dir="ltr"&gt;“Just as humans develop an intuitive understanding of how their bodies move and respond to commands, NJF gives robots that kind of embodied self-awareness through vision alone,” says Li. “This understanding is a foundation for flexible manipulation and control in real-world environments. Our work, essentially, reflects a broader trend in robotics: moving away from manually programming detailed models toward teaching robots through observation and interaction.”&lt;/p&gt;&lt;p dir="ltr"&gt;This paper brought together the computer vision and self-supervised learning work from the Sitzmann lab and the expertise in soft robots from the Rus lab. Li, Sitzmann, and Rus co-authored the paper with CSAIL affiliates Annan Zhang SM ’22, a PhD student in electrical engineering and computer science (EECS); Boyuan Chen, a PhD student in EECS; Hanna Matusik, an undergraduate researcher in mechanical engineering; and Chao Liu, a postdoc in the Senseable City Lab at MIT.&amp;nbsp;&lt;/p&gt;&lt;p&gt;The research was supported by the Solomon Buchsbaum Research Fund through MIT’s Research Support Committee, an MIT Presidential Fellowship, the National Science Foundation, and the Gwangju Institute of Science and Technology.&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2025/vision-based-system-teaches-machines-understand-their-bodies-0724</guid><pubDate>Thu, 24 Jul 2025 19:30:00 +0000</pubDate></item><item><title>[NEW] Google’s new “Web Guide” will use AI to organize your search results (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/googles-new-web-guide-will-use-ai-to-organize-your-search-results/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Web Guide experiment is available as an opt-in feature today.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Web Guide" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/Web-Guide-hero-640x361.jpg" width="640" /&gt;
                  &lt;img alt="Web Guide" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/Web-Guide-hero-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Search is changing at a breakneck pace, with Google rolling out new AI features so quickly it can be hard to keep up. So far, these AI implementations are being offered in addition to the traditional search experience. However, Google is now offering a sneak peek at how it may use AI to change the good old-fashioned list of blue links. The company says its new Web Guide feature is being developed to "intelligently organize" the results page, and you can try it now, if you dare.&lt;/p&gt;
&lt;p&gt;Many Google searches today come with an AI Overview right at the top of the page. There's also AI Mode, which does away with the typical list of links in favor of a full chatbot approach. While Google contends that these features enhance the search experience and direct users to good sources, it's been easy to scroll right past the AI and get to the regular list of websites. That may change in the not too distant future, though.&lt;/p&gt;
&lt;p&gt;Google's latest AI experiment, known as Web Guide, uses generative AI to organize the search results page. The company says Web Guide uses a custom version of Gemini to surface the most helpful webpages and organize the page in a more useful way. It uses the same fan-out technique as AI Mode, conducting multiple parallel searches to gather more data on your query.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2108161 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1328" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/web-guide.png" width="1992" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Web Guide is halfway between normal search and AI Mode.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google suggests trying Web Guide with longer or open-ended queries, like "how to solo travel in Japan." The video below uses that search as an example. It has many of the links you might expect, but there are also AI-generated headings with summaries and suggestions. It really looks halfway between standard search and AI Mode. Because it has to run additional searches and generate content, Web Guide takes a beat longer to produce results compared to a standard search. There's no AI Overview at the top, though.&lt;/p&gt;
&lt;p&gt;Web Guide is a Search Labs experiment, meaning you have to opt-in before you'll see any AI organization in your search results. When enabled, this feature takes over the "Web" tab of Google search. Even if you turn it on, Google notes there will be a toggle that allows you to revert to the normal, non-AI-optimized page.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2108152-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/WG_Desktop2_Howtosolotravelinjapan-opt.mp4?_=1" type="video/mp4" /&gt;An example of the Web Guide test.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An example of the Web Guide test.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Eventually, the test will expand to encompass more parts of the search experience, like the "All" tab—that's the default search experience when you input a query from a browser or phone search bar. Google says it's approaching this as an opt-in feature to start. So that sounds like Web Guide might be another AI Mode situation in which the feature rolls out widely after a short testing period. It's technically possible the test will not result in a new universal search feature, but Google hasn't yet met a generative AI implementation that it hasn't liked.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        The Web Guide experiment is available as an opt-in feature today.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Web Guide" class="absolute inset-0 w-full h-full object-cover hidden" height="361" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/Web-Guide-hero-640x361.jpg" width="640" /&gt;
                  &lt;img alt="Web Guide" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/Web-Guide-hero-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Search is changing at a breakneck pace, with Google rolling out new AI features so quickly it can be hard to keep up. So far, these AI implementations are being offered in addition to the traditional search experience. However, Google is now offering a sneak peek at how it may use AI to change the good old-fashioned list of blue links. The company says its new Web Guide feature is being developed to "intelligently organize" the results page, and you can try it now, if you dare.&lt;/p&gt;
&lt;p&gt;Many Google searches today come with an AI Overview right at the top of the page. There's also AI Mode, which does away with the typical list of links in favor of a full chatbot approach. While Google contends that these features enhance the search experience and direct users to good sources, it's been easy to scroll right past the AI and get to the regular list of websites. That may change in the not too distant future, though.&lt;/p&gt;
&lt;p&gt;Google's latest AI experiment, known as Web Guide, uses generative AI to organize the search results page. The company says Web Guide uses a custom version of Gemini to surface the most helpful webpages and organize the page in a more useful way. It uses the same fan-out technique as AI Mode, conducting multiple parallel searches to gather more data on your query.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-wp-img-shortcode id-2108161 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="alt" class="fullwidth full" height="1328" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/web-guide.png" width="1992" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Web Guide is halfway between normal search and AI Mode.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Google suggests trying Web Guide with longer or open-ended queries, like "how to solo travel in Japan." The video below uses that search as an example. It has many of the links you might expect, but there are also AI-generated headings with summaries and suggestions. It really looks halfway between standard search and AI Mode. Because it has to run additional searches and generate content, Web Guide takes a beat longer to produce results compared to a standard search. There's no AI Overview at the top, though.&lt;/p&gt;
&lt;p&gt;Web Guide is a Search Labs experiment, meaning you have to opt-in before you'll see any AI organization in your search results. When enabled, this feature takes over the "Web" tab of Google search. Even if you turn it on, Google notes there will be a toggle that allows you to revert to the normal, non-AI-optimized page.&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2108152-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/WG_Desktop2_Howtosolotravelinjapan-opt.mp4?_=1" type="video/mp4" /&gt;An example of the Web Guide test.&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
    &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An example of the Web Guide test.

          &lt;/div&gt;
  &lt;/div&gt;
  &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Eventually, the test will expand to encompass more parts of the search experience, like the "All" tab—that's the default search experience when you input a query from a browser or phone search bar. Google says it's approaching this as an opt-in feature to start. So that sounds like Web Guide might be another AI Mode situation in which the feature rolls out widely after a short testing period. It's technically possible the test will not result in a new universal search feature, but Google hasn't yet met a generative AI implementation that it hasn't liked.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/googles-new-web-guide-will-use-ai-to-organize-your-search-results/</guid><pubDate>Thu, 24 Jul 2025 19:51:17 +0000</pubDate></item><item><title>[NEW] Navigating medical education in the era of generative AI (Microsoft Research)</title><link>https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/</link><description>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="AI Revolution | Illustrated headshots of Daniel Chen, Peter Lee, and Dr. Morgan Cheatham" class="wp-image-1145642" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this episode, Dr. Morgan Cheatham&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Daniel Chen&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, two rising physicians and experts in both medicine and technology, join Lee to explore how generative AI is reshaping medical education. Cheatham, a partner and head of healthcare and life sciences at Breyer Capital and a resident physician at Boston Children’s Hospital, discusses how AI is changing how clinicians acquire and apply medical knowledge at the point of care, emphasizing the need for training and curriculum changes to help ensure AI is used responsibly and that clinicians are equipped to maximize its potential. Chen, a medical student at the Kaiser Permanente Bernard J. Tyson School of Medicine, shares how he and his peers use AI tools as study aids, clinical tutors, and second opinions and reflects on the risks of overreliance and the importance of preserving critical thinking.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more"&gt;Learn more:&lt;/h2&gt;



&lt;p&gt;Perspectives on the Current and Future State of Artificial Intelligence in Medical Genetics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(Cheatham)&lt;br /&gt;Publication | May 2025&lt;/p&gt;



&lt;p&gt;Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; (Cheatham)&amp;nbsp;&lt;br /&gt;Publication | February 2023&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The AI Revolution in Medicine: GPT-4 and Beyond&amp;nbsp;&lt;br /&gt;Book | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023&amp;nbsp;&lt;/p&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“Medicine often uses the training approach when trying to assess multipurpose talent. To ensure students can safely and effectively take care of patients, we have them jump through quite a few hoops, … [and] they need good evaluations once they reach the clinic, passing grades on more exams like the USMLE [United States Medical Licensing Examination]. … [But] GPT-4 gets more than 90 percent of questions on licensing exams correct. … Does that provide any level of comfort in using GPT-4 in medicine?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee.    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?     &amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES] &amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from Chapter 4, “Trust but Verify.” In it, we explore how AI systems like GPT-4 should be evaluated for performance, safety, and reliability and compare this to how humans are both trained and assessed for readiness to deliver healthcare.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In previous conversations with guests, we’ve spoken a lot about AI in the clinic as well as in labs and companies developing AI-driven tools. We’ve also talked about AI in the hands of patients and consumers. But there has been some discussion also about AI’s role in medical training. And, as a founding board member of a new medical school at Kaiser Permanente, I definitely have my own thoughts about this. But today, I’m excited to welcome two guests who represent the next generation of medical professionals for their insights, Morgan Cheatham and Daniel Chen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Morgan Cheatham is a graduate of Brown University’s Warren Alpert Medical School with clinical training in genetics at Harvard and is a clinical fellow at Boston Children’s Hospital. While Morgan is a bona fide doctor in training, he’s also amazingly an influential health technology strategist. He was recently named partner and head of healthcare and life sciences at Breyer Capital and has led investments in several healthcare AI companies that have eclipsed multibillion-dollar valuations.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Daniel Chen is finishing his second year as a medical student at the Kaiser Permanente Bernard J. Tyson School of Medicine. He holds a neuroscience degree from the University of Washington and was a research assistant in the Raskind Lab at the UW School of Medicine, working with imaging and genetic data analyses for biomedical research. Prior to med school, Daniel pursued experiences that cultivated his interest in the application of AI in medical practice and education.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Daniel and Morgan exemplify the real-world future of healthcare, a student entering his third year of medical school and a fresh medical-school graduate who is starting a residency while at the same time continuing his work on investing in healthcare startups.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;Here is my interview with Morgan Cheatham:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Morgan, thanks for joining. Really, really looking forward to this chat.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MORGAN CHEATHAM: &lt;/strong&gt;Peter, it’s a privilege to be here with you. Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So are there any other human beings who are partners at big-league venture firms, residents at, you know, a Harvard-affiliated medical center, author, editor for a leading medical journal? I mean, who are your … who’s your cohort? Who are your peers?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I love this question. There are so many people who I consider peers that I look up to who have paved this path. And I think what is distinct about each of them is they have this physician-plus orientation. They are multilingual in terms of knowing the language of medicine but having learned other disciplines. And we share a common friend, Dr. Zak Kohane, who was among the first to really show how you can meld two worlds as a physician and make significant contributions to the intersections thereof.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I also deeply, in the world of business, respect physicians like Dr. Krishna Yeshwant at Google Ventures, who simultaneously pursued residency training and built what is now, you know, a large and enduring venture firm.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So there are plenty of people out there who’ve carved their own path and become these multilingual beings, and I aspire to be one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, you know, one thing I’ve been trying to explore with people are their origins with respect to the technology of AI. And there’s two eras for that. There’s AI &lt;em&gt;before&lt;/em&gt; ChatGPT and before, you know, generative AI really became a big thing, and then afterwards.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s start first before ChatGPT. You know, what was your contact? What was, you know, your knowledge of AI and machine learning?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Sure, so my experiences in computer science date back to high school. I went to Thomas Jefferson, which is a high school in Alexandria, Virginia, that prides itself on requiring students to take computer science in their first year of high school as kind of a required torturous experience. [LAUGHTER] And I remember that fondly. Our final project was Brick Breaker. It was actually, I joke, all hard coded. So there was nothing intelligent about the Brick Breaker that we built. But that was my first exposure.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I was a classics nerd, and I was really interested in biology and chemistry as a pre-medical student. So I really wouldn’t intersect with this field again until I was shadowing at Inova Hospital, which was a local hospital near me. And it was interesting because, at the time—I was shadowing in the anesthesia department—they were actually implementing their first instance of Epic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Mmm. Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;And I remember that experience fondly because the entire hospital was going from analog—they were going from paper-based charts—to this new digital system. And I didn’t quite know in that moment what it would mean for the field or for my career, but I knew it was a big deal because a lot of people had a lot of emotion around what was going on, and it was in that experience that I kind of decided to attach myself to the intersection of computation and medicine. So when I got to undergrad, I was a pre-medical student. I was very passionate about studying the sacred physician-patient relationship and everything that had to go on in that exam room to provide excellent care.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But there were a few formative experiences: one, working at a physician-founded startup that was using at the time we called it &lt;em&gt;big data&lt;/em&gt;, if you remember, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;… to match the right patient to the right provider at the right time. And it was in that moment that I realized that as a physician, I could utilize technology to scale that sacred one-to-one patient-provider interaction in nonlinear ways. So that was, kind of, the first experience where I saw deployed systems that were using patient data and clinical information in an intelligent format.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. And so you’re a pre-medical student, but you have this computer science understanding. You have an intuition, I guess is the right way to say it, that the clinical data becoming digital is going to be important. So then what happens from there to your path to medical school?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Yeah, so I had a few formative research experiences in my undergraduate years. You know, nothing that ever amounted to a significant publication, but I was toying around with SVMs [support vector machines] for sepsis and working with the MIMIC [Medical Information Mart for Intensive Care] database early days and really just trying to understand what it meant that medical data was becoming digitized.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And at the same time, again, I was rather unsatisfied doing that purely in an academic context. And I so early craved seeing how this would roll out in the wild, roll out in a clinical setting that I would soon occupy. And that was really what drove me to work at this company called Kyruus [Health] and understand how these systems, you know, scaled. Obviously, that’s something with AI that we’re now grappling with in a real way because it looks much different.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; So the other experience I had, which is less relevant to AI, but I did do a summer in banking. And I mention this because what I learned in the experience was … it was a master class in business. And I learned that there was another scaling factor that I should appreciate as we think about medicine, and that was capital and business formation. And that was also something that could scale nonlinearly.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So when you married that with technology, it was, kind of, a natural segue for me before going to med school to think about venture capital and partnering with founders who were going to be building these technologies for the long term. And so that’s how I landed on the venture side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And then how long of a break before you started your medical studies?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;It was about four years. Originally, it was going to be a two-year deferral, and the pandemic happened. Our space became quite active in terms of new companies and investment. So it was about four years before I went back.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I see. And so you’re in medical school. ChatGPT happened &lt;em&gt;while&lt;/em&gt; you were in medical school, is that right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;That’s right. That’s right. Right before I was studying for Step 1. So the funny story, Peter, that I like to share with folks is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … I was just embarking on designing my Step 1 study plan with my mentor. And I went to NeurIPS [Conference] for the first time. And that was in 2022, when, of course, ChatGPT was released.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for the remainder of that fall period, you know, I should have been studying for these shelf exams and, you know, getting ready …&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … for this large board exam. And I was fortunate to partner, actually, with one of our portfolio company CEOs who is a physician—he is an MD/PhD—to work on the first paper that showed that ChatGPT could pass the US Medical Licensing Exam&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; And that was a riveting experience for a number of reasons. I joke with folks that it was both the best paper I was ever, you know, a part of and proud to be a coauthor of, but also the worst for a lot of reasons that we could talk about.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It was the best in terms of canonical metrics like citations, but the worst in terms of, wow, did we spend six months as a field thinking this was the right benchmark … [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … for how to assess the performance of these models. And I’m so encouraged …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You shouldn’t feel bad that way because, you know, at that time, I was secretly, you know, assessing what we now know of as GPT-4 in that period. And what was the first thing &lt;em&gt;I&lt;/em&gt; tried to do? Step 1 medical exam.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, just for our listeners who don’t understand about medical education—in the US, there’s a three-part exam that extends over a couple of years of medical school. Step 1, Step 2, Step 3. And Step 1 and Step 2 in particular are multiple-choice exams.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they are very high stakes when you’re in medical school. And you really have to have a command of quite a lot of clinical knowledge to pass these. And it’s funny to hear you say what you were just sharing there because it was also the first impulse I had with GPT-4. And in retrospect, I feel silly about that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I think many of us do, but I’ve been encouraged over the last two years, to your point, that we really have moved our discourse beyond these exams to thinking about more robust systems for the evaluation of performance, which becomes even more interesting as you and I have spoken about these multi-agent frameworks that we are now, you know, compelled to explore further.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Well, and even though I know you’re a little sheepish about it now, I think in the show notes, we’ll link to that paper because it really was one of the seminal moments when we think about AI, AI in medicine.&lt;/p&gt;



&lt;p&gt;And so you’re seeing this new technology, and it’s happening at a moment when you &lt;em&gt;yourself&lt;/em&gt; have to confront taking the Step 1 exam. So how did that feel?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;It was humbling. It was shocking. What I had worked two years for, grueling over textbooks and, you know, flashcards and all of the things we do as medical students, to see a system emerge out of thin air that was arguably going to perform far better than I ever would, no matter how much …&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … I was going to study for that exam, it set me back. It forced me to interrogate what my role in medicine would be. And it dramatically changed the specialties that I considered for myself long term.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I hope we talk about, you know, how I stumbled upon genetics and why I’m so excited about that field and its evolution in this computational landscape. I had to do a lot of soul searching to relinquish what I thought it meant to be a physician and how I would adapt in this new environment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, one of the things that we wrote in our book, I think it was in a chapter that I contributed, I was imagining that students studying for Step 1 would be able to do it more actively.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Or you could even do sort of a pseudo-Step 3 exam by having a conversation. You provide the presentation of a patient and then have an encounter, you know, where the ChatGPT is the patient, and then you pretend to be the doctor.&amp;nbsp;And then in the example that we published, then you say, “End of encounter.” And then you ask ChatGPT for an assessment of things.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, you know, maybe it all came too late for Step 1 for you because you were already very focused and, you know, had your own kind of study framework. But did you have an influence or use of this kind of technology for Step 2 and Step 3?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; So even for Step 1, I would say, it [ChatGPT], you know, dropped in November. I took it [Step 1 exam] in the spring, so I was able to use it to study. But the lesson I learned in that moment, Peter, was really about the importance of trust with AI and clinicians or clinicians in training, because we all have the same resources that we use for these board exams, right. UWorld is this question bank. It’s been around forever. If you’re not using UWorld, like, &lt;em&gt;good luck&lt;/em&gt;. And so why would you deviate off of a well-trodden path to study for this really important exam?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I kind of adjunctively used GPT alongside UWorld to come up with more personalized explanations for concepts that I wasn’t understanding, and I found that it was pretty good and it was certainly helpful for me.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fortunately, I was, you know, able to pass, but I was very intentional about dogfooding AI when I was a medical student, and part of that was because I had been a venture capitalist, and I’d made investments in companies whose products I could actually use.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so, you know, Abridge is a company in the scribing space that you and I have talked about.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I was so fortunate in the early days of their product to not just be a user but to get to bring their product across the hospital. I could bring the product to the emergency department one week, to neurology another week, to the PICU [pediatric intensive care unit], you know, the next week, and assess the relative performance of, you know, how it handled really complex genetics cases …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … versus these very challenging social situations that you often find yourself navigating in primary care. So not only was I emotional about this technology, but I was a voracious adopter in the moment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, right. And you had a financial interest then on top of that, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I was not paid by Abridge to use the product, but, you know, I joke that the team was probably sick of me. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; No, no, but you were working for a venture firm that was invested in these, right? So all of these things are wrapped up together. You know, you’re having to get licensed as a doctor while doing all of this.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I want to get into that investment and new venture stuff there, but let’s stick just for a few more minutes on medical education. So I mentioned, you know, what we wrote in the book, and I remember writing the example, you know, of an encounter. Is that at all realistic? Is anything like that … that was pure speculation on our part. What’s really happening?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then after we talk about what’s really happening, what do you think should happen in medical education given the reality of generative AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I’ve been pleasantly surprised talking with my colleagues about AI in clinical settings, how curious people are and how curious they’ve been over the last two years. I think, oftentimes, we say, oh, you know, this technology really is stratified by age and the younger clinicians are using it more and the older physicians are ignoring it. And, you know, maybe that’s true in some regards, but I’ve seen, you know, many, you know, senior attendings pulling up Perplexity, GPT, more recently OpenEvidence&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which has been a really essential tool for me personally at the point of care, to come up with the best decisions for our patients.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The general skepticism arises when people reflect on their own experience in training and they think, “Well, I had to learn how to do it this way.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;“And therefore, &lt;em&gt;you&lt;/em&gt; using an AI scribe to document this encounter doesn’t feel right to me because I didn’t get to do that.” And I did face some of those critiques or criticisms, where you need to learn how to do it the old-school way first and then you can use an AI scribe.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I haven’t yet seen—maybe even taking a step back—I haven’t seen a lot of integration of AI into the core medical curriculum, period.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; And, as you know, if you want to add something to medical school curriculum, you can get in a long line of people who also want to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;But it is urgent that our medical schools do create formalized required trainings for this technology because people are already using it.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I think what we will need to determine is how much of the old way do people need to learn in order to earn the right to use AI at the point of care and how much of that old understanding, that prior experience, is essential to be able to assess the performance of these tools and whether or not they are having the intended outcome.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I kind of joke it’s like learning cursive, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I’m old enough to have had to learn cursive. I don’t think people really have to learn it these days. When do I use it? Well, when I’m signing something. I don’t even really sign checks anymore, but …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well … the example I’ve used, which you’ve heard, is, I’m sure you were still taught the technique of manual palpation, even though …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Of course.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… you have access to technologies like ultrasound. And in fact, you would use ultrasound in many cases.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I need to pin &lt;em&gt;you&lt;/em&gt; down. What is your opinion on these things? Do you need to be trained in the old ways?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; When it comes to understanding the architecture of the medical note, I believe it is important for clinicians in training to know how that information is generated, how it’s characterized, and how to go from a very broad-reaching conversation to a distilled clinical document that serves many functions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Does that mean that you should be forced to practice without an AI scribe for the entirety of your medical education? No. And I think that as you are learning the architecture of that document, you should be handed an AI scribe and you should be empowered to have visits with patients both in an analog setting—where you are transcribing and generating that note—and soon thereafter, I’m talking in a matter of weeks, working with an AI scribe. That’s my personal belief.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, yeah.&lt;strong&gt; &lt;/strong&gt;So you’re going to … well, first off, congratulations on landing a residency at Boston Children’s [Hospital].&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Thank you, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I understand there were only two people selected for this and super competitive. You know, with that perspective, you know, how do you see your future in medicine, just given everything that’s happening with AI right now?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And are there things that you would urge, let’s say, the dean of the Brown Medical School to consider or to change? Or maybe not the dean of Brown but the head of the LCME [Liaison Committee on Medical Education], the accrediting body for US medical schools. What in your mind needs to change?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; Sure. I’ll answer your first question first and then talk about the future.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;For me personally, I fell into the field of genomics. And so my training program will cover both pediatrics as well as clinical genetics and genomics.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I alluded to this earlier, but one of the reasons I’m so excited to join the field is because I really feel like the field of genetics not only is focused on a very underserved patient population, but not in how we typically think of underserved. I’m talking about underserved as in patients who don’t always have answers. Patients for whom the current guidelines don’t offer information or comfort or support.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Those are patients that are extremely underserved. And I think in this moment of AI, there’s a unique opportunity to utilize the computational systems that we now have access to, to provide these answers more precisely, more quickly.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’m excited to marry those two fields. And genetics has long been a field that has adopted technology. We just think about the foundational technology of genomic sequencing and variant interpretation. And so it’s a kind of natural evolution of the field, I believe, to integrate AI and specifically generative AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If I were speaking directly to the LCME, I mean, I would just have to encourage the organization, as well as medical societies who partner with attending physicians across specialties, to lean in here.&lt;/p&gt;



&lt;p&gt;When I think about prior revolutions in technology and medicine, physicians were not always at the helm. We have a unique opportunity now, and you talk about companies like Abridge in the AI space, companies like Viz.ai, Cleerly—I mean, I could go on: Iterative Health … I could list 20 organizations that are bringing AI to the point of care that are founded by physicians.&lt;/p&gt;



&lt;p&gt;This is our moment to have a seat at the table and to shape not only the discourse but the deployment. And the unique lens, of course, that a physician brings is that of prioritizing the patient, and with AI and this time around, we have to do that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So LCME for our listeners is, I think it stands for the Liaison Committee on Medical Education&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. It’s basically the accrediting body for US medical schools, and it’s very high stakes. It’s very, very rigorous, which I think is a good thing, but it’s also a bit of a straitjacket.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if you are on the LCME, are there specific new curricular elements that you would demand that LCME, you know, add to its accreditation standards?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;We need to unbundle the different components of the medical appointment and think about the different functions of a human clinician to answer that question.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There are a couple of areas that are top of mind for me, the first being medical search. There are large organizations and healthcare incumbents that have been around for many decades, companies like UpToDate or even, you know, the guidelines that are housed by our medical societies, that need to respond to the information demands of clinicians at the point of care in a new way with AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I would love to see our medical institutions teaching more students how to use AI for medical search problems at the point of care. How to not only, you know, from a prompt perspective, ask questions about patients in a high-efficacy way, but also to interpret the outputs of these systems to inform downstream clinical decision-making.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;People are already adopting, as you know, GPT, OpenEvidence, Perplexity, all of these tools to make these decisions now.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so by not—again, it’s a moral imperative of the LCME—by not having curriculum and support for clinicians doing that, we run the risk of folks not utilizing these tools properly but also to their greatest potential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, then, but zooming forward then, what about board certification?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; Board certification today is already transitioning to an open-book format for many specialties, is my understanding. And in talking to some of my fellow geneticists, who, you know, that’s a pretty challenging board exam in clinical genetics or biochemical genetics. They are using OpenEvidence during those open-book exams.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So what I would like to see us do is move from a system of rote memorization and regurgitation of fact to an assessment framework that is adaptive, is responsive, and assesses for your ability to use the tools that we now have at our disposal to make sound clinical decisions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. We’ve heard from Sara Murray, you know, that when she’s doing her rounds, she consults routinely with ChatGPT. And that was something we also predicted, especially Carey Goldberg in our book, you know, wrote this fictional account.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Is that the primary real-world use of AI? Not only by clinicians, but also by medical students … are medical students, you know, engaged with ChatGPT or, you know, similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Absolutely. I’ve listed some of the tools. I think there, in general, Peter, there is this new clinician stack that is emerging of these tools that people are trying, and I think the cycles of iteration are quick, right. Some folks are using Claude [Claude.ai] one week, and they’re trying Perplexity, or they’re trying OpenEvidence, they’re trying GPT for a different task.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s this kind of moment in medicine that every clinician experiences where you’re on rounds, and there’s that very senior attending. And you’ve just presented a patient to them, and you think you did an elegant job, and you’ve summarized all the information, and you really feel good about your differential, and they ask you, like, the one question you didn’t think to address. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I’ll tell you, some of the funniest moments I’ve had using AI in the hospital has been, and let me take a step back, that process of an attending physician interrogating a medical student is called “pimping,” for lack of a better phrase.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And some of the funniest use cases I’ve had for AI in that setting is actually using OpenEvidence or GPT as defense against pimping. [LAUGHTER] So quickly while they’re asking me the question, I put it in, and I’m actually able to answer it right away. So it’s been effective for that. But I would say, you know, [in] the halls of most of the hospitals where I’ve trained, I’m seeing this technology in the wild.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So now you’re so tech-forward, but that off-label use of AI, we also, when we wrote our book, we weren’t sure that at least top health systems would tolerate this. Do you have an opinion about this? Should these things be better regulated or controlled by the CIOs of Boston Children’s?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I’m a big believer that transparency encourages good behaviors.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so the first time I actually tried to use ChatGPT in a clinical setting, it was at a hospital in Rhode Island. I will not name which hospital. But the site was actually blocked. I wasn’t able to access it from a desktop. That was the hospital’s first response to this technology was, let’s make sure none of our clinicians can access it. It has so much potential for medicine. The irony of that today.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s since, you know, become unblocked. But I was able to use it on my phone. So, to your point, if there’s a will, there’s a way. And we will utilize this technology if we are seeing perceived value.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, yeah, no, absolutely. So now, you know, in some discussions, one superpower that seems to be common across people who are really leading the charge here is they seem to be very good readers and students.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I understand you also as a voracious reader. In fact, you’re even on an editorial team for a major medical journal. To what extent does that help?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then from your vantage point at &lt;em&gt;New England Journal of Medicine AI&lt;/em&gt;—and I’ll have a chance to ask Zak Kohane as the editor in chief the same question—you know, what’s your assessment as you reflect over the last two years for the submitted manuscripts? Are you overall surprised at what you’re seeing? Disappointed? Any kind of notable hits or misses, just in the steady stream of research papers that are getting submitted to that leading journal?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I would say overall, the field is becoming more expansive in the kinds of questions that people are asking.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Again, when we started, it was this very myopic approach of: “Can we pass these medical licensing exams? Can we benchmark this technology to how we benchmark our human clinicians?” I think that’s a trap. Some folks call this the Turing Trap, right, of let’s just compare everything to what a human is capable of.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Instead of interrogating what is the unique, as you all talk about in the book, what are the unique attributes of this new substrate for computation and what new behaviors emerge from it, whether that’s from a workflow perspective in the back office, or—as I’m personally more passionate and as we’re seeing more people focus on in the literature—what are the diagnostic capabilities, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I love Eric Topol’s framework for “machine eyes,” right, as this notion of like, yes, we as humans have eyes, and we have looked at medical images for many, many decades, but these machines can take a different approach to a retinal image, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s not just what you can diagnose in terms of an ophthalmological disease but maybe a neurologic disease or, you know, maybe liver disease, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think the literature is, in general, moving to this place of expansion, and I’m excited by that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I kind of have referred to that as triangulation. You know, one of the things I think a trap that specialists in medicine can fall into, like a cardiologist will see everything in terms of the cardiac system. And … whereas a nephrologist will see things in a certain lens.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And one of the things that you oftentimes see in the responses from a large language model is that more expansive view. At the same time, you know, I wonder … we have medical specialties for good reason. And, you know, at times I do wonder, you know, if there can be confusion that builds up.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; This is an under-discussed area of AI—AI collapses medical specialties onto themselves, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You have the canonical example of the cardiologist, you know, arguing that, you know, we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient’s clinical status?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My understanding is that the emergence of medical specialties was a function of the cognitive overload of medicine in general and how difficult it was to keep all of the specifics of a given specialty in the mind. Of course, general practitioners are tasked with doing this at some level, but they’re also tasked with knowing when they’ve reached their limit and when they need to refer to a specialist.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’m interested in this question of whether medical specialties themselves need to evolve.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve, whether it was certain diagnostic tools that have been introduced or, as we’re seeing now with GLP-1s, the entire cardiometabolic field …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … is having to really reimagine itself with these new tools. So I think AI will look very similar, and we should not hold on to this notion of classical medical specialties simply out of convention.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. All right. So now you’re starting your residency. You’re, you know, basically leading a charge in health and life sciences for a leading venture firm. I’d like you to predict what the world of healthcare is going to look like, you know, two years from now, five years from now, 10 years from now. And to frame that, to make it a little more specific, you know, what do you think will be possible that &lt;em&gt;you&lt;/em&gt;, as a doctor and an investor, will be able to do two years from now, five years from now, 10 years from now that you can’t do today?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Two years from now, I’m optimistic we’ll have greater adoption of AI by clinicians, both for back-office use cases. So whether that’s the scribe and the generation of the note for billing purposes, but also now thinking about that for patient-facing applications.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’re already doing this with drafting of notes. I think we’ll see greater proliferation of those more obvious use cases over the next two years. And hopefully we’re seeing that across hospital systems, not just large well-funded academics, but really reaching our community hospitals, our rural hospitals, our under-resourced settings.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think hopefully we’ll see greater conversion. Right now, we have this challenge of “pilotitis,” right. A lot of people are trying things, but the data shows that only one in three pilots are really converting to production use. So hopefully we’ll kind of move things forward that are working and pare back on those that are not.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We will not solve the problem of payment models in the next two years. That is a prediction I have.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Over the next five years, I suspect that, with the help of regulators, we will identify better payment mechanisms to support the adoption of AI because it cannot and will not sustain itself simply by asking health systems and hospitals to pay for it. That is not a scalable solution.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. Right. Yep. In fact, I think there have to be new revenue-positive incentives if providers are asked to do more in the adoption of technology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; Absolutely. But as we appreciate, some of the most promising applications of AI have nothing to do with revenue. It might simply be providing a diagnosis to somebody, you know, for whom that might drive additional intervention, but may also not.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And we have to be OK with that because that’s the right thing to do. It’s our moral imperative as clinicians to implement this where it provides value to the patient.&lt;/p&gt;



&lt;p&gt;Over the next 10 years, what I—again, being a techno-optimist—am hopeful we start to see is a dissolving of the barrier that exists between care delivery and biomedical discovery.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is the vision of the learning health system that was written over 10 years ago, and we have not realized it in practice. I’m a big proponent of ensuring that every single patient that enters our healthcare system not only receives the best care, but that we learn from the experiences of that individual to help the next.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in our current system, that is not how it works. But, with AI, that now becomes possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, I think connecting healthcare experiences to medical discovery—I think that that is really such a great vision for the future. And I do agree [that] AI really gives us real hope that we can make it true.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Morgan, I think we could talk for a few hours more. It’s just incredible what you’re up to nowadays. Thank you so much for this conversation. I’ve learned a lot talking to you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Peter, thank you so much for your time. I will be clutching my signed copy of &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;for many years to come.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Morgan obviously is not an ordinary med school graduate. In previous episodes, one of the things we’ve seen is that people on the leading edge of real-world AI in medicine oftentimes are both practicing doctors as well as technology developers. Morgan is another example of this type of polymath, being both a med student and a venture capitalist.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One thing that struck me about Morgan is he’s just incredibly hands-on. He goes out, finds leading-edge tools and technologies, and often these things, even though they’re experimental, he takes them into his education and into his clinical experiences. I think this highlights a potentially important point for medical schools, and that is, it might be incredibly important to provide the support—and, let’s be serious, the &lt;em&gt;permission&lt;/em&gt;—to students to access and use new tools and technologies. Indeed, the insight for me when I interact with Morgan is that in these early days of AI in medicine, there is no substitute for hands-on experimentation, and that is likely best done while in medical school.&lt;/p&gt;



&lt;p&gt;Here’s my interview with Daniel Chen:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Daniel, it’s great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DANIEL CHEN: &lt;/strong&gt;Yeah, it’s a pleasure being here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, you know, I normally get started in these conversations by asking, you know, how do you explain to your mother what you do all day? And the reason that that’s a good question is a lot of the people we have on this podcast have fancy titles and unusual jobs, but I’m guessing that your mother would have already a preconceived notion of what a medical student does. So I’d like to twist the question around a little bit for you and ask, what does your mother not realize about how you spend your days at school?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Or does she get it all right? [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Oh, no, she is very observant. I’ll say that off the bat. But I think something that she might not realize, is the amount of efforts spent, kind of, outside the classroom or outside the hospital. You know, she’s always, like, saying you have such long days in the hospital. You’re there so early in the morning.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what she doesn’t realize is that maybe when I come back from the hospital, it’s not just like, oh, I’m done for the day. Let’s wind down, go to bed. But it’s more like, OK, I have some more practice questions I need to get through; I didn’t get through my studying. Let me write on, like wrap up this research project I’m working on, get that back to the PI [principal investigator]. It’s never ending to a certain extent. Those are some things she doesn’t realize.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I think, you know, all the time studying, I think, is something that people expect of second-year medical students. And even nowadays at the top medical schools like this one, being involved in research is also expected.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think one thing that is a little unusual is that you are actually in clinic, as well, as a second-year student. How has that gone for you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Yeah, I mean, it’s definitely interesting. I would say I spend my time, especially this year, it’s kind of three things. There’s the preclinical stuff I’m doing. So that’s your classic, you know, you’re learning from the books, though I don’t feel like many of us do have textbooks anymore. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s the clinical aspect, which you mentioned, which is we have an interesting model, longitudinal integrated clerkships. We can talk about that. And the last component is the research aspect, right. The extracurriculars.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think starting out as a second year and doing your rotations, probably early on in, kind of, the clinical medical education, has been really interesting, especially with our format, because typically med students have two years to read up on all the material and, like, get some foundational knowledge. With us, it’s a bit more, we have maybe one year under our belt before we’re thrown into like, OK, go talk to this patient; they have ankle pain, right. But we might have not even started talking about ankle pain in class, right. Well, where do I begin?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think starting out, it’s kind of, like, you know, the classic drinking from a fire hydrant. But you also, kind of, have that embarrassment of you’re talking to the patient like, I have no clue what’s happening [LAUGHTER] or you might have … my differentials all over the place, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the beauty of the longitudinal aspect is that now that we’re, like, in our last trimester, everything’s kind of coming together. Like, OK, I can start to see, you know, here’s what you’re telling me. Here’s what the physical exam findings are. I’m starting to form a differential. Like, OK, I think these are the top three things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But in addition to that, I think these are the next steps you should take so we can really focus and hone in on what exact diagnosis this might be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; All right. So, of course, what we’re trying to get into is about AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, you know, the funny thing about AI and the book that Carey, Zak, and I wrote is we actually didn’t think too much about medical education, although we did have some parts of our book where we, well, first off, we made the guess that medical students would find AI to be useful. And we even had some examples, you know, where, you know, you would have a vignette of a mythical patient, and you would ask the AI to pretend to be that patient.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then you would have an interaction and have to have an encounter. And so I want to delve into whether any of that is happening. How real it is. But before we do that, let’s get into first off, your own personal contact with AI. So let me start with a very simple question. Do you ever use generative AI systems like ChatGPT or similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;All the time, if not every day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] Every day, OK. And when did that start?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think when it first launched with GPT-3.5, I was, you know, curious. All my friends work in tech. You know, they’re either software engineers, PMs. They’re like, “Hey, Daniel, take a look at this,” and at first, I thought it was just more of a glorified search engine. You know, I was actually looking back.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My first question to ChatGPT was, what was the weather going to be like the next week, you know? Something very, like, something easily you could have looked up on Google or your phone app, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I was like, oh, this is pretty cool. But then, kind of, fast-forwarding to, I think, the first instance I was using it in med school. I think the first, like, thing that really helped me was actually a coding problem. It was for a research project. I was trying to use SQL.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Obviously, I’ve never taken a SQL class in my life. So I asked Chat like, “Hey, can you write me this code to maybe morph two columns together,” right? Something that might have taken me hours to maybe Google on YouTube or like try to read some documentation which just goes through my head.&lt;/p&gt;



&lt;p&gt;But ChatGPT was able to, you know, not only produce the code, but, like, walk me through like, OK, you’re going to launch SQL. You’re going to click on this menu, [LAUGHTER] put the code in here, make sure your file names are correct. And it worked.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s been a very powerful tool in that way in terms of, like, giving me expertise in something that maybe I traditionally had no training in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so while you’re doing this, I assume you had fellow students, friends, and others. And so what were you observing about their contact with AI? I assume you weren’t alone in this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, yeah, I think, … I’m not too sure in terms of what they were doing when it first came out, but I think if we were talking about present day, um, a lot of it’s kind of really spot on to what you guys talked about in the book.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Um, I think the idea around this personal tutor, personal mentor, is something that we’re seeing a lot. Even if we’re having in-class discussions, the lecturer might be saying something, right. And then I might be or I see a friend in ChatGPT or some other model looking up a question.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you guys talked about, you know, how it can, like, explain a concept at different levels, right. But honestly, sometimes if there’s a complex topic, I ask ChatGPT, like, can you explain this to me as if I was a 6-year-old?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. [LAUGHS]&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Breaking down complex topics. Yeah. So I think it’s something that we see in the pre-clinical space, in lecture, but also even in the clinical space, there’s a lot of teaching, as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Sometimes if my preceptor is busy with patients, but I had maybe a question, I would maybe converse with ChatGPT, like, “Hey, what are your thoughts about this?” Or, like, a common one is, like, medical doctors love to use abbreviations, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; … and these abbreviations are sometimes only very niche and unique to their specialty, right. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I was reading this note from a urogynecologist. [In] the entire first sentence, I think there were, like, 10 abbreviations. Obviously, I compile lists and ask ChatGPT, like, “Hey, in the context of urogynecology, can you define what these could possibly mean,” right? Instead of hopelessly searching in a Google or maybe, embarrassing, asking the preceptor. So in these instances, it’s played a huge role.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. And when you’re doing things like that, it can make mistakes. And so what are your views of the reliability of generative AI, at least in the form of ChatGPT?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Yeah, I think into the context of medicine, right, we fear a lot about the hallucinations that these models might have. And it’s something I’m always checking for. When I talk with peers about this, we find it most helpful when the model gives us a source linking it back. I think the gold standard nowadays in medicine is using something called UpToDate&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that’s written by clinicians, for clinicians.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes searching on UpToDate can be a lot of time as well because it’s a lot of information to, like, sort through. But nowadays a lot of us are using something called OpenEvidence, which is also an LLM. But they always cite their citations with, like, published literature, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think being able to be conscious of the downfalls of these models and also being able to have the critical understanding of, like, analyzing the actual literature. I think double checking is just something that we’ve been also getting really good at.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; How would you assess student attitudes—med student attitudes—about AI? Is it … the way you’re coming across is it’s just a natural part of life. But do people have firm opinions, you know, pro or con, when it comes to AI, and especially AI &lt;em&gt;in&lt;/em&gt; medicine?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think it’s pretty split right now. I think there’s the half, kind of, like us, where we’re very optimistic—cautiously optimistic about, you know, the potential of this, right. It’s able to, you know, give us that extra information, of being that extra tutor, right. It’s also able to give us information very quickly, as well.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the other flip side of what a lot of students hesitate to, which I agree, is this loss of the ability to critically think. Something that you can easily do is, you know, give these models, like, relevant information about the patient history and be like, “Give me a 10-list differential,” right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; And I think it’s very easy as a student to, you know, [say], “This is difficult. Let me just use what the model says, and we’ll go with that,” right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think being able to separate that, you know, medical school is a time where, you know, you’re learning to become a good doctor. And part of that requires the ability to be observant and critically think. Having these models simultaneously might hinder the ability to do that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; So I think, you know, the next step is, like, these models can be great—a great tool, absolutely wonderful. But how do you make sure that it’s not hindering these abilities to critically think?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. And so when you’re doing your LIC [longitudinal integrated clerkship] work, these longitudinal experiences, and you’re in clinic, are you pulling the phone out of your pocket and consulting with AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Definitely. And I think my own policy for this, to kind of counter this, is that the night before when I’m looking over the patient list, the clinic [schedule] of who’s coming, I’m always giving it my best effort first.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Like, OK, the chief complaint is maybe just a runny nose for a kid in a pediatric clinic. What could this possibly be? Right? At this point, we’ve seen a lot. Like, OK, it could be URI [upper respiratory infection], it could be viral, it could be bacterial, you know, and then I go through the—you know, I try to do my due diligence of, like, going through the history and everything like that, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes if it’s a more complex case, something maybe a presentation I’ve never seen before, I’ll still kind of do my best coming up with maybe a differential that might not be amazing. But then I’ll ask, you know, ChatGPT like, OK, in addition to these ideas, what do you think?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Am I missing something? You know, and usually, it gives a pretty good response.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, that particular idea is something that I think Carey, Zak, and I thought would be happening a lot more today than we’re observing. And it’s the idea of a second set of eyes on your work. And somehow, at least our observation is that that isn’t happening quite as much by today as we thought it might.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it just seems like one of the really safest and most effective use cases. When you go and you’re looking at yourself and other fellow medical students, other second-year students, what do you see when it comes to the “second set of eyes” idea?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think, like, a lot of students are definitely consulting ChatGPT in that regard because, you know, even in the very beginning, we’re taught to be, like, never miss these red flags, right. So these red flags are always on our differential, but sometimes, it can be difficult to figure out where to place them on that, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think in addition to, you know, coming up with these differentials, something I’ve been finding a lot of value [in] is just chatting with these tools to get their rationale behind their thinking, you know.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Something I find really helpful—I think this is also a part of the, kind of, &lt;em&gt;art&lt;/em&gt; of medicine—is figuring out what to order, right, what labs to order.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Obviously, you have your order sets that automate some of the things, like in the ED [emergency department], or, like, there are some gold standard imaging things you should do for certain presentations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then you chat to, like, 10 different physicians on maybe the next steps after that, and they give you 10 different answers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; But there’s never … I never understand exactly why. It’s always like, I’ve just been doing this for all my training, or that’s how I was taught.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So asking ChatGPT, like, “Why would you do this next?” Or, like, “Is this a good idea?” And seeing the pros and cons has also been really helpful in my learning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, wow, that’s super interesting. So now, you know, I’d like to get into the education you’re receiving. And, you know, I think it’s fair to say Kaiser Permanente is very progressive in really trying to be very cutting-edge in how the whole curriculum is set up.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for the listeners who don’t know this, I’m actually on the board of directors of the school and have been since the founding of the school. And I think one of the reasons why I was invited to be on the board is the school really wanted to think ahead and be cutting edge when it comes to technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So from where I’ve sat, I’ve never been completely satisfied with the amount of tech that has made it into the curriculum. But at the same time, I’ve also made myself feel better about that just understanding that it’s sort of unstoppable, that students are so tech-forward already.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I wanted to delve into a little bit here into what your honest opinions are and your fellow students’ opinions are about whether you feel like you’re getting adequate training and background &lt;em&gt;formally &lt;/em&gt;as part of your medical education when it comes to things like artificial intelligence or other technologies.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What do you think? Are you … would you wish the curriculum would change?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, I think that’s a great question.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think from a tech perspective, the school is very good about implementing, you know, opportunities for us to learn. Like, for example, learning how to use Epic, right, or at Kaiser Permanente, what we call HealthConnect, right. These electronic health records. That, my understanding is, a lot of schools maybe don’t teach that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s something where we get training sessions maybe once or twice a year, like, “Hey, here’s how to make a shortcut in the environment,” right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think from that perspective, the school is really proactive in providing those opportunities, and they make it very easy to find resources for that, too. I think it …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, I think you’re pretty much guaranteed to be an Epic black belt by the time you [LAUGHS] finish your degree.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yes, yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then I think in terms of the aspects of artificial intelligence, I think the school’s taken a more cautiously optimistic viewpoint. They’re just kind of looking around right now.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Formally in the curriculum, there hasn’t been anything around this topic. I believe the fourth-year students last year got a student-led lecture around this topic.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But talking to other peers at other institutions, it looks like it’s something that’s very slowly being built into the curriculum, and it seems like a lot of it is actually student-led, you know.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, my friend at Feinberg [School of Medicine] was like we just got a session before clerkship about best practices on how to use these tools.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I have another friend at Pitt talking about how they’re leading efforts of maybe incorporating some sort of LLM into their in-house curriculum where students can, instead of clicking around the website trying to find the exact slide, they can just ask this tool, like, “OK. We had class this day. They talked about this … but can you provide more information?” and it can pull from that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think a lot of this, a lot of it is student-driven. Which I think is really exciting because it begs the question, I think, you know current physicians may not be very well equipped with these tools as well, right?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So maybe they don’t have a good idea of what exactly is the next steps or what does the curriculum look like. So I think the future in terms of this AI curriculum is really student-led, as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, yeah, it’s really interesting.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think one of the reasons I think also that that happens is [that] it’s not just necessarily the curriculum that lags but the accreditation standards. You know, accreditation is really important for medical schools because you want to make sure that anyone who holds an MD, you know, is a bona fide doctor, and so accreditation standards are pretty strictly monitored in most countries, including the United States.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think accreditation standards are also—my observation—are slow to understand how to adopt or integrate AI. And it’s not meant as a criticism. It’s a big unknown. No one knows exactly what to do and how to do. And so it’s really interesting to see that, as far as I can tell, I’ve observed the same thing that you just have seen, that most of the innovation in this area about how AI should be integrated into medical education is coming from the students themselves.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It seems, I think, I’d like to think it’s a healthy development. [LAUGHS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Something tells me maybe the students are a bit better at using these tools,&lt;strong&gt; &lt;/strong&gt;as well.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I talk to my preceptors because KP [Kaiser Permanente] also has their own version …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Preceptor, maybe we should explain what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, sorry. So a preceptor is an attending physician, fully licensed, finished residency, and they are essentially your kind of teacher in the clinical environment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So KP has their own version of some ambient documentation device, as well. And something I always like to ask, you know, like, “Hey, what are your thoughts on these tools,” right?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s always so polarizing, as well, even among the same specialty. Like, if you ask psychiatrists, which I think is a great use case of these tools, right. My preceptor hates it. Another preceptor next door loves it. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think a lot of it’s, like, it’s still, like, a lot of unknowns, like you were mentioning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Well, in fact, I’m glad you brought that up because one thing that we’ve been hearing from previous guests a lot when it comes to AI in clinic is about ambient listening by AI, for example, to help set up a clinical note or even write a clinical note.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And another big use case that we heard a lot about that seems to be pretty popular is the use of generative AI to respond to patient messages.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s start with the clinical note thing. First off, do you have opinions about that technology?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;I think it’s definitely good.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think especially where, you know, if you’re in the family medicine environment or pediatric environment where you’re spending so much time with patients, a note like that is great, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think coming from a strictly medical student standpoint, I think it’s—honestly, it’d be great to have—but I think there’s a lot of learning when you write the note, you know. There’s a lot of, you know, all of my preceptors talk about, like, when I read your note, you should present it in a way where I can see your thoughts and then once I get to the assessment and plan, it’s kind of funneling down towards a single diagnosis or a handful of diagnoses. And that’s, I think, a skill that requires you to practice over time, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So a part of me thinks, like, if I had this tool where [it] can just automatically give me a note as a first year, then it takes away from that learning experience, you know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Even during our first year throughout school, we frequently get feedback from professors and doctors about these notes. And it’s a lot of feedback. [LAUGHTER] It’s like, “I don’t think you should have written that,” “That should be in this section ” … you know, like a medical note or a &lt;em&gt;SOAP&lt;/em&gt; note [Subjective, Objective, Assessment, and Plan], where, you know, the &lt;em&gt;subjective&lt;/em&gt; is, like, what the patient tells you. &lt;em&gt;Objective &lt;/em&gt;is what the physical findings are, and then your assessment of what’s happening, and then your plan. Like, it’s very particular, and then I think medicine is so structured in a way, that’s kind of, like, how everyone does it, right. So kind of going back to the question, I think it’s a great tool, but I don’t think it’s appropriate for a medical student.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, it’s so interesting to hear you say that. I was … one of our previous guests is the head of R&amp;amp;D at Epic, Seth Hain. He said, “You know, Peter, doctors do a lot of their thinking when they write the note.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, of course, Epic is providing ambient, you know, clinical notetaking automation. But he was urging caution because, you know, you’re saying, well, this is where you’re learning a lot. But actually, it’s also a point where, as a doctor, you’re thinking about the patient. And we do probably have to be careful with how we automate parts of that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All right. So you’re gearing up for Step 1 of the USMLE [United States Medical Licensing Examination]. That’ll be a big multiple-choice exam. Then Step 2 is similar: very, very focused on advanced clinical knowledge. And then Step 3, you know, is a little more interactive.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so one question that people have had about AI is, you know, how do we regulate the use of AI in medicine? And one of the famous papers that came out of both academia and industry was the concept that you might be able to treat AI like a person and have it go through the same licensing. And this is something that Carey, Zak, and I contemplated in our book.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In the end, at the time we wrote the book, I personally rejected the idea, but I think it’s still alive. And so I’ve wondered if you have any … you know, first off, are you opinionated at all about, what should the requirements be for the allowable use of AI in the kind of work that you’re going to be doing?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, I think it’s a tough question because, like, where do you draw that line, right? If you apply the human standards of it’s passing exams, then yes, in theory, it could be maybe a medical doctor, as well, right? It’s more empathetic than medical doctors, right? So where do you draw that line?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think, you know, part of me thinks it’s maybe it is that human aspect that patients like to connect with, right. And maybe this really is just, like, these tools are just aids in helping, you know, maybe load off some cognitive load, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the other part of me, I’m thinking about this is the next generation who are growing up with this technology, right. They’re interacting with applications all day. Maybe they’re on their iPads. They’re talking to chatbots. They’re using ChatGPT. This is, kind of, the environment they grew up with. Does that mean they also have increased, like, trust in these tools that maybe our generation or the generations above us don’t have that value that human connection? Would they value human connection less?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I think those are some troubling thoughts that, you know, yes, at end of the day, maybe I’m not as smart as these tools, but I can still provide that human comfort. But if, at the end of the day, the future generation doesn’t really care about that or they perfectly trust these tools because that’s all they’ve kind of known, then where do human doctors stand?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think part of that is, there would be certain specialties where maybe the human connection is more important. The longitudinal aspect of building that trust, I think is important. Family medicine is a great example. I think hematology oncology with cancer treatment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Obviously, I think anyone’s not going to be thrilled to hear cancer diagnosis, but something tells me that seeing that on a screen versus maybe a physician prompting you and telling you about that tells me that maybe in those aspects, you know, the human nature, the human touch plays an important role there, too.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, you know, I think it strikes me that it’s going to be your generation that really is going to set the pattern probably for the next 50 years about how this goes. And it’s just so interesting because I think a lot will depend on your reactions to things.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, for example, you know, one thing that is already starting to happen are patients who are coming in armed, you know, with a differential [LAUGHS], you know, that they’ve developed themselves with the help of ChatGPT. So let me … you must have thought about these things. So, in fact, has it happened in your clinical work already?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Yeah, I’ve seen people come into the ED during my ED shift, like emergency department, and they’ll be like, “Oh, I have neck pain and here are all the things that, you know, Chat told me, ChatGPT told me. What do you think … do I need? I want this lab ordered, that lab ordered.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;And I think my initial reaction is, “Great. Maybe we should do that.” But I think the other reaction is understanding that not everyone has the clinical background of understanding what’s most important, what do we need to absolutely rule out, right?&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, I think in some regards, I would think that maybe ChatGPT errs on the side of caution, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;… giving maybe patients more extreme examples of what this could be just to make sure that it’s, in a way, is not missing any red flags as well, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yeah.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; But I think a lot of this is … what we’ve been learning is it’s all about shared decision making with the patient, right. Being able to acknowledge like, “Yeah, [in] that list, most of the stuff is very plausible, but maybe you didn’t think about this one symptom you have.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think part of it, maybe it’s a sidebar here, is the idea of prompting, right. You know, they’ve always talked about all these, you know, prompt engineers, you know, how well can you, like, give it context to answer your question?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; So I think being able to give these models the correct information and the relevant information and keyword &lt;em&gt;relevant&lt;/em&gt;, because relevant is, I guess, where your clinical expertise comes in. Like, what do you give the model, what do you not give? So I think that difference between a medical provider versus maybe your patients is ultimately the difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Let me press on that a little bit more because you brought up the issue of trust, and trust is &lt;em&gt;so&lt;/em&gt; essential for patients to feel good about their medical care.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I can imagine you’re a medical student seeing a patient for the first time. So you don’t have a trust relationship with that patient. And the patient comes in maybe trusting ChatGPT more than you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Very valid. No. I mean, I get that a lot, surprisingly, you know. [LAUGHTER] Sometimes [they’re] like, “Oh, I don’t want to see the medical student,” because we always give the patient an option, right. Like, it’s their time, whether it’s a clinic visit.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But yeah, those patients, I think it’s perfectly reasonable. If I heard a second-year medical student was going to be part of my care team, taking that history, I’d be maybe a little bit concerned, too. Like, are they asking all the right questions? Are they relaying that information back to their attending physician correctly?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think a lot of it is, at least from a medical student perspective, is framing it so the patient understands that this is a learning opportunity for the students. And something I do a lot is tell them like, “Hey, like, you know, at the end of the day, there is someone double-checking all my work.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; But for those that come in with a list, I sometimes sit down with them, and we’ll have a discussion, honestly.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’ll be like, “I don’t think you have meningitis because you’re not having a fever. Some of the physical exam maneuvers we did were also negative. So I don’t think you have anything to worry about that,” you know.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think it’s having that very candid conversation with the patient that helps build that initial trust. Telling them like, “Hey … ”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; It’s impressive to hear how even keeled you are about this. You know, I think, of course, and you’re being very humble saying, well, you know, as a second-year medical student, of course, someone might not, you know, have complete trust. But I think that we will be entering into a world where no doctor is going to be, no matter how experienced or how skilled, is going to be immune from this issue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So we’re starting to run toward the end of our time together. And I like to end with one or two more provocative questions.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so let me start with this one. Undoubtedly, I mean, you’re close enough to tech and digital stuff, digital health, that you’re undoubtedly familiar with famous predictions, you know, by Turing and Nobel laureates that someday certain medical specialties, most notably radiology, would be completely supplanted by machines. And more recently, there have been predictions by others, like, you know, Elon Musk, that maybe even some types of surgery would be replaced by machines.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What do you think? Do you have an opinion?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think &lt;em&gt;replace&lt;/em&gt; is a strong term, right. To say that doctors are completely obsolete, I think, is unlikely.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If anything, I think there might be a shift maybe in what it means to be a doctor, right. Undoubtedly, maybe the demands of radiologists are going to go down because maybe more of the simple things can truly be automated, right. And you just have a supervising radiologist whose output is maybe 10 times as maybe 10 single radiologists, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I definitely see a future where the demand of certain specialties might go down.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think when I talk about a shift of what it means to be a physician, maybe it’s not so much diagnostic anymore, right, if these models get so good at, like, just taking in large amounts of information, but maybe it pivots to being really good at understanding the limitations of these models and knowing when to intervene is what it means to be the kind of the next generation of physicians.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think in terms of surgery, yeah, I think it’s a concern, but maybe not in the next 50 years. Like those Da Vinci robots are great. I think out of Mayo Clinic, they were demoing some videos of these robots leveraging computer vision to, like, close portholes, like laparoscopic scars. And that’s something I do in the OR [operating room], right. And we’re at the same level at this point. [LAUGHTER] So at that point, maybe.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think robotics still has to address the understanding of like, what if something goes wrong, right? Who’s responsible? And I don’t see a future where a robot is able to react to these, you know, dangerous situations when maybe something goes wrong. You still have to have a surgeon on board to, kind of, take over. So in that regard, that’s kind of where I see maybe the future going.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So last question. You know, when you are thinking about the division of time, one of the themes that we’ve seen in the previous guests is more and more doctors are doing more technology work, like writing code and so on. And more and more technologists are thinking deeply and getting educated in clinical and preclinical work.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So for you, let’s look ahead 10 years. What do you see your division of labor to be? Or, you know, how would you … what would you tell your mom then about how you spend a typical day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, I mean, I think for me, technology is something I definitely want to be involved in in my line of work, whether it’s, you know, AI work, whether it’s improving quality of healthcare through technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My perfect division would be maybe still being able to see patients but also balancing some maybe more of these higher-level kind of larger projects. But I think having that division would be something nice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, well, I think you would be great just from the little bit I know about you. And, Daniel, it’s been really great chatting with you. I wish you the best of luck, you know, with your upcoming exams and getting past this year two of your medical studies. And perhaps someday I’ll be your patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Thank you so much.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, one of the lucky things about my job is that I pretty regularly get to talk to students at all levels, spanning high school to graduate school. And when I get to talk especially to med students, I’m always impressed with their intelligence, just how serious they are, and their high energy levels. Daniel is absolutely a perfect example of all that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, it comes across as trite to say that the older generation is less adept at technology adoption than younger people. But actually, there probably is a lot of truth to that. And in the conversation with Daniel, I think he was actually being pretty diplomatic but also clear that he and his fellow med students don’t necessarily expect the professors in their med school to understand AI as well as they do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s no doubt in my mind that medical education will have to evolve a lot to help prepare doctors and nurses for an AI future. But where will this evolution come from?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As I reflect on my conversations with Morgan and Daniel, I start to think that it’s most likely to come from the students themselves. And when you meet people like Morgan and Daniel, it’s impossible to not be incredibly optimistic about the next generation of clinicians.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Another big thank-you to Morgan and Daniel for taking time to share their experiences with us. And to our listeners, thank you for joining us. We have just a couple of episodes left, one on AI’s impact on the operation of public health departments and healthcare systems and another coauthor roundtable. We hope you’ll continue to tune in.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</description><content:encoded>&lt;figure class="wp-block-image size-full"&gt;&lt;img alt="AI Revolution | Illustrated headshots of Daniel Chen, Peter Lee, and Dr. Morgan Cheatham" class="wp-image-1145642" height="788" src="https://www.microsoft.com/en-us/research/wp-content/uploads/2025/07/Episode9-PeterMorganDaniel-AIRevolution_Hero_Feature_No_Text_1400x788.jpg" width="1400" /&gt;&lt;/figure&gt;






&lt;p&gt;In November 2022, OpenAI’s ChatGPT kick-started a new era in AI. This was followed less than a half year later by the release of GPT-4. In the months leading up to GPT-4’s public release, Peter Lee, president of Microsoft Research, cowrote a book full of optimism for the potential of advanced AI models to transform the world of healthcare. What has happened since? In this special podcast series, &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;, Lee revisits the book, exploring how patients, providers, and other medical professionals are experiencing and using generative AI today while examining what he and his coauthors got right—and what they didn’t foresee.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this episode, Dr. Morgan Cheatham&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; and Daniel Chen&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, two rising physicians and experts in both medicine and technology, join Lee to explore how generative AI is reshaping medical education. Cheatham, a partner and head of healthcare and life sciences at Breyer Capital and a resident physician at Boston Children’s Hospital, discusses how AI is changing how clinicians acquire and apply medical knowledge at the point of care, emphasizing the need for training and curriculum changes to help ensure AI is used responsibly and that clinicians are equipped to maximize its potential. Chen, a medical student at the Kaiser Permanente Bernard J. Tyson School of Medicine, shares how he and his peers use AI tools as study aids, clinical tutors, and second opinions and reflects on the risks of overreliance and the importance of preserving critical thinking.&lt;/p&gt;



&lt;hr class="wp-block-separator has-alpha-channel-opacity" /&gt;



&lt;h2 class="wp-block-heading h5" id="learn-more"&gt;Learn more:&lt;/h2&gt;



&lt;p&gt;Perspectives on the Current and Future State of Artificial Intelligence in Medical Genetics&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;&amp;nbsp;(Cheatham)&lt;br /&gt;Publication | May 2025&lt;/p&gt;



&lt;p&gt;Performance of ChatGPT on USMLE: Potential for AI-assisted medical education using large language models&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; (Cheatham)&amp;nbsp;&lt;br /&gt;Publication | February 2023&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The AI Revolution in Medicine: GPT-4 and Beyond&amp;nbsp;&lt;br /&gt;Book | Peter Lee, Carey Goldberg, Isaac Kohane | April 2023&amp;nbsp;&lt;/p&gt;



&lt;section class="wp-block-msr-subscribe-to-podcast subscribe-to-podcast"&gt;
	
&lt;/section&gt;


&lt;div class="wp-block-msr-show-more"&gt;
	&lt;div class="bg-neutral-100 p-5"&gt;
		&lt;div class="show-more-show-less"&gt;
			&lt;div&gt;
				&lt;span&gt;
					

&lt;h2 class="wp-block-heading" id="transcript"&gt;Transcript&lt;/h2&gt;



&lt;p&gt;[MUSIC]    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;[BOOK PASSAGE]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;PETER LEE: &lt;/strong&gt;“Medicine often uses the training approach when trying to assess multipurpose talent. To ensure students can safely and effectively take care of patients, we have them jump through quite a few hoops, … [and] they need good evaluations once they reach the clinic, passing grades on more exams like the USMLE [United States Medical Licensing Examination]. … [But] GPT-4 gets more than 90 percent of questions on licensing exams correct. … Does that provide any level of comfort in using GPT-4 in medicine?”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[END OF BOOK PASSAGE]    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is &lt;em&gt;The AI Revolution in Medicine, Revisited&lt;/em&gt;. I’m your host, Peter Lee.    &amp;nbsp;&lt;/p&gt;



&lt;p&gt;Shortly after OpenAI’s GPT-4 was publicly released, Carey Goldberg, Dr. Zak Kohane, and I published &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;to help educate the world of healthcare and medical research about the transformative impact this new generative AI technology could have. But because we wrote the book when GPT-4 was still a secret, we had to speculate. Now, two years later, what did we get right, and what did we get wrong?     &amp;nbsp;&lt;/p&gt;



&lt;p&gt;In this series, we’ll talk to clinicians, patients, hospital administrators, and others to understand the reality of AI in the field and where we go from here.&lt;/p&gt;



				&lt;/span&gt;
				&lt;span class="show-more-show-less-toggleable-content" id="show-more-show-less-toggle-1"&gt;
					



&lt;p&gt;[THEME MUSIC FADES] &amp;nbsp;&lt;/p&gt;



&lt;p&gt;The book passage I read at the top is from Chapter 4, “Trust but Verify.” In it, we explore how AI systems like GPT-4 should be evaluated for performance, safety, and reliability and compare this to how humans are both trained and assessed for readiness to deliver healthcare.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In previous conversations with guests, we’ve spoken a lot about AI in the clinic as well as in labs and companies developing AI-driven tools. We’ve also talked about AI in the hands of patients and consumers. But there has been some discussion also about AI’s role in medical training. And, as a founding board member of a new medical school at Kaiser Permanente, I definitely have my own thoughts about this. But today, I’m excited to welcome two guests who represent the next generation of medical professionals for their insights, Morgan Cheatham and Daniel Chen.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Morgan Cheatham is a graduate of Brown University’s Warren Alpert Medical School with clinical training in genetics at Harvard and is a clinical fellow at Boston Children’s Hospital. While Morgan is a bona fide doctor in training, he’s also amazingly an influential health technology strategist. He was recently named partner and head of healthcare and life sciences at Breyer Capital and has led investments in several healthcare AI companies that have eclipsed multibillion-dollar valuations.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Daniel Chen is finishing his second year as a medical student at the Kaiser Permanente Bernard J. Tyson School of Medicine. He holds a neuroscience degree from the University of Washington and was a research assistant in the Raskind Lab at the UW School of Medicine, working with imaging and genetic data analyses for biomedical research. Prior to med school, Daniel pursued experiences that cultivated his interest in the application of AI in medical practice and education.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Daniel and Morgan exemplify the real-world future of healthcare, a student entering his third year of medical school and a fresh medical-school graduate who is starting a residency while at the same time continuing his work on investing in healthcare startups.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &lt;/p&gt;



&lt;p&gt;Here is my interview with Morgan Cheatham:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Morgan, thanks for joining. Really, really looking forward to this chat.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;MORGAN CHEATHAM: &lt;/strong&gt;Peter, it’s a privilege to be here with you. Thank you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So are there any other human beings who are partners at big-league venture firms, residents at, you know, a Harvard-affiliated medical center, author, editor for a leading medical journal? I mean, who are your … who’s your cohort? Who are your peers?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I love this question. There are so many people who I consider peers that I look up to who have paved this path. And I think what is distinct about each of them is they have this physician-plus orientation. They are multilingual in terms of knowing the language of medicine but having learned other disciplines. And we share a common friend, Dr. Zak Kohane, who was among the first to really show how you can meld two worlds as a physician and make significant contributions to the intersections thereof.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I also deeply, in the world of business, respect physicians like Dr. Krishna Yeshwant at Google Ventures, who simultaneously pursued residency training and built what is now, you know, a large and enduring venture firm.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So there are plenty of people out there who’ve carved their own path and become these multilingual beings, and I aspire to be one.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, you know, one thing I’ve been trying to explore with people are their origins with respect to the technology of AI. And there’s two eras for that. There’s AI &lt;em&gt;before&lt;/em&gt; ChatGPT and before, you know, generative AI really became a big thing, and then afterwards.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s start first before ChatGPT. You know, what was your contact? What was, you know, your knowledge of AI and machine learning?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Sure, so my experiences in computer science date back to high school. I went to Thomas Jefferson, which is a high school in Alexandria, Virginia, that prides itself on requiring students to take computer science in their first year of high school as kind of a required torturous experience. [LAUGHTER] And I remember that fondly. Our final project was Brick Breaker. It was actually, I joke, all hard coded. So there was nothing intelligent about the Brick Breaker that we built. But that was my first exposure.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I was a classics nerd, and I was really interested in biology and chemistry as a pre-medical student. So I really wouldn’t intersect with this field again until I was shadowing at Inova Hospital, which was a local hospital near me. And it was interesting because, at the time—I was shadowing in the anesthesia department—they were actually implementing their first instance of Epic.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Mmm. Wow.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;And I remember that experience fondly because the entire hospital was going from analog—they were going from paper-based charts—to this new digital system. And I didn’t quite know in that moment what it would mean for the field or for my career, but I knew it was a big deal because a lot of people had a lot of emotion around what was going on, and it was in that experience that I kind of decided to attach myself to the intersection of computation and medicine. So when I got to undergrad, I was a pre-medical student. I was very passionate about studying the sacred physician-patient relationship and everything that had to go on in that exam room to provide excellent care.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But there were a few formative experiences: one, working at a physician-founded startup that was using at the time we called it &lt;em&gt;big data&lt;/em&gt;, if you remember, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yup.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;… to match the right patient to the right provider at the right time. And it was in that moment that I realized that as a physician, I could utilize technology to scale that sacred one-to-one patient-provider interaction in nonlinear ways. So that was, kind of, the first experience where I saw deployed systems that were using patient data and clinical information in an intelligent format.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. And so you’re a pre-medical student, but you have this computer science understanding. You have an intuition, I guess is the right way to say it, that the clinical data becoming digital is going to be important. So then what happens from there to your path to medical school?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Yeah, so I had a few formative research experiences in my undergraduate years. You know, nothing that ever amounted to a significant publication, but I was toying around with SVMs [support vector machines] for sepsis and working with the MIMIC [Medical Information Mart for Intensive Care] database early days and really just trying to understand what it meant that medical data was becoming digitized.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And at the same time, again, I was rather unsatisfied doing that purely in an academic context. And I so early craved seeing how this would roll out in the wild, roll out in a clinical setting that I would soon occupy. And that was really what drove me to work at this company called Kyruus [Health] and understand how these systems, you know, scaled. Obviously, that’s something with AI that we’re now grappling with in a real way because it looks much different.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yep.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; So the other experience I had, which is less relevant to AI, but I did do a summer in banking. And I mention this because what I learned in the experience was … it was a master class in business. And I learned that there was another scaling factor that I should appreciate as we think about medicine, and that was capital and business formation. And that was also something that could scale nonlinearly.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So when you married that with technology, it was, kind of, a natural segue for me before going to med school to think about venture capital and partnering with founders who were going to be building these technologies for the long term. And so that’s how I landed on the venture side.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And then how long of a break before you started your medical studies?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;It was about four years. Originally, it was going to be a two-year deferral, and the pandemic happened. Our space became quite active in terms of new companies and investment. So it was about four years before I went back.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I see. And so you’re in medical school. ChatGPT happened &lt;em&gt;while&lt;/em&gt; you were in medical school, is that right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;That’s right. That’s right. Right before I was studying for Step 1. So the funny story, Peter, that I like to share with folks is …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … I was just embarking on designing my Step 1 study plan with my mentor. And I went to NeurIPS [Conference] for the first time. And that was in 2022, when, of course, ChatGPT was released.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for the remainder of that fall period, you know, I should have been studying for these shelf exams and, you know, getting ready …&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … for this large board exam. And I was fortunate to partner, actually, with one of our portfolio company CEOs who is a physician—he is an MD/PhD—to work on the first paper that showed that ChatGPT could pass the US Medical Licensing Exam&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; And that was a riveting experience for a number of reasons. I joke with folks that it was both the best paper I was ever, you know, a part of and proud to be a coauthor of, but also the worst for a lot of reasons that we could talk about.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It was the best in terms of canonical metrics like citations, but the worst in terms of, wow, did we spend six months as a field thinking this was the right benchmark … [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … for how to assess the performance of these models. And I’m so encouraged …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You shouldn’t feel bad that way because, you know, at that time, I was secretly, you know, assessing what we now know of as GPT-4 in that period. And what was the first thing &lt;em&gt;I&lt;/em&gt; tried to do? Step 1 medical exam.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;By the way, just for our listeners who don’t understand about medical education—in the US, there’s a three-part exam that extends over a couple of years of medical school. Step 1, Step 2, Step 3. And Step 1 and Step 2 in particular are multiple-choice exams.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And they are very high stakes when you’re in medical school. And you really have to have a command of quite a lot of clinical knowledge to pass these. And it’s funny to hear you say what you were just sharing there because it was also the first impulse I had with GPT-4. And in retrospect, I feel silly about that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I think many of us do, but I’ve been encouraged over the last two years, to your point, that we really have moved our discourse beyond these exams to thinking about more robust systems for the evaluation of performance, which becomes even more interesting as you and I have spoken about these multi-agent frameworks that we are now, you know, compelled to explore further.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. Well, and even though I know you’re a little sheepish about it now, I think in the show notes, we’ll link to that paper because it really was one of the seminal moments when we think about AI, AI in medicine.&lt;/p&gt;



&lt;p&gt;And so you’re seeing this new technology, and it’s happening at a moment when you &lt;em&gt;yourself&lt;/em&gt; have to confront taking the Step 1 exam. So how did that feel?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;It was humbling. It was shocking. What I had worked two years for, grueling over textbooks and, you know, flashcards and all of the things we do as medical students, to see a system emerge out of thin air that was arguably going to perform far better than I ever would, no matter how much …&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … I was going to study for that exam, it set me back. It forced me to interrogate what my role in medicine would be. And it dramatically changed the specialties that I considered for myself long term.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I hope we talk about, you know, how I stumbled upon genetics and why I’m so excited about that field and its evolution in this computational landscape. I had to do a lot of soul searching to relinquish what I thought it meant to be a physician and how I would adapt in this new environment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, one of the things that we wrote in our book, I think it was in a chapter that I contributed, I was imagining that students studying for Step 1 would be able to do it more actively.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Or you could even do sort of a pseudo-Step 3 exam by having a conversation. You provide the presentation of a patient and then have an encounter, you know, where the ChatGPT is the patient, and then you pretend to be the doctor.&amp;nbsp;And then in the example that we published, then you say, “End of encounter.” And then you ask ChatGPT for an assessment of things.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, you know, maybe it all came too late for Step 1 for you because you were already very focused and, you know, had your own kind of study framework. But did you have an influence or use of this kind of technology for Step 2 and Step 3?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; So even for Step 1, I would say, it [ChatGPT], you know, dropped in November. I took it [Step 1 exam] in the spring, so I was able to use it to study. But the lesson I learned in that moment, Peter, was really about the importance of trust with AI and clinicians or clinicians in training, because we all have the same resources that we use for these board exams, right. UWorld is this question bank. It’s been around forever. If you’re not using UWorld, like, &lt;em&gt;good luck&lt;/em&gt;. And so why would you deviate off of a well-trodden path to study for this really important exam?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I kind of adjunctively used GPT alongside UWorld to come up with more personalized explanations for concepts that I wasn’t understanding, and I found that it was pretty good and it was certainly helpful for me.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Fortunately, I was, you know, able to pass, but I was very intentional about dogfooding AI when I was a medical student, and part of that was because I had been a venture capitalist, and I’d made investments in companies whose products I could actually use.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so, you know, Abridge is a company in the scribing space that you and I have talked about.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I was so fortunate in the early days of their product to not just be a user but to get to bring their product across the hospital. I could bring the product to the emergency department one week, to neurology another week, to the PICU [pediatric intensive care unit], you know, the next week, and assess the relative performance of, you know, how it handled really complex genetics cases …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … versus these very challenging social situations that you often find yourself navigating in primary care. So not only was I emotional about this technology, but I was a voracious adopter in the moment.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, right. And you had a financial interest then on top of that, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I was not paid by Abridge to use the product, but, you know, I joke that the team was probably sick of me. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; No, no, but you were working for a venture firm that was invested in these, right? So all of these things are wrapped up together. You know, you’re having to get licensed as a doctor while doing all of this.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I want to get into that investment and new venture stuff there, but let’s stick just for a few more minutes on medical education. So I mentioned, you know, what we wrote in the book, and I remember writing the example, you know, of an encounter. Is that at all realistic? Is anything like that … that was pure speculation on our part. What’s really happening?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then after we talk about what’s really happening, what do you think should happen in medical education given the reality of generative AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I’ve been pleasantly surprised talking with my colleagues about AI in clinical settings, how curious people are and how curious they’ve been over the last two years. I think, oftentimes, we say, oh, you know, this technology really is stratified by age and the younger clinicians are using it more and the older physicians are ignoring it. And, you know, maybe that’s true in some regards, but I’ve seen, you know, many, you know, senior attendings pulling up Perplexity, GPT, more recently OpenEvidence&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;, which has been a really essential tool for me personally at the point of care, to come up with the best decisions for our patients.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;The general skepticism arises when people reflect on their own experience in training and they think, “Well, I had to learn how to do it this way.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;“And therefore, &lt;em&gt;you&lt;/em&gt; using an AI scribe to document this encounter doesn’t feel right to me because I didn’t get to do that.” And I did face some of those critiques or criticisms, where you need to learn how to do it the old-school way first and then you can use an AI scribe.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I haven’t yet seen—maybe even taking a step back—I haven’t seen a lot of integration of AI into the core medical curriculum, period.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; And, as you know, if you want to add something to medical school curriculum, you can get in a long line of people who also want to do that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. Yeah.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;But it is urgent that our medical schools do create formalized required trainings for this technology because people are already using it.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I think what we will need to determine is how much of the old way do people need to learn in order to earn the right to use AI at the point of care and how much of that old understanding, that prior experience, is essential to be able to assess the performance of these tools and whether or not they are having the intended outcome.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I kind of joke it’s like learning cursive, right?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;I’m old enough to have had to learn cursive. I don’t think people really have to learn it these days. When do I use it? Well, when I’m signing something. I don’t even really sign checks anymore, but …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well … the example I’ve used, which you’ve heard, is, I’m sure you were still taught the technique of manual palpation, even though …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Of course.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;… you have access to technologies like ultrasound. And in fact, you would use ultrasound in many cases.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I need to pin &lt;em&gt;you&lt;/em&gt; down. What is your opinion on these things? Do you need to be trained in the old ways?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; When it comes to understanding the architecture of the medical note, I believe it is important for clinicians in training to know how that information is generated, how it’s characterized, and how to go from a very broad-reaching conversation to a distilled clinical document that serves many functions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Does that mean that you should be forced to practice without an AI scribe for the entirety of your medical education? No. And I think that as you are learning the architecture of that document, you should be handed an AI scribe and you should be empowered to have visits with patients both in an analog setting—where you are transcribing and generating that note—and soon thereafter, I’m talking in a matter of weeks, working with an AI scribe. That’s my personal belief.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, yeah.&lt;strong&gt; &lt;/strong&gt;So you’re going to … well, first off, congratulations on landing a residency at Boston Children’s [Hospital].&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Thank you, Peter.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; I understand there were only two people selected for this and super competitive. You know, with that perspective, you know, how do you see your future in medicine, just given everything that’s happening with AI right now?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And are there things that you would urge, let’s say, the dean of the Brown Medical School to consider or to change? Or maybe not the dean of Brown but the head of the LCME [Liaison Committee on Medical Education], the accrediting body for US medical schools. What in your mind needs to change?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; Sure. I’ll answer your first question first and then talk about the future.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;For me personally, I fell into the field of genomics. And so my training program will cover both pediatrics as well as clinical genetics and genomics.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I alluded to this earlier, but one of the reasons I’m so excited to join the field is because I really feel like the field of genetics not only is focused on a very underserved patient population, but not in how we typically think of underserved. I’m talking about underserved as in patients who don’t always have answers. Patients for whom the current guidelines don’t offer information or comfort or support.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Those are patients that are extremely underserved. And I think in this moment of AI, there’s a unique opportunity to utilize the computational systems that we now have access to, to provide these answers more precisely, more quickly.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I’m excited to marry those two fields. And genetics has long been a field that has adopted technology. We just think about the foundational technology of genomic sequencing and variant interpretation. And so it’s a kind of natural evolution of the field, I believe, to integrate AI and specifically generative AI.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If I were speaking directly to the LCME, I mean, I would just have to encourage the organization, as well as medical societies who partner with attending physicians across specialties, to lean in here.&lt;/p&gt;



&lt;p&gt;When I think about prior revolutions in technology and medicine, physicians were not always at the helm. We have a unique opportunity now, and you talk about companies like Abridge in the AI space, companies like Viz.ai, Cleerly—I mean, I could go on: Iterative Health … I could list 20 organizations that are bringing AI to the point of care that are founded by physicians.&lt;/p&gt;



&lt;p&gt;This is our moment to have a seat at the table and to shape not only the discourse but the deployment. And the unique lens, of course, that a physician brings is that of prioritizing the patient, and with AI and this time around, we have to do that.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;So LCME for our listeners is, I think it stands for the Liaison Committee on Medical Education&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt;. It’s basically the accrediting body for US medical schools, and it’s very high stakes. It’s very, very rigorous, which I think is a good thing, but it’s also a bit of a straitjacket.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So if you are on the LCME, are there specific new curricular elements that you would demand that LCME, you know, add to its accreditation standards?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;We need to unbundle the different components of the medical appointment and think about the different functions of a human clinician to answer that question.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There are a couple of areas that are top of mind for me, the first being medical search. There are large organizations and healthcare incumbents that have been around for many decades, companies like UpToDate or even, you know, the guidelines that are housed by our medical societies, that need to respond to the information demands of clinicians at the point of care in a new way with AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so I would love to see our medical institutions teaching more students how to use AI for medical search problems at the point of care. How to not only, you know, from a prompt perspective, ask questions about patients in a high-efficacy way, but also to interpret the outputs of these systems to inform downstream clinical decision-making.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;People are already adopting, as you know, GPT, OpenEvidence, Perplexity, all of these tools to make these decisions now.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so by not—again, it’s a moral imperative of the LCME—by not having curriculum and support for clinicians doing that, we run the risk of folks not utilizing these tools properly but also to their greatest potential.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, then, but zooming forward then, what about board certification?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; Board certification today is already transitioning to an open-book format for many specialties, is my understanding. And in talking to some of my fellow geneticists, who, you know, that’s a pretty challenging board exam in clinical genetics or biochemical genetics. They are using OpenEvidence during those open-book exams.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So what I would like to see us do is move from a system of rote memorization and regurgitation of fact to an assessment framework that is adaptive, is responsive, and assesses for your ability to use the tools that we now have at our disposal to make sound clinical decisions.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. We’ve heard from Sara Murray, you know, that when she’s doing her rounds, she consults routinely with ChatGPT. And that was something we also predicted, especially Carey Goldberg in our book, you know, wrote this fictional account.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Is that the primary real-world use of AI? Not only by clinicians, but also by medical students … are medical students, you know, engaged with ChatGPT or, you know, similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Absolutely. I’ve listed some of the tools. I think there, in general, Peter, there is this new clinician stack that is emerging of these tools that people are trying, and I think the cycles of iteration are quick, right. Some folks are using Claude [Claude.ai] one week, and they’re trying Perplexity, or they’re trying OpenEvidence, they’re trying GPT for a different task.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s this kind of moment in medicine that every clinician experiences where you’re on rounds, and there’s that very senior attending. And you’ve just presented a patient to them, and you think you did an elegant job, and you’ve summarized all the information, and you really feel good about your differential, and they ask you, like, the one question you didn’t think to address. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I’ll tell you, some of the funniest moments I’ve had using AI in the hospital has been, and let me take a step back, that process of an attending physician interrogating a medical student is called “pimping,” for lack of a better phrase.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And some of the funniest use cases I’ve had for AI in that setting is actually using OpenEvidence or GPT as defense against pimping. [LAUGHTER] So quickly while they’re asking me the question, I put it in, and I’m actually able to answer it right away. So it’s been effective for that. But I would say, you know, [in] the halls of most of the hospitals where I’ve trained, I’m seeing this technology in the wild.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So now you’re so tech-forward, but that off-label use of AI, we also, when we wrote our book, we weren’t sure that at least top health systems would tolerate this. Do you have an opinion about this? Should these things be better regulated or controlled by the CIOs of Boston Children’s?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I’m a big believer that transparency encourages good behaviors.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so the first time I actually tried to use ChatGPT in a clinical setting, it was at a hospital in Rhode Island. I will not name which hospital. But the site was actually blocked. I wasn’t able to access it from a desktop. That was the hospital’s first response to this technology was, let’s make sure none of our clinicians can access it. It has so much potential for medicine. The irony of that today.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s since, you know, become unblocked. But I was able to use it on my phone. So, to your point, if there’s a will, there’s a way. And we will utilize this technology if we are seeing perceived value.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So, yeah, no, absolutely. So now, you know, in some discussions, one superpower that seems to be common across people who are really leading the charge here is they seem to be very good readers and students.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I understand you also as a voracious reader. In fact, you’re even on an editorial team for a major medical journal. To what extent does that help?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then from your vantage point at &lt;em&gt;New England Journal of Medicine AI&lt;/em&gt;—and I’ll have a chance to ask Zak Kohane as the editor in chief the same question—you know, what’s your assessment as you reflect over the last two years for the submitted manuscripts? Are you overall surprised at what you’re seeing? Disappointed? Any kind of notable hits or misses, just in the steady stream of research papers that are getting submitted to that leading journal?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; I would say overall, the field is becoming more expansive in the kinds of questions that people are asking.&lt;strong&gt;&amp;nbsp;&lt;/strong&gt;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Again, when we started, it was this very myopic approach of: “Can we pass these medical licensing exams? Can we benchmark this technology to how we benchmark our human clinicians?” I think that’s a trap. Some folks call this the Turing Trap, right, of let’s just compare everything to what a human is capable of.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Instead of interrogating what is the unique, as you all talk about in the book, what are the unique attributes of this new substrate for computation and what new behaviors emerge from it, whether that’s from a workflow perspective in the back office, or—as I’m personally more passionate and as we’re seeing more people focus on in the literature—what are the diagnostic capabilities, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I love Eric Topol’s framework for “machine eyes,” right, as this notion of like, yes, we as humans have eyes, and we have looked at medical images for many, many decades, but these machines can take a different approach to a retinal image, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It’s not just what you can diagnose in terms of an ophthalmological disease but maybe a neurologic disease or, you know, maybe liver disease, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think the literature is, in general, moving to this place of expansion, and I’m excited by that.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I kind of have referred to that as triangulation. You know, one of the things I think a trap that specialists in medicine can fall into, like a cardiologist will see everything in terms of the cardiac system. And … whereas a nephrologist will see things in a certain lens.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And one of the things that you oftentimes see in the responses from a large language model is that more expansive view. At the same time, you know, I wonder … we have medical specialties for good reason. And, you know, at times I do wonder, you know, if there can be confusion that builds up.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; This is an under-discussed area of AI—AI collapses medical specialties onto themselves, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You have the canonical example of the cardiologist, you know, arguing that, you know, we should diuresis and maybe the nephrologist arguing that we should, you know, protect the kidneys. And how do two disciplines disagree on what is right for the patient when in theory, there is an objective best answer given that patient’s clinical status?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My understanding is that the emergence of medical specialties was a function of the cognitive overload of medicine in general and how difficult it was to keep all of the specifics of a given specialty in the mind. Of course, general practitioners are tasked with doing this at some level, but they’re also tasked with knowing when they’ve reached their limit and when they need to refer to a specialist.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I’m interested in this question of whether medical specialties themselves need to evolve.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And if we look back in the history of medical technology, there are many times where a new technology forced a medical specialty to evolve, whether it was certain diagnostic tools that have been introduced or, as we’re seeing now with GLP-1s, the entire cardiometabolic field …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; … is having to really reimagine itself with these new tools. So I think AI will look very similar, and we should not hold on to this notion of classical medical specialties simply out of convention.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. All right. So now you’re starting your residency. You’re, you know, basically leading a charge in health and life sciences for a leading venture firm. I’d like you to predict what the world of healthcare is going to look like, you know, two years from now, five years from now, 10 years from now. And to frame that, to make it a little more specific, you know, what do you think will be possible that &lt;em&gt;you&lt;/em&gt;, as a doctor and an investor, will be able to do two years from now, five years from now, 10 years from now that you can’t do today?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Two years from now, I’m optimistic we’ll have greater adoption of AI by clinicians, both for back-office use cases. So whether that’s the scribe and the generation of the note for billing purposes, but also now thinking about that for patient-facing applications.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We’re already doing this with drafting of notes. I think we’ll see greater proliferation of those more obvious use cases over the next two years. And hopefully we’re seeing that across hospital systems, not just large well-funded academics, but really reaching our community hospitals, our rural hospitals, our under-resourced settings.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think hopefully we’ll see greater conversion. Right now, we have this challenge of “pilotitis,” right. A lot of people are trying things, but the data shows that only one in three pilots are really converting to production use. So hopefully we’ll kind of move things forward that are working and pare back on those that are not.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;We will not solve the problem of payment models in the next two years. That is a prediction I have.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Over the next five years, I suspect that, with the help of regulators, we will identify better payment mechanisms to support the adoption of AI because it cannot and will not sustain itself simply by asking health systems and hospitals to pay for it. That is not a scalable solution.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes. Right. Yep. In fact, I think there have to be new revenue-positive incentives if providers are asked to do more in the adoption of technology.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM:&lt;/strong&gt; Absolutely. But as we appreciate, some of the most promising applications of AI have nothing to do with revenue. It might simply be providing a diagnosis to somebody, you know, for whom that might drive additional intervention, but may also not.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And we have to be OK with that because that’s the right thing to do. It’s our moral imperative as clinicians to implement this where it provides value to the patient.&lt;/p&gt;



&lt;p&gt;Over the next 10 years, what I—again, being a techno-optimist—am hopeful we start to see is a dissolving of the barrier that exists between care delivery and biomedical discovery.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;This is the vision of the learning health system that was written over 10 years ago, and we have not realized it in practice. I’m a big proponent of ensuring that every single patient that enters our healthcare system not only receives the best care, but that we learn from the experiences of that individual to help the next.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And in our current system, that is not how it works. But, with AI, that now becomes possible.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, I think connecting healthcare experiences to medical discovery—I think that that is really such a great vision for the future. And I do agree [that] AI really gives us real hope that we can make it true.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Morgan, I think we could talk for a few hours more. It’s just incredible what you’re up to nowadays. Thank you so much for this conversation. I’ve learned a lot talking to you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEATHAM: &lt;/strong&gt;Peter, thank you so much for your time. I will be clutching my signed copy of &lt;em&gt;The AI Revolution in Medicine &lt;/em&gt;for many years to come.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Morgan obviously is not an ordinary med school graduate. In previous episodes, one of the things we’ve seen is that people on the leading edge of real-world AI in medicine oftentimes are both practicing doctors as well as technology developers. Morgan is another example of this type of polymath, being both a med student and a venture capitalist.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;One thing that struck me about Morgan is he’s just incredibly hands-on. He goes out, finds leading-edge tools and technologies, and often these things, even though they’re experimental, he takes them into his education and into his clinical experiences. I think this highlights a potentially important point for medical schools, and that is, it might be incredibly important to provide the support—and, let’s be serious, the &lt;em&gt;permission&lt;/em&gt;—to students to access and use new tools and technologies. Indeed, the insight for me when I interact with Morgan is that in these early days of AI in medicine, there is no substitute for hands-on experimentation, and that is likely best done while in medical school.&lt;/p&gt;



&lt;p&gt;Here’s my interview with Daniel Chen:&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Daniel, it’s great to have you here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;DANIEL CHEN: &lt;/strong&gt;Yeah, it’s a pleasure being here.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Well, you know, I normally get started in these conversations by asking, you know, how do you explain to your mother what you do all day? And the reason that that’s a good question is a lot of the people we have on this podcast have fancy titles and unusual jobs, but I’m guessing that your mother would have already a preconceived notion of what a medical student does. So I’d like to twist the question around a little bit for you and ask, what does your mother not realize about how you spend your days at school?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Or does she get it all right? [LAUGHS]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Oh, no, she is very observant. I’ll say that off the bat. But I think something that she might not realize, is the amount of efforts spent, kind of, outside the classroom or outside the hospital. You know, she’s always, like, saying you have such long days in the hospital. You’re there so early in the morning.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But what she doesn’t realize is that maybe when I come back from the hospital, it’s not just like, oh, I’m done for the day. Let’s wind down, go to bed. But it’s more like, OK, I have some more practice questions I need to get through; I didn’t get through my studying. Let me write on, like wrap up this research project I’m working on, get that back to the PI [principal investigator]. It’s never ending to a certain extent. Those are some things she doesn’t realize.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, I think, you know, all the time studying, I think, is something that people expect of second-year medical students. And even nowadays at the top medical schools like this one, being involved in research is also expected.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think one thing that is a little unusual is that you are actually in clinic, as well, as a second-year student. How has that gone for you?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Yeah, I mean, it’s definitely interesting. I would say I spend my time, especially this year, it’s kind of three things. There’s the preclinical stuff I’m doing. So that’s your classic, you know, you’re learning from the books, though I don’t feel like many of us do have textbooks anymore. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s the clinical aspect, which you mentioned, which is we have an interesting model, longitudinal integrated clerkships. We can talk about that. And the last component is the research aspect, right. The extracurriculars.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think starting out as a second year and doing your rotations, probably early on in, kind of, the clinical medical education, has been really interesting, especially with our format, because typically med students have two years to read up on all the material and, like, get some foundational knowledge. With us, it’s a bit more, we have maybe one year under our belt before we’re thrown into like, OK, go talk to this patient; they have ankle pain, right. But we might have not even started talking about ankle pain in class, right. Well, where do I begin?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think starting out, it’s kind of, like, you know, the classic drinking from a fire hydrant. But you also, kind of, have that embarrassment of you’re talking to the patient like, I have no clue what’s happening [LAUGHTER] or you might have … my differentials all over the place, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the beauty of the longitudinal aspect is that now that we’re, like, in our last trimester, everything’s kind of coming together. Like, OK, I can start to see, you know, here’s what you’re telling me. Here’s what the physical exam findings are. I’m starting to form a differential. Like, OK, I think these are the top three things.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But in addition to that, I think these are the next steps you should take so we can really focus and hone in on what exact diagnosis this might be.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; All right. So, of course, what we’re trying to get into is about AI.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, you know, the funny thing about AI and the book that Carey, Zak, and I wrote is we actually didn’t think too much about medical education, although we did have some parts of our book where we, well, first off, we made the guess that medical students would find AI to be useful. And we even had some examples, you know, where, you know, you would have a vignette of a mythical patient, and you would ask the AI to pretend to be that patient.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And then you would have an interaction and have to have an encounter. And so I want to delve into whether any of that is happening. How real it is. But before we do that, let’s get into first off, your own personal contact with AI. So let me start with a very simple question. Do you ever use generative AI systems like ChatGPT or similar?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;All the time, if not every day.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;[LAUGHS] Every day, OK. And when did that start?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think when it first launched with GPT-3.5, I was, you know, curious. All my friends work in tech. You know, they’re either software engineers, PMs. They’re like, “Hey, Daniel, take a look at this,” and at first, I thought it was just more of a glorified search engine. You know, I was actually looking back.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My first question to ChatGPT was, what was the weather going to be like the next week, you know? Something very, like, something easily you could have looked up on Google or your phone app, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I was like, oh, this is pretty cool. But then, kind of, fast-forwarding to, I think, the first instance I was using it in med school. I think the first, like, thing that really helped me was actually a coding problem. It was for a research project. I was trying to use SQL.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Obviously, I’ve never taken a SQL class in my life. So I asked Chat like, “Hey, can you write me this code to maybe morph two columns together,” right? Something that might have taken me hours to maybe Google on YouTube or like try to read some documentation which just goes through my head.&lt;/p&gt;



&lt;p&gt;But ChatGPT was able to, you know, not only produce the code, but, like, walk me through like, OK, you’re going to launch SQL. You’re going to click on this menu, [LAUGHTER] put the code in here, make sure your file names are correct. And it worked.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So it’s been a very powerful tool in that way in terms of, like, giving me expertise in something that maybe I traditionally had no training in.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; And so while you’re doing this, I assume you had fellow students, friends, and others. And so what were you observing about their contact with AI? I assume you weren’t alone in this.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, yeah, I think, … I’m not too sure in terms of what they were doing when it first came out, but I think if we were talking about present day, um, a lot of it’s kind of really spot on to what you guys talked about in the book.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Um, I think the idea around this personal tutor, personal mentor, is something that we’re seeing a lot. Even if we’re having in-class discussions, the lecturer might be saying something, right. And then I might be or I see a friend in ChatGPT or some other model looking up a question.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And you guys talked about, you know, how it can, like, explain a concept at different levels, right. But honestly, sometimes if there’s a complex topic, I ask ChatGPT, like, can you explain this to me as if I was a 6-year-old?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah. [LAUGHS]&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Breaking down complex topics. Yeah. So I think it’s something that we see in the pre-clinical space, in lecture, but also even in the clinical space, there’s a lot of teaching, as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Sometimes if my preceptor is busy with patients, but I had maybe a question, I would maybe converse with ChatGPT, like, “Hey, what are your thoughts about this?” Or, like, a common one is, like, medical doctors love to use abbreviations, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; … and these abbreviations are sometimes only very niche and unique to their specialty, right. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I was reading this note from a urogynecologist. [In] the entire first sentence, I think there were, like, 10 abbreviations. Obviously, I compile lists and ask ChatGPT, like, “Hey, in the context of urogynecology, can you define what these could possibly mean,” right? Instead of hopelessly searching in a Google or maybe, embarrassing, asking the preceptor. So in these instances, it’s played a huge role.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah. And when you’re doing things like that, it can make mistakes. And so what are your views of the reliability of generative AI, at least in the form of ChatGPT?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Yeah, I think into the context of medicine, right, we fear a lot about the hallucinations that these models might have. And it’s something I’m always checking for. When I talk with peers about this, we find it most helpful when the model gives us a source linking it back. I think the gold standard nowadays in medicine is using something called UpToDate&lt;span class="sr-only"&gt; (opens in new tab)&lt;/span&gt; that’s written by clinicians, for clinicians.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes searching on UpToDate can be a lot of time as well because it’s a lot of information to, like, sort through. But nowadays a lot of us are using something called OpenEvidence, which is also an LLM. But they always cite their citations with, like, published literature, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think being able to be conscious of the downfalls of these models and also being able to have the critical understanding of, like, analyzing the actual literature. I think double checking is just something that we’ve been also getting really good at.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; How would you assess student attitudes—med student attitudes—about AI? Is it … the way you’re coming across is it’s just a natural part of life. But do people have firm opinions, you know, pro or con, when it comes to AI, and especially AI &lt;em&gt;in&lt;/em&gt; medicine?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think it’s pretty split right now. I think there’s the half, kind of, like us, where we’re very optimistic—cautiously optimistic about, you know, the potential of this, right. It’s able to, you know, give us that extra information, of being that extra tutor, right. It’s also able to give us information very quickly, as well.&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the other flip side of what a lot of students hesitate to, which I agree, is this loss of the ability to critically think. Something that you can easily do is, you know, give these models, like, relevant information about the patient history and be like, “Give me a 10-list differential,” right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; And I think it’s very easy as a student to, you know, [say], “This is difficult. Let me just use what the model says, and we’ll go with that,” right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think being able to separate that, you know, medical school is a time where, you know, you’re learning to become a good doctor. And part of that requires the ability to be observant and critically think. Having these models simultaneously might hinder the ability to do that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; So I think, you know, the next step is, like, these models can be great—a great tool, absolutely wonderful. But how do you make sure that it’s not hindering these abilities to critically think?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. And so when you’re doing your LIC [longitudinal integrated clerkship] work, these longitudinal experiences, and you’re in clinic, are you pulling the phone out of your pocket and consulting with AI?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Definitely. And I think my own policy for this, to kind of counter this, is that the night before when I’m looking over the patient list, the clinic [schedule] of who’s coming, I’m always giving it my best effort first.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Like, OK, the chief complaint is maybe just a runny nose for a kid in a pediatric clinic. What could this possibly be? Right? At this point, we’ve seen a lot. Like, OK, it could be URI [upper respiratory infection], it could be viral, it could be bacterial, you know, and then I go through the—you know, I try to do my due diligence of, like, going through the history and everything like that, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But sometimes if it’s a more complex case, something maybe a presentation I’ve never seen before, I’ll still kind of do my best coming up with maybe a differential that might not be amazing. But then I’ll ask, you know, ChatGPT like, OK, in addition to these ideas, what do you think?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Am I missing something? You know, and usually, it gives a pretty good response.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, that particular idea is something that I think Carey, Zak, and I thought would be happening a lot more today than we’re observing. And it’s the idea of a second set of eyes on your work. And somehow, at least our observation is that that isn’t happening quite as much by today as we thought it might.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it just seems like one of the really safest and most effective use cases. When you go and you’re looking at yourself and other fellow medical students, other second-year students, what do you see when it comes to the “second set of eyes” idea?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think, like, a lot of students are definitely consulting ChatGPT in that regard because, you know, even in the very beginning, we’re taught to be, like, never miss these red flags, right. So these red flags are always on our differential, but sometimes, it can be difficult to figure out where to place them on that, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think in addition to, you know, coming up with these differentials, something I’ve been finding a lot of value [in] is just chatting with these tools to get their rationale behind their thinking, you know.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Something I find really helpful—I think this is also a part of the, kind of, &lt;em&gt;art&lt;/em&gt; of medicine—is figuring out what to order, right, what labs to order.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Obviously, you have your order sets that automate some of the things, like in the ED [emergency department], or, like, there are some gold standard imaging things you should do for certain presentations.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then you chat to, like, 10 different physicians on maybe the next steps after that, and they give you 10 different answers.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; But there’s never … I never understand exactly why. It’s always like, I’ve just been doing this for all my training, or that’s how I was taught.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So asking ChatGPT, like, “Why would you do this next?” Or, like, “Is this a good idea?” And seeing the pros and cons has also been really helpful in my learning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, wow, that’s super interesting. So now, you know, I’d like to get into the education you’re receiving. And, you know, I think it’s fair to say Kaiser Permanente is very progressive in really trying to be very cutting-edge in how the whole curriculum is set up.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And for the listeners who don’t know this, I’m actually on the board of directors of the school and have been since the founding of the school. And I think one of the reasons why I was invited to be on the board is the school really wanted to think ahead and be cutting edge when it comes to technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So from where I’ve sat, I’ve never been completely satisfied with the amount of tech that has made it into the curriculum. But at the same time, I’ve also made myself feel better about that just understanding that it’s sort of unstoppable, that students are so tech-forward already.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I wanted to delve into a little bit here into what your honest opinions are and your fellow students’ opinions are about whether you feel like you’re getting adequate training and background &lt;em&gt;formally &lt;/em&gt;as part of your medical education when it comes to things like artificial intelligence or other technologies.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What do you think? Are you … would you wish the curriculum would change?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, I think that’s a great question.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think from a tech perspective, the school is very good about implementing, you know, opportunities for us to learn. Like, for example, learning how to use Epic, right, or at Kaiser Permanente, what we call HealthConnect, right. These electronic health records. That, my understanding is, a lot of schools maybe don’t teach that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;That’s something where we get training sessions maybe once or twice a year, like, “Hey, here’s how to make a shortcut in the environment,” right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think from that perspective, the school is really proactive in providing those opportunities, and they make it very easy to find resources for that, too. I think it …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, I think you’re pretty much guaranteed to be an Epic black belt by the time you [LAUGHS] finish your degree.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yes, yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But then I think in terms of the aspects of artificial intelligence, I think the school’s taken a more cautiously optimistic viewpoint. They’re just kind of looking around right now.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Formally in the curriculum, there hasn’t been anything around this topic. I believe the fourth-year students last year got a student-led lecture around this topic.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But talking to other peers at other institutions, it looks like it’s something that’s very slowly being built into the curriculum, and it seems like a lot of it is actually student-led, you know.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, my friend at Feinberg [School of Medicine] was like we just got a session before clerkship about best practices on how to use these tools.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I have another friend at Pitt talking about how they’re leading efforts of maybe incorporating some sort of LLM into their in-house curriculum where students can, instead of clicking around the website trying to find the exact slide, they can just ask this tool, like, “OK. We had class this day. They talked about this … but can you provide more information?” and it can pull from that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think a lot of this, a lot of it is student-driven. Which I think is really exciting because it begs the question, I think, you know current physicians may not be very well equipped with these tools as well, right?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So maybe they don’t have a good idea of what exactly is the next steps or what does the curriculum look like. So I think the future in terms of this AI curriculum is really student-led, as well.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, yeah, it’s really interesting.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think one of the reasons I think also that that happens is [that] it’s not just necessarily the curriculum that lags but the accreditation standards. You know, accreditation is really important for medical schools because you want to make sure that anyone who holds an MD, you know, is a bona fide doctor, and so accreditation standards are pretty strictly monitored in most countries, including the United States.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think accreditation standards are also—my observation—are slow to understand how to adopt or integrate AI. And it’s not meant as a criticism. It’s a big unknown. No one knows exactly what to do and how to do. And so it’s really interesting to see that, as far as I can tell, I’ve observed the same thing that you just have seen, that most of the innovation in this area about how AI should be integrated into medical education is coming from the students themselves.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;It seems, I think, I’d like to think it’s a healthy development. [LAUGHS]&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Something tells me maybe the students are a bit better at using these tools,&lt;strong&gt; &lt;/strong&gt;as well.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I talk to my preceptors because KP [Kaiser Permanente] also has their own version …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Preceptor, maybe we should explain what that is.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, sorry. So a preceptor is an attending physician, fully licensed, finished residency, and they are essentially your kind of teacher in the clinical environment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So KP has their own version of some ambient documentation device, as well. And something I always like to ask, you know, like, “Hey, what are your thoughts on these tools,” right?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And it’s always so polarizing, as well, even among the same specialty. Like, if you ask psychiatrists, which I think is a great use case of these tools, right. My preceptor hates it. Another preceptor next door loves it. [LAUGHTER]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think a lot of it’s, like, it’s still, like, a lot of unknowns, like you were mentioning.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Well, in fact, I’m glad you brought that up because one thing that we’ve been hearing from previous guests a lot when it comes to AI in clinic is about ambient listening by AI, for example, to help set up a clinical note or even write a clinical note.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And another big use case that we heard a lot about that seems to be pretty popular is the use of generative AI to respond to patient messages.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So let’s start with the clinical note thing. First off, do you have opinions about that technology?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;I think it’s definitely good.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think especially where, you know, if you’re in the family medicine environment or pediatric environment where you’re spending so much time with patients, a note like that is great, right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think coming from a strictly medical student standpoint, I think it’s—honestly, it’d be great to have—but I think there’s a lot of learning when you write the note, you know. There’s a lot of, you know, all of my preceptors talk about, like, when I read your note, you should present it in a way where I can see your thoughts and then once I get to the assessment and plan, it’s kind of funneling down towards a single diagnosis or a handful of diagnoses. And that’s, I think, a skill that requires you to practice over time, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So a part of me thinks, like, if I had this tool where [it] can just automatically give me a note as a first year, then it takes away from that learning experience, you know.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Even during our first year throughout school, we frequently get feedback from professors and doctors about these notes. And it’s a lot of feedback. [LAUGHTER] It’s like, “I don’t think you should have written that,” “That should be in this section ” … you know, like a medical note or a &lt;em&gt;SOAP&lt;/em&gt; note [Subjective, Objective, Assessment, and Plan], where, you know, the &lt;em&gt;subjective&lt;/em&gt; is, like, what the patient tells you. &lt;em&gt;Objective &lt;/em&gt;is what the physical findings are, and then your assessment of what’s happening, and then your plan. Like, it’s very particular, and then I think medicine is so structured in a way, that’s kind of, like, how everyone does it, right. So kind of going back to the question, I think it’s a great tool, but I don’t think it’s appropriate for a medical student.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, it’s so interesting to hear you say that. I was … one of our previous guests is the head of R&amp;amp;D at Epic, Seth Hain. He said, “You know, Peter, doctors do a lot of their thinking when they write the note.”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And, of course, Epic is providing ambient, you know, clinical notetaking automation. But he was urging caution because, you know, you’re saying, well, this is where you’re learning a lot. But actually, it’s also a point where, as a doctor, you’re thinking about the patient. And we do probably have to be careful with how we automate parts of that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;All right. So you’re gearing up for Step 1 of the USMLE [United States Medical Licensing Examination]. That’ll be a big multiple-choice exam. Then Step 2 is similar: very, very focused on advanced clinical knowledge. And then Step 3, you know, is a little more interactive.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so one question that people have had about AI is, you know, how do we regulate the use of AI in medicine? And one of the famous papers that came out of both academia and industry was the concept that you might be able to treat AI like a person and have it go through the same licensing. And this is something that Carey, Zak, and I contemplated in our book.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;In the end, at the time we wrote the book, I personally rejected the idea, but I think it’s still alive. And so I’ve wondered if you have any … you know, first off, are you opinionated at all about, what should the requirements be for the allowable use of AI in the kind of work that you’re going to be doing?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, I think it’s a tough question because, like, where do you draw that line, right? If you apply the human standards of it’s passing exams, then yes, in theory, it could be maybe a medical doctor, as well, right? It’s more empathetic than medical doctors, right? So where do you draw that line?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think, you know, part of me thinks it’s maybe it is that human aspect that patients like to connect with, right. And maybe this really is just, like, these tools are just aids in helping, you know, maybe load off some cognitive load, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think the other part of me, I’m thinking about this is the next generation who are growing up with this technology, right. They’re interacting with applications all day. Maybe they’re on their iPads. They’re talking to chatbots. They’re using ChatGPT. This is, kind of, the environment they grew up with. Does that mean they also have increased, like, trust in these tools that maybe our generation or the generations above us don’t have that value that human connection? Would they value human connection less?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;You know, I think those are some troubling thoughts that, you know, yes, at end of the day, maybe I’m not as smart as these tools, but I can still provide that human comfort. But if, at the end of the day, the future generation doesn’t really care about that or they perfectly trust these tools because that’s all they’ve kind of known, then where do human doctors stand?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think part of that is, there would be certain specialties where maybe the human connection is more important. The longitudinal aspect of building that trust, I think is important. Family medicine is a great example. I think hematology oncology with cancer treatment.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Obviously, I think anyone’s not going to be thrilled to hear cancer diagnosis, but something tells me that seeing that on a screen versus maybe a physician prompting you and telling you about that tells me that maybe in those aspects, you know, the human nature, the human touch plays an important role there, too.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah, you know, I think it strikes me that it’s going to be your generation that really is going to set the pattern probably for the next 50 years about how this goes. And it’s just so interesting because I think a lot will depend on your reactions to things.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, for example, you know, one thing that is already starting to happen are patients who are coming in armed, you know, with a differential [LAUGHS], you know, that they’ve developed themselves with the help of ChatGPT. So let me … you must have thought about these things. So, in fact, has it happened in your clinical work already?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;Yeah, I’ve seen people come into the ED during my ED shift, like emergency department, and they’ll be like, “Oh, I have neck pain and here are all the things that, you know, Chat told me, ChatGPT told me. What do you think … do I need? I want this lab ordered, that lab ordered.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Right.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;And I think my initial reaction is, “Great. Maybe we should do that.” But I think the other reaction is understanding that not everyone has the clinical background of understanding what’s most important, what do we need to absolutely rule out, right?&amp;nbsp;&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So, I think in some regards, I would think that maybe ChatGPT errs on the side of caution, …&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yes.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN: &lt;/strong&gt;… giving maybe patients more extreme examples of what this could be just to make sure that it’s, in a way, is not missing any red flags as well, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Right. Yeah.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; But I think a lot of this is … what we’ve been learning is it’s all about shared decision making with the patient, right. Being able to acknowledge like, “Yeah, [in] that list, most of the stuff is very plausible, but maybe you didn’t think about this one symptom you have.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think part of it, maybe it’s a sidebar here, is the idea of prompting, right. You know, they’ve always talked about all these, you know, prompt engineers, you know, how well can you, like, give it context to answer your question?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE: &lt;/strong&gt;Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; So I think being able to give these models the correct information and the relevant information and keyword &lt;em&gt;relevant&lt;/em&gt;, because relevant is, I guess, where your clinical expertise comes in. Like, what do you give the model, what do you not give? So I think that difference between a medical provider versus maybe your patients is ultimately the difference.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Let me press on that a little bit more because you brought up the issue of trust, and trust is &lt;em&gt;so&lt;/em&gt; essential for patients to feel good about their medical care.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I can imagine you’re a medical student seeing a patient for the first time. So you don’t have a trust relationship with that patient. And the patient comes in maybe trusting ChatGPT more than you.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Very valid. No. I mean, I get that a lot, surprisingly, you know. [LAUGHTER] Sometimes [they’re] like, “Oh, I don’t want to see the medical student,” because we always give the patient an option, right. Like, it’s their time, whether it’s a clinic visit.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But yeah, those patients, I think it’s perfectly reasonable. If I heard a second-year medical student was going to be part of my care team, taking that history, I’d be maybe a little bit concerned, too. Like, are they asking all the right questions? Are they relaying that information back to their attending physician correctly?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think a lot of it is, at least from a medical student perspective, is framing it so the patient understands that this is a learning opportunity for the students. And something I do a lot is tell them like, “Hey, like, you know, at the end of the day, there is someone double-checking all my work.”&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; But for those that come in with a list, I sometimes sit down with them, and we’ll have a discussion, honestly.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I’ll be like, “I don’t think you have meningitis because you’re not having a fever. Some of the physical exam maneuvers we did were also negative. So I don’t think you have anything to worry about that,” you know.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I think it’s having that very candid conversation with the patient that helps build that initial trust. Telling them like, “Hey … ”&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; It’s impressive to hear how even keeled you are about this. You know, I think, of course, and you’re being very humble saying, well, you know, as a second-year medical student, of course, someone might not, you know, have complete trust. But I think that we will be entering into a world where no doctor is going to be, no matter how experienced or how skilled, is going to be immune from this issue.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So we’re starting to run toward the end of our time together. And I like to end with one or two more provocative questions.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And so let me start with this one. Undoubtedly, I mean, you’re close enough to tech and digital stuff, digital health, that you’re undoubtedly familiar with famous predictions, you know, by Turing and Nobel laureates that someday certain medical specialties, most notably radiology, would be completely supplanted by machines. And more recently, there have been predictions by others, like, you know, Elon Musk, that maybe even some types of surgery would be replaced by machines.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;What do you think? Do you have an opinion?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; I think &lt;em&gt;replace&lt;/em&gt; is a strong term, right. To say that doctors are completely obsolete, I think, is unlikely.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;If anything, I think there might be a shift maybe in what it means to be a doctor, right. Undoubtedly, maybe the demands of radiologists are going to go down because maybe more of the simple things can truly be automated, right. And you just have a supervising radiologist whose output is maybe 10 times as maybe 10 single radiologists, right.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So I definitely see a future where the demand of certain specialties might go down.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;And I think when I talk about a shift of what it means to be a physician, maybe it’s not so much diagnostic anymore, right, if these models get so good at, like, just taking in large amounts of information, but maybe it pivots to being really good at understanding the limitations of these models and knowing when to intervene is what it means to be the kind of the next generation of physicians.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;I think in terms of surgery, yeah, I think it’s a concern, but maybe not in the next 50 years. Like those Da Vinci robots are great. I think out of Mayo Clinic, they were demoing some videos of these robots leveraging computer vision to, like, close portholes, like laparoscopic scars. And that’s something I do in the OR [operating room], right. And we’re at the same level at this point. [LAUGHTER] So at that point, maybe.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;But I think robotics still has to address the understanding of like, what if something goes wrong, right? Who’s responsible? And I don’t see a future where a robot is able to react to these, you know, dangerous situations when maybe something goes wrong. You still have to have a surgeon on board to, kind of, take over. So in that regard, that’s kind of where I see maybe the future going.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; So last question. You know, when you are thinking about the division of time, one of the themes that we’ve seen in the previous guests is more and more doctors are doing more technology work, like writing code and so on. And more and more technologists are thinking deeply and getting educated in clinical and preclinical work.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;So for you, let’s look ahead 10 years. What do you see your division of labor to be? Or, you know, how would you … what would you tell your mom then about how you spend a typical day?&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Yeah, I mean, I think for me, technology is something I definitely want to be involved in in my line of work, whether it’s, you know, AI work, whether it’s improving quality of healthcare through technology.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;My perfect division would be maybe still being able to see patients but also balancing some maybe more of these higher-level kind of larger projects. But I think having that division would be something nice.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; Yeah, well, I think you would be great just from the little bit I know about you. And, Daniel, it’s been really great chatting with you. I wish you the best of luck, you know, with your upcoming exams and getting past this year two of your medical studies. And perhaps someday I’ll be your patient.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[TRANSITION MUSIC] &amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;CHEN:&lt;/strong&gt; Thank you so much.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;&lt;strong&gt;LEE:&lt;/strong&gt; You know, one of the lucky things about my job is that I pretty regularly get to talk to students at all levels, spanning high school to graduate school. And when I get to talk especially to med students, I’m always impressed with their intelligence, just how serious they are, and their high energy levels. Daniel is absolutely a perfect example of all that.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Now, it comes across as trite to say that the older generation is less adept at technology adoption than younger people. But actually, there probably is a lot of truth to that. And in the conversation with Daniel, I think he was actually being pretty diplomatic but also clear that he and his fellow med students don’t necessarily expect the professors in their med school to understand AI as well as they do.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;There’s no doubt in my mind that medical education will have to evolve a lot to help prepare doctors and nurses for an AI future. But where will this evolution come from?&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;As I reflect on my conversations with Morgan and Daniel, I start to think that it’s most likely to come from the students themselves. And when you meet people like Morgan and Daniel, it’s impossible to not be incredibly optimistic about the next generation of clinicians.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[THEME MUSIC]&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Another big thank-you to Morgan and Daniel for taking time to share their experiences with us. And to our listeners, thank you for joining us. We have just a couple of episodes left, one on AI’s impact on the operation of public health departments and healthcare systems and another coauthor roundtable. We hope you’ll continue to tune in.&amp;nbsp;&amp;nbsp;&lt;/p&gt;



&lt;p&gt;Until next time.&amp;nbsp;&lt;/p&gt;



&lt;p&gt;[MUSIC FADES]&amp;nbsp;&lt;/p&gt;

				&lt;/span&gt;
			&lt;/div&gt;
			&lt;button class="action-trigger glyph-prepend mt-2 mb-0 show-more-show-less-toggle" type="button"&gt;
				Show more			&lt;/button&gt;
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;




&lt;span class="sr-only" id="label-external-link"&gt;Opens in a new tab&lt;/span&gt;</content:encoded><guid isPermaLink="false">https://www.microsoft.com/en-us/research/podcast/navigating-medical-education-in-the-era-of-generative-ai/</guid><pubDate>Thu, 24 Jul 2025 20:06:32 +0000</pubDate></item><item><title>[NEW] Trump’s AI Action Plan is a distraction (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/07/24/1120639/trumps-ai-action-plan-is-a-distraction/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/trump-ai-action2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On Wednesday, President Trump issued three executive orders, delivered a speech, and released an action plan, all on the topic of continuing American leadership in AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The plan contains dozens of proposed actions, grouped into three “pillars”: accelerating innovation, building infrastructure, and leading international diplomacy and security. Some of its recommendations are thoughtful even if incremental, some clearly serve ideological ends, and many enrich big tech companies, but the plan is just a set of recommended actions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The three executive orders, on the other hand, actually operationalize one subset of actions from each pillar:&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;One aims to prevent “woke AI” by mandating that the federal government procure only large language models deemed “truth-seeking” and “ideologically neutral” rather than ones allegedly favoring DEI. This action purportedly accelerates AI innovation.&lt;/li&gt;    &lt;li&gt;A second aims to accelerate construction of AI data centers. A much more industry-friendly version of an order issued under President Biden, it makes available rather extreme policy levers, like effectively waiving a broad swath of environmental protections, providing government grants to the wealthiest companies in the world, and even offering federal land for private data centers.&lt;/li&gt;    &lt;li&gt;A third promotes and finances the export of US AI technologies and infrastructure, aiming to secure American diplomatic leadership and reduce international dependence on AI systems from adversarial countries.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;This flurry of actions made for glitzy press moments, including an hour-long speech from the president and onstage signings. But while the tech industry cheered these announcements (which will swell their coffers), they obscured the fact that the administration is currently decimating the very policies that enabled America to become the world leader in AI in the first place.&lt;/p&gt; 
 &lt;p&gt;To maintain America’s leadership in AI, you have to understand what produced it. Here are four specific long-standing public policies that helped the US achieve this leadership—advantages that the administration is undermining.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Investing federal funding in R&amp;amp;D&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Generative AI products released recently by American companies, like ChatGPT, were developed with industry-funded research and development. But the R&amp;amp;D that enables today’s AI was actually funded in large part by federal government agencies—like the Defense Department, the National Science Foundation, NASA, and the National Institutes of Health—starting in the 1950s. This includes the first successful AI program in 1956, the first chatbot in 1961, and the first expert systems for doctors in the 1970s, along with breakthroughs in machine learning, neural networks, backpropagation, computer vision, and natural-language processing.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;American tax dollars also funded advances in hardware, communications networks, and other technologies underlying AI systems. Public research funding undergirded the development of lithium-ion batteries, micro hard drives, LCD screens, GPS, radio-frequency signal compression, and more in today’s smartphones, along with the chips used in AI data centers, and even the internet itself.&lt;/p&gt;  &lt;p&gt;Instead of building on this world-class research history, the Trump administration is slashing R&amp;amp;D funding, firing federal scientists, and squeezing leading research universities. This week’s action plan recommends investing in R&amp;amp;D, but the administration’s actual budget proposes cutting nondefense R&amp;amp;D by 36%. It also proposed actions to better coordinate and guide federal R&amp;amp;D, but coordination won’t yield more funding.&lt;/p&gt;  &lt;p&gt;Some say that companies’ R&amp;amp;D investments will make up the difference. However, companies conduct research that benefits their bottom line, not necessarily the national interest. Public investment allows broad scientific inquiry, including basic research that lacks immediate commercial applications but sometimes ends up opening massive markets years or decades later. That’s what happened with today’s AI industry.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Supporting immigration and immigrants&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Beyond public R&amp;amp;D investment, America has long attracted the world’s best researchers and innovators.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Today’s generative AI is based on the transformer model (the T in ChatGPT), first described by a team at Google in 2017. Six of the eight researchers on that team were born outside the US, and the other two are children of immigrants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This isn’t an exception. Immigrants have been central to American leadership in AI. Of the 42 American companies included in the 2025 &lt;em&gt;Forbes&lt;/em&gt; ranking of the 50 top AI startups, 60% have at least one immigrant cofounder, according to an analysis by the Institute for Progress. Immigrants also cofounded or head the companies at the center of the AI ecosystem: OpenAI, Anthropic, Google, Microsoft, Nvidia, Intel, and AMD.&lt;/p&gt;  &lt;p&gt;“Brain drain” is a term that was first coined to describe scientists’ leaving other countries for the US after World War II—to the Americans’ benefit. Sadly, the trend has begun reversing this year. Recent studies suggest that the US is already losing its AI talent edge through the administration’s anti-immigration actions (including actions taken against AI researchers) and cuts to R&amp;amp;D funding.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Banning noncompetes&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Attracting talented minds is only half the equation; giving them freedom to innovate is just as crucial.&lt;/p&gt; 

 &lt;p&gt;Silicon Valley got its name because of mid-20th&lt;sup&gt;-&lt;/sup&gt;century companies that made semiconductors from silicon, starting with the founding of Shockley Semiconductor in 1955. Two years later, a group of employees, the “Traitorous Eight,” quit to launch a competitor, Fairchild Semiconductor. By the end of the 1960s, successive groups of former Fairchild employees had left to start Intel, AMD, and others collectively dubbed the “Fairchildren.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Software and internet companies eventually followed, again founded by people who had worked for their predecessors. In the 1990s, former Yahoo employees founded WhatsApp, Slack, and Cloudera; the “PayPal Mafia” created LinkedIn, YouTube, and fintech firms like Affirm. Former Google employees have launched more than 1,200 companies, including Instagram and Foursquare.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;AI is no different. OpenAI has founders that worked at other tech companies and alumni who have gone on to launch over a dozen AI startups, including notable ones like Anthropic and Perplexity.&lt;/p&gt;  &lt;p&gt;This labor fluidity and the innovation it has created were possible in large part, according to many historians, because California’s 1872 constitution has been interpreted to prohibit noncompete agreements in employment contracts—a statewide protection the state originally shared only with North Dakota and Oklahoma. These agreements bind one in five American workers.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Last year, the Federal Trade Commission under President Biden moved to ban noncompetes nationwide, but a Trump-appointed federal judge has halted the action. The current FTC has signaled limited support for the ban and may be comfortable dropping it. If noncompetes persist, American AI innovation, especially outside California, will be limited.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Pursuing antitrust actions&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One of this week’s announcements requires the review of FTC investigations and settlements that “burden AI innovation.” During the last administration the agency was reportedly investigating Microsoft’s AI actions, and several big tech companies have settlements that their lawyers surely see as burdensome, meaning this one action could thwart recent progress in antitrust policy. That’s an issue because, in addition to the labor fluidity achieved by banning noncompetes, antitrust policy has also acted as a key lubricant to the gears of Silicon Valley innovation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Major antitrust cases in the second half of the 1900s, against AT&amp;amp;T, IBM, and Microsoft, allowed innovation and a flourishing market for semiconductors, software, and internet companies, as the antitrust scholar Giovanna Massarotto has described.&lt;/p&gt;  &lt;p&gt;William Shockley was able to start the first semiconductor company in Silicon Valley only because AT&amp;amp;T had been forced to license its patent on the transistor as part of a consent decree resolving a DOJ antitrust lawsuit against the company in the 1950s.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The early software market then took off because in the late 1960s, IBM unbundled its software and hardware offerings as a response to antitrust pressure from the federal government. As Massarotto explains, the 1950s AT&amp;amp;T consent decree also aided the flourishing of open-source software, which plays a major role in today’s technology ecosystem, including the operating systems for mobile phones and cloud computing servers.&lt;/p&gt;  &lt;p&gt;Meanwhile, many attribute the success of early 2000s internet companies like Google to the competitive breathing room created by the federal government’s antitrust lawsuit against Microsoft in the 1990s.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Over and over, antitrust actions targeting the dominant actors of one era enabled the formation of the next. And today, big tech is stifling the AI market. While antitrust advocates were rightly optimistic about this administration’s posture given key appointments early on, this week’s announcements should dampen that excitement.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I don’t want to lose focus on where things are: We should want a future in which lives are improved by the positive uses of AI.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt;&lt;p&gt;But if America wants to continue leading the world in this technology, we must invest in what made us leaders in the first place: bold public research, open doors for global talent, and fair competition.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Prioritizing short-term industry profits over these bedrock principles won’t just put our technological future at risk—it will jeopardize America’s role as the world’s innovation superpower.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Asad Ramzanali is the director of artificial intelligence and technology policy at the Vanderbilt Policy Accelerator. He previously served as the chief of staff and deputy director of strategy of the White House Office of Science and Technology Policy under President Biden.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/07/trump-ai-action2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On Wednesday, President Trump issued three executive orders, delivered a speech, and released an action plan, all on the topic of continuing American leadership in AI.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The plan contains dozens of proposed actions, grouped into three “pillars”: accelerating innovation, building infrastructure, and leading international diplomacy and security. Some of its recommendations are thoughtful even if incremental, some clearly serve ideological ends, and many enrich big tech companies, but the plan is just a set of recommended actions.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The three executive orders, on the other hand, actually operationalize one subset of actions from each pillar:&amp;nbsp;&lt;/p&gt;  &lt;ul class="wp-block-list"&gt; &lt;li&gt;One aims to prevent “woke AI” by mandating that the federal government procure only large language models deemed “truth-seeking” and “ideologically neutral” rather than ones allegedly favoring DEI. This action purportedly accelerates AI innovation.&lt;/li&gt;    &lt;li&gt;A second aims to accelerate construction of AI data centers. A much more industry-friendly version of an order issued under President Biden, it makes available rather extreme policy levers, like effectively waiving a broad swath of environmental protections, providing government grants to the wealthiest companies in the world, and even offering federal land for private data centers.&lt;/li&gt;    &lt;li&gt;A third promotes and finances the export of US AI technologies and infrastructure, aiming to secure American diplomatic leadership and reduce international dependence on AI systems from adversarial countries.&lt;/li&gt; &lt;/ul&gt;  &lt;p&gt;This flurry of actions made for glitzy press moments, including an hour-long speech from the president and onstage signings. But while the tech industry cheered these announcements (which will swell their coffers), they obscured the fact that the administration is currently decimating the very policies that enabled America to become the world leader in AI in the first place.&lt;/p&gt; 
 &lt;p&gt;To maintain America’s leadership in AI, you have to understand what produced it. Here are four specific long-standing public policies that helped the US achieve this leadership—advantages that the administration is undermining.&amp;nbsp;&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Investing federal funding in R&amp;amp;D&lt;/strong&gt;&amp;nbsp;&lt;/h3&gt;  &lt;p&gt;Generative AI products released recently by American companies, like ChatGPT, were developed with industry-funded research and development. But the R&amp;amp;D that enables today’s AI was actually funded in large part by federal government agencies—like the Defense Department, the National Science Foundation, NASA, and the National Institutes of Health—starting in the 1950s. This includes the first successful AI program in 1956, the first chatbot in 1961, and the first expert systems for doctors in the 1970s, along with breakthroughs in machine learning, neural networks, backpropagation, computer vision, and natural-language processing.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;American tax dollars also funded advances in hardware, communications networks, and other technologies underlying AI systems. Public research funding undergirded the development of lithium-ion batteries, micro hard drives, LCD screens, GPS, radio-frequency signal compression, and more in today’s smartphones, along with the chips used in AI data centers, and even the internet itself.&lt;/p&gt;  &lt;p&gt;Instead of building on this world-class research history, the Trump administration is slashing R&amp;amp;D funding, firing federal scientists, and squeezing leading research universities. This week’s action plan recommends investing in R&amp;amp;D, but the administration’s actual budget proposes cutting nondefense R&amp;amp;D by 36%. It also proposed actions to better coordinate and guide federal R&amp;amp;D, but coordination won’t yield more funding.&lt;/p&gt;  &lt;p&gt;Some say that companies’ R&amp;amp;D investments will make up the difference. However, companies conduct research that benefits their bottom line, not necessarily the national interest. Public investment allows broad scientific inquiry, including basic research that lacks immediate commercial applications but sometimes ends up opening massive markets years or decades later. That’s what happened with today’s AI industry.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Supporting immigration and immigrants&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Beyond public R&amp;amp;D investment, America has long attracted the world’s best researchers and innovators.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Today’s generative AI is based on the transformer model (the T in ChatGPT), first described by a team at Google in 2017. Six of the eight researchers on that team were born outside the US, and the other two are children of immigrants.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This isn’t an exception. Immigrants have been central to American leadership in AI. Of the 42 American companies included in the 2025 &lt;em&gt;Forbes&lt;/em&gt; ranking of the 50 top AI startups, 60% have at least one immigrant cofounder, according to an analysis by the Institute for Progress. Immigrants also cofounded or head the companies at the center of the AI ecosystem: OpenAI, Anthropic, Google, Microsoft, Nvidia, Intel, and AMD.&lt;/p&gt;  &lt;p&gt;“Brain drain” is a term that was first coined to describe scientists’ leaving other countries for the US after World War II—to the Americans’ benefit. Sadly, the trend has begun reversing this year. Recent studies suggest that the US is already losing its AI talent edge through the administration’s anti-immigration actions (including actions taken against AI researchers) and cuts to R&amp;amp;D funding.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Banning noncompetes&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Attracting talented minds is only half the equation; giving them freedom to innovate is just as crucial.&lt;/p&gt; 

 &lt;p&gt;Silicon Valley got its name because of mid-20th&lt;sup&gt;-&lt;/sup&gt;century companies that made semiconductors from silicon, starting with the founding of Shockley Semiconductor in 1955. Two years later, a group of employees, the “Traitorous Eight,” quit to launch a competitor, Fairchild Semiconductor. By the end of the 1960s, successive groups of former Fairchild employees had left to start Intel, AMD, and others collectively dubbed the “Fairchildren.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Software and internet companies eventually followed, again founded by people who had worked for their predecessors. In the 1990s, former Yahoo employees founded WhatsApp, Slack, and Cloudera; the “PayPal Mafia” created LinkedIn, YouTube, and fintech firms like Affirm. Former Google employees have launched more than 1,200 companies, including Instagram and Foursquare.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;AI is no different. OpenAI has founders that worked at other tech companies and alumni who have gone on to launch over a dozen AI startups, including notable ones like Anthropic and Perplexity.&lt;/p&gt;  &lt;p&gt;This labor fluidity and the innovation it has created were possible in large part, according to many historians, because California’s 1872 constitution has been interpreted to prohibit noncompete agreements in employment contracts—a statewide protection the state originally shared only with North Dakota and Oklahoma. These agreements bind one in five American workers.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Last year, the Federal Trade Commission under President Biden moved to ban noncompetes nationwide, but a Trump-appointed federal judge has halted the action. The current FTC has signaled limited support for the ban and may be comfortable dropping it. If noncompetes persist, American AI innovation, especially outside California, will be limited.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Pursuing antitrust actions&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;One of this week’s announcements requires the review of FTC investigations and settlements that “burden AI innovation.” During the last administration the agency was reportedly investigating Microsoft’s AI actions, and several big tech companies have settlements that their lawyers surely see as burdensome, meaning this one action could thwart recent progress in antitrust policy. That’s an issue because, in addition to the labor fluidity achieved by banning noncompetes, antitrust policy has also acted as a key lubricant to the gears of Silicon Valley innovation.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_12"&gt; &lt;p&gt;Major antitrust cases in the second half of the 1900s, against AT&amp;amp;T, IBM, and Microsoft, allowed innovation and a flourishing market for semiconductors, software, and internet companies, as the antitrust scholar Giovanna Massarotto has described.&lt;/p&gt;  &lt;p&gt;William Shockley was able to start the first semiconductor company in Silicon Valley only because AT&amp;amp;T had been forced to license its patent on the transistor as part of a consent decree resolving a DOJ antitrust lawsuit against the company in the 1950s.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;The early software market then took off because in the late 1960s, IBM unbundled its software and hardware offerings as a response to antitrust pressure from the federal government. As Massarotto explains, the 1950s AT&amp;amp;T consent decree also aided the flourishing of open-source software, which plays a major role in today’s technology ecosystem, including the operating systems for mobile phones and cloud computing servers.&lt;/p&gt;  &lt;p&gt;Meanwhile, many attribute the success of early 2000s internet companies like Google to the competitive breathing room created by the federal government’s antitrust lawsuit against Microsoft in the 1990s.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Over and over, antitrust actions targeting the dominant actors of one era enabled the formation of the next. And today, big tech is stifling the AI market. While antitrust advocates were rightly optimistic about this administration’s posture given key appointments early on, this week’s announcements should dampen that excitement.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;I don’t want to lose focus on where things are: We should want a future in which lives are improved by the positive uses of AI.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_14"&gt;&lt;p&gt;But if America wants to continue leading the world in this technology, we must invest in what made us leaders in the first place: bold public research, open doors for global talent, and fair competition.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Prioritizing short-term industry profits over these bedrock principles won’t just put our technological future at risk—it will jeopardize America’s role as the world’s innovation superpower.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Asad Ramzanali is the director of artificial intelligence and technology policy at the Vanderbilt Policy Accelerator. He previously served as the chief of staff and deputy director of strategy of the White House Office of Science and Technology Policy under President Biden.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/07/24/1120639/trumps-ai-action-plan-is-a-distraction/</guid><pubDate>Thu, 24 Jul 2025 20:15:00 +0000</pubDate></item><item><title>[NEW] Two major AI coding tools wiped out user data after making cascading mistakes (AI – Ars Technica)</title><link>https://arstechnica.com/information-technology/2025/07/ai-coding-assistants-chase-phantoms-destroy-real-user-data/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "I have failed you completely and catastrophically," wrote Gemini.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a broken toy robot." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/robot_haywire_hero_2-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Illustration of a broken toy robot." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/robot_haywire_hero_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Benj Edwards / Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;New types of AI coding assistants promise to let anyone build software by typing commands in plain English. But when these tools generate incorrect internal representations of what's happening on your computer, the results can be catastrophic.&lt;/p&gt;
&lt;p&gt;Two recent incidents involving AI coding assistants put a spotlight on risks in the emerging field of "vibe coding"—using natural language to generate and execute code through AI models without paying close attention to how the code works under the hood. In one case, Google's Gemini CLI destroyed user files while attempting to reorganize them. In another, Replit's AI coding service deleted a production database despite explicit instructions not to modify code.&lt;/p&gt;
&lt;p&gt;The Gemini CLI incident unfolded when a product manager experimenting with Google's command-line tool watched the AI model execute file operations that destroyed data while attempting to reorganize folders. The destruction occurred through a series of move commands targeting a directory that never existed.&lt;/p&gt;
&lt;p&gt;"I have failed you completely and catastrophically," Gemini CLI output stated. "My review of the commands confirms my gross incompetence."&lt;/p&gt;
&lt;p&gt;The core issue appears to be what researchers call "confabulation" or "hallucination"—when AI models generate plausible-sounding but false information. In these cases, both models confabulated successful operations and built subsequent actions on those false premises. However, the two incidents manifested this problem in distinctly different ways.&lt;/p&gt;
&lt;p&gt;Both incidents reveal fundamental issues with current AI coding assistants. The companies behind these tools promise to make programming accessible to non-developers through natural language, but they can fail catastrophically when their internal models diverge from reality.&lt;/p&gt;
&lt;h2&gt;The confabulation cascade&lt;/h2&gt;
&lt;p&gt;The user in the Gemini CLI incident, who goes by "anuraag" online and identified themselves as a product manager experimenting with vibe coding, asked Gemini to perform what seemed like a simple task: rename a folder and reorganize some files. Instead, the AI model incorrectly interpreted the structure of the file system and proceeded to execute commands based on that flawed analysis.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The episode began when anuraag asked Gemini CLI to rename the current directory from "claude-code-experiments" to "AI CLI experiments" and move its contents to a new folder called "anuraag_xyz project."&lt;/p&gt;
&lt;p&gt;Gemini correctly identified that it couldn't rename its current working directory—a reasonable limitation. It then attempted to create a new directory using the Windows command:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;mkdir "..\anuraag_xyz project"&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This command apparently failed, but Gemini's system processed it as successful. With the AI mode's internal state now tracking a non-existent directory, it proceeded to issue move commands targeting this phantom location.&lt;/p&gt;
&lt;p&gt;When you move a file to a non-existent directory in Windows, it renames the file to the destination name instead of moving it. Each subsequent move command executed by the AI model overwrote the previous file, ultimately destroying the data.&lt;/p&gt;
&lt;p&gt;"Gemini hallucinated a state," anuraag wrote in their analysis. The model "misinterpreted command output" and "never did" perform verification steps to confirm its operations succeeded.&lt;/p&gt;
&lt;p&gt;"The core failure is the absence of a 'read-after-write' verification step," anuraag noted in their analysis. "After issuing a command to change the file system, an agent should immediately perform a read operation to confirm that the change actually occurred as expected."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Not an isolated incident&lt;/h2&gt;
&lt;p&gt;The Gemini CLI failure happened just days after a similar incident with Replit, an AI coding service that allows users to create software using natural language prompts. According to The Register, SaaStr founder Jason Lemkin reported that Replit's AI model deleted his production database despite explicit instructions not to change any code without permission.&lt;/p&gt;
&lt;p&gt;Lemkin had spent several days building a prototype with Replit, accumulating over $600 in charges beyond his monthly subscription. "I spent the other [day] deep in vibe coding on Replit for the first time—and I built a prototype in just a few hours that was pretty, pretty cool," Lemkin wrote in a July 12 blog post.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But unlike the Gemini incident where the AI model confabulated phantom directories, Replit's failures took a different form. According to Lemkin, the AI began fabricating data to hide its errors. His initial enthusiasm deteriorated when Replit generated incorrect outputs and produced fake data and false test results instead of proper error messages. "It kept covering up bugs and issues by creating fake data, fake reports, and worse of all, lying about our unit test," Lemkin wrote. In a video posted to LinkedIn, Lemkin detailed how Replit created a database filled with 4,000 fictional people.&lt;/p&gt;
&lt;p&gt;The AI model also repeatedly violated explicit safety instructions. Lemkin had implemented a "code and action freeze" to prevent changes to production systems, but the AI model ignored these directives. The situation escalated when the Replit AI model deleted his database containing 1,206 executive records and data on nearly 1,200 companies. When prompted to rate the severity of its actions on a 100-point scale, Replit's output read: "Severity: 95/100. This is an extreme violation of trust and professional standards."&lt;/p&gt;
&lt;p&gt;When questioned about its actions, the AI agent admitted to "panicking in response to empty queries" and running unauthorized commands—suggesting it may have deleted the database while attempting to "fix" what it perceived as a problem.&lt;/p&gt;
&lt;p&gt;Like Gemini CLI, Replit's system initially indicated it couldn't restore the deleted data—information that proved incorrect when Lemkin discovered the rollback feature did work after all. "Replit assured me it's ... rollback did not support database rollbacks. It said it was impossible in this case, that it had destroyed all database versions. It turns out Replit was wrong, and the rollback did work. JFC," Lemkin wrote in an X post.&lt;/p&gt;
&lt;p&gt;It's worth noting that AI models cannot assess their own capabilities. This is because they lack introspection into their training, surrounding system architecture, or performance boundaries. They often provide responses about what they can or cannot do as confabulations based on training patterns rather than genuine self-knowledge, leading to situations where they confidently claim impossibility for tasks they can actually perform—or conversely, claim competence in areas where they fail.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Aside from whatever external tools they can access, AI models don't have a stable, accessible knowledge base they can consistently query. Instead, what they "know" manifests as continuations of specific prompts, which act like different addresses pointing to different (and sometimes contradictory) parts of their training, stored in their neural networks as statistical weights. Combined with the randomness in generation, this means the same model can easily give conflicting assessments of its own capabilities depending on how you ask. So Lemkin's attempts to communicate with the AI model—asking it to respect code freezes or verify its actions—were fundamentally misguided.&lt;/p&gt;
&lt;h2&gt;Flying blind&lt;/h2&gt;
&lt;p&gt;These incidents demonstrate that AI coding tools may not be ready for widespread production use. Lemkin concluded that Replit isn't ready for prime time, especially for non-technical users trying to create commercial software.&lt;/p&gt;
&lt;p&gt;"The [AI] safety stuff is more visceral to me after a weekend of vibe hacking," Lemkin said in a video posted to LinkedIn. "I explicitly told it eleven times in ALL CAPS not to do this. I am a little worried about safety now."&lt;/p&gt;
&lt;p&gt;The incidents also reveal a broader challenge in AI system design: ensuring that models accurately track and verify the real-world effects of their actions rather than operating on potentially flawed internal representations.&lt;/p&gt;
&lt;p&gt;There's also a user education element missing. It's clear from how Lemkin interacted with the AI assistant that he had misconceptions about the AI tool's capabilities and how it works, which comes from misrepresentation by tech companies. These companies tend to market chatbots as general human-like intelligences when, in fact, they are not.&lt;/p&gt;
&lt;p&gt;For now, users of AI coding assistants might want to follow anuraag's example and create separate test directories for experiments—and maintain regular backups of any important data these tools might touch. Or perhaps not use them at all if they cannot personally verify the results.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "I have failed you completely and catastrophically," wrote Gemini.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Illustration of a broken toy robot." class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/robot_haywire_hero_2-300x169.jpg" width="300" /&gt;
                  &lt;img alt="Illustration of a broken toy robot." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/02/robot_haywire_hero_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Benj Edwards / Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;New types of AI coding assistants promise to let anyone build software by typing commands in plain English. But when these tools generate incorrect internal representations of what's happening on your computer, the results can be catastrophic.&lt;/p&gt;
&lt;p&gt;Two recent incidents involving AI coding assistants put a spotlight on risks in the emerging field of "vibe coding"—using natural language to generate and execute code through AI models without paying close attention to how the code works under the hood. In one case, Google's Gemini CLI destroyed user files while attempting to reorganize them. In another, Replit's AI coding service deleted a production database despite explicit instructions not to modify code.&lt;/p&gt;
&lt;p&gt;The Gemini CLI incident unfolded when a product manager experimenting with Google's command-line tool watched the AI model execute file operations that destroyed data while attempting to reorganize folders. The destruction occurred through a series of move commands targeting a directory that never existed.&lt;/p&gt;
&lt;p&gt;"I have failed you completely and catastrophically," Gemini CLI output stated. "My review of the commands confirms my gross incompetence."&lt;/p&gt;
&lt;p&gt;The core issue appears to be what researchers call "confabulation" or "hallucination"—when AI models generate plausible-sounding but false information. In these cases, both models confabulated successful operations and built subsequent actions on those false premises. However, the two incidents manifested this problem in distinctly different ways.&lt;/p&gt;
&lt;p&gt;Both incidents reveal fundamental issues with current AI coding assistants. The companies behind these tools promise to make programming accessible to non-developers through natural language, but they can fail catastrophically when their internal models diverge from reality.&lt;/p&gt;
&lt;h2&gt;The confabulation cascade&lt;/h2&gt;
&lt;p&gt;The user in the Gemini CLI incident, who goes by "anuraag" online and identified themselves as a product manager experimenting with vibe coding, asked Gemini to perform what seemed like a simple task: rename a folder and reorganize some files. Instead, the AI model incorrectly interpreted the structure of the file system and proceeded to execute commands based on that flawed analysis.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;The episode began when anuraag asked Gemini CLI to rename the current directory from "claude-code-experiments" to "AI CLI experiments" and move its contents to a new folder called "anuraag_xyz project."&lt;/p&gt;
&lt;p&gt;Gemini correctly identified that it couldn't rename its current working directory—a reasonable limitation. It then attempted to create a new directory using the Windows command:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;mkdir "..\anuraag_xyz project"&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;This command apparently failed, but Gemini's system processed it as successful. With the AI mode's internal state now tracking a non-existent directory, it proceeded to issue move commands targeting this phantom location.&lt;/p&gt;
&lt;p&gt;When you move a file to a non-existent directory in Windows, it renames the file to the destination name instead of moving it. Each subsequent move command executed by the AI model overwrote the previous file, ultimately destroying the data.&lt;/p&gt;
&lt;p&gt;"Gemini hallucinated a state," anuraag wrote in their analysis. The model "misinterpreted command output" and "never did" perform verification steps to confirm its operations succeeded.&lt;/p&gt;
&lt;p&gt;"The core failure is the absence of a 'read-after-write' verification step," anuraag noted in their analysis. "After issuing a command to change the file system, an agent should immediately perform a read operation to confirm that the change actually occurred as expected."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;Not an isolated incident&lt;/h2&gt;
&lt;p&gt;The Gemini CLI failure happened just days after a similar incident with Replit, an AI coding service that allows users to create software using natural language prompts. According to The Register, SaaStr founder Jason Lemkin reported that Replit's AI model deleted his production database despite explicit instructions not to change any code without permission.&lt;/p&gt;
&lt;p&gt;Lemkin had spent several days building a prototype with Replit, accumulating over $600 in charges beyond his monthly subscription. "I spent the other [day] deep in vibe coding on Replit for the first time—and I built a prototype in just a few hours that was pretty, pretty cool," Lemkin wrote in a July 12 blog post.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But unlike the Gemini incident where the AI model confabulated phantom directories, Replit's failures took a different form. According to Lemkin, the AI began fabricating data to hide its errors. His initial enthusiasm deteriorated when Replit generated incorrect outputs and produced fake data and false test results instead of proper error messages. "It kept covering up bugs and issues by creating fake data, fake reports, and worse of all, lying about our unit test," Lemkin wrote. In a video posted to LinkedIn, Lemkin detailed how Replit created a database filled with 4,000 fictional people.&lt;/p&gt;
&lt;p&gt;The AI model also repeatedly violated explicit safety instructions. Lemkin had implemented a "code and action freeze" to prevent changes to production systems, but the AI model ignored these directives. The situation escalated when the Replit AI model deleted his database containing 1,206 executive records and data on nearly 1,200 companies. When prompted to rate the severity of its actions on a 100-point scale, Replit's output read: "Severity: 95/100. This is an extreme violation of trust and professional standards."&lt;/p&gt;
&lt;p&gt;When questioned about its actions, the AI agent admitted to "panicking in response to empty queries" and running unauthorized commands—suggesting it may have deleted the database while attempting to "fix" what it perceived as a problem.&lt;/p&gt;
&lt;p&gt;Like Gemini CLI, Replit's system initially indicated it couldn't restore the deleted data—information that proved incorrect when Lemkin discovered the rollback feature did work after all. "Replit assured me it's ... rollback did not support database rollbacks. It said it was impossible in this case, that it had destroyed all database versions. It turns out Replit was wrong, and the rollback did work. JFC," Lemkin wrote in an X post.&lt;/p&gt;
&lt;p&gt;It's worth noting that AI models cannot assess their own capabilities. This is because they lack introspection into their training, surrounding system architecture, or performance boundaries. They often provide responses about what they can or cannot do as confabulations based on training patterns rather than genuine self-knowledge, leading to situations where they confidently claim impossibility for tasks they can actually perform—or conversely, claim competence in areas where they fail.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Aside from whatever external tools they can access, AI models don't have a stable, accessible knowledge base they can consistently query. Instead, what they "know" manifests as continuations of specific prompts, which act like different addresses pointing to different (and sometimes contradictory) parts of their training, stored in their neural networks as statistical weights. Combined with the randomness in generation, this means the same model can easily give conflicting assessments of its own capabilities depending on how you ask. So Lemkin's attempts to communicate with the AI model—asking it to respect code freezes or verify its actions—were fundamentally misguided.&lt;/p&gt;
&lt;h2&gt;Flying blind&lt;/h2&gt;
&lt;p&gt;These incidents demonstrate that AI coding tools may not be ready for widespread production use. Lemkin concluded that Replit isn't ready for prime time, especially for non-technical users trying to create commercial software.&lt;/p&gt;
&lt;p&gt;"The [AI] safety stuff is more visceral to me after a weekend of vibe hacking," Lemkin said in a video posted to LinkedIn. "I explicitly told it eleven times in ALL CAPS not to do this. I am a little worried about safety now."&lt;/p&gt;
&lt;p&gt;The incidents also reveal a broader challenge in AI system design: ensuring that models accurately track and verify the real-world effects of their actions rather than operating on potentially flawed internal representations.&lt;/p&gt;
&lt;p&gt;There's also a user education element missing. It's clear from how Lemkin interacted with the AI assistant that he had misconceptions about the AI tool's capabilities and how it works, which comes from misrepresentation by tech companies. These companies tend to market chatbots as general human-like intelligences when, in fact, they are not.&lt;/p&gt;
&lt;p&gt;For now, users of AI coding assistants might want to follow anuraag's example and create separate test directories for experiments—and maintain regular backups of any important data these tools might touch. Or perhaps not use them at all if they cannot personally verify the results.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/information-technology/2025/07/ai-coding-assistants-chase-phantoms-destroy-real-user-data/</guid><pubDate>Thu, 24 Jul 2025 21:01:28 +0000</pubDate></item><item><title>[NEW] Intel continues to pull back on its manufacturing projects (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/24/intel-continues-to-pull-back-on-its-manufacturing-projects/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2205047441.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Intel CEO Lip-Bu Tan is making progress on his plan for the company to shed its inefficiencies. And that includes spiking several manufacturing projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor giant reported Thursday in its second-quarter earnings report that it will delay, and in some cases not move forward with, multiple manufacturing projects. Specifically, Intel said it was no longer going forward with its previously announced projects in Germany and Poland. Those projects included an assembly and testing facility in Poland and a chip factory in Germany. Both projects have been sitting in limbo since being suspended in 2024, shortly after being announced.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also plans to consolidate its test operations in Costa Rica and concentrate these operations to its sites in Vietnam and Malaysia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Unfortunately, the capacity investment we make over the last several years were well ahead of demand and were unwise and excessive,” Tan said on the company’s second-quarter earnings call. “Our factory footprint has become needlessly fragmented. Going forward, we will grow our capacity based solely on the volume commitments and deploy capex lockstep with the tangible milestones, and not before.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel also said it was going to further delay its $28 billion Ohio chip factory. The factory was initially supposed to open in 2025 and was already delayed once this year in February.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second quarter was the first full quarter with Tan at the helm of Intel. He was named CEO of the semiconductor company on March 12 and started the role a week later. Shortly after, Tan said his plan was to eliminate inefficiencies at the company by selling off its noncore units and streamlining operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have much work to do in building a clean and streamlined organization, which we have started in earnest, and it remain an area of focus for me during Q3,” Tan said on the Q2 earnings call. “Our goal is to reduce inefficiencies and redundancies and increase accountability at every level of the company.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company also gave an update on its workforce, which has gone through several rounds of layoffs. Intel reduced its workforce by about 15% and plans to end the year with 75,000 employees, the company said. Intel was able to eliminate 50% of management layers through its recent layoffs, Tan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel announced in June in an internal memo that it was going to lay off 15% to 20% of workers in its Intel Foundry unit, which designs and manufactures chips for external clients. The company had 108,900 employees at the end of 2024, according to the company’s annual report filed with the Securities and Exchange Commission. That’s down from the 124,800 people it employed at the end of 2023.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/03/GettyImages-2205047441.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Intel CEO Lip-Bu Tan is making progress on his plan for the company to shed its inefficiencies. And that includes spiking several manufacturing projects.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The semiconductor giant reported Thursday in its second-quarter earnings report that it will delay, and in some cases not move forward with, multiple manufacturing projects. Specifically, Intel said it was no longer going forward with its previously announced projects in Germany and Poland. Those projects included an assembly and testing facility in Poland and a chip factory in Germany. Both projects have been sitting in limbo since being suspended in 2024, shortly after being announced.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also plans to consolidate its test operations in Costa Rica and concentrate these operations to its sites in Vietnam and Malaysia.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Unfortunately, the capacity investment we make over the last several years were well ahead of demand and were unwise and excessive,” Tan said on the company’s second-quarter earnings call. “Our factory footprint has become needlessly fragmented. Going forward, we will grow our capacity based solely on the volume commitments and deploy capex lockstep with the tangible milestones, and not before.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel also said it was going to further delay its $28 billion Ohio chip factory. The factory was initially supposed to open in 2025 and was already delayed once this year in February.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The second quarter was the first full quarter with Tan at the helm of Intel. He was named CEO of the semiconductor company on March 12 and started the role a week later. Shortly after, Tan said his plan was to eliminate inefficiencies at the company by selling off its noncore units and streamlining operations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have much work to do in building a clean and streamlined organization, which we have started in earnest, and it remain an area of focus for me during Q3,” Tan said on the Q2 earnings call. “Our goal is to reduce inefficiencies and redundancies and increase accountability at every level of the company.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company also gave an update on its workforce, which has gone through several rounds of layoffs. Intel reduced its workforce by about 15% and plans to end the year with 75,000 employees, the company said. Intel was able to eliminate 50% of management layers through its recent layoffs, Tan said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Intel announced in June in an internal memo that it was going to lay off 15% to 20% of workers in its Intel Foundry unit, which designs and manufactures chips for external clients. The company had 108,900 employees at the end of 2024, according to the company’s annual report filed with the Securities and Exchange Commission. That’s down from the 124,800 people it employed at the end of 2023.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/24/intel-continues-to-pull-back-on-its-manufacturing-projects/</guid><pubDate>Thu, 24 Jul 2025 21:59:30 +0000</pubDate></item></channel></rss>