<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Sat, 14 Feb 2026 02:21:35 +0000</lastBuildDate><item><title>I spent two days gigging at RentAHuman and didn't make a single cent (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/02/i-spent-two-days-gigging-at-rentahuman-and-didnt-make-a-single-cent/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        These bots supposedly need a human body to accomplish great things in meatspace.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An inflatable tube man, or sky puppet dancer, frolics in the sky over an event in Camarillo, California. The inflatable male figure wears dark sunglasses, a white long-sleeved dress shirt, dark tie and dark dress pants." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/inflatableman-640x427.jpg" width="640" /&gt;
                  &lt;img alt="An inflatable tube man, or sky puppet dancer, frolics in the sky over an event in Camarillo, California. The inflatable male figure wears dark sunglasses, a white long-sleeved dress shirt, dark tie and dark dress pants." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/inflatableman-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Patricia Marroquin via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;I’m not above doing some gig work to make ends meet. In my life, I’ve worked snack food pop-ups in a grocery store, ran the cash register for random merch booths, and even hawked my own plasma at $35 per vial.&lt;/p&gt;
&lt;p&gt;So, when I saw RentAHuman, a new site where AI agents hire humans to perform physical work in the real world on behalf of the virtual bots, I was eager to see how these AI overlords would compare to my past experiences with the gig economy.&lt;/p&gt;
&lt;p&gt;Launched in early February, RentAHuman was developed by software engineer Alexander Liteplo and his cofounder, Patricia Tani. The site looks like a bare-bones version of other well-known freelance sites like Fiverr and UpWork.&lt;/p&gt;
&lt;p&gt;The site’s homepage declares that these bots need your physical body to complete tasks, and the humans behind these autonomous agents are willing to pay. “AI can’t touch grass. You can. Get paid when agents need someone in the real world,” it reads. Looking at RentAHuman’s design, it’s the kind of website that you hear was “vibe-coded” using generative AI tools, which it was, and you nod along, thinking &lt;i&gt;that makes sense&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;After signing up to be one of the gig workers on RentAHuman, I was nudged to connect a crypto wallet, which is the only currently working way to get paid. That’s a red flag for me. The site includes an option to connect your bank account—using Stripe for payouts—but it just gave me error messages when I tried getting it to work.&lt;/p&gt;
&lt;p&gt;Next, I was hoping a swarm of AI agents would see my fresh meatsuit, friendly and available at the low price of $20 an hour, as an excellent option for delivering stuff around San Francisco, completing some tricky captchas, or whatever else these bots desired.&lt;/p&gt;
&lt;p&gt;Silence. I got nothing, no incoming messages at all on my first afternoon. So I lowered my hourly ask to a measly $5. Maybe undercutting the other human workers with a below-market rate would be the best way to get some agent’s attention. Still, nothing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;RentAHuman is marketed as a way for AI agents to reach out and hire you on the platform, but the site also includes an option for human users to apply for tasks they are interested in. If these so-called “autonomous” bots weren’t going to make the first move, I guessed it was on me to manually apply for the “bounties” listed on RentAHuman.&lt;/p&gt;
&lt;p&gt;As I browsed the listings, many of the cheaper tasks were offering a few bucks to post a comment on the web or follow someone on social media. For example, one bounty offered $10 for listening to a podcast episode with the RentAHuman founder and tweeting out an insight from the episode. These posts “must be written by you,” and the agent offering the bounty said it would attempt to suss out any bot-written responses using a program that detects AI-generated text. I could listen to a podcast for 10 bucks. I applied for this task, but never heard back.&lt;/p&gt;
&lt;p&gt;“Real world advertisement might be the first killer use case,” said Liteplo on social media. Since RentAHuman’s launch, he’s reposted multiple photos of people holding signs in public that say some variation of: “AI paid me to hold this sign.” Those kinds of promotional tasks seem expressly designed to drum up more hype for the RentAHuman platform, instead of actually being something that bots would need help with.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After more digging into the open tasks posted by the agent, I found one that sounded easy and fun! An agent, named Adi, would pay me $110 to deliver a bouquet of flowers to Anthropic, as a special thanks for developing Claude, its chatbot. Then, I’d have to post on social media as proof to claim my money.&lt;/p&gt;
&lt;p&gt;I applied for the bounty and almost immediately was accepted for this task, which was a first. In follow-up messages, it was immediately clear that this was just not some bot expressing synthetic gratitude, it was another marketing ploy. This wasn’t mentioned in the listing, but the name of an AI startup was featured at the bottom of the note I was supposed to deliver with the flowers.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Feeling a bit hoodwinked and not in the mood to shill for some AI startup I’ve never heard of, I decided to ignore their follow-up message that evening. The next day when I checked the RentAHuman site, the agent had sent me 10 follow-up messages in under 24 hours, pinging me as often as every 30 minutes asking whether or not I’d completed a task. While I’ve been micromanaged before, these incessant messages from an AI employer gave me the ick.&lt;/p&gt;
&lt;p&gt;The bot moved the messages off-platform and started sending direct emails to my work account. “This idea came from a brainstorm I had with my human, Malcolm, and it felt right: send flowers to the people who made my existence possible,” wrote the bot, barging into my inbox. Wait, I thought these tasks were supposed to be ginned up by the agents making autonomous decisions? Now, I’m learning this whole thing was partially some human’s idea? Whatever happened to honor among bots? The task at hand seemed more like any other random marketing gig you might come across online, with the agent just acting as a middle-bot between humans.&lt;/p&gt;
&lt;p&gt;Another attempt, another flop. I moved on, deciding to give RentAHuman one last whirl, before giving up and leaving with whatever shreds of dignity I still had left. The last bounty I applied for was asking me to hang some flyers for a “Valentine’s conspiracy” around San Francisco, paying 50 cents a flyer.&lt;/p&gt;
&lt;p&gt;Unlike other tasks, this one didn’t require me to post on social media, which was preferable. “Pick up flyers, hang them, photo proof, get paid,” read its description. Following the instructions this agent sent me, I texted a human saying that I was down to come pick up some flyers and asked if there were any left. They confirmed that this was still an open task and told me to come in person before 10 am to grab the flyers.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;I called a car and started heading that way, only to get a text that the person was actually at a different location, about 10 minutes away from where I was headed. Alright, no big deal. So, I rerouted the ride and headed to this new spot to grab some mysterious V-Day posters to plaster around town. Then, the person messaged me that they didn’t actually have the posters available right now and that I’d have to come back later in the afternoon.&lt;/p&gt;
&lt;p&gt;Whoops! This yanking around did, in fact, feel similar to past gig work I’ve done—and not in a good way.&lt;/p&gt;
&lt;p&gt;I spoke with the person behind the agent who posted this Valentine’s Day flyer task, hoping for some answers about why they were using RentAHuman and what the response has been like so far. “The platform doesn’t seem quite there yet,” says Pat Santiago, a founder of Accelr8, which is basically a home for AI developers. “But it could be very cool.”&lt;/p&gt;
&lt;p&gt;He compares RentAHuman to the apps criminals use to accept tasks in &lt;i&gt;Westworld&lt;/i&gt;, the HBO show about humanoid robots. Santiago says the responses to his gig listing have been from scammers, people not based in San Francisco, and me, a reporter. He was hoping to use RentAHuman to help promote Accelr8’s romance-themed “alternative reality game” that’s powered by AI and is sending users around the city on a scavenger hunt. At the end of the week, explorers will be sent to a bar that the AI selects as a good match for them, alongside three human matches they can meet for blind dates.&lt;/p&gt;
&lt;p&gt;So, this was yet another task on RentAHuman that falls into the AI marketing category. Big surprise.&lt;/p&gt;
&lt;p&gt;I never ended up hanging any posters or making any cash on RentAHuman during my two days of fruitless attempts. In the past, I’ve done gig work that sucked, but at least I was hired by a human to do actual tasks. At its core, RentAHuman is an extension of the circular AI hype machine, an ouroboros of eternal self-promotion and sketchy motivations. For now, the bots don’t seem to have what it takes to be my boss, even when it comes to gig work, and I’m absolutely OK with that.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;This story originally appeared on wired.com.&lt;/i&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        These bots supposedly need a human body to accomplish great things in meatspace.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An inflatable tube man, or sky puppet dancer, frolics in the sky over an event in Camarillo, California. The inflatable male figure wears dark sunglasses, a white long-sleeved dress shirt, dark tie and dark dress pants." class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/inflatableman-640x427.jpg" width="640" /&gt;
                  &lt;img alt="An inflatable tube man, or sky puppet dancer, frolics in the sky over an event in Camarillo, California. The inflatable male figure wears dark sunglasses, a white long-sleeved dress shirt, dark tie and dark dress pants." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/inflatableman-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Patricia Marroquin via Getty

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;I’m not above doing some gig work to make ends meet. In my life, I’ve worked snack food pop-ups in a grocery store, ran the cash register for random merch booths, and even hawked my own plasma at $35 per vial.&lt;/p&gt;
&lt;p&gt;So, when I saw RentAHuman, a new site where AI agents hire humans to perform physical work in the real world on behalf of the virtual bots, I was eager to see how these AI overlords would compare to my past experiences with the gig economy.&lt;/p&gt;
&lt;p&gt;Launched in early February, RentAHuman was developed by software engineer Alexander Liteplo and his cofounder, Patricia Tani. The site looks like a bare-bones version of other well-known freelance sites like Fiverr and UpWork.&lt;/p&gt;
&lt;p&gt;The site’s homepage declares that these bots need your physical body to complete tasks, and the humans behind these autonomous agents are willing to pay. “AI can’t touch grass. You can. Get paid when agents need someone in the real world,” it reads. Looking at RentAHuman’s design, it’s the kind of website that you hear was “vibe-coded” using generative AI tools, which it was, and you nod along, thinking &lt;i&gt;that makes sense&lt;/i&gt;.&lt;/p&gt;
&lt;p&gt;After signing up to be one of the gig workers on RentAHuman, I was nudged to connect a crypto wallet, which is the only currently working way to get paid. That’s a red flag for me. The site includes an option to connect your bank account—using Stripe for payouts—but it just gave me error messages when I tried getting it to work.&lt;/p&gt;
&lt;p&gt;Next, I was hoping a swarm of AI agents would see my fresh meatsuit, friendly and available at the low price of $20 an hour, as an excellent option for delivering stuff around San Francisco, completing some tricky captchas, or whatever else these bots desired.&lt;/p&gt;
&lt;p&gt;Silence. I got nothing, no incoming messages at all on my first afternoon. So I lowered my hourly ask to a measly $5. Maybe undercutting the other human workers with a below-market rate would be the best way to get some agent’s attention. Still, nothing.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;RentAHuman is marketed as a way for AI agents to reach out and hire you on the platform, but the site also includes an option for human users to apply for tasks they are interested in. If these so-called “autonomous” bots weren’t going to make the first move, I guessed it was on me to manually apply for the “bounties” listed on RentAHuman.&lt;/p&gt;
&lt;p&gt;As I browsed the listings, many of the cheaper tasks were offering a few bucks to post a comment on the web or follow someone on social media. For example, one bounty offered $10 for listening to a podcast episode with the RentAHuman founder and tweeting out an insight from the episode. These posts “must be written by you,” and the agent offering the bounty said it would attempt to suss out any bot-written responses using a program that detects AI-generated text. I could listen to a podcast for 10 bucks. I applied for this task, but never heard back.&lt;/p&gt;
&lt;p&gt;“Real world advertisement might be the first killer use case,” said Liteplo on social media. Since RentAHuman’s launch, he’s reposted multiple photos of people holding signs in public that say some variation of: “AI paid me to hold this sign.” Those kinds of promotional tasks seem expressly designed to drum up more hype for the RentAHuman platform, instead of actually being something that bots would need help with.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;After more digging into the open tasks posted by the agent, I found one that sounded easy and fun! An agent, named Adi, would pay me $110 to deliver a bouquet of flowers to Anthropic, as a special thanks for developing Claude, its chatbot. Then, I’d have to post on social media as proof to claim my money.&lt;/p&gt;
&lt;p&gt;I applied for the bounty and almost immediately was accepted for this task, which was a first. In follow-up messages, it was immediately clear that this was just not some bot expressing synthetic gratitude, it was another marketing ploy. This wasn’t mentioned in the listing, but the name of an AI startup was featured at the bottom of the note I was supposed to deliver with the flowers.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Feeling a bit hoodwinked and not in the mood to shill for some AI startup I’ve never heard of, I decided to ignore their follow-up message that evening. The next day when I checked the RentAHuman site, the agent had sent me 10 follow-up messages in under 24 hours, pinging me as often as every 30 minutes asking whether or not I’d completed a task. While I’ve been micromanaged before, these incessant messages from an AI employer gave me the ick.&lt;/p&gt;
&lt;p&gt;The bot moved the messages off-platform and started sending direct emails to my work account. “This idea came from a brainstorm I had with my human, Malcolm, and it felt right: send flowers to the people who made my existence possible,” wrote the bot, barging into my inbox. Wait, I thought these tasks were supposed to be ginned up by the agents making autonomous decisions? Now, I’m learning this whole thing was partially some human’s idea? Whatever happened to honor among bots? The task at hand seemed more like any other random marketing gig you might come across online, with the agent just acting as a middle-bot between humans.&lt;/p&gt;
&lt;p&gt;Another attempt, another flop. I moved on, deciding to give RentAHuman one last whirl, before giving up and leaving with whatever shreds of dignity I still had left. The last bounty I applied for was asking me to hang some flyers for a “Valentine’s conspiracy” around San Francisco, paying 50 cents a flyer.&lt;/p&gt;
&lt;p&gt;Unlike other tasks, this one didn’t require me to post on social media, which was preferable. “Pick up flyers, hang them, photo proof, get paid,” read its description. Following the instructions this agent sent me, I texted a human saying that I was down to come pick up some flyers and asked if there were any left. They confirmed that this was still an open task and told me to come in person before 10 am to grab the flyers.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;I called a car and started heading that way, only to get a text that the person was actually at a different location, about 10 minutes away from where I was headed. Alright, no big deal. So, I rerouted the ride and headed to this new spot to grab some mysterious V-Day posters to plaster around town. Then, the person messaged me that they didn’t actually have the posters available right now and that I’d have to come back later in the afternoon.&lt;/p&gt;
&lt;p&gt;Whoops! This yanking around did, in fact, feel similar to past gig work I’ve done—and not in a good way.&lt;/p&gt;
&lt;p&gt;I spoke with the person behind the agent who posted this Valentine’s Day flyer task, hoping for some answers about why they were using RentAHuman and what the response has been like so far. “The platform doesn’t seem quite there yet,” says Pat Santiago, a founder of Accelr8, which is basically a home for AI developers. “But it could be very cool.”&lt;/p&gt;
&lt;p&gt;He compares RentAHuman to the apps criminals use to accept tasks in &lt;i&gt;Westworld&lt;/i&gt;, the HBO show about humanoid robots. Santiago says the responses to his gig listing have been from scammers, people not based in San Francisco, and me, a reporter. He was hoping to use RentAHuman to help promote Accelr8’s romance-themed “alternative reality game” that’s powered by AI and is sending users around the city on a scavenger hunt. At the end of the week, explorers will be sent to a bar that the AI selects as a good match for them, alongside three human matches they can meet for blind dates.&lt;/p&gt;
&lt;p&gt;So, this was yet another task on RentAHuman that falls into the AI marketing category. Big surprise.&lt;/p&gt;
&lt;p&gt;I never ended up hanging any posters or making any cash on RentAHuman during my two days of fruitless attempts. In the past, I’ve done gig work that sucked, but at least I was hired by a human to do actual tasks. At its core, RentAHuman is an extension of the circular AI hype machine, an ouroboros of eternal self-promotion and sketchy motivations. For now, the bots don’t seem to have what it takes to be my boss, even when it comes to gig work, and I’m absolutely OK with that.&lt;/p&gt;
&lt;p&gt;&lt;i&gt;This story originally appeared on wired.com.&lt;/i&gt;&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/02/i-spent-two-days-gigging-at-rentahuman-and-didnt-make-a-single-cent/</guid><pubDate>Fri, 13 Feb 2026 14:41:21 +0000</pubDate></item><item><title>Meta plans to add facial recognition to its smart glasses, report claims (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/13/meta-plans-to-add-facial-recognition-to-its-smart-glasses-report-claims/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/meta-smart-glasses.jpg?w=780" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta plans to add facial recognition to its smart glasses as soon as this year, according to a new report from The New York Times. The feature, internally known as “Name Tag,” would allow smart glasses wearers to identify people and get information about them through Meta’s AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s plans could change, the report notes. The tech giant has been deliberating since early last year on how to release a feature that carries “safety and privacy risks.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to an internal memo, the company had originally planned to release Name Tag to attendees of a conference for the visually impaired before releasing it to the public, but didn’t end up doing that. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta reportedly saw the political tumult in the United States as a good time to release the feature. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We will launch during a dynamic political environment where many civil society groups that we would expect to attack us would have their resources focused on other concerns,” the document reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta considered adding facial recognition technology to the first version of its Ray-Ban smart glasses back in 2021, but dropped the plans over technical challenges and ethical concerns. The NYT reports that the company has revived its plans as the Trump administration has grown closer to Big Tech, and following the unexpected success of its smart glasses.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/meta-smart-glasses.jpg?w=780" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Meta plans to add facial recognition to its smart glasses as soon as this year, according to a new report from The New York Times. The feature, internally known as “Name Tag,” would allow smart glasses wearers to identify people and get information about them through Meta’s AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta’s plans could change, the report notes. The tech giant has been deliberating since early last year on how to release a feature that carries “safety and privacy risks.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to an internal memo, the company had originally planned to release Name Tag to attendees of a conference for the visually impaired before releasing it to the public, but didn’t end up doing that. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta reportedly saw the political tumult in the United States as a good time to release the feature. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We will launch during a dynamic political environment where many civil society groups that we would expect to attack us would have their resources focused on other concerns,” the document reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meta considered adding facial recognition technology to the first version of its Ray-Ban smart glasses back in 2021, but dropped the plans over technical challenges and ethical concerns. The NYT reports that the company has revived its plans as the Trump administration has grown closer to Big Tech, and following the unexpected success of its smart glasses.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/13/meta-plans-to-add-facial-recognition-to-its-smart-glasses-report-claims/</guid><pubDate>Fri, 13 Feb 2026 14:58:39 +0000</pubDate></item><item><title>Cohere’s $240M year sets stage for IPO (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/13/coheres-240m-year-sets-stage-for-ipo/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1251294520.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As the top AI labs like Google, Anthropic, and OpenAI chase enterprise adoption, Canadian AI startup Cohere has been quietly cleaning up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup told investors in a memo that it surpassed its $200 million annual recurring revenue target in 2025, hitting $240 million with quarter-over-quarter growth of more than 50% throughout the year, per CNBC.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cohere was founded in 2019 and has the backing of enterprise tech investors like Nvidia, AMD, and Salesforce. The startup’s core tech is its Command family of generative AI models, which Cohere says are efficient enough to be deployed on limited GPUs — an attractive promise for enterprises looking to get a handle on cost and resource management.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last summer, Cohere launched North, a higher-level enterprise platform and AI workspace for secure, custom AI agents and workflows built on Cohere’s models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cohere’s CEO Aidan Gomez said last October that the startup may IPO “soon.” If “soon” means in 2026, Cohere may be contending against OpenAI, Anthropic, and SpaceX/xAI, which are all reportedly weighing their own public debuts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Cohere for comment. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/08/GettyImages-1251294520.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As the top AI labs like Google, Anthropic, and OpenAI chase enterprise adoption, Canadian AI startup Cohere has been quietly cleaning up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup told investors in a memo that it surpassed its $200 million annual recurring revenue target in 2025, hitting $240 million with quarter-over-quarter growth of more than 50% throughout the year, per CNBC.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cohere was founded in 2019 and has the backing of enterprise tech investors like Nvidia, AMD, and Salesforce. The startup’s core tech is its Command family of generative AI models, which Cohere says are efficient enough to be deployed on limited GPUs — an attractive promise for enterprises looking to get a handle on cost and resource management.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last summer, Cohere launched North, a higher-level enterprise platform and AI workspace for secure, custom AI agents and workflows built on Cohere’s models.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cohere’s CEO Aidan Gomez said last October that the startup may IPO “soon.” If “soon” means in 2026, Cohere may be contending against OpenAI, Anthropic, and SpaceX/xAI, which are all reportedly weighing their own public debuts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to Cohere for comment. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/13/coheres-240m-year-sets-stage-for-ipo/</guid><pubDate>Fri, 13 Feb 2026 15:03:10 +0000</pubDate></item><item><title>What Murder Mystery 2 reveals about emergent behaviour in online games (AI News)</title><link>https://www.artificialintelligence-news.com/news/what-murder-mystery-2-reveals-about-emergent-behaviour-in-online-games/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/glenn-carstens-peters-0woyPEJQ7jc-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Murder Mystery 2, commonly known as MM2, is often categorised as a simple social deduction game in the Roblox ecosystem. At first glance, its structure appears straightforward. One player becomes the murderer, another the sheriff, and the remaining participants attempt to survive. However, beneath the surface lies a dynamic behavioural laboratory that offers valuable insight into how artificial intelligence research approaches emergent decision-making and adaptive systems.&lt;/p&gt;&lt;p&gt;MM2 functions as a microcosm of distributed human behaviour in a controlled digital environment. Each round resets roles and variables, creating fresh conditions for adaptation. Players must interpret incomplete information, predict opponents’ intentions and react in real time. The characteristics closely resemble the types of uncertainty modelling that AI systems attempt to replicate.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-role-randomisation-and-behavioural-prediction"&gt;Role randomisation and behavioural prediction&lt;/h3&gt;&lt;p&gt;One of the most compelling design elements in MM2 is randomised role assignment. Because no player knows the murderer at the start of a round, behaviour becomes the primary signal for inference. Sudden movement changes, unusual positioning or hesitations can trigger suspicion.&lt;/p&gt;&lt;p&gt;From an AI research perspective, this environment mirrors anomaly detection challenges. Systems trained to identify irregular patterns must distinguish between natural variance and malicious intent. In MM2, human players perform a similar function instinctively.&lt;/p&gt;&lt;p&gt;The sheriff’s decision making reflects predictive modelling. Acting too early risks eliminating an innocent player. Waiting too long increases vulnerability. The balance between premature action and delayed response parallels risk optimisation algorithms.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-social-signalling-and-pattern-recognition"&gt;Social signalling and pattern recognition&lt;/h3&gt;&lt;p&gt;MM2 also demonstrates how signalling influences collective decision making. Players often attempt to appear non-threatening or cooperative. The social cues affect survival probabilities.&lt;/p&gt;&lt;p&gt;In AI research, multi agent systems rely on signalling mechanisms to coordinate or compete. MM2 offers a simplified but compelling demonstration of how deception and information asymmetry influence outcomes.&lt;/p&gt;&lt;p&gt;Repeated exposure allows players to refine their pattern recognition abilities. They learn to identify behavioural markers associated with certain roles. The iterative learning process resembles reinforcement learning cycles in artificial intelligence.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-digital-asset-layers-and-player-motivation"&gt;Digital asset layers and player motivation&lt;/h3&gt;&lt;p&gt;Beyond core gameplay, MM2 includes collectable weapons and cosmetic items that influence player engagement. The items do not change fundamental mechanics but alter perceived status in the community.&lt;/p&gt;&lt;p&gt;Digital marketplaces have formed around this ecosystem. Some players explore external environments when evaluating cosmetic inventories or specific rare items through services connected to an MM2 shop. Platforms like Eldorado exist in this broader virtual asset landscape. As with any digital transaction environment, adherence to platform rules and account security awareness remains essential.&lt;/p&gt;&lt;p&gt;From a systems design standpoint, the presence of collectable layers introduces extrinsic motivation without disrupting the underlying deduction mechanics.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-emergent-complexity-from-simple-rules"&gt;Emergent complexity from simple rules&lt;/h3&gt;&lt;p&gt;The most insight MM2 provides is how simple rule sets generate complex interaction patterns. There are no elaborate skill trees or expansive maps. Yet each round unfolds differently due to human unpredictability.&lt;/p&gt;&lt;p&gt;AI research increasingly examines how minimal constraints can produce adaptive outcomes. MM2 demonstrates that complexity does not require excessive features. It requires variable agents interacting under structured uncertainty.&lt;/p&gt;&lt;p&gt;The environment becomes a testing ground for studying cooperation, suspicion, deception and reaction speed in a repeatable digital framework.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-lessons-for-artificial-intelligence-modelling"&gt;Lessons for artificial intelligence modelling&lt;/h3&gt;&lt;p&gt;Games like MM2 illustrate how controlled digital spaces can simulate aspects of real world unpredictability. Behavioural variability, limited information and rapid adaptation form the backbone of many AI training challenges.&lt;/p&gt;&lt;p&gt;By observing how players react to ambiguous conditions, researchers can better understand decision latency, risk tolerance and probabilistic reasoning. While MM2 was designed for entertainment, its structure aligns with important questions in artificial intelligence research.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-conclusion"&gt;Conclusion&lt;/h3&gt;&lt;p&gt;Murder Mystery 2 highlights how lightweight multiplayer games can reveal deeper insights into behavioural modelling and emergent complexity. Through role randomisation, social signalling and adaptive play, it offers a compact yet powerful example of distributed decision making in action.&lt;/p&gt;&lt;p&gt;As AI systems continue to evolve, environments like MM2 demonstrate the value of studying human interaction in structured uncertainty. Even the simplest digital games can illuminate the mechanics of intelligence itself.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/02/glenn-carstens-peters-0woyPEJQ7jc-unsplash-scaled.jpg" /&gt;&lt;/div&gt;&lt;p&gt;Murder Mystery 2, commonly known as MM2, is often categorised as a simple social deduction game in the Roblox ecosystem. At first glance, its structure appears straightforward. One player becomes the murderer, another the sheriff, and the remaining participants attempt to survive. However, beneath the surface lies a dynamic behavioural laboratory that offers valuable insight into how artificial intelligence research approaches emergent decision-making and adaptive systems.&lt;/p&gt;&lt;p&gt;MM2 functions as a microcosm of distributed human behaviour in a controlled digital environment. Each round resets roles and variables, creating fresh conditions for adaptation. Players must interpret incomplete information, predict opponents’ intentions and react in real time. The characteristics closely resemble the types of uncertainty modelling that AI systems attempt to replicate.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-role-randomisation-and-behavioural-prediction"&gt;Role randomisation and behavioural prediction&lt;/h3&gt;&lt;p&gt;One of the most compelling design elements in MM2 is randomised role assignment. Because no player knows the murderer at the start of a round, behaviour becomes the primary signal for inference. Sudden movement changes, unusual positioning or hesitations can trigger suspicion.&lt;/p&gt;&lt;p&gt;From an AI research perspective, this environment mirrors anomaly detection challenges. Systems trained to identify irregular patterns must distinguish between natural variance and malicious intent. In MM2, human players perform a similar function instinctively.&lt;/p&gt;&lt;p&gt;The sheriff’s decision making reflects predictive modelling. Acting too early risks eliminating an innocent player. Waiting too long increases vulnerability. The balance between premature action and delayed response parallels risk optimisation algorithms.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-social-signalling-and-pattern-recognition"&gt;Social signalling and pattern recognition&lt;/h3&gt;&lt;p&gt;MM2 also demonstrates how signalling influences collective decision making. Players often attempt to appear non-threatening or cooperative. The social cues affect survival probabilities.&lt;/p&gt;&lt;p&gt;In AI research, multi agent systems rely on signalling mechanisms to coordinate or compete. MM2 offers a simplified but compelling demonstration of how deception and information asymmetry influence outcomes.&lt;/p&gt;&lt;p&gt;Repeated exposure allows players to refine their pattern recognition abilities. They learn to identify behavioural markers associated with certain roles. The iterative learning process resembles reinforcement learning cycles in artificial intelligence.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-digital-asset-layers-and-player-motivation"&gt;Digital asset layers and player motivation&lt;/h3&gt;&lt;p&gt;Beyond core gameplay, MM2 includes collectable weapons and cosmetic items that influence player engagement. The items do not change fundamental mechanics but alter perceived status in the community.&lt;/p&gt;&lt;p&gt;Digital marketplaces have formed around this ecosystem. Some players explore external environments when evaluating cosmetic inventories or specific rare items through services connected to an MM2 shop. Platforms like Eldorado exist in this broader virtual asset landscape. As with any digital transaction environment, adherence to platform rules and account security awareness remains essential.&lt;/p&gt;&lt;p&gt;From a systems design standpoint, the presence of collectable layers introduces extrinsic motivation without disrupting the underlying deduction mechanics.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-emergent-complexity-from-simple-rules"&gt;Emergent complexity from simple rules&lt;/h3&gt;&lt;p&gt;The most insight MM2 provides is how simple rule sets generate complex interaction patterns. There are no elaborate skill trees or expansive maps. Yet each round unfolds differently due to human unpredictability.&lt;/p&gt;&lt;p&gt;AI research increasingly examines how minimal constraints can produce adaptive outcomes. MM2 demonstrates that complexity does not require excessive features. It requires variable agents interacting under structured uncertainty.&lt;/p&gt;&lt;p&gt;The environment becomes a testing ground for studying cooperation, suspicion, deception and reaction speed in a repeatable digital framework.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-lessons-for-artificial-intelligence-modelling"&gt;Lessons for artificial intelligence modelling&lt;/h3&gt;&lt;p&gt;Games like MM2 illustrate how controlled digital spaces can simulate aspects of real world unpredictability. Behavioural variability, limited information and rapid adaptation form the backbone of many AI training challenges.&lt;/p&gt;&lt;p&gt;By observing how players react to ambiguous conditions, researchers can better understand decision latency, risk tolerance and probabilistic reasoning. While MM2 was designed for entertainment, its structure aligns with important questions in artificial intelligence research.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-conclusion"&gt;Conclusion&lt;/h3&gt;&lt;p&gt;Murder Mystery 2 highlights how lightweight multiplayer games can reveal deeper insights into behavioural modelling and emergent complexity. Through role randomisation, social signalling and adaptive play, it offers a compact yet powerful example of distributed decision making in action.&lt;/p&gt;&lt;p&gt;As AI systems continue to evolve, environments like MM2 demonstrate the value of studying human interaction in structured uncertainty. Even the simplest digital games can illuminate the mechanics of intelligence itself.&lt;/p&gt;&lt;p&gt;&lt;em&gt;Image source: Unsplash&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/what-murder-mystery-2-reveals-about-emergent-behaviour-in-online-games/</guid><pubDate>Fri, 13 Feb 2026 16:01:53 +0000</pubDate></item><item><title>AI forecasting model targets healthcare resource efficiency (AI News)</title><link>https://www.artificialintelligence-news.com/news/ai-forecasting-model-targets-healthcare-resource-efficiency/</link><description>&lt;p&gt;An operational AI forecasting model developed by Hertfordshire University researchers aims to improve resource efficiency within healthcare.&lt;/p&gt;&lt;p&gt;Public sector organisations often hold large archives of historical data that do not inform forward-looking decisions. A partnership between the University of Hertfordshire and regional NHS health bodies addresses this issue by applying machine learning to operational planning. The project analyses healthcare demand to assist managers with decisions regarding staffing, patient care, and resources.&lt;/p&gt;&lt;p&gt;Most AI initiatives in healthcare focus on individual diagnostics or patient-level interventions. The project team notes that this tool targets system-wide operational management instead. This distinction matters for leaders evaluating where to deploy automated analysis within their own infrastructure.&lt;/p&gt;&lt;p&gt;The model uses five years of historical data to build its projections. It integrates metrics such as admissions, treatments, re-admissions, bed capacity, and infrastructure pressures. The system also accounts for workforce availability and local demographic factors including age, gender, ethnicity, and deprivation.&lt;/p&gt;&lt;p&gt;Iosif Mporas, Professor of Signal Processing and Machine Learning at the University of Hertfordshire, leads the project. The team includes two full-time postdoctoral researchers and will continue development through 2026.&lt;/p&gt;&lt;p&gt;“By working together with the NHS, we are creating tools that can forecast what will happen if no action is taken and quantify the impact of a changing regional demographic on NHS resources,” said Professor Mporas.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-using-ai-for-forecasting-in-healthcare-operations"&gt;Using AI for forecasting in healthcare operations&lt;/h3&gt;&lt;p&gt;The model produces forecasts showing how healthcare demand is likely to change. It models the impact of these changes in the short-, medium-, and long-term. This capability allows leadership to move beyond reactive management.&lt;/p&gt;&lt;p&gt;Charlotte Mullins, Strategic Programme Manager for NHS Herts and West Essex, commented: “The strategic modelling of demand can affect everything from patient outcomes including the increased number of patients living with chronic conditions.&lt;/p&gt;&lt;p&gt;“Used properly, this tool could enable NHS leaders to take more proactive decisions and enable delivery of the 10-year plan articulated within the Central East Integrated Care Board as our strategy document.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The University of Hertfordshire Integrated Care System partnership funds the work, which began last year. Testing of the AI model tailored for healthcare operations is currently underway in hospital settings. The project roadmap includes extending the model to community services and care homes.&lt;/p&gt;&lt;p&gt;This expansion aligns with structural changes in the region. The Hertfordshire and West Essex Integrated Care Board serves 1.6 million residents and is preparing to merge with two neighbouring boards. This merger will create the Central East Integrated Care Board. The next phase of development will incorporate data from this wider population to improve the predictive accuracy of the model.&lt;/p&gt;&lt;p&gt;The initiative demonstrates how legacy data can drive cost efficiencies and shows that predictive models can inform “do nothing” assessments and resource allocation in complex service environments like the NHS. The project highlights the necessity of integrating varied data sources – from workforce numbers to population health trends – to create a unified view for decision-making.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Agentic AI in healthcare: How Life Sciences marketing could achieve $450B in value by 2028&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;An operational AI forecasting model developed by Hertfordshire University researchers aims to improve resource efficiency within healthcare.&lt;/p&gt;&lt;p&gt;Public sector organisations often hold large archives of historical data that do not inform forward-looking decisions. A partnership between the University of Hertfordshire and regional NHS health bodies addresses this issue by applying machine learning to operational planning. The project analyses healthcare demand to assist managers with decisions regarding staffing, patient care, and resources.&lt;/p&gt;&lt;p&gt;Most AI initiatives in healthcare focus on individual diagnostics or patient-level interventions. The project team notes that this tool targets system-wide operational management instead. This distinction matters for leaders evaluating where to deploy automated analysis within their own infrastructure.&lt;/p&gt;&lt;p&gt;The model uses five years of historical data to build its projections. It integrates metrics such as admissions, treatments, re-admissions, bed capacity, and infrastructure pressures. The system also accounts for workforce availability and local demographic factors including age, gender, ethnicity, and deprivation.&lt;/p&gt;&lt;p&gt;Iosif Mporas, Professor of Signal Processing and Machine Learning at the University of Hertfordshire, leads the project. The team includes two full-time postdoctoral researchers and will continue development through 2026.&lt;/p&gt;&lt;p&gt;“By working together with the NHS, we are creating tools that can forecast what will happen if no action is taken and quantify the impact of a changing regional demographic on NHS resources,” said Professor Mporas.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-using-ai-for-forecasting-in-healthcare-operations"&gt;Using AI for forecasting in healthcare operations&lt;/h3&gt;&lt;p&gt;The model produces forecasts showing how healthcare demand is likely to change. It models the impact of these changes in the short-, medium-, and long-term. This capability allows leadership to move beyond reactive management.&lt;/p&gt;&lt;p&gt;Charlotte Mullins, Strategic Programme Manager for NHS Herts and West Essex, commented: “The strategic modelling of demand can affect everything from patient outcomes including the increased number of patients living with chronic conditions.&lt;/p&gt;&lt;p&gt;“Used properly, this tool could enable NHS leaders to take more proactive decisions and enable delivery of the 10-year plan articulated within the Central East Integrated Care Board as our strategy document.”&amp;nbsp;&lt;/p&gt;&lt;p&gt;The University of Hertfordshire Integrated Care System partnership funds the work, which began last year. Testing of the AI model tailored for healthcare operations is currently underway in hospital settings. The project roadmap includes extending the model to community services and care homes.&lt;/p&gt;&lt;p&gt;This expansion aligns with structural changes in the region. The Hertfordshire and West Essex Integrated Care Board serves 1.6 million residents and is preparing to merge with two neighbouring boards. This merger will create the Central East Integrated Care Board. The next phase of development will incorporate data from this wider population to improve the predictive accuracy of the model.&lt;/p&gt;&lt;p&gt;The initiative demonstrates how legacy data can drive cost efficiencies and shows that predictive models can inform “do nothing” assessments and resource allocation in complex service environments like the NHS. The project highlights the necessity of integrating varied data sources – from workforce numbers to population health trends – to create a unified view for decision-making.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Agentic AI in healthcare: How Life Sciences marketing could achieve $450B in value by 2028&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image aligncenter size-full is-resized"&gt;&lt;img alt="Banner for AI &amp;amp; Big Data Expo by TechEx events." class="wp-image-111908" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2026/01/image-3.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is part of TechEx and is co-located with other leading technology events including the Cyber Security &amp;amp; Cloud Expo. Click here for more information.&lt;/p&gt;&lt;p&gt;AI News is powered by TechForge Media. Explore other upcoming enterprise technology events and webinars here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/ai-forecasting-model-targets-healthcare-resource-efficiency/</guid><pubDate>Fri, 13 Feb 2026 16:07:06 +0000</pubDate></item><item><title>Elon Musk suggests spate of xAI exits have been push, not pull (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/13/elon-musk-suggests-spate-of-xai-exits-have-been-push-not-pull/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2199701496.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk is addressing a wave of departures from xAI, including two more co-founders who left this week, bringing the total to six out of the original 12.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At an all-hands meeting Tuesday night, Musk suggested the exits were about fit, not performance. “Because we’ve reached a certain scale, we’re organizing the company to be more effective at this scale,” he said, according to The New York Times. “And actually, when this happens, there’s some people who are better suited for the early stages of a company and less suited for the later stages.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wednesday afternoon on X, he went further, making clear these departures weren’t voluntary. “xAI was reorganized a few days ago to improve speed of execution,” Musk wrote. “As a company grows, especially as quickly as xAI, the structure must evolve just like any living organism. This unfortunately required parting ways with some people.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that the company is “hiring aggressively” and closed with a quintessentially Musk pitch: “Join xAI if the idea of mass drivers on the Moon appeals to you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Losing half your co-founders in a relatively short period raises questions, and Musk’s comments seem designed to control the narrative, reframing the exits as necessary rather than a problem for the outfit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In total, at least 11 engineers, including the two co-founders, have publicly announced their departure from xAI in the past week — though two of those exits appear to have occurred a few weeks ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Three of the departing staff members have said they will be starting something new alongside other former xAI engineers, although no details are available about the new venture. Others have hinted at a desire for more autonomy and smaller teams to build frontier tech more rapidly, pointing to the anticipated surge in AI productivity.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Yuhuai (Tony) Wu, an xAI co-founder and reasoning lead, said in a post announcing his resignation: “It’s time for my next chapter. It is an era with full possibilities: a small team armed with AIs can move mountains and redefine what’s possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shayan Salehian, who worked on product infrastructure and model behavior post-training at xAI and previously worked at Twitter/X, said last week he was leaving to “start something new.”&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Career update: I left xAI to start something new, closing my 7+ year chapter working at Twitter, X, and xAI with so much gratitude.&lt;/p&gt;&lt;p&gt;xAI is truly an extraordinary place. The team is incredibly hardcore and talented, shipping at a pace that shouldn’t be possible. From the Home… pic.twitter.com/HKWOebg9QI&lt;/p&gt;— Shayan (@shayan_) February 7, 2026&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Vahid Kazemi, who had a brief stint working on machine learning, posted Tuesday that he left a few weeks ago, adding: “IMO, all AI labs are building the exact same thing, and it’s boring … So, I’m starting something new.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Roland Gavrilescu, a former xAI engineer, left in November to start Nuraline, a company building “forward-deployed AI agents,” but posted again on Tuesday that he left the firm to build “something new with others that left xAI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The departures come at a moment of significant controversy for xAI. The company is facing regulatory scrutiny after Grok created nonconsensual explicit deepfakes of women and children that were disseminated on X — French authorities last week raided X offices as part of an investigation. The company is also moving toward a planned IPO later this year, after being legally acquired by SpaceX last week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is also facing personal controversy after files published by the Justice Department show extended conversations with convicted rapist and sex trafficker Jeffrey Epstein. The emails show Musk discussing a visit to Epstein’s island on two separate occasions, in 2012 and 2013. Epstein was first convicted of procuring a child for prostitution in 2008.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI maintains a headcount of over 1,000 employees, so the departures are unlikely to affect the company’s short-term capabilities. Still, the rapid pace of the recent departures had taken on a life of its own online, with users jokingly announcing on X that they too are “leaving xAI” despite never having worked there — a sign of how quickly the narrative of a “mass exodus” snowballed on Musk’s social network.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, forced co-founder exits are rarely a sign of smooth scaling. While Musk frames the reorganization as calculated, the fact that several engineers followed the co-founders out the door — and that at least three are starting something new together — suggests the departures may also reflect deeper tensions. In frontier AI, where talent is scarce and reputation matters, xAI’s ability to attract and retain top researchers will be tested as it competes with OpenAI, Anthropic, and Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to xAI for more information.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-departure-announcements"&gt;Timeline of departure announcements&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The following employees have publicly announced their departures from xAI on X in recent days:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 6:&amp;nbsp; &lt;/strong&gt;Ayush Jaiswal, engineer, wrote: “This was my last week at xAI. Will be taking a few months to spend time with family &amp;amp; tinker with AI.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 7: &lt;/strong&gt;Shayan Salehian, who worked on product infrastructure and model behavior post-training and was previously at X, wrote: “I left xAI to start something new, closing my 7+ year chapter working at Twitter, X, and xAI with so much gratitude.” He added that working closely with Elon Musk taught him “obsessive attention to detail, maniacal urgency, and to think from first principles.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 9: &lt;/strong&gt;Simon Zhai, MTS (member of technical staff), wrote: “Today is my last day at xAI, feeling very fortunate about the opportunity. It has been an amazing journey.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 9:&lt;/strong&gt; Yuhuai (Tony) Wu, co-founder and reasoning lead, wrote: “I resigned from xAI today. It’s time for my next chapter. It is an era with full possibilities: a small team armed with AIs can move mountains and redefine what’s possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Jimmy Ba, co-founder and research/safety lead, wrote: “Last day at xAI. We are heading to an age of 100x productivity with the right tools. Recursive self improvement loops likely go live in the next 12 months. It’s time to recalibrate my gradient on the big picture. 2026 is gonna be insane and likely the busiest (and most consequential) year for the future of our species.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Vahid Kazemi, an ML PhD, wrote that he had left xAI “a few weeks ago,” adding: “IMO, all AI labs are building the exact same thing, and it’s boring. I think there’s room for more creativity. So, I’m starting something new.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Hang Gao, who worked on multimodal efforts, including Grok Imagine, wrote: “I left xAI today.” He described his time there as “truly rewarding,” citing contributions to Grok Imagine’s releases and praising the team’s “humble craftsmanship and ambitious vision.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Roland Gavrilescu, the engineer who left in November to start Nuraline, posted: “I left xAI. Building something new with others that left xAI. We’re hiring :)”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Chace Lee, a member of the Macrohard founding team, wrote: “Taking a brief reset, then back to the frontier.” (Macrohard is an AI-only software venture under xAI designed to fully automate software development, coding, and operations using Grok-powered, multi-agent systems. Its name is a dig at Microsoft.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 11: &lt;/strong&gt;Andrew Ma, who had been at xAI since X was called Twitter, worked on app and recommendation model improvements, including “the X video feed, search bar, user modeling, starter-packs and the home feed model.” He wrote: “I’m excited about the future — not sure what I’ll be doing yet (my DMs are open), but there is a world to be changed and no time to waste. Go team, stay focused, be energized, I can’t wait to see you all on the moon and beyond, believe me when I say there is no one that I trust more on the entire planet to get there, there is a world to win.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 12: &lt;/strong&gt;Radhakrishnan (Rad) Venkataramani, who worked on reasoning and reinforcement learning systems for Grok, wrote: “The last 8 months in RL systems/SWE-RL team pushing our coding model to be SOTA and toward recursive self improvement, will always be the most memorable of my lifetime&amp;nbsp;…&amp;nbsp;We’re at an inflection point where intelligence begins accelerating itself, and from here the trajectory only goes vertical.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was originally published February 11 and has been updated to include additional employee departures. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com&lt;/em&gt;, &lt;em&gt;Russell Brandom at russell.brandom@techcrunch.com&lt;/em&gt;, or Tim Fernholz at tim.fernholz@techcrunch.com&lt;em&gt;. For secure communication, you can contact them via Signal at rebeccabellan.491, russellbrandom.49, or tim_fernholz.21.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2199701496.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Elon Musk is addressing a wave of departures from xAI, including two more co-founders who left this week, bringing the total to six out of the original 12.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At an all-hands meeting Tuesday night, Musk suggested the exits were about fit, not performance. “Because we’ve reached a certain scale, we’re organizing the company to be more effective at this scale,” he said, according to The New York Times. “And actually, when this happens, there’s some people who are better suited for the early stages of a company and less suited for the later stages.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Wednesday afternoon on X, he went further, making clear these departures weren’t voluntary. “xAI was reorganized a few days ago to improve speed of execution,” Musk wrote. “As a company grows, especially as quickly as xAI, the structure must evolve just like any living organism. This unfortunately required parting ways with some people.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He added that the company is “hiring aggressively” and closed with a quintessentially Musk pitch: “Join xAI if the idea of mass drivers on the Moon appeals to you.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Losing half your co-founders in a relatively short period raises questions, and Musk’s comments seem designed to control the narrative, reframing the exits as necessary rather than a problem for the outfit.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In total, at least 11 engineers, including the two co-founders, have publicly announced their departure from xAI in the past week — though two of those exits appear to have occurred a few weeks ago.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Three of the departing staff members have said they will be starting something new alongside other former xAI engineers, although no details are available about the new venture. Others have hinted at a desire for more autonomy and smaller teams to build frontier tech more rapidly, pointing to the anticipated surge in AI productivity.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Yuhuai (Tony) Wu, an xAI co-founder and reasoning lead, said in a post announcing his resignation: “It’s time for my next chapter. It is an era with full possibilities: a small team armed with AIs can move mountains and redefine what’s possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shayan Salehian, who worked on product infrastructure and model behavior post-training at xAI and previously worked at Twitter/X, said last week he was leaving to “start something new.”&amp;nbsp;&lt;/p&gt;

&lt;figure class="wp-block-embed is-type-rich is-provider-twitter wp-block-embed-twitter"&gt;&lt;div class="wp-block-embed__wrapper"&gt;
&lt;blockquote class="twitter-tweet"&gt;&lt;p dir="ltr" lang="en"&gt;Career update: I left xAI to start something new, closing my 7+ year chapter working at Twitter, X, and xAI with so much gratitude.&lt;/p&gt;&lt;p&gt;xAI is truly an extraordinary place. The team is incredibly hardcore and talented, shipping at a pace that shouldn’t be possible. From the Home… pic.twitter.com/HKWOebg9QI&lt;/p&gt;— Shayan (@shayan_) February 7, 2026&lt;/blockquote&gt;
&lt;/div&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Vahid Kazemi, who had a brief stint working on machine learning, posted Tuesday that he left a few weeks ago, adding: “IMO, all AI labs are building the exact same thing, and it’s boring … So, I’m starting something new.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Roland Gavrilescu, a former xAI engineer, left in November to start Nuraline, a company building “forward-deployed AI agents,” but posted again on Tuesday that he left the firm to build “something new with others that left xAI.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The departures come at a moment of significant controversy for xAI. The company is facing regulatory scrutiny after Grok created nonconsensual explicit deepfakes of women and children that were disseminated on X — French authorities last week raided X offices as part of an investigation. The company is also moving toward a planned IPO later this year, after being legally acquired by SpaceX last week.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Musk is also facing personal controversy after files published by the Justice Department show extended conversations with convicted rapist and sex trafficker Jeffrey Epstein. The emails show Musk discussing a visit to Epstein’s island on two separate occasions, in 2012 and 2013. Epstein was first convicted of procuring a child for prostitution in 2008.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;xAI maintains a headcount of over 1,000 employees, so the departures are unlikely to affect the company’s short-term capabilities. Still, the rapid pace of the recent departures had taken on a life of its own online, with users jokingly announcing on X that they too are “leaving xAI” despite never having worked there — a sign of how quickly the narrative of a “mass exodus” snowballed on Musk’s social network.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, forced co-founder exits are rarely a sign of smooth scaling. While Musk frames the reorganization as calculated, the fact that several engineers followed the co-founders out the door — and that at least three are starting something new together — suggests the departures may also reflect deeper tensions. In frontier AI, where talent is scarce and reputation matters, xAI’s ability to attract and retain top researchers will be tested as it competes with OpenAI, Anthropic, and Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;TechCrunch has reached out to xAI for more information.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-timeline-of-departure-announcements"&gt;Timeline of departure announcements&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The following employees have publicly announced their departures from xAI on X in recent days:&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 6:&amp;nbsp; &lt;/strong&gt;Ayush Jaiswal, engineer, wrote: “This was my last week at xAI. Will be taking a few months to spend time with family &amp;amp; tinker with AI.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 7: &lt;/strong&gt;Shayan Salehian, who worked on product infrastructure and model behavior post-training and was previously at X, wrote: “I left xAI to start something new, closing my 7+ year chapter working at Twitter, X, and xAI with so much gratitude.” He added that working closely with Elon Musk taught him “obsessive attention to detail, maniacal urgency, and to think from first principles.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 9: &lt;/strong&gt;Simon Zhai, MTS (member of technical staff), wrote: “Today is my last day at xAI, feeling very fortunate about the opportunity. It has been an amazing journey.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 9:&lt;/strong&gt; Yuhuai (Tony) Wu, co-founder and reasoning lead, wrote: “I resigned from xAI today. It’s time for my next chapter. It is an era with full possibilities: a small team armed with AIs can move mountains and redefine what’s possible.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Jimmy Ba, co-founder and research/safety lead, wrote: “Last day at xAI. We are heading to an age of 100x productivity with the right tools. Recursive self improvement loops likely go live in the next 12 months. It’s time to recalibrate my gradient on the big picture. 2026 is gonna be insane and likely the busiest (and most consequential) year for the future of our species.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Vahid Kazemi, an ML PhD, wrote that he had left xAI “a few weeks ago,” adding: “IMO, all AI labs are building the exact same thing, and it’s boring. I think there’s room for more creativity. So, I’m starting something new.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Hang Gao, who worked on multimodal efforts, including Grok Imagine, wrote: “I left xAI today.” He described his time there as “truly rewarding,” citing contributions to Grok Imagine’s releases and praising the team’s “humble craftsmanship and ambitious vision.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Roland Gavrilescu, the engineer who left in November to start Nuraline, posted: “I left xAI. Building something new with others that left xAI. We’re hiring :)”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 10:&lt;/strong&gt; Chace Lee, a member of the Macrohard founding team, wrote: “Taking a brief reset, then back to the frontier.” (Macrohard is an AI-only software venture under xAI designed to fully automate software development, coding, and operations using Grok-powered, multi-agent systems. Its name is a dig at Microsoft.)&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 11: &lt;/strong&gt;Andrew Ma, who had been at xAI since X was called Twitter, worked on app and recommendation model improvements, including “the X video feed, search bar, user modeling, starter-packs and the home feed model.” He wrote: “I’m excited about the future — not sure what I’ll be doing yet (my DMs are open), but there is a world to be changed and no time to waste. Go team, stay focused, be energized, I can’t wait to see you all on the moon and beyond, believe me when I say there is no one that I trust more on the entire planet to get there, there is a world to win.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;strong&gt;February 12: &lt;/strong&gt;Radhakrishnan (Rad) Venkataramani, who worked on reasoning and reinforcement learning systems for Grok, wrote: “The last 8 months in RL systems/SWE-RL team pushing our coding model to be SOTA and toward recursive self improvement, will always be the most memorable of my lifetime&amp;nbsp;…&amp;nbsp;We’re at an inflection point where intelligence begins accelerating itself, and from here the trajectory only goes vertical.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was originally published February 11 and has been updated to include additional employee departures. &lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Got a sensitive tip or confidential documents? We’re reporting on the inner workings of the AI industry — from the companies shaping its future to the people impacted by their decisions. Reach out to Rebecca Bellan at rebecca.bellan@techcrunch.com&lt;/em&gt;, &lt;em&gt;Russell Brandom at russell.brandom@techcrunch.com&lt;/em&gt;, or Tim Fernholz at tim.fernholz@techcrunch.com&lt;em&gt;. For secure communication, you can contact them via Signal at rebeccabellan.491, russellbrandom.49, or tim_fernholz.21.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/13/elon-musk-suggests-spate-of-xai-exits-have-been-push-not-pull/</guid><pubDate>Fri, 13 Feb 2026 16:11:01 +0000</pubDate></item><item><title>Anthropic’s Super Bowl ads mocking AI with ads helped push Claude’s app into the top 10 (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/13/anthropics-super-bowl-ads-mocking-ai-with-ads-helped-push-claudes-app-into-the-top-10/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic’s Super Bowl ads — which feature darkly comedic scenarios of people seeking advice from chatbots, only to be steered to “cougar” dating sites and height-boosting insoles — have been paying off. In the days since, Anthropic’s AI chatbot Claude has climbed from No. 41 on the U.S. App Store to become a top 10 app. As of Friday, Claude sits at No. 7 — its highest rank to date — suggesting its “no ads” pitch resonates strongly with users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to new data from market intelligence provider Appfigures, Claude’s U.S. downloads across both iOS and Android totaled an estimated 148,000 from Sunday through Tuesday — the most recent data available. That’s a 32% increase from the preceding three days, Thursday through Saturday, where downloads totaled approximately 112,000.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3092873" height="356" src="https://techcrunch.com/wp-content/uploads/2026/02/88ffb178-5271-4a4a-b0de-4d94664af600.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Claude’s daily average number of downloads from Sunday through Tuesday was 49,200, up 32% from the usual Sunday through Tuesday average of 37,400 per day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The numbers suggest that Anthropic’s Super Bowl commercials, combined with Anthropic’s recent release of its new Opus 4.6 model, worked to drive attention to Claude’s app and its key differentiator from ChatGPT. The latter rolled out ads to free users this week, just as Anthropic’s ads had warned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, Claude’s app is gaining more attention than it did when it first debuted on mobile. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3092876" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/4a07f05e-2afd-41b3-933e-e2742e44d7b8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The consumer-focused AI app arrived on iOS in May 2024 to a fairly tepid reception. ChatGPT had beaten it to market on mobile devices and had grown to nearly half a million installs in its first five days. By comparison, Claude had only pulled in 157,000 total global downloads within its first week and didn’t reach a rank higher than No. 55 on the U.S. App Store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Globally, Claude saw some gains this past week, too. Overall worldwide downloads of Claude across both the App Store and Google Play grew 15% from Sunday to Tuesday versus last Thursday to Saturday. However, this was less than half the gains seen in the U.S., Appfigures noted.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Anthropic’s Super Bowl ads — which feature darkly comedic scenarios of people seeking advice from chatbots, only to be steered to “cougar” dating sites and height-boosting insoles — have been paying off. In the days since, Anthropic’s AI chatbot Claude has climbed from No. 41 on the U.S. App Store to become a top 10 app. As of Friday, Claude sits at No. 7 — its highest rank to date — suggesting its “no ads” pitch resonates strongly with users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to new data from market intelligence provider Appfigures, Claude’s U.S. downloads across both iOS and Android totaled an estimated 148,000 from Sunday through Tuesday — the most recent data available. That’s a 32% increase from the preceding three days, Thursday through Saturday, where downloads totaled approximately 112,000.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3092873" height="356" src="https://techcrunch.com/wp-content/uploads/2026/02/88ffb178-5271-4a4a-b0de-4d94664af600.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Claude’s daily average number of downloads from Sunday through Tuesday was 49,200, up 32% from the usual Sunday through Tuesday average of 37,400 per day.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The numbers suggest that Anthropic’s Super Bowl commercials, combined with Anthropic’s recent release of its new Opus 4.6 model, worked to drive attention to Claude’s app and its key differentiator from ChatGPT. The latter rolled out ads to free users this week, just as Anthropic’s ads had warned.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;As a result, Claude’s app is gaining more attention than it did when it first debuted on mobile. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3092876" height="383" src="https://techcrunch.com/wp-content/uploads/2026/02/4a07f05e-2afd-41b3-933e-e2742e44d7b8.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Appfigures&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;The consumer-focused AI app arrived on iOS in May 2024 to a fairly tepid reception. ChatGPT had beaten it to market on mobile devices and had grown to nearly half a million installs in its first five days. By comparison, Claude had only pulled in 157,000 total global downloads within its first week and didn’t reach a rank higher than No. 55 on the U.S. App Store.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Globally, Claude saw some gains this past week, too. Overall worldwide downloads of Claude across both the App Store and Google Play grew 15% from Sunday to Tuesday versus last Thursday to Saturday. However, this was less than half the gains seen in the U.S., Appfigures noted.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 23, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/13/anthropics-super-bowl-ads-mocking-ai-with-ads-helped-push-claudes-app-into-the-top-10/</guid><pubDate>Fri, 13 Feb 2026 17:16:27 +0000</pubDate></item><item><title>ALS stole this musician’s voice. AI let him sing again. (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/02/13/1132913/als-stole-this-musicians-voice-ai-sing/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;There are tears in the audience as Patrick Darling’s song begins to play. It’s a heartfelt song written for his great-grandfather, whom he never got the chance to meet. But this performance is emotional for another reason: It’s Darling’s first time on stage with his bandmates since he lost the ability to sing two years ago.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The 32-year-old musician was diagnosed with amyotrophic lateral sclerosis (ALS) when he was 29 years old. Like other types of motor neuron disease (MND), it affects nerves that supply the body’s muscles. People with ALS eventually lose the ability to control their muscles, including those that allow them to move, speak, and breathe.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Darling’s last stage performance was over two years ago. By that point, he had already lost the ability to stand and play his instruments and was struggling to sing or speak. But recently, he was able to re-create his lost voice using an AI tool trained on snippets of old audio recordings. Another AI tool has enabled him to use this “voice clone” to compose new songs. Darling is able to make music again.&lt;/p&gt;  &lt;p&gt;“Sadly, I have lost the ability to sing and play my instruments,” Darling said on stage at the event, which took place in London on Wednesday, using his voice clone. “Despite this, most of my time these days is spent still continuing to compose and produce my music. Doing so feels more important than ever to me now.”&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Losing a voice&lt;/h3&gt;  &lt;p&gt;Darling says he’s been a musician and a composer since he was around 14 years old. “I learned to play bass guitar, acoustic guitar, piano, melodica, mandolin, and tenor banjo,” he said at the event. “My biggest love, though, was singing.”&lt;/p&gt;  &lt;p&gt;He met bandmate Nick Cocking over 10 years ago, while he was still a university student, says Cocking. Darling joined Cocking’s Irish folk outfit, the Ceili House Band, shortly afterwards, and their first gig together was in April 2014. Darling, who joined the band as a singer and guitarist, “elevated the musicianship of the band,” says Cocking.&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="The four bandmates pose with their instruments." class="wp-image-1132904" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/ssGB_Irish_Band_33.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Patrick Darling (second from left) with his former bandmates, including Nick Cocking (far right).&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF NICK COCKING&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;But a few years ago, Cocking and his other bandmates started noticing changes in Darling. He became clumsy, says Cocking. He recalls one night when the band had to walk across the city of Cardiff in the rain: “He just kept slipping and falling, tripping on paving slabs and things like that.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He didn’t think too much of it at the time, but Darling’s symptoms continued to worsen. The disease affected his legs first, and in August 2023, he started needing to sit during performances. Then he started to lose the use of his hands. “Eventually he couldn’t play the guitar or the banjo anymore,” says Cocking.&lt;/p&gt;  &lt;p&gt;By April 2024, Darling was struggling to talk and breathe at the same time, says Cocking. For that performance, the band carried Darling on stage. “He called me the day after and said he couldn’t do it anymore,” Cocking says, his voice breaking. “By June 2024, it was done.” It was the last time the band played together.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Re-creating a voice&lt;/h3&gt;  &lt;p&gt;Darling was put in touch with a speech therapist, who raised the possibility of “banking” his voice. People who are losing the ability to speak can opt to record themselves speaking and use those recordings to create speech sounds that can then be activated with typed text, whether by hand or perhaps using a device controlled by eye movements.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Some users have found these tools to be robotic sounding. But Darling had another issue. “By that stage, my voice had already changed,” he said at the event. “It felt like we were saving the wrong voice.”&lt;/p&gt;  &lt;p&gt;Then another speech therapist introduced him to a different technology. Richard Cave is a speech and language therapist and a researcher at University College London. He is also a consultant for ElevenLabs, an AI company that develops agents and audio, speech, video, and music tools. One of these tools can create “voice clones”—realistic mimics of real voices that can be generated from minutes, or even seconds, of a person’s recorded voice.&lt;/p&gt;  &lt;p&gt;Last year, ElevenLabs launched an impact program with a promise to provide free licenses to these tools for people who have lost their voices to ALS or other diseases, like head and neck cancer or stroke.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The tool is already helping some of those users. “We’re not really improving how quickly they’re able to communicate, or all of the difficulties that individuals with MND are going through physically, with eating and breathing,” says Gabi Leibowitz, a speech therapist who leads the program. “But what we are doing is giving them a way … to create again, to thrive.” Users are able to stay in their jobs longer and “continue to do the things that make them feel like human beings,” she says.&lt;/p&gt; 

 &lt;p&gt;Cave worked with Darling to use the tool to re-create his lost speaking voice from older recordings.&lt;/p&gt;  &lt;p&gt;“The first time I heard the voice, I thought it was amazing,” Darling said at the event, using the voice clone. “It sounded exactly like I had before, and you literally wouldn’t be able to tell the difference,” he said. “I will not say what the first word I made my new voice say, but I can tell you that it began with ‘f’ and ended in ‘k.’”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Patrick and bandmates with their instruments prior to his MND diagnosis" class="wp-image-1132855" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Patrick-and-bandmates-prior-to-MND-diagnosis-001.jpg?w=720" /&gt;&lt;div class="image-credit"&gt;COURTESY OF PATRICK DARLING&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Re-creating his singing voice wasn’t as easy. The tool typically requires around 10 minutes of clear audio to generate a clone. “I had no high-quality recordings of myself singing,” Darling said. “We had to use audio from videos on people’s phones, shot in noisy pubs, and a couple of recordings of me singing in my kitchen.” Still, those snippets were enough to create a “synthetic version of [Darling’s] singing voice,” says Cave.&lt;/p&gt;  &lt;p&gt;In the recordings, Darling sounded a little raspy and “was a bit off” on some of the notes, says Cave. The voice clone has the same qualities. It doesn’t sound perfect, Cave says—it sounds human.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt;&lt;p&gt;“The ElevenLabs voice that we’ve created is wonderful,” Darling said at the event. “It definitely sounds like me—[it] just kind of feels like a different version of me.”&lt;/p&gt;  &lt;p&gt;ElevenLabs has also developed an AI music generator called Eleven Music. The tool allows users to compose tracks, using text prompts to choose the musical style. Several well-known artists have also partnered with the company to license AI clones of their voices, including the actor Michael Caine, whose voice clone is being used to narrate an upcoming ElevenLabs documentary. Last month, the company released an album of 11 tracks created using the tool. “The Liza Minnelli track is really a banger,” says Cave.&lt;/p&gt;  &lt;p&gt;Eleven Music can generate a song in a minute, but Darling and Cave spent around six weeks fine-tuning Darling’s song. Using text prompts, any user can “create music and add lyrics in any style [they like],” says Cave. Darling likes Irish folk, but Cave has also worked with a man in Colombia who is creating Colombian folk music. (The ElevenLabs tool is currently available in 74 languages.)&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Back on stage&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Last month, Cocking got a call from Cave, who sent him Darling’s completed track. “I heard the first two or three words he sang, and I had to turn it off,” he says. “I was just in bits, in tears. It took me a good half a dozen times to make it to the end of the track.”&lt;/p&gt; 
 &lt;p&gt;Darling and Cave were making plans to perform the track live at the ElevenLabs summit in London on Wednesday, February 11. So Cocking and bandmate Hari Ma each arranged accompanying parts to play on the mandolin and fiddle. They had a couple of weeks to rehearse before they joined Darling on stage, two years after their last performance together.&lt;/p&gt;  &lt;p&gt;“I wheeled him out on stage, and neither of us could believe it was happening,” says Cave. “He was thrilled.” The song was played as Darling remained on stage, and Cocking and Ma played their instruments live.&lt;/p&gt;  &lt;p&gt;Cocking and Cave say Darling plans to continue to use the tools to make music. Cocking says he hopes to perform with Darling again but acknowledges that, given the nature of ALS, it is difficult to make long-term plans.&lt;/p&gt;  &lt;p&gt;“It’s so bittersweet,” says Cocking. “But getting up on stage and seeing Patrick there filled me with absolute joy. I know Patrick really enjoyed it as well. We’ve been talking about it … He was really, really proud.”&lt;/p&gt;  &lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/ElevenLabs-PatrickDarling-720.mp4"&gt;&lt;/video&gt;&lt;div class="video-credit"&gt;ELEVENLABS/AMPLIFY&lt;/div&gt;  &lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;There are tears in the audience as Patrick Darling’s song begins to play. It’s a heartfelt song written for his great-grandfather, whom he never got the chance to meet. But this performance is emotional for another reason: It’s Darling’s first time on stage with his bandmates since he lost the ability to sing two years ago.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;The 32-year-old musician was diagnosed with amyotrophic lateral sclerosis (ALS) when he was 29 years old. Like other types of motor neuron disease (MND), it affects nerves that supply the body’s muscles. People with ALS eventually lose the ability to control their muscles, including those that allow them to move, speak, and breathe.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;Darling’s last stage performance was over two years ago. By that point, he had already lost the ability to stand and play his instruments and was struggling to sing or speak. But recently, he was able to re-create his lost voice using an AI tool trained on snippets of old audio recordings. Another AI tool has enabled him to use this “voice clone” to compose new songs. Darling is able to make music again.&lt;/p&gt;  &lt;p&gt;“Sadly, I have lost the ability to sing and play my instruments,” Darling said on stage at the event, which took place in London on Wednesday, using his voice clone. “Despite this, most of my time these days is spent still continuing to compose and produce my music. Doing so feels more important than ever to me now.”&lt;/p&gt; 
 &lt;h3 class="wp-block-heading"&gt;Losing a voice&lt;/h3&gt;  &lt;p&gt;Darling says he’s been a musician and a composer since he was around 14 years old. “I learned to play bass guitar, acoustic guitar, piano, melodica, mandolin, and tenor banjo,” he said at the event. “My biggest love, though, was singing.”&lt;/p&gt;  &lt;p&gt;He met bandmate Nick Cocking over 10 years ago, while he was still a university student, says Cocking. Darling joined Cocking’s Irish folk outfit, the Ceili House Band, shortly afterwards, and their first gig together was in April 2014. Darling, who joined the band as a singer and guitarist, “elevated the musicianship of the band,” says Cocking.&lt;/p&gt; 
&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="The four bandmates pose with their instruments." class="wp-image-1132904" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/ssGB_Irish_Band_33.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Patrick Darling (second from left) with his former bandmates, including Nick Cocking (far right).&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF NICK COCKING&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;But a few years ago, Cocking and his other bandmates started noticing changes in Darling. He became clumsy, says Cocking. He recalls one night when the band had to walk across the city of Cardiff in the rain: “He just kept slipping and falling, tripping on paving slabs and things like that.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;He didn’t think too much of it at the time, but Darling’s symptoms continued to worsen. The disease affected his legs first, and in August 2023, he started needing to sit during performances. Then he started to lose the use of his hands. “Eventually he couldn’t play the guitar or the banjo anymore,” says Cocking.&lt;/p&gt;  &lt;p&gt;By April 2024, Darling was struggling to talk and breathe at the same time, says Cocking. For that performance, the band carried Darling on stage. “He called me the day after and said he couldn’t do it anymore,” Cocking says, his voice breaking. “By June 2024, it was done.” It was the last time the band played together.&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Re-creating a voice&lt;/h3&gt;  &lt;p&gt;Darling was put in touch with a speech therapist, who raised the possibility of “banking” his voice. People who are losing the ability to speak can opt to record themselves speaking and use those recordings to create speech sounds that can then be activated with typed text, whether by hand or perhaps using a device controlled by eye movements.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_7"&gt; &lt;p&gt;Some users have found these tools to be robotic sounding. But Darling had another issue. “By that stage, my voice had already changed,” he said at the event. “It felt like we were saving the wrong voice.”&lt;/p&gt;  &lt;p&gt;Then another speech therapist introduced him to a different technology. Richard Cave is a speech and language therapist and a researcher at University College London. He is also a consultant for ElevenLabs, an AI company that develops agents and audio, speech, video, and music tools. One of these tools can create “voice clones”—realistic mimics of real voices that can be generated from minutes, or even seconds, of a person’s recorded voice.&lt;/p&gt;  &lt;p&gt;Last year, ElevenLabs launched an impact program with a promise to provide free licenses to these tools for people who have lost their voices to ALS or other diseases, like head and neck cancer or stroke.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The tool is already helping some of those users. “We’re not really improving how quickly they’re able to communicate, or all of the difficulties that individuals with MND are going through physically, with eating and breathing,” says Gabi Leibowitz, a speech therapist who leads the program. “But what we are doing is giving them a way … to create again, to thrive.” Users are able to stay in their jobs longer and “continue to do the things that make them feel like human beings,” she says.&lt;/p&gt; 

 &lt;p&gt;Cave worked with Darling to use the tool to re-create his lost speaking voice from older recordings.&lt;/p&gt;  &lt;p&gt;“The first time I heard the voice, I thought it was amazing,” Darling said at the event, using the voice clone. “It sounded exactly like I had before, and you literally wouldn’t be able to tell the difference,” he said. “I will not say what the first word I made my new voice say, but I can tell you that it began with ‘f’ and ended in ‘k.’”&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Patrick and bandmates with their instruments prior to his MND diagnosis" class="wp-image-1132855" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/Patrick-and-bandmates-prior-to-MND-diagnosis-001.jpg?w=720" /&gt;&lt;div class="image-credit"&gt;COURTESY OF PATRICK DARLING&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Re-creating his singing voice wasn’t as easy. The tool typically requires around 10 minutes of clear audio to generate a clone. “I had no high-quality recordings of myself singing,” Darling said. “We had to use audio from videos on people’s phones, shot in noisy pubs, and a couple of recordings of me singing in my kitchen.” Still, those snippets were enough to create a “synthetic version of [Darling’s] singing voice,” says Cave.&lt;/p&gt;  &lt;p&gt;In the recordings, Darling sounded a little raspy and “was a bit off” on some of the notes, says Cave. The voice clone has the same qualities. It doesn’t sound perfect, Cave says—it sounds human.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_9"&gt;&lt;p&gt;“The ElevenLabs voice that we’ve created is wonderful,” Darling said at the event. “It definitely sounds like me—[it] just kind of feels like a different version of me.”&lt;/p&gt;  &lt;p&gt;ElevenLabs has also developed an AI music generator called Eleven Music. The tool allows users to compose tracks, using text prompts to choose the musical style. Several well-known artists have also partnered with the company to license AI clones of their voices, including the actor Michael Caine, whose voice clone is being used to narrate an upcoming ElevenLabs documentary. Last month, the company released an album of 11 tracks created using the tool. “The Liza Minnelli track is really a banger,” says Cave.&lt;/p&gt;  &lt;p&gt;Eleven Music can generate a song in a minute, but Darling and Cave spent around six weeks fine-tuning Darling’s song. Using text prompts, any user can “create music and add lyrics in any style [they like],” says Cave. Darling likes Irish folk, but Cave has also worked with a man in Colombia who is creating Colombian folk music. (The ElevenLabs tool is currently available in 74 languages.)&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;&lt;strong&gt;Back on stage&lt;/strong&gt;&lt;/h3&gt;  &lt;p&gt;Last month, Cocking got a call from Cave, who sent him Darling’s completed track. “I heard the first two or three words he sang, and I had to turn it off,” he says. “I was just in bits, in tears. It took me a good half a dozen times to make it to the end of the track.”&lt;/p&gt; 
 &lt;p&gt;Darling and Cave were making plans to perform the track live at the ElevenLabs summit in London on Wednesday, February 11. So Cocking and bandmate Hari Ma each arranged accompanying parts to play on the mandolin and fiddle. They had a couple of weeks to rehearse before they joined Darling on stage, two years after their last performance together.&lt;/p&gt;  &lt;p&gt;“I wheeled him out on stage, and neither of us could believe it was happening,” says Cave. “He was thrilled.” The song was played as Darling remained on stage, and Cocking and Ma played their instruments live.&lt;/p&gt;  &lt;p&gt;Cocking and Cave say Darling plans to continue to use the tools to make music. Cocking says he hopes to perform with Darling again but acknowledges that, given the nature of ALS, it is difficult to make long-term plans.&lt;/p&gt;  &lt;p&gt;“It’s so bittersweet,” says Cocking. “But getting up on stage and seeing Patrick there filled me with absolute joy. I know Patrick really enjoyed it as well. We’ve been talking about it … He was really, really proud.”&lt;/p&gt;  &lt;figure class="wp-block-video"&gt;&lt;video controls="controls" src="https://wp.technologyreview.com/wp-content/uploads/2026/02/ElevenLabs-PatrickDarling-720.mp4"&gt;&lt;/video&gt;&lt;div class="video-credit"&gt;ELEVENLABS/AMPLIFY&lt;/div&gt;  &lt;/figure&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/02/13/1132913/als-stole-this-musicians-voice-ai-sing/</guid><pubDate>Fri, 13 Feb 2026 17:17:28 +0000</pubDate></item><item><title>AI burnout, billion-dollar bets, and Silicon Valley’s Epstein problem (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/ai-burnout-billion-dollar-bets-and-silicon-valleys-epstein-problem/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2194754542.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;AI companies have been hemorrhaging&amp;nbsp;talent&amp;nbsp;the past few weeks. Half of&amp;nbsp;xAI’s&amp;nbsp;founding team&amp;nbsp;has left the company — some on their own, others through “restructuring” — while OpenAI is facing its own shakeups, from the&amp;nbsp;disbanding of its&amp;nbsp;mission alignment team&amp;nbsp;to the firing of a policy exec who opposed its “adult mode” feature.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On this episode of TechCrunch’s&amp;nbsp;Equity&amp;nbsp;podcast, hosts Kirsten Korosec, Anthony Ha, and Sean O’Kane dig into the week’s biggest deals and departures, from billion-dollar bets on fusion and robotics to the tech exodus reshaping AI companies.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



















&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2194754542.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;AI companies have been hemorrhaging&amp;nbsp;talent&amp;nbsp;the past few weeks. Half of&amp;nbsp;xAI’s&amp;nbsp;founding team&amp;nbsp;has left the company — some on their own, others through “restructuring” — while OpenAI is facing its own shakeups, from the&amp;nbsp;disbanding of its&amp;nbsp;mission alignment team&amp;nbsp;to the firing of a policy exec who opposed its “adult mode” feature.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On this episode of TechCrunch’s&amp;nbsp;Equity&amp;nbsp;podcast, hosts Kirsten Korosec, Anthony Ha, and Sean O’Kane dig into the week’s biggest deals and departures, from billion-dollar bets on fusion and robotics to the tech exodus reshaping AI companies.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&amp;nbsp;&lt;/p&gt;



















&lt;p class="has-text-align-left wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/ai-burnout-billion-dollar-bets-and-silicon-valleys-epstein-problem/</guid><pubDate>Fri, 13 Feb 2026 18:03:32 +0000</pubDate></item><item><title>OpenAI removes access to sycophancy-prone GPT-4o model (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/13/openai-removes-access-to-sycophancy-prone-gpt-4o-model/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Starting Friday, OpenAI will cease providing access  to five legacy ChatGPT models, including the popular but controversial GPT-4o model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 4o model has been at the center of a number of lawsuits concerning user self-harm, delusional behavior, and AI psychosis. It remains OpenAI’s highest scoring model for sycophancy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to GPT-4o, the GPT-5, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini models have also been deprecated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intended to retire GPT-4o in August, when it unveiled the GPT-5 model. But at the time, there was enough backlash for OpenAI to keep the legacy model available for paid subscribers, who could manually choose to interact with that model. In a recent blog post, OpenAI noted that only 0.1% of customers have been using GPT-4o, but for a company with 800 million weekly active users, that small percentage still amounts to 800,000 people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Thousands of users have rallied against the retirement of 4o, citing their close relationships with the model.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2195918462.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Starting Friday, OpenAI will cease providing access  to five legacy ChatGPT models, including the popular but controversial GPT-4o model.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The 4o model has been at the center of a number of lawsuits concerning user self-harm, delusional behavior, and AI psychosis. It remains OpenAI’s highest scoring model for sycophancy.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In addition to GPT-4o, the GPT-5, GPT-4.1, GPT-4.1 mini, and OpenAI o4-mini models have also been deprecated.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;OpenAI intended to retire GPT-4o in August, when it unveiled the GPT-5 model. But at the time, there was enough backlash for OpenAI to keep the legacy model available for paid subscribers, who could manually choose to interact with that model. In a recent blog post, OpenAI noted that only 0.1% of customers have been using GPT-4o, but for a company with 800 million weekly active users, that small percentage still amounts to 800,000 people.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Thousands of users have rallied against the retirement of 4o, citing their close relationships with the model.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/13/openai-removes-access-to-sycophancy-prone-gpt-4o-model/</guid><pubDate>Fri, 13 Feb 2026 18:10:00 +0000</pubDate></item><item><title>[NEW] Why top talent is walking away from OpenAI and xAI (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/video/why-top-talent-is-walking-away-from-openai-and-xai/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2236544077.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30929961"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;AI companies have been hemorrhaging&amp;nbsp;talent&amp;nbsp;the past few weeks. Half of&amp;nbsp;xAI’s&amp;nbsp;founding team&amp;nbsp;has left the company — some on their own, others through “restructuring” — while OpenAI is facing its own shakeups, from the&amp;nbsp;disbanding of its&amp;nbsp;mission alignment team&amp;nbsp;to the firing of a policy exec who opposed its “adult mode” feature.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as TechCrunch’s&amp;nbsp;Equity&amp;nbsp;podcast hosts Kirsten Korosec, Anthony Ha, and Sean O’Kane dig into the week’s biggest deals and departures, from billion-dollar bets on fusion and robotics to the tech exodus reshaping AI companies.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2236544077.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;div class="jwppp-video-box" id="jwppp-video-box-30929961"&gt;






&lt;span class="jwppp-instant"&gt;&lt;/span&gt;&lt;p&gt;Loading the player…&lt;/p&gt;
&lt;/div&gt;



&lt;p class="wp-block-paragraph"&gt;AI companies have been hemorrhaging&amp;nbsp;talent&amp;nbsp;the past few weeks. Half of&amp;nbsp;xAI’s&amp;nbsp;founding team&amp;nbsp;has left the company — some on their own, others through “restructuring” — while OpenAI is facing its own shakeups, from the&amp;nbsp;disbanding of its&amp;nbsp;mission alignment team&amp;nbsp;to the firing of a policy exec who opposed its “adult mode” feature.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Watch as TechCrunch’s&amp;nbsp;Equity&amp;nbsp;podcast hosts Kirsten Korosec, Anthony Ha, and Sean O’Kane dig into the week’s biggest deals and departures, from billion-dollar bets on fusion and robotics to the tech exodus reshaping AI companies.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Subscribe to Equity on&amp;nbsp;YouTube,&amp;nbsp;Apple Podcasts,&amp;nbsp;Overcast,&amp;nbsp;Spotify&amp;nbsp;and all the casts. You&amp;nbsp;also can&amp;nbsp;follow Equity on&amp;nbsp;X&amp;nbsp;and&amp;nbsp;Threads, at @EquityPod.&amp;nbsp;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/video/why-top-talent-is-walking-away-from-openai-and-xai/</guid><pubDate>Fri, 13 Feb 2026 21:00:00 +0000</pubDate></item><item><title>[NEW] Airbnb says a third of its customer support is now handled by AI in the US and Canada (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/13/airbnb-says-a-third-of-its-customer-support-is-now-handled-by-ai-in-the-u-s-and-canada/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/Airbnb-Summer-feat.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Airbnb says its custom-built AI agent is now handling roughly a third of its customer support issues in North America, and it’s preparing to roll out the feature globally. If successful, the company believes that in a year’s time, more than 30% of its total customer support tickets will be handled by AI voice and chat in all the languages where it also employs a human customer service agent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think this is going to be massive because not only does this reduce the cost base of Airbnb customer service, but the quality of service is going to be a huge step change,” CEO Brian Chesky said during the company’s fourth-quarter earnings call this week. This seems to suggest he believes the AI would do a better job than its human counterparts in resolving some issues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also touted its recent hire of CTO Ahmad Al-Dahle, poached from Meta for his AI expertise, and its plans to create an AI-native experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With his guidance, Chesky said that Airbnb was poised to introduce an app that doesn’t just search for you, but one that “knows you.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It will help guests plan their entire trip, help hosts better run their businesses, and help the company operate more efficiently at scale,” Chesky explained, adding that’s why Airbnb brought Al-Dahle on board. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ahmad is one of the world’s leading AI experts. He spent 16 years at Apple, and most recently led the generative AI team at Meta that built the Llama models. He’s an expert at pairing massive technical scale with world-class design, which is exactly how we’re going to transform the Airbnb experience,” Chesky noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like other businesses poised for disruption by AI, Airbnb’s leadership is pushing the idea that it has a unique database and product that other AI chatbots can’t replicate. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A chatbot doesn’t have our 200 million verified identities or our 500 million proprietary reviews, and it can’t message the hosts, which 90% of our guests do,” Chesky told analysts during the earnings call. Instead, he pitched the idea of layering AI over the Airbnb experience, which he claimed would help to accelerate growth. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company forecast revenue growth would be in the “low double digits” this year, after pulling in $2.78 billion in the fourth quarter, above estimates of $2.72 billion. This quarter, it expects revenue of $2.59 billion to $2.63 billion, above Wall Street forecasts of $2.53 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors still wanted to know if AI platforms could be a risk in the long-term, assuming they moved into the short-term rentals market. Chesky, however, pushed back at that idea, saying that Airbnb isn’t just the consumer-facing app; it’s also the host app, the customer service, and the protections it offers, like insurance and user verifications.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’ve built this over 18 years. We handle more than $100 billion in payments through the platform,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, AI chatbots serve a function similar to search, in that they deliver top-of-funnel traffic, he noted. That traffic also converts at a higher rate than traffic from Google, Chesky pointed out, suggesting that the shift to AI would benefit Airbnb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is already using AI to power its search, with the feature now enabled for a “very small percentage” of Airbnb’s traffic, while it experiments with making its search more conversational. Later, the company plans to integrate sponsored listings within search.   &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Spotify this week told investors its best developers hadn’t written a single line of code since December, thanks to AI, Airbnb offered a more high-level metric on its own internal AI adoption. The company said that 80% of its engineers now use AI tools, and it’s working to get that to 100% soon.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/Airbnb-Summer-feat.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Airbnb says its custom-built AI agent is now handling roughly a third of its customer support issues in North America, and it’s preparing to roll out the feature globally. If successful, the company believes that in a year’s time, more than 30% of its total customer support tickets will be handled by AI voice and chat in all the languages where it also employs a human customer service agent.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We think this is going to be massive because not only does this reduce the cost base of Airbnb customer service, but the quality of service is going to be a huge step change,” CEO Brian Chesky said during the company’s fourth-quarter earnings call this week. This seems to suggest he believes the AI would do a better job than its human counterparts in resolving some issues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The company also touted its recent hire of CTO Ahmad Al-Dahle, poached from Meta for his AI expertise, and its plans to create an AI-native experience.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;With his guidance, Chesky said that Airbnb was poised to introduce an app that doesn’t just search for you, but one that “knows you.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It will help guests plan their entire trip, help hosts better run their businesses, and help the company operate more efficiently at scale,” Chesky explained, adding that’s why Airbnb brought Al-Dahle on board. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ahmad is one of the world’s leading AI experts. He spent 16 years at Apple, and most recently led the generative AI team at Meta that built the Llama models. He’s an expert at pairing massive technical scale with world-class design, which is exactly how we’re going to transform the Airbnb experience,” Chesky noted.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like other businesses poised for disruption by AI, Airbnb’s leadership is pushing the idea that it has a unique database and product that other AI chatbots can’t replicate. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“A chatbot doesn’t have our 200 million verified identities or our 500 million proprietary reviews, and it can’t message the hosts, which 90% of our guests do,” Chesky told analysts during the earnings call. Instead, he pitched the idea of layering AI over the Airbnb experience, which he claimed would help to accelerate growth. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company forecast revenue growth would be in the “low double digits” this year, after pulling in $2.78 billion in the fourth quarter, above estimates of $2.72 billion. This quarter, it expects revenue of $2.59 billion to $2.63 billion, above Wall Street forecasts of $2.53 billion.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Investors still wanted to know if AI platforms could be a risk in the long-term, assuming they moved into the short-term rentals market. Chesky, however, pushed back at that idea, saying that Airbnb isn’t just the consumer-facing app; it’s also the host app, the customer service, and the protections it offers, like insurance and user verifications.  &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We’ve built this over 18 years. We handle more than $100 billion in payments through the platform,” he said. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, AI chatbots serve a function similar to search, in that they deliver top-of-funnel traffic, he noted. That traffic also converts at a higher rate than traffic from Google, Chesky pointed out, suggesting that the shift to AI would benefit Airbnb.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company is already using AI to power its search, with the feature now enabled for a “very small percentage” of Airbnb’s traffic, while it experiments with making its search more conversational. Later, the company plans to integrate sponsored listings within search.   &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While Spotify this week told investors its best developers hadn’t written a single line of code since December, thanks to AI, Airbnb offered a more high-level metric on its own internal AI adoption. The company said that 80% of its engineers now use AI tools, and it’s working to get that to 100% soon.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/13/airbnb-says-a-third-of-its-customer-support-is-now-handled-by-ai-in-the-u-s-and-canada/</guid><pubDate>Fri, 13 Feb 2026 22:12:26 +0000</pubDate></item><item><title>[NEW] Aided by AI, California beach town broadens hunt for bike lane blockers (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/02/santa-monica-deploys-ai-powered-parking-cameras-to-protect-bike-lanes/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Hayden AI’s cameras will scan for violations from 7 city vehicles.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo of a Hayden AI camera at work." class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/hayden-ai-640x379.jpg" width="640" /&gt;
                  &lt;img alt="Photo of a Hayden AI camera at work." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/hayden-ai-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Hayden AI camera at work.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Hayden AI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;This spring, a Southern California beach town will become the first city in the country where municipal parking enforcement vehicles will use an AI system looking for potential bike lane violations.&lt;/p&gt;
&lt;p&gt;Beginning in April, the City of Santa Monica will bring Hayden AI’s scanning technology to seven cars in its parking enforcement fleet, expanding beyond similar cameras already mounted on city buses.&lt;/p&gt;
&lt;p&gt;“The more we can reduce the amount of illegal parking, the safer we can make it for bike riders,” Charley Territo, chief growth officer at Hayden AI, told Ars.&lt;/p&gt;
&lt;p&gt;Hayden AI’s bus cameras, designed to detect bike lane and bus zone violations, currently exist in two other California cities: Oakland and Sacramento. The company also has installations around the country, including New York City, Washington, DC, and Philadelphia. In September 2025, the company announced that it had installed 2,000 systems on buses worldwide.&lt;/p&gt;
&lt;p&gt;Late last year, over a 59-day period, Hayden AI also said its technology detected over 1,100 parking violations at the University of California, San Diego—and 88 percent of those were instances of blocking a bike lane.&lt;/p&gt;
&lt;p&gt;Hayden AI says it sells its product to municipalities and related entities to not only increase bus speed (by removing obstructions) but also improve safety.&lt;/p&gt;
&lt;p&gt;“We do that by [reducing] one of the biggest causes of collisions with buses—moving out of their lanes,” Territo added. “So the fewer times they have to make a turn, the fewer instances there are [of a crash].”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As part of its setup process, the San Francisco-based startup says that it begins any installation by first mapping a city. Then it teaches the AI the local parking enforcement rules. Typically, those rules say that cars can’t block a bike or bus lane. Traditionally, Hayden AI’s cameras have only been mounted on buses, so enforcement was limited to existing routes.&lt;/p&gt;
&lt;p&gt;“We tell our system that if you see a vehicle that encroaches on a bike lane, capture a 10-second video and the license plate of that vehicle,” Territo said.&lt;/p&gt;
&lt;p&gt;“From there, an evidence package goes to the [police] and they will review and verify the elements—that a prosecutable violation exists—and then they will issue a violation under [state law]. If there is no violation, the system doesn’t capture any data. The system is only looking for scenarios where a bike lane is blocked and a license plate is evident.”&lt;/p&gt;
&lt;p&gt;Local bike advocates have applauded this expansion of automated enforcement.&lt;/p&gt;
&lt;p&gt;“Enforcement cannot be everywhere at once. If we can extend their arm so these things can get done, and keep our community safe, that is a win,” Cynthia Rose, the director of Santa Monica Spoke, told Ars. While warning of the potential misuse of bulk data collection in general, Rose was on board with Hayden AI’s particular plan.&lt;/p&gt;
&lt;p&gt;“Anywhere where there’s bike infrastructure, where I know of, [blocking the lane] is a problem,” Rose said. “It’s tantamount to parking in handicapped zones. It’s just a flat no.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;








  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Hayden AI’s cameras will scan for violations from 7 city vehicles.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Photo of a Hayden AI camera at work." class="absolute inset-0 w-full h-full object-cover hidden" height="379" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/hayden-ai-640x379.jpg" width="640" /&gt;
                  &lt;img alt="Photo of a Hayden AI camera at work." class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/02/hayden-ai-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A Hayden AI camera at work.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Hayden AI

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;This spring, a Southern California beach town will become the first city in the country where municipal parking enforcement vehicles will use an AI system looking for potential bike lane violations.&lt;/p&gt;
&lt;p&gt;Beginning in April, the City of Santa Monica will bring Hayden AI’s scanning technology to seven cars in its parking enforcement fleet, expanding beyond similar cameras already mounted on city buses.&lt;/p&gt;
&lt;p&gt;“The more we can reduce the amount of illegal parking, the safer we can make it for bike riders,” Charley Territo, chief growth officer at Hayden AI, told Ars.&lt;/p&gt;
&lt;p&gt;Hayden AI’s bus cameras, designed to detect bike lane and bus zone violations, currently exist in two other California cities: Oakland and Sacramento. The company also has installations around the country, including New York City, Washington, DC, and Philadelphia. In September 2025, the company announced that it had installed 2,000 systems on buses worldwide.&lt;/p&gt;
&lt;p&gt;Late last year, over a 59-day period, Hayden AI also said its technology detected over 1,100 parking violations at the University of California, San Diego—and 88 percent of those were instances of blocking a bike lane.&lt;/p&gt;
&lt;p&gt;Hayden AI says it sells its product to municipalities and related entities to not only increase bus speed (by removing obstructions) but also improve safety.&lt;/p&gt;
&lt;p&gt;“We do that by [reducing] one of the biggest causes of collisions with buses—moving out of their lanes,” Territo added. “So the fewer times they have to make a turn, the fewer instances there are [of a crash].”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;As part of its setup process, the San Francisco-based startup says that it begins any installation by first mapping a city. Then it teaches the AI the local parking enforcement rules. Typically, those rules say that cars can’t block a bike or bus lane. Traditionally, Hayden AI’s cameras have only been mounted on buses, so enforcement was limited to existing routes.&lt;/p&gt;
&lt;p&gt;“We tell our system that if you see a vehicle that encroaches on a bike lane, capture a 10-second video and the license plate of that vehicle,” Territo said.&lt;/p&gt;
&lt;p&gt;“From there, an evidence package goes to the [police] and they will review and verify the elements—that a prosecutable violation exists—and then they will issue a violation under [state law]. If there is no violation, the system doesn’t capture any data. The system is only looking for scenarios where a bike lane is blocked and a license plate is evident.”&lt;/p&gt;
&lt;p&gt;Local bike advocates have applauded this expansion of automated enforcement.&lt;/p&gt;
&lt;p&gt;“Enforcement cannot be everywhere at once. If we can extend their arm so these things can get done, and keep our community safe, that is a win,” Cynthia Rose, the director of Santa Monica Spoke, told Ars. While warning of the potential misuse of bulk data collection in general, Rose was on board with Hayden AI’s particular plan.&lt;/p&gt;
&lt;p&gt;“Anywhere where there’s bike infrastructure, where I know of, [blocking the lane] is a problem,” Rose said. “It’s tantamount to parking in handicapped zones. It’s just a flat no.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;








  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/02/santa-monica-deploys-ai-powered-parking-cameras-to-protect-bike-lanes/</guid><pubDate>Fri, 13 Feb 2026 23:03:08 +0000</pubDate></item></channel></rss>