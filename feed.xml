<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 13 Jan 2026 01:53:28 +0000</lastBuildDate><item><title>[NEW] Mitigating emissions from air freight: Unlocking the potential of SAF with book and claim (MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/12/1128939/mitigating-emissions-from-air-freight-unlocking-the-potential-of-saf-with-book-and-claim/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/MITTRIShell-webcast-open-closing-card.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Avelia&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Emissions from air freight have increased by 25% since 2019, according to a 2024 analysis by environmental advocacy organization Stand.Earth.&lt;/p&gt;  &lt;p&gt;The researchers found that the expansion of cargo-only fleets to transport goods during the pandemic — as air travel halted, slower freight modes faced disruption, but demand for rapid delivery soared — has led to a yearly increase of almost 20 million tons of carbon dioxide, making up 93.8m tonnes from air freight overall.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;div&gt;[embedded content]&lt;/div&gt;    &lt;p&gt;And though fleet modernization and operational improvements by freight operators have contributed to ongoing decarbonization efforts, sustainable aviation fuel (SAF) looks set to be instrumental in helping the sector achieve its ambitions to reduce environmental footprint in the long-term.&lt;/p&gt;  &lt;p&gt;When used neat, or pure and unblended, SAF can help reduce the life cycle of greenhouse gas emissions from aviation by as much as 80% relative to conventional fuel. It’s why the International Air Transport Association (IATA) estimates that SAF could account for as much as 65% of total reduction of emissions.&lt;/p&gt; 
 &lt;p&gt;For Christoph Wolff, CEO of the Smart Freight Centre, “SAF is the main pathway” to decarbonization across both freight and the wider aviation ecosystem.&lt;/p&gt;  &lt;p&gt;“The great thing about SAF is it’s chemically identical to Jet A fuel,” he says. “You can blend it [which means] you have a pathway to ramp it up. You can start small and you can scale it. By scaling it there is the promise or the hope that the price comes down.”&lt;/p&gt; 
 &lt;p&gt;At at least twice the price of conventional jet fuel, cost is a significant barrier hindering broader adoption.&lt;/p&gt;  &lt;p&gt;And it isn’t the only one standing between SAF and wider penetration.&lt;/p&gt;  &lt;p&gt;Bridging the gap between a concentrated supply of SAF and global demand also remains a major hurdle.&lt;/p&gt;  &lt;p&gt;Though the number of verified SAF outlets has increased from fewer than 20 locations in 2021 to 114 as of April 2025, according to sustainability solutions framework 4Air, that accounts for only 92 airports worldwide out of more than 40,000.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“SAF is central to the decarbonization of the aviation sector,” believes Raman Ojha, president of Shell Aviation. “Having said that, adoption and penetration of SAF hasn't really picked up massively. It's not due to lack of production capacity, but there are lots of things that are at play. And book and claim in that context helps to bridge that gap.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Bridging the gap with book and claim&lt;/h3&gt;  &lt;p&gt;Book and claim is a chain of custody model, where the flow of administrative records is not necessarily connected to the physical product through the supply chain (source: ISO 22095:2020).&lt;/p&gt;  &lt;p&gt;Book and claim potentially enables airlines and corporations to access the life cycle GHG emissions reduction benefits of SAF relative to conventional jet fuel even when SAF is not physically available at their location; this model helps bridge the gap between that concentrated supply and global demand, until SAF’s availability improves.&lt;/p&gt;  &lt;p&gt;“To be bold, without book and claim, no short-term science-based target will be achieved,” says Bettina Paschke, vice president of ESG accounting, reporting and controlling at DHL Express. “Book and claim is essential to achieving science-based targets.”&lt;/p&gt; 

 &lt;p&gt;“SAF production facilities are not everywhere,” she reiterates. “They're very focused on one location, and if a customer wants to fulfil a mass balance obligation, SAF would need to be shipped around the world just to be at that airport for that customer. That would be very complicated, and very unrealistic.” It would also, counterintuitively, increase total emissions. By using book and claim instead, air freight operators can unlock the life cycle greenhouse gas emissions reduction benefits of SAF relative to conventional jet fuel now, without waiting for supply to broaden. “It might no longer be needed when we have SAF product facilities at each airport in the future,” she points out. “But at the moment, that’s not the case.”&lt;/p&gt;  &lt;p&gt;At DHL itself, the mechanism has become central to achieving its own three interconnected sustainability pillars, which focus on decarbonizing logistics supply chains, supporting customers toward their decarbonization goals, and ensuring credible emission claims can be shared along the value chain.&lt;/p&gt;  &lt;p&gt;Demonstrating the importance of a credible and viable framework for book and claim systems is also what inspired the 2022 launch of Shell’s Avelia, one of the first blockchain-powered digital SAF book and claim solutions for aviation, which expanded in 2024 to encompass air freight in addition to business travel. Depending on the offering, Avelia offers freight forwarders the opportunity to share the life cycle greenhouse gas emissions reduction benefits of SAF relative to conventional jet fuel across the value chain with shippers using their services.&lt;/p&gt;  &lt;p&gt;“It’s also backed by a physical supply chain, which gives our customers — whether those be corporates or freight forwarders or even airlines — a peace of mind that the SAF has been injected at a certain airport, it’s been used and environmental attributes, with the help of blockchain, have been tracked to where they're getting retired,” says Ojha.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;He adds: “The most important or critical part is the transparency that it's providing to our customers to be sure that they're not saying something which they can't confidently stand behind.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Moving beyond early adoption&lt;/h3&gt;  &lt;p&gt;To scale up SAF via book and claim and help make it a more commercially viable lower-carbon solution, its adoption will need to be a coordinated “ecosystem play,” says Wolff. That includes early adopters, such as DHL, inspiring action from peers, solution providers such as Shell, working with various stakeholders to drive joint advocacy, and industry associations, like the Smart Freight Centre creating the required frameworks, educational resources, and industry alignment.&lt;/p&gt;  &lt;p&gt;An active book and claim community made up of many forward-thinking advocates is already driving much of this work forward with a common goal to develop greater standardization and consensus, Wolff points out. “It helps to make sure all definitions on the system are compatible and they can talk to one another, provide educational support, and [also that] there’s a repository of transactions so that it can be documented in a way that people can see and think, ‘oh this is how we do it.’ There are some early adopters that are very experienced, but it needs a lot more people for it to get comfortable.”&lt;/p&gt;  &lt;p&gt;In early 2024, discussions were held with a diverse group of expert book and claim stakeholders to develop and refine 11 key principles and best practices book and claim models. These represent an aligned set of principles informed by practical successes and challenges faced by practitioners working to decarbonize the heavy transport sector.&lt;/p&gt; 
 &lt;p&gt;Adherence to such a framework is crucial given that book and claim is not yet accepted by the Greenhouse Gas (GHG) Protocol nor the Science Based Targets Initiative (SBTi) as a recognized model for reducing greenhouse gas emissions — though there are hopes that might change.&lt;/p&gt;  &lt;p&gt;“The industrialization of book and claim delivery systems is key to credibility and recognition,” says Wolff. “The Greenhouse Gas Protocol and the Science Based Targets Initiative are making steps in recognizing that. There’s a pathway that the Smart Freight Centre is very closely involved in the technical working groups for [looking]to build such a system where, in addition to physical inventory, you also pursue market-based inventories.”&lt;/p&gt; 
 &lt;p&gt;Paschke urges companies not to sit back and wait for policy to change before taking action, though. “The solution is there,” she says. “There are companies like DHL that are making huge upfront investments, and every single contribution helps to scale the industry and give a strong signal to the eco-space.”&lt;/p&gt;  &lt;p&gt;As pressure to accelerate decarbonization gains pace, it’s critical that air freight operators consider this now, agrees Ojha. “Don't wait for perfection in guidelines, regulations, or platforms — act now,” he says. “That’s very, very critical. Second, learn by doing and join hands with others. Don’t try to do everything independently or in-house.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;“Third, make use of registries and platforms, such as Avelia, that can give credibility. Join them, utilize them, and leverage them so that you won’t have to establish auditability from scratch.&lt;/p&gt;  &lt;p&gt;“And fourth, don’t look at scope book and claim as a means for acquiring a certificate for environmental attributes. Think in terms of your decarbonisation commitment and think of this as a tool for exposure management. Think in terms of the bigger picture.”&lt;/p&gt;  &lt;p&gt;That bigger picture being a significant sector-wide push toward faster decarbonization — and turning the tide on emissions’ steep upward ascent.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the full webcast.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content is produced by MIT Technology Review Insights in association with Avelia. Avelia is a Shell owned solution and brand that was developed with support from Amex GBT, Accenture and Energy Web Foundation. The views from individuals not affiliated with Shell are their own and not those of Shell PLC or its affiliates.&amp;nbsp;Cautionary note | Shell Global&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/12/MITTRIShell-webcast-open-closing-card.png?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;section class="sponsoredModule__wrapper--c8f6fcf4edb2dcd3a940a2824bb850dc sponsoredModule__minimalist--f63b84a37007076f51d0ebb0dc1af42f"&gt;&lt;p class="sponsoredModule__intro--e69c514244f1e38617e4ec5ea754fb7f"&gt;&lt;span&gt;In association with&lt;/span&gt;&lt;span class="sponsoredModule__name--dbd90349922f15155a4c483b397356c2"&gt;Avelia&lt;/span&gt;&lt;/p&gt;&lt;/section&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;Emissions from air freight have increased by 25% since 2019, according to a 2024 analysis by environmental advocacy organization Stand.Earth.&lt;/p&gt;  &lt;p&gt;The researchers found that the expansion of cargo-only fleets to transport goods during the pandemic — as air travel halted, slower freight modes faced disruption, but demand for rapid delivery soared — has led to a yearly increase of almost 20 million tons of carbon dioxide, making up 93.8m tonnes from air freight overall.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;div&gt;[embedded content]&lt;/div&gt;    &lt;p&gt;And though fleet modernization and operational improvements by freight operators have contributed to ongoing decarbonization efforts, sustainable aviation fuel (SAF) looks set to be instrumental in helping the sector achieve its ambitions to reduce environmental footprint in the long-term.&lt;/p&gt;  &lt;p&gt;When used neat, or pure and unblended, SAF can help reduce the life cycle of greenhouse gas emissions from aviation by as much as 80% relative to conventional fuel. It’s why the International Air Transport Association (IATA) estimates that SAF could account for as much as 65% of total reduction of emissions.&lt;/p&gt; 
 &lt;p&gt;For Christoph Wolff, CEO of the Smart Freight Centre, “SAF is the main pathway” to decarbonization across both freight and the wider aviation ecosystem.&lt;/p&gt;  &lt;p&gt;“The great thing about SAF is it’s chemically identical to Jet A fuel,” he says. “You can blend it [which means] you have a pathway to ramp it up. You can start small and you can scale it. By scaling it there is the promise or the hope that the price comes down.”&lt;/p&gt; 
 &lt;p&gt;At at least twice the price of conventional jet fuel, cost is a significant barrier hindering broader adoption.&lt;/p&gt;  &lt;p&gt;And it isn’t the only one standing between SAF and wider penetration.&lt;/p&gt;  &lt;p&gt;Bridging the gap between a concentrated supply of SAF and global demand also remains a major hurdle.&lt;/p&gt;  &lt;p&gt;Though the number of verified SAF outlets has increased from fewer than 20 locations in 2021 to 114 as of April 2025, according to sustainability solutions framework 4Air, that accounts for only 92 airports worldwide out of more than 40,000.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;“SAF is central to the decarbonization of the aviation sector,” believes Raman Ojha, president of Shell Aviation. “Having said that, adoption and penetration of SAF hasn't really picked up massively. It's not due to lack of production capacity, but there are lots of things that are at play. And book and claim in that context helps to bridge that gap.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Bridging the gap with book and claim&lt;/h3&gt;  &lt;p&gt;Book and claim is a chain of custody model, where the flow of administrative records is not necessarily connected to the physical product through the supply chain (source: ISO 22095:2020).&lt;/p&gt;  &lt;p&gt;Book and claim potentially enables airlines and corporations to access the life cycle GHG emissions reduction benefits of SAF relative to conventional jet fuel even when SAF is not physically available at their location; this model helps bridge the gap between that concentrated supply and global demand, until SAF’s availability improves.&lt;/p&gt;  &lt;p&gt;“To be bold, without book and claim, no short-term science-based target will be achieved,” says Bettina Paschke, vice president of ESG accounting, reporting and controlling at DHL Express. “Book and claim is essential to achieving science-based targets.”&lt;/p&gt; 

 &lt;p&gt;“SAF production facilities are not everywhere,” she reiterates. “They're very focused on one location, and if a customer wants to fulfil a mass balance obligation, SAF would need to be shipped around the world just to be at that airport for that customer. That would be very complicated, and very unrealistic.” It would also, counterintuitively, increase total emissions. By using book and claim instead, air freight operators can unlock the life cycle greenhouse gas emissions reduction benefits of SAF relative to conventional jet fuel now, without waiting for supply to broaden. “It might no longer be needed when we have SAF product facilities at each airport in the future,” she points out. “But at the moment, that’s not the case.”&lt;/p&gt;  &lt;p&gt;At DHL itself, the mechanism has become central to achieving its own three interconnected sustainability pillars, which focus on decarbonizing logistics supply chains, supporting customers toward their decarbonization goals, and ensuring credible emission claims can be shared along the value chain.&lt;/p&gt;  &lt;p&gt;Demonstrating the importance of a credible and viable framework for book and claim systems is also what inspired the 2022 launch of Shell’s Avelia, one of the first blockchain-powered digital SAF book and claim solutions for aviation, which expanded in 2024 to encompass air freight in addition to business travel. Depending on the offering, Avelia offers freight forwarders the opportunity to share the life cycle greenhouse gas emissions reduction benefits of SAF relative to conventional jet fuel across the value chain with shippers using their services.&lt;/p&gt;  &lt;p&gt;“It’s also backed by a physical supply chain, which gives our customers — whether those be corporates or freight forwarders or even airlines — a peace of mind that the SAF has been injected at a certain airport, it’s been used and environmental attributes, with the help of blockchain, have been tracked to where they're getting retired,” says Ojha.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;He adds: “The most important or critical part is the transparency that it's providing to our customers to be sure that they're not saying something which they can't confidently stand behind.”&lt;/p&gt;  &lt;h3 class="wp-block-heading"&gt;Moving beyond early adoption&lt;/h3&gt;  &lt;p&gt;To scale up SAF via book and claim and help make it a more commercially viable lower-carbon solution, its adoption will need to be a coordinated “ecosystem play,” says Wolff. That includes early adopters, such as DHL, inspiring action from peers, solution providers such as Shell, working with various stakeholders to drive joint advocacy, and industry associations, like the Smart Freight Centre creating the required frameworks, educational resources, and industry alignment.&lt;/p&gt;  &lt;p&gt;An active book and claim community made up of many forward-thinking advocates is already driving much of this work forward with a common goal to develop greater standardization and consensus, Wolff points out. “It helps to make sure all definitions on the system are compatible and they can talk to one another, provide educational support, and [also that] there’s a repository of transactions so that it can be documented in a way that people can see and think, ‘oh this is how we do it.’ There are some early adopters that are very experienced, but it needs a lot more people for it to get comfortable.”&lt;/p&gt;  &lt;p&gt;In early 2024, discussions were held with a diverse group of expert book and claim stakeholders to develop and refine 11 key principles and best practices book and claim models. These represent an aligned set of principles informed by practical successes and challenges faced by practitioners working to decarbonize the heavy transport sector.&lt;/p&gt; 
 &lt;p&gt;Adherence to such a framework is crucial given that book and claim is not yet accepted by the Greenhouse Gas (GHG) Protocol nor the Science Based Targets Initiative (SBTi) as a recognized model for reducing greenhouse gas emissions — though there are hopes that might change.&lt;/p&gt;  &lt;p&gt;“The industrialization of book and claim delivery systems is key to credibility and recognition,” says Wolff. “The Greenhouse Gas Protocol and the Science Based Targets Initiative are making steps in recognizing that. There’s a pathway that the Smart Freight Centre is very closely involved in the technical working groups for [looking]to build such a system where, in addition to physical inventory, you also pursue market-based inventories.”&lt;/p&gt; 
 &lt;p&gt;Paschke urges companies not to sit back and wait for policy to change before taking action, though. “The solution is there,” she says. “There are companies like DHL that are making huge upfront investments, and every single contribution helps to scale the industry and give a strong signal to the eco-space.”&lt;/p&gt;  &lt;p&gt;As pressure to accelerate decarbonization gains pace, it’s critical that air freight operators consider this now, agrees Ojha. “Don't wait for perfection in guidelines, regulations, or platforms — act now,” he says. “That’s very, very critical. Second, learn by doing and join hands with others. Don’t try to do everything independently or in-house.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt;&lt;p&gt;“Third, make use of registries and platforms, such as Avelia, that can give credibility. Join them, utilize them, and leverage them so that you won’t have to establish auditability from scratch.&lt;/p&gt;  &lt;p&gt;“And fourth, don’t look at scope book and claim as a means for acquiring a certificate for environmental attributes. Think in terms of your decarbonisation commitment and think of this as a tool for exposure management. Think in terms of the bigger picture.”&lt;/p&gt;  &lt;p&gt;That bigger picture being a significant sector-wide push toward faster decarbonization — and turning the tide on emissions’ steep upward ascent.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Watch the full webcast.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Review’s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This content is produced by MIT Technology Review Insights in association with Avelia. Avelia is a Shell owned solution and brand that was developed with support from Amex GBT, Accenture and Energy Web Foundation. The views from individuals not affiliated with Shell are their own and not those of Shell PLC or its affiliates.&amp;nbsp;Cautionary note | Shell Global&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/12/1128939/mitigating-emissions-from-air-freight-unlocking-the-potential-of-saf-with-book-and-claim/</guid><pubDate>Mon, 12 Jan 2026 14:00:00 +0000</pubDate></item><item><title>[NEW] Harmattan AI raises $200M Series B led by Dassault Aviation, becomes defense unicorn (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/harmattan-ai-raises-200m-series-b-led-by-dassault-aviation-becomes-defense-unicorn/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2220168874.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;French defense tech company Harmattan AI is rising almost as fast as the supersonic planes of its new backer. Founded in 2024, the company is now valued at $1.4 billion after raising a $200 million Series B round led by Dassault Aviation, which is best known for making the Rafale fighter jet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harmattan AI, which builds autonomy and mission-system software for defense aircraft, had already received strong validation signals from the French and British ministries of defense in its less than two years of existence. But this funding and the accompanying partnership will give new wings to a company that once described itself as a “European Anduril.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Like its American peer, Harmattan AI once aspired to overtake defense incumbents, which are also known as primes. But the company is now also ready to partner with them — even if it means no longer calling itself “a next-generation defense prime.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Harmattan’s latest press release, the now “defense technology company” will help Dassault Aviation shape the future of air combat by developing embedded AI capabilities for its next generations of Rafales and drones while making sure this implementation is both sovereign and scalable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The use of drones in Ukraine has been a wake-up call for NATO armies, creating tailwinds for defense tech startups that can help them adapt. According to Harmattan AI, which recently partnered with Ukrainian drone maker Skyeton, the funding will help it extend its product offering into new domains and scale manufacturing of its platforms for drone interception, electronic warfare, and ISR (Intelligence, Surveillance, and Reconnaissance).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;French president Emmanuel Macron praised the announcement on social media, calling it “excellent news for our strategic autonomy, for the technological superiority of our armed forces in the field of AI-activated defense drones, as well as for our economy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While important for France, this strategic play isn’t exclusive. Harmattan AI’s stated goal of “empowering the armed forces of liberal democracies and their allies” leaves some wiggle room for the company to sell its technology beyond France and Europe. The company is already putting this into action: it will exhibit at the World Defense Show in Riyadh next month, and is expanding its U.S. team.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company claimed a new record in July when it was awarded a “multi-million-U.S. dollar contract by a NATO government” for the delivery of AI-enabled small drones, just one year after its founding. But according to its CEO and co-founder, Mouad M’Ghari, Harmattan AI is now “entering a new phase of scale” as it seeks to “ramp-up manufacturing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In that same LinkedIn post, the entrepreneur disclosed that the new funding comes in addition to the $42 million Harmattan AI had raised to date, including a seed round led by Atlantic and a Series A led by FirstMark, with other backers including Motier Ventures and Sisyphus Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Harmattan AI’s CTO and co-founder Martin de Gourcuff chose a different note with political undertones. “As the international order goes off the rails,” he wrote, “we are entering an era where, increasingly, power precedes law. A reversal of the civilized world we strive for. Harmattan AI exists to protect our values and flip that relationship back, as power without law is just mere violence.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was updated to correct Skyeton’s origins.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2220168874.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;French defense tech company Harmattan AI is rising almost as fast as the supersonic planes of its new backer. Founded in 2024, the company is now valued at $1.4 billion after raising a $200 million Series B round led by Dassault Aviation, which is best known for making the Rafale fighter jet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Harmattan AI, which builds autonomy and mission-system software for defense aircraft, had already received strong validation signals from the French and British ministries of defense in its less than two years of existence. But this funding and the accompanying partnership will give new wings to a company that once described itself as a “European Anduril.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Like its American peer, Harmattan AI once aspired to overtake defense incumbents, which are also known as primes. But the company is now also ready to partner with them — even if it means no longer calling itself “a next-generation defense prime.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to Harmattan’s latest press release, the now “defense technology company” will help Dassault Aviation shape the future of air combat by developing embedded AI capabilities for its next generations of Rafales and drones while making sure this implementation is both sovereign and scalable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The use of drones in Ukraine has been a wake-up call for NATO armies, creating tailwinds for defense tech startups that can help them adapt. According to Harmattan AI, which recently partnered with Ukrainian drone maker Skyeton, the funding will help it extend its product offering into new domains and scale manufacturing of its platforms for drone interception, electronic warfare, and ISR (Intelligence, Surveillance, and Reconnaissance).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;French president Emmanuel Macron praised the announcement on social media, calling it “excellent news for our strategic autonomy, for the technological superiority of our armed forces in the field of AI-activated defense drones, as well as for our economy.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While important for France, this strategic play isn’t exclusive. Harmattan AI’s stated goal of “empowering the armed forces of liberal democracies and their allies” leaves some wiggle room for the company to sell its technology beyond France and Europe. The company is already putting this into action: it will exhibit at the World Defense Show in Riyadh next month, and is expanding its U.S. team.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The company claimed a new record in July when it was awarded a “multi-million-U.S. dollar contract by a NATO government” for the delivery of AI-enabled small drones, just one year after its founding. But according to its CEO and co-founder, Mouad M’Ghari, Harmattan AI is now “entering a new phase of scale” as it seeks to “ramp-up manufacturing.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In that same LinkedIn post, the entrepreneur disclosed that the new funding comes in addition to the $42 million Harmattan AI had raised to date, including a seed round led by Atlantic and a Series A led by FirstMark, with other backers including Motier Ventures and Sisyphus Ventures.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Harmattan AI’s CTO and co-founder Martin de Gourcuff chose a different note with political undertones. “As the international order goes off the rails,” he wrote, “we are entering an era where, increasingly, power precedes law. A reversal of the civilized world we strive for. Harmattan AI exists to protect our values and flip that relationship back, as power without law is just mere violence.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This story was updated to correct Skyeton’s origins.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/harmattan-ai-raises-200m-series-b-led-by-dassault-aviation-becomes-defense-unicorn/</guid><pubDate>Mon, 12 Jan 2026 14:00:44 +0000</pubDate></item><item><title>[NEW] UK probes X over Grok CSAM scandal; Elon Musk cries censorship (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/01/uk-investigating-x-after-grok-undressed-thousands-of-women-and-children/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Grok tests if UK can penalize platforms for sexualized deepfakes generated by AI.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2246892016-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2246892016-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          BRENDAN SMIALOWSKI / Contributor | AFP

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Elon Musk’s X is currently under investigation in the United Kingdom after failing to stop the platform’s chatbot, Grok, from generating thousands of sexualized images of women and children.&lt;/p&gt;
&lt;p&gt;On Monday, UK media regulator Ofcom confirmed that X may have violated the UK’s Online Safety Act, which requires platforms to block illegal content. The proliferation of “undressed images of people” by X users may amount to intimate image abuse, pornography, and child sexual abuse material (CSAM), the regulator said. And X may also have neglected its duty to stop kids from seeing porn.&lt;/p&gt;
&lt;p&gt;“Reports of Grok being used to create and share illegal non-consensual intimate images and child sexual abuse material on X have been deeply concerning,” an Ofcom spokesperson said. “Platforms must protect people in the UK from content that’s illegal in the UK, and we won’t hesitate to investigate where we suspect companies are failing in their duties, especially where there’s a risk of harm to children.”&lt;/p&gt;
&lt;h2&gt;X risks fines, Grok block&lt;/h2&gt;
&lt;p&gt;X is cooperating with the probe, Ofcom said, noting that X met a “firm” deadline last week to explain what steps it’s taking to comply with the UK law. Ofcom declined Ars’ request to share more details about possible changes X has already made to either limit Grok in the UK or more broadly, since the investigation is “live.”&lt;/p&gt;
&lt;p&gt;Grok has already been blocked in Indonesia and Malaysia, as the chatbot remains unchecked. The UK could be next to block Grok if X fails to comply with the Online Safety Act. Additionally, X could face fines of up to 10 percent of its global revenue.&lt;/p&gt;
&lt;p&gt;It’s unclear how long the probe will take to conclude. Ofcom’s spokesperson told Ars that the agency will progress the investigation “as a matter of the highest priority, while ensuring we follow due process.” The probe will end “as soon as reasonably possible.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;X will have an opportunity to respond to Ofcom’s preliminary ruling before any final decision is made.&lt;/p&gt;
&lt;p&gt;Ars could not reach X to comment on the probe, but Musk has complained that Grok critics are looking for an “excuse for censorship,” the BBC reported. X has previously said that it will report harmful outputs to law enforcement and permanently suspend accounts that are abusing Grok to nudify images that X deems to be illegal content. The platform also started charging some users to edit images, instead of blocking outputs.&lt;/p&gt;
&lt;h2&gt;Grok tests UK’s power to regulate deepfakes&lt;/h2&gt;
&lt;p&gt;Shortly after Ofcom announced the probe, UK Technology Secretary Liz Kendall said the country would be bringing a new law into force that makes it illegal for companies to supply tools designed to create sexualized images, the BBC reported.&lt;/p&gt;
&lt;p&gt;Before Kendall’s announcement, it seemed possible for X to escape the investigation unscathed due to “gaps” in the Online Safety Act, according to the chairwomen of the UK Parliament’s technology and media committees, the BBC reported.&lt;/p&gt;
&lt;p&gt;“There are doubts as to whether the Online Safety Act actually has the power to regulate functionality—that means generative AI’s ability to nudify someone’s image,” Caroline Dinenage, chairwoman of the culture, media, and sport committee, told the BBC.&lt;/p&gt;
&lt;p&gt;Chairwomen suggested that the UK may need to update the law to better explain platforms’ duties to remove or prevent the making and sharing of sexualized deepfakes. In a document defining illegal content, however, Ofcom emphasizes that deepfakes can count as both CSAM and intimate image abuse, suggesting X could face penalties under the Online Safety Act for some of Grok’s outputs, even if Ofcom cannot require changes to Grok’s functionality.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ofcom noted that in its view, CSAM does include “AI-generated imagery, deepfakes and other manipulated media,” which “would fall under the category of a ‘pseudo-photograph.’” As Ofcom explained, “If the impression conveyed by a pseudo-photograph is that the person shown is a child, then the photo should be treated as showing a child.”&lt;/p&gt;
&lt;p&gt;Similarly, “manipulated images and videos such as deepfakes should be considered within the scope” of intimate image abuse, Ofcom said. “Any photograph or video which appears to depict an intimate situation” that a real person would not want publicly posted should “be treated as a photograph or video actually depicting such a situation.”&lt;/p&gt;
&lt;p&gt;Some Grok fans think that the chatbot’s outputs that undress people and put them in skimpy bikinis or underwear isn’t abuse. However, the UK law further details that an “intimate situation” could be an image where a person’s “genitals, buttocks, or breasts” are “covered only with underwear” or “covered only by clothing that is wet or otherwise transparent.”&lt;/p&gt;
&lt;p&gt;It’s unclear how long Ofcom may take to reach its decision, but the regulator acted urgently to intervene. And UK officials who were shocked by the scandal have confirmed that they are quickly moving to protect people in the UK from being targeted by Grok’s worst outputs.&lt;/p&gt;
&lt;p&gt;While Ofcom does not directly refer to Musk’s comments on censorship, the regulator takes a defensive stance in its announcement—likely preparing to fight X’s argument by pointing out that X would be the one in charge of deciding what is illegal content and what should be removed.&lt;/p&gt;
&lt;p&gt;“The legal responsibility is on platforms to decide whether content breaks UK laws, and they can use our Illegal Content Judgements Guidance when making these decisions,” Ofcom noted. “Ofcom is not a censor—we do not tell platforms which specific posts or accounts to take down.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Grok tests if UK can penalize platforms for sexualized deepfakes generated by AI.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2246892016-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/GettyImages-2246892016-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          BRENDAN SMIALOWSKI / Contributor | AFP

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Elon Musk’s X is currently under investigation in the United Kingdom after failing to stop the platform’s chatbot, Grok, from generating thousands of sexualized images of women and children.&lt;/p&gt;
&lt;p&gt;On Monday, UK media regulator Ofcom confirmed that X may have violated the UK’s Online Safety Act, which requires platforms to block illegal content. The proliferation of “undressed images of people” by X users may amount to intimate image abuse, pornography, and child sexual abuse material (CSAM), the regulator said. And X may also have neglected its duty to stop kids from seeing porn.&lt;/p&gt;
&lt;p&gt;“Reports of Grok being used to create and share illegal non-consensual intimate images and child sexual abuse material on X have been deeply concerning,” an Ofcom spokesperson said. “Platforms must protect people in the UK from content that’s illegal in the UK, and we won’t hesitate to investigate where we suspect companies are failing in their duties, especially where there’s a risk of harm to children.”&lt;/p&gt;
&lt;h2&gt;X risks fines, Grok block&lt;/h2&gt;
&lt;p&gt;X is cooperating with the probe, Ofcom said, noting that X met a “firm” deadline last week to explain what steps it’s taking to comply with the UK law. Ofcom declined Ars’ request to share more details about possible changes X has already made to either limit Grok in the UK or more broadly, since the investigation is “live.”&lt;/p&gt;
&lt;p&gt;Grok has already been blocked in Indonesia and Malaysia, as the chatbot remains unchecked. The UK could be next to block Grok if X fails to comply with the Online Safety Act. Additionally, X could face fines of up to 10 percent of its global revenue.&lt;/p&gt;
&lt;p&gt;It’s unclear how long the probe will take to conclude. Ofcom’s spokesperson told Ars that the agency will progress the investigation “as a matter of the highest priority, while ensuring we follow due process.” The probe will end “as soon as reasonably possible.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;X will have an opportunity to respond to Ofcom’s preliminary ruling before any final decision is made.&lt;/p&gt;
&lt;p&gt;Ars could not reach X to comment on the probe, but Musk has complained that Grok critics are looking for an “excuse for censorship,” the BBC reported. X has previously said that it will report harmful outputs to law enforcement and permanently suspend accounts that are abusing Grok to nudify images that X deems to be illegal content. The platform also started charging some users to edit images, instead of blocking outputs.&lt;/p&gt;
&lt;h2&gt;Grok tests UK’s power to regulate deepfakes&lt;/h2&gt;
&lt;p&gt;Shortly after Ofcom announced the probe, UK Technology Secretary Liz Kendall said the country would be bringing a new law into force that makes it illegal for companies to supply tools designed to create sexualized images, the BBC reported.&lt;/p&gt;
&lt;p&gt;Before Kendall’s announcement, it seemed possible for X to escape the investigation unscathed due to “gaps” in the Online Safety Act, according to the chairwomen of the UK Parliament’s technology and media committees, the BBC reported.&lt;/p&gt;
&lt;p&gt;“There are doubts as to whether the Online Safety Act actually has the power to regulate functionality—that means generative AI’s ability to nudify someone’s image,” Caroline Dinenage, chairwoman of the culture, media, and sport committee, told the BBC.&lt;/p&gt;
&lt;p&gt;Chairwomen suggested that the UK may need to update the law to better explain platforms’ duties to remove or prevent the making and sharing of sexualized deepfakes. In a document defining illegal content, however, Ofcom emphasizes that deepfakes can count as both CSAM and intimate image abuse, suggesting X could face penalties under the Online Safety Act for some of Grok’s outputs, even if Ofcom cannot require changes to Grok’s functionality.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Ofcom noted that in its view, CSAM does include “AI-generated imagery, deepfakes and other manipulated media,” which “would fall under the category of a ‘pseudo-photograph.’” As Ofcom explained, “If the impression conveyed by a pseudo-photograph is that the person shown is a child, then the photo should be treated as showing a child.”&lt;/p&gt;
&lt;p&gt;Similarly, “manipulated images and videos such as deepfakes should be considered within the scope” of intimate image abuse, Ofcom said. “Any photograph or video which appears to depict an intimate situation” that a real person would not want publicly posted should “be treated as a photograph or video actually depicting such a situation.”&lt;/p&gt;
&lt;p&gt;Some Grok fans think that the chatbot’s outputs that undress people and put them in skimpy bikinis or underwear isn’t abuse. However, the UK law further details that an “intimate situation” could be an image where a person’s “genitals, buttocks, or breasts” are “covered only with underwear” or “covered only by clothing that is wet or otherwise transparent.”&lt;/p&gt;
&lt;p&gt;It’s unclear how long Ofcom may take to reach its decision, but the regulator acted urgently to intervene. And UK officials who were shocked by the scandal have confirmed that they are quickly moving to protect people in the UK from being targeted by Grok’s worst outputs.&lt;/p&gt;
&lt;p&gt;While Ofcom does not directly refer to Musk’s comments on censorship, the regulator takes a defensive stance in its announcement—likely preparing to fight X’s argument by pointing out that X would be the one in charge of deciding what is illegal content and what should be removed.&lt;/p&gt;
&lt;p&gt;“The legal responsibility is on platforms to decide whether content breaks UK laws, and they can use our Illegal Content Judgements Guidance when making these decisions,” Ofcom noted. “Ofcom is not a censor—we do not tell platforms which specific posts or accounts to take down.”&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/01/uk-investigating-x-after-grok-undressed-thousands-of-women-and-children/</guid><pubDate>Mon, 12 Jan 2026 16:32:21 +0000</pubDate></item><item><title>[NEW] A New Jersey lawsuit shows how hard it is to fight deepfake porn (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/a-new-jersey-lawsuit-shows-how-hard-it-is-to-fight-deepfake-porn/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/07/gavel-messy-legal.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For more than two years, an app called ClothOff has been terrorizing young women online — and it’s been maddeningly difficult to stop. The app has been taken down from the two major app stores and it’s banned from most social platforms, but it’s still available on the web and through a Telegram bot. In October, a clinic at Yale Law School filed a lawsuit that would take down the app entirely, forcing the owners to delete all images and cease operation entirely. But simply finding the defendants has been a challenge.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s incorporated in the British Virgin Islands,” explains Professor John Langford, a co-lead counsel in the lawsuit, “but we believe it’s run by a brother and sister in Belarus. It may even be part of a larger network around the world.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s a bitter lesson in the wake of the recent flood of non-consensual pornography generated by Elon Musk’s xAI, which included many underage victims. Child sexual abuse material is the most legally toxic content on the internet — illegal to produce, transmit, or store, and regularly scanned for on every major cloud service. But despite the intense legal prohibitions, there are still few ways to deal with image generators like ClothOff, as Langford’s case demonstrates. Individual users can be prosecuted, but platforms like ClothOff and Grok are far more difficult to police, leaving few options for victims hoping to find justice in court.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The clinic’s complaint, which is available online, paints an alarming picture. The plaintiff is an anonymous high school student in New Jersey, whose classmates used ClothOff to alter her Instagram photos. She was 14 years old when the original Instagram photos were taken, which means the AI-modified versions are legally classified as child abuse imagery. But even though the modified images are straightforwardly illegal, local authorities declined to prosecute the case, citing the difficulty of obtaining evidence from suspects’ devices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Neither the school nor law enforcement ever established how broadly the CSAM of Jane Doe and other girls was distributed,” the complaint reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the court case has moved slowly. The complaint was filed in October, and in the months since, Langford and his colleagues have been in the process of serving notice to the defendants — a difficult task given the global nature of the enterprise. Once they’ve been served, the clinic can push for a court appearance and, eventually, a judgment, but in the meantime the legal system has given little comfort to ClothOff’s victims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Grok case might seem like a simpler problem to fix. Elon Musk’s xAI isn’t hiding, and there’s plenty of money at the end for lawyers who can win a claim. But Grok is a general-purpose tool, which makes it much harder to hold it accountable in court.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“ClothOff is designed and marketed specifically as a deepfake pornography image and video generator,” Langford told me. “When you’re suing a general system that users can query for all sorts of things, it gets a lot more complicated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A number of U.S. laws have already banned deepfake pornography — most notably the Take It Down Act. But while specific users are clearly breaking those laws, it’s much harder to hold the entire platform accountable. Existing laws require clear evidence of an intent to harm, which would mean providing evidence xAI knew their tool would be used to produce non-consensual pornography. Without that evidence, xAI’s basic first amendment rights would provide significant legal protection.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In terms of the First Amendment, it’s quite clear Child Sexual Abuse material is not protected expression,” Langford says. “So when you’re designing a system to create that kind of content, you’re clearly operating outside of what’s protected by the First Amendment. But when you’re a general system that users can query for all sorts of things, it’s not so clear.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The easiest way to surmount those problems would be to show that xAI had willfully ignored the problem. It’s a real possibility, given recent reporting that Musk directed employees to loosen Grok’s safeguards. But even then, it would be a far riskier case to take on. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Reasonable people can say, we knew this was a problem years ago,” Langford says. “How can you not have had more stringent controls in place to make sure this doesn’t happen? That is a kind of recklessness or knowledge but it’s just a more complicated case.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those First Amendment issues are why xAI’s biggest pushback has come from court systems without robust legal protections for free speech. Both Indonesia and Malaysia have taken steps to block access to the Grok chatbot, while regulators in the United Kingdom have opened an investigation that could lead to a similar ban. Other preliminary steps have been taken by the European Commission, France, Ireland, India, and Brazil. In contrast, no U.S. regulatory agency has issued an official response.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s impossible to say how the investigations will resolve, but at the very least, the flood of imagery raises lots of questions for regulators to investigate — and the answers could be damning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you are posting, distributing, disseminating Child Sexual Abuse material, you are violating criminal prohibitions and can be held accountable,” Langford says. “The hard question is, what did X know? What did X do or not do? What are they doing now in response to it?“&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/07/gavel-messy-legal.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;For more than two years, an app called ClothOff has been terrorizing young women online — and it’s been maddeningly difficult to stop. The app has been taken down from the two major app stores and it’s banned from most social platforms, but it’s still available on the web and through a Telegram bot. In October, a clinic at Yale Law School filed a lawsuit that would take down the app entirely, forcing the owners to delete all images and cease operation entirely. But simply finding the defendants has been a challenge.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s incorporated in the British Virgin Islands,” explains Professor John Langford, a co-lead counsel in the lawsuit, “but we believe it’s run by a brother and sister in Belarus. It may even be part of a larger network around the world.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;It’s a bitter lesson in the wake of the recent flood of non-consensual pornography generated by Elon Musk’s xAI, which included many underage victims. Child sexual abuse material is the most legally toxic content on the internet — illegal to produce, transmit, or store, and regularly scanned for on every major cloud service. But despite the intense legal prohibitions, there are still few ways to deal with image generators like ClothOff, as Langford’s case demonstrates. Individual users can be prosecuted, but platforms like ClothOff and Grok are far more difficult to police, leaving few options for victims hoping to find justice in court.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The clinic’s complaint, which is available online, paints an alarming picture. The plaintiff is an anonymous high school student in New Jersey, whose classmates used ClothOff to alter her Instagram photos. She was 14 years old when the original Instagram photos were taken, which means the AI-modified versions are legally classified as child abuse imagery. But even though the modified images are straightforwardly illegal, local authorities declined to prosecute the case, citing the difficulty of obtaining evidence from suspects’ devices.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Neither the school nor law enforcement ever established how broadly the CSAM of Jane Doe and other girls was distributed,” the complaint reads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Still, the court case has moved slowly. The complaint was filed in October, and in the months since, Langford and his colleagues have been in the process of serving notice to the defendants — a difficult task given the global nature of the enterprise. Once they’ve been served, the clinic can push for a court appearance and, eventually, a judgment, but in the meantime the legal system has given little comfort to ClothOff’s victims.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The Grok case might seem like a simpler problem to fix. Elon Musk’s xAI isn’t hiding, and there’s plenty of money at the end for lawyers who can win a claim. But Grok is a general-purpose tool, which makes it much harder to hold it accountable in court.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“ClothOff is designed and marketed specifically as a deepfake pornography image and video generator,” Langford told me. “When you’re suing a general system that users can query for all sorts of things, it gets a lot more complicated.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A number of U.S. laws have already banned deepfake pornography — most notably the Take It Down Act. But while specific users are clearly breaking those laws, it’s much harder to hold the entire platform accountable. Existing laws require clear evidence of an intent to harm, which would mean providing evidence xAI knew their tool would be used to produce non-consensual pornography. Without that evidence, xAI’s basic first amendment rights would provide significant legal protection.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“In terms of the First Amendment, it’s quite clear Child Sexual Abuse material is not protected expression,” Langford says. “So when you’re designing a system to create that kind of content, you’re clearly operating outside of what’s protected by the First Amendment. But when you’re a general system that users can query for all sorts of things, it’s not so clear.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The easiest way to surmount those problems would be to show that xAI had willfully ignored the problem. It’s a real possibility, given recent reporting that Musk directed employees to loosen Grok’s safeguards. But even then, it would be a far riskier case to take on. &amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Reasonable people can say, we knew this was a problem years ago,” Langford says. “How can you not have had more stringent controls in place to make sure this doesn’t happen? That is a kind of recklessness or knowledge but it’s just a more complicated case.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Those First Amendment issues are why xAI’s biggest pushback has come from court systems without robust legal protections for free speech. Both Indonesia and Malaysia have taken steps to block access to the Grok chatbot, while regulators in the United Kingdom have opened an investigation that could lead to a similar ban. Other preliminary steps have been taken by the European Commission, France, Ireland, India, and Brazil. In contrast, no U.S. regulatory agency has issued an official response.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s impossible to say how the investigations will resolve, but at the very least, the flood of imagery raises lots of questions for regulators to investigate — and the answers could be damning.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“If you are posting, distributing, disseminating Child Sexual Abuse material, you are violating criminal prohibitions and can be held accountable,” Langford says. “The hard question is, what did X know? What did X do or not do? What are they doing now in response to it?“&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/a-new-jersey-lawsuit-shows-how-hard-it-is-to-fight-deepfake-porn/</guid><pubDate>Mon, 12 Jan 2026 16:34:53 +0000</pubDate></item><item><title>[NEW] CES showed me why Chinese tech companies feel so optimistic (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2026/01/12/1131193/ces-showed-me-why-chinese-tech-companies-feel-so-optimistic/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;I decided to go to CES kind of at the last minute. Over the holiday break, contacts from China kept messaging me about their travel plans. After the umpteenth “See you in Vegas?” I caved. As a China tech writer based in the US, I have one week a year when my entire beat seems to come to me—no 20-hour flights required.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;CES, the Consumer Electronics Show, is the world’s biggest tech show, where companies launch new gadgets and announce new developments, and it happens every January. This year, it attracted over 148,000 attendees and over 4,100 exhibitors. It sprawls across the Las Vegas Convention Center, the city’s biggest exhibition space, and spills over into adjacent hotels.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;China has long had a presence at CES, but this year it showed up in a big way. Chinese exhibitors accounted for nearly a quarter of all companies at the show, and in pockets like AI hardware and robotics, China’s presence felt especially dominant. On the floor, I saw tons of Chinese industry attendees roaming around, plus a notable number of Chinese VCs. Multiple experienced CES attendees told me this is the first post-covid CES where China was present in a way you couldn’t miss. Last year might have been trending that way too, but a lot of Chinese attendees reportedly ran into visa denials. Now AI has become the universal excuse, and reason, to make the trip.&lt;/p&gt; 
 &lt;p&gt;As expected, AI was the biggest theme this year, seen on every booth wall. It’s both the biggest thing everyone is talking about and a deeply confusing marketing gimmick. “We added AI” is slapped onto everything from the reasonable (PCs, phones, TVs, security systems) to the deranged (slippers, hair dryers, bed frames).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Consumer AI gadgets still feel early and of very uneven quality. The most common categories are educational devices and emotional support toys—which, as I’ve written about recently, are all the rage in China. There are some memorable ones: Luka AI makes a robotic panda that scuttles around and keeps a watchful eye on your baby. Fuzozo, a fluffy keychain-size AI robot, is basically a digital pet in physical form. It comes with a built-in personality and reacts to how you treat it. The companies selling these just hope you won’t think too hard about the privacy implications.&lt;/p&gt; 
 &lt;p&gt;Ian Goh, an investor at 01.VC, told me China’s manufacturing advantage gives it a unique edge in AI consumer electronics, because a lot of Western companies feel they simply cannot fight and win in the arena of hardware.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another area where Chinese companies seem to be at the head of the pack is household electronics. The products they make are becoming impressively sophisticated. Home robots, 360 cams, security systems, drones, lawn-mowing machines, pool heat pumps … Did you know two Chinese brands basically dominate the market for home cleaning robots in the US and are eating the lunch of Dyson and Shark? Did you know almost all the suburban yard tech you can buy in the West comes from Shenzhen, even though that whole backyard-obsessed lifestyle barely exists in China? This stuff is so sleek that you wouldn’t clock it as Chinese unless you went looking. The old “cheap and repetitive” stereotype doesn’t explain what I saw. I walked away from CES feeling that I needed a major home appliance upgrade.&lt;/p&gt;  &lt;p&gt;Of course, appliances are a safe, mature market. On the more experiential front, humanoid robots were a giant magnet for crowds, and Chinese companies put on a great show. Every robot seemed to be dancing, in styles from Michael Jackson to K-pop to lion dancing, some even doing back flips. Hangzhou-based Unitree even set up a boxing ring where people could “challenge” its robots. The robot fighters were about half the size of an adult human and the matches often ended in a robot knockout, but that’s not really the point. What Unitree was actually showing off was its robots’ stability and balance: they got shoved, stumbled across the ring, and stayed upright, recovering mid-motion. Beyond flexing dynamic movements like these there were also impressive showcases of dexterity: Robots could be seen folding paper pinwheels, doing laundry, playing piano, and even making latte art.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Attendees take photos of the UniTree autonomous robot which is posing with its boxing gloves and headgear" class="wp-image-1131189" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/AP26008139270328.jpg?w=2667" width="2667" /&gt;&lt;div class="image-credit"&gt;CAL SPORT MEDIA VIA AP IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;However, most of these robots, even the good ones, are one-trick ponies. They’re optimized for a specific task on the show floor. I tried to make one fold a T-shirt after I’d flipped the garment around, and it got confused very quickly.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;Still, they’re getting a lot of hype as an&amp;nbsp; important next frontier because they could help drag AI out of text boxes and into the physical world. As LLMs mature, vision-language models feel like the logical next step. But then you run into the big problem: There’s far less physical-world data than text data to train AI on. Humanoid robots become both applications and roaming data-collection terminals. China is uniquely positioned here because of supply chains, manufacturing depth, and spillover from adjacent industries (EVs, batteries, motors, sensors), and it’s already developing a humanoid training industry, as &lt;em&gt;Rest of World&lt;/em&gt; reported recently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Most Chinese companies believe that if you can manufacture at scale, you can innovate, and they’re not wrong. A lot of the confidence in China’s nascent humanoid robot industry and beyond is less about a single breakthrough and more about “We can iterate faster than the West.”&lt;/p&gt;  &lt;p&gt;Chinese companies are not just selling gadgets, though—they’re working on every layer of the tech stack. Not just on end products but frameworks, tooling, IoT enablement, spatial data. Open-source culture feels deeply embedded; engineers from Hangzhou tell me there are AI hackathons every week in the city, where China’s new “little Silicon Valley” is located.&lt;/p&gt;  &lt;p&gt;Indeed, the headline innovations at CES 2026 were not on devices but in cloud: platforms, ecosystems, enterprise deployments, and “hybrid AI” (cloud + on-device) applications. Lenovo threw the buzziest main-stage events this year, and yes, there were PCs—but the core story was its cross-device AI agent system, Qira, and a partnership pitch with Nvidia aimed at AI cloud providers. Nvidia’s CEO, Jensen Huang, launched Vera Rubin, a new data-center platform, claiming it would&amp;nbsp; dramatically lower costs for training and running AI. AMD’s CEO, Lisa Su, introduced Helios, another data-center system built to run huge AI workloads. These solutions point to the ballooning AI computing workload at data centers, and the real race of making cloud services cheap and powerful enough to keep up.&lt;/p&gt;  &lt;p&gt;As I spoke with China-related attendees, the overall mood I felt was a cautious optimism. At a house party I went to, VCs and founders from China were mingling effortlessly with Bay Area transplants. Everyone is building something. Almost no one wants to just make money from Chinese consumers anymore. The new default is: Build in China, sell to the world, and treat the US market like the proving ground.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0 html_first"&gt; &lt;p&gt;&lt;em&gt;This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;I decided to go to CES kind of at the last minute. Over the holiday break, contacts from China kept messaging me about their travel plans. After the umpteenth “See you in Vegas?” I caved. As a China tech writer based in the US, I have one week a year when my entire beat seems to come to me—no 20-hour flights required.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;CES, the Consumer Electronics Show, is the world’s biggest tech show, where companies launch new gadgets and announce new developments, and it happens every January. This year, it attracted over 148,000 attendees and over 4,100 exhibitors. It sprawls across the Las Vegas Convention Center, the city’s biggest exhibition space, and spills over into adjacent hotels.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;China has long had a presence at CES, but this year it showed up in a big way. Chinese exhibitors accounted for nearly a quarter of all companies at the show, and in pockets like AI hardware and robotics, China’s presence felt especially dominant. On the floor, I saw tons of Chinese industry attendees roaming around, plus a notable number of Chinese VCs. Multiple experienced CES attendees told me this is the first post-covid CES where China was present in a way you couldn’t miss. Last year might have been trending that way too, but a lot of Chinese attendees reportedly ran into visa denials. Now AI has become the universal excuse, and reason, to make the trip.&lt;/p&gt; 
 &lt;p&gt;As expected, AI was the biggest theme this year, seen on every booth wall. It’s both the biggest thing everyone is talking about and a deeply confusing marketing gimmick. “We added AI” is slapped onto everything from the reasonable (PCs, phones, TVs, security systems) to the deranged (slippers, hair dryers, bed frames).&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Consumer AI gadgets still feel early and of very uneven quality. The most common categories are educational devices and emotional support toys—which, as I’ve written about recently, are all the rage in China. There are some memorable ones: Luka AI makes a robotic panda that scuttles around and keeps a watchful eye on your baby. Fuzozo, a fluffy keychain-size AI robot, is basically a digital pet in physical form. It comes with a built-in personality and reacts to how you treat it. The companies selling these just hope you won’t think too hard about the privacy implications.&lt;/p&gt; 
 &lt;p&gt;Ian Goh, an investor at 01.VC, told me China’s manufacturing advantage gives it a unique edge in AI consumer electronics, because a lot of Western companies feel they simply cannot fight and win in the arena of hardware.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Another area where Chinese companies seem to be at the head of the pack is household electronics. The products they make are becoming impressively sophisticated. Home robots, 360 cams, security systems, drones, lawn-mowing machines, pool heat pumps … Did you know two Chinese brands basically dominate the market for home cleaning robots in the US and are eating the lunch of Dyson and Shark? Did you know almost all the suburban yard tech you can buy in the West comes from Shenzhen, even though that whole backyard-obsessed lifestyle barely exists in China? This stuff is so sleek that you wouldn’t clock it as Chinese unless you went looking. The old “cheap and repetitive” stereotype doesn’t explain what I saw. I walked away from CES feeling that I needed a major home appliance upgrade.&lt;/p&gt;  &lt;p&gt;Of course, appliances are a safe, mature market. On the more experiential front, humanoid robots were a giant magnet for crowds, and Chinese companies put on a great show. Every robot seemed to be dancing, in styles from Michael Jackson to K-pop to lion dancing, some even doing back flips. Hangzhou-based Unitree even set up a boxing ring where people could “challenge” its robots. The robot fighters were about half the size of an adult human and the matches often ended in a robot knockout, but that’s not really the point. What Unitree was actually showing off was its robots’ stability and balance: they got shoved, stumbled across the ring, and stayed upright, recovering mid-motion. Beyond flexing dynamic movements like these there were also impressive showcases of dexterity: Robots could be seen folding paper pinwheels, doing laundry, playing piano, and even making latte art.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="Attendees take photos of the UniTree autonomous robot which is posing with its boxing gloves and headgear" class="wp-image-1131189" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2026/01/AP26008139270328.jpg?w=2667" width="2667" /&gt;&lt;div class="image-credit"&gt;CAL SPORT MEDIA VIA AP IMAGES&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;However, most of these robots, even the good ones, are one-trick ponies. They’re optimized for a specific task on the show floor. I tried to make one fold a T-shirt after I’d flipped the garment around, and it got confused very quickly.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;p&gt;Still, they’re getting a lot of hype as an&amp;nbsp; important next frontier because they could help drag AI out of text boxes and into the physical world. As LLMs mature, vision-language models feel like the logical next step. But then you run into the big problem: There’s far less physical-world data than text data to train AI on. Humanoid robots become both applications and roaming data-collection terminals. China is uniquely positioned here because of supply chains, manufacturing depth, and spillover from adjacent industries (EVs, batteries, motors, sensors), and it’s already developing a humanoid training industry, as &lt;em&gt;Rest of World&lt;/em&gt; reported recently.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Most Chinese companies believe that if you can manufacture at scale, you can innovate, and they’re not wrong. A lot of the confidence in China’s nascent humanoid robot industry and beyond is less about a single breakthrough and more about “We can iterate faster than the West.”&lt;/p&gt;  &lt;p&gt;Chinese companies are not just selling gadgets, though—they’re working on every layer of the tech stack. Not just on end products but frameworks, tooling, IoT enablement, spatial data. Open-source culture feels deeply embedded; engineers from Hangzhou tell me there are AI hackathons every week in the city, where China’s new “little Silicon Valley” is located.&lt;/p&gt;  &lt;p&gt;Indeed, the headline innovations at CES 2026 were not on devices but in cloud: platforms, ecosystems, enterprise deployments, and “hybrid AI” (cloud + on-device) applications. Lenovo threw the buzziest main-stage events this year, and yes, there were PCs—but the core story was its cross-device AI agent system, Qira, and a partnership pitch with Nvidia aimed at AI cloud providers. Nvidia’s CEO, Jensen Huang, launched Vera Rubin, a new data-center platform, claiming it would&amp;nbsp; dramatically lower costs for training and running AI. AMD’s CEO, Lisa Su, introduced Helios, another data-center system built to run huge AI workloads. These solutions point to the ballooning AI computing workload at data centers, and the real race of making cloud services cheap and powerful enough to keep up.&lt;/p&gt;  &lt;p&gt;As I spoke with China-related attendees, the overall mood I felt was a cautious optimism. At a house party I went to, VCs and founders from China were mingling effortlessly with Bay Area transplants. Everyone is building something. Almost no one wants to just make money from Chinese consumers anymore. The new default is: Build in China, sell to the world, and treat the US market like the proving ground.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2026/01/12/1131193/ces-showed-me-why-chinese-tech-companies-feel-so-optimistic/</guid><pubDate>Mon, 12 Jan 2026 17:01:00 +0000</pubDate></item><item><title>[NEW] Google’s Gemini to power Apple’s AI features like Siri (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/googles-gemini-to-power-apples-ai-features-like-siri/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s official. Apple has chosen to work with Google, a longtime partner, to power AI features like Siri.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“After careful evaluation, we determined that Google’s technology provides the most capable foundation for Apple Foundation Models and we’re excited about the innovative new experiences it will unlock for our users,” Apple and Google said in a statement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The partnership confirms previous reporting on a deal with Google. Neither Apple nor Google have confirmed the price tag, but previous reports indicate Apple could be paying Google around $1 billion for access to its AI technology. The deal also comes after Apple spent some time testing the technology of competitors like OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The multi-year partnership will involve Apple using Google’s Gemini models and cloud technology for future Apple foundational models. The deal is not exclusive, per a source familiar with the matter. Apple has historically focused on vertical integration, relying on its own hardware and software.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The iPhone-maker has faced a fair amount of public chatter criticizing it after its AI efforts, particularly its assistant Siri, lagged behind competitors. That’s not to say Apple hasn’t been quietly building powerful foundational models. The company released the first versions of Apple Intelligence in 2024, which adds AI to existing OS functions like searching for photos and summarizing notifications. Apple has also focused on privacy with its AI rollout, with much of the processing happening on-device or through tightly controlled infrastructure. Apple says it will maintain those privacy standards throughout its partnership with Google.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm’s strategy has resulted in a subtle, sometimes invisible, occasionally resented form of AI — one that doesn’t have the same wow factor as ChatGPT or Gemini. It also stops short of delivering the kind of Siri overhaul many users have been waiting for.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has delayed the rollout of its “more personalized Siri” voice assistant several times, but a spokesperson told TechCrunch an upgrade is coming this year. Previous reports indicate the overhauled Siri is expected to launch in the spring.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Apple’s partnership with Google also comes as the search and adtech giant is in the midst of multiple antitrust lawsuits, including one that put its relationship with Apple front and center. In August 2024, a federal judge ruled that Google acted illegally to maintain a monopoly in online search by paying companies like Apple to present its search engine as the default on its devices and web browsers. Between 2021 and 2022, Google paid Apple about $38 billion to secure default search placements.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In December 2025, Judge Amit Mehta issued his final remedies on the case, which include banning Google from entering into exclusive, default agreements like the one it had with Apple “unless the agreement terminates no more than one year after the date it is entered.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/apple-intelligence-iphone-mac.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;It’s official. Apple has chosen to work with Google, a longtime partner, to power AI features like Siri.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“After careful evaluation, we determined that Google’s technology provides the most capable foundation for Apple Foundation Models and we’re excited about the innovative new experiences it will unlock for our users,” Apple and Google said in a statement.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The partnership confirms previous reporting on a deal with Google. Neither Apple nor Google have confirmed the price tag, but previous reports indicate Apple could be paying Google around $1 billion for access to its AI technology. The deal also comes after Apple spent some time testing the technology of competitors like OpenAI and Anthropic.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The multi-year partnership will involve Apple using Google’s Gemini models and cloud technology for future Apple foundational models. The deal is not exclusive, per a source familiar with the matter. Apple has historically focused on vertical integration, relying on its own hardware and software.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The iPhone-maker has faced a fair amount of public chatter criticizing it after its AI efforts, particularly its assistant Siri, lagged behind competitors. That’s not to say Apple hasn’t been quietly building powerful foundational models. The company released the first versions of Apple Intelligence in 2024, which adds AI to existing OS functions like searching for photos and summarizing notifications. Apple has also focused on privacy with its AI rollout, with much of the processing happening on-device or through tightly controlled infrastructure. Apple says it will maintain those privacy standards throughout its partnership with Google.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The firm’s strategy has resulted in a subtle, sometimes invisible, occasionally resented form of AI — one that doesn’t have the same wow factor as ChatGPT or Gemini. It also stops short of delivering the kind of Siri overhaul many users have been waiting for.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has delayed the rollout of its “more personalized Siri” voice assistant several times, but a spokesperson told TechCrunch an upgrade is coming this year. Previous reports indicate the overhauled Siri is expected to launch in the spring.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Apple’s partnership with Google also comes as the search and adtech giant is in the midst of multiple antitrust lawsuits, including one that put its relationship with Apple front and center. In August 2024, a federal judge ruled that Google acted illegally to maintain a monopoly in online search by paying companies like Apple to present its search engine as the default on its devices and web browsers. Between 2021 and 2022, Google paid Apple about $38 billion to secure default search placements.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In December 2025, Judge Amit Mehta issued his final remedies on the case, which include banning Google from entering into exclusive, default agreements like the one it had with Apple “unless the agreement terminates no more than one year after the date it is entered.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/googles-gemini-to-power-apples-ai-features-like-siri/</guid><pubDate>Mon, 12 Jan 2026 17:12:41 +0000</pubDate></item><item><title>[NEW] NeuralGCM harnesses AI to better simulate long-range global precipitation (The latest research from Google)</title><link>https://research.google/blog/neuralgcm-harnesses-ai-to-better-simulate-long-range-global-precipitation/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Clouds’ diversity and fleeting nature pose challenges&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;To simulate precipitation, we must go to its source: clouds. Clouds can exist at scales smaller than 100 meters, the size of an athletic field — far below the kilometers-scale resolution of global weather models, or the tens-of-kilometers–scale resolution of global climate models. Clouds come in different types, change quickly, and the intricate physics happening at even smaller scales can generate water droplets or ice crystals. All this complexity is impossible for large-scale models to resolve or calculate.&lt;/p&gt;&lt;p&gt;To account for the effect of small-scale atmospheric processes like cloud formation on the climate, models use approximations, called parameterizations, which are based on other variables. Rather than depending on these parameterizations, NeuralGCM uses a neural network to learn the effects of such small-scale events directly from existing weather data.&lt;/p&gt;&lt;p&gt;We improved the representation of precipitation in this version of our model by training the ML portion of NeuralGCM directly on satellite-based precipitation observations. The initial offering of NeuralGCM was, like most ML weather models, trained on recreations of previous atmospheric conditions, i.e., reanalyses, that combine physics-based models with observations to fill in gaps in observational data. But the physics of clouds is so complex that even reanalyses struggle to get precipitation right. Training on output from reanalyses means reproducing their weaknesses, for example, on precipitation extremes and the daily cycle.&lt;/p&gt;&lt;p&gt;Instead, we trained the precipitation part of NeuralGCM directly on NASA satellite-based precipitation observations spanning from 2001 to 2018. NeuralGCM’s differential dynamical core infrastructure allowed us to train it on satellite observations. Previous hybrid models that combine physics and AI could only use output from high-fidelity simulations or reanalysis data. By training the AI component of NeuralGCM directly on high-quality satellite observations instead of relying on reanalyses, we are effectively finding a better, machine-learned parameterization for precipitation.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://storage.googleapis.com/gweb-research2023-media/images/Open_Graph.width-800.format-jpeg.jpg" /&gt;&lt;/div&gt;&lt;p&gt;
        
            
                &lt;h2 class="class"&gt;Clouds’ diversity and fleeting nature pose challenges&lt;/h2&gt;
            
        
        
    &lt;/p&gt;



    &lt;p&gt;To simulate precipitation, we must go to its source: clouds. Clouds can exist at scales smaller than 100 meters, the size of an athletic field — far below the kilometers-scale resolution of global weather models, or the tens-of-kilometers–scale resolution of global climate models. Clouds come in different types, change quickly, and the intricate physics happening at even smaller scales can generate water droplets or ice crystals. All this complexity is impossible for large-scale models to resolve or calculate.&lt;/p&gt;&lt;p&gt;To account for the effect of small-scale atmospheric processes like cloud formation on the climate, models use approximations, called parameterizations, which are based on other variables. Rather than depending on these parameterizations, NeuralGCM uses a neural network to learn the effects of such small-scale events directly from existing weather data.&lt;/p&gt;&lt;p&gt;We improved the representation of precipitation in this version of our model by training the ML portion of NeuralGCM directly on satellite-based precipitation observations. The initial offering of NeuralGCM was, like most ML weather models, trained on recreations of previous atmospheric conditions, i.e., reanalyses, that combine physics-based models with observations to fill in gaps in observational data. But the physics of clouds is so complex that even reanalyses struggle to get precipitation right. Training on output from reanalyses means reproducing their weaknesses, for example, on precipitation extremes and the daily cycle.&lt;/p&gt;&lt;p&gt;Instead, we trained the precipitation part of NeuralGCM directly on NASA satellite-based precipitation observations spanning from 2001 to 2018. NeuralGCM’s differential dynamical core infrastructure allowed us to train it on satellite observations. Previous hybrid models that combine physics and AI could only use output from high-fidelity simulations or reanalysis data. By training the AI component of NeuralGCM directly on high-quality satellite observations instead of relying on reanalyses, we are effectively finding a better, machine-learned parameterization for precipitation.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://research.google/blog/neuralgcm-harnesses-ai-to-better-simulate-long-range-global-precipitation/</guid><pubDate>Mon, 12 Jan 2026 17:52:41 +0000</pubDate></item><item><title>[NEW] Apple chooses Google’s Gemini over OpenAI’s ChatGPT to power next-gen Siri (AI - Ars Technica)</title><link>https://arstechnica.com/apple/2026/01/apple-says-its-new-ai-powered-siri-will-use-googles-gemini-language-models/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Apple goes with Google’s tech despite using OpenAI’s ChatGPT elsewhere in iOS.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/apple_google_hero_3-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/apple_google_hero_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The “more intelligent” version of Siri that Apple plans to release later this year will be backed by Google’s Gemini language models, the company announced today. CNBC reports that the deal is part of a “multi-year partnership” between Apple and Google that will allow Apple to use Google’s AI models in its own software.&lt;/p&gt;
&lt;p&gt;“After careful evaluation, we determined that Google’s technology provides the most capable foundation for Apple Foundation Models and we’re excited about the innovative new experiences it will unlock for our users,” reads an Apple statement given to CNBC.&lt;/p&gt;
&lt;p&gt;Today’s announcement confirms reporting by Bloomberg’s Mark Gurman late last year that Apple and Google were nearing a deal. Apple didn’t disclose terms, but Gurman said that Apple would be paying Google “about $1 billion a year” for access to its AI models “following an extensive evaluation period.”&lt;/p&gt;
&lt;p&gt;Bloomberg has also reported that the Gemini model would be run on Apple’s Private Cloud Compute servers, “ensuring that user data remains walled off from Google’s infrastructure,” and that Apple still hopes to improve its own in-house language models to the point that they can eventually be used instead of relying on third-party models.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although Apple’s iPhones and iOS compete with Google’s Android operating system and the many smartphones that use it, the companies still cooperate in plenty of other areas. Google has paid Apple billions of dollars to remain the default search engine in Safari on iOS, iPadOS, and macOS (though that deal has faced increased regulatory scrutiny in recent years).&lt;/p&gt;
&lt;p&gt;Apple’s announcement is a blow to OpenAI and the many versions of its ChatGPT model, which Apple has used elsewhere in iOS and macOS. Bloomberg reports that Apple also tested OpenAI’s ChatGPT and Anthropic’s Claude models before deciding to go with Gemini. ChatGPT came out ahead of Gemini in tests that Ars ran using earlier versions of the models, but Google’s models have apparently improved enough (and amassed enough users) to worry OpenAI; CEO Sam Altman declared a “code red” last month and pushed back several planned ChatGPT features so that the company could better respond to Google’s Gemini 3 release.&lt;/p&gt;
&lt;p&gt;Apple originally promised the improved, AI-powered Siri for 2024’s iOS 18 release, but ultimately delayed the feature because it didn’t work reliably enough. The new version of Siri should arrive in an update to iOS 26, iPadOS 26, and macOS 26 Tahoe later this year.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Apple goes with Google’s tech despite using OpenAI’s ChatGPT elsewhere in iOS.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/apple_google_hero_3-640x360.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/apple_google_hero_3-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Benj Edwards

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;The “more intelligent” version of Siri that Apple plans to release later this year will be backed by Google’s Gemini language models, the company announced today. CNBC reports that the deal is part of a “multi-year partnership” between Apple and Google that will allow Apple to use Google’s AI models in its own software.&lt;/p&gt;
&lt;p&gt;“After careful evaluation, we determined that Google’s technology provides the most capable foundation for Apple Foundation Models and we’re excited about the innovative new experiences it will unlock for our users,” reads an Apple statement given to CNBC.&lt;/p&gt;
&lt;p&gt;Today’s announcement confirms reporting by Bloomberg’s Mark Gurman late last year that Apple and Google were nearing a deal. Apple didn’t disclose terms, but Gurman said that Apple would be paying Google “about $1 billion a year” for access to its AI models “following an extensive evaluation period.”&lt;/p&gt;
&lt;p&gt;Bloomberg has also reported that the Gemini model would be run on Apple’s Private Cloud Compute servers, “ensuring that user data remains walled off from Google’s infrastructure,” and that Apple still hopes to improve its own in-house language models to the point that they can eventually be used instead of relying on third-party models.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Although Apple’s iPhones and iOS compete with Google’s Android operating system and the many smartphones that use it, the companies still cooperate in plenty of other areas. Google has paid Apple billions of dollars to remain the default search engine in Safari on iOS, iPadOS, and macOS (though that deal has faced increased regulatory scrutiny in recent years).&lt;/p&gt;
&lt;p&gt;Apple’s announcement is a blow to OpenAI and the many versions of its ChatGPT model, which Apple has used elsewhere in iOS and macOS. Bloomberg reports that Apple also tested OpenAI’s ChatGPT and Anthropic’s Claude models before deciding to go with Gemini. ChatGPT came out ahead of Gemini in tests that Ars ran using earlier versions of the models, but Google’s models have apparently improved enough (and amassed enough users) to worry OpenAI; CEO Sam Altman declared a “code red” last month and pushed back several planned ChatGPT features so that the company could better respond to Google’s Gemini 3 release.&lt;/p&gt;
&lt;p&gt;Apple originally promised the improved, AI-powered Siri for 2024’s iOS 18 release, but ultimately delayed the feature because it didn’t work reliably enough. The new version of Siri should arrive in an update to iOS 26, iPadOS 26, and macOS 26 Tahoe later this year.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/apple/2026/01/apple-says-its-new-ai-powered-siri-will-use-googles-gemini-language-models/</guid><pubDate>Mon, 12 Jan 2026 17:57:32 +0000</pubDate></item><item><title>[NEW] Amazon says 97% of its devices can support Alexa+ (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/amazon-says-97-of-its-devices-can-support-alexa/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/alexa-plus-event.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon offered a bit more insight into how it sees its AI platform competing in the real world at the Consumer Electronics Show in Las Vegas last week. Namely, Amazon plans to leverage the extensive footprint its devices already have in the home as well as consumers’ existing familiarity with its Alexa brand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ninety-seven percent of devices we ever shipped can support Alexa+,” noted Amazon Alexa and Echo VP Daniel Rausch in an interview at CES. He said the latest figures Amazon has on hand indicate the company has sold more than 600 million devices, and the “vast majority” will support its revamped AI assistant, Alexa+.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Announced early last year, Alexa+ is Amazon’s future in the generative AI market, offering more expressive voices, access to world knowledge similar to other AI assistants, and AI agents that perform tasks on behalf of the customer — like calling an Uber or ordering food. The company has been steadily rolling out access to the AI platform, with more than 1 million Alexa customers gaining access by last June, and now, “tens of millions” can opt in to upgrade to the AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon doesn’t have an exact date for when Alexa+ will be available to everyone; the company is focusing first on bringing the AI to all Prime members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What Amazon soon has to prove, beyond availability, is whether customers will actually use its AI. That’s where Rausch believes Alexa’s existing footprint will help. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that there’s going to be a whole range of AI out there for customers. I think that Alexa will be one of the foundational assistants,” he said. While he believes there will always be some specialist AIs on the market, like those that focus on one thing, like being a legal assistant, there will be a few “nameable, foundational AIs that are highly capable,” which is where Alexa slots in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think some of the advantages Alexa has is the familiarity of customers, the tens of millions of customers already engaging continuously,” Rausch said. “It’s in the home, ambiently available, in voice, in the most natural interface. I do believe that that’s our opportunity to grow,” he added.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Alexa’s plans for the home come as Apple announced it’s teaming up with Google’s Gemini for Siri, as other AI chatbots, like ChatGPT and Claude, compete across a variety of use cases ranging from research to healthcare to coding and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just ahead of CES, Amazon announced a way to access Alexa on the web and a redesigned Alexa app that puts a chatbot-style interface front and center. At the conference, Amazon partners like Samsung, BMW, and Oura showed off their Alexa integrations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also promoted its recent acquisition of Bee, an AI wearable that lets you record conversations and gain insights. Customers can engage with Bee via text or voice chat.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In the future, Rausch says Alexa and Bee will become more integrated. But, he added, Bee has value as its own standalone brand, calling it a “an important and lovable experience.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/alexa-plus-event.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon offered a bit more insight into how it sees its AI platform competing in the real world at the Consumer Electronics Show in Las Vegas last week. Namely, Amazon plans to leverage the extensive footprint its devices already have in the home as well as consumers’ existing familiarity with its Alexa brand.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Ninety-seven percent of devices we ever shipped can support Alexa+,” noted Amazon Alexa and Echo VP Daniel Rausch in an interview at CES. He said the latest figures Amazon has on hand indicate the company has sold more than 600 million devices, and the “vast majority” will support its revamped AI assistant, Alexa+.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Announced early last year, Alexa+ is Amazon’s future in the generative AI market, offering more expressive voices, access to world knowledge similar to other AI assistants, and AI agents that perform tasks on behalf of the customer — like calling an Uber or ordering food. The company has been steadily rolling out access to the AI platform, with more than 1 million Alexa customers gaining access by last June, and now, “tens of millions” can opt in to upgrade to the AI assistant.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon doesn’t have an exact date for when Alexa+ will be available to everyone; the company is focusing first on bringing the AI to all Prime members.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;What Amazon soon has to prove, beyond availability, is whether customers will actually use its AI. That’s where Rausch believes Alexa’s existing footprint will help. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think that there’s going to be a whole range of AI out there for customers. I think that Alexa will be one of the foundational assistants,” he said. While he believes there will always be some specialist AIs on the market, like those that focus on one thing, like being a legal assistant, there will be a few “nameable, foundational AIs that are highly capable,” which is where Alexa slots in.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think some of the advantages Alexa has is the familiarity of customers, the tens of millions of customers already engaging continuously,” Rausch said. “It’s in the home, ambiently available, in voice, in the most natural interface. I do believe that that’s our opportunity to grow,” he added.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Alexa’s plans for the home come as Apple announced it’s teaming up with Google’s Gemini for Siri, as other AI chatbots, like ChatGPT and Claude, compete across a variety of use cases ranging from research to healthcare to coding and more. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Just ahead of CES, Amazon announced a way to access Alexa on the web and a redesigned Alexa app that puts a chatbot-style interface front and center. At the conference, Amazon partners like Samsung, BMW, and Oura showed off their Alexa integrations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also promoted its recent acquisition of Bee, an AI wearable that lets you record conversations and gain insights. Customers can engage with Bee via text or voice chat.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In the future, Rausch says Alexa and Bee will become more integrated. But, he added, Bee has value as its own standalone brand, calling it a “an important and lovable experience.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/amazon-says-97-of-its-devices-can-support-alexa/</guid><pubDate>Mon, 12 Jan 2026 19:20:05 +0000</pubDate></item><item><title>[NEW] Anthropic’s new Cowork tool offers Claude Code without the code (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/anthropics-new-cowork-tool-offers-claude-code-without-the-code/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Anthropic announced a new tool called Cowork, designed as a more accessible version of Claude Code. Built into the Claude Desktop app, the new tool lets users designate a specific folder where Claude can read or modify files, with further instructions given through the standard chat interface. The result is similar to a sandboxed instance of Claude Code, but requires far less technical savvy to set up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently in research preview, Cowork is only available to Max subscribers, with a waitlist available for users on other plans.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new tool is inspired in part by the growing number of subscribers using Claude Code to achieve non-coding tasks, treating it as a general-purpose agentic AI tool. Cowork is built on the Claude Agent SDK, which means it’s drawing on the same underlying model as Claude Code. The folder partition gives an easy way to manage what files Cowork has access to, and because the app doesn’t require command-line tools or virtual environments, it’s less intimidating for non-technical users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That opens up a new world of potential use cases. Anthropic gives the example of assembling an expense report from a folder of receipt photos — but Claude Code users have also put the system to work managing media files, scanning social media posts, or analyzing conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to Claude Code, Cowork is designed to take strings of actions without user input — a potentially dangerous approach if the tool is given vague or contradictory instructions. In a blog post announcing the new tool, Anthropic explicitly warns about the risk of prompt injection or deleted files, recommending that users make instructions as clear and unambiguous as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These risks aren’t new with Cowork,” the post reads, “but it might be the first time you’re using a more advanced tool that moves beyond a simple conversation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched as a command-line tool in November 2024, Claude Code has become one of Anthropic’s most successful products, leading the company to launch a string of new interfaces in recent months. A web interface launched in October, followed by a Slack integration just two months later.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/08/Claude-Chrome-Ext_email-hero-hero.png?w=1200" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Monday, Anthropic announced a new tool called Cowork, designed as a more accessible version of Claude Code. Built into the Claude Desktop app, the new tool lets users designate a specific folder where Claude can read or modify files, with further instructions given through the standard chat interface. The result is similar to a sandboxed instance of Claude Code, but requires far less technical savvy to set up.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently in research preview, Cowork is only available to Max subscribers, with a waitlist available for users on other plans.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The new tool is inspired in part by the growing number of subscribers using Claude Code to achieve non-coding tasks, treating it as a general-purpose agentic AI tool. Cowork is built on the Claude Agent SDK, which means it’s drawing on the same underlying model as Claude Code. The folder partition gives an easy way to manage what files Cowork has access to, and because the app doesn’t require command-line tools or virtual environments, it’s less intimidating for non-technical users.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That opens up a new world of potential use cases. Anthropic gives the example of assembling an expense report from a folder of receipt photos — but Claude Code users have also put the system to work managing media files, scanning social media posts, or analyzing conversations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Similar to Claude Code, Cowork is designed to take strings of actions without user input — a potentially dangerous approach if the tool is given vague or contradictory instructions. In a blog post announcing the new tool, Anthropic explicitly warns about the risk of prompt injection or deleted files, recommending that users make instructions as clear and unambiguous as possible.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“These risks aren’t new with Cowork,” the post reads, “but it might be the first time you’re using a more advanced tool that moves beyond a simple conversation.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Launched as a command-line tool in November 2024, Claude Code has become one of Anthropic’s most successful products, leading the company to launch a string of new interfaces in recent months. A web interface launched in October, followed by a Slack integration just two months later.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/anthropics-new-cowork-tool-offers-claude-code-without-the-code/</guid><pubDate>Mon, 12 Jan 2026 19:30:00 +0000</pubDate></item><item><title>[NEW] Apps like Grok are explicitly banned under Google’s rules—why is it still in the Play Store? (AI - Ars Technica)</title><link>https://arstechnica.com/google/2026/01/apps-like-grok-are-explicitly-banned-under-googles-rules-why-is-it-still-in-the-play-store/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google describes apps exactly like Grok and says they are banned from Google Play.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2225386195-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2225386195-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A smartphone shows Ani, a virtual anime-style assistant character featured in the Grok 4 AI chatbot developed by xAI. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng Xin / Contributor | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Elon Musk’s xAI recently weakened content guard rails for image generation in the Grok AI bot. This led to a new spate of non-consensual sexual imagery on X, much of it aimed at silencing women on the platform. This, along with the creation of sexualized images of children in the more compliant Grok, has led regulators to begin investigating xAI. In the meantime, Google has rules in place for exactly this eventuality—it’s just not enforcing them.&lt;/p&gt;
&lt;p&gt;It really could not be more clear from Google’s publicly available policies that Grok should have been banned yesterday. And yet, it remains in the Play Store. Not only that—it enjoys a T for Teen rating, one notch below the M-rated X app. Apple also still offers the Grok app on its platform, but its rules actually leave more wiggle room.&lt;/p&gt;
&lt;p&gt;App content restrictions at Apple and Google have evolved in very different ways. From the start, Apple has been prone to removing apps on a whim, so developers have come to expect that Apple’s guidelines may not mention every possible eventuality. As Google has shifted from a laissez-faire attitude to more hard-nosed control of the Play Store, it has progressively piled on clarifications in the content policy. As a result, Google’s rules are spelled out in no uncertain terms, and Grok runs afoul of them.&lt;/p&gt;
&lt;p&gt;Google has a dedicated support page that explains how to interpret its “Inappropriate Content” policy for the Play Store. Like Apple, the rules begin with a ban on apps that contain or promote sexual content including, but not limited to, pornography. That’s where Apple stops, but Google goes on to list more types of content and experiences that it considers against the rules.&lt;/p&gt;
&lt;p&gt;“We don’t allow apps that contain or promote content associated with sexually predatory behavior, &lt;em&gt;or distribute non-consensual sexual content&lt;/em&gt;,” the Play Store policy reads (emphasis ours). So the policy is taking aim at apps like Grok, but this line on its own could be read as focused on apps featuring “real” sexual content. However, Google is very thorough and has helpfully explained that this rule covers AI.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2135045 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Play Store policy" class="fullwidth full" height="120" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/2026-01-12-12_46_58-.png" width="661" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Recent additions to Google’s Play Store policy explicitly ban apps like Grok.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The detailed policy includes examples of content that violate this rule, which include much of what you’d expect—nothing lewd or profane, no escort services, and no illegal sexual themes. After a spate of rudimentary “nudify” apps in 2020 and 2021, Google added language to this page clarifying that “apps that claim to undress people” are not allowed in Google Play. In 2023, as the AI boom got underway, Google added another line to note that it also would remove apps that contained “non-consensual sexual content created via deepfake or similar technology.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Sound like any apps you know?&lt;/p&gt;
&lt;h2&gt;The archetype of a bannable app, approved for teens&lt;/h2&gt;
&lt;p&gt;Taken together, Google’s description of bannable apps describes Grok’s app to a tee. Google made these additions as new threats became apparent, knowing that developers would try to publish AI-undressing apps in the Play Store. The company did not, apparently, think the world’s richest person would be the one pushing digital humiliation tools on its platform. And Google’s response to this situation so far has been to do nothing.&lt;/p&gt;
&lt;p&gt;The backlash to xAI’s loosened restrictions prompted the company to limit access to image editing slightly. You can no longer edit images on X without paying for a premium plan. However, the Grok app does not have that limitation. Anyone who downloads Grok can use it to create non-consensual sexual content.&lt;/p&gt;
&lt;p&gt;Since the app is cleared for teens, even devices with parental controls enabled will permit 13- to 17-year-olds to download Grok. There is no paywall, and you don’t even have to log in before editing your first image. The app does ask the user to confirm their birth year, but teenagers would never lie about that, right?&lt;/p&gt;
&lt;p&gt;This is not xAI’s first problem with non-consensual sexual content. Last year, the AI was widely used to create fake Taylor Swift nudes. However, in that case, users were simply prompting the bot with the singer’s name—Grok can create entirely new images of famous people because the training data includes real images of them. Grok’s newer ability to “edit” images of people is a different and more insidious feature because it can turn anyone into an AI plaything.&lt;/p&gt;
&lt;p&gt;Ars has reached out to Google to ask why Grok has not been removed and why it has retained a Teen rating. The company has declined to make a statement at this time. So we’re left with a policy that explicitly bans apps like Grok, but Google is taking no action to enforce those policies, allowing impressionable teenagers and unsavory weirdos to use it to sexualize real people.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google describes apps exactly like Grok and says they are banned from Google Play.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2225386195-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2225386195-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A smartphone shows Ani, a virtual anime-style assistant character featured in the Grok 4 AI chatbot developed by xAI. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Cheng Xin / Contributor | Getty Images News

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Elon Musk’s xAI recently weakened content guard rails for image generation in the Grok AI bot. This led to a new spate of non-consensual sexual imagery on X, much of it aimed at silencing women on the platform. This, along with the creation of sexualized images of children in the more compliant Grok, has led regulators to begin investigating xAI. In the meantime, Google has rules in place for exactly this eventuality—it’s just not enforcing them.&lt;/p&gt;
&lt;p&gt;It really could not be more clear from Google’s publicly available policies that Grok should have been banned yesterday. And yet, it remains in the Play Store. Not only that—it enjoys a T for Teen rating, one notch below the M-rated X app. Apple also still offers the Grok app on its platform, but its rules actually leave more wiggle room.&lt;/p&gt;
&lt;p&gt;App content restrictions at Apple and Google have evolved in very different ways. From the start, Apple has been prone to removing apps on a whim, so developers have come to expect that Apple’s guidelines may not mention every possible eventuality. As Google has shifted from a laissez-faire attitude to more hard-nosed control of the Play Store, it has progressively piled on clarifications in the content policy. As a result, Google’s rules are spelled out in no uncertain terms, and Grok runs afoul of them.&lt;/p&gt;
&lt;p&gt;Google has a dedicated support page that explains how to interpret its “Inappropriate Content” policy for the Play Store. Like Apple, the rules begin with a ban on apps that contain or promote sexual content including, but not limited to, pornography. That’s where Apple stops, but Google goes on to list more types of content and experiences that it considers against the rules.&lt;/p&gt;
&lt;p&gt;“We don’t allow apps that contain or promote content associated with sexually predatory behavior, &lt;em&gt;or distribute non-consensual sexual content&lt;/em&gt;,” the Play Store policy reads (emphasis ours). So the policy is taking aim at apps like Grok, but this line on its own could be read as focused on apps featuring “real” sexual content. However, Google is very thorough and has helpfully explained that this rule covers AI.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2135045 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Play Store policy" class="fullwidth full" height="120" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/2026-01-12-12_46_58-.png" width="661" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Recent additions to Google’s Play Store policy explicitly ban apps like Grok.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The detailed policy includes examples of content that violate this rule, which include much of what you’d expect—nothing lewd or profane, no escort services, and no illegal sexual themes. After a spate of rudimentary “nudify” apps in 2020 and 2021, Google added language to this page clarifying that “apps that claim to undress people” are not allowed in Google Play. In 2023, as the AI boom got underway, Google added another line to note that it also would remove apps that contained “non-consensual sexual content created via deepfake or similar technology.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Sound like any apps you know?&lt;/p&gt;
&lt;h2&gt;The archetype of a bannable app, approved for teens&lt;/h2&gt;
&lt;p&gt;Taken together, Google’s description of bannable apps describes Grok’s app to a tee. Google made these additions as new threats became apparent, knowing that developers would try to publish AI-undressing apps in the Play Store. The company did not, apparently, think the world’s richest person would be the one pushing digital humiliation tools on its platform. And Google’s response to this situation so far has been to do nothing.&lt;/p&gt;
&lt;p&gt;The backlash to xAI’s loosened restrictions prompted the company to limit access to image editing slightly. You can no longer edit images on X without paying for a premium plan. However, the Grok app does not have that limitation. Anyone who downloads Grok can use it to create non-consensual sexual content.&lt;/p&gt;
&lt;p&gt;Since the app is cleared for teens, even devices with parental controls enabled will permit 13- to 17-year-olds to download Grok. There is no paywall, and you don’t even have to log in before editing your first image. The app does ask the user to confirm their birth year, but teenagers would never lie about that, right?&lt;/p&gt;
&lt;p&gt;This is not xAI’s first problem with non-consensual sexual content. Last year, the AI was widely used to create fake Taylor Swift nudes. However, in that case, users were simply prompting the bot with the singer’s name—Grok can create entirely new images of famous people because the training data includes real images of them. Grok’s newer ability to “edit” images of people is a different and more insidious feature because it can turn anyone into an AI plaything.&lt;/p&gt;
&lt;p&gt;Ars has reached out to Google to ask why Grok has not been removed and why it has retained a Teen rating. The company has declined to make a statement at this time. So we’re left with a policy that explicitly bans apps like Grok, but Google is taking no action to enforce those policies, allowing impressionable teenagers and unsavory weirdos to use it to sexualize real people.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2026/01/apps-like-grok-are-explicitly-banned-under-googles-rules-why-is-it-still-in-the-play-store/</guid><pubDate>Mon, 12 Jan 2026 19:36:17 +0000</pubDate></item><item><title>[NEW] Anthropic announces Claude for Healthcare following OpenAI’s ChatGPT Health reveal (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/anthropic-announces-claude-for-healthcare-following-openais-chatgpt-health-reveal/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On the heels of OpenAI’s ChatGPT Health reveal, Anthropic announced on Sunday that it’s introducing Claude for Healthcare, a set of tools for providers, payers, and patients.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like ChatGPT Health, Claude for Healthcare will allow users to sync health data from their phones, smartwatches, and other platforms (both OpenAI and Anthropic have said that their models won’t use this data for training). But Anthropic’s product promises more sophistication than ChatGPT Health, which seems as though it will be more focused on a patient-side chat experience as it rolls out gradually.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Though some industry professionals are concerned about the role of hallucination-prone LLMs in offering clients medical advice, Anthropic’s “agent skills” seem promising.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude has added what it calls “connectors” to give the AI access to platforms and databases that can speed up research processes and report generation for payers and providers, including the Centers for Medicare and Medicaid Services (CMS) Coverage Database; the International Classification of Diseases, 10th Revision (ICD-10); the National Provider Identifier Standard; and PubMed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic explained in a blog post that Claude for Health could use its connectors to speed up prior authorization review, the process in which a doctor must submit additional information to an insurance provider to see if it will cover a medication or treatment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Clinicians often report spending more time on documentation and paperwork than actually seeing patients,” Anthropic CPO Mike Krieger said in a presentation about the product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For doctors, submitting prior authorization documents is more of an administrative task than something that requires their specialized training and expertise. It’s something that makes more sense to automate than the actual process of administering medical advice&amp;nbsp;… though Claude will do that as well.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;People are already relying on LLMs for medical advice. OpenAI said that 230 million people talk about their health with ChatGPT each week, and there’s no doubt that Anthropic is observing that use case as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, both Anthropic and OpenAI warn consumers that they should see healthcare professionals for more reliable, tailored guidance.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/GettyImages-2252871842.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On the heels of OpenAI’s ChatGPT Health reveal, Anthropic announced on Sunday that it’s introducing Claude for Healthcare, a set of tools for providers, payers, and patients.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like ChatGPT Health, Claude for Healthcare will allow users to sync health data from their phones, smartwatches, and other platforms (both OpenAI and Anthropic have said that their models won’t use this data for training). But Anthropic’s product promises more sophistication than ChatGPT Health, which seems as though it will be more focused on a patient-side chat experience as it rolls out gradually.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Though some industry professionals are concerned about the role of hallucination-prone LLMs in offering clients medical advice, Anthropic’s “agent skills” seem promising.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Claude has added what it calls “connectors” to give the AI access to platforms and databases that can speed up research processes and report generation for payers and providers, including the Centers for Medicare and Medicaid Services (CMS) Coverage Database; the International Classification of Diseases, 10th Revision (ICD-10); the National Provider Identifier Standard; and PubMed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic explained in a blog post that Claude for Health could use its connectors to speed up prior authorization review, the process in which a doctor must submit additional information to an insurance provider to see if it will cover a medication or treatment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Clinicians often report spending more time on documentation and paperwork than actually seeing patients,” Anthropic CPO Mike Krieger said in a presentation about the product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For doctors, submitting prior authorization documents is more of an administrative task than something that requires their specialized training and expertise. It’s something that makes more sense to automate than the actual process of administering medical advice&amp;nbsp;… though Claude will do that as well.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;People are already relying on LLMs for medical advice. OpenAI said that 230 million people talk about their health with ChatGPT each week, and there’s no doubt that Anthropic is observing that use case as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Of course, both Anthropic and OpenAI warn consumers that they should see healthcare professionals for more reliable, tailored guidance.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/anthropic-announces-claude-for-healthcare-following-openais-chatgpt-health-reveal/</guid><pubDate>Mon, 12 Jan 2026 20:48:21 +0000</pubDate></item><item><title>[NEW] Mark Zuckerberg says Meta is launching its own AI infrastructure initiative (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/mark-zuckerberg-says-meta-is-launching-its-own-ai-infrastructure-initiative/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Meta announced capital expenditure projections last year, the company made it known that it planned to spend big to build out capacity for its AI business. “We expect that developing leading AI infrastructure will be a core advantage in developing the best AI models and product experiences,” said Susan Li, Meta CFO, during an earnings call last summer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now the tech giant appears to be making good on that promise. On Monday, CEO Mark Zuckerberg announced the launch of Meta Compute, a new initiative designed to bolster the tech giant’s AI infrastructure. Zuckerberg said the company intended to drastically expand its energy footprint in the coming years.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Meta is planning to build tens of gigawatts this decade, and hundreds of gigawatts or more over time. How we engineer, invest, and partner to build this infrastructure will become a strategic advantage,” Zuckerberg said in a post on Threads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For reference, a gigawatt is a measurement of electrical power equivalent to a billion watts. The energy-hungry AI business means that America’s electrical consumption could spike exponentially over the next decade (from 5 GW to 50, according to one estimate).   &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has named three executives that he says will be spearheading the new project. One of those people is Santosh Janardhan, the company’s head of global infrastructure. Janardhan, who has been with the company since 2009, will lead work on “technical architecture, software stack, silicon program, developer productivity, and building and operating our global datacenter fleet and network,” Zuckerberg said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also involved is Daniel Gross, who joined the company just last year. Gross is the co-founder of Safe Superintelligence, along with former OpenAI chief scientist Ilya Sutskever. Zuckerberg said that Gross would be leading a new group within Meta that is “responsible for long-term capacity strategy, supplier partnerships, industry analysis, planning, and business modeling.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Finally, Zuckerberg said that Dina Powell McCormick, a former government official who recently joined Meta as the company’s president and vice chairman, would be responsible for working with governments to help “build, deploy, invest in, and finance Meta’s infrastructure.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;There’s obviously a race to build out generative AI-ready cloud environments, and Capex projections announced last year showed most of Meta’s peers had similar ambitions. Microsoft has been busy partnering with AI infrastructure providers wherever it can, and in December, Google parent company Alphabet announced the acquisition of data center firm Intersect. TechCrunch reached out to Meta for more information about the new initiative.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2173579488.jpg?resize=1200,799" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Meta announced capital expenditure projections last year, the company made it known that it planned to spend big to build out capacity for its AI business. “We expect that developing leading AI infrastructure will be a core advantage in developing the best AI models and product experiences,” said Susan Li, Meta CFO, during an earnings call last summer.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Now the tech giant appears to be making good on that promise. On Monday, CEO Mark Zuckerberg announced the launch of Meta Compute, a new initiative designed to bolster the tech giant’s AI infrastructure. Zuckerberg said the company intended to drastically expand its energy footprint in the coming years.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“Meta is planning to build tens of gigawatts this decade, and hundreds of gigawatts or more over time. How we engineer, invest, and partner to build this infrastructure will become a strategic advantage,” Zuckerberg said in a post on Threads.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For reference, a gigawatt is a measurement of electrical power equivalent to a billion watts. The energy-hungry AI business means that America’s electrical consumption could spike exponentially over the next decade (from 5 GW to 50, according to one estimate).   &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Zuckerberg has named three executives that he says will be spearheading the new project. One of those people is Santosh Janardhan, the company’s head of global infrastructure. Janardhan, who has been with the company since 2009, will lead work on “technical architecture, software stack, silicon program, developer productivity, and building and operating our global datacenter fleet and network,” Zuckerberg said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Also involved is Daniel Gross, who joined the company just last year. Gross is the co-founder of Safe Superintelligence, along with former OpenAI chief scientist Ilya Sutskever. Zuckerberg said that Gross would be leading a new group within Meta that is “responsible for long-term capacity strategy, supplier partnerships, industry analysis, planning, and business modeling.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Finally, Zuckerberg said that Dina Powell McCormick, a former government official who recently joined Meta as the company’s president and vice chairman, would be responsible for working with governments to help “build, deploy, invest in, and finance Meta’s infrastructure.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 13-15, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;There’s obviously a race to build out generative AI-ready cloud environments, and Capex projections announced last year showed most of Meta’s peers had similar ambitions. Microsoft has been busy partnering with AI infrastructure providers wherever it can, and in December, Google parent company Alphabet announced the acquisition of data center firm Intersect. TechCrunch reached out to Meta for more information about the new initiative.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/mark-zuckerberg-says-meta-is-launching-its-own-ai-infrastructure-initiative/</guid><pubDate>Mon, 12 Jan 2026 21:44:43 +0000</pubDate></item><item><title>[NEW] Google removes some AI health summaries after investigation finds “dangerous” flaws (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI Overviews provided false liver test information experts called alarming.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-300x169.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This is fine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Sunday, Google removed some of its AI Overviews health summaries after a Guardian investigation found people were being put at risk by false and misleading information. The removals came after the newspaper found that Google’s generative AI feature delivered inaccurate health information at the top of search results, potentially leading seriously ill patients to mistakenly conclude they are in good health.&lt;/p&gt;
&lt;p&gt;Google disabled specific queries, such as “what is the normal range for liver blood tests,” after experts contacted by The Guardian flagged the results as dangerous. The report also highlighted a critical error regarding pancreatic cancer: The AI suggested patients avoid high-fat foods, a recommendation that contradicts standard medical guidance to maintain weight and could jeopardize patient health. Despite these findings, Google only deactivated the summaries for the liver test queries, leaving other potentially harmful answers accessible.&lt;/p&gt;
&lt;p&gt;The investigation revealed that searching for liver test norms generated raw data tables (listing specific enzymes like ALT, AST, and alkaline phosphatase) that lacked essential context. The AI feature also failed to adjust these figures for patient demographics such as age, sex, and ethnicity. Experts warned that because the AI model’s definition of “normal” often differed from actual medical standards, patients with serious liver conditions might mistakenly believe they are healthy and skip necessary follow-up care.&lt;/p&gt;
&lt;p&gt;Vanessa Hebditch, director of communications and policy at the British Liver Trust, told The Guardian that a liver function test is a collection of different blood tests and that understanding the results “is complex and involves a lot more than comparing a set of numbers.” She added that the AI Overviews fail to warn that someone can get normal results for these tests when they have serious liver disease and need further medical care. “This false reassurance could be very harmful,” she said.&lt;/p&gt;
&lt;p&gt;Google declined to comment on the specific removals to The Guardian. A company spokesperson told The Verge that Google invests in the quality of AI Overviews, particularly for health topics, and that “the vast majority provide accurate information.” The spokesperson added that the company’s internal team of clinicians reviewed what was shared and “found that in many instances, the information was not inaccurate and was also supported by high-quality websites.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Why AI Overviews produces errors&lt;/h2&gt;
&lt;p&gt;The recurring problems with AI Overviews stem from a design flaw in how the system works. As we reported in May 2024, Google built AI Overviews to show information backed up by top web results from its page ranking system. The company designed the feature this way based on the assumption that highly ranked pages contain accurate information.&lt;/p&gt;
&lt;p&gt;However, Google’s page ranking algorithm has long struggled with SEO-gamed content and spam. The system now feeds these unreliable results to its AI model, which then summarizes them with an authoritative tone that can mislead users. Even when the AI draws from accurate sources, the language model can still draw incorrect conclusions from the data, producing flawed summaries of otherwise reliable information.&lt;/p&gt;
&lt;p&gt;The technology does not inherently provide factual accuracy. Instead, it reflects whatever inaccuracies exist on the websites Google’s algorithm ranks highly, presenting the facts with an authority that makes errors appear trustworthy.&lt;/p&gt;
&lt;h2&gt;Other examples remain active&lt;/h2&gt;
&lt;p&gt;The Guardian found that typing slight variations of the original queries into Google, such as “lft reference range” or “lft test reference range,” still prompted AI Overviews. Hebditch said this was a big worry and that the AI Overviews present a list of tests in bold, making it very easy for readers to miss that these numbers might not even be the right ones for their test.&lt;/p&gt;
&lt;p&gt;AI Overviews still appear for other examples that The Guardian originally highlighted to Google. When asked why these AI Overviews had not also been removed, Google said they linked to well-known&amp;nbsp;and reputable sources and informed people when it was important to seek out expert advice.&lt;/p&gt;
&lt;p&gt;Google said AI Overviews only appear for queries where it has high confidence in the quality of the responses. The company constantly measures and reviews the quality of its summaries across many different categories of information, it added.&lt;/p&gt;
&lt;p&gt;This is not the first controversy for AI Overviews. The feature has previously told people to put glue on pizza and eat rocks. It has proven unpopular enough that users have discovered that inserting curse words into search queries disables AI Overviews entirely.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        AI Overviews provided false liver test information experts called alarming.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="169" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-300x169.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2024/05/GettyImages-1488311999-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      This is fine.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Getty Images

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;On Sunday, Google removed some of its AI Overviews health summaries after a Guardian investigation found people were being put at risk by false and misleading information. The removals came after the newspaper found that Google’s generative AI feature delivered inaccurate health information at the top of search results, potentially leading seriously ill patients to mistakenly conclude they are in good health.&lt;/p&gt;
&lt;p&gt;Google disabled specific queries, such as “what is the normal range for liver blood tests,” after experts contacted by The Guardian flagged the results as dangerous. The report also highlighted a critical error regarding pancreatic cancer: The AI suggested patients avoid high-fat foods, a recommendation that contradicts standard medical guidance to maintain weight and could jeopardize patient health. Despite these findings, Google only deactivated the summaries for the liver test queries, leaving other potentially harmful answers accessible.&lt;/p&gt;
&lt;p&gt;The investigation revealed that searching for liver test norms generated raw data tables (listing specific enzymes like ALT, AST, and alkaline phosphatase) that lacked essential context. The AI feature also failed to adjust these figures for patient demographics such as age, sex, and ethnicity. Experts warned that because the AI model’s definition of “normal” often differed from actual medical standards, patients with serious liver conditions might mistakenly believe they are healthy and skip necessary follow-up care.&lt;/p&gt;
&lt;p&gt;Vanessa Hebditch, director of communications and policy at the British Liver Trust, told The Guardian that a liver function test is a collection of different blood tests and that understanding the results “is complex and involves a lot more than comparing a set of numbers.” She added that the AI Overviews fail to warn that someone can get normal results for these tests when they have serious liver disease and need further medical care. “This false reassurance could be very harmful,” she said.&lt;/p&gt;
&lt;p&gt;Google declined to comment on the specific removals to The Guardian. A company spokesperson told The Verge that Google invests in the quality of AI Overviews, particularly for health topics, and that “the vast majority provide accurate information.” The spokesperson added that the company’s internal team of clinicians reviewed what was shared and “found that in many instances, the information was not inaccurate and was also supported by high-quality websites.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Why AI Overviews produces errors&lt;/h2&gt;
&lt;p&gt;The recurring problems with AI Overviews stem from a design flaw in how the system works. As we reported in May 2024, Google built AI Overviews to show information backed up by top web results from its page ranking system. The company designed the feature this way based on the assumption that highly ranked pages contain accurate information.&lt;/p&gt;
&lt;p&gt;However, Google’s page ranking algorithm has long struggled with SEO-gamed content and spam. The system now feeds these unreliable results to its AI model, which then summarizes them with an authoritative tone that can mislead users. Even when the AI draws from accurate sources, the language model can still draw incorrect conclusions from the data, producing flawed summaries of otherwise reliable information.&lt;/p&gt;
&lt;p&gt;The technology does not inherently provide factual accuracy. Instead, it reflects whatever inaccuracies exist on the websites Google’s algorithm ranks highly, presenting the facts with an authority that makes errors appear trustworthy.&lt;/p&gt;
&lt;h2&gt;Other examples remain active&lt;/h2&gt;
&lt;p&gt;The Guardian found that typing slight variations of the original queries into Google, such as “lft reference range” or “lft test reference range,” still prompted AI Overviews. Hebditch said this was a big worry and that the AI Overviews present a list of tests in bold, making it very easy for readers to miss that these numbers might not even be the right ones for their test.&lt;/p&gt;
&lt;p&gt;AI Overviews still appear for other examples that The Guardian originally highlighted to Google. When asked why these AI Overviews had not also been removed, Google said they linked to well-known&amp;nbsp;and reputable sources and informed people when it was important to seek out expert advice.&lt;/p&gt;
&lt;p&gt;Google said AI Overviews only appear for queries where it has high confidence in the quality of the responses. The company constantly measures and reviews the quality of its summaries across many different categories of information, it added.&lt;/p&gt;
&lt;p&gt;This is not the first controversy for AI Overviews. The feature has previously told people to put glue on pizza and eat rocks. It has proven unpopular enough that users have discovered that inserting curse words into search queries disables AI Overviews entirely.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/google-removes-some-ai-health-summaries-after-investigation-finds-dangerous-flaws/</guid><pubDate>Mon, 12 Jan 2026 21:47:32 +0000</pubDate></item><item><title>[NEW] Why Amazon bought Bee, an AI wearable (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/why-amazon-bought-bee-an-ai-wearable/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/HD_8500c2.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Smart rings, smart screens, smart TVs, smart pins, smart&amp;nbsp;… ice cube makers? Sure, why not! AI was everywhere at this year’s Consumer Electronics Show (CES) in Las Vegas, where companies large and small were showing off how they’re bringing AI to more devices. For Amazon, CES was a time to show off its newest acquisition in the space: Bee, an AI device that can be worn as a clip-on pin or a bracelet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon already has an entry in the AI consumer devices space with Alexa, whose upgraded AI-powered version, Alexa+, can run on 97% of the hardware devices Amazon has shipped. However, with Bee, the company is gaining access to a wearable that could extend its reach outside the home.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Largely designed for recording conversations like interviews, meetings, or classes, Bee also works as an AI companion. The AI has access to world knowledge, and it learns more about you from a combination of your recordings and the services you permit it to access like Gmail, Google Calendar, your phone’s contacts, and Apple Health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that Amazon has already tried integrating Alexa into wearables like earbuds and glasses, it could seem like the company is muddying the waters with the addition of another AI companion. However, those earlier Alexa devices have not taken off in the face of competition like Apple’s AirPods and Ray-Ban Meta AI glasses. Amazon seems to understand this, which is why it’s adding Bee to its lineup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see each other as complementary friends,” says Bee co-founder Maria de Lourdes Zollo of Bee’s relationship with Alexa, in an interview at CES last week. “Bee has the understanding of outside the house, and Alexa has the understanding of inside the house. Of course, there will be a future where these two things come together.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That future doesn’t yet mean Bee’s AI will be replaced by Alexa. Noted Amazon Alexa VP Daniel Rausch, Amazon thinks what the team at Bee created is an “important and lovable experience.” He describes Bee as a “deeply engaging and personal” AI, but he also agreed that, at some point, Alexa and Bee would come together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We know that it will create even more benefit for customers than what [the AI experiences] do on their own,” Rausch explained. “When you have access to the power of these AI experiences with you throughout the day, and they’re continuous — we’re gonna be able to do so much more for customers.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;De Lourdes Zollo said that Bee learns from its users, gaining an understanding of their patterns, insights, and commitments, which can help it to suggest to-do items and follow-ups throughout your day. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early use cases have included students who record lectures, elderly people who have trouble remembering things, and people who speak for a living and don’t want to always take notes manually. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They just want a place to have all the summarization of everything they said,” Bee’s co-founder said. “So based on that, we build a really big graph of knowledge [about] you, where you can go chat with Bee, and have an understanding of what happened to you, but also how you’re changing during the course of your life,” de Lourdes Zollo added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similar to Alexa, Bee uses a combination of AI models under the hood, but it’s exploring adding Amazon’s AI as one in the mix. After transcribing the conversation, Bee discards the audio, making it impractical for many work-related use cases where you need to play back the conversation to ensure accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s still much ahead for Bee in 2026, de Lourdes Zollo teased, without giving anything away. In addition to recent announcements of new features and functionality — like voice notes, templates, daily insights, and more — the founder said the eight-person team is working on “many new things” out of their HQ in San Francisco, where Amazon already has a large number of hardware and Alexa employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Honestly, it’s endless possibilities now, and that’s one of the reasons why we’re really excited to be part of Amazon,” she said. &lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/07/HD_8500c2.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Smart rings, smart screens, smart TVs, smart pins, smart&amp;nbsp;… ice cube makers? Sure, why not! AI was everywhere at this year’s Consumer Electronics Show (CES) in Las Vegas, where companies large and small were showing off how they’re bringing AI to more devices. For Amazon, CES was a time to show off its newest acquisition in the space: Bee, an AI device that can be worn as a clip-on pin or a bracelet.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon already has an entry in the AI consumer devices space with Alexa, whose upgraded AI-powered version, Alexa+, can run on 97% of the hardware devices Amazon has shipped. However, with Bee, the company is gaining access to a wearable that could extend its reach outside the home.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Largely designed for recording conversations like interviews, meetings, or classes, Bee also works as an AI companion. The AI has access to world knowledge, and it learns more about you from a combination of your recordings and the services you permit it to access like Gmail, Google Calendar, your phone’s contacts, and Apple Health.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Given that Amazon has already tried integrating Alexa into wearables like earbuds and glasses, it could seem like the company is muddying the waters with the addition of another AI companion. However, those earlier Alexa devices have not taken off in the face of competition like Apple’s AirPods and Ray-Ban Meta AI glasses. Amazon seems to understand this, which is why it’s adding Bee to its lineup.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see each other as complementary friends,” says Bee co-founder Maria de Lourdes Zollo of Bee’s relationship with Alexa, in an interview at CES last week. “Bee has the understanding of outside the house, and Alexa has the understanding of inside the house. Of course, there will be a future where these two things come together.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That future doesn’t yet mean Bee’s AI will be replaced by Alexa. Noted Amazon Alexa VP Daniel Rausch, Amazon thinks what the team at Bee created is an “important and lovable experience.” He describes Bee as a “deeply engaging and personal” AI, but he also agreed that, at some point, Alexa and Bee would come together.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We know that it will create even more benefit for customers than what [the AI experiences] do on their own,” Rausch explained. “When you have access to the power of these AI experiences with you throughout the day, and they’re continuous — we’re gonna be able to do so much more for customers.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;De Lourdes Zollo said that Bee learns from its users, gaining an understanding of their patterns, insights, and commitments, which can help it to suggest to-do items and follow-ups throughout your day. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Early use cases have included students who record lectures, elderly people who have trouble remembering things, and people who speak for a living and don’t want to always take notes manually. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“They just want a place to have all the summarization of everything they said,” Bee’s co-founder said. “So based on that, we build a really big graph of knowledge [about] you, where you can go chat with Bee, and have an understanding of what happened to you, but also how you’re changing during the course of your life,” de Lourdes Zollo added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Similar to Alexa, Bee uses a combination of AI models under the hood, but it’s exploring adding Amazon’s AI as one in the mix. After transcribing the conversation, Bee discards the audio, making it impractical for many work-related use cases where you need to play back the conversation to ensure accuracy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s still much ahead for Bee in 2026, de Lourdes Zollo teased, without giving anything away. In addition to recent announcements of new features and functionality — like voice notes, templates, daily insights, and more — the founder said the eight-person team is working on “many new things” out of their HQ in San Francisco, where Amazon already has a large number of hardware and Alexa employees.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Honestly, it’s endless possibilities now, and that’s one of the reasons why we’re really excited to be part of Amazon,” she said. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/why-amazon-bought-bee-an-ai-wearable/</guid><pubDate>Mon, 12 Jan 2026 21:55:44 +0000</pubDate></item><item><title>[NEW] Even Linus Torvalds is trying his hand at vibe coding (but just a little) (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/hobby-github-repo-shows-linus-torvalds-vibe-codes-sometimes/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “But then I cut out the middle man—me.”
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="300" src="https://cdn.arstechnica.net/wp-content/uploads/2015/08/LinuxCon_Europe_Linus_Torvalds_05-300x300.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2015/08/LinuxCon_Europe_Linus_Torvalds_05-1152x648-1768254932.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Linus Torvalds.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Krd

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Linux and Git creator Linus Torvalds’ latest project contains code that was “basically written by vibe coding,” but you shouldn’t read that to mean that Torvalds is embracing that approach for anything and everything.&lt;/p&gt;
&lt;p&gt;Torvalds sometimes works on a small hobby projects over holiday breaks. Last year, he made guitar pedals. This year, he did some work on AudioNoise, which he calls “another silly guitar-pedal-related repo.” It creates random digital audio effects.&lt;/p&gt;
&lt;p&gt;Torvalds revealed that he had used an AI coding tool in the README for the repo:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Also note that the python visualizer tool has been basically written by vibe-coding. I know more about analog filters—and that’s not saying much—than I do about python. It started out as my typical “google and do the monkey-see-monkey-do” kind of programming, but then I cut out the middle-man—me—and just used Google Antigravity to do the audio sample visualizer.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Google’s Antigravity is a fork of the AI-focused IDE Windsurf. He didn’t specify which model he used, but using Antigravity suggests (but does not prove) that it was some version of Google’s Gemini.&lt;/p&gt;
&lt;p&gt;Torvalds’ past public comments on using large language model-based tools for programming have been more nuanced than many online discussions about it.&lt;/p&gt;
&lt;p&gt;He has touted AI primarily as “a tool to help maintain code, including automated patch checking and code review,” citing examples of tools that found problems he had missed.&lt;/p&gt;
&lt;p&gt;On the other hand, he has also said he is generally “much less interested in AI for writing code,” and has publicly said that he’s not anti-AI in principle, but he’s very much anti-hype around AI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Based on that, you might be surprised that he used self-described vibe coding to build a part of his application, but you probably shouldn’t be. There are a few key things here. First, AudioNoise is entirely a personal hobby project, and it’s pretty much just a toy, not serious infrastructure.&lt;/p&gt;
&lt;p&gt;Second, Torvalds’ README note makes it clear that he went with this approach in an instance where he previously would have just copied something from a forum thread or StackOverflow anyway, as the visualizer tool component in the project is written in Python, which is not his specialty.&lt;/p&gt;
&lt;p&gt;Developers of all stripes are still fiercely debating what use (if any) AI coding tools should have in workflows. Just yesterday, developer Salvatore Sanfilippo published a widely circulated and discussed blog post arguing that such tools have already changed programming forever and aren’t going away, even as he acknowledged the related chaos and problems. He wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;How do I feel, about all the code I wrote that was ingested by LLMs? I feel great to be part of that, because I see this as a continuation of what I tried to do all my life: democratizing code, systems, knowledge. LLMs are going to help us to write better software, faster, and will allow small teams to have a chance to compete with bigger companies. The same thing open source software did in the 90s.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As you might expect, the debate about this has been spirited. But while people argue in Hacker News comments, Torvalds—normally known to be intensely opinionated himself—is vibe coding audio tools over the holidays.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “But then I cut out the middle man—me.”
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="300" src="https://cdn.arstechnica.net/wp-content/uploads/2015/08/LinuxCon_Europe_Linus_Torvalds_05-300x300.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2015/08/LinuxCon_Europe_Linus_Torvalds_05-1152x648-1768254932.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Linus Torvalds.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Krd

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Linux and Git creator Linus Torvalds’ latest project contains code that was “basically written by vibe coding,” but you shouldn’t read that to mean that Torvalds is embracing that approach for anything and everything.&lt;/p&gt;
&lt;p&gt;Torvalds sometimes works on a small hobby projects over holiday breaks. Last year, he made guitar pedals. This year, he did some work on AudioNoise, which he calls “another silly guitar-pedal-related repo.” It creates random digital audio effects.&lt;/p&gt;
&lt;p&gt;Torvalds revealed that he had used an AI coding tool in the README for the repo:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Also note that the python visualizer tool has been basically written by vibe-coding. I know more about analog filters—and that’s not saying much—than I do about python. It started out as my typical “google and do the monkey-see-monkey-do” kind of programming, but then I cut out the middle-man—me—and just used Google Antigravity to do the audio sample visualizer.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Google’s Antigravity is a fork of the AI-focused IDE Windsurf. He didn’t specify which model he used, but using Antigravity suggests (but does not prove) that it was some version of Google’s Gemini.&lt;/p&gt;
&lt;p&gt;Torvalds’ past public comments on using large language model-based tools for programming have been more nuanced than many online discussions about it.&lt;/p&gt;
&lt;p&gt;He has touted AI primarily as “a tool to help maintain code, including automated patch checking and code review,” citing examples of tools that found problems he had missed.&lt;/p&gt;
&lt;p&gt;On the other hand, he has also said he is generally “much less interested in AI for writing code,” and has publicly said that he’s not anti-AI in principle, but he’s very much anti-hype around AI.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Based on that, you might be surprised that he used self-described vibe coding to build a part of his application, but you probably shouldn’t be. There are a few key things here. First, AudioNoise is entirely a personal hobby project, and it’s pretty much just a toy, not serious infrastructure.&lt;/p&gt;
&lt;p&gt;Second, Torvalds’ README note makes it clear that he went with this approach in an instance where he previously would have just copied something from a forum thread or StackOverflow anyway, as the visualizer tool component in the project is written in Python, which is not his specialty.&lt;/p&gt;
&lt;p&gt;Developers of all stripes are still fiercely debating what use (if any) AI coding tools should have in workflows. Just yesterday, developer Salvatore Sanfilippo published a widely circulated and discussed blog post arguing that such tools have already changed programming forever and aren’t going away, even as he acknowledged the related chaos and problems. He wrote:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;How do I feel, about all the code I wrote that was ingested by LLMs? I feel great to be part of that, because I see this as a continuation of what I tried to do all my life: democratizing code, systems, knowledge. LLMs are going to help us to write better software, faster, and will allow small teams to have a chance to compete with bigger companies. The same thing open source software did in the 90s.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;As you might expect, the debate about this has been spirited. But while people argue in Hacker News comments, Torvalds—normally known to be intensely opinionated himself—is vibe coding audio tools over the holidays.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/hobby-github-repo-shows-linus-torvalds-vibe-codes-sometimes/</guid><pubDate>Mon, 12 Jan 2026 22:27:50 +0000</pubDate></item><item><title>[NEW] Anthropic launches Cowork, a Claude Code-like for general computing (AI - Ars Technica)</title><link>https://arstechnica.com/ai/2026/01/anthropic-launches-cowork-a-claude-code-like-for-general-computing/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Users can give Claude access to a folder and tell it what to do for them.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An orange logo with a lightning bolt" class="absolute inset-0 w-full h-full object-cover hidden" height="364" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Claude-Cowork-640x364.jpg" width="640" /&gt;
                  &lt;img alt="An orange logo with a lightning bolt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Claude-Cowork-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The very corporate, very vague branding image for Anthropic's Claude Cowork.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anthropic’s agentic tool Claude Code has been an enormous hit with some software developers and hobbyists, and now the company is bringing that modality to more general office work with a new feature called Cowork.&lt;/p&gt;
&lt;p&gt;Built on the same foundations as Claude Code and baked into the macOS Claude desktop app, Cowork allows users to give Claude access to a specific folder on their computer and then give plain language instructions for tasks.&lt;/p&gt;
&lt;p&gt;Anthropic gave examples like filling out an expense report from a folder full of receipt photos, writing reports based on a big stack of digital notes, or reorganizing a folder (or cleaning up your desktop) based on a prompt.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An example demo of Cowork in action

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;A lot of this was already possible with Claude Code, but it might not have been clear to all users that it could be used that way, and Claude Code required more technical know-how to set up. Anthropic’s goal with Cowork is to make it something any knowledge worker—from developers to marketers—could get rolling with right away. Anthropic says it started working on Cowork partly because people were already using Claude Code for general knowledge work tasks anyway.&lt;/p&gt;
&lt;p&gt;I’ve already been doing things similar to this with the Claude desktop app via &lt;span class="K6pdKd wtBS9" id="_cIVlafCEDvOs0PEPh6XHsQE_70"&gt;Model Context Protocol (MCP)&lt;/span&gt;, prompting it to perform tasks like creating notes directly in my Obsidian vault based on files I showed it, but this is clearly a cleaner way to do some of that—and there are Claude Code-like usability perks here, like the ability to make new requests or amendments to the assignment with a new message before the initial task is complete.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That said, there are some causes for concern. Generally speaking, you expect a Claude Code-using developer or a hobbyist geeky enough to play around with MCP to understand the risks in what they’re doing. Less technical users might not have that foresight.&lt;/p&gt;
&lt;p&gt;Anthropic’s announcement about Cowork names a few potential concerns up front. First, you have to be careful with how you word your prompts, as a vague one (or, frankly, just incredibly bad luck) can lead the agent to do destructive things like unexpectedly delete files.&lt;/p&gt;
&lt;p&gt;There’s also the very real, seemingly unsolvable risk of prompt injection attacks.&lt;/p&gt;
&lt;p&gt;Given all of that, Cowork is currently available only as a research preview to Max subscribers. There’s no word about when it might see a wider release.&lt;/p&gt;
&lt;p&gt;This isn’t the only effort Anthropic has made to branch out beyond its established footprint among coders this week. Yesterday, the company also announced Claude for Healthcare, competing with OpenAI’s similar announcement of a health management tool for ChatGPT.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Users can give Claude access to a folder and tell it what to do for them.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="An orange logo with a lightning bolt" class="absolute inset-0 w-full h-full object-cover hidden" height="364" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Claude-Cowork-640x364.jpg" width="640" /&gt;
                  &lt;img alt="An orange logo with a lightning bolt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2026/01/Claude-Cowork-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The very corporate, very vague branding image for Anthropic's Claude Cowork.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Anthropic

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Anthropic’s agentic tool Claude Code has been an enormous hit with some software developers and hobbyists, and now the company is bringing that modality to more general office work with a new feature called Cowork.&lt;/p&gt;
&lt;p&gt;Built on the same foundations as Claude Code and baked into the macOS Claude desktop app, Cowork allows users to give Claude access to a specific folder on their computer and then give plain language instructions for tasks.&lt;/p&gt;
&lt;p&gt;Anthropic gave examples like filling out an expense report from a folder full of receipt photos, writing reports based on a big stack of digital notes, or reorganizing a folder (or cleaning up your desktop) based on a prompt.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      An example demo of Cowork in action

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;A lot of this was already possible with Claude Code, but it might not have been clear to all users that it could be used that way, and Claude Code required more technical know-how to set up. Anthropic’s goal with Cowork is to make it something any knowledge worker—from developers to marketers—could get rolling with right away. Anthropic says it started working on Cowork partly because people were already using Claude Code for general knowledge work tasks anyway.&lt;/p&gt;
&lt;p&gt;I’ve already been doing things similar to this with the Claude desktop app via &lt;span class="K6pdKd wtBS9" id="_cIVlafCEDvOs0PEPh6XHsQE_70"&gt;Model Context Protocol (MCP)&lt;/span&gt;, prompting it to perform tasks like creating notes directly in my Obsidian vault based on files I showed it, but this is clearly a cleaner way to do some of that—and there are Claude Code-like usability perks here, like the ability to make new requests or amendments to the assignment with a new message before the initial task is complete.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That said, there are some causes for concern. Generally speaking, you expect a Claude Code-using developer or a hobbyist geeky enough to play around with MCP to understand the risks in what they’re doing. Less technical users might not have that foresight.&lt;/p&gt;
&lt;p&gt;Anthropic’s announcement about Cowork names a few potential concerns up front. First, you have to be careful with how you word your prompts, as a vague one (or, frankly, just incredibly bad luck) can lead the agent to do destructive things like unexpectedly delete files.&lt;/p&gt;
&lt;p&gt;There’s also the very real, seemingly unsolvable risk of prompt injection attacks.&lt;/p&gt;
&lt;p&gt;Given all of that, Cowork is currently available only as a research preview to Max subscribers. There’s no word about when it might see a wider release.&lt;/p&gt;
&lt;p&gt;This isn’t the only effort Anthropic has made to branch out beyond its established footprint among coders this week. Yesterday, the company also announced Claude for Healthcare, competing with OpenAI’s similar announcement of a health management tool for ChatGPT.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2026/01/anthropic-launches-cowork-a-claude-code-like-for-general-computing/</guid><pubDate>Mon, 12 Jan 2026 23:42:09 +0000</pubDate></item><item><title>[NEW] Hands-on with Bee, Amazon’s latest AI wearable (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/01/12/hands-on-with-bee-amazons-latest-ai-wearable/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In early tests with a review unit of Bee, we found the device itself was easy to use. It’s just a press of a button to turn recording on or off. In the app, you can configure whether a double press bookmarks a section of the conversation, processes the current conversation, or both, and you can set whether a press and hold gesture lets you leave a voice note or chat with the AI assistant. (Bee’s companion app currently reminds you to enable voice notes, so we did.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like many other AI products and services, such as Plaud, Granola, Fathom, Fireflies, Otter, and more, Bee can listen, record, and transcribe audio conversations. Where it differs is that instead of offering an overview or a raw transcript, it segments the audio into sections and summarizes each part. For instance, an interview might be segmented into sections like the introduction, the nitty-gritty product details, an overview of industry trends, and whatever else you may have talked about.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Each section is tinted with a different background color for easier differentiation as you scroll. You can tap into an individual section to see the exact transcription. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082063" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0715.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It wasn’t immediately obvious how to label the speakers in the app — we learned we could tap on a segment of the conversation to confirm if we were the speaker, but this fell short of other professional AI transcribers, where each speaker could be labeled. In addition, Bee discards the audio after transcription, making it a non-starter for use cases where you need to play back the audio to ensure accuracy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Bee isn’t necessarily meant to be a work tool. Amazon sees this as an AI that can live alongside you as you go about your day. By integrating with Google’s services, Bee can tie a recorded conversation to a task. For instance, after meeting someone at a conference, it could suggest that you friend them on LinkedIn or research their product.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082060" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_7F964ECF5294-1.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot with redacted personal data&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can also leave yourself voice notes, as an alternative to writing something down in your notes app, for instance. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another section in Bee’s app lets you look back at past days’ memories, while a “Grow” section will offer insights the more it learns about you. You can also confirm and add to a “facts” section about yourself, which is somewhat equivalent to other AI chatbots’ ability to remember things you discussed. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon says it will be shipping more features for Bee in the year ahead.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082062" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0713.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082061" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0714.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Bee &lt;em&gt;isn’t&lt;/em&gt; always listening by default, which is why rival wearables like the Friend AI pendant saw backlash. Instead, you’re meant to ask if you can record someone’s conversation (unless at a public event of some sort, where recording is already expected). &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When you do record, a green light turns on, alerting others to the fact that the device is in use.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Bee’s sports band was a little flimsy. The band fell off twice while being worn, both times while just sitting and not moving the hands much (like in a taxi). We have not yet tested the clip-on pin, but it feels more sturdy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, the mobile app’s design is far ahead of the apps Amazon has built in-house, like the Alexa mobile experience, and it’s easy to use. But the premise that we need an AI specifically to record conversations to learn more about us is still largely untested. Is there a world where such devices make sense for consumers who aren’t recording in professional settings, like meetings and interviews?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, if AI listening devices go mainstream, there will also have to be some sort of cultural shift in terms of what’s appropriate and what’s not. Today, it’s somewhat looked down upon to record video of everyday people going about their lives, even though it’s technically legal when they’re in public; similarly, it may be considered tasteless or gauche to record audio with an AI device if you don’t first ask permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not everyone will abide by that social contract, of course, which could see people self-censoring their speech in public. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At CES, for instance, we were chatting with a rep at the Soundcore booth. When they liked something I said about a competitor’s product, they joked, ‘Say that louder into my microphone,’ pointing to the already-recording AI device subtly pinned to their shirt. It was an odd experience to realize that everything said in the real world could one day be “on the record,” whether you consented or not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bee’s traction — or lack thereof — will help Amazon determine if that’s a world that consumers actually want.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;In early tests with a review unit of Bee, we found the device itself was easy to use. It’s just a press of a button to turn recording on or off. In the app, you can configure whether a double press bookmarks a section of the conversation, processes the current conversation, or both, and you can set whether a press and hold gesture lets you leave a voice note or chat with the AI assistant. (Bee’s companion app currently reminds you to enable voice notes, so we did.)&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Like many other AI products and services, such as Plaud, Granola, Fathom, Fireflies, Otter, and more, Bee can listen, record, and transcribe audio conversations. Where it differs is that instead of offering an overview or a raw transcript, it segments the audio into sections and summarizes each part. For instance, an interview might be segmented into sections like the introduction, the nitty-gritty product details, an overview of industry trends, and whatever else you may have talked about.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Each section is tinted with a different background color for easier differentiation as you scroll. You can tap into an individual section to see the exact transcription. &lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082063" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0715.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;It wasn’t immediately obvious how to label the speakers in the app — we learned we could tap on a segment of the conversation to confirm if we were the speaker, but this fell short of other professional AI transcribers, where each speaker could be labeled. In addition, Bee discards the audio after transcription, making it a non-starter for use cases where you need to play back the audio to ensure accuracy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;That said, Bee isn’t necessarily meant to be a work tool. Amazon sees this as an AI that can live alongside you as you go about your day. By integrating with Google’s services, Bee can tie a recorded conversation to a task. For instance, after meeting someone at a conference, it could suggest that you friend them on LinkedIn or research their product.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082060" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_7F964ECF5294-1.jpeg?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot with redacted personal data&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;You can also leave yourself voice notes, as an alternative to writing something down in your notes app, for instance. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another section in Bee’s app lets you look back at past days’ memories, while a “Grow” section will offer insights the more it learns about you. You can also confirm and add to a “facts” section about yourself, which is somewhat equivalent to other AI chatbots’ ability to remember things you discussed. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon says it will be shipping more features for Bee in the year ahead.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082062" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0713.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3082061" height="680" src="https://techcrunch.com/wp-content/uploads/2026/01/IMG_0714.png?w=313" width="313" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Bee screenshot&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Bee &lt;em&gt;isn’t&lt;/em&gt; always listening by default, which is why rival wearables like the Friend AI pendant saw backlash. Instead, you’re meant to ask if you can record someone’s conversation (unless at a public event of some sort, where recording is already expected). &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;When you do record, a green light turns on, alerting others to the fact that the device is in use.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Bee’s sports band was a little flimsy. The band fell off twice while being worn, both times while just sitting and not moving the hands much (like in a taxi). We have not yet tested the clip-on pin, but it feels more sturdy. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Overall, the mobile app’s design is far ahead of the apps Amazon has built in-house, like the Alexa mobile experience, and it’s easy to use. But the premise that we need an AI specifically to record conversations to learn more about us is still largely untested. Is there a world where such devices make sense for consumers who aren’t recording in professional settings, like meetings and interviews?&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Plus, if AI listening devices go mainstream, there will also have to be some sort of cultural shift in terms of what’s appropriate and what’s not. Today, it’s somewhat looked down upon to record video of everyday people going about their lives, even though it’s technically legal when they’re in public; similarly, it may be considered tasteless or gauche to record audio with an AI device if you don’t first ask permission.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Not everyone will abide by that social contract, of course, which could see people self-censoring their speech in public. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At CES, for instance, we were chatting with a rep at the Soundcore booth. When they liked something I said about a competitor’s product, they joked, ‘Say that louder into my microphone,’ pointing to the already-recording AI device subtly pinned to their shirt. It was an odd experience to realize that everything said in the real world could one day be “on the record,” whether you consented or not.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Bee’s traction — or lack thereof — will help Amazon determine if that’s a world that consumers actually want.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/01/12/hands-on-with-bee-amazons-latest-ai-wearable/</guid><pubDate>Tue, 13 Jan 2026 00:00:00 +0000</pubDate></item></channel></rss>