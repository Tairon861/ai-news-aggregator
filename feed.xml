<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Tue, 24 Jun 2025 18:31:06 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Huawei HarmonyOS 6 AI agents offer alternative to Android and iOS (AI News)</title><link>https://www.artificialintelligence-news.com/news/huawei-harmonyos-6-ai-agents-beta/</link><description>&lt;p&gt;The latest phase of the mobile OS wars isn’t being fought over app stores or user interfaces – it’s being waged with artificial intelligence. Huawei’s latest salvo comes in the form of HarmonyOS 6, in which AI agents aren’t features but the architecture driving user interactions.&lt;/p&gt;&lt;p&gt;The beta release to developers signals a broader industry shift where operating systems transform from passive platforms into what are being framed as intelligent intermediaries that anticipate, learn, and act on behalf of users.&lt;/p&gt;&lt;h3&gt;The AI-first approach defines the latest release&lt;/h3&gt;&lt;p&gt;The centrepiece of HarmonyOS 6 lies in its AI agents framework, which lets developers create automated programmes without the complexity of building or training foundation models from scratch.&lt;/p&gt;&lt;p&gt;The HarmonyOS Agent Framework attempts to make AI development more accessible in Huawei’s ecosystem.&lt;/p&gt;&lt;p&gt;Richard Yu Chengdong, chairman of Huawei’s consumer business group, has announced that more than 50 AI agents from established Chinese platforms including Weibo and Ximalaya will be available when HarmonyOS 6 launches to consumers.&lt;/p&gt;&lt;p&gt;However, Yu did not specify a public release date during a developer conference presentation held on Friday.&lt;/p&gt;&lt;p&gt;The AI agents integration develops an industry trend where operating systems become platforms for artificial intelligence deployment rather than application launchers. By embedding AI capabilities directly into the OS layer, Huawei positions HarmonyOS 6 as a foundation for what the company calls next-generation computing experiences.&lt;/p&gt;&lt;h3&gt;Ecosystem metrics show steady progress&lt;/h3&gt;&lt;p&gt;The platform has eight million registered developers and hosts more than 30,000 applications and “atomic services” – lightweight programmes that run without installation. HarmonyOS 5 operates on more than 40 device models, indicating steady hardware adoption.&lt;/p&gt;&lt;p&gt;Yu acknowledged the competitive landscape, stating that HarmonyOS still lags behind Apple’s iOS and Google’s Android in terms of global reach and application support.&lt;/p&gt;&lt;p&gt;“But the top 5,000 apps accounted for 99.9 per cent of consumer time spent” on Huawei devices, he said, suggesting the company prioritises essential applications over total app quantity.&lt;/p&gt;&lt;p&gt;The pragmatic approach reflects Huawei’s understanding that ecosystem success depends on quality and user engagement rather than purely numerical metrics. The focus on core applications that drive user behaviour indicates a mature strategy to compete with established platforms.&lt;/p&gt;&lt;h3&gt;Pangu AI models target industrial applications&lt;/h3&gt;&lt;p&gt;Huawei has also introduced Pangu 5.5, the latest in the family of AI models designed for enterprise and industrial uses. The natural language processing model contains 718 billion parameters, while the computer vision model features 15 billion parameters – specifications that position these models competitively in the current AI landscape.&lt;/p&gt;&lt;p&gt;The company is targeting five specialised sectors: medicine, finance, governance, manufacturing, and automotive. The industrial focus suggests Huawei is using AI development to strengthen its enterprise relationships while consumer market access remains constrained by geopolitical factors.&lt;/p&gt;&lt;p&gt;The AI model’s integration with HarmonyOS 6 creates a vertically integrated stack where Huawei controls both the AI infrastructure and the operating system deployment, potentially offering advantages in optimisation and performance.&lt;/p&gt;&lt;h3&gt;Market trajectory and strategic implications&lt;/h3&gt;&lt;p&gt;According to consultancy Canalys, Huawei has shipped more than 103 million smartphones and 21 million tablets running HarmonyOS, with nearly half delivered in 2024. The acceleration indicates growing internal adoption and suggests the platform is gaining momentum in China’s domestic market.&lt;/p&gt;&lt;p&gt;The company has expanded HarmonyOS beyond mobile devices, launching two laptops with the operating system last month. The multi-device strategy aims to create a unified software experience similar to Apple’s ecosystem approach, though execution in diverse hardware categories presents significant technical challenges.&lt;/p&gt;&lt;p&gt;The HarmonyOS 6 development reflects Huawei’s broader transformation from a hardware-focused company to a software and services provider. The evolution, driven by US Entity List restrictions since 2019, has forced innovative approaches to technology development and market positioning.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei Supernode 384 disrupts Nvidia’s AI market hold&lt;/strong&gt;&lt;/p&gt;&lt;img alt="alt" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;The latest phase of the mobile OS wars isn’t being fought over app stores or user interfaces – it’s being waged with artificial intelligence. Huawei’s latest salvo comes in the form of HarmonyOS 6, in which AI agents aren’t features but the architecture driving user interactions.&lt;/p&gt;&lt;p&gt;The beta release to developers signals a broader industry shift where operating systems transform from passive platforms into what are being framed as intelligent intermediaries that anticipate, learn, and act on behalf of users.&lt;/p&gt;&lt;h3&gt;The AI-first approach defines the latest release&lt;/h3&gt;&lt;p&gt;The centrepiece of HarmonyOS 6 lies in its AI agents framework, which lets developers create automated programmes without the complexity of building or training foundation models from scratch.&lt;/p&gt;&lt;p&gt;The HarmonyOS Agent Framework attempts to make AI development more accessible in Huawei’s ecosystem.&lt;/p&gt;&lt;p&gt;Richard Yu Chengdong, chairman of Huawei’s consumer business group, has announced that more than 50 AI agents from established Chinese platforms including Weibo and Ximalaya will be available when HarmonyOS 6 launches to consumers.&lt;/p&gt;&lt;p&gt;However, Yu did not specify a public release date during a developer conference presentation held on Friday.&lt;/p&gt;&lt;p&gt;The AI agents integration develops an industry trend where operating systems become platforms for artificial intelligence deployment rather than application launchers. By embedding AI capabilities directly into the OS layer, Huawei positions HarmonyOS 6 as a foundation for what the company calls next-generation computing experiences.&lt;/p&gt;&lt;h3&gt;Ecosystem metrics show steady progress&lt;/h3&gt;&lt;p&gt;The platform has eight million registered developers and hosts more than 30,000 applications and “atomic services” – lightweight programmes that run without installation. HarmonyOS 5 operates on more than 40 device models, indicating steady hardware adoption.&lt;/p&gt;&lt;p&gt;Yu acknowledged the competitive landscape, stating that HarmonyOS still lags behind Apple’s iOS and Google’s Android in terms of global reach and application support.&lt;/p&gt;&lt;p&gt;“But the top 5,000 apps accounted for 99.9 per cent of consumer time spent” on Huawei devices, he said, suggesting the company prioritises essential applications over total app quantity.&lt;/p&gt;&lt;p&gt;The pragmatic approach reflects Huawei’s understanding that ecosystem success depends on quality and user engagement rather than purely numerical metrics. The focus on core applications that drive user behaviour indicates a mature strategy to compete with established platforms.&lt;/p&gt;&lt;h3&gt;Pangu AI models target industrial applications&lt;/h3&gt;&lt;p&gt;Huawei has also introduced Pangu 5.5, the latest in the family of AI models designed for enterprise and industrial uses. The natural language processing model contains 718 billion parameters, while the computer vision model features 15 billion parameters – specifications that position these models competitively in the current AI landscape.&lt;/p&gt;&lt;p&gt;The company is targeting five specialised sectors: medicine, finance, governance, manufacturing, and automotive. The industrial focus suggests Huawei is using AI development to strengthen its enterprise relationships while consumer market access remains constrained by geopolitical factors.&lt;/p&gt;&lt;p&gt;The AI model’s integration with HarmonyOS 6 creates a vertically integrated stack where Huawei controls both the AI infrastructure and the operating system deployment, potentially offering advantages in optimisation and performance.&lt;/p&gt;&lt;h3&gt;Market trajectory and strategic implications&lt;/h3&gt;&lt;p&gt;According to consultancy Canalys, Huawei has shipped more than 103 million smartphones and 21 million tablets running HarmonyOS, with nearly half delivered in 2024. The acceleration indicates growing internal adoption and suggests the platform is gaining momentum in China’s domestic market.&lt;/p&gt;&lt;p&gt;The company has expanded HarmonyOS beyond mobile devices, launching two laptops with the operating system last month. The multi-device strategy aims to create a unified software experience similar to Apple’s ecosystem approach, though execution in diverse hardware categories presents significant technical challenges.&lt;/p&gt;&lt;p&gt;The HarmonyOS 6 development reflects Huawei’s broader transformation from a hardware-focused company to a software and services provider. The evolution, driven by US Entity List restrictions since 2019, has forced innovative approaches to technology development and market positioning.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: Huawei Supernode 384 disrupts Nvidia’s AI market hold&lt;/strong&gt;&lt;/p&gt;&lt;img alt="alt" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/huawei-harmonyos-6-ai-agents-beta/</guid><pubDate>Tue, 24 Jun 2025 08:33:05 +0000</pubDate></item><item><title>Can we fix AI’s evaluation crisis? (Artificial intelligence – MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/24/1119187/fix-ai-evaluation-crisis/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/250623_algo_v2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As a tech reporter I often get asked questions like “Is DeepSeek actually better than ChatGPT?” or “Is the Anthropic model any good?” If I don’t feel like turning it into an hour-long seminar, I’ll usually give the diplomatic answer: “They’re both solid in different ways.”&lt;/p&gt;  &lt;p&gt;Most people asking aren’t defining “good” in any precise way, and that’s fair. It’s human to want to make sense of something new and seemingly powerful. &lt;strong&gt;But that simple question—Is this model good?—is really just the everyday version of a much more complicated technical problem.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So far, the way we’ve tried to answer that question is through benchmarks. These give models a fixed set of questions to answer and grade them on how many they get right. But just like exams like the SAT (an admissions test used by many US colleges), these benchmarks don’t always reflect deeper abilities. Lately it feels as if a new AI model drops every week, and every time a company launches one, it comes with fresh scores showing it beating the capabilities of predecessors. &lt;strong&gt;On paper, everything appears to be getting better all the time.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;In practice, it’s not so simple. &lt;/strong&gt;Just as grinding for the SAT might boost your score without improving your critical thinking, models can be trained to optimize for benchmark results without actually getting smarter, as Russell Brandon explained in his piece for us. As OpenAI and Tesla AI veteran Andrej Karpathy recently put it, we’re living through an evaluation crisis—our scoreboard for AI no longer reflects what we really want to measure.&lt;/p&gt;&lt;p&gt;Benchmarks have grown stale for a few key reasons. First, the industry has learned to “teach to the test,” training AI models to score well rather than genuinely improve. Second, widespread data contamination means models may have already seen the benchmark questions, or even the answers, somewhere in their training data. And finally, many benchmarks are simply maxed out. On popular tests like SuperGLUE, models have already reached or surpassed 90% accuracy, making further gains feel more like statistical noise than meaningful improvement. &lt;strong&gt;At that point, the scores stop telling us anything useful. &lt;/strong&gt;That’s especially true in high-skill domains like coding, reasoning, and complex STEM problem-solving.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;However, there are a growing number of teams around the world trying to address the AI evaluation crisis.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;One result is a new benchmark called LiveCodeBench Pro. It draws problems from international algorithmic olympiads—competitions for elite high school and university programmers where participants solve challenging problems without external tools. The top AI models currently manage only about 53% at first pass on medium-difficulty problems and 0% on the hardest ones. These are tasks where human experts routinely excel.&lt;/p&gt; 
 &lt;p&gt;Zihan Zheng, a junior at NYU and a world finalist in competitive coding, led the project to develop LiveCodeBench Pro with a team of olympiad medalists. They’ve published both the benchmark and a detailed study showing that top-tier models like GPT-4o mini and Google’s Gemini 2.5 perform at a level comparable to the top 10% of human competitors. Across the board, Zheng observed a pattern: AI excels at making plans and executing tasks, but it struggles with nuanced algorithmic reasoning. “It shows that AI is still far from matching the best human coders,” he says.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;LiveCodeBench Pro might define a new upper bar. But what about the floor?&lt;/strong&gt; Earlier this month, a group of researchers from multiple universities argued that LLM agents should be evaluated primarily on the basis of their riskiness, not just how well they perform. In real-world, application-driven environments—especially with AI agents—unreliability, hallucinations, and brittleness are ruinous. One wrong move could spell disaster when money or safety are on the line.&lt;/p&gt;&lt;p&gt;There are other new attempts to address the problem. Some benchmarks, like ARC-AGI, now keep part of their data set private to prevent AI models from being optimized excessively for the test, a problem called “overfitting.” Meta’s Yann LeCun has created LiveBench, a dynamic benchmark where questions evolve every six months. The goal is to evaluate models not just on knowledge but on adaptability.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Xbench, a Chinese benchmark project developed by HongShan Capital Group (formerly Sequoia China), is another one of these effort.&amp;nbsp;I just wrote about it in a story. &lt;/strong&gt;Xbench was initially built in 2022—right after ChatGPT’s launch—as an internal tool to evaluate models for investment research. Over time, the team expanded the system and brought in external collaborators. It just made parts of its question set publicly available last week.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Xbench is notable for its dual-track design, which tries to bridge the gap between lab-based tests and real-world utility. The first track evaluates technical reasoning skills by testing a model’s STEM knowledge and ability to carry out Chinese-language research. The second track aims to assess practical usefulness—how well a model performs on tasks in fields like recruitment and marketing. For instance, one task asks an agent to identify five qualified battery engineer candidates; another has it match brands with relevant influencers from a pool of more than 800 creators.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;The team behind Xbench has big ambitions. They plan to expand its testing capabilities into sectors like finance, law, and design, and they plan to update the test set quarterly to avoid stagnation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is something that I often wonder about, because a model’s hardcore reasoning ability doesn’t necessarily translate into a fun, informative, and creative experience. Most queries from average users are probably not going to be rocket science. There isn’t much research yet on how to effectively evaluate a model’s creativity, but I’d love to know which model would be the best for creative writing or art projects.&lt;/p&gt;  &lt;p&gt;Human preference testing has also emerged as an alternative to benchmarks. One increasingly popular platform is LMarena, which lets users submit questions and compare responses from different models side by side—and then pick which one they like best. Still, this method has its flaws. Users sometimes reward the answer that sounds more flattering or agreeable, even if it’s wrong. That can incentivize “sweet-talking” models and skew results in favor of pandering.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;AI researchers are beginning to realize—and admit—that the status quo of AI testing cannot continue.&lt;/strong&gt; At the recent CVPR conference, NYU professor Saining Xie drew on historian James Carse’s Finite and Infinite Games to critique the hypercompetitive culture of AI research. An infinite game, he noted, is open-ended—the goal is to keep playing. But in AI, a dominant player often drops a big result, triggering a wave of follow-up papers chasing the same narrow topic. This race-to-publish culture puts enormous pressure on researchers and rewards speed over depth, short-term wins over long-term insight. “If academia chooses to play a finite game,” he warned, “it will lose everything.”&lt;/p&gt;  &lt;p&gt;I found his framing powerful—and maybe it applies to benchmarks, too. So, do we have a truly comprehensive scoreboard for how good a model is? Not really. Many dimensions—social, emotional, interdisciplinary—still evade assessment. But the wave of new benchmarks hints at a shift. As the field evolves, a bit of skepticism is probably healthy.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in&amp;nbsp;&lt;/em&gt;The Algorithm&lt;em&gt;, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/250623_algo_v2.jpg?resize=1200,600" /&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="class"&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;As a tech reporter I often get asked questions like “Is DeepSeek actually better than ChatGPT?” or “Is the Anthropic model any good?” If I don’t feel like turning it into an hour-long seminar, I’ll usually give the diplomatic answer: “They’re both solid in different ways.”&lt;/p&gt;  &lt;p&gt;Most people asking aren’t defining “good” in any precise way, and that’s fair. It’s human to want to make sense of something new and seemingly powerful. &lt;strong&gt;But that simple question—Is this model good?—is really just the everyday version of a much more complicated technical problem.&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;So far, the way we’ve tried to answer that question is through benchmarks. These give models a fixed set of questions to answer and grade them on how many they get right. But just like exams like the SAT (an admissions test used by many US colleges), these benchmarks don’t always reflect deeper abilities. Lately it feels as if a new AI model drops every week, and every time a company launches one, it comes with fresh scores showing it beating the capabilities of predecessors. &lt;strong&gt;On paper, everything appears to be getting better all the time.&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;In practice, it’s not so simple. &lt;/strong&gt;Just as grinding for the SAT might boost your score without improving your critical thinking, models can be trained to optimize for benchmark results without actually getting smarter, as Russell Brandon explained in his piece for us. As OpenAI and Tesla AI veteran Andrej Karpathy recently put it, we’re living through an evaluation crisis—our scoreboard for AI no longer reflects what we really want to measure.&lt;/p&gt;&lt;p&gt;Benchmarks have grown stale for a few key reasons. First, the industry has learned to “teach to the test,” training AI models to score well rather than genuinely improve. Second, widespread data contamination means models may have already seen the benchmark questions, or even the answers, somewhere in their training data. And finally, many benchmarks are simply maxed out. On popular tests like SuperGLUE, models have already reached or surpassed 90% accuracy, making further gains feel more like statistical noise than meaningful improvement. &lt;strong&gt;At that point, the scores stop telling us anything useful. &lt;/strong&gt;That’s especially true in high-skill domains like coding, reasoning, and complex STEM problem-solving.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;&lt;strong&gt;However, there are a growing number of teams around the world trying to address the AI evaluation crisis.&amp;nbsp;&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;One result is a new benchmark called LiveCodeBench Pro. It draws problems from international algorithmic olympiads—competitions for elite high school and university programmers where participants solve challenging problems without external tools. The top AI models currently manage only about 53% at first pass on medium-difficulty problems and 0% on the hardest ones. These are tasks where human experts routinely excel.&lt;/p&gt; 
 &lt;p&gt;Zihan Zheng, a junior at NYU and a world finalist in competitive coding, led the project to develop LiveCodeBench Pro with a team of olympiad medalists. They’ve published both the benchmark and a detailed study showing that top-tier models like GPT-4o mini and Google’s Gemini 2.5 perform at a level comparable to the top 10% of human competitors. Across the board, Zheng observed a pattern: AI excels at making plans and executing tasks, but it struggles with nuanced algorithmic reasoning. “It shows that AI is still far from matching the best human coders,” he says.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;LiveCodeBench Pro might define a new upper bar. But what about the floor?&lt;/strong&gt; Earlier this month, a group of researchers from multiple universities argued that LLM agents should be evaluated primarily on the basis of their riskiness, not just how well they perform. In real-world, application-driven environments—especially with AI agents—unreliability, hallucinations, and brittleness are ruinous. One wrong move could spell disaster when money or safety are on the line.&lt;/p&gt;&lt;p&gt;There are other new attempts to address the problem. Some benchmarks, like ARC-AGI, now keep part of their data set private to prevent AI models from being optimized excessively for the test, a problem called “overfitting.” Meta’s Yann LeCun has created LiveBench, a dynamic benchmark where questions evolve every six months. The goal is to evaluate models not just on knowledge but on adaptability.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;Xbench, a Chinese benchmark project developed by HongShan Capital Group (formerly Sequoia China), is another one of these effort.&amp;nbsp;I just wrote about it in a story. &lt;/strong&gt;Xbench was initially built in 2022—right after ChatGPT’s launch—as an internal tool to evaluate models for investment research. Over time, the team expanded the system and brought in external collaborators. It just made parts of its question set publicly available last week.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Xbench is notable for its dual-track design, which tries to bridge the gap between lab-based tests and real-world utility. The first track evaluates technical reasoning skills by testing a model’s STEM knowledge and ability to carry out Chinese-language research. The second track aims to assess practical usefulness—how well a model performs on tasks in fields like recruitment and marketing. For instance, one task asks an agent to identify five qualified battery engineer candidates; another has it match brands with relevant influencers from a pool of more than 800 creators.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;The team behind Xbench has big ambitions. They plan to expand its testing capabilities into sectors like finance, law, and design, and they plan to update the test set quarterly to avoid stagnation.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;This is something that I often wonder about, because a model’s hardcore reasoning ability doesn’t necessarily translate into a fun, informative, and creative experience. Most queries from average users are probably not going to be rocket science. There isn’t much research yet on how to effectively evaluate a model’s creativity, but I’d love to know which model would be the best for creative writing or art projects.&lt;/p&gt;  &lt;p&gt;Human preference testing has also emerged as an alternative to benchmarks. One increasingly popular platform is LMarena, which lets users submit questions and compare responses from different models side by side—and then pick which one they like best. Still, this method has its flaws. Users sometimes reward the answer that sounds more flattering or agreeable, even if it’s wrong. That can incentivize “sweet-talking” models and skew results in favor of pandering.&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;AI researchers are beginning to realize—and admit—that the status quo of AI testing cannot continue.&lt;/strong&gt; At the recent CVPR conference, NYU professor Saining Xie drew on historian James Carse’s Finite and Infinite Games to critique the hypercompetitive culture of AI research. An infinite game, he noted, is open-ended—the goal is to keep playing. But in AI, a dominant player often drops a big result, triggering a wave of follow-up papers chasing the same narrow topic. This race-to-publish culture puts enormous pressure on researchers and rewards speed over depth, short-term wins over long-term insight. “If academia chooses to play a finite game,” he warned, “it will lose everything.”&lt;/p&gt;  &lt;p&gt;I found his framing powerful—and maybe it applies to benchmarks, too. So, do we have a truly comprehensive scoreboard for how good a model is? Not really. Many dimensions—social, emotional, interdisciplinary—still evade assessment. But the wave of new benchmarks hints at a shift. As the field evolves, a bit of skepticism is probably healthy.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;This story originally appeared in&amp;nbsp;&lt;/em&gt;The Algorithm&lt;em&gt;, our weekly newsletter on AI. To get stories like this in your inbox first,&amp;nbsp;sign up here.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/24/1119187/fix-ai-evaluation-crisis/</guid><pubDate>Tue, 24 Jun 2025 08:50:30 +0000</pubDate></item><item><title>Namibia wants to build the world’s first hydrogen economy (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/24/1118433/namibia-world-first-hydrogen-economy-wind-solar-power/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On an afternoon in March in the middle of the world’s oldest desert, Johannes Michels looks out at an array of solar panels, the size of 40 football fields, that stretches toward a ridge of jagged peaks between the ochre-colored sand and a cloudless blue sky. Inside a building to Michels’s left sits a 12-megawatt electrolyzer—a machine resembling two giant AA batteries that is designed to split water into its two component parts, H₂ and O. Behind him is the desert factory’s key piece of proprietary tech: a rotating kiln in which the hydrogen gas from that water is mixed with iron ore to create a pure form of iron, the main ingredient in steel.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Factories have used fossil fuels to process iron ore for three centuries, and the climate has paid a heavy price: According to the International Energy Agency (IEA), the steel industry today accounts for 8% of carbon dioxide emissions. Purifying the ore involves extracting iron that is bound to oxygen, and “removing the bond between the iron and oxygen requires a massive amount of energy,” says Michels, the 39-year-old CEO of HyIron, the startup behind the project.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But it turns out there is a less carbon-­intensive alternative: using hydrogen to extract the iron. Unlike coal or natural gas, which release carbon dioxide as a by-product, this process, Michels explains, releases water. And if the hydrogen itself is “green”—meaning it’s made through renewable-­powered electrolysis rather than the conventional technique of mixing natural gas and steam—the climate impact of the entire process will be minimal.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;HyIron, which began processing test batches of iron a month after my visit, is one of a handful of companies around the world that are betting green hydrogen can help the $1.8 trillion steel industry clean up its act. What sets it apart, above all, is its location. HyIron’s kiln was designed and prototyped in Germany, but the production site is in Namibia, more than 5,000 miles to the south. This former German colony, which was ruled by South Africa from 1915 to 1990, has little industry itself and is an ocean or two away from the world’s biggest importers of iron. What it does have is immense untapped potential for wind and solar power, which studies suggest could make it possible to produce hydrogen and its derivative products, like iron, ammonia, and low-carbon aviation fuel, as cheaply as is feasible anywhere. HyIron’s site in the Namib Desert, 50 miles from the Atlantic coast, averages just 30 hours of overcast skies per year, Michels tells me. The energy potential here, he says, is “incredible.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Michels, who trained as an economist and started HyIron as a side project when his family-owned safari lodge went quiet during the covid pandemic, isn’t the only Namibian with big plans for hydrogen. Since 2021, when the government identified the gas as a potentially “transformative strategic industry,” it’s become something of a national obsession. There are at least nine other projects planned or under construction, including one, in Namibia’s south, that’s among the largest proposed green hydrogen investments in the world. The Namibian government’s Green Hydrogen and Derivatives Strategy, released in 2022, envisions the creation of three “hydrogen valleys,” along the southern, central, and northern coasts, with a target production of 10 million to 12 million metric tons per year by 2050. That’s equivalent to more than 10% of all hydrogen made annually today. As soon as 2030, the strategy document claims, the industry could create 80,000 jobs and raise GDP by 30% through a combination of tax revenue, royalties, and the knock-on effect of so many investments.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If even a fraction of this production comes to pass, it will give Namibia’s economy a major boost. But it is a gamble. Green hydrogen technology is still in its infancy, and long-term demand for its products remains uncertain. Pursuing a technology that isn’t yet commercially established, some critics fear, could strain government resources and distract from more urgent priorities, including the persistence of hunger and a domestic power grid that reaches only half of Namibia’s households. This is especially the case with the largest project under development, along the country’s southern coast, which will require at least $10 billion to get off the ground, a figure nearly as big as Namibia’s GDP today. That venture is contentious for environmental reasons, too: Under current plans, most of its infrastructure will be built inside a national park in a location Namibia’s top environmental watchdog calls the “most sensitive ecosystem in southern Africa.”&lt;/p&gt; 
 &lt;p&gt;“Given the small country that we are, we’re risking quite a lot entering into this global race,” says Ronny Dempers, executive director of the Namibia Development Trust, which advocates for community-based management of natural resources.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Adding to the uncertainty is the death last year of Namibian president Hage Geingob, the hydrogen strategy’s chief political backer. The new president, Netumbo Nandi-Ndaitwah, who took office in March, hails from the same political party, but multiple people familiar with her thinking told me she’s keener on developing oil and natural gas.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Nonetheless, HyIron’s launch has given Namibia’s hydrogen ambitions a long-awaited jolt of momentum.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The question now is whether Namibia’s government, its trading partners, and hydrogen innovators like Michels can work together to build the industry in a way that satisfies the world’s appetite for cleaner fuels—and also helps improve lives at home.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;The lightest element&lt;/h3&gt;  &lt;p&gt;The idea of powering the world with hydrogen is hardly new. In his 1874 novel &lt;em&gt;The Mysterious Island&lt;/em&gt;, Jules Verne wrote that water, “decomposed” into hydrogen and oxygen, could function as the “coal of the future.” Not only is hydrogen the most abundant element in the universe, but H&lt;sub&gt;2&lt;/sub&gt; gas, when burned, does not produce greenhouse gases and releases more energy per unit mass than any other nonradioactive fuel—roughly five times more than coal and three times more than gasoline or diesel. Unlike oxygen or nitrogen, pure hydrogen gas can’t readily be captured from the atmosphere—because it’s so light, it tends to escape into space. Instead, hydrogen must be sourced by splitting it off from other molecules.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Until now, the process has been anything but green: Most hydrogen made today, primarily for use in petroleum refining, fertilizers, and petrochemicals, is created through a process called steam methane reforming, in which high-temperature steam reacts with methane (CH&lt;sub&gt;4&lt;/sub&gt;), releasing large amounts of CO&lt;sub&gt;2&lt;/sub&gt; in the process. As a result, the IEA calls hydrogen today “more of a climate problem than a climate solution.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Making hydrogen via electrolysis, as Verne described, was first achieved around 1800. But the process needs a lot of energy, and it wasn’t until the late 2010s, with the costs of wind and solar power falling and governments taking concrete steps to help keep global warming to a minimum, that commercial interest in splitting water with renewables began to emerge. A road map published by the IEA in 2023, which outlines a path to reaching net-zero ­emissions by midcentury, calls for dramatically expanded use of this “green” hydrogen. A portion of it would replace conventional “gray” hydrogen for existing uses. But the bulk would be for new applications, like iron and steel production, power generation, or long-haul transport—some fueled by hydrogen itself and others by derivatives like ammonia (NH&lt;sub&gt;3&lt;/sub&gt;), which is made by fusing hydrogen with nitrogen.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Most rich countries have adopted policies that incentivize this shift. The European Union, for example, which has caps on fossil-fuel emissions in many sectors, mandates that 42% of hydrogen used by 2030 originate from renewable sources.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118682" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Oshivela-Launch-45.jpg?w=1053" /&gt;&lt;figcaption class="wp-element-caption"&gt;Netumbo Nandi-Ndaitwah, president of Namibia, speaks at a ceremonial opening for HyIron Oshivela in April.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118679" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Feb-2025-2.jpg?w=1500" width="1500" /&gt;&lt;figcaption class="wp-element-caption"&gt;Part of the facility’s 12-megawatt electrolyzer, which separates hydrogen from water&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118680" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Feb-2025-3.jpg?w=1500" width="1500" /&gt;&lt;figcaption class="wp-element-caption"&gt;After hydrogen gas is created in the electrolyzer, it is sent into liquid-gas separators, which remove residual water.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118681" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Oshivela-Launch-30.jpg?w=754" /&gt;&lt;figcaption class="wp-element-caption"&gt;Johannes Michels, CEO of HyIron&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;For many African countries, this represents an opportunity. According to the IEA, the continent is home to 60% of the world’s best potential sites for solar power, thanks to its levels of year-round sunshine and quantity of land suitable for solar farms. The Africa Green Hydrogen Alliance, a 10-country body formed in 2022, believes Africa can produce nearly a quarter of the hydrogen and hydrogen derivatives traded globally by 2050.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A handful of North African countries, including Egypt, Morocco, and Mauritania, have tentative plans to send hydrogen to Europe via pipelines—some new, and some retrofitted from existing pipelines built to carry natural gas. Namibia’s distance from Europe makes pipeline transport economically prohibitive. Shipping H&lt;sub&gt;2&lt;/sub&gt; gas, which takes up a lot of space even when stored in high-pressure tanks, wouldn’t be cost-competitive either. So Namibia’s plan is to use the hydrogen it makes to create iron, ammonia, and other products, which are dense enough to be transported by sea.&lt;/p&gt;  &lt;p&gt;The country’s biggest advantage is its especially strong wind and solar potential. Marco Raffinetti, CEO of Hyphen Hydrogen Energy, the firm developing the large-scale project in the south, believes that the company’s site there is one of the top three spots for hydrogen production in the world. The key, he says, is strong winds that peak at times when solar output is low, which minimizes power fluctuations and thus reduces costs. Namibia has other selling points as well, including vast tracts of sparsely populated land, a stable political climate, and a government open to new economic opportunities. The country’s GDP per capita, $4,168, ranks among the top 10 in Africa.&lt;/p&gt;  &lt;p&gt;But Namibia is also the world’s second most economically unequal society, in large part because of more than 40 years of rule under South African apartheid that included forced relocation. De facto segregation is still visible. Upmarket neighborhoods of the capital, Windhoek, home to a large share of the country’s white minority, resemble parts of suburban Los Angeles, with modernist houses on quiet tree-lined streets stretching into the surrounding hills. But much of the city’s population resides in an apartheid-era settlement known as Katutura, or “the place where we do not want to live.” Many of the homes here are corrugated-iron shacks without electricity or running water.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;Namibia’s poverty is also a consequence of more recent economic stagnation. According to the World Bank, GDP per capita fell by 30% between 2012 and 2023. Uranium, one of the country’s largest exports, faced a decade-long slump as several countries reevaluated their use of nuclear power following the 2011 meltdown in Fukushima, Japan. Namibia’s fishing sector was hit with a major corruption scandal in 2019 that left two high-ranking officials in prison. Then came covid, which stifled tourism, and the country’s worst drought in a century, which left nearly half the population in need of aid; according to government figures, more than 1,100 people died of malnutrition between 2020 and 2024. Jobs are now scarcer than ever. As of 2023, according to the Namibia Statistics Agency, fewer than one in three people of working age were employed.&lt;/p&gt;    &lt;p&gt;It is in this context that Geingob, the late president, turned to hydrogen. A veteran of the independence struggle, Geingob had been elected in 2014 by promising to deliver prosperity. Instead, according to Robin Sherbourne, an economist who’s studied Namibia since the 1990s, growth continued to stagnate and support for his party began to wane.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Green hydrogen was starting to take off, and Namibia had all the basic ingredients,” Sherbourne tells me. “So [Geingob] jumped at it. It gave him something to wave in front of the electorate and say, ‘Look, things are happening.’”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“It gave him something to wave in front of the electorate and say, ‘Look, things are happening.’”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Robin Sherbourne, economist&lt;/cite&gt;&lt;/blockquote&gt;  &lt;h3 class="wp-block-heading"&gt;Electrolyzers in the desert&lt;/h3&gt;  &lt;p&gt;Two and a half years after the release of the government’s Green Hydrogen Strategy, the industry is gradually coming to life. HyIron’s current setup, which cost €30 million (currently $34 million) and was financed in part by a grant from the German government, is capable of producing 15,000 metric tons of iron per year, roughly enough for 10,000 midsize cars or one large high-rise ­building. Michels hopes to scale that to 2 million metric tons by 2030, at an estimated cost of $2.7 billion.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;Another project, developed by the Belgian shipping company CMB.Tech and the Namibian firm Ohlthaver &amp;amp; List, is working to produce trial amounts of hydrogen. In a second phase, it will trial generation of ammonia, which is primarily used today in fertilizers but could eventually be a key fuel for ocean-faring vessels. Ultimately the idea is to spend $3 billion on commercial-­scale ammonia production, aiming for 250,000 metric tons per year by the end of the decade, as well as a terminal at the port of Walvis Bay, where vessels rounding the southern tip of Africa will be able to bunker with the fuel.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="aerial view of a solar array and facility" class="wp-image-1118676" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/Cleanergy_overview.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Near the port city of Walvis Bay, the Belgian shipping company CMB.Tech, in partnership with the Namibian firm Ohlthaver &amp;amp; List, has built a solar-powered plant to create hydrogen that can be dispensed as fuel. In the future, the venture will use hydrogen to produce ammonia, some of which will fuel CMB.Tech’s own oceanfaring vessels. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF CMB.TECH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The Hyphen project, by contrast, exists for now mainly on paper. Although the company signed a concession agreement with Namibia’s government in 2023, it hasn’t yet secured the financing it needs to move ahead with construction. But if the project does come to life, it will be one of the world’s largest: Plans call for the installation of seven gigawatts of renewable power, more than 10 times Namibia’s current generation capacity, to produce 2 million metric tons of ammonia annually by 2030. According to Raffinetti, Hyphen plans to “overbuild” the accompanying infrastructure so it could also be used in future projects in the planned southern hydrogen valley. Meeting Namibia’s 2050 targets under the Green Hydrogen Strategy would require the equivalent&amp;nbsp;of 30 Hyphen-size projects spread across the three corridors of production.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;p&gt;This planned footprint has already been the source of controversy. Hyphen’s concession—the land it has been granted access to—encompasses 18% of Tsau Khaeb National Park, a protected area about the size of Massachusetts that’s home to flamingos, African penguins, and 31 species of plants found nowhere else on Earth, many of them water-storing succulents that blanket the desert in majestic pastel-colored flowers when it rains.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1118675" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/Cleanergy_HydrogenAcademy.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;The CMB.Tech project’s Hydrogen Academy has begun holding training sessions on hydrogen and how to handle it.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF CMB.TECH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Chris Brown, who leads the Namibia Chamber of Environment, a coalition of environmental NGOs, says the project would irreparably damage the “integrity and resilience” of the park. Raffinetti says Hyphen’s equipment will take up a small fraction of its concession and will be built in a “surgical way” to avoid the most ecologically sensitive areas.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;But environmentalists are not the only ones who’ve criticized the choice of location. An expanded port, built to facilitate ammonia exports, will sit immediately adjacent to a site that housed a labor and extermination camp during Namibia’s 1904–1908 genocide, in which tens of thousands of Nama and Herero people were killed by German soldiers during a period of resistance to colonial rule. A 2024 report commissioned by Nama and Herero leaders argues that the extension of port infrastructure would “desecrate” the heritage of the area and those who died there. It doesn’t help the optics that Hyphen’s majority shareholder, the renewable power producer Enertrag, is a German company.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Beyond these sensitivities, Namibia’s broader hydrogen aspirations remain subject to many questions. While the country’s desert climate is ideal for generating power, the other key input for green hydrogen—water—is scarce. The central coastal region, where the HyIron and CMB.Tech projects (as well as several others in early-stage development) are based, already sources much of its water from a local seawater desalination plant that’s powered only in part by renewables. Other facilities are planned here and in the south, but some worry that hydrogen projects could face water-related bottlenecks.&lt;/p&gt; 
 &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“If you want your green hydrogen projects to be implemented here, we want our household problems to be solved.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;William Minnie, youth spokesperson, the Landless People’s Movement&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;Namibia’s prospects also hinge on a global market for green fuels that’s highly precarious. Over the past few years, the hydrogen sector has gone from a period of “hype” to one of “disillusionment,” according to Martin Tengler, head of hydrogen research at BloombergNEF, which studies markets for new energy technologies. Absent incentives, Tengler is skeptical that green hydrogen will ever reach cost parity with gray hydrogen in most parts of the world. Certain industries, though, could embrace it even if it costs more. He notes that some higher-end automakers have already shown a willingness to pay a premium for green steel, even if it means a car’s price goes up by 2 or 3%. (Benteler, a German metals processing firm that supplies the automotive market, has committed to purchasing test quantities of green iron from HyIron.)&lt;/p&gt;  &lt;p&gt;Uncertainties also surround the future of ammonia. According to the IEA road map, ammonia made from green hydrogen could power 44% of global shipping by midcentury. But it, too, is likely to remain expensive relative to both conventional fuels and carbon-based alternatives like methanol and liquefied natural gas.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Some in Namibia are especially worried about Hyphen, which has not yet signed any binding agreements with customers. In a bid to boost Hyphen’s attractiveness to other financiers, the government assumed a 24% ownership stake in the venture. The money it’s put in so far, roughly €24 million ($27&amp;nbsp;million), is covered by a Dutch government grant. But Namibia’s portion of construction would likely be financed through loans, exposing taxpayers to the project’s risks. Detlof von Oertzen, an energy consultant who’s been exploring Namibia’s hydrogen potential since independence, believes this is reckless, especially given the country’s pressing needs in food, health care, and education. “We have a massive budget deficit,” he tells me. “We should not be binding resources to projects that might not end up leading anywhere.”&lt;/p&gt;  &lt;p&gt;Like many Namibians I spoke to, von Oertzen thinks the government’s targets for hydrogen production, and jobs associated with it, are wildly unrealistic. At the same time, he and other critics believe there are ways in which the industry can contribute to national development. Despite his misgivings about the government’s support of Hyphen, he believes a desalination plant that the company plans to build could play an important role in combating local water shortages in Namibia’s sparsely populated south and, in turn, help draw more industry and people.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;Raffinetti tells me that his company is also exploring the possibility of transmitting excess electricity from peak periods to the grid for local use. That may not put a major dent in the country’s electrification deficit, since the majority of Namibians who lack grid power live in the distant rural north. Still, some would like to see the government make more explicit demands from foreign investors to address local gaps. William Minnie, youth spokesperson for the Landless People’s Movement, an opposition party, believes it comes down to better negotiation. “If you want your green hydrogen projects to be implemented here,” he says, “we want our household problems to be solved.”&lt;/p&gt;  &lt;p&gt;Some see Nandi-Ndaitwah’s arrival in office as a chance to forge a more pragmatic way forward. One goal outlined by her party during last year’s election campaign is “to increase rural electrification and ensure availability of affordable electricity.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118678" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Feb-2025-dji-8.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;Banks of solar panels at the HyIron Oshivela facility in the Namib Desert&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;At a ceremonial launch of HyIron’s plant in April, Nandi-Ndaitwah praised the project for opening a “new chapter in Namibia’s industrial history.” At the same time, she’s also pledged to move toward the extraction of oil and gas. Since 2022, firms exploring in the deep waters off Namibia’s coast have announced significant discoveries of those resources. The reserves might be too expensive to develop, and they don’t exactly position the country as a steward of the energy transition. Some observers, though, believe embracing fossil fuels could be a way to hedge against the uncertainty surrounding green hydrogen while lowering the costs of developing both. “If you take a combined approach, there’s a lot of infrastructure that can be shared between the two industries,” says Ekkehard Friedrich, a Windhoek-based investment advisor.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For all the questions about hydrogen that linger, there’s also a strong sense of anticipation. After my tour of HyIron, I drove for an hour, much of it along a desolate gravel road, to explore the nearest town. A faded desert settlement, Arandis was originally built to house employees of Rössing, an open-pit uranium mine that was once the largest in the world. There I met Joel Ochurub, 20, the son of a mine worker who’s studying to be a machinist. Jobs in Namibia, he told me, are “very scarce”; hydrogen might not create opportunities for everyone, he said, but the more industry Namibia can lure, the better. “When you see posts about green hydrogen on Instagram, there are so many likes,” he said. “People are excited.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jonathan W. Rosen is a journalist who writes about Africa.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;On an afternoon in March in the middle of the world’s oldest desert, Johannes Michels looks out at an array of solar panels, the size of 40 football fields, that stretches toward a ridge of jagged peaks between the ochre-colored sand and a cloudless blue sky. Inside a building to Michels’s left sits a 12-megawatt electrolyzer—a machine resembling two giant AA batteries that is designed to split water into its two component parts, H₂ and O. Behind him is the desert factory’s key piece of proprietary tech: a rotating kiln in which the hydrogen gas from that water is mixed with iron ore to create a pure form of iron, the main ingredient in steel.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Factories have used fossil fuels to process iron ore for three centuries, and the climate has paid a heavy price: According to the International Energy Agency (IEA), the steel industry today accounts for 8% of carbon dioxide emissions. Purifying the ore involves extracting iron that is bound to oxygen, and “removing the bond between the iron and oxygen requires a massive amount of energy,” says Michels, the 39-year-old CEO of HyIron, the startup behind the project.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;But it turns out there is a less carbon-­intensive alternative: using hydrogen to extract the iron. Unlike coal or natural gas, which release carbon dioxide as a by-product, this process, Michels explains, releases water. And if the hydrogen itself is “green”—meaning it’s made through renewable-­powered electrolysis rather than the conventional technique of mixing natural gas and steam—the climate impact of the entire process will be minimal.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;HyIron, which began processing test batches of iron a month after my visit, is one of a handful of companies around the world that are betting green hydrogen can help the $1.8 trillion steel industry clean up its act. What sets it apart, above all, is its location. HyIron’s kiln was designed and prototyped in Germany, but the production site is in Namibia, more than 5,000 miles to the south. This former German colony, which was ruled by South Africa from 1915 to 1990, has little industry itself and is an ocean or two away from the world’s biggest importers of iron. What it does have is immense untapped potential for wind and solar power, which studies suggest could make it possible to produce hydrogen and its derivative products, like iron, ammonia, and low-carbon aviation fuel, as cheaply as is feasible anywhere. HyIron’s site in the Namib Desert, 50 miles from the Atlantic coast, averages just 30 hours of overcast skies per year, Michels tells me. The energy potential here, he says, is “incredible.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;Michels, who trained as an economist and started HyIron as a side project when his family-owned safari lodge went quiet during the covid pandemic, isn’t the only Namibian with big plans for hydrogen. Since 2021, when the government identified the gas as a potentially “transformative strategic industry,” it’s become something of a national obsession. There are at least nine other projects planned or under construction, including one, in Namibia’s south, that’s among the largest proposed green hydrogen investments in the world. The Namibian government’s Green Hydrogen and Derivatives Strategy, released in 2022, envisions the creation of three “hydrogen valleys,” along the southern, central, and northern coasts, with a target production of 10 million to 12 million metric tons per year by 2050. That’s equivalent to more than 10% of all hydrogen made annually today. As soon as 2030, the strategy document claims, the industry could create 80,000 jobs and raise GDP by 30% through a combination of tax revenue, royalties, and the knock-on effect of so many investments.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;If even a fraction of this production comes to pass, it will give Namibia’s economy a major boost. But it is a gamble. Green hydrogen technology is still in its infancy, and long-term demand for its products remains uncertain. Pursuing a technology that isn’t yet commercially established, some critics fear, could strain government resources and distract from more urgent priorities, including the persistence of hunger and a domestic power grid that reaches only half of Namibia’s households. This is especially the case with the largest project under development, along the country’s southern coast, which will require at least $10 billion to get off the ground, a figure nearly as big as Namibia’s GDP today. That venture is contentious for environmental reasons, too: Under current plans, most of its infrastructure will be built inside a national park in a location Namibia’s top environmental watchdog calls the “most sensitive ecosystem in southern Africa.”&lt;/p&gt; 
 &lt;p&gt;“Given the small country that we are, we’re risking quite a lot entering into this global race,” says Ronny Dempers, executive director of the Namibia Development Trust, which advocates for community-based management of natural resources.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Adding to the uncertainty is the death last year of Namibian president Hage Geingob, the hydrogen strategy’s chief political backer. The new president, Netumbo Nandi-Ndaitwah, who took office in March, hails from the same political party, but multiple people familiar with her thinking told me she’s keener on developing oil and natural gas.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Nonetheless, HyIron’s launch has given Namibia’s hydrogen ambitions a long-awaited jolt of momentum.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;The question now is whether Namibia’s government, its trading partners, and hydrogen innovators like Michels can work together to build the industry in a way that satisfies the world’s appetite for cleaner fuels—and also helps improve lives at home.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;h3 class="wp-block-heading"&gt;The lightest element&lt;/h3&gt;  &lt;p&gt;The idea of powering the world with hydrogen is hardly new. In his 1874 novel &lt;em&gt;The Mysterious Island&lt;/em&gt;, Jules Verne wrote that water, “decomposed” into hydrogen and oxygen, could function as the “coal of the future.” Not only is hydrogen the most abundant element in the universe, but H&lt;sub&gt;2&lt;/sub&gt; gas, when burned, does not produce greenhouse gases and releases more energy per unit mass than any other nonradioactive fuel—roughly five times more than coal and three times more than gasoline or diesel. Unlike oxygen or nitrogen, pure hydrogen gas can’t readily be captured from the atmosphere—because it’s so light, it tends to escape into space. Instead, hydrogen must be sourced by splitting it off from other molecules.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Until now, the process has been anything but green: Most hydrogen made today, primarily for use in petroleum refining, fertilizers, and petrochemicals, is created through a process called steam methane reforming, in which high-temperature steam reacts with methane (CH&lt;sub&gt;4&lt;/sub&gt;), releasing large amounts of CO&lt;sub&gt;2&lt;/sub&gt; in the process. As a result, the IEA calls hydrogen today “more of a climate problem than a climate solution.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt; &lt;p&gt;Making hydrogen via electrolysis, as Verne described, was first achieved around 1800. But the process needs a lot of energy, and it wasn’t until the late 2010s, with the costs of wind and solar power falling and governments taking concrete steps to help keep global warming to a minimum, that commercial interest in splitting water with renewables began to emerge. A road map published by the IEA in 2023, which outlines a path to reaching net-zero ­emissions by midcentury, calls for dramatically expanded use of this “green” hydrogen. A portion of it would replace conventional “gray” hydrogen for existing uses. But the bulk would be for new applications, like iron and steel production, power generation, or long-haul transport—some fueled by hydrogen itself and others by derivatives like ammonia (NH&lt;sub&gt;3&lt;/sub&gt;), which is made by fusing hydrogen with nitrogen.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Most rich countries have adopted policies that incentivize this shift. The European Union, for example, which has caps on fossil-fuel emissions in many sectors, mandates that 42% of hydrogen used by 2030 originate from renewable sources.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118682" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Oshivela-Launch-45.jpg?w=1053" /&gt;&lt;figcaption class="wp-element-caption"&gt;Netumbo Nandi-Ndaitwah, president of Namibia, speaks at a ceremonial opening for HyIron Oshivela in April.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118679" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Feb-2025-2.jpg?w=1500" width="1500" /&gt;&lt;figcaption class="wp-element-caption"&gt;Part of the facility’s 12-megawatt electrolyzer, which separates hydrogen from water&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118680" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Feb-2025-3.jpg?w=1500" width="1500" /&gt;&lt;figcaption class="wp-element-caption"&gt;After hydrogen gas is created in the electrolyzer, it is sent into liquid-gas separators, which remove residual water.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118681" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Oshivela-Launch-30.jpg?w=754" /&gt;&lt;figcaption class="wp-element-caption"&gt;Johannes Michels, CEO of HyIron&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_13"&gt; &lt;p&gt;For many African countries, this represents an opportunity. According to the IEA, the continent is home to 60% of the world’s best potential sites for solar power, thanks to its levels of year-round sunshine and quantity of land suitable for solar farms. The Africa Green Hydrogen Alliance, a 10-country body formed in 2022, believes Africa can produce nearly a quarter of the hydrogen and hydrogen derivatives traded globally by 2050.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;A handful of North African countries, including Egypt, Morocco, and Mauritania, have tentative plans to send hydrogen to Europe via pipelines—some new, and some retrofitted from existing pipelines built to carry natural gas. Namibia’s distance from Europe makes pipeline transport economically prohibitive. Shipping H&lt;sub&gt;2&lt;/sub&gt; gas, which takes up a lot of space even when stored in high-pressure tanks, wouldn’t be cost-competitive either. So Namibia’s plan is to use the hydrogen it makes to create iron, ammonia, and other products, which are dense enough to be transported by sea.&lt;/p&gt;  &lt;p&gt;The country’s biggest advantage is its especially strong wind and solar potential. Marco Raffinetti, CEO of Hyphen Hydrogen Energy, the firm developing the large-scale project in the south, believes that the company’s site there is one of the top three spots for hydrogen production in the world. The key, he says, is strong winds that peak at times when solar output is low, which minimizes power fluctuations and thus reduces costs. Namibia has other selling points as well, including vast tracts of sparsely populated land, a stable political climate, and a government open to new economic opportunities. The country’s GDP per capita, $4,168, ranks among the top 10 in Africa.&lt;/p&gt;  &lt;p&gt;But Namibia is also the world’s second most economically unequal society, in large part because of more than 40 years of rule under South African apartheid that included forced relocation. De facto segregation is still visible. Upmarket neighborhoods of the capital, Windhoek, home to a large share of the country’s white minority, resemble parts of suburban Los Angeles, with modernist houses on quiet tree-lined streets stretching into the surrounding hills. But much of the city’s population resides in an apartheid-era settlement known as Katutura, or “the place where we do not want to live.” Many of the homes here are corrugated-iron shacks without electricity or running water.&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_15"&gt; &lt;p&gt;Namibia’s poverty is also a consequence of more recent economic stagnation. According to the World Bank, GDP per capita fell by 30% between 2012 and 2023. Uranium, one of the country’s largest exports, faced a decade-long slump as several countries reevaluated their use of nuclear power following the 2011 meltdown in Fukushima, Japan. Namibia’s fishing sector was hit with a major corruption scandal in 2019 that left two high-ranking officials in prison. Then came covid, which stifled tourism, and the country’s worst drought in a century, which left nearly half the population in need of aid; according to government figures, more than 1,100 people died of malnutrition between 2020 and 2024. Jobs are now scarcer than ever. As of 2023, according to the Namibia Statistics Agency, fewer than one in three people of working age were employed.&lt;/p&gt;    &lt;p&gt;It is in this context that Geingob, the late president, turned to hydrogen. A veteran of the independence struggle, Geingob had been elected in 2014 by promising to deliver prosperity. Instead, according to Robin Sherbourne, an economist who’s studied Namibia since the 1990s, growth continued to stagnate and support for his party began to wane.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;“Green hydrogen was starting to take off, and Namibia had all the basic ingredients,” Sherbourne tells me. “So [Geingob] jumped at it. It gave him something to wave in front of the electorate and say, ‘Look, things are happening.’”&lt;/p&gt;  &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“It gave him something to wave in front of the electorate and say, ‘Look, things are happening.’”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;Robin Sherbourne, economist&lt;/cite&gt;&lt;/blockquote&gt;  &lt;h3 class="wp-block-heading"&gt;Electrolyzers in the desert&lt;/h3&gt;  &lt;p&gt;Two and a half years after the release of the government’s Green Hydrogen Strategy, the industry is gradually coming to life. HyIron’s current setup, which cost €30 million (currently $34 million) and was financed in part by a grant from the German government, is capable of producing 15,000 metric tons of iron per year, roughly enough for 10,000 midsize cars or one large high-rise ­building. Michels hopes to scale that to 2 million metric tons by 2030, at an estimated cost of $2.7 billion.&amp;nbsp;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_17"&gt; &lt;p&gt;Another project, developed by the Belgian shipping company CMB.Tech and the Namibian firm Ohlthaver &amp;amp; List, is working to produce trial amounts of hydrogen. In a second phase, it will trial generation of ammonia, which is primarily used today in fertilizers but could eventually be a key fuel for ocean-faring vessels. Ultimately the idea is to spend $3 billion on commercial-­scale ammonia production, aiming for 250,000 metric tons per year by the end of the decade, as well as a terminal at the port of Walvis Bay, where vessels rounding the southern tip of Africa will be able to bunker with the fuel.&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="aerial view of a solar array and facility" class="wp-image-1118676" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/Cleanergy_overview.jpg?w=3000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Near the port city of Walvis Bay, the Belgian shipping company CMB.Tech, in partnership with the Namibian firm Ohlthaver &amp;amp; List, has built a solar-powered plant to create hydrogen that can be dispensed as fuel. In the future, the venture will use hydrogen to produce ammonia, some of which will fuel CMB.Tech’s own oceanfaring vessels. &lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF CMB.TECH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;The Hyphen project, by contrast, exists for now mainly on paper. Although the company signed a concession agreement with Namibia’s government in 2023, it hasn’t yet secured the financing it needs to move ahead with construction. But if the project does come to life, it will be one of the world’s largest: Plans call for the installation of seven gigawatts of renewable power, more than 10 times Namibia’s current generation capacity, to produce 2 million metric tons of ammonia annually by 2030. According to Raffinetti, Hyphen plans to “overbuild” the accompanying infrastructure so it could also be used in future projects in the planned southern hydrogen valley. Meeting Namibia’s 2050 targets under the Green Hydrogen Strategy would require the equivalent&amp;nbsp;of 30 Hyphen-size projects spread across the three corridors of production.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_19"&gt; &lt;p&gt;This planned footprint has already been the source of controversy. Hyphen’s concession—the land it has been granted access to—encompasses 18% of Tsau Khaeb National Park, a protected area about the size of Massachusetts that’s home to flamingos, African penguins, and 31 species of plants found nowhere else on Earth, many of them water-storing succulents that blanket the desert in majestic pastel-colored flowers when it rains.&amp;nbsp;&lt;/p&gt; &lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image alignright size-large"&gt;&lt;img alt="alt" class="wp-image-1118675" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/Cleanergy_HydrogenAcademy.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;The CMB.Tech project’s Hydrogen Academy has begun holding training sessions on hydrogen and how to handle it.&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF CMB.TECH&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Chris Brown, who leads the Namibia Chamber of Environment, a coalition of environmental NGOs, says the project would irreparably damage the “integrity and resilience” of the park. Raffinetti says Hyphen’s equipment will take up a small fraction of its concession and will be built in a “surgical way” to avoid the most ecologically sensitive areas.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_21"&gt; &lt;p&gt;But environmentalists are not the only ones who’ve criticized the choice of location. An expanded port, built to facilitate ammonia exports, will sit immediately adjacent to a site that housed a labor and extermination camp during Namibia’s 1904–1908 genocide, in which tens of thousands of Nama and Herero people were killed by German soldiers during a period of resistance to colonial rule. A 2024 report commissioned by Nama and Herero leaders argues that the extension of port infrastructure would “desecrate” the heritage of the area and those who died there. It doesn’t help the optics that Hyphen’s majority shareholder, the renewable power producer Enertrag, is a German company.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;Beyond these sensitivities, Namibia’s broader hydrogen aspirations remain subject to many questions. While the country’s desert climate is ideal for generating power, the other key input for green hydrogen—water—is scarce. The central coastal region, where the HyIron and CMB.Tech projects (as well as several others in early-stage development) are based, already sources much of its water from a local seawater desalination plant that’s powered only in part by renewables. Other facilities are planned here and in the south, but some worry that hydrogen projects could face water-related bottlenecks.&lt;/p&gt; 
 &lt;blockquote class="wp-block-quote is-layout-flow wp-block-quote-is-layout-flow"&gt; &lt;p&gt;&lt;strong&gt;“If you want your green hydrogen projects to be implemented here, we want our household problems to be solved.”&lt;/strong&gt;&lt;/p&gt; &lt;cite&gt;William Minnie, youth spokesperson, the Landless People’s Movement&lt;/cite&gt;&lt;/blockquote&gt;  &lt;p&gt;Namibia’s prospects also hinge on a global market for green fuels that’s highly precarious. Over the past few years, the hydrogen sector has gone from a period of “hype” to one of “disillusionment,” according to Martin Tengler, head of hydrogen research at BloombergNEF, which studies markets for new energy technologies. Absent incentives, Tengler is skeptical that green hydrogen will ever reach cost parity with gray hydrogen in most parts of the world. Certain industries, though, could embrace it even if it costs more. He notes that some higher-end automakers have already shown a willingness to pay a premium for green steel, even if it means a car’s price goes up by 2 or 3%. (Benteler, a German metals processing firm that supplies the automotive market, has committed to purchasing test quantities of green iron from HyIron.)&lt;/p&gt;  &lt;p&gt;Uncertainties also surround the future of ammonia. According to the IEA road map, ammonia made from green hydrogen could power 44% of global shipping by midcentury. But it, too, is likely to remain expensive relative to both conventional fuels and carbon-based alternatives like methanol and liquefied natural gas.&amp;nbsp;&lt;/p&gt; 
 &lt;p&gt;Some in Namibia are especially worried about Hyphen, which has not yet signed any binding agreements with customers. In a bid to boost Hyphen’s attractiveness to other financiers, the government assumed a 24% ownership stake in the venture. The money it’s put in so far, roughly €24 million ($27&amp;nbsp;million), is covered by a Dutch government grant. But Namibia’s portion of construction would likely be financed through loans, exposing taxpayers to the project’s risks. Detlof von Oertzen, an energy consultant who’s been exploring Namibia’s hydrogen potential since independence, believes this is reckless, especially given the country’s pressing needs in food, health care, and education. “We have a massive budget deficit,” he tells me. “We should not be binding resources to projects that might not end up leading anywhere.”&lt;/p&gt;  &lt;p&gt;Like many Namibians I spoke to, von Oertzen thinks the government’s targets for hydrogen production, and jobs associated with it, are wildly unrealistic. At the same time, he and other critics believe there are ways in which the industry can contribute to national development. Despite his misgivings about the government’s support of Hyphen, he believes a desalination plant that the company plans to build could play an important role in combating local water shortages in Namibia’s sparsely populated south and, in turn, help draw more industry and people.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;aside class="related__wrap alignleft"&gt;&lt;/aside&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_23"&gt; &lt;p&gt;Raffinetti tells me that his company is also exploring the possibility of transmitting excess electricity from peak periods to the grid for local use. That may not put a major dent in the country’s electrification deficit, since the majority of Namibians who lack grid power live in the distant rural north. Still, some would like to see the government make more explicit demands from foreign investors to address local gaps. William Minnie, youth spokesperson for the Landless People’s Movement, an opposition party, believes it comes down to better negotiation. “If you want your green hydrogen projects to be implemented here,” he says, “we want our household problems to be solved.”&lt;/p&gt;  &lt;p&gt;Some see Nandi-Ndaitwah’s arrival in office as a chance to forge a more pragmatic way forward. One goal outlined by her party during last year’s election campaign is “to increase rural electrification and ensure availability of affordable electricity.”&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_26"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="&amp;quot;&amp;quot;" class="wp-image-1118678" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/HyIron-Feb-2025-dji-8.jpg?w=2667" width="2667" /&gt;&lt;figcaption class="wp-element-caption"&gt;Banks of solar panels at the HyIron Oshivela facility in the Namib Desert&lt;/figcaption&gt;&lt;div class="image-credit"&gt;COURTESY OF HYIRON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;At a ceremonial launch of HyIron’s plant in April, Nandi-Ndaitwah praised the project for opening a “new chapter in Namibia’s industrial history.” At the same time, she’s also pledged to move toward the extraction of oil and gas. Since 2022, firms exploring in the deep waters off Namibia’s coast have announced significant discoveries of those resources. The reserves might be too expensive to develop, and they don’t exactly position the country as a steward of the energy transition. Some observers, though, believe embracing fossil fuels could be a way to hedge against the uncertainty surrounding green hydrogen while lowering the costs of developing both. “If you take a combined approach, there’s a lot of infrastructure that can be shared between the two industries,” says Ekkehard Friedrich, a Windhoek-based investment advisor.&amp;nbsp;&lt;/p&gt;  &lt;p&gt;For all the questions about hydrogen that linger, there’s also a strong sense of anticipation. After my tour of HyIron, I drove for an hour, much of it along a desolate gravel road, to explore the nearest town. A faded desert settlement, Arandis was originally built to house employees of Rössing, an open-pit uranium mine that was once the largest in the world. There I met Joel Ochurub, 20, the son of a mine worker who’s studying to be a machinist. Jobs in Namibia, he told me, are “very scarce”; hydrogen might not create opportunities for everyone, he said, but the more industry Namibia can lure, the better. “When you see posts about green hydrogen on Instagram, there are so many likes,” he said. “People are excited.”&amp;nbsp;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;Jonathan W. Rosen is a journalist who writes about Africa.&lt;/em&gt;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/24/1118433/namibia-world-first-hydrogen-economy-wind-solar-power/</guid><pubDate>Tue, 24 Jun 2025 09:00:00 +0000</pubDate></item><item><title>NVIDIA and Partners Highlight Next-Generation Robotics, Automation and AI Technologies at Automatica (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/automatica-robotics-2025/</link><description>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;From the heart of Germany’s automotive sector to manufacturing hubs across France and Italy, Europe is embracing industrial AI and advanced AI-powered robotics to address labor shortages, boost productivity and fuel sustainable economic growth.&lt;/p&gt;
&lt;p&gt;Robotics companies are developing humanoid robots and collaborative systems that integrate AI into real-world manufacturing applications. Supported by a $200 billion investment initiative and coordinated efforts from the European Commission, Europe is positioning itself at the forefront of the next wave of industrial automation, powered by AI.&lt;/p&gt;
&lt;p&gt;This momentum is on full display at Automatica — Europe’s premier conference on advancements in robotics, machine vision and intelligent manufacturing — taking place this week in Munich, Germany.&lt;/p&gt;
&lt;p&gt;NVIDIA and its ecosystem of partners and customers are showcasing next-generation robots, automation and AI technologies designed to accelerate the continent’s leadership in smart manufacturing and logistics.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Technologies Boost Robotics Development&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Central to advancing robotics development is Europe’s first industrial AI cloud, announced at NVIDIA GTC Paris at VivaTech earlier this month. The Germany-based AI factory, featuring 10,000 NVIDIA GPUs, provides European manufacturers with secure, sovereign and centralized AI infrastructure for industrial workloads. It will support applications ranging from design and engineering to factory digital twins and robotics.&lt;/p&gt;
&lt;p&gt;To help accelerate humanoid development, NVIDIA released NVIDIA Isaac GR00T N1.5 — an open foundation model for humanoid robot reasoning and skills. This update enhances the model’s adaptability and ability to follow instructions, significantly improving its performance in material handling and manufacturing tasks.&lt;/p&gt;
&lt;p&gt;To help post-train GR00T N1.5, NVIDIA has also released the Isaac GR00T-Dreams blueprint — a reference workflow for generating vast amounts of synthetic trajectory data from a small number of human demonstrations — enabling robots to generalize across behaviors and adapt to new environments with minimal human demonstration data.&lt;/p&gt;
&lt;p&gt;In addition, early developer previews of NVIDIA Isaac Sim 5.0 and Isaac Lab 2.2 — open-source robot simulation and learning frameworks optimized for NVIDIA RTX PRO 6000 workstations — are now available on GitHub.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_82566"&gt;&lt;img alt="alt" class="size-large wp-image-82566" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/wandelbots-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82566"&gt;Image courtesy of Wandelbots.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Robotics Leaders Tap NVIDIA Simulation Technology to Develop and Deploy Humanoids and More&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Robotics developers and solutions providers across the globe are integrating NVIDIA’s three computers to train, simulate and deploy robots.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;NEURA Robotics&lt;/b&gt;, a German robotics company and pioneer for cognitive robots, unveiled the third generation of its humanoid, 4NE1, designed to assist humans in domestic and professional environments through advanced cognitive capabilities and humanlike interaction. 4NE1 is powered by GR00T N1 and was trained in Isaac Sim and Isaac Lab before real-world deployment.&lt;/p&gt;
&lt;p&gt;NEURA Robotics is also presenting Neuraverse, a digital twin and interconnected ecosystem for robot training, skills and applications, fully compatible with NVIDIA Omniverse technologies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Delta Electronics&lt;/b&gt;, a global leader in power management and smart green solutions, is debuting two next-generation collaborative robots: D-Bot Mar and D-Bot 2 in 1 — both trained using Omniverse and Isaac Sim technologies and libraries. These cobots are engineered to transform intralogistics and optimize production flows.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Wandelbots&lt;/b&gt;, the creator of the Wandelbots NOVA software platform for industrial robotics, is partnering with SoftServe, a global IT consulting and digital services provider, to scale simulation-first automating using NVIDIA Isaac Sim, enabling virtual validation and real-world deployment with maximum impact.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Cyngn&lt;/b&gt;, a pioneer in autonomous mobile robotics, is integrating its DriveMod technology into Isaac Sim to enable large-scale, high fidelity virtual testing of advanced autonomous operation. Purpose-built for industrial applications, DriveMod is already deployed on vehicles such as the Motrec MT-160 Tugger and BYD Forklift, delivering sophisticated automation to material handling operations.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Doosan Robotics&lt;/b&gt;, a company specializing in AI robotic solutions, will showcase its “sim to real” solution, using NVIDIA Isaac Sim and cuRobo. Doosan will be showcasing how to seamlessly transfer tasks from simulation to real robots across a wide range of applications — from manufacturing to service industries.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Franka Robotics&lt;/b&gt; has integrated Isaac GR00T N1.5 into a dual-arm Franka Research 3 (FR3) robot for robotic control. The integration of GR00T N1.5 allows the system to interpret visual input, understand task context and autonomously perform complex manipulation — without the need for task-specific programming or hardcoded logic.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_82569"&gt;&lt;img alt="alt" class="size-full wp-image-82569" height="1999" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/franka.jpg" width="1506" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82569"&gt;Image courtesy of Franka Robotics.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;b&gt;Hexagon&lt;/b&gt;, the global leader in measurement technologies, launched its new humanoid, dubbed AEON. With its unique locomotion system and multimodal sensor fusion, and powered by NVIDIA’s three-computer solution, AEON is engineered to perform a wide range of industrial applications, from manipulation and asset inspection to reality capture and operator support.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Intrinsic&lt;/b&gt;, a software and AI robotics company, is integrating Intrinsic Flowstate with&amp;nbsp; Omniverse and OpenUSD for advanced visualization and digital twins that can be used in many industrial use cases. The company is also using NVIDIA foundation models to enhance robot capabilities like grasp planning through AI and simulation technologies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;SCHUNK&lt;/b&gt;, a global leader in gripping systems and automation technology, is showcasing its innovative grasping kit powered by the NVIDIA Jetson AGX Orin module. The kit intelligently detects objects and calculates optimal grasping points. Schunk is also demonstrating seamless simulation-to-reality transfer using IGS Virtuous software — built on Omniverse technologies — to control a real robot through simulation in a pick-and-place scenario.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Universal Robots&lt;/b&gt; is showcasing UR15, its fastest cobot yet. Powered by the UR AI Accelerator — developed with NVIDIA and running on Jetson AGX Orin using CUDA-accelerated Isaac libraries — UR15 helps set a new standard for industrial automation.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Vention&lt;/b&gt;, a full-stack software and hardware automation company, launched its Machine Motion AI, built on CUDA-accelerated Isaac libraries and powered by Jetson. Vention is also expanding its lineup of robotic offerings by adding the FR3 robot from Franka Robotics to its ecosystem, enhancing its solutions for academic and research applications.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_82572"&gt;&lt;img alt="alt" class="size-large wp-image-82572" height="1012" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/vention-1680x1012.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82572"&gt;Image courtesy of Vention.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Learn more about the latest robotics advancements by joining &lt;/i&gt;&lt;i&gt;NVIDIA at Automatica&lt;/i&gt;&lt;i&gt;, running through Friday, June 27.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;From the heart of Germany’s automotive sector to manufacturing hubs across France and Italy, Europe is embracing industrial AI and advanced AI-powered robotics to address labor shortages, boost productivity and fuel sustainable economic growth.&lt;/p&gt;
&lt;p&gt;Robotics companies are developing humanoid robots and collaborative systems that integrate AI into real-world manufacturing applications. Supported by a $200 billion investment initiative and coordinated efforts from the European Commission, Europe is positioning itself at the forefront of the next wave of industrial automation, powered by AI.&lt;/p&gt;
&lt;p&gt;This momentum is on full display at Automatica — Europe’s premier conference on advancements in robotics, machine vision and intelligent manufacturing — taking place this week in Munich, Germany.&lt;/p&gt;
&lt;p&gt;NVIDIA and its ecosystem of partners and customers are showcasing next-generation robots, automation and AI technologies designed to accelerate the continent’s leadership in smart manufacturing and logistics.&lt;/p&gt;
&lt;h2&gt;&lt;b&gt;NVIDIA Technologies Boost Robotics Development&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Central to advancing robotics development is Europe’s first industrial AI cloud, announced at NVIDIA GTC Paris at VivaTech earlier this month. The Germany-based AI factory, featuring 10,000 NVIDIA GPUs, provides European manufacturers with secure, sovereign and centralized AI infrastructure for industrial workloads. It will support applications ranging from design and engineering to factory digital twins and robotics.&lt;/p&gt;
&lt;p&gt;To help accelerate humanoid development, NVIDIA released NVIDIA Isaac GR00T N1.5 — an open foundation model for humanoid robot reasoning and skills. This update enhances the model’s adaptability and ability to follow instructions, significantly improving its performance in material handling and manufacturing tasks.&lt;/p&gt;
&lt;p&gt;To help post-train GR00T N1.5, NVIDIA has also released the Isaac GR00T-Dreams blueprint — a reference workflow for generating vast amounts of synthetic trajectory data from a small number of human demonstrations — enabling robots to generalize across behaviors and adapt to new environments with minimal human demonstration data.&lt;/p&gt;
&lt;p&gt;In addition, early developer previews of NVIDIA Isaac Sim 5.0 and Isaac Lab 2.2 — open-source robot simulation and learning frameworks optimized for NVIDIA RTX PRO 6000 workstations — are now available on GitHub.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_82566"&gt;&lt;img alt="alt" class="size-large wp-image-82566" height="945" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/wandelbots-1680x945.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82566"&gt;Image courtesy of Wandelbots.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;h2&gt;&lt;b&gt;Robotics Leaders Tap NVIDIA Simulation Technology to Develop and Deploy Humanoids and More&amp;nbsp;&lt;/b&gt;&lt;/h2&gt;
&lt;p&gt;Robotics developers and solutions providers across the globe are integrating NVIDIA’s three computers to train, simulate and deploy robots.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;NEURA Robotics&lt;/b&gt;, a German robotics company and pioneer for cognitive robots, unveiled the third generation of its humanoid, 4NE1, designed to assist humans in domestic and professional environments through advanced cognitive capabilities and humanlike interaction. 4NE1 is powered by GR00T N1 and was trained in Isaac Sim and Isaac Lab before real-world deployment.&lt;/p&gt;
&lt;p&gt;NEURA Robotics is also presenting Neuraverse, a digital twin and interconnected ecosystem for robot training, skills and applications, fully compatible with NVIDIA Omniverse technologies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Delta Electronics&lt;/b&gt;, a global leader in power management and smart green solutions, is debuting two next-generation collaborative robots: D-Bot Mar and D-Bot 2 in 1 — both trained using Omniverse and Isaac Sim technologies and libraries. These cobots are engineered to transform intralogistics and optimize production flows.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Wandelbots&lt;/b&gt;, the creator of the Wandelbots NOVA software platform for industrial robotics, is partnering with SoftServe, a global IT consulting and digital services provider, to scale simulation-first automating using NVIDIA Isaac Sim, enabling virtual validation and real-world deployment with maximum impact.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Cyngn&lt;/b&gt;, a pioneer in autonomous mobile robotics, is integrating its DriveMod technology into Isaac Sim to enable large-scale, high fidelity virtual testing of advanced autonomous operation. Purpose-built for industrial applications, DriveMod is already deployed on vehicles such as the Motrec MT-160 Tugger and BYD Forklift, delivering sophisticated automation to material handling operations.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Doosan Robotics&lt;/b&gt;, a company specializing in AI robotic solutions, will showcase its “sim to real” solution, using NVIDIA Isaac Sim and cuRobo. Doosan will be showcasing how to seamlessly transfer tasks from simulation to real robots across a wide range of applications — from manufacturing to service industries.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Franka Robotics&lt;/b&gt; has integrated Isaac GR00T N1.5 into a dual-arm Franka Research 3 (FR3) robot for robotic control. The integration of GR00T N1.5 allows the system to interpret visual input, understand task context and autonomously perform complex manipulation — without the need for task-specific programming or hardcoded logic.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_82569"&gt;&lt;img alt="alt" class="size-full wp-image-82569" height="1999" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/franka.jpg" width="1506" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82569"&gt;Image courtesy of Franka Robotics.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;b&gt;Hexagon&lt;/b&gt;, the global leader in measurement technologies, launched its new humanoid, dubbed AEON. With its unique locomotion system and multimodal sensor fusion, and powered by NVIDIA’s three-computer solution, AEON is engineered to perform a wide range of industrial applications, from manipulation and asset inspection to reality capture and operator support.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Intrinsic&lt;/b&gt;, a software and AI robotics company, is integrating Intrinsic Flowstate with&amp;nbsp; Omniverse and OpenUSD for advanced visualization and digital twins that can be used in many industrial use cases. The company is also using NVIDIA foundation models to enhance robot capabilities like grasp planning through AI and simulation technologies.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;SCHUNK&lt;/b&gt;, a global leader in gripping systems and automation technology, is showcasing its innovative grasping kit powered by the NVIDIA Jetson AGX Orin module. The kit intelligently detects objects and calculates optimal grasping points. Schunk is also demonstrating seamless simulation-to-reality transfer using IGS Virtuous software — built on Omniverse technologies — to control a real robot through simulation in a pick-and-place scenario.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Universal Robots&lt;/b&gt; is showcasing UR15, its fastest cobot yet. Powered by the UR AI Accelerator — developed with NVIDIA and running on Jetson AGX Orin using CUDA-accelerated Isaac libraries — UR15 helps set a new standard for industrial automation.&lt;/p&gt;
&lt;p&gt;[embedded content]&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Vention&lt;/b&gt;, a full-stack software and hardware automation company, launched its Machine Motion AI, built on CUDA-accelerated Isaac libraries and powered by Jetson. Vention is also expanding its lineup of robotic offerings by adding the FR3 robot from Franka Robotics to its ecosystem, enhancing its solutions for academic and research applications.&lt;/p&gt;
&lt;figure class="wp-caption alignnone" id="attachment_82572"&gt;&lt;img alt="alt" class="size-large wp-image-82572" height="1012" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/vention-1680x1012.jpg" width="1680" /&gt;&lt;figcaption class="wp-caption-text" id="caption-attachment-82572"&gt;Image courtesy of Vention.&lt;/figcaption&gt;&lt;/figure&gt;
&lt;p&gt;&lt;i&gt;Learn more about the latest robotics advancements by joining &lt;/i&gt;&lt;i&gt;NVIDIA at Automatica&lt;/i&gt;&lt;i&gt;, running through Friday, June 27.&amp;nbsp;&lt;/i&gt;&lt;/p&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/automatica-robotics-2025/</guid><pubDate>Tue, 24 Jun 2025 09:00:30 +0000</pubDate></item><item><title>The Anthropocene illusion (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/24/1118442/zed-nelson-photography-nature-curation/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Over six years and across four continents, the London-based documentary photographer Zed Nelson has examined how humans have immersed themselves in increasingly simulated environments to mask their destructive divorce from the natural world. Featuring everything from theme parks and zoos to national parks and African safaris, his images reveal not only a desperate craving for a connection to a world we have turned our back on but also a global phenomenon of denial and collective self-­delusion. “People may have flocked to see them to see the unfamiliar and the exotic,” he says. “Now they may go to see what is no longer out there, what is endangered, what we have lost.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="tropical red fish" class="wp-image-1118875" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160390.jpg?w=2500" width="2500" /&gt;&lt;figcaption class="wp-element-caption"&gt;Quancheng Ocean Polar World, Shandong, China&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="the back of a woman in a sun hat standing next to an artificial snow wall" class="wp-image-1118871" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160365.jpg?w=2500" width="2500" /&gt;&lt;figcaption class="wp-element-caption"&gt;World of Water, Watford, UK&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In his new photo book, &lt;em&gt;The Anthropocene Illusion&lt;/em&gt;, Nelson writes, “In a tiny fraction of our Earth’s history, we humans have altered our world beyond anything it has experienced in tens of millions of years.” His images document our increasingly futile attempts to create a simulacrum of an Edenic natural world that none of us have actually experienced. The number of wild animals on Earth has halved in the past 40 years, and that decline shows no signs of slowing down. We are forcing animals and plants to extinction by removing their habitats. Future geologists will likely find evidence in the rock strata of an unprecedented human impact on our planet—huge concentrations of plastics, fallout from the burning of fossil fuels, and vast deposits of concrete used to build our cities.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a chimpanzee on a rock in a paved enclosure where a wall mural has been painted to look like a landscape" class="wp-image-1118873" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160380.jpg?w=2755" width="2755" /&gt;&lt;figcaption class="wp-element-caption"&gt;Shanghai Wild Animal Park, China&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Yet deep within us, the desire for contact with nature remains. So we have become masters of what Nelson calls “a stage-managed, artificial ‘experience’ of nature, a reassuring spectacle.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="buses and cars in traffic on a road in Yosemite" class="wp-image-1118874" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160386.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Yosemite National Park, California&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two tourist standing on a path surrounded by tropical foliage" class="wp-image-1118872" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160373.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Rainforest at Tropical Islands holiday resort, Krausnick, Germany&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Charles Darwin reduced humans to just another species—a twig on the grand tree of life,” Nelson writes in his book’s afterword. “But now, the paradigm has shifted: humankind is no longer just another species. We are the first to knowingly reshape the living earth’s biology and chemistry. We have become the masters of our planet and integral to the destiny of life on Earth. Surrounding ourselves with simulated recreations of nature paradoxically constitutes an unwitting monument to the very thing that we have lost.”&lt;/p&gt;  &lt;p&gt;As Jon Mooallem observed in &lt;em&gt;Wild Ones&lt;/em&gt;, his cultural history of wild animals and our relationship to them, “We are everywhere in the wilderness with white gloves on, directing traffic.”&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;Over six years and across four continents, the London-based documentary photographer Zed Nelson has examined how humans have immersed themselves in increasingly simulated environments to mask their destructive divorce from the natural world. Featuring everything from theme parks and zoos to national parks and African safaris, his images reveal not only a desperate craving for a connection to a world we have turned our back on but also a global phenomenon of denial and collective self-­delusion. “People may have flocked to see them to see the unfamiliar and the exotic,” he says. “Now they may go to see what is no longer out there, what is endangered, what we have lost.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="tropical red fish" class="wp-image-1118875" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160390.jpg?w=2500" width="2500" /&gt;&lt;figcaption class="wp-element-caption"&gt;Quancheng Ocean Polar World, Shandong, China&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="the back of a woman in a sun hat standing next to an artificial snow wall" class="wp-image-1118871" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160365.jpg?w=2500" width="2500" /&gt;&lt;figcaption class="wp-element-caption"&gt;World of Water, Watford, UK&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;In his new photo book, &lt;em&gt;The Anthropocene Illusion&lt;/em&gt;, Nelson writes, “In a tiny fraction of our Earth’s history, we humans have altered our world beyond anything it has experienced in tens of millions of years.” His images document our increasingly futile attempts to create a simulacrum of an Edenic natural world that none of us have actually experienced. The number of wild animals on Earth has halved in the past 40 years, and that decline shows no signs of slowing down. We are forcing animals and plants to extinction by removing their habitats. Future geologists will likely find evidence in the rock strata of an unprecedented human impact on our planet—huge concentrations of plastics, fallout from the burning of fossil fuels, and vast deposits of concrete used to build our cities.&amp;nbsp;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="a chimpanzee on a rock in a paved enclosure where a wall mural has been painted to look like a landscape" class="wp-image-1118873" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160380.jpg?w=2755" width="2755" /&gt;&lt;figcaption class="wp-element-caption"&gt;Shanghai Wild Animal Park, China&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt; &lt;p&gt;Yet deep within us, the desire for contact with nature remains. So we have become masters of what Nelson calls “a stage-managed, artificial ‘experience’ of nature, a reassuring spectacle.”&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div class="imageSet__wrap"&gt;&lt;div class="columns__wrapper--07c4096a3b25e22dc82ee78b6368d947"&gt;&lt;div class="wp-block-columns"&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="buses and cars in traffic on a road in Yosemite" class="wp-image-1118874" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160386.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Yosemite National Park, California&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="wp-block-column"&gt;&lt;div class="columns__content--3becc448c76a1a5a553df1358f1eebf3"&gt;&lt;div class="wp-block-image"&gt; &lt;figure class="wp-block-image size-large"&gt;&lt;img alt="two tourist standing on a path surrounded by tropical foliage" class="wp-image-1118872" height="2000" src="https://wp.technologyreview.com/wp-content/uploads/2025/06/IAM_00160373.jpg?w=2000" width="2000" /&gt;&lt;figcaption class="wp-element-caption"&gt;Rainforest at Tropical Islands holiday resort, Krausnick, Germany&lt;/figcaption&gt;&lt;div class="image-credit"&gt;ZED NELSON&lt;/div&gt; &lt;/figure&gt; &lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt;&lt;p&gt;“Charles Darwin reduced humans to just another species—a twig on the grand tree of life,” Nelson writes in his book’s afterword. “But now, the paradigm has shifted: humankind is no longer just another species. We are the first to knowingly reshape the living earth’s biology and chemistry. We have become the masters of our planet and integral to the destiny of life on Earth. Surrounding ourselves with simulated recreations of nature paradoxically constitutes an unwitting monument to the very thing that we have lost.”&lt;/p&gt;  &lt;p&gt;As Jon Mooallem observed in &lt;em&gt;Wild Ones&lt;/em&gt;, his cultural history of wild animals and our relationship to them, “We are everywhere in the wilderness with white gloves on, directing traffic.”&amp;nbsp;&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/24/1118442/zed-nelson-photography-nature-curation/</guid><pubDate>Tue, 24 Jun 2025 10:00:00 +0000</pubDate></item><item><title>Curated realities: An AI film festival and the future of human expression (AI – Ars Technica)</title><link>https://arstechnica.com/culture/2025/06/curated-realities-an-ai-film-festival-and-the-future-of-human-expression/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      We saw 10 AI films and interviewed Runway's CEO as well as Hollywood pros.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="An AI-generated frame of a person looking at an array of television screens" class="intro-image" height="887" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Total-Pixel-Space-still.jpg" width="1822" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A still from &lt;em&gt;Total Pixel Space&lt;/em&gt;, the Grand Prix winner at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last week, I attended a film festival dedicated to shorts made using generative AI. Dubbed AIFF 2025, it was an event precariously balancing between two different worlds.&lt;/p&gt;
&lt;p&gt;The festival was hosted by Runway, a company that produces models and tools for generating images and videos. In panels and press briefings, a curated list of industry professionals made the case for Hollywood to embrace AI tools. In private meetings with industry professionals, I gained a strong sense that there is already a widening philosophical divide within the film and television business.&lt;/p&gt;
&lt;p&gt;I also interviewed Runway CEO Cristóbal Valenzuela about the tightrope he walks as he pitches his products to an industry that has deeply divided feelings about what role AI will have in its future.&lt;/p&gt;
&lt;p&gt;To unpack all this, it makes sense to start with the films, partly because the film that was chosen as the festival's top prize winner says a lot about the issues at hand.&lt;/p&gt;
&lt;h2&gt;A festival of oddities and profundities&lt;/h2&gt;
&lt;p&gt;Since this was the first time the festival has been open to the public, the crowd was a diverse mix: AI tech enthusiasts, working industry creatives, and folks who enjoy movies and who were curious about what they'd see—as well as quite a few people who fit into all three groups.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102065 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="474" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/AIFF-2025-1024x474.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The scene at the entrance to the theater at AIFF 2025 in Santa Monica, California.

          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The films shown were all short, and most would be more at home at an art film fest than something more mainstream. Some shorts featured an animated aesthetic (including one inspired by anime) and some presented as live action. There was even a documentary of sorts. The films could be made entirely with Runway or other AI tools, or those tools could simply be a key part of a stack that also includes more traditional filmmaking methods.&lt;/p&gt;
&lt;p&gt;Many of these shorts were quite weird. Most of us have seen by now that AI video-generation tools excel at producing surreal and distorted imagery—sometimes whether the person prompting the tool wants that or not. Several of these films leaned into that limitation, treating it as a strength.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Representing that camp was Vallée Duhamel's &lt;em&gt;Fragments of Nowhere&lt;/em&gt;, which visually explored the notion of multiple dimensions bleeding into one another. Cars morphed into the sides of houses, and humanoid figures, purported to be inter-dimensional travelers, moved in ways that defied anatomy. While I found this film visually compelling at times, I wasn't seeing much in it that I hadn't already seen from dreamcore or horror AI video TikTok creators like GLUMLOT or SinRostroz in recent years.&lt;/p&gt;
&lt;p&gt;More compelling were shorts that used this propensity for oddity to generate imagery that was curated and thematically tied to some aspect of human experience or identity. For example, &lt;em&gt;More Tears than Harm&lt;/em&gt; by Herinarivo Rakotomanana was a rotoscope animation-style "sensory collage of childhood memories" of growing up in Madagascar. Its specificity and consistent styling lent it a credibility that &lt;em&gt;Fragments of Nowhere&lt;/em&gt; didn't achieve. I also enjoyed Riccardo Fusetti's &lt;em&gt;Editorial&lt;/em&gt; on this front.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      &lt;em&gt;More Tears Than Harm&lt;/em&gt;, an unusual animated film at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Among the 10 films in the festival, two clearly stood above the others in my impressions—and they ended up being the Grand Prix and Gold prize winners. (The judging panel included filmmakers Gaspar Noé and Harmony Korine, Tribeca Enterprises CEO Jane Rosenthal, IMAX head of post and image capture Bruce Markoe, Lionsgate VFX SVP Brianna Domont, Nvidia developer relations lead Richard Kerris, and Runway CEO Cristóbal Valenzuela, among others).&lt;/p&gt;
&lt;p&gt;Runner-up &lt;em&gt;Jailbird&lt;/em&gt; was the aforementioned quasi-documentary. Directed by Andrew Salter, it was a brief piece that introduced viewers to a program in the UK that places chickens in human prisons as companion animals, to positive effect. Why make that film with AI, you might ask? Well, AI was used to achieve shots that wouldn't otherwise be doable for a small-budget film to depict the experience from the chicken's point of view. The crowd loved it.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      &lt;em&gt;Jailbird&lt;/em&gt;, the runner-up&amp;nbsp;at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Then there was the Grand Prix winner, Jacob Adler's Total Pixel Space, which was, among other things, a philosophical defense of the very idea of AI art. You can watch &lt;em&gt;Total Pixel Space&lt;/em&gt; on YouTube right now, unlike some of the other films. I found it strangely moving, even as I saw its selection as the festival's top winner with some cynicism. Of course they'd pick that one, I thought, although I agreed it was the most interesting of the lot.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      &lt;em&gt;Total Pixel Space&lt;/em&gt;, the Grand Prix winner at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;&lt;em&gt;Total Pixel Space&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Even though it risked navel-gazing and self-congratulation in this venue, &lt;em&gt;Total Pixel Space&lt;/em&gt; was filled with compelling imagery that matched the themes, and it touched on some genuinely interesting ideas—at times, it seemed almost profound, didactic as it was.&lt;/p&gt;
&lt;p&gt;"How many images can possibly exist?" the film's narrator asked. To answer that, it explains the concept of total pixel space, which actually reflects how image generation tools work:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Pixels are the building blocks of digital images—tiny tiles forming a mosaic. Each pixel is defined by numbers representing color and position. Therefore, any digital image can be represented as a sequence of numbers...&lt;/p&gt;
&lt;p&gt;Just as we don't need to write down every number between zero and one to prove they exist, we don't need to generate every possible image to prove they exist. Their existence is guaranteed by the mathematics that defines them... Every frame of every possible film exists as coordinates... To deny this would be to deny the existence of numbers themselves.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The nine-minute film demonstrates that the number of possible images or films is greater than the number of atoms in the universe and argues that photographers and filmmakers may be seen as discovering images that already exist in the possibility space rather than creating something new.&lt;/p&gt;
&lt;p&gt;Within that framework, it's easy to argue that generative AI is just another way for artists to "discover" images.&lt;/p&gt;
&lt;h2&gt;The balancing act&lt;/h2&gt;
&lt;p&gt;"We are all—and I include myself in that group as well—obsessed with technology, and we keep chatting about models and data sets and training and capabilities," Runway CEO Cristóbal Valenzuela said to me when we spoke the next morning. "But if you look back and take a minute, the festival was celebrating filmmakers and artists."&lt;/p&gt;
&lt;p&gt;I admitted that I found myself moved by &lt;em&gt;Total Pixel Space&lt;/em&gt;'s articulations. "The winner would never have thought of himself as a filmmaker, and he made a film that made you feel something," Valenzuela responded. "I feel that's very powerful. And the reason he could do it was because he had access to something that just wasn't possible a couple of months ago."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;First-time and outsider filmmakers were the focus of AIFF 2025, but Runway works with established studios, too—and those relationships have an inherent tension.&lt;/p&gt;
&lt;p&gt;The company has signed deals with companies like Lionsgate and AMC Networks. In some cases, it trains on data provided by those companies; in others, it embeds within them to try to develop tools that fit how they already work. That's not something competitors like OpenAI are doing yet, so that, combined with a head start in video generation, has allowed Runway to grow and stay competitive so far.&lt;/p&gt;
&lt;p&gt;"We go directly into the companies, and we have teams of creatives that are working alongside them. We basically embed ourselves within the organizations that we're working with very deeply," Valenzuela explained. "We do versions of our film festival internally for teams as well so they can go through the process of making something and seeing the potential."&lt;/p&gt;
&lt;p&gt;Founded in 2018 at New York University's Tisch School of the Arts by two Chileans and one Greek co-founder, Runway has a very different story than its Silicon Valley competitors. It was one of the first to bring an actually usable video-generation tool to the masses. Runway also contributed in foundational ways to the popular Stable Diffusion model.&lt;/p&gt;
&lt;p&gt;Though it is vastly outspent by competitors like OpenAI, it has taken a hands-on approach to working with existing industries. You won't hear Valenzuela or other Runway leaders talking about the imminence of AGI or anything so lofty; instead, it's all about selling the product as something that can solve existing problems in creatives' workflows.&lt;/p&gt;
&lt;p&gt;Still, an artist's mindset and relationships within the industry don't negate some fundamental conflicts. There are multiple intellectual property cases involving Runway and its peers, and though the company hasn't admitted it, there is evidence that it trained its models on copyrighted YouTube videos, among other things.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2102066 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="557" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Cristobal-Valenzuela-1024x557.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Cristóbal Valenzuela speaking on the AIFF 2025 stage.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Valenzuela suggested that studios are worried about liability, not underlying principles, though, saying:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;Most of the concerns on copyright are on the output side, which is like, how do you make sure that the model doesn't create something that already exists or infringes on something. And I think for that, we've made sure our models don't and are supportive of the creative direction you want to take without being too limiting. We work with every major studio, and we offer them indemnification.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In the past, he has also defended Runway by saying that what it's producing is not a re-creation of what has come before. He sees the tool's generative process as distinct—legally, creatively, and ethically—from simply pulling up assets or references from a database.&lt;/p&gt;
&lt;p&gt;"People believe AI is sort of like a system that creates and conjures things magically with no input from users," he said. "And it's not. You have to do that work. You still are involved, and you're still responsible as a user in terms of how you use it."&lt;/p&gt;
&lt;p&gt;He seemed to share this defense of AI as a legitimate tool for artists with conviction, but given that he's been pitching these products directly to working filmmakers, he was also clearly aware that not everyone agrees with him. There is not even a consensus among those in the industry.&lt;/p&gt;
&lt;h2&gt;An industry divided&lt;/h2&gt;
&lt;p&gt;While in LA for the event, I visited separately with two of my oldest friends. Both of them work in the film and television industry in similar disciplines. They each asked what I was in town for, and I told them I was there to cover an AI film festival.&lt;/p&gt;
&lt;p&gt;One immediately responded with a grimace of disgust, "Oh, yikes, I'm sorry." The other responded with bright eyes and intense interest and began telling me how he already uses AI in his day-to-day to do things like extend shots by a second or two for a better edit, and expressed frustration at his company for not adopting the tools faster.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Neither is alone in their attitudes. Hollywood is divided—and not for the first time.&lt;/p&gt;
&lt;p&gt;There have been seismic technological changes in the film industry before. There was the transition from silent films to talkies, obviously; moviemaking transformed into an entirely different art. Numerous old jobs were lost, and numerous new jobs were created.&lt;/p&gt;
&lt;p&gt;Later, there was the transition from film to digital projection, which may be an even tighter parallel. It was a major disruption, with some companies and careers collapsing while others rose. There were people saying, "Why do we even need this?" while others believed it was the only sane way forward. Some audiences declared the quality worse, and others said it was better. There were analysts arguing it could be stopped, while others insisted it was inevitable.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;IMAX's head of post production, Bruce Markoe, spoke briefly about that history at a press mixer before the festival. "It was a little scary," he recalled. "It was a big, fundamental change that we were going through."&lt;/p&gt;
&lt;p&gt;People ultimately embraced it, though. "The motion picture and television industry has always been very technology-forward, and they've always used new technologies to advance the state of the art and improve the efficiencies," Markoe said.&lt;/p&gt;
&lt;p&gt;When asked whether he thinks the same thing will happen with generative AI tools, he said, "I think some filmmakers are going to embrace it faster than others." He pointed to AI tools' usefulness for pre-visualization as particularly valuable and noted some people are already using it that way, but it will take time for people to get comfortable with.&lt;/p&gt;
&lt;p&gt;And indeed, many, many filmmakers are still loudly skeptical. "The &lt;em&gt;concept&lt;/em&gt; of AI is great," &lt;em&gt;The Mitchells vs. the Machines&lt;/em&gt; director Mike Rianda said in a Wired interview. "But in the hands of a corporation, it is like a buzzsaw that will destroy us all."&lt;/p&gt;
&lt;p&gt;Others are interested in the technology but are concerned that it's being brought into the industry too quickly, with insufficient planning and protections. That includes Crafty Apes Senior VFX Supervisor Luke DiTomasso. "&lt;span class="mVzZr"&gt;How fast do we roll out AI technologies without really having an understanding of them?" he asked in an interview with Production Designers Collective. "There’s a potential for AI to accelerate beyond what we might be comfortable with, so I do have some trepidation and am maybe not gung-ho about all aspects of it.&lt;/span&gt;"&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Others remain skeptical that the tools will be as useful as some optimists believe. "AI never passed on anything. It loved everything it read. It wants you to win. But storytelling requires nuance—subtext, emotion, what’s left unsaid. That’s something AI simply can’t replicate," said Alegre Rodriquez, a member of the Emerging Technology committee at the Motion Picture Editors Guild.&lt;/p&gt;
&lt;h2&gt;The mirror&lt;/h2&gt;
&lt;p&gt;Flying back from Los Angeles, I considered two key differences between this generative AI inflection point for Hollywood and the silent/talkie or film/digital transitions.&lt;/p&gt;
&lt;p&gt;First, neither of those transitions involved an existential threat to the technology on the basis of intellectual property and copyright. Valenzuela talked about what matters to studio heads—protection from liability over the outputs. But the countless creatives who are critical of these tools also believe they should be consulted and even compensated for their work's use in the training data for Runway's models. In other words, it's not just about the outputs, it's also about the sourcing. As noted before, there are several cases underway. We don't know where they'll land yet.&lt;/p&gt;
&lt;p&gt;Second, there's a more cultural and philosophical issue at play, which Valenzuela himself touched on in our conversation.&lt;/p&gt;
&lt;p&gt;"I think AI has become this sort of mirror where anyone can project all their fears and anxieties, but also their optimism and ideas of the future," he told me.&lt;/p&gt;
&lt;p&gt;You don't have to scroll for long to come across techno-utopians declaring with no evidence that AGI is right around the corner and that it will cure cancer and save our society. You also don't have to scroll long to encounter visceral anger at every generative AI company from people declaring the technology—which is essentially just a new methodology for programming a computer—fundamentally unethical and harmful, with apocalyptic societal and economic ramifications.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amid all those bold declarations, this film festival put the focus on the on-the-ground reality. First-time filmmakers who might never have previously cleared Hollywood's gatekeepers are getting screened at festivals because they can create competitive-looking work with a fraction of the crew and hours. Studios and the people who work there are saying they're saving time, resources, and headaches in pre-viz, editing, visual effects, and other work that's usually done under immense time and resource pressure.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“People are not paying attention to the very huge amount of positive outcomes of this technology,” Valenzuela told me, pointing to those examples.&lt;/p&gt;
&lt;p&gt;In this online discussion ecosystem that elevates outrage above everything else, that's likely true. Still, there is a sincere and rigorous conviction among many creatives that their work is contributing to this technology's capabilities without credit or compensation and that the structural and legal frameworks to ensure minimal human harm in this evolving period of disruption are still inadequate. That's why we've seen groups like the Writers Guild of America West support the Generative AI Copyright Disclosure Act and other similar legislation meant to increase transparency about how these models are trained.&lt;/p&gt;
&lt;h2&gt;The philosophical question with a legal answer&lt;/h2&gt;
&lt;p&gt;The winning film argued that "total pixel space represents both the ultimate determinism and the ultimate freedom—every possibility existing simultaneously, waiting for consciousness to give it meaning through the act of choice."&lt;/p&gt;
&lt;p&gt;In making this statement, the film suggested that creativity, above all else, is an act of curation. It's a claim that nothing, truly, is original. It's a distillation of human expression into the language of mathematics.&lt;/p&gt;
&lt;p&gt;To many, that philosophy rings undeniably true: Every possibility already exists, and artists are just collapsing the waveform to the frame they want to reveal. To others, there is more personal truth to the romantic ideal that artwork is valued precisely because it did not exist until the artist produced it.&lt;/p&gt;
&lt;p&gt;All this is to say that the debate about creativity and AI in Hollywood is ultimately a philosophical one. But it won't be resolved that way.&lt;/p&gt;
&lt;p&gt;The industry may succumb to litigation fatigue and a hollowed-out workforce—or it may instead find its way to fair deals, new opportunities for fresh voices, and transparent training sets.&lt;/p&gt;
&lt;p&gt;For all this lofty talk about creativity and ideas, the outcome will come down to the contracts, court decisions, and compensation structures—all things that have always been at least as big a part of Hollywood as the creative work itself.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-white py-4 dark:bg-gray-700 md:my-10 md:py-8"&gt;
  &lt;div class="mx-auto max-w-2xl px-4 md:px-8 lg:grid lg:max-w-6xl"&gt;
    

    

    &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 my-3 text-2xl leading-[1.1] md:leading-[1.2]"&gt;
      We saw 10 AI films and interviewed Runway's CEO as well as Hollywood pros.
    &lt;/p&gt;

    

    &lt;div class="relative"&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="An AI-generated frame of a person looking at an array of television screens" class="intro-image" height="887" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Total-Pixel-Space-still.jpg" width="1822" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;

    &lt;div&gt;
      &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      A still from &lt;em&gt;Total Pixel Space&lt;/em&gt;, the Grand Prix winner at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
    &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Last week, I attended a film festival dedicated to shorts made using generative AI. Dubbed AIFF 2025, it was an event precariously balancing between two different worlds.&lt;/p&gt;
&lt;p&gt;The festival was hosted by Runway, a company that produces models and tools for generating images and videos. In panels and press briefings, a curated list of industry professionals made the case for Hollywood to embrace AI tools. In private meetings with industry professionals, I gained a strong sense that there is already a widening philosophical divide within the film and television business.&lt;/p&gt;
&lt;p&gt;I also interviewed Runway CEO Cristóbal Valenzuela about the tightrope he walks as he pitches his products to an industry that has deeply divided feelings about what role AI will have in its future.&lt;/p&gt;
&lt;p&gt;To unpack all this, it makes sense to start with the films, partly because the film that was chosen as the festival's top prize winner says a lot about the issues at hand.&lt;/p&gt;
&lt;h2&gt;A festival of oddities and profundities&lt;/h2&gt;
&lt;p&gt;Since this was the first time the festival has been open to the public, the crowd was a diverse mix: AI tech enthusiasts, working industry creatives, and folks who enjoy movies and who were curious about what they'd see—as well as quite a few people who fit into all three groups.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102065 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="474" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/AIFF-2025-1024x474.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The scene at the entrance to the theater at AIFF 2025 in Santa Monica, California.

          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;The films shown were all short, and most would be more at home at an art film fest than something more mainstream. Some shorts featured an animated aesthetic (including one inspired by anime) and some presented as live action. There was even a documentary of sorts. The films could be made entirely with Runway or other AI tools, or those tools could simply be a key part of a stack that also includes more traditional filmmaking methods.&lt;/p&gt;
&lt;p&gt;Many of these shorts were quite weird. Most of us have seen by now that AI video-generation tools excel at producing surreal and distorted imagery—sometimes whether the person prompting the tool wants that or not. Several of these films leaned into that limitation, treating it as a strength.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Representing that camp was Vallée Duhamel's &lt;em&gt;Fragments of Nowhere&lt;/em&gt;, which visually explored the notion of multiple dimensions bleeding into one another. Cars morphed into the sides of houses, and humanoid figures, purported to be inter-dimensional travelers, moved in ways that defied anatomy. While I found this film visually compelling at times, I wasn't seeing much in it that I hadn't already seen from dreamcore or horror AI video TikTok creators like GLUMLOT or SinRostroz in recent years.&lt;/p&gt;
&lt;p&gt;More compelling were shorts that used this propensity for oddity to generate imagery that was curated and thematically tied to some aspect of human experience or identity. For example, &lt;em&gt;More Tears than Harm&lt;/em&gt; by Herinarivo Rakotomanana was a rotoscope animation-style "sensory collage of childhood memories" of growing up in Madagascar. Its specificity and consistent styling lent it a credibility that &lt;em&gt;Fragments of Nowhere&lt;/em&gt; didn't achieve. I also enjoyed Riccardo Fusetti's &lt;em&gt;Editorial&lt;/em&gt; on this front.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      &lt;em&gt;More Tears Than Harm&lt;/em&gt;, an unusual animated film at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Among the 10 films in the festival, two clearly stood above the others in my impressions—and they ended up being the Grand Prix and Gold prize winners. (The judging panel included filmmakers Gaspar Noé and Harmony Korine, Tribeca Enterprises CEO Jane Rosenthal, IMAX head of post and image capture Bruce Markoe, Lionsgate VFX SVP Brianna Domont, Nvidia developer relations lead Richard Kerris, and Runway CEO Cristóbal Valenzuela, among others).&lt;/p&gt;
&lt;p&gt;Runner-up &lt;em&gt;Jailbird&lt;/em&gt; was the aforementioned quasi-documentary. Directed by Andrew Salter, it was a brief piece that introduced viewers to a program in the UK that places chickens in human prisons as companion animals, to positive effect. Why make that film with AI, you might ask? Well, AI was used to achieve shots that wouldn't otherwise be doable for a small-budget film to depict the experience from the chicken's point of view. The crowd loved it.&lt;/p&gt;
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      &lt;em&gt;Jailbird&lt;/em&gt;, the runner-up&amp;nbsp;at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;p&gt;Then there was the Grand Prix winner, Jacob Adler's Total Pixel Space, which was, among other things, a philosophical defense of the very idea of AI art. You can watch &lt;em&gt;Total Pixel Space&lt;/em&gt; on YouTube right now, unlike some of the other films. I found it strangely moving, even as I saw its selection as the festival's top winner with some cynicism. Of course they'd pick that one, I thought, although I agreed it was the most interesting of the lot.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="ars-video"&gt;&lt;div class="relative"&gt;&lt;/div&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      &lt;em&gt;Total Pixel Space&lt;/em&gt;, the Grand Prix winner at AIFF 2025.

          &lt;/div&gt;
  &lt;/div&gt;
&lt;/figure&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;&lt;em&gt;Total Pixel Space&lt;/em&gt;&lt;/h2&gt;
&lt;p&gt;Even though it risked navel-gazing and self-congratulation in this venue, &lt;em&gt;Total Pixel Space&lt;/em&gt; was filled with compelling imagery that matched the themes, and it touched on some genuinely interesting ideas—at times, it seemed almost profound, didactic as it was.&lt;/p&gt;
&lt;p&gt;"How many images can possibly exist?" the film's narrator asked. To answer that, it explains the concept of total pixel space, which actually reflects how image generation tools work:&lt;/p&gt;
&lt;blockquote&gt;&lt;p&gt;Pixels are the building blocks of digital images—tiny tiles forming a mosaic. Each pixel is defined by numbers representing color and position. Therefore, any digital image can be represented as a sequence of numbers...&lt;/p&gt;
&lt;p&gt;Just as we don't need to write down every number between zero and one to prove they exist, we don't need to generate every possible image to prove they exist. Their existence is guaranteed by the mathematics that defines them... Every frame of every possible film exists as coordinates... To deny this would be to deny the existence of numbers themselves.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The nine-minute film demonstrates that the number of possible images or films is greater than the number of atoms in the universe and argues that photographers and filmmakers may be seen as discovering images that already exist in the possibility space rather than creating something new.&lt;/p&gt;
&lt;p&gt;Within that framework, it's easy to argue that generative AI is just another way for artists to "discover" images.&lt;/p&gt;
&lt;h2&gt;The balancing act&lt;/h2&gt;
&lt;p&gt;"We are all—and I include myself in that group as well—obsessed with technology, and we keep chatting about models and data sets and training and capabilities," Runway CEO Cristóbal Valenzuela said to me when we spoke the next morning. "But if you look back and take a minute, the festival was celebrating filmmakers and artists."&lt;/p&gt;
&lt;p&gt;I admitted that I found myself moved by &lt;em&gt;Total Pixel Space&lt;/em&gt;'s articulations. "The winner would never have thought of himself as a filmmaker, and he made a film that made you feel something," Valenzuela responded. "I feel that's very powerful. And the reason he could do it was because he had access to something that just wasn't possible a couple of months ago."&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;First-time and outsider filmmakers were the focus of AIFF 2025, but Runway works with established studios, too—and those relationships have an inherent tension.&lt;/p&gt;
&lt;p&gt;The company has signed deals with companies like Lionsgate and AMC Networks. In some cases, it trains on data provided by those companies; in others, it embeds within them to try to develop tools that fit how they already work. That's not something competitors like OpenAI are doing yet, so that, combined with a head start in video generation, has allowed Runway to grow and stay competitive so far.&lt;/p&gt;
&lt;p&gt;"We go directly into the companies, and we have teams of creatives that are working alongside them. We basically embed ourselves within the organizations that we're working with very deeply," Valenzuela explained. "We do versions of our film festival internally for teams as well so they can go through the process of making something and seeing the potential."&lt;/p&gt;
&lt;p&gt;Founded in 2018 at New York University's Tisch School of the Arts by two Chileans and one Greek co-founder, Runway has a very different story than its Silicon Valley competitors. It was one of the first to bring an actually usable video-generation tool to the masses. Runway also contributed in foundational ways to the popular Stable Diffusion model.&lt;/p&gt;
&lt;p&gt;Though it is vastly outspent by competitors like OpenAI, it has taken a hands-on approach to working with existing industries. You won't hear Valenzuela or other Runway leaders talking about the imminence of AGI or anything so lofty; instead, it's all about selling the product as something that can solve existing problems in creatives' workflows.&lt;/p&gt;
&lt;p&gt;Still, an artist's mindset and relationships within the industry don't negate some fundamental conflicts. There are multiple intellectual property cases involving Runway and its peers, and though the company hasn't admitted it, there is evidence that it trained its models on copyrighted YouTube videos, among other things.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;figure class="ars-wp-img-shortcode id-2102066 align-none"&gt;
    &lt;div&gt;
                        &lt;img alt="alt" class="none large" height="557" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Cristobal-Valenzuela-1024x557.jpg" width="1024" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      Cristóbal Valenzuela speaking on the AIFF 2025 stage.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Valenzuela suggested that studios are worried about liability, not underlying principles, though, saying:&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;blockquote&gt;&lt;p&gt;Most of the concerns on copyright are on the output side, which is like, how do you make sure that the model doesn't create something that already exists or infringes on something. And I think for that, we've made sure our models don't and are supportive of the creative direction you want to take without being too limiting. We work with every major studio, and we offer them indemnification.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;In the past, he has also defended Runway by saying that what it's producing is not a re-creation of what has come before. He sees the tool's generative process as distinct—legally, creatively, and ethically—from simply pulling up assets or references from a database.&lt;/p&gt;
&lt;p&gt;"People believe AI is sort of like a system that creates and conjures things magically with no input from users," he said. "And it's not. You have to do that work. You still are involved, and you're still responsible as a user in terms of how you use it."&lt;/p&gt;
&lt;p&gt;He seemed to share this defense of AI as a legitimate tool for artists with conviction, but given that he's been pitching these products directly to working filmmakers, he was also clearly aware that not everyone agrees with him. There is not even a consensus among those in the industry.&lt;/p&gt;
&lt;h2&gt;An industry divided&lt;/h2&gt;
&lt;p&gt;While in LA for the event, I visited separately with two of my oldest friends. Both of them work in the film and television industry in similar disciplines. They each asked what I was in town for, and I told them I was there to cover an AI film festival.&lt;/p&gt;
&lt;p&gt;One immediately responded with a grimace of disgust, "Oh, yikes, I'm sorry." The other responded with bright eyes and intense interest and began telling me how he already uses AI in his day-to-day to do things like extend shots by a second or two for a better edit, and expressed frustration at his company for not adopting the tools faster.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Neither is alone in their attitudes. Hollywood is divided—and not for the first time.&lt;/p&gt;
&lt;p&gt;There have been seismic technological changes in the film industry before. There was the transition from silent films to talkies, obviously; moviemaking transformed into an entirely different art. Numerous old jobs were lost, and numerous new jobs were created.&lt;/p&gt;
&lt;p&gt;Later, there was the transition from film to digital projection, which may be an even tighter parallel. It was a major disruption, with some companies and careers collapsing while others rose. There were people saying, "Why do we even need this?" while others believed it was the only sane way forward. Some audiences declared the quality worse, and others said it was better. There were analysts arguing it could be stopped, while others insisted it was inevitable.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;IMAX's head of post production, Bruce Markoe, spoke briefly about that history at a press mixer before the festival. "It was a little scary," he recalled. "It was a big, fundamental change that we were going through."&lt;/p&gt;
&lt;p&gt;People ultimately embraced it, though. "The motion picture and television industry has always been very technology-forward, and they've always used new technologies to advance the state of the art and improve the efficiencies," Markoe said.&lt;/p&gt;
&lt;p&gt;When asked whether he thinks the same thing will happen with generative AI tools, he said, "I think some filmmakers are going to embrace it faster than others." He pointed to AI tools' usefulness for pre-visualization as particularly valuable and noted some people are already using it that way, but it will take time for people to get comfortable with.&lt;/p&gt;
&lt;p&gt;And indeed, many, many filmmakers are still loudly skeptical. "The &lt;em&gt;concept&lt;/em&gt; of AI is great," &lt;em&gt;The Mitchells vs. the Machines&lt;/em&gt; director Mike Rianda said in a Wired interview. "But in the hands of a corporation, it is like a buzzsaw that will destroy us all."&lt;/p&gt;
&lt;p&gt;Others are interested in the technology but are concerned that it's being brought into the industry too quickly, with insufficient planning and protections. That includes Crafty Apes Senior VFX Supervisor Luke DiTomasso. "&lt;span class="mVzZr"&gt;How fast do we roll out AI technologies without really having an understanding of them?" he asked in an interview with Production Designers Collective. "There’s a potential for AI to accelerate beyond what we might be comfortable with, so I do have some trepidation and am maybe not gung-ho about all aspects of it.&lt;/span&gt;"&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Others remain skeptical that the tools will be as useful as some optimists believe. "AI never passed on anything. It loved everything it read. It wants you to win. But storytelling requires nuance—subtext, emotion, what’s left unsaid. That’s something AI simply can’t replicate," said Alegre Rodriquez, a member of the Emerging Technology committee at the Motion Picture Editors Guild.&lt;/p&gt;
&lt;h2&gt;The mirror&lt;/h2&gt;
&lt;p&gt;Flying back from Los Angeles, I considered two key differences between this generative AI inflection point for Hollywood and the silent/talkie or film/digital transitions.&lt;/p&gt;
&lt;p&gt;First, neither of those transitions involved an existential threat to the technology on the basis of intellectual property and copyright. Valenzuela talked about what matters to studio heads—protection from liability over the outputs. But the countless creatives who are critical of these tools also believe they should be consulted and even compensated for their work's use in the training data for Runway's models. In other words, it's not just about the outputs, it's also about the sourcing. As noted before, there are several cases underway. We don't know where they'll land yet.&lt;/p&gt;
&lt;p&gt;Second, there's a more cultural and philosophical issue at play, which Valenzuela himself touched on in our conversation.&lt;/p&gt;
&lt;p&gt;"I think AI has become this sort of mirror where anyone can project all their fears and anxieties, but also their optimism and ideas of the future," he told me.&lt;/p&gt;
&lt;p&gt;You don't have to scroll for long to come across techno-utopians declaring with no evidence that AGI is right around the corner and that it will cure cancer and save our society. You also don't have to scroll long to encounter visceral anger at every generative AI company from people declaring the technology—which is essentially just a new methodology for programming a computer—fundamentally unethical and harmful, with apocalyptic societal and economic ramifications.&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Amid all those bold declarations, this film festival put the focus on the on-the-ground reality. First-time filmmakers who might never have previously cleared Hollywood's gatekeepers are getting screened at festivals because they can create competitive-looking work with a fraction of the crew and hours. Studios and the people who work there are saying they're saving time, resources, and headaches in pre-viz, editing, visual effects, and other work that's usually done under immense time and resource pressure.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;“People are not paying attention to the very huge amount of positive outcomes of this technology,” Valenzuela told me, pointing to those examples.&lt;/p&gt;
&lt;p&gt;In this online discussion ecosystem that elevates outrage above everything else, that's likely true. Still, there is a sincere and rigorous conviction among many creatives that their work is contributing to this technology's capabilities without credit or compensation and that the structural and legal frameworks to ensure minimal human harm in this evolving period of disruption are still inadequate. That's why we've seen groups like the Writers Guild of America West support the Generative AI Copyright Disclosure Act and other similar legislation meant to increase transparency about how these models are trained.&lt;/p&gt;
&lt;h2&gt;The philosophical question with a legal answer&lt;/h2&gt;
&lt;p&gt;The winning film argued that "total pixel space represents both the ultimate determinism and the ultimate freedom—every possibility existing simultaneously, waiting for consciousness to give it meaning through the act of choice."&lt;/p&gt;
&lt;p&gt;In making this statement, the film suggested that creativity, above all else, is an act of curation. It's a claim that nothing, truly, is original. It's a distillation of human expression into the language of mathematics.&lt;/p&gt;
&lt;p&gt;To many, that philosophy rings undeniably true: Every possibility already exists, and artists are just collapsing the waveform to the frame they want to reveal. To others, there is more personal truth to the romantic ideal that artwork is valued precisely because it did not exist until the artist produced it.&lt;/p&gt;
&lt;p&gt;All this is to say that the debate about creativity and AI in Hollywood is ultimately a philosophical one. But it won't be resolved that way.&lt;/p&gt;
&lt;p&gt;The industry may succumb to litigation fatigue and a hollowed-out workforce—or it may instead find its way to fair deals, new opportunities for fresh voices, and transparent training sets.&lt;/p&gt;
&lt;p&gt;For all this lofty talk about creativity and ideas, the outcome will come down to the contracts, court decisions, and compensation structures—all things that have always been at least as big a part of Hollywood as the creative work itself.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/culture/2025/06/curated-realities-an-ai-film-festival-and-the-future-of-human-expression/</guid><pubDate>Tue, 24 Jun 2025 11:00:47 +0000</pubDate></item><item><title>The Download: Namibia’s hydrogen hopes, and fixing AI evaluation (MIT Technology Review)</title><link>https://www.technologyreview.com/2025/06/24/1119282/the-download-namibias-hydrogen-hopes-and-fixing-ai-evaluation/</link><description>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Namibia wants to build the world’s first hydrogen economy&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Factories have used fossil fuels to process iron ore for three centuries, and the climate has paid a heavy price: According to the International Energy Agency, the steel industry today accounts for 8% of carbon dioxide emissions.&lt;/p&gt;&lt;p&gt;But it turns out there is a less carbon-­intensive alternative: using hydrogen. Unlike coal or natural gas, which release carbon dioxide as a by-product, this process releases water. And if the hydrogen itself is “green,” the climate impact of the entire process will be minimal.&lt;/p&gt;  &lt;p&gt;HyIron, which has a site in the Namib desert, is one of a handful of companies around the world that are betting green hydrogen can help the $1.8 trillion steel industry clean up its act. The question now is whether Namibia’s government, its trading partners, and hydrogen innovators can work together to build the industry in a way that satisfies the world’s appetite for cleaner fuels—and also helps improve lives at home.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the next print edition of MIT Technology Review, which explores power—who has it, and who wants it. It’s set to go live tomorrow, so &lt;/strong&gt;&lt;strong&gt;subscribe &amp;amp; save 25%&lt;/strong&gt;&lt;strong&gt; to read it and get a copy of the issue when it lands!&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Can we fix AI’s evaluation crisis?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Every time a company launches a new AI model, its scores show it beating the capabilities of predecessors. On paper, everything appears to be getting better all the time.&lt;/p&gt;  &lt;p&gt;In practice, it’s not so simple. In fact, many now openly admit that the process of testing AI, using sets of exam-style questions called benchmarks, is broken.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;In response, a growing number of teams around the world are trying to address the AI evaluation crisis. One of them is Xbench, a benchmark project developed by HongShan Capital Group (formerly Sequoia China). It evaluates models not only on the ability to pass arbitrary tests, like most other benchmarks, but also on the ability to execute real-world tasks, which is more unusual. It’s also updated on a regular basis to try to keep it evergreen.&lt;/p&gt;  &lt;p&gt;Read more about Xbench in our story, and more about the broader efforts to tackle the evaluation crisis in this week’s edition of The Algorithm, our weekly newsletter about the latest goings-on in the world of AI.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The Anthropocene illusion&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Over six years and across four continents, the London-based documentary photographer Zed Nelson has examined how humans have immersed themselves in increasingly simulated environments to mask their destructive divorce from the natural world.&lt;/p&gt;&lt;p&gt;Featuring everything from theme parks and zoos to national parks and African safaris, his images reveal not only a desperate craving for a connection to a world we have turned our back on but also a global phenomenon of denial and collective self-­delusion. Check out a selection of his arresting images here.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Allison Arieff&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 US auto safety regulators are investigating Tesla’s robotaxis&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They’re probing incidents where the vehicles appear to violate traffic laws. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;One video depicts a robotaxi driving on the wrong side of the road. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;The probe has started just one day after the service launched in Texas. &lt;/em&gt;(TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Officials fear Iran is planning a cyber retaliation&lt;br /&gt;&lt;/strong&gt;Iran-linked groups could cause quite a bit of havoc in the US. (WP $)&lt;br /&gt;+ &lt;em&gt;The US says the conflict has triggered a "heightened threat environment." &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;Donald Trump has set off a whole new wave of bombing disinformation. &lt;/em&gt;(Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Caregivers are struggling to cope with measles outbreaks&lt;br /&gt;&lt;/strong&gt;The virus is infecting children and adults alike around the US. (NYT $)&lt;br /&gt;+ &lt;em&gt;RFK Jr’s planned dietary guideline shakeup is severely lacking. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;How measuring vaccine hesitancy could help health professionals tackle it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 A man was killed by police after speaking with ChatGPT&lt;/strong&gt;&lt;br /&gt;Alex Taylor, who struggled with his mental health, was convinced OpenAI had “killed” an entity called Juliet. (Rolling Stone $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 WhatsApp has been banned from US House of Representatives devices&lt;br /&gt;&lt;/strong&gt;The Office of Cybersecurity believes it poses a high risk to data security. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Another app banned from the same devices? TikTok. &lt;/em&gt;(Reuters)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 How AI is opening up a new digital divide&lt;/strong&gt;&lt;br /&gt;Between the nations with the computing power to build it, and the ones without. (NYT $)&lt;br /&gt;+ &lt;em&gt;Meta’s data center is not winning over communities in Louisiana. &lt;/em&gt;(404 Media)&lt;br /&gt;+ &lt;em&gt;The UAE wants to spend its way to becoming a tech superpower. &lt;/em&gt;(Rest of World)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 China’s EV factories are a must-see for tourists&lt;br /&gt;&lt;/strong&gt;Tens of thousands of people enter draws for the privilege each month. (Wired $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;8 Meta’s AI model has memorized nearly all of the first Harry Potter book&lt;br /&gt;&lt;/strong&gt;Which suggests it’s storing books, rather than training on them. (404 Media)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;9 How to get people to behave better online&lt;/strong&gt;&lt;br /&gt;Suspensions really work. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Elon Musk does not use a computer &lt;/strong&gt;&lt;strong&gt;💻&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;That’s his lawyers’ story, and they’re sticking to it. (Wired $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s like announcing that, ‘I’m going to Mars’ and then, you know, going to Cleveland.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Bryant Walker Smith, a University of South Carolina law professor, pokes fun at Elon Musk’s autonomous ride-hailing ambitions, Reuters reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/02/0511013_01.jpg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside the hunt for new physics at the world’s largest particle collider&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In 2012, using data from CERN’s Large Hadron Collider, researchers discovered a particle called the Higgs boson. In the process, they answered a nagging question: Where do fundamental particles, such as the ones that make up all the protons and neutrons in our bodies, get their mass?&lt;/p&gt;&lt;p&gt;When the particle was finally found, scientists celebrated with champagne. A Nobel for two of the physicists who predicted the Higgs boson soon followed.&lt;/p&gt;&lt;p&gt;But now, more than a decade later, there is a sense of unease. That’s because there are still so many unanswered questions about the fundamental constituents of the universe.&lt;/p&gt;&lt;p&gt;So researchers are trying something new. They are repurposing detectors to search for unusual-looking particles, squeezing what they can out of the data with machine learning, and planning for entirely new kinds of colliders. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Dan Garisto&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ A fascinating new database ranks sea creatures by body size.&lt;br /&gt;+ Talking of oceanic monsters, it’s 50 years since Jaws first terrified us from setting foot in the water.&lt;br /&gt;+ After 62 years, U2’s The Edge is finally an Irish citizen.&lt;br /&gt;+ Fashion regrets? Sarah Jessica Parker has none.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_0"&gt; &lt;p&gt;&lt;em&gt;This is today's edition of&amp;nbsp;The Download&lt;/em&gt;,&lt;em&gt;&amp;nbsp;our weekday newsletter that provides a daily dose of what's going on in the world of technology.&lt;/em&gt;&lt;/p&gt;  &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Namibia wants to build the world’s first hydrogen economy&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_2"&gt; &lt;p&gt;Factories have used fossil fuels to process iron ore for three centuries, and the climate has paid a heavy price: According to the International Energy Agency, the steel industry today accounts for 8% of carbon dioxide emissions.&lt;/p&gt;&lt;p&gt;But it turns out there is a less carbon-­intensive alternative: using hydrogen. Unlike coal or natural gas, which release carbon dioxide as a by-product, this process releases water. And if the hydrogen itself is “green,” the climate impact of the entire process will be minimal.&lt;/p&gt;  &lt;p&gt;HyIron, which has a site in the Namib desert, is one of a handful of companies around the world that are betting green hydrogen can help the $1.8 trillion steel industry clean up its act. The question now is whether Namibia’s government, its trading partners, and hydrogen innovators can work together to build the industry in a way that satisfies the world’s appetite for cleaner fuels—and also helps improve lives at home.&lt;strong&gt; &lt;/strong&gt;Read the full story.&lt;/p&gt; 
 &lt;p&gt;&lt;em&gt;—Jonathan W. Rosen&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;This story is from the next print edition of MIT Technology Review, which explores power—who has it, and who wants it. It’s set to go live tomorrow, so &lt;/strong&gt;&lt;strong&gt;subscribe &amp;amp; save 25%&lt;/strong&gt;&lt;strong&gt; to read it and get a copy of the issue when it lands!&lt;/strong&gt;&lt;/p&gt; 
   &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Can we fix AI’s evaluation crisis?&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Every time a company launches a new AI model, its scores show it beating the capabilities of predecessors. On paper, everything appears to be getting better all the time.&lt;/p&gt;  &lt;p&gt;In practice, it’s not so simple. In fact, many now openly admit that the process of testing AI, using sets of exam-style questions called benchmarks, is broken.&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_4"&gt; &lt;p&gt;In response, a growing number of teams around the world are trying to address the AI evaluation crisis. One of them is Xbench, a benchmark project developed by HongShan Capital Group (formerly Sequoia China). It evaluates models not only on the ability to pass arbitrary tests, like most other benchmarks, but also on the ability to execute real-world tasks, which is more unusual. It’s also updated on a regular basis to try to keep it evergreen.&lt;/p&gt;  &lt;p&gt;Read more about Xbench in our story, and more about the broader efforts to tackle the evaluation crisis in this week’s edition of The Algorithm, our weekly newsletter about the latest goings-on in the world of AI.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Caiwei Chen&lt;/em&gt;&lt;/p&gt;   

 &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The Anthropocene illusion&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;Over six years and across four continents, the London-based documentary photographer Zed Nelson has examined how humans have immersed themselves in increasingly simulated environments to mask their destructive divorce from the natural world.&lt;/p&gt;&lt;p&gt;Featuring everything from theme parks and zoos to national parks and African safaris, his images reveal not only a desperate craving for a connection to a world we have turned our back on but also a global phenomenon of denial and collective self-­delusion. Check out a selection of his arresting images here.&lt;/p&gt;&lt;p&gt;&lt;em&gt;—Allison Arieff&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;The must-reads&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_6"&gt; &lt;p&gt;&lt;em&gt;I’ve combed the internet to find you today’s most fun/important/scary/fascinating stories about technology.&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;1 US auto safety regulators are investigating Tesla’s robotaxis&amp;nbsp;&lt;/strong&gt;&lt;br /&gt;They’re probing incidents where the vehicles appear to violate traffic laws. (Bloomberg $)&lt;br /&gt;+ &lt;em&gt;One video depicts a robotaxi driving on the wrong side of the road. &lt;/em&gt;(The Verge)&lt;br /&gt;+ &lt;em&gt;The probe has started just one day after the service launched in Texas. &lt;/em&gt;(TechCrunch)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;2 Officials fear Iran is planning a cyber retaliation&lt;br /&gt;&lt;/strong&gt;Iran-linked groups could cause quite a bit of havoc in the US. (WP $)&lt;br /&gt;+ &lt;em&gt;The US says the conflict has triggered a "heightened threat environment." &lt;/em&gt;(Axios)&lt;br /&gt;+ &lt;em&gt;Donald Trump has set off a whole new wave of bombing disinformation. &lt;/em&gt;(Wired $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;3 Caregivers are struggling to cope with measles outbreaks&lt;br /&gt;&lt;/strong&gt;The virus is infecting children and adults alike around the US. (NYT $)&lt;br /&gt;+ &lt;em&gt;RFK Jr’s planned dietary guideline shakeup is severely lacking. &lt;/em&gt;(The Atlantic $)&lt;br /&gt;+ &lt;em&gt;How measuring vaccine hesitancy could help health professionals tackle it. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;4 A man was killed by police after speaking with ChatGPT&lt;/strong&gt;&lt;br /&gt;Alex Taylor, who struggled with his mental health, was convinced OpenAI had “killed” an entity called Juliet. (Rolling Stone $)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;5 WhatsApp has been banned from US House of Representatives devices&lt;br /&gt;&lt;/strong&gt;The Office of Cybersecurity believes it poses a high risk to data security. (The Guardian)&lt;br /&gt;+ &lt;em&gt;Another app banned from the same devices? TikTok. &lt;/em&gt;(Reuters)&lt;/p&gt; 
 &lt;p&gt;&lt;strong&gt;6 How AI is opening up a new digital divide&lt;/strong&gt;&lt;br /&gt;Between the nations with the computing power to build it, and the ones without. (NYT $)&lt;br /&gt;+ &lt;em&gt;Meta’s data center is not winning over communities in Louisiana. &lt;/em&gt;(404 Media)&lt;br /&gt;+ &lt;em&gt;The UAE wants to spend its way to becoming a tech superpower. &lt;/em&gt;(Rest of World)&lt;br /&gt;+ &lt;em&gt;We did the math on AI’s energy footprint. Here’s the story you haven’t heard. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;7 China’s EV factories are a must-see for tourists&lt;br /&gt;&lt;/strong&gt;Tens of thousands of people enter draws for the privilege each month. (Wired $)&lt;br /&gt;+ &lt;em&gt;China’s EV giants are betting big on humanoid robots. &lt;/em&gt;(MIT Technology Review)&lt;br /&gt;&lt;strong&gt;&lt;br /&gt;8 Meta’s AI model has memorized nearly all of the first Harry Potter book&lt;br /&gt;&lt;/strong&gt;Which suggests it’s storing books, rather than training on them. (404 Media)&lt;/p&gt; &lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_8"&gt; &lt;p&gt;&lt;strong&gt;9 How to get people to behave better online&lt;/strong&gt;&lt;br /&gt;Suspensions really work. (Fast Company $)&lt;br /&gt;+ &lt;em&gt;How to fix the internet. &lt;/em&gt;(MIT Technology Review)&lt;/p&gt;  &lt;p&gt;&lt;strong&gt;10 Elon Musk does not use a computer &lt;/strong&gt;&lt;strong&gt;💻&lt;/strong&gt;&lt;strong&gt;&lt;br /&gt;&lt;/strong&gt;That’s his lawyers’ story, and they’re sticking to it. (Wired $)&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;Quote of the day&lt;/strong&gt;&lt;/p&gt; 
 &lt;p class="has-large-font-size"&gt;&lt;strong&gt;“It’s like announcing that, ‘I’m going to Mars’ and then, you know, going to Cleveland.”&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;—Bryant Walker Smith, a University of South Carolina law professor, pokes fun at Elon Musk’s autonomous ride-hailing ambitions, Reuters reports.&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;One more thing&lt;/strong&gt;&lt;/p&gt; 
&lt;/div&gt;&lt;/div&gt;&lt;div&gt;&lt;div class="gutenbergContent__content--109b03a769a11e8ae3acbab352a64269 html_10"&gt;&lt;figure class="wp-block-image size-large"&gt;&lt;img alt="alt" src="https://wp.technologyreview.com/wp-content/uploads/2024/02/0511013_01.jpg?fit=1064,598" /&gt;&lt;/figure&gt;  &lt;p&gt;&lt;strong&gt;Inside the hunt for new physics at the world’s largest particle collider&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;In 2012, using data from CERN’s Large Hadron Collider, researchers discovered a particle called the Higgs boson. In the process, they answered a nagging question: Where do fundamental particles, such as the ones that make up all the protons and neutrons in our bodies, get their mass?&lt;/p&gt;&lt;p&gt;When the particle was finally found, scientists celebrated with champagne. A Nobel for two of the physicists who predicted the Higgs boson soon followed.&lt;/p&gt;&lt;p&gt;But now, more than a decade later, there is a sense of unease. That’s because there are still so many unanswered questions about the fundamental constituents of the universe.&lt;/p&gt;&lt;p&gt;So researchers are trying something new. They are repurposing detectors to search for unusual-looking particles, squeezing what they can out of the data with machine learning, and planning for entirely new kinds of colliders. Read the full story.&lt;/p&gt;  &lt;p&gt;&lt;em&gt;—Dan Garisto&lt;/em&gt;&lt;/p&gt;    &lt;p class="has-medium-font-size"&gt;&lt;strong&gt;We can still have nice things&lt;/strong&gt;&lt;/p&gt;  &lt;p&gt;&lt;em&gt;A place for comfort, fun and distraction to brighten up your day. (Got any ideas? &lt;/em&gt;&lt;em&gt;Drop me a line&lt;/em&gt;&lt;em&gt; or &lt;/em&gt;&lt;em&gt;skeet 'em at me&lt;/em&gt;&lt;em&gt;.)&lt;/em&gt;&lt;/p&gt;  &lt;p&gt;+ A fascinating new database ranks sea creatures by body size.&lt;br /&gt;+ Talking of oceanic monsters, it’s 50 years since Jaws first terrified us from setting foot in the water.&lt;br /&gt;+ After 62 years, U2’s The Edge is finally an Irish citizen.&lt;br /&gt;+ Fashion regrets? Sarah Jessica Parker has none.&lt;svg class="monogramTLogo" viewBox="0 0 1091.84 1091.84" xmlns="http://www.w3.org/2000/svg"&gt;&lt;polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"&gt;&lt;polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"&gt;&lt;polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"&gt;&lt;/svg&gt; &lt;/p&gt;&lt;/div&gt;&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://www.technologyreview.com/2025/06/24/1119282/the-download-namibias-hydrogen-hopes-and-fixing-ai-evaluation/</guid><pubDate>Tue, 24 Jun 2025 12:10:00 +0000</pubDate></item><item><title>[NEW] How a data-processing problem at Lyft became the basis for Eventual (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/24/how-a-data-processing-problem-at-lyft-became-the-basis-for-eventual/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/DSC01886.jpg?resize=1200,727" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Eventual founders Sammy Sidhu and Jay Chia were working as software engineers at Lyft’s autonomous vehicle program, they witnessed a brewing data infrastructure problem — one that would only become larger with the rise of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Self-driving cars produce a ton of unstructured data from 3D scans and photos to text and audio. There wasn’t a tool for Lyft engineers that could understand and process all of those different types of data at the same time — and all in one place. This left engineers to piece together open source tools in a lengthy process with reliability issues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We had all these brilliant PhDs, brilliant folks across the industry, working on autonomous vehicles but they’re spending like 80% of their time working on infrastructure rather than building their core application,” Sidhu, who is Eventual’s CEO, told TechCrunch in a recent interview. “And most of these problems that they were facing were around data infrastructure.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sidhu and Chia helped build an internal multimodal data processing tool for Lyft. When Sidhu set out to apply to other jobs, he found interviewers kept asking him about potentially building the same data solution for their companies, and the idea behind Eventual was born.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eventual built a Python-native open source data processing engine, known as Daft, that is designed to work quickly across different modalities from text to audio and video, and more. Sidhu said the goal is to make Daft as transformational to unstructured data infrastructure as SQL was to tabular datasets in the past.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded in early 2022, nearly a year before ChatGPT was released, and before many people were aware of this data infrastructure gap. They launched the first open source version of Daft in 2022 and are gearing up to launch an enterprise product in the third quarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The explosion of ChatGPT, what we saw is just a lot of other folks who are then building AI applications with different types of modalities,” Sidhu said. “Then everyone started kind of like using things like images and documents and videos in their applications. And that’s kind of where we saw usage just [increase] dramatically.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;While the original idea behind building Daft stemmed from the autonomous vehicle space, there are numerous other industries that process multimodal data, including robotics, retail tech, and healthcare. The company now counts Amazon, CloudKitchens, and Together AI, among others, as customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eventual recently raised two rounds of funding within eight months. The first was a $7.5 million seed round led by CRV. More recently, the company raised a $20 million Series A round led by Felicis with participation from Microsoft’s M12 and Citi.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This latest round will go toward bulking up Eventual’s open source offering as well as creating a commercial product that will allow its customers to build AI applications off of this processed data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Astasia Myers, a general partner at Felicis, told TechCrunch that she found Eventual through a market mapping exercise that involved looking for data infrastructure that would be able to support the growing number of multimodal AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Myers said that Eventual stood out for being a first mover in the space —&amp;nbsp;which will likely get more crowded — and based on the fact that the founders had dealt with this data processing problem firsthand. She added that Eventual is also solving a growing problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The multimodal AI industry is predicted to grow at a 35% compound annual growth rate between 2023 and 2028, according to management consulting firm MarketsandMarkets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Annual data generation is up 1,000x over the past 20 years and 90% of the world’s data was generated in the past two years, and according to IDC, the vast majority of data is unstructured,” Myers said. “Daft fits into this huge macro trend of generative AI being built around text, image, video, and voice. You need a multimodal-native data processing engine.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/06/DSC01886.jpg?resize=1200,727" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;When Eventual founders Sammy Sidhu and Jay Chia were working as software engineers at Lyft’s autonomous vehicle program, they witnessed a brewing data infrastructure problem — one that would only become larger with the rise of AI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Self-driving cars produce a ton of unstructured data from 3D scans and photos to text and audio. There wasn’t a tool for Lyft engineers that could understand and process all of those different types of data at the same time — and all in one place. This left engineers to piece together open source tools in a lengthy process with reliability issues.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“We had all these brilliant PhDs, brilliant folks across the industry, working on autonomous vehicles but they’re spending like 80% of their time working on infrastructure rather than building their core application,” Sidhu, who is Eventual’s CEO, told TechCrunch in a recent interview. “And most of these problems that they were facing were around data infrastructure.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Sidhu and Chia helped build an internal multimodal data processing tool for Lyft. When Sidhu set out to apply to other jobs, he found interviewers kept asking him about potentially building the same data solution for their companies, and the idea behind Eventual was born.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eventual built a Python-native open source data processing engine, known as Daft, that is designed to work quickly across different modalities from text to audio and video, and more. Sidhu said the goal is to make Daft as transformational to unstructured data infrastructure as SQL was to tabular datasets in the past.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company was founded in early 2022, nearly a year before ChatGPT was released, and before many people were aware of this data infrastructure gap. They launched the first open source version of Daft in 2022 and are gearing up to launch an enterprise product in the third quarter.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“The explosion of ChatGPT, what we saw is just a lot of other folks who are then building AI applications with different types of modalities,” Sidhu said. “Then everyone started kind of like using things like images and documents and videos in their applications. And that’s kind of where we saw usage just [increase] dramatically.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;While the original idea behind building Daft stemmed from the autonomous vehicle space, there are numerous other industries that process multimodal data, including robotics, retail tech, and healthcare. The company now counts Amazon, CloudKitchens, and Together AI, among others, as customers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Eventual recently raised two rounds of funding within eight months. The first was a $7.5 million seed round led by CRV. More recently, the company raised a $20 million Series A round led by Felicis with participation from Microsoft’s M12 and Citi.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This latest round will go toward bulking up Eventual’s open source offering as well as creating a commercial product that will allow its customers to build AI applications off of this processed data.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Astasia Myers, a general partner at Felicis, told TechCrunch that she found Eventual through a market mapping exercise that involved looking for data infrastructure that would be able to support the growing number of multimodal AI models.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Myers said that Eventual stood out for being a first mover in the space —&amp;nbsp;which will likely get more crowded — and based on the fact that the founders had dealt with this data processing problem firsthand. She added that Eventual is also solving a growing problem.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The multimodal AI industry is predicted to grow at a 35% compound annual growth rate between 2023 and 2028, according to management consulting firm MarketsandMarkets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Annual data generation is up 1,000x over the past 20 years and 90% of the world’s data was generated in the past two years, and according to IDC, the vast majority of data is unstructured,” Myers said. “Daft fits into this huge macro trend of generative AI being built around text, image, video, and voice. You need a multimodal-native data processing engine.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/24/how-a-data-processing-problem-at-lyft-became-the-basis-for-eventual/</guid><pubDate>Tue, 24 Jun 2025 13:00:00 +0000</pubDate></item><item><title>[NEW] Google rolls out new Gemini model that can run on robots locally (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/24/google-rolls-out-new-gemini-model-that-can-run-on-robots-locally/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind on Tuesday released a new language model called Gemini Robotics On-Device that can run tasks locally on robots without requiring an internet connection. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Building on the company’s previous Gemini Robotics model that was released in March, Gemini Robotics On-Device can control a robot’s movements. Developers can control and fine-tune the model to suit various needs using natural language prompts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In benchmarks, Google claims the model performs at a level close to the cloud-based Gemini Robotics model. The company says it outperforms other on-device models in general benchmarks, though it didn’t name those models.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3021560" height="428" src="https://techcrunch.com/wp-content/uploads/2025/06/image.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In a demo, the company showed robots running this local model doing things like unzipping bags and folding clothes. Google says that while the model was trained for ALOHA robots, it later adapted it to work on a bi-arm Franka FR3 robot and the Apollo humanoid robot by Apptronik.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google claims the bi-arm Franka FR3 was successful in tackling scenarios and objects it hadn’t “seen” before, like doing assembly on an industrial belt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google DeepMind is also releasing a Gemini Robotics SDK. The company said developers can show robots 50 to 100 demonstrations of tasks to train them on new tasks using these models on the MuJoCo physics simulator.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other AI model developers are also dipping their toes in robotics. Nvidia is building a platform to create foundation models for humanoids; Hugging Face is not only developing open models and datasets for robotics, but it is also working on robots; and Mirae Asset-backed Korean startup RLWRLD is working on creating foundational models for robots.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Google DeepMind on Tuesday released a new language model called Gemini Robotics On-Device that can run tasks locally on robots without requiring an internet connection. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Building on the company’s previous Gemini Robotics model that was released in March, Gemini Robotics On-Device can control a robot’s movements. Developers can control and fine-tune the model to suit various needs using natural language prompts.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;In benchmarks, Google claims the model performs at a level close to the cloud-based Gemini Robotics model. The company says it outperforms other on-device models in general benchmarks, though it didn’t name those models.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3021560" height="428" src="https://techcrunch.com/wp-content/uploads/2025/06/image.png?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Google&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;In a demo, the company showed robots running this local model doing things like unzipping bags and folding clothes. Google says that while the model was trained for ALOHA robots, it later adapted it to work on a bi-arm Franka FR3 robot and the Apollo humanoid robot by Apptronik.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google claims the bi-arm Franka FR3 was successful in tackling scenarios and objects it hadn’t “seen” before, like doing assembly on an industrial belt.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google DeepMind is also releasing a Gemini Robotics SDK. The company said developers can show robots 50 to 100 demonstrations of tasks to train them on new tasks using these models on the MuJoCo physics simulator.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other AI model developers are also dipping their toes in robotics. Nvidia is building a platform to create foundation models for humanoids; Hugging Face is not only developing open models and datasets for robotics, but it is also working on robots; and Mirae Asset-backed Korean startup RLWRLD is working on creating foundational models for robots.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/24/google-rolls-out-new-gemini-model-that-can-run-on-robots-locally/</guid><pubDate>Tue, 24 Jun 2025 14:00:00 +0000</pubDate></item><item><title>[NEW] Gemini Robotics On-Device brings AI to local robotic devices (Google DeepMind Blog)</title><link>https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1200-h630-n-nu" /&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;We gratefully acknowledge contributions, advice, and support from Abbas Abdolmaleki, Saminda Abeyruwan, Joshua Ainslie, Jean-Baptiste Alayrac, Montserrat Gonzalez Arenas, Travis Armstrong, Maria Attarian, Ashwin Balakrishna, Yanan Bao, Clara Barbu, Catarina Barros, Robert Baruch, Nathan Batchelor, Maria Bauza, Lucas Beyer, Michael Bloesch, Michiel Blokzijl, Steven Bohez, Konstantinos Bousmalis, Demetra Brady, Philemon Brakel, Anthony Brohan, Thomas Buschmann, Arunkumar Byravan, Kendra Byrne, Serkan Cabi, Ken Caluwaerts, Federico Casarini, Christine Chan, Oscar Chang, Jose Enrique Chen, Xi Chen, Huizhong Chen, Hao-Tien Lewis Chiang, Krzysztof Choromanski, Adrian Collister, Kieran Connell, David D'Ambrosio, Sudeep Dasari, Todor Davchev, Coline Devin, Norman Di Palo, Tianli Ding, Adil Dostmohamed, Anca Dragan, Yilun Du, Debidatta Dwibedi, Michael Elabd, Tom Erez, Claudio Fantacci, Cody Fong, Erik Frey, Chuyuan Fu, Frankie Garcia, Ashley Gibb, Marissa Giustina, Keerthana Gopalakrishnan, Laura Graesser, Simon Green, Oliver Groth, Roland Hafner, Leonard Hasenclever, Sam Haves, Nicolas Heess, Brandon Hernaez, Tim Hertweck, Alexander Herzog, R. Alex Hofer, Sandy H Huang, Jan Humplik , Atil Iscen, Mithun George Jacob, Deepali Jain, Sally Jesmonth, Ryan Julian, Dmitry Kalashnikov, M. Emre Karagozler, Stefani Karp, Chase Kew, Jerad Kirkland, Sean Kirmani, Yuheng Kuang, Thomas Lampe, Antoine Laurens, Isabel Leal, Alex X. Lee, Tsang-Wei Edward Lee, Jennie Lees, Jacky Liang, Yixin Lin, Li-Heng Lin, Caden Lu, Sharath Maddineni, Anirudha Majumdar, Kevis-Kokitsi Maninis, Siobhan Mcloughlin, Assaf Hurwitz Michaely, Joss Moore, Robert Moreno, Thomas Mulc, Michael Neunert, Francesco Nori, Dave Orr, Carolina Parada, Emilio Parisotto, Peter Pastor, André Susano Pinto, Acorn Pooley, Grace Popple, Thomas Power, Alessio Quaglino, Haroon Qureshi, Kanishka Rao, Dushyant Rao, Krista Reymann, Martin Riedmiller, Francesco Romano, Keran Rong, Dorsa Sadigh, Stefano Saliceti, Daniel Salz, Pannag Sanketi, Mili Sanwalka, Kevin Sayed, Pierre Sermanet, Dhruv Shah, Mohit Sharma, Kathryn Shea, Mohit Shridhar, Charles Shu, Vikas Sindhwani, Sumeet Singh, Radu Soricut, Andreas Steiner, Rachel Sterneck, Ian Storz, Razvan Surdulescu, Ben Swanson, Mitri Syriani, Jie Tan, Yuval Tassa, Alan Thompson, Dhruva Tirumala, Jonathan Tompson, Karen Truong, Jake Varley, Siddharth Verma, Grace Vesom, Giulia Vezzani, Oriol Vinyals, Ayzaan Wahid, Zhicheng Wang, Stefan Welker, Paul Wohlhart, Chengda Wu, Markus Wulfmeier, Fei Xia, Ted Xiao, Annie Xie, Jinyu Xie, Peng Xu, Sichun Xu, Ying Xu, Zhuo Xu, Yuxiang Yang, Rui Yao, Sergey Yaroshenko, Matt Young, Wenhao Yu, Wentao Yuan, Martina Zambelli, Xiaohua Zhai, Jingwei Zhang, Tingnan Zhang, Allan Zhou, Yuxiang Zhou, Guangyao (Stannis) Zhou, Howard Zhou.&lt;/p&gt;&lt;p&gt;We also thank the operations and support staff that performed data collection and robot evaluations for this project.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://lh3.googleusercontent.com/Jt_Vw7PIJEZtXcMIKM1HbWbBCLxv7RUyjyf07eHp-YOfxMCUZA6mPI9kSCaz65UkMoGcZ8CwlD3dNBvy7bnnYchjSkWyN-SugglT3dmg1A9KdoDqdQM=w1200-h630-n-nu" /&gt;&lt;/div&gt;&lt;p&gt;&lt;strong&gt;Acknowledgements&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;We gratefully acknowledge contributions, advice, and support from Abbas Abdolmaleki, Saminda Abeyruwan, Joshua Ainslie, Jean-Baptiste Alayrac, Montserrat Gonzalez Arenas, Travis Armstrong, Maria Attarian, Ashwin Balakrishna, Yanan Bao, Clara Barbu, Catarina Barros, Robert Baruch, Nathan Batchelor, Maria Bauza, Lucas Beyer, Michael Bloesch, Michiel Blokzijl, Steven Bohez, Konstantinos Bousmalis, Demetra Brady, Philemon Brakel, Anthony Brohan, Thomas Buschmann, Arunkumar Byravan, Kendra Byrne, Serkan Cabi, Ken Caluwaerts, Federico Casarini, Christine Chan, Oscar Chang, Jose Enrique Chen, Xi Chen, Huizhong Chen, Hao-Tien Lewis Chiang, Krzysztof Choromanski, Adrian Collister, Kieran Connell, David D'Ambrosio, Sudeep Dasari, Todor Davchev, Coline Devin, Norman Di Palo, Tianli Ding, Adil Dostmohamed, Anca Dragan, Yilun Du, Debidatta Dwibedi, Michael Elabd, Tom Erez, Claudio Fantacci, Cody Fong, Erik Frey, Chuyuan Fu, Frankie Garcia, Ashley Gibb, Marissa Giustina, Keerthana Gopalakrishnan, Laura Graesser, Simon Green, Oliver Groth, Roland Hafner, Leonard Hasenclever, Sam Haves, Nicolas Heess, Brandon Hernaez, Tim Hertweck, Alexander Herzog, R. Alex Hofer, Sandy H Huang, Jan Humplik , Atil Iscen, Mithun George Jacob, Deepali Jain, Sally Jesmonth, Ryan Julian, Dmitry Kalashnikov, M. Emre Karagozler, Stefani Karp, Chase Kew, Jerad Kirkland, Sean Kirmani, Yuheng Kuang, Thomas Lampe, Antoine Laurens, Isabel Leal, Alex X. Lee, Tsang-Wei Edward Lee, Jennie Lees, Jacky Liang, Yixin Lin, Li-Heng Lin, Caden Lu, Sharath Maddineni, Anirudha Majumdar, Kevis-Kokitsi Maninis, Siobhan Mcloughlin, Assaf Hurwitz Michaely, Joss Moore, Robert Moreno, Thomas Mulc, Michael Neunert, Francesco Nori, Dave Orr, Carolina Parada, Emilio Parisotto, Peter Pastor, André Susano Pinto, Acorn Pooley, Grace Popple, Thomas Power, Alessio Quaglino, Haroon Qureshi, Kanishka Rao, Dushyant Rao, Krista Reymann, Martin Riedmiller, Francesco Romano, Keran Rong, Dorsa Sadigh, Stefano Saliceti, Daniel Salz, Pannag Sanketi, Mili Sanwalka, Kevin Sayed, Pierre Sermanet, Dhruv Shah, Mohit Sharma, Kathryn Shea, Mohit Shridhar, Charles Shu, Vikas Sindhwani, Sumeet Singh, Radu Soricut, Andreas Steiner, Rachel Sterneck, Ian Storz, Razvan Surdulescu, Ben Swanson, Mitri Syriani, Jie Tan, Yuval Tassa, Alan Thompson, Dhruva Tirumala, Jonathan Tompson, Karen Truong, Jake Varley, Siddharth Verma, Grace Vesom, Giulia Vezzani, Oriol Vinyals, Ayzaan Wahid, Zhicheng Wang, Stefan Welker, Paul Wohlhart, Chengda Wu, Markus Wulfmeier, Fei Xia, Ted Xiao, Annie Xie, Jinyu Xie, Peng Xu, Sichun Xu, Ying Xu, Zhuo Xu, Yuxiang Yang, Rui Yao, Sergey Yaroshenko, Matt Young, Wenhao Yu, Wentao Yuan, Martina Zambelli, Xiaohua Zhai, Jingwei Zhang, Tingnan Zhang, Allan Zhou, Yuxiang Zhou, Guangyao (Stannis) Zhou, Howard Zhou.&lt;/p&gt;&lt;p&gt;We also thank the operations and support staff that performed data collection and robot evaluations for this project.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://deepmind.google/discover/blog/gemini-robotics-on-device-brings-ai-to-local-robotic-devices/</guid><pubDate>Tue, 24 Jun 2025 14:00:36 +0000</pubDate></item><item><title>[NEW] Google’s new robotics AI can run without the cloud and still tie your shoes (AI – Ars Technica)</title><link>https://arstechnica.com/google/2025/06/google-releases-first-cloud-free-ai-robotics-model/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google's Carolina Parada says Gemini has enabled huge robotics breakthroughs, like the new on-device AI.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Apollo robot" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robotics-SocialShare_1920x1080.width-1300-640x360.png" width="640" /&gt;
                  &lt;img alt="Apollo robot" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robotics-SocialShare_1920x1080.width-1300-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The humanoid Apollo robot is one of the platforms supported in Gemini Robotics. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;We sometimes call chatbots like Gemini and ChatGPT "robots," but generative AI is also playing a growing role in real, physical robots. After announcing Gemini Robotics earlier this year, Google DeepMind has now revealed a new on-device VLA (vision language action) model to control robots. Unlike the previous release, there's no cloud component, allowing robots to operate with full autonomy.&lt;/p&gt;
&lt;p&gt;Carolina Parada, head of robotics at Google DeepMind, says this approach to AI robotics could make robots more reliable in challenging situations. This is also the first version of Google's robotics model that developers can tune for their specific uses.&lt;/p&gt;
&lt;p&gt;Robotics is a unique problem for AI because, not only does the robot exist in the physical world, but it also changes its environment. Whether you're having it move blocks around or tie your shoes, it's hard to predict every eventuality a robot might encounter. The traditional approach of training a robot on action with reinforcement was very slow, but generative AI allows for much greater generalization.&lt;/p&gt;
&lt;p&gt;"It's drawing from Gemini's multimodal world understanding in order to do a completely new task," explains Carolina Parada. "What that enables is in that same way Gemini can produce text, write poetry, just summarize an article, you can also write code, and you can also generate images. It also can generate robot actions."&lt;/p&gt;
&lt;h2&gt;General robots, no cloud needed&lt;/h2&gt;
&lt;p&gt;In the previous Gemini Robotics release (which is still the "best" version of Google's robotics tech), the platforms ran a hybrid system with a small model on the robot and a larger one running in the cloud. You've probably watched chatbots "think" for measurable seconds as they generate an output, but robots need to react quickly. If you tell the robot to pick up and move an object, you don't want it to pause while each step is generated. The local model allows quick adaptation, while the server-based model can help with complex reasoning tasks. Google DeepMind is now unleashing the local model as a standalone VLA, and it's surprisingly robust.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2102351-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Dexterity-General-Aloha.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The new Gemini Robotics On-Device model is only a little less accurate than the hybrid version. According to Parada, many tasks will work out of the box. "When we play with the robots, we see that they're surprisingly capable of understanding a new situation," Parada tells Ars.&lt;/p&gt;
&lt;p&gt;By releasing this model with a full SDK, the team hopes developers will give Gemini-powered robots new tasks and show them new environments, which could reveal actions that don't work with the model's stock tuning. With the SDK, robotics researchers will be able to adapt the VLA to new tasks with as little as 50 to 100 demonstrations.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102439 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Robotics On-Device chart" class="fullwidth full" height="476" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/On-Device-Robotics-AI.png" width="756" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new Robotics On-Device model is almost as adaptable as the hybrid model with cloud processing.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;A "demonstration" in AI robotics is a bit different from other areas of AI research. Parada explains that demonstrations typically involve tele-operating the robot—controlling the machinery manually to complete a task tunes the model to handle that task autonomously. While synthetic data is an element of Google's training, it's not a substitute for the real thing. "We still find that in the most complex, dexterous behaviors, we need real data," says Parada. "But there is quite a lot that you can do with simulation."&lt;/p&gt;
&lt;p&gt;But those highly complex behaviors may be beyond the capabilities of the on-device VLA. It should have no problem with straightforward actions like tying a shoe (a traditionally difficult task for AI robots) or folding a shirt. If, however, you wanted a robot to make you a sandwich, it would probably need a more powerful model to go through the multi-step reasoning required to get the bread in the right place.&lt;/p&gt;
&lt;p&gt;The team sees Gemini Robotics On-Device as ideal for environments where connectivity to the cloud is spotty or non-existent. Processing the robot's visual data locally is also better for privacy, for example, in a health care environment.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Building safe robots&lt;/h2&gt;
&lt;p&gt;Safety is always a concern with AI systems, whether it's a chatbot that provides dangerous information or a robot that goes Terminator. We've all seen generative AI chatbots and image generators hallucinate falsehoods in their outputs, and the generative systems powering Gemini Robotics are no different—the model doesn't get it right every time, but giving the model a physical embodiment with cold, unfeeling metal graspers makes the issue a little more thorny.&lt;/p&gt;
&lt;p&gt;To ensure robots behave safely, Gemini Robotics uses a multi-layered approach. "With the full Gemini Robotics, you are connecting to a model that is reasoning about what is safe to do, period," says Parada. "And then you have it talk to a VLA that actually produces options, and then that VLA calls a low-level controller, which typically has safety-critical components, like how much force you can move or how fast you can move this arm."&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2102351-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robustness-Omega-Star.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Importantly, the new on-device model is just a VLA, so developers will be on their own to build in safety. Google suggests they replicate what the Gemini team has done, though. It's recommended that developers in the early tester program connect the system to the standard Gemini Live API, which includes a safety layer. They should also implement a low-level controller for critical safety checks.&lt;/p&gt;
&lt;p&gt;Anyone interested in testing Gemini Robotics On-Device should apply for access to Google's trusted tester program. Google's Carolina Parada says there have been a lot of robotics breakthroughs in the past three years, and this is just the beginning—the current release of Gemini Robotics is still based on Gemini 2.0. Parada notes that the Gemini Robotics team typically trails behind Gemini development by one version, and Gemini 2.5 has been cited as a massive improvement in chatbot functionality. Maybe the same will be true of robots.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Google's Carolina Parada says Gemini has enabled huge robotics breakthroughs, like the new on-device AI.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="Apollo robot" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robotics-SocialShare_1920x1080.width-1300-640x360.png" width="640" /&gt;
                  &lt;img alt="Apollo robot" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robotics-SocialShare_1920x1080.width-1300-1152x648.png" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The humanoid Apollo robot is one of the platforms supported in Gemini Robotics. 

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;We sometimes call chatbots like Gemini and ChatGPT "robots," but generative AI is also playing a growing role in real, physical robots. After announcing Gemini Robotics earlier this year, Google DeepMind has now revealed a new on-device VLA (vision language action) model to control robots. Unlike the previous release, there's no cloud component, allowing robots to operate with full autonomy.&lt;/p&gt;
&lt;p&gt;Carolina Parada, head of robotics at Google DeepMind, says this approach to AI robotics could make robots more reliable in challenging situations. This is also the first version of Google's robotics model that developers can tune for their specific uses.&lt;/p&gt;
&lt;p&gt;Robotics is a unique problem for AI because, not only does the robot exist in the physical world, but it also changes its environment. Whether you're having it move blocks around or tie your shoes, it's hard to predict every eventuality a robot might encounter. The traditional approach of training a robot on action with reinforcement was very slow, but generative AI allows for much greater generalization.&lt;/p&gt;
&lt;p&gt;"It's drawing from Gemini's multimodal world understanding in order to do a completely new task," explains Carolina Parada. "What that enables is in that same way Gemini can produce text, write poetry, just summarize an article, you can also write code, and you can also generate images. It also can generate robot actions."&lt;/p&gt;
&lt;h2&gt;General robots, no cloud needed&lt;/h2&gt;
&lt;p&gt;In the previous Gemini Robotics release (which is still the "best" version of Google's robotics tech), the platforms ran a hybrid system with a small model on the robot and a larger one running in the cloud. You've probably watched chatbots "think" for measurable seconds as they generate an output, but robots need to react quickly. If you tell the robot to pick up and move an object, you don't want it to pause while each step is generated. The local model allows quick adaptation, while the server-based model can help with complex reasoning tasks. Google DeepMind is now unleashing the local model as a standalone VLA, and it's surprisingly robust.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2102351-1" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Dexterity-General-Aloha.mp4?_=1" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;The new Gemini Robotics On-Device model is only a little less accurate than the hybrid version. According to Parada, many tasks will work out of the box. "When we play with the robots, we see that they're surprisingly capable of understanding a new situation," Parada tells Ars.&lt;/p&gt;
&lt;p&gt;By releasing this model with a full SDK, the team hopes developers will give Gemini-powered robots new tasks and show them new environments, which could reveal actions that don't work with the model's stock tuning. With the SDK, robotics researchers will be able to adapt the VLA to new tasks with as little as 50 to 100 demonstrations.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2102439 align-fullwidth"&gt;
    &lt;div&gt;
              &lt;div class="ars-lightbox"&gt;
          &lt;div class="ars-lightbox-item"&gt;
            
              &lt;img alt="Robotics On-Device chart" class="fullwidth full" height="476" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/On-Device-Robotics-AI.png" width="756" /&gt;
            
            
          &lt;/div&gt;
        &lt;/div&gt;
          &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      The new Robotics On-Device model is almost as adaptable as the hybrid model with cloud processing.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Google

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;A "demonstration" in AI robotics is a bit different from other areas of AI research. Parada explains that demonstrations typically involve tele-operating the robot—controlling the machinery manually to complete a task tunes the model to handle that task autonomously. While synthetic data is an element of Google's training, it's not a substitute for the real thing. "We still find that in the most complex, dexterous behaviors, we need real data," says Parada. "But there is quite a lot that you can do with simulation."&lt;/p&gt;
&lt;p&gt;But those highly complex behaviors may be beyond the capabilities of the on-device VLA. It should have no problem with straightforward actions like tying a shoe (a traditionally difficult task for AI robots) or folding a shirt. If, however, you wanted a robot to make you a sandwich, it would probably need a more powerful model to go through the multi-step reasoning required to get the bread in the right place.&lt;/p&gt;
&lt;p&gt;The team sees Gemini Robotics On-Device as ideal for environments where connectivity to the cloud is spotty or non-existent. Processing the robot's visual data locally is also better for privacy, for example, in a health care environment.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;h2&gt;Building safe robots&lt;/h2&gt;
&lt;p&gt;Safety is always a concern with AI systems, whether it's a chatbot that provides dangerous information or a robot that goes Terminator. We've all seen generative AI chatbots and image generators hallucinate falsehoods in their outputs, and the generative systems powering Gemini Robotics are no different—the model doesn't get it right every time, but giving the model a physical embodiment with cold, unfeeling metal graspers makes the issue a little more thorny.&lt;/p&gt;
&lt;p&gt;To ensure robots behave safely, Gemini Robotics uses a multi-layered approach. "With the full Gemini Robotics, you are connecting to a model that is reasoning about what is safe to do, period," says Parada. "And then you have it talk to a VLA that actually produces options, and then that VLA calls a low-level controller, which typically has safety-critical components, like how much force you can move or how fast you can move this arm."&lt;/p&gt;
&lt;figure class="video ars-wp-video"&gt;
  &lt;div class="wrapper ars-wp-video-wrapper relative"&gt;
    &lt;video class="wp-video-shortcode absolute w-full h-full object-cover left-0 top-0" controls="controls" height="1080" id="video-2102351-2" preload="metadata" width="1920"&gt;&lt;source src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/Robustness-Omega-Star.mp4?_=2" type="video/mp4" /&gt;&lt;/video&gt;
  &lt;/div&gt;

  &lt;figcaption&gt;
    &lt;span class="icon caption-arrow icon-drop-indicator"&gt;&lt;/span&gt;
      &lt;/figcaption&gt;
&lt;/figure&gt;

&lt;p&gt;Importantly, the new on-device model is just a VLA, so developers will be on their own to build in safety. Google suggests they replicate what the Gemini team has done, though. It's recommended that developers in the early tester program connect the system to the standard Gemini Live API, which includes a safety layer. They should also implement a low-level controller for critical safety checks.&lt;/p&gt;
&lt;p&gt;Anyone interested in testing Gemini Robotics On-Device should apply for access to Google's trusted tester program. Google's Carolina Parada says there have been a lot of robotics breakthroughs in the past three years, and this is just the beginning—the current release of Gemini Robotics is still based on Gemini 2.0. Parada notes that the Gemini Robotics team typically trails behind Gemini development by one version, and Gemini 2.5 has been cited as a massive improvement in chatbot functionality. Maybe the same will be true of robots.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/google/2025/06/google-releases-first-cloud-free-ai-robotics-model/</guid><pubDate>Tue, 24 Jun 2025 14:00:41 +0000</pubDate></item><item><title>[NEW] A federal judge sides with Anthropic in lawsuit over training AI on books without authors’ permission (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/24/a-federal-judge-sides-with-anthropic-in-lawsuit-over-training-ai-on-books-without-authors-permission/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/10/GettyImages-1243240042-1.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Federal judge William Alsup ruled that it was legal for Anthropic to train its AI models on published books without the authors’ permission. This marks the first time that the courts have given credence to AI companies’ claim that fair use doctrine can absolve AI companies from fault when they use copyrighted materials to train large language models (LLMs).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This decision comes as a blow to authors, artists, and publishers who have brought dozens of lawsuits against companies like OpenAI, Meta, Midjourney, Google, and more. While the ruling is not a guarantee that other judges will follow Judge Alsup’s lead, it lays the foundation for courts to side with tech companies over creatives.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These lawsuits often depend on how a judge interprets fair use doctrine, a notoriously finicky carve-out of copyright law that hasn’t been updated since 1976 — a time before the internet, let alone the concept of generative AI training sets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fair use rulings take into account what the work is being used for (parody and education can be viable), whether it’s being reproduced for commercial gain (you can write “Star Wars” fan fiction, but you can’t sell it), and how transformative a derivative work is from the original.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like Meta have made similar fair use arguments in defense of training on copyrighted works, though before this week’s decision, it was less clear how the courts would sway.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this particular case, Bartz v. Anthropic, the group of plaintiff authors also brought into question the manner in which Anthropic attained and stored their works. According to the lawsuit, Anthropic sought to create a “central library” of “all the books in the world” to keep “forever.” But millions of these copyrighted books were downloaded for free from pirate sites, which is unambiguously illegal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the judge granted that Anthropic’s training of these materials was a fair use, the court will hold a trial about the nature of the “central library.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“We will have a trial on the pirated copies used to create Anthropic’s central library and the resulting damages,” Judge Alsup wrote in the decision. “That Anthropic later bought a copy of a book it earlier stole off the internet will not absolve it of liability for theft but it may affect the extent of statutory damages.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2022/10/GettyImages-1243240042-1.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Federal judge William Alsup ruled that it was legal for Anthropic to train its AI models on published books without the authors’ permission. This marks the first time that the courts have given credence to AI companies’ claim that fair use doctrine can absolve AI companies from fault when they use copyrighted materials to train large language models (LLMs).&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This decision comes as a blow to authors, artists, and publishers who have brought dozens of lawsuits against companies like OpenAI, Meta, Midjourney, Google, and more. While the ruling is not a guarantee that other judges will follow Judge Alsup’s lead, it lays the foundation for courts to side with tech companies over creatives.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;These lawsuits often depend on how a judge interprets fair use doctrine, a notoriously finicky carve-out of copyright law that hasn’t been updated since 1976 — a time before the internet, let alone the concept of generative AI training sets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fair use rulings take into account what the work is being used for (parody and education can be viable), whether it’s being reproduced for commercial gain (you can write “Star Wars” fan fiction, but you can’t sell it), and how transformative a derivative work is from the original.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Companies like Meta have made similar fair use arguments in defense of training on copyrighted works, though before this week’s decision, it was less clear how the courts would sway.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In this particular case, Bartz v. Anthropic, the group of plaintiff authors also brought into question the manner in which Anthropic attained and stored their works. According to the lawsuit, Anthropic sought to create a “central library” of “all the books in the world” to keep “forever.” But millions of these copyrighted books were downloaded for free from pirate sites, which is unambiguously illegal.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;While the judge granted that Anthropic’s training of these materials was a fair use, the court will hold a trial about the nature of the “central library.”&lt;/p&gt;


&lt;p class="wp-block-paragraph"&gt;“We will have a trial on the pirated copies used to create Anthropic’s central library and the resulting damages,” Judge Alsup wrote in the decision. “That Anthropic later bought a copy of a book it earlier stole off the internet will not absolve it of liability for theft but it may affect the extent of statutory damages.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/24/a-federal-judge-sides-with-anthropic-in-lawsuit-over-training-ai-on-books-without-authors-permission/</guid><pubDate>Tue, 24 Jun 2025 15:17:18 +0000</pubDate></item><item><title>[NEW] Wispr Flow raises $30M from Menlo Ventures for its AI-powered dictation app (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/06/24/wispr-flow-raises-30m-from-menlo-ventures-for-its-ai-powered-dictation-app/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Startups developing voice AI technology and applications are having their moment. Model builders like ElevenLabs and Cartesia have raised millions of dollars in the last few months. Applications such as AI-powered notetaker Granola and meeting tools Read AI and Fireflies AI have also received investor attention and backing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Continuing the trend, dictation app Wispr Flow announced today that it is raising $30 million in Series A funding from Menlo Ventures with participation from NEA, 8VC, Opal&amp;nbsp;CEO Kenneth&amp;nbsp;Schlenker, Pinterest founder Evan Sharp, Carta&amp;nbsp;CEO Henry&amp;nbsp;Ward, and Lindy CEO Flo&amp;nbsp;Crivelli. Menlo Ventures’ Matt Kraning, who also backed the company as an angel investor, will join its board. To date, the company has raised $56 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup’s founder and CEO, Tanay Kothari, started building Wispr to create a device that would allow users to type just by mouthing words silently. Its prior funding was for that business. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, the company instead started focusing on Wispr Flow, the software interface designed for the hardware device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company released a Mac app in October 2024, followed by a Windows app in March 2025 and an iOS app earlier this month. Kothari mentioned that, since its early release, VCs in Silicon Valley have been using the product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think every single tier one venture fund in the valley uses Wispr Flow for their emails, memos, documents, and more. They feel themselves being hooked on it, and it is one of the products they use every day. Because of this, we started getting a lot of inbound,” Kothari said about investor interest. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Granola also had a similar story of receiving immense investor interest because VCs used their product a lot.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3021583" height="677" src="https://techcrunch.com/wp-content/uploads/2025/06/Tanay-headshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Startup’s CEO Tanay Kothari.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Wispr Flow&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kothari also noted that the startup will soon achieve profitability at the current rate of growth, and initially, he didn’t want to raise money. However, he worried that Big Tech players with a massive distribution advantage could be a risk to the company. He wanted to rapidly multiply the company’s revenue and reach and decided to take the investment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Menlo Ventures CEO Matt Kraning, who has been an avid user of the app, said that his initial thesis for Wispr Flow was that with the current set of input methods, like keyboards, we are “waiting for our thumbs to catch up with our thoughts.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Wispr Flow is creating an efficient way to translate digital thoughts and intent. The app captures users’ speech and what they want to convey very well. The team has thought about how people speak while developing models rather than focusing on things like word error rates,” he told TechCrunch.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-user-growth-and-future-roadmap"&gt;User growth and future roadmap&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said that the app has been growing its user base by 50% month-over-month. Kothari noted that 40% of users of the app are in the U.S., 30% in Europe, and 30% in other parts of the world. In addition, more than 30% of the app’s users are from a nontechnical background.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“More and more people are using AI tools, but still, there isn’t a good interface for people who are not techies. ChatGPT-style interface is the most common one, and that was released three and a half years ago. We are building for all kinds of users so they don’t have to write system prompts to interface with AI,” Kothari said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the moment, Wispr Flow supports dictation in 104 languages. Kothari said that 40% of dications are in English, and 60% of them are in the rest of the languages, with Spanish, French, German, Dutch, Hindi, and Mandarin being the top languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company will use the funding to grow its team of 18 with roles in engineering and go-to-market. It will also release an Android app and cater to enterprise users by setting up company-wide phrase context and support teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is working on building Flow into a product that is akin to an AI-powered assistant that knows more about your personal context and helps you do everyday tasks like send messages, take notes, and set reminders. Plus, the company said it’s working with some AI hardware partners, without naming them, to power the interaction layer.&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Startups developing voice AI technology and applications are having their moment. Model builders like ElevenLabs and Cartesia have raised millions of dollars in the last few months. Applications such as AI-powered notetaker Granola and meeting tools Read AI and Fireflies AI have also received investor attention and backing.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Continuing the trend, dictation app Wispr Flow announced today that it is raising $30 million in Series A funding from Menlo Ventures with participation from NEA, 8VC, Opal&amp;nbsp;CEO Kenneth&amp;nbsp;Schlenker, Pinterest founder Evan Sharp, Carta&amp;nbsp;CEO Henry&amp;nbsp;Ward, and Lindy CEO Flo&amp;nbsp;Crivelli. Menlo Ventures’ Matt Kraning, who also backed the company as an angel investor, will join its board. To date, the company has raised $56 million.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The startup’s founder and CEO, Tanay Kothari, started building Wispr to create a device that would allow users to type just by mouthing words silently. Its prior funding was for that business. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last year, the company instead started focusing on Wispr Flow, the software interface designed for the hardware device.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company released a Mac app in October 2024, followed by a Windows app in March 2025 and an iOS app earlier this month. Kothari mentioned that, since its early release, VCs in Silicon Valley have been using the product.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“I think every single tier one venture fund in the valley uses Wispr Flow for their emails, memos, documents, and more. They feel themselves being hooked on it, and it is one of the products they use every day. Because of this, we started getting a lot of inbound,” Kothari said about investor interest. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Notably, Granola also had a similar story of receiving immense investor interest because VCs used their product a lot.&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3021583" height="677" src="https://techcrunch.com/wp-content/uploads/2025/06/Tanay-headshot.jpeg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Startup’s CEO Tanay Kothari.&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Wispr Flow&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Kothari also noted that the startup will soon achieve profitability at the current rate of growth, and initially, he didn’t want to raise money. However, he worried that Big Tech players with a massive distribution advantage could be a risk to the company. He wanted to rapidly multiply the company’s revenue and reach and decided to take the investment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Menlo Ventures CEO Matt Kraning, who has been an avid user of the app, said that his initial thesis for Wispr Flow was that with the current set of input methods, like keyboards, we are “waiting for our thumbs to catch up with our thoughts.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Wispr Flow is creating an efficient way to translate digital thoughts and intent. The app captures users’ speech and what they want to convey very well. The team has thought about how people speak while developing models rather than focusing on things like word error rates,” he told TechCrunch.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-user-growth-and-future-roadmap"&gt;User growth and future roadmap&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;The startup said that the app has been growing its user base by 50% month-over-month. Kothari noted that 40% of users of the app are in the U.S., 30% in Europe, and 30% in other parts of the world. In addition, more than 30% of the app’s users are from a nontechnical background.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“More and more people are using AI tools, but still, there isn’t a good interface for people who are not techies. ChatGPT-style interface is the most common one, and that was released three and a half years ago. We are building for all kinds of users so they don’t have to write system prompts to interface with AI,” Kothari said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;At the moment, Wispr Flow supports dictation in 104 languages. Kothari said that 40% of dications are in English, and 60% of them are in the rest of the languages, with Spanish, French, German, Dutch, Hindi, and Mandarin being the top languages.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company will use the funding to grow its team of 18 with roles in engineering and go-to-market. It will also release an Android app and cater to enterprise users by setting up company-wide phrase context and support teams.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The startup is working on building Flow into a product that is akin to an AI-powered assistant that knows more about your personal context and helps you do everyday tasks like send messages, take notes, and set reminders. Plus, the company said it’s working with some AI hardware partners, without naming them, to power the interaction layer.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/06/24/wispr-flow-raises-30m-from-menlo-ventures-for-its-ai-powered-dictation-app/</guid><pubDate>Tue, 24 Jun 2025 16:00:00 +0000</pubDate></item><item><title>[NEW] HPE and NVIDIA Debut AI Factory Stack to Power Next Industrial Shift (NVIDIA Blog)</title><link>https://blogs.nvidia.com/blog/hpe-nvidia-ai-factory/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/NVIDIA-HPE.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;To speed up AI adoption across industries, HPE and NVIDIA today launched new AI factory offerings at HPE Discover in Las Vegas.&lt;/p&gt;
&lt;p&gt;The new lineup includes everything from modular AI factory infrastructure and HPE’s AI-ready RTX PRO Servers&amp;nbsp; (HPE ProLiant Compute DL380a Gen12), to the next generation of HPE’s turnkey AI platform, HPE Private Cloud AI. The goal: give enterprises a framework to build and scale generative, agentic and industrial AI.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Computing by HPE portfolio is now among the broadest in the market.&lt;/p&gt;
&lt;p&gt;The portfolio combines NVIDIA Blackwell accelerated computing, NVIDIA Spectrum-X Ethernet and NVIDIA BlueField-3 networking technologies, NVIDIA AI Enterprise software, and HPE’s full portfolio of servers, storage, services and software. This now includes HPE OpsRamp Software, a validated observability solution for the NVIDIA Enterprise AI Factory, and HPE Morpheus Enterprise Software for orchestration. The result is a pre-integrated, modular infrastructure stack to help teams get AI into production faster.&lt;/p&gt;
&lt;p&gt;This includes the next-generation HPE Private Cloud AI, co-engineered with NVIDIA and validated as part of the NVIDIA Enterprise AI Factory framework. This full-stack, turnkey AI factory solution will offer HPE ProLiant Compute DL380a Gen12 servers with the new NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs.&lt;/p&gt;
&lt;p&gt;These new NVIDIA RTX PRO Servers from HPE provide a universal data center platform for a wide range of enterprise AI and industrial AI use cases, and are now available to order from HPE. HPE Private Cloud AI includes the latest NVIDIA AI Blueprints, including the NVIDIA AI-Q Blueprint for AI agent creation and workflows.&lt;/p&gt;
&lt;p&gt;HPE also announced a new NVIDIA HGX B300 system, the HPE Compute XD690, built with NVIDIA Blackwell Ultra GPUs. It’s the latest entry in the NVIDIA AI Computing by HPE lineup and is expected to ship in October.&lt;/p&gt;
&lt;p&gt;In Japan, KDDI is working with HPE to build NVIDIA AI infrastructure to accelerate global adoption.&lt;/p&gt;
&lt;p&gt;The HPE-built KDDI system will be based on the NVIDIA GB200 NVL72 platform, built on the NVIDIA Grace Blackwell architecture, at the KDDI Osaka Sakai Data Center.&lt;/p&gt;
&lt;p&gt;To accelerate AI for financial services, HPE will co-test agentic AI workflows built on Accenture’s AI Refinery with NVIDIA, running on HPE Private Cloud AI. Initial use cases include sourcing, procurement and risk analysis.&lt;/p&gt;
&lt;p&gt;HPE said it’s adding 26 new partners to its “Unleash AI” ecosystem to support more NVIDIA AI use cases. The company now offers more than 70 packaged AI workloads, from fraud detection and video analytics to sovereign AI and cybersecurity.&lt;/p&gt;
&lt;p&gt;Security and governance were a focus, too. HPE Private Cloud AI supports air-gapped management, multi-tenancy and post-quantum cryptography. HPE’s try-before-you-buy program lets customers test the system in Equinix data centers before purchase. HPE also introduced new programs, including AI Acceleration Workshops with NVIDIA, to help scale AI deployments.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Watch the keynote: &lt;/b&gt;HPE CEO Antonio Neri announced the news from the Las Vegas Sphere on Tuesday at 9 a.m. PT. Register for the livestream and replay.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Explore more:&lt;/b&gt; Learn how NVIDIA and HPE build AI factories for every industry. Visit the partner page.&lt;/li&gt;
&lt;/ul&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://blogs.nvidia.com/wp-content/uploads/2025/06/NVIDIA-HPE.jpg" /&gt;&lt;/div&gt;&lt;span class="bsf-rt-reading-time"&gt;&lt;span class="bsf-rt-display-label"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-time"&gt;&lt;/span&gt; &lt;span class="bsf-rt-display-postfix"&gt;&lt;/span&gt;&lt;/span&gt;&lt;p&gt;To speed up AI adoption across industries, HPE and NVIDIA today launched new AI factory offerings at HPE Discover in Las Vegas.&lt;/p&gt;
&lt;p&gt;The new lineup includes everything from modular AI factory infrastructure and HPE’s AI-ready RTX PRO Servers&amp;nbsp; (HPE ProLiant Compute DL380a Gen12), to the next generation of HPE’s turnkey AI platform, HPE Private Cloud AI. The goal: give enterprises a framework to build and scale generative, agentic and industrial AI.&lt;/p&gt;
&lt;p&gt;The NVIDIA AI Computing by HPE portfolio is now among the broadest in the market.&lt;/p&gt;
&lt;p&gt;The portfolio combines NVIDIA Blackwell accelerated computing, NVIDIA Spectrum-X Ethernet and NVIDIA BlueField-3 networking technologies, NVIDIA AI Enterprise software, and HPE’s full portfolio of servers, storage, services and software. This now includes HPE OpsRamp Software, a validated observability solution for the NVIDIA Enterprise AI Factory, and HPE Morpheus Enterprise Software for orchestration. The result is a pre-integrated, modular infrastructure stack to help teams get AI into production faster.&lt;/p&gt;
&lt;p&gt;This includes the next-generation HPE Private Cloud AI, co-engineered with NVIDIA and validated as part of the NVIDIA Enterprise AI Factory framework. This full-stack, turnkey AI factory solution will offer HPE ProLiant Compute DL380a Gen12 servers with the new NVIDIA RTX PRO 6000 Blackwell Server Edition GPUs.&lt;/p&gt;
&lt;p&gt;These new NVIDIA RTX PRO Servers from HPE provide a universal data center platform for a wide range of enterprise AI and industrial AI use cases, and are now available to order from HPE. HPE Private Cloud AI includes the latest NVIDIA AI Blueprints, including the NVIDIA AI-Q Blueprint for AI agent creation and workflows.&lt;/p&gt;
&lt;p&gt;HPE also announced a new NVIDIA HGX B300 system, the HPE Compute XD690, built with NVIDIA Blackwell Ultra GPUs. It’s the latest entry in the NVIDIA AI Computing by HPE lineup and is expected to ship in October.&lt;/p&gt;
&lt;p&gt;In Japan, KDDI is working with HPE to build NVIDIA AI infrastructure to accelerate global adoption.&lt;/p&gt;
&lt;p&gt;The HPE-built KDDI system will be based on the NVIDIA GB200 NVL72 platform, built on the NVIDIA Grace Blackwell architecture, at the KDDI Osaka Sakai Data Center.&lt;/p&gt;
&lt;p&gt;To accelerate AI for financial services, HPE will co-test agentic AI workflows built on Accenture’s AI Refinery with NVIDIA, running on HPE Private Cloud AI. Initial use cases include sourcing, procurement and risk analysis.&lt;/p&gt;
&lt;p&gt;HPE said it’s adding 26 new partners to its “Unleash AI” ecosystem to support more NVIDIA AI use cases. The company now offers more than 70 packaged AI workloads, from fraud detection and video analytics to sovereign AI and cybersecurity.&lt;/p&gt;
&lt;p&gt;Security and governance were a focus, too. HPE Private Cloud AI supports air-gapped management, multi-tenancy and post-quantum cryptography. HPE’s try-before-you-buy program lets customers test the system in Equinix data centers before purchase. HPE also introduced new programs, including AI Acceleration Workshops with NVIDIA, to help scale AI deployments.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Watch the keynote: &lt;/b&gt;HPE CEO Antonio Neri announced the news from the Las Vegas Sphere on Tuesday at 9 a.m. PT. Register for the livestream and replay.&lt;/li&gt;
&lt;li&gt;&lt;b&gt;Explore more:&lt;/b&gt; Learn how NVIDIA and HPE build AI factories for every industry. Visit the partner page.&lt;/li&gt;
&lt;/ul&gt;

		&lt;footer class="entry-footer  " id="post-footer"&gt;
					&lt;/footer&gt;</content:encoded><guid isPermaLink="false">https://blogs.nvidia.com/blog/hpe-nvidia-ai-factory/</guid><pubDate>Tue, 24 Jun 2025 16:30:14 +0000</pubDate></item><item><title>[NEW] Salesforce Agentforce 3 brings visibility to AI agents (AI News)</title><link>https://www.artificialintelligence-news.com/news/salesforce-agentforce-3-brings-visibility-ai-agents/</link><description>&lt;p&gt;Salesforce Agentforce 3 aims to tackle what many businesses have been struggling with: actually seeing what their AI agents are up to.&lt;/p&gt;&lt;p&gt;Since its debut back in October 2024, Agentforce has been racking up some wins across a variety of sectors. Engine managed to slash customer case handling times by 15 percent, while 1-800Accountant handed off 70 percent of administrative chat queries to AI during the madness of tax season.&lt;/p&gt;&lt;p&gt;But what’s interesting about this upgrade isn’t just the numbers, it’s how Salesforce is addressing the elephant in the room that nobody likes to talk about: businesses are deploying AI agents at breakneck speed without really understanding what they’re doing or how to improve them.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-keeping-tabs-on-your-agents"&gt;Keeping tabs on your agents&lt;/h3&gt;&lt;p&gt;The centrepiece of Agentforce 3 is what Salesforce calls the Command Center (essentially a mission control for your AI employees.) It lets managers peek under the bonnet to spot patterns in how agents are performing, track health metrics in real-time (latency, escalation rates, errors), and identify which bits are working versus which need a swift kick.&lt;/p&gt;&lt;p&gt;For anyone who’s ever deployed AI tools and then wondered “now what?” this level of visibility could be game-changing. The system captures all agent activity using the OpenTelemetry standard, which means it plays nicely with tools like Datadog and Splunk that your IT team probably already has on their screens.&lt;/p&gt;&lt;p&gt;AI adoption is absolutely skyrocketing. Forthcoming data from the Slack Workflow Index shows AI agent usage up 233 percent in just six months. During that time, about 8,000 organisations signed up to deploy Agentforce.&lt;/p&gt;&lt;p&gt;Ryan Teeples, CTO at 1-800Accountant, said: “Agentforce autonomously resolved 70% of 1-800Accountant’s administrative chat engagements during the peak of this past tax season, an incredible lift during one of our busiest periods. But that early success was just the beginning.&lt;/p&gt;&lt;p&gt;“We’ve established a strong deployment foundation and weekly are focused on launching new agentic experiences and AI automations through Agentforce’s newest capabilities. With a high level of observability, we can see what’s working, optimise in real time, and scale support with confidence.”&lt;/p&gt;&lt;p&gt;Salesforce Agentforce 3 doesn’t just provide data, it actually suggests improvements. The AI effectively watches itself, identifying conversation patterns and recommending tweaks. It’s a bit meta, but potentially very useful for overstretched teams who don’t have time to manually review thousands of bot interactions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-connectivity-conundrum-solved"&gt;The connectivity conundrum solved?&lt;/h3&gt;&lt;p&gt;Another headache Salesforce is tackling is connectivity. AI agents are only as useful as the systems they can access, but connecting them securely to your business tools has been a pain for most organisations.&lt;/p&gt;&lt;p&gt;Agentforce 3 brings native support for Model Context Protocol (MCP) – which Salesforce rather aptly describes as “USB-C for AI.” This essentially means AI agents can plug into any MCP-compliant server without custom coding, while still respecting your security policies.&lt;/p&gt;&lt;p&gt;This is where MuleSoft (which Salesforce acquired a few years back) comes into play, converting APIs and integrations into agent-ready assets. Heroku then handles deployment and maintenance of custom MCP servers.&lt;/p&gt;&lt;p&gt;Mollie Bodensteiner, SVP of Operations at Engine, commented: “Salesforce’s open ecosystem approach, especially through its native support for open standards like MCP, will be instrumental in helping us scale our use of AI agents with full confidence.&lt;/p&gt;&lt;p&gt;“We’ll be able to securely connect agents to the enterprise systems we rely on without custom code or compromising governance. That level of interoperability has given us the flexibility to accelerate adoption while staying in complete control of how agents operate within our environment.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-growing-the-salesforce-agentforce-ecosystem"&gt;Growing the Salesforce Agentforce ecosystem&lt;/h3&gt;&lt;p&gt;Perhaps the most interesting aspect of this announcement isn’t what Salesforce built themselves, but the ecosystem they’re nurturing. Over 30 partners have created MCP servers that integrate with Agentforce, including players like AWS, Google Cloud, Box, PayPal, and Stripe.&lt;/p&gt;&lt;p&gt;These integrations go far beyond simple data access. For instance, AWS integration lets agents analyse documents, extract information from images, transcribe audio recordings, and even identify important moments in videos. Google Cloud connections tie into Maps, databases, and AI models like Veo and Imagen.&lt;/p&gt;&lt;p&gt;Healthcare appears to be a particularly promising sector.&lt;/p&gt;&lt;p&gt;Tyler Bauer, VP for System Ambulatory Operations at UChicago Medicine, explains: “AI tools in healthcare must be adaptable to the complex and highly individualised needs of both patients and care teams.&lt;/p&gt;&lt;p&gt;“We need to support that goal by automating routine interactions in our patient access center that involve common questions and requests, which would free up the team’s time to focus on sensitive, more involved, or complex needs.”&lt;/p&gt;&lt;p&gt;The real question, of course, is whether all this will actually help businesses manage the growing army of AI agents they’re deploying. Getting visibility into AI performance has been a blind spot for many organisations—they often know roughly what percentage of queries the AI is handling, but struggle to identify specific shortcomings or improvement opportunities.&lt;/p&gt;&lt;p&gt;Adam Evans, EVP &amp;amp; GM of Salesforce AI, says: “Agentforce 3 will redefine how humans and AI agents work together—driving breakthrough levels of productivity, efficiency, and business transformation.”&lt;/p&gt;&lt;p&gt;Whether it lives up to that lofty promise remains to be seen, but addressing the visibility and control gap is certainly a step in the right direction for businesses struggling to properly manage their AI initiatives.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Huawei HarmonyOS 6 AI agents offer alternative to Android and iOS&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</description><content:encoded>&lt;p&gt;Salesforce Agentforce 3 aims to tackle what many businesses have been struggling with: actually seeing what their AI agents are up to.&lt;/p&gt;&lt;p&gt;Since its debut back in October 2024, Agentforce has been racking up some wins across a variety of sectors. Engine managed to slash customer case handling times by 15 percent, while 1-800Accountant handed off 70 percent of administrative chat queries to AI during the madness of tax season.&lt;/p&gt;&lt;p&gt;But what’s interesting about this upgrade isn’t just the numbers, it’s how Salesforce is addressing the elephant in the room that nobody likes to talk about: businesses are deploying AI agents at breakneck speed without really understanding what they’re doing or how to improve them.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-keeping-tabs-on-your-agents"&gt;Keeping tabs on your agents&lt;/h3&gt;&lt;p&gt;The centrepiece of Agentforce 3 is what Salesforce calls the Command Center (essentially a mission control for your AI employees.) It lets managers peek under the bonnet to spot patterns in how agents are performing, track health metrics in real-time (latency, escalation rates, errors), and identify which bits are working versus which need a swift kick.&lt;/p&gt;&lt;p&gt;For anyone who’s ever deployed AI tools and then wondered “now what?” this level of visibility could be game-changing. The system captures all agent activity using the OpenTelemetry standard, which means it plays nicely with tools like Datadog and Splunk that your IT team probably already has on their screens.&lt;/p&gt;&lt;p&gt;AI adoption is absolutely skyrocketing. Forthcoming data from the Slack Workflow Index shows AI agent usage up 233 percent in just six months. During that time, about 8,000 organisations signed up to deploy Agentforce.&lt;/p&gt;&lt;p&gt;Ryan Teeples, CTO at 1-800Accountant, said: “Agentforce autonomously resolved 70% of 1-800Accountant’s administrative chat engagements during the peak of this past tax season, an incredible lift during one of our busiest periods. But that early success was just the beginning.&lt;/p&gt;&lt;p&gt;“We’ve established a strong deployment foundation and weekly are focused on launching new agentic experiences and AI automations through Agentforce’s newest capabilities. With a high level of observability, we can see what’s working, optimise in real time, and scale support with confidence.”&lt;/p&gt;&lt;p&gt;Salesforce Agentforce 3 doesn’t just provide data, it actually suggests improvements. The AI effectively watches itself, identifying conversation patterns and recommending tweaks. It’s a bit meta, but potentially very useful for overstretched teams who don’t have time to manually review thousands of bot interactions.&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-the-connectivity-conundrum-solved"&gt;The connectivity conundrum solved?&lt;/h3&gt;&lt;p&gt;Another headache Salesforce is tackling is connectivity. AI agents are only as useful as the systems they can access, but connecting them securely to your business tools has been a pain for most organisations.&lt;/p&gt;&lt;p&gt;Agentforce 3 brings native support for Model Context Protocol (MCP) – which Salesforce rather aptly describes as “USB-C for AI.” This essentially means AI agents can plug into any MCP-compliant server without custom coding, while still respecting your security policies.&lt;/p&gt;&lt;p&gt;This is where MuleSoft (which Salesforce acquired a few years back) comes into play, converting APIs and integrations into agent-ready assets. Heroku then handles deployment and maintenance of custom MCP servers.&lt;/p&gt;&lt;p&gt;Mollie Bodensteiner, SVP of Operations at Engine, commented: “Salesforce’s open ecosystem approach, especially through its native support for open standards like MCP, will be instrumental in helping us scale our use of AI agents with full confidence.&lt;/p&gt;&lt;p&gt;“We’ll be able to securely connect agents to the enterprise systems we rely on without custom code or compromising governance. That level of interoperability has given us the flexibility to accelerate adoption while staying in complete control of how agents operate within our environment.”&lt;/p&gt;&lt;h3 class="wp-block-heading" id="h-growing-the-salesforce-agentforce-ecosystem"&gt;Growing the Salesforce Agentforce ecosystem&lt;/h3&gt;&lt;p&gt;Perhaps the most interesting aspect of this announcement isn’t what Salesforce built themselves, but the ecosystem they’re nurturing. Over 30 partners have created MCP servers that integrate with Agentforce, including players like AWS, Google Cloud, Box, PayPal, and Stripe.&lt;/p&gt;&lt;p&gt;These integrations go far beyond simple data access. For instance, AWS integration lets agents analyse documents, extract information from images, transcribe audio recordings, and even identify important moments in videos. Google Cloud connections tie into Maps, databases, and AI models like Veo and Imagen.&lt;/p&gt;&lt;p&gt;Healthcare appears to be a particularly promising sector.&lt;/p&gt;&lt;p&gt;Tyler Bauer, VP for System Ambulatory Operations at UChicago Medicine, explains: “AI tools in healthcare must be adaptable to the complex and highly individualised needs of both patients and care teams.&lt;/p&gt;&lt;p&gt;“We need to support that goal by automating routine interactions in our patient access center that involve common questions and requests, which would free up the team’s time to focus on sensitive, more involved, or complex needs.”&lt;/p&gt;&lt;p&gt;The real question, of course, is whether all this will actually help businesses manage the growing army of AI agents they’re deploying. Getting visibility into AI performance has been a blind spot for many organisations—they often know roughly what percentage of queries the AI is handling, but struggle to identify specific shortcomings or improvement opportunities.&lt;/p&gt;&lt;p&gt;Adam Evans, EVP &amp;amp; GM of Salesforce AI, says: “Agentforce 3 will redefine how humans and AI agents work together—driving breakthrough levels of productivity, efficiency, and business transformation.”&lt;/p&gt;&lt;p&gt;Whether it lives up to that lofty promise remains to be seen, but addressing the visibility and control gap is certainly a step in the right direction for businesses struggling to properly manage their AI initiatives.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;See also: &lt;/strong&gt;&lt;strong&gt;Huawei HarmonyOS 6 AI agents offer alternative to Android and iOS&lt;/strong&gt;&lt;/p&gt;&lt;figure class="wp-block-image size-full is-resized"&gt;&lt;img alt="alt" class="wp-image-11874" height="90" src="https://www.artificialintelligence-news.com/wp-content/uploads/2022/04/ai-expo-world-728x-90-01.png" width="728" /&gt;&lt;/figure&gt;&lt;p&gt;&lt;strong&gt;Want to learn more about AI and big data from industry leaders?&lt;/strong&gt; Check out AI &amp;amp; Big Data Expo taking place in Amsterdam, California, and London. The comprehensive event is co-located with other leading events including Intelligent Automation Conference, BlockX, Digital Transformation Week, and Cyber Security &amp;amp; Cloud Expo.&lt;/p&gt;&lt;p&gt;Explore other upcoming enterprise technology events and webinars powered by TechForge here.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://www.artificialintelligence-news.com/news/salesforce-agentforce-3-brings-visibility-ai-agents/</guid><pubDate>Tue, 24 Jun 2025 17:10:37 +0000</pubDate></item><item><title>[NEW] The résumé is dying, and AI is holding the smoking gun (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/06/the-resume-is-dying-and-ai-is-holding-the-smoking-gun/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        As thousands of applications flood job posts, 'hiring slop' is kicking off an AI arms race.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A businessman is trapped in his glass office by a surplus of discarded ideas on paper . His colleague in the next office is working more efficiently and is oblivious to him being trapped , as is a passing female office worker" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/buried_in_papers_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A businessman is trapped in his glass office by a surplus of discarded ideas on paper . His colleague in the next office is working more efficiently and is oblivious to him being trapped , as is a passing female office worker" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/buried_in_papers_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          sturti via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Employers are drowning in AI-generated job applications, with LinkedIn now processing 11,000 submissions per minute—a 45 percent surge from last year, according to new data reported by The New York Times.&lt;/p&gt;
&lt;p&gt;Due to AI, the traditional hiring process has become overwhelmed with automated noise. It's the résumé equivalent of AI slop—call it "hiring slop," perhaps—that currently haunts social media and the web with sensational pictures and misleading information. The flood of ChatGPT-crafted résumés and bot-submitted applications has created an arms race between job seekers and employers, with both sides deploying increasingly sophisticated AI tools in a bot-versus-bot standoff that is quickly spiraling out of control.&lt;/p&gt;
&lt;p&gt;The Times illustrates the scale of the problem with the story of an HR consultant named Katie Tanner, who was so inundated with over 1,200 applications for a single remote role that she had to remove the post entirely and was still sorting through the applications three months later.&lt;/p&gt;
&lt;p&gt;In an age where ChatGPT can insert every keyword from a job description into a résumé with a simple prompt, her story is not unique. The problem began shortly after the emergence of mainstream generative AI bots in 2022, when some companies applied the technology to job applications to help overwhelmed job seekers. Now, several years later, the technology has evolved from a convenience tool to a systemic disruption of the hiring process.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1980193 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Illustration of robot hands using a typewriter." class="center large" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2023/10/ai_typewriter_getty-640x360.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Some candidates are now taking automation even further, paying for AI agents that autonomously find jobs and submit applications on their behalf. Recruiters report that many of the résumés look suspiciously similar, making it more difficult to identify genuinely qualified or interested candidates.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Computer tools have been assisting with creating résumés for decades, and everything from the typewriter to word processors to spellcheck and résumé templates have increased the ease of making a competent résumé. But AI has pushed the trend into overdrive. The potential to create endless output makes AI fundamentally different from its predecessors. Whereas earlier technologies helped people craft one good résumé more efficiently, AI enables candidates to generate hundreds of customized applications with minimal effort—turning what was once a time-intensive process of demonstrating interest into a numbers game that overwhelms businesses trying to find genuinely qualified applicants.&lt;/p&gt;
&lt;p&gt;The frustration has reached a point where AI companies themselves are backing away from their own technology during the hiring process. Anthropic recently advised job seekers not to use LLMs on their applications—a striking admission from a company whose business model depends on people using AI for everything else.&lt;/p&gt;
&lt;h2&gt;The slow, painful death of the résumé&lt;/h2&gt;
&lt;p&gt;In response to the deluge, companies now deploy their own AI defenses. Chipotle's AI chatbot screening tool, nicknamed Ava Cado, has reportedly reduced hiring time by 75 percent. However, this trend from businesses has led to an arms race of escalating automation, with candidates using AI to generate interview answers while companies deploy AI to detect them—creating what amounts to machines talking to machines while humans get lost in the shuffle.&lt;/p&gt;
&lt;p&gt;Ironically, LinkedIn has stepped into the middle of the crisis by providing even more AI, with new tools that aim to help both candidates and recruiters narrow their focus. For example, an AI agent launched late last year can write follow-up messages, conduct screening chats, suggest top applicants, and search for potential hires using natural language on the platform.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Beyond volume, fraud poses an increasing threat. In January, the Justice Department announced indictments in a scheme to place North Korean nationals in remote IT roles at US companies. Research firm Gartner says that fake identity cases are growing rapidly, with the company estimating that by 2028, about 1 in 4 job applicants could be fraudulent. And as we have previously reported, security researchers have also discovered that AI systems can hide invisible text in applications, potentially allowing candidates to game screening systems using prompt injections in ways human reviewers can't detect.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2043141 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Illustration of a robot generating endless text, controlled by a scientist." class="center large" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2024/08/robot_science_header-640x360.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;And that's not all. Even when AI screening tools work as intended, they exhibit similar biases to human recruiters, preferring white male names on résumés—raising legal concerns about discrimination. The European Union's AI Act already classifies hiring under its high-risk category with stringent restrictions. Although no US federal law specifically addresses AI use in hiring, general anti-discrimination laws still apply.&lt;/p&gt;
&lt;p&gt;So perhaps résumés as a meaningful signal of candidate interest and qualification are becoming obsolete. And maybe that's OK. When anyone can generate hundreds of tailored applications with a few prompts, the document that once demonstrated effort and genuine interest in a position has devolved into noise.&lt;/p&gt;
&lt;p&gt;Instead, the future of hiring may require abandoning the résumé altogether in favor of methods that AI can't easily replicate—live problem-solving sessions, portfolio reviews, or trial work periods, just to name a few ideas. For now, employers and job seekers remain locked in an escalating technological arms race where machines screen the output of other machines, while the humans they're meant to serve struggle to make authentic connections in an increasingly inauthentic world.&lt;/p&gt;
&lt;p&gt;Perhaps the endgame is robots interviewing other robots for jobs performed by robots, while humans sit on the beach drinking daiquiris and playing vintage video games. Well, one can dream.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        As thousands of applications flood job posts, 'hiring slop' is kicking off an AI arms race.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="A businessman is trapped in his glass office by a surplus of discarded ideas on paper . His colleague in the next office is working more efficiently and is oblivious to him being trapped , as is a passing female office worker" class="absolute inset-0 w-full h-full object-cover hidden" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/buried_in_papers_2-640x360.jpg" width="640" /&gt;
                  &lt;img alt="A businessman is trapped in his glass office by a surplus of discarded ideas on paper . His colleague in the next office is working more efficiently and is oblivious to him being trapped , as is a passing female office worker" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/06/buried_in_papers_2-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          sturti via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;Employers are drowning in AI-generated job applications, with LinkedIn now processing 11,000 submissions per minute—a 45 percent surge from last year, according to new data reported by The New York Times.&lt;/p&gt;
&lt;p&gt;Due to AI, the traditional hiring process has become overwhelmed with automated noise. It's the résumé equivalent of AI slop—call it "hiring slop," perhaps—that currently haunts social media and the web with sensational pictures and misleading information. The flood of ChatGPT-crafted résumés and bot-submitted applications has created an arms race between job seekers and employers, with both sides deploying increasingly sophisticated AI tools in a bot-versus-bot standoff that is quickly spiraling out of control.&lt;/p&gt;
&lt;p&gt;The Times illustrates the scale of the problem with the story of an HR consultant named Katie Tanner, who was so inundated with over 1,200 applications for a single remote role that she had to remove the post entirely and was still sorting through the applications three months later.&lt;/p&gt;
&lt;p&gt;In an age where ChatGPT can insert every keyword from a job description into a résumé with a simple prompt, her story is not unique. The problem began shortly after the emergence of mainstream generative AI bots in 2022, when some companies applied the technology to job applications to help overwhelmed job seekers. Now, several years later, the technology has evolved from a convenience tool to a systemic disruption of the hiring process.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-1980193 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Illustration of robot hands using a typewriter." class="center large" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2023/10/ai_typewriter_getty-640x360.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;Some candidates are now taking automation even further, paying for AI agents that autonomously find jobs and submit applications on their behalf. Recruiters report that many of the résumés look suspiciously similar, making it more difficult to identify genuinely qualified or interested candidates.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Computer tools have been assisting with creating résumés for decades, and everything from the typewriter to word processors to spellcheck and résumé templates have increased the ease of making a competent résumé. But AI has pushed the trend into overdrive. The potential to create endless output makes AI fundamentally different from its predecessors. Whereas earlier technologies helped people craft one good résumé more efficiently, AI enables candidates to generate hundreds of customized applications with minimal effort—turning what was once a time-intensive process of demonstrating interest into a numbers game that overwhelms businesses trying to find genuinely qualified applicants.&lt;/p&gt;
&lt;p&gt;The frustration has reached a point where AI companies themselves are backing away from their own technology during the hiring process. Anthropic recently advised job seekers not to use LLMs on their applications—a striking admission from a company whose business model depends on people using AI for everything else.&lt;/p&gt;
&lt;h2&gt;The slow, painful death of the résumé&lt;/h2&gt;
&lt;p&gt;In response to the deluge, companies now deploy their own AI defenses. Chipotle's AI chatbot screening tool, nicknamed Ava Cado, has reportedly reduced hiring time by 75 percent. However, this trend from businesses has led to an arms race of escalating automation, with candidates using AI to generate interview answers while companies deploy AI to detect them—creating what amounts to machines talking to machines while humans get lost in the shuffle.&lt;/p&gt;
&lt;p&gt;Ironically, LinkedIn has stepped into the middle of the crisis by providing even more AI, with new tools that aim to help both candidates and recruiters narrow their focus. For example, an AI agent launched late last year can write follow-up messages, conduct screening chats, suggest top applicants, and search for potential hires using natural language on the platform.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Beyond volume, fraud poses an increasing threat. In January, the Justice Department announced indictments in a scheme to place North Korean nationals in remote IT roles at US companies. Research firm Gartner says that fake identity cases are growing rapidly, with the company estimating that by 2028, about 1 in 4 job applicants could be fraudulent. And as we have previously reported, security researchers have also discovered that AI systems can hide invisible text in applications, potentially allowing candidates to game screening systems using prompt injections in ways human reviewers can't detect.&lt;/p&gt;
&lt;figure class="ars-wp-img-shortcode id-2043141 align-center"&gt;
    &lt;div&gt;
                        &lt;img alt="Illustration of a robot generating endless text, controlled by a scientist." class="center large" height="360" src="https://cdn.arstechnica.net/wp-content/uploads/2024/08/robot_science_header-640x360.jpg" width="640" /&gt;
                  &lt;/div&gt;
          &lt;figcaption&gt;
        &lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          Moor Studio via Getty Images

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;
      &lt;/figcaption&gt;
      &lt;/figure&gt;

&lt;p&gt;And that's not all. Even when AI screening tools work as intended, they exhibit similar biases to human recruiters, preferring white male names on résumés—raising legal concerns about discrimination. The European Union's AI Act already classifies hiring under its high-risk category with stringent restrictions. Although no US federal law specifically addresses AI use in hiring, general anti-discrimination laws still apply.&lt;/p&gt;
&lt;p&gt;So perhaps résumés as a meaningful signal of candidate interest and qualification are becoming obsolete. And maybe that's OK. When anyone can generate hundreds of tailored applications with a few prompts, the document that once demonstrated effort and genuine interest in a position has devolved into noise.&lt;/p&gt;
&lt;p&gt;Instead, the future of hiring may require abandoning the résumé altogether in favor of methods that AI can't easily replicate—live problem-solving sessions, portfolio reviews, or trial work periods, just to name a few ideas. For now, employers and job seekers remain locked in an escalating technological arms race where machines screen the output of other machines, while the humans they're meant to serve struggle to make authentic connections in an increasingly inauthentic world.&lt;/p&gt;
&lt;p&gt;Perhaps the endgame is robots interviewing other robots for jobs performed by robots, while humans sit on the beach drinking daiquiris and playing vintage video games. Well, one can dream.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/06/the-resume-is-dying-and-ai-is-holding-the-smoking-gun/</guid><pubDate>Tue, 24 Jun 2025 17:25:41 +0000</pubDate></item></channel></rss>