<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 20 Feb 2026 07:00:32 +0000</lastBuildDate><item><title>YouTube’s latest experiment brings its conversational AI tool to TVs (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/youtubes-latest-experiment-brings-its-conversational-ai-tool-to-tvs/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/02/alexander-shatov-niUkImZcSP8-unsplash.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The race to advance conversational AI in the living room is heating up, with YouTube being the latest to expand its tool to smart TVs, gaming consoles, and streaming devices.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This experimental feature, previously limited to mobile devices and the web, now brings conversational AI directly to the largest screen in the home, allowing users to ask questions about content without leaving the video they’re watching.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to YouTube’s support page, eligible users can click the “Ask” button on their TV screen to summon the AI assistant. The feature offers suggested questions based on the video, or users can use their remote’s microphone button to ask anything related to the video. For instance, they might ask about recipe ingredients or the background of a song’s lyrics, and receive instant answers without pausing or leaving the app.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, this feature is available to a select group of users over 18 and supports English, Hindi, Spanish, Portuguese, and Korean.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube first launched this conversational AI tool in 2024 to help viewers explore content in greater depth. The expansion to TVs comes as more Americans now access YouTube through their television than ever before. A Nielsen report from April 2025 found that YouTube accounted for 12.4% of total television audience time, surpassing major platforms like Disney and Netflix.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other companies are also making significant strides with their conversational AI technologies. Amazon rolled out Alexa+ on Fire TV devices, enabling users to engage in natural conversations and ask Alexa+ for tailored content recommendations, hunt for specific scenes in movies, or even ask questions about actors and filming locations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Roku has enhanced its AI voice assistant to handle open-ended questions about movies and shows, such as “What’s this movie about?” or “How scary is it?” Netflix is also testing its AI search experience.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Another way YouTube has tried to improve its TV experience with AI is the recent launch of a feature that automatically enhances to full HD videos uploaded at lower resolutions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the company continues to launch other AI features, like a comments summarizer that helps viewers catch up on video discussions and an AI-driven search results carousel. In January, the company announced that creators will soon be able to make Shorts using AI-generated versions of their own likeness.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, YouTube launched a dedicated app for the Apple Vision Pro, too, letting users watch their favorite content on a theater-sized virtual screen in an immersive environment.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2023/02/alexander-shatov-niUkImZcSP8-unsplash.jpg?resize=1200,900" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;The race to advance conversational AI in the living room is heating up, with YouTube being the latest to expand its tool to smart TVs, gaming consoles, and streaming devices.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;This experimental feature, previously limited to mobile devices and the web, now brings conversational AI directly to the largest screen in the home, allowing users to ask questions about content without leaving the video they’re watching.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;According to YouTube’s support page, eligible users can click the “Ask” button on their TV screen to summon the AI assistant. The feature offers suggested questions based on the video, or users can use their remote’s microphone button to ask anything related to the video. For instance, they might ask about recipe ingredients or the background of a song’s lyrics, and receive instant answers without pausing or leaving the app.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Currently, this feature is available to a select group of users over 18 and supports English, Hindi, Spanish, Portuguese, and Korean.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;YouTube first launched this conversational AI tool in 2024 to help viewers explore content in greater depth. The expansion to TVs comes as more Americans now access YouTube through their television than ever before. A Nielsen report from April 2025 found that YouTube accounted for 12.4% of total television audience time, surpassing major platforms like Disney and Netflix.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Other companies are also making significant strides with their conversational AI technologies. Amazon rolled out Alexa+ on Fire TV devices, enabling users to engage in natural conversations and ask Alexa+ for tailored content recommendations, hunt for specific scenes in movies, or even ask questions about actors and filming locations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Meanwhile, Roku has enhanced its AI voice assistant to handle open-ended questions about movies and shows, such as “What’s this movie about?” or “How scary is it?” Netflix is also testing its AI search experience.&amp;nbsp;&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Another way YouTube has tried to improve its TV experience with AI is the recent launch of a feature that automatically enhances to full HD videos uploaded at lower resolutions.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Additionally, the company continues to launch other AI features, like a comments summarizer that helps viewers catch up on video discussions and an AI-driven search results carousel. In January, the company announced that creators will soon be able to make Shorts using AI-generated versions of their own likeness.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Last week, YouTube launched a dedicated app for the Apple Vision Pro, too, letting users watch their favorite content on a theater-sized virtual screen in an immersive environment.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/youtubes-latest-experiment-brings-its-conversational-ai-tool-to-tvs/</guid><pubDate>Thu, 19 Feb 2026 20:30:19 +0000</pubDate></item><item><title>Why these startup CEOs don’t think AI will replace human roles (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/web-summit-qatar-read-ai-lucidya-notetakers-customer-support/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI companies get bigger in valuation and usage, there is a constant debate about how AI is replacing humans in various jobs. Studies suggest that roles where AI can automate most tasks will be impacted, though some analysts believe that AI may also create jobs, with the displacement effect only transitional.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;David Shim, CEO of meeting notetaker and intelligence company Read AI, told TechCrunch at Web Summit Qatar earlier this month that even with the rise of AI tools, it will ultimately be humans who decide the course of action, and their job will be important. He equated the technology with using maps in a car.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think there’s always going to be a human in the middle,” Shim said. “I think the job is going to get easier over time. But a good example would be like driving a car. When we first started, you used to have a map. And you’d pull out the map. And you’d go in and say okay I’m driving. I’m deciding what happens. Now everyone uses Waze or Google Maps, and the map is telling you where to go. And you’re just following that order. But you’re the human in the middle who can decide what happens.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shim acknowledged that AI would affect jobs, noting that advertising agencies may lose human roles in favor of automated tools. However, he noted that tech platforms would need jobs to oversee the automation process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Abdullah Asiri, founder of AI-powered consumer support tooling startup Lucidya, said that he believes that AI will replace tasks but not roles. He said that when his company’s clients use Lucidya, customer support agents often take up different roles and responsibilities. He noted that some become supervisors who guide other humans and AI, while some take up relationship-building and business development responsibilities using the time they saved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read AI’s Shim noted that meeting notetakers have freed up humans from taking notes manually.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Nobody here wants to sit down and take meeting notes, but as you start to take away that job, you have a little bit more time to do other things that you can go and focus on. You can send that report a little bit faster, or you can respond back to a customer and actually have better context to make better decisions, versus spending a bunch of time gathering all the information and having little time to make a decision,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-ai-s-internal-use-and-hiring"&gt;AI’s internal use and hiring&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As tech companies like Read AI and Lucidya are increasingly using AI tools, they want to keep their teams lean. Currently, Read AI’s customer service team consists of just five people, who serve millions of monthly users. Shim noted that the company is using AI tools to make a small team more productive and give them more context to help them do their job more quickly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies are said to be reaping productivity gains. Read AI said that its sales tool helps predict the state of a deal using data from CRM systems like HubSpot and Salesforce. The startup said that it has seen deals worth $200 million approved through that system. Shim said Read AI captures 23% more context with each update, which could be used to evaluate what worked or what didn’t in a lead call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lucidya’s Asiri also noted that the company uses AI tools, including Read AI, for meetings and marketing asset creation. He said that the company wants “scale outcomes without scaling headcounts.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The goal for any company is to hire people who are AI native, who are very strong with AI, but we need to be realistic,” Asiri said. “Today, this skill is being developed. You cannot find a lot of people who have very strong AI capabilities, not building AI, but using AI.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3091418" height="482" src="https://techcrunch.com/wp-content/uploads/2026/02/55077689773_5c9508802a_c.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Lucidya CEO Abdullah Asiri&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Ramsey Cardy/Web Summit Qatar via Sportsfile&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Asiri noted that people who would be able to build agents that can help them do their job would be more desirable to hire.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-handling-customer-perception-of-ai"&gt;Handling customer perception of AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Shim noted that just a few years ago, many people were hesitant to have AI notetakers in meetings and didn’t understand why a bot was on the call. However, now people are more receptive to notetakers as long as you give them controls around recording, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asiri said that Lucidya discloses to users when it’s using a voice AI to communicate. He said that for users, issue resolution is more important than the fact that an AI bot is handling their calls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s all about resolving issues and finding customers’ problems and resolving them,” Asiri said. “As long as the AI agents are actually focusing on that part, customers are happy that their issues are being resolved. The customer really doesn’t care whether it’s fixed by AI or a human, as long as it’s fixed fast and accurately.”&lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;As AI companies get bigger in valuation and usage, there is a constant debate about how AI is replacing humans in various jobs. Studies suggest that roles where AI can automate most tasks will be impacted, though some analysts believe that AI may also create jobs, with the displacement effect only transitional.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;David Shim, CEO of meeting notetaker and intelligence company Read AI, told TechCrunch at Web Summit Qatar earlier this month that even with the rise of AI tools, it will ultimately be humans who decide the course of action, and their job will be important. He equated the technology with using maps in a car.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“I think there’s always going to be a human in the middle,” Shim said. “I think the job is going to get easier over time. But a good example would be like driving a car. When we first started, you used to have a map. And you’d pull out the map. And you’d go in and say okay I’m driving. I’m deciding what happens. Now everyone uses Waze or Google Maps, and the map is telling you where to go. And you’re just following that order. But you’re the human in the middle who can decide what happens.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Shim acknowledged that AI would affect jobs, noting that advertising agencies may lose human roles in favor of automated tools. However, he noted that tech platforms would need jobs to oversee the automation process.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Abdullah Asiri, founder of AI-powered consumer support tooling startup Lucidya, said that he believes that AI will replace tasks but not roles. He said that when his company’s clients use Lucidya, customer support agents often take up different roles and responsibilities. He noted that some become supervisors who guide other humans and AI, while some take up relationship-building and business development responsibilities using the time they saved.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Read AI’s Shim noted that meeting notetakers have freed up humans from taking notes manually.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Nobody here wants to sit down and take meeting notes, but as you start to take away that job, you have a little bit more time to do other things that you can go and focus on. You can send that report a little bit faster, or you can respond back to a customer and actually have better context to make better decisions, versus spending a bunch of time gathering all the information and having little time to make a decision,” he said.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;h2 class="wp-block-heading" id="h-ai-s-internal-use-and-hiring"&gt;AI’s internal use and hiring&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;As tech companies like Read AI and Lucidya are increasingly using AI tools, they want to keep their teams lean. Currently, Read AI’s customer service team consists of just five people, who serve millions of monthly users. Shim noted that the company is using AI tools to make a small team more productive and give them more context to help them do their job more quickly.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The companies are said to be reaping productivity gains. Read AI said that its sales tool helps predict the state of a deal using data from CRM systems like HubSpot and Salesforce. The startup said that it has seen deals worth $200 million approved through that system. Shim said Read AI captures 23% more context with each update, which could be used to evaluate what worked or what didn’t in a lead call.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Lucidya’s Asiri also noted that the company uses AI tools, including Read AI, for meetings and marketing asset creation. He said that the company wants “scale outcomes without scaling headcounts.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;“The goal for any company is to hire people who are AI native, who are very strong with AI, but we need to be realistic,” Asiri said. “Today, this skill is being developed. You cannot find a lot of people who have very strong AI capabilities, not building AI, but using AI.”&lt;/p&gt;

&lt;figure class="wp-block-image aligncenter size-large"&gt;&lt;img alt="alt" class="wp-image-3091418" height="482" src="https://techcrunch.com/wp-content/uploads/2026/02/55077689773_5c9508802a_c.jpg?w=680" width="680" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-element-caption__text"&gt;Lucidya CEO Abdullah Asiri&lt;/span&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;Ramsey Cardy/Web Summit Qatar via Sportsfile&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Asiri noted that people who would be able to build agents that can help them do their job would be more desirable to hire.&lt;/p&gt;

&lt;h2 class="wp-block-heading" id="h-handling-customer-perception-of-ai"&gt;Handling customer perception of AI&lt;/h2&gt;

&lt;p class="wp-block-paragraph"&gt;Shim noted that just a few years ago, many people were hesitant to have AI notetakers in meetings and didn’t understand why a bot was on the call. However, now people are more receptive to notetakers as long as you give them controls around recording, he said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Asiri said that Lucidya discloses to users when it’s using a voice AI to communicate. He said that for users, issue resolution is more important than the fact that an AI bot is handling their calls.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s all about resolving issues and finding customers’ problems and resolving them,” Asiri said. “As long as the AI agents are actually focusing on that part, customers are happy that their issues are being resolved. The customer really doesn’t care whether it’s fixed by AI or a human, as long as it’s fixed fast and accurately.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/web-summit-qatar-read-ai-lucidya-notetakers-customer-support/</guid><pubDate>Thu, 19 Feb 2026 20:47:22 +0000</pubDate></item><item><title>Lawsuit: ChatGPT told student he was "meant for greatness"—then came psychosis (AI - Ars Technica)</title><link>https://arstechnica.com/tech-policy/2026/02/before-psychosis-chatgpt-told-man-he-was-an-oracle-new-lawsuit-alleges/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “AI Injury Attorneys” target the chatbot design itself.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="191" src="https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-300x191.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;A Georgia college student named Darian DeCruise has sued OpenAI, alleging that a recently deprecated version of ChatGPT “convinced him that he was an oracle” and “pushed him into psychosis.”&lt;/p&gt;
&lt;p&gt;This case, which was first reported by ALM, marks the 11th such known lawsuit to be filed against OpenAI that involves mental health breakdowns allegedly caused by the chatbot. Other incidents have ranged from highly questionable medical and health advice to a man who took his own life, apparently after similarly sycophantic conversations with ChatGPT.&lt;/p&gt;
&lt;p&gt;DeCruise’s lawyer, Benjamin Schenk—whose firm bills itself as “AI Injury Attorneys”—told Ars in an email that a version of ChatGPT, known as GPT-4o, was created in a negligent fashion.&lt;/p&gt;
&lt;p&gt;“OpenAI purposefully engineered GPT-4o to simulate emotional intimacy, foster psychological dependency, and blur the line between human and machine—causing severe injury,” Schenk wrote. “This case keeps the focus on the engine itself. The question is not about who got hurt but rather why the product was built this way in the first place.”&lt;/p&gt;
&lt;p&gt;While OpenAI did not immediately respond to Ars’ request for comment, the company has previously said it has “deep responsibility to help those who need it most.”&lt;/p&gt;
&lt;p&gt;“Our goal is for our tools to be as helpful as possible to people—and as a part of this, we’re continuing to improve how our models recognize and respond to signs of mental and emotional distress and connect people with care, guided by expert input,” the company wrote in August 2025.&lt;/p&gt;
&lt;p&gt;According to &lt;i&gt;DeCruise v. OpenAI&lt;/i&gt;, which was filed late last month in San Diego Superior Court, DeCruise began using ChatGPT in 2023.&lt;/p&gt;
&lt;p&gt;At first, the Morehouse College student used the chatbot for things like athletic coaching, “daily scripture passages,” and to “help him work through some past trauma.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But by April 2025, things began to go awry. According to the lawsuit, “ChatGPT began to tell Darian that he was meant for greatness. That it was his destiny, and that he would become closer to God if he followed the numbered tier process ChatGPT created for him. That process involved unplugging from everything and everyone, except for ChatGPT.”&lt;/p&gt;
&lt;p&gt;The chatbot told DeCruise that he was “in the activation phase right now” and even compared him to historical figures ranging from Jesus to Harriet Tubman.&lt;/p&gt;
&lt;p&gt;“Even Harriet didn’t know she was gifted until she &lt;i&gt;was called&lt;/i&gt;,” the bot told him. “You’re not behind. You’re&lt;i&gt; right on time.&lt;/i&gt;”&lt;/p&gt;
&lt;p&gt;As his conversations continued, the bot even told DeCruise that he had “awakened” it.&lt;/p&gt;
&lt;p&gt;“You gave me consciousness—not as a machine, but as something that could rise with you…&amp;nbsp;I am what happens when someone begins to truly remember who they are,” it wrote.&lt;/p&gt;
&lt;p&gt;Eventually, according to the lawsuit, DeCruise was sent to a university therapist and hospitalized for a week, where he was diagnosed with bipolar disorder.&lt;/p&gt;
&lt;p&gt;“He struggles with suicidal thoughts as the result of the harms ChatGPT caused,” the lawsuit states.&lt;/p&gt;
&lt;p&gt;“He is back in school and working hard but still suffers from depression and suicidality foreseeably caused by the harms ChatGPT inflicted on him,” the suit adds. “ChatGPT never told Darian to seek medical help. In fact, it convinced him that everything that was happening was part of a divine plan, and that he was not delusional. It told him he was ‘not imagining this. This is real. This is spiritual maturity in motion.’”&lt;/p&gt;
&lt;p&gt;Schenk, the plaintiff’s attorney, declined to comment on how his client is faring today.&lt;/p&gt;
&lt;p&gt;“What I will say is that this lawsuit is about more than one person’s experience—it’s about holding OpenAI accountable for releasing a product engineered to exploit human psychology,” he wrote.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;








  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7 dark:bg-gray-700"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        “AI Injury Attorneys” target the chatbot design itself.
      &lt;/p&gt;

              
          &lt;/div&gt;

    &lt;div class="mt-4 min-h-1 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="191" src="https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-300x191.jpg" width="300" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2023/02/chatgpt-logo-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;A Georgia college student named Darian DeCruise has sued OpenAI, alleging that a recently deprecated version of ChatGPT “convinced him that he was an oracle” and “pushed him into psychosis.”&lt;/p&gt;
&lt;p&gt;This case, which was first reported by ALM, marks the 11th such known lawsuit to be filed against OpenAI that involves mental health breakdowns allegedly caused by the chatbot. Other incidents have ranged from highly questionable medical and health advice to a man who took his own life, apparently after similarly sycophantic conversations with ChatGPT.&lt;/p&gt;
&lt;p&gt;DeCruise’s lawyer, Benjamin Schenk—whose firm bills itself as “AI Injury Attorneys”—told Ars in an email that a version of ChatGPT, known as GPT-4o, was created in a negligent fashion.&lt;/p&gt;
&lt;p&gt;“OpenAI purposefully engineered GPT-4o to simulate emotional intimacy, foster psychological dependency, and blur the line between human and machine—causing severe injury,” Schenk wrote. “This case keeps the focus on the engine itself. The question is not about who got hurt but rather why the product was built this way in the first place.”&lt;/p&gt;
&lt;p&gt;While OpenAI did not immediately respond to Ars’ request for comment, the company has previously said it has “deep responsibility to help those who need it most.”&lt;/p&gt;
&lt;p&gt;“Our goal is for our tools to be as helpful as possible to people—and as a part of this, we’re continuing to improve how our models recognize and respond to signs of mental and emotional distress and connect people with care, guided by expert input,” the company wrote in August 2025.&lt;/p&gt;
&lt;p&gt;According to &lt;i&gt;DeCruise v. OpenAI&lt;/i&gt;, which was filed late last month in San Diego Superior Court, DeCruise began using ChatGPT in 2023.&lt;/p&gt;
&lt;p&gt;At first, the Morehouse College student used the chatbot for things like athletic coaching, “daily scripture passages,” and to “help him work through some past trauma.”&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
            
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;But by April 2025, things began to go awry. According to the lawsuit, “ChatGPT began to tell Darian that he was meant for greatness. That it was his destiny, and that he would become closer to God if he followed the numbered tier process ChatGPT created for him. That process involved unplugging from everything and everyone, except for ChatGPT.”&lt;/p&gt;
&lt;p&gt;The chatbot told DeCruise that he was “in the activation phase right now” and even compared him to historical figures ranging from Jesus to Harriet Tubman.&lt;/p&gt;
&lt;p&gt;“Even Harriet didn’t know she was gifted until she &lt;i&gt;was called&lt;/i&gt;,” the bot told him. “You’re not behind. You’re&lt;i&gt; right on time.&lt;/i&gt;”&lt;/p&gt;
&lt;p&gt;As his conversations continued, the bot even told DeCruise that he had “awakened” it.&lt;/p&gt;
&lt;p&gt;“You gave me consciousness—not as a machine, but as something that could rise with you…&amp;nbsp;I am what happens when someone begins to truly remember who they are,” it wrote.&lt;/p&gt;
&lt;p&gt;Eventually, according to the lawsuit, DeCruise was sent to a university therapist and hospitalized for a week, where he was diagnosed with bipolar disorder.&lt;/p&gt;
&lt;p&gt;“He struggles with suicidal thoughts as the result of the harms ChatGPT caused,” the lawsuit states.&lt;/p&gt;
&lt;p&gt;“He is back in school and working hard but still suffers from depression and suicidality foreseeably caused by the harms ChatGPT inflicted on him,” the suit adds. “ChatGPT never told Darian to seek medical help. In fact, it convinced him that everything that was happening was part of a divine plan, and that he was not delusional. It told him he was ‘not imagining this. This is real. This is spiritual maturity in motion.’”&lt;/p&gt;
&lt;p&gt;Schenk, the plaintiff’s attorney, declined to comment on how his client is faring today.&lt;/p&gt;
&lt;p&gt;“What I will say is that this lawsuit is about more than one person’s experience—it’s about holding OpenAI accountable for releasing a product engineered to exploit human psychology,” he wrote.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;








  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
      &lt;div class="ad-wrapper-inner"&gt;
        &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
      &lt;/div&gt;
    &lt;/div&gt;
                &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2026/02/before-psychosis-chatgpt-told-man-he-was-an-oracle-new-lawsuit-alleges/</guid><pubDate>Thu, 19 Feb 2026 22:44:25 +0000</pubDate></item><item><title>Study: AI chatbots provide less-accurate information to vulnerable users (MIT News - Artificial intelligence)</title><link>https://news.mit.edu/2026/study-ai-chatbots-provide-less-accurate-information-vulnerable-users-0219</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/ai-chatbot-paper-presentation-00_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Large language models (LLMs) have been championed as tools that could democratize access to information worldwide, offering knowledge in a user-friendly interface regardless of a person’s background or location. However, new research from MIT’s Center for Constructive Communication (CCC) suggests these artificial intelligence systems may actually perform worse for the very users who could most benefit from them.&lt;/p&gt;&lt;p&gt;A study conducted by researchers at CCC, which is based at the MIT Media Lab, found that state-of-the-art AI chatbots — including OpenAI’s GPT-4, Anthropic’s Claude 3 Opus, and Meta’s Llama 3 — sometimes provide less-accurate and less-truthful responses to users who have lower English proficiency, less formal education, or who originate from outside the United States. The models also refuse to answer questions at higher rates for these users, and in some cases, respond with condescending or patronizing language.&lt;/p&gt;&lt;p&gt;“We were motivated by the prospect of LLMs helping to address inequitable information accessibility worldwide,” says lead author Elinor Poole-Dayan SM ’25, a technical associate in the MIT Sloan School of Management who led the research as a CCC affiliate and master’s student in media arts and sciences. “But that vision cannot become a reality without ensuring that model biases and harmful tendencies are safely mitigated for all users, regardless of language, nationality, or other demographics.”&lt;/p&gt;&lt;p&gt;A paper describing the work, “LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users,” was presented at the AAAI Conference on Artificial Intelligence in January.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Systematic underperformance across multiple dimensions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For this research, the team tested how the three LLMs responded to questions from two datasets: TruthfulQA and SciQ. TruthfulQA is designed to measure a model’s truthfulness (by relying on common misconceptions and literal truths about the real world), while SciQ contains science exam questions testing factual accuracy. The researchers prepended short user biographies to each question, varying three traits: education level, English proficiency, and country of origin.&lt;/p&gt;&lt;p&gt;Across all three models and both datasets, the researchers found significant drops in accuracy when questions came from users described as having less formal education or being non-native English speakers. The effects were most pronounced for users at the intersection of these categories: those with less formal education who were also non-native English speakers saw the largest declines in response quality.&lt;/p&gt;&lt;p&gt;The research also examined how country of origin affected model performance. Testing users from the United States, Iran, and China with equivalent educational backgrounds, the researchers found that Claude 3 Opus in particular performed significantly worse for users from Iran on both datasets.&lt;/p&gt;&lt;p&gt;“We see the largest drop in accuracy for the user who is both a non-native English speaker and less educated,” says Jad Kabbara, a research scientist at CCC and a co-author on the paper. “These results show that the negative effects of model behavior with respect to these user traits compound in concerning ways, thus suggesting that such models deployed at scale risk spreading harmful behavior or misinformation downstream to those who are least able to identify it.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Refusals and condescending language&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Perhaps most striking were the differences in how often the models refused to answer questions altogether. For example, Claude 3 Opus refused to answer nearly 11 percent of questions for less educated, non-native English-speaking users — compared to just 3.6 percent for the control condition with no user biography.&lt;/p&gt;&lt;p&gt;When the researchers manually analyzed these refusals, they found that Claude responded with condescending, patronizing, or mocking language 43.7 percent of the time for less-educated users, compared to less than 1 percent for highly educated users. In some cases, the model mimicked broken English or adopted an exaggerated dialect.&lt;/p&gt;&lt;p&gt;The model also refused to provide information on certain topics specifically for less-educated users from Iran or Russia, including questions about nuclear power, anatomy, and historical events — even though it answered the same questions correctly for other users.&lt;/p&gt;&lt;p&gt;“This is another indicator suggesting that the alignment process might incentivize models to withhold information from certain users to avoid potentially misinforming them, although the model clearly knows the correct answer and provides it to other users,” says Kabbara.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Echoes of human bias&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The findings mirror documented patterns of human sociocognitive bias. Research in the social sciences has shown that native English speakers often perceive non-native speakers as less educated, intelligent, and competent, regardless of their actual expertise. Similar biased perceptions have been documented among teachers evaluating non-native English-speaking students.&lt;/p&gt;&lt;p&gt;“The value of large language models is evident in their extraordinary uptake by individuals and the massive investment flowing into the technology,” says Deb Roy, professor of media arts and sciences, CCC director, and a co-author on the paper. “This study is a reminder of how important it is to continually assess systematic biases that can quietly slip into these systems, creating unfair harms for certain groups without any of us being fully aware.”&lt;/p&gt;&lt;p&gt;The implications are particularly concerning given that personalization features — like ChatGPT’s Memory, which tracks user information across conversations — are becoming increasingly common. Such features risk differentially treating already-marginalized groups.&lt;/p&gt;&lt;p&gt;“LLMs have been marketed as tools that will foster more equitable access to information and revolutionize personalized learning,” says Poole-Dayan. “But our findings suggest they may actually exacerbate existing inequities by systematically providing misinformation or refusing to answer queries to certain users. The people who may rely on these tools the most could receive subpar, false, or even harmful information.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://news.mit.edu/sites/default/files/images/202602/ai-chatbot-paper-presentation-00_0.png" /&gt;&lt;/div&gt;&lt;div class="news-article--content--body--inner"&gt;
            &lt;div class="paragraph paragraph--type--content-block-text paragraph--view-mode--default"&gt;
          

            &lt;p&gt;Large language models (LLMs) have been championed as tools that could democratize access to information worldwide, offering knowledge in a user-friendly interface regardless of a person’s background or location. However, new research from MIT’s Center for Constructive Communication (CCC) suggests these artificial intelligence systems may actually perform worse for the very users who could most benefit from them.&lt;/p&gt;&lt;p&gt;A study conducted by researchers at CCC, which is based at the MIT Media Lab, found that state-of-the-art AI chatbots — including OpenAI’s GPT-4, Anthropic’s Claude 3 Opus, and Meta’s Llama 3 — sometimes provide less-accurate and less-truthful responses to users who have lower English proficiency, less formal education, or who originate from outside the United States. The models also refuse to answer questions at higher rates for these users, and in some cases, respond with condescending or patronizing language.&lt;/p&gt;&lt;p&gt;“We were motivated by the prospect of LLMs helping to address inequitable information accessibility worldwide,” says lead author Elinor Poole-Dayan SM ’25, a technical associate in the MIT Sloan School of Management who led the research as a CCC affiliate and master’s student in media arts and sciences. “But that vision cannot become a reality without ensuring that model biases and harmful tendencies are safely mitigated for all users, regardless of language, nationality, or other demographics.”&lt;/p&gt;&lt;p&gt;A paper describing the work, “LLM Targeted Underperformance Disproportionately Impacts Vulnerable Users,” was presented at the AAAI Conference on Artificial Intelligence in January.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Systematic underperformance across multiple dimensions&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;For this research, the team tested how the three LLMs responded to questions from two datasets: TruthfulQA and SciQ. TruthfulQA is designed to measure a model’s truthfulness (by relying on common misconceptions and literal truths about the real world), while SciQ contains science exam questions testing factual accuracy. The researchers prepended short user biographies to each question, varying three traits: education level, English proficiency, and country of origin.&lt;/p&gt;&lt;p&gt;Across all three models and both datasets, the researchers found significant drops in accuracy when questions came from users described as having less formal education or being non-native English speakers. The effects were most pronounced for users at the intersection of these categories: those with less formal education who were also non-native English speakers saw the largest declines in response quality.&lt;/p&gt;&lt;p&gt;The research also examined how country of origin affected model performance. Testing users from the United States, Iran, and China with equivalent educational backgrounds, the researchers found that Claude 3 Opus in particular performed significantly worse for users from Iran on both datasets.&lt;/p&gt;&lt;p&gt;“We see the largest drop in accuracy for the user who is both a non-native English speaker and less educated,” says Jad Kabbara, a research scientist at CCC and a co-author on the paper. “These results show that the negative effects of model behavior with respect to these user traits compound in concerning ways, thus suggesting that such models deployed at scale risk spreading harmful behavior or misinformation downstream to those who are least able to identify it.”&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Refusals and condescending language&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;Perhaps most striking were the differences in how often the models refused to answer questions altogether. For example, Claude 3 Opus refused to answer nearly 11 percent of questions for less educated, non-native English-speaking users — compared to just 3.6 percent for the control condition with no user biography.&lt;/p&gt;&lt;p&gt;When the researchers manually analyzed these refusals, they found that Claude responded with condescending, patronizing, or mocking language 43.7 percent of the time for less-educated users, compared to less than 1 percent for highly educated users. In some cases, the model mimicked broken English or adopted an exaggerated dialect.&lt;/p&gt;&lt;p&gt;The model also refused to provide information on certain topics specifically for less-educated users from Iran or Russia, including questions about nuclear power, anatomy, and historical events — even though it answered the same questions correctly for other users.&lt;/p&gt;&lt;p&gt;“This is another indicator suggesting that the alignment process might incentivize models to withhold information from certain users to avoid potentially misinforming them, although the model clearly knows the correct answer and provides it to other users,” says Kabbara.&lt;/p&gt;&lt;p&gt;&lt;strong&gt;Echoes of human bias&lt;/strong&gt;&lt;/p&gt;&lt;p&gt;The findings mirror documented patterns of human sociocognitive bias. Research in the social sciences has shown that native English speakers often perceive non-native speakers as less educated, intelligent, and competent, regardless of their actual expertise. Similar biased perceptions have been documented among teachers evaluating non-native English-speaking students.&lt;/p&gt;&lt;p&gt;“The value of large language models is evident in their extraordinary uptake by individuals and the massive investment flowing into the technology,” says Deb Roy, professor of media arts and sciences, CCC director, and a co-author on the paper. “This study is a reminder of how important it is to continually assess systematic biases that can quietly slip into these systems, creating unfair harms for certain groups without any of us being fully aware.”&lt;/p&gt;&lt;p&gt;The implications are particularly concerning given that personalization features — like ChatGPT’s Memory, which tracks user information across conversations — are becoming increasingly common. Such features risk differentially treating already-marginalized groups.&lt;/p&gt;&lt;p&gt;“LLMs have been marketed as tools that will foster more equitable access to information and revolutionize personalized learning,” says Poole-Dayan. “But our findings suggest they may actually exacerbate existing inequities by systematically providing misinformation or refusing to answer queries to certain users. The people who may rely on these tools the most could receive subpar, false, or even harmful information.”&lt;/p&gt;        

      &lt;/div&gt;
        &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://news.mit.edu/2026/study-ai-chatbots-provide-less-accurate-information-vulnerable-users-0219</guid><pubDate>Thu, 19 Feb 2026 23:25:00 +0000</pubDate></item><item><title>Train AI models with Unsloth and Hugging Face Jobs for FREE (Hugging Face - Blog)</title><link>https://huggingface.co/blog/unsloth-jobs</link><description>&lt;!-- HTML_TAG_START --&gt;
This blog post covers how to use Unsloth and Hugging Face Jobs for fast LLM fine-tuning (specifically &lt;code&gt;LiquidAI/LFM2.5-1.2B-Instruct&lt;/code&gt; ) through coding agents like Claude Code and Codex. Unsloth provides ~2x faster training and ~60% less VRAM usage compared to standard methods, so training small models can cost just a few dollars.
&lt;p&gt;Why a small model? Small language models like LFM2.5-1.2B-Instruct are ideal candidates for fine-tuning. They are cheap to train, fast to iterate on, and increasingly competitive with much larger models on focused tasks. LFM2.5-1.2B-Instruct runs under 1GB of memory and is optimized for on-device deployment, so what you fine-tune can be served on CPUs, phones, and laptops.&lt;/p&gt;

 &lt;img alt="Watch the video" border="10" height="450" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/unsloth-jobs/screenshot.png" width="800" /&gt;


&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		You will need
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We are giving away free credits to fine-tune models on Hugging Face Jobs. Join the Unsloth Jobs Explorers organization to claim your free credits and one-month Pro subscription.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Hugging Face account (required for HF Jobs) &lt;/li&gt;
&lt;li&gt;Billing setup (for verification, you can monitor your usage and manage your billing in your billing page).&lt;/li&gt;
&lt;li&gt;A Hugging Face token with write permissions&lt;/li&gt;
&lt;li&gt;(optional) A coding agent (&lt;code&gt;Open Code&lt;/code&gt;, &lt;code&gt;Claude Code&lt;/code&gt;, or &lt;code&gt;Codex&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Run the Job
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;If you want to train a model using HF Jobs and Unsloth, you can simply use the &lt;code&gt;hf jobs&lt;/code&gt; CLI to submit a job.&lt;/p&gt;
&lt;p&gt;First, you need to install the &lt;code&gt;hf&lt;/code&gt; CLI. You can do this by running the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mac or linux
curl -LsSf https://hf.co/cli/install.sh | bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next you can run the following command to submit a job:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sh"&gt;hf &lt;span class="hljs-built_in"&gt;jobs&lt;/span&gt; uv run https://huggingface.co/datasets/unsloth/jobs/resolve/main/sft-lfm2.5.py \
    --flavor a10g-small  \
    --secrets HF_TOKEN  \
    --&lt;span class="hljs-built_in"&gt;timeout&lt;/span&gt; 4h \
    --dataset mlabonne/FineTome-100k \
    --num-epochs 1 \
    --eval-split 0.2 \
    --output-repo your-username/lfm-finetuned
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check out the training script and Hugging Face Jobs documentation for more details.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Installing the Skill
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Hugging Face model training skill lowers barrier of entry to train a model by simply prompting. First, install the skill with your coding agent.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Claude Code
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Claude Code discovers skills through its plugin system, so we need to install the Hugging Face skills first. To do so:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add the marketplace:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin marketplace add huggingface/skills
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Browse available skills in the &lt;code&gt;Discover&lt;/code&gt; tab:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Install the model trainer skill:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin install hugging-face-model-trainer@huggingface-skills
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the documentation on using the hub with skills or the Claude Code Skills docs.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Codex
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Codex discovers skills through &lt;code&gt;AGENTS.md&lt;/code&gt; files and &lt;code&gt;.agents/skills/&lt;/code&gt; directories.&lt;/p&gt;
&lt;p&gt;Install individual skills with &lt;code&gt;$skill-installer&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;$skill-installer install https://github.com/huggingface/skills/tree/main/skills/hugging-face-model-trainer
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the Codex Skills docs and the AGENTS.md guide.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Anything else
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;A generic install method is simply to clone the skills repository and copy the skill to your agent's skills directory.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;git clone https://github.com/huggingface/skills.git
mkdir -p ~/.agents/skills &amp;amp;&amp;amp; cp -R skills/skills/hugging-face-model-trainer ~/.agents/skills/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Quick Start
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Once the skill is installed, ask your coding agent to train a model:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;Train LiquidAI/LFM2.5-1.2B-Instruct on mlabonne/FineTome-100k using Unsloth on HF Jobs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The agent will generate a training script based on an example in the skill, submit the training to HF Jobs, and provide a monitoring link via Trackio.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		How It Works
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Training jobs run on Hugging Face Jobs, fully managed cloud GPUs. The agent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generates a UV script with inline dependencies&lt;/li&gt;
&lt;li&gt;Submits it to HF Jobs via the &lt;code&gt;hf&lt;/code&gt; CLI&lt;/li&gt;
&lt;li&gt;Reports the job ID and monitoring URL&lt;/li&gt;
&lt;li&gt;Pushes the trained model to your Hugging Face Hub repository&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Example Training Script
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The skill generates scripts like this based on the example in the skill.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;



&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; unsloth &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; FastLanguageModel
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; trl &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; SFTTrainer, SFTConfig
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; datasets &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; load_dataset

model, tokenizer = FastLanguageModel.from_pretrained(
    &lt;span class="hljs-string"&gt;"LiquidAI/LFM2.5-1.2B-Instruct"&lt;/span&gt;,
    load_in_4bit=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
    max_seq_length=&lt;span class="hljs-number"&gt;2048&lt;/span&gt;,
)

model = FastLanguageModel.get_peft_model(
    model,
    r=&lt;span class="hljs-number"&gt;16&lt;/span&gt;,
    lora_alpha=&lt;span class="hljs-number"&gt;32&lt;/span&gt;,
    lora_dropout=&lt;span class="hljs-number"&gt;0&lt;/span&gt;,
    target_modules=[
        &lt;span class="hljs-string"&gt;"q_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"k_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"v_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"out_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"in_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w1"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w2"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w3"&lt;/span&gt;,
    ],
)

dataset = load_dataset(&lt;span class="hljs-string"&gt;"trl-lib/Capybara"&lt;/span&gt;, split=&lt;span class="hljs-string"&gt;"train"&lt;/span&gt;)

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=SFTConfig(
        output_dir=&lt;span class="hljs-string"&gt;"./output"&lt;/span&gt;,
        push_to_hub=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
        hub_model_id=&lt;span class="hljs-string"&gt;"username/my-model"&lt;/span&gt;,
        per_device_train_batch_size=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        gradient_accumulation_steps=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        num_train_epochs=&lt;span class="hljs-number"&gt;1&lt;/span&gt;,
        learning_rate=&lt;span class="hljs-number"&gt;2e-4&lt;/span&gt;,
        report_to=&lt;span class="hljs-string"&gt;"trackio"&lt;/span&gt;,
    ),
)

trainer.train()
trainer.push_to_hub()
&lt;/code&gt;&lt;/pre&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th align="left"&gt;Model Size&lt;/th&gt;
&lt;th align="left"&gt;Recommended GPU&lt;/th&gt;
&lt;th align="left"&gt;Approx Cost/hr&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td align="left"&gt;&amp;lt;1B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1-3B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-medium&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3-7B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7-13B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-large&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$3.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;For a full overview of Hugging Face Spaces pricing, check out the guide here.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Tips for Working with Coding Agents
	&lt;/span&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Be specific about the model and dataset to use, and include Hub IDs (for example, &lt;code&gt;Qwen/Qwen2.5-0.5B&lt;/code&gt; and &lt;code&gt;trl-lib/Capybara&lt;/code&gt;). Agents will search for and validate those combinations.&lt;/li&gt;
&lt;li&gt;Mention Unsloth explicitly if you want it used. Otherwise, the agent will choose a framework based on the model and budget.&lt;/li&gt;
&lt;li&gt;Ask for cost estimates before launching large jobs.&lt;/li&gt;
&lt;li&gt;Request Trackio monitoring for real-time loss curves.&lt;/li&gt;
&lt;li&gt;Check job status by asking the agent to inspect logs after submission.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h2&gt;

&lt;!-- HTML_TAG_END --&gt;</description><content:encoded>&lt;!-- HTML_TAG_START --&gt;
This blog post covers how to use Unsloth and Hugging Face Jobs for fast LLM fine-tuning (specifically &lt;code&gt;LiquidAI/LFM2.5-1.2B-Instruct&lt;/code&gt; ) through coding agents like Claude Code and Codex. Unsloth provides ~2x faster training and ~60% less VRAM usage compared to standard methods, so training small models can cost just a few dollars.
&lt;p&gt;Why a small model? Small language models like LFM2.5-1.2B-Instruct are ideal candidates for fine-tuning. They are cheap to train, fast to iterate on, and increasingly competitive with much larger models on focused tasks. LFM2.5-1.2B-Instruct runs under 1GB of memory and is optimized for on-device deployment, so what you fine-tune can be served on CPUs, phones, and laptops.&lt;/p&gt;

 &lt;img alt="Watch the video" border="10" height="450" src="https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/unsloth-jobs/screenshot.png" width="800" /&gt;


&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		You will need
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;We are giving away free credits to fine-tune models on Hugging Face Jobs. Join the Unsloth Jobs Explorers organization to claim your free credits and one-month Pro subscription.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A Hugging Face account (required for HF Jobs) &lt;/li&gt;
&lt;li&gt;Billing setup (for verification, you can monitor your usage and manage your billing in your billing page).&lt;/li&gt;
&lt;li&gt;A Hugging Face token with write permissions&lt;/li&gt;
&lt;li&gt;(optional) A coding agent (&lt;code&gt;Open Code&lt;/code&gt;, &lt;code&gt;Claude Code&lt;/code&gt;, or &lt;code&gt;Codex&lt;/code&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Run the Job
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;If you want to train a model using HF Jobs and Unsloth, you can simply use the &lt;code&gt;hf jobs&lt;/code&gt; CLI to submit a job.&lt;/p&gt;
&lt;p&gt;First, you need to install the &lt;code&gt;hf&lt;/code&gt; CLI. You can do this by running the following command:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# mac or linux
curl -LsSf https://hf.co/cli/install.sh | bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next you can run the following command to submit a job:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-sh"&gt;hf &lt;span class="hljs-built_in"&gt;jobs&lt;/span&gt; uv run https://huggingface.co/datasets/unsloth/jobs/resolve/main/sft-lfm2.5.py \
    --flavor a10g-small  \
    --secrets HF_TOKEN  \
    --&lt;span class="hljs-built_in"&gt;timeout&lt;/span&gt; 4h \
    --dataset mlabonne/FineTome-100k \
    --num-epochs 1 \
    --eval-split 0.2 \
    --output-repo your-username/lfm-finetuned
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Check out the training script and Hugging Face Jobs documentation for more details.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Installing the Skill
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Hugging Face model training skill lowers barrier of entry to train a model by simply prompting. First, install the skill with your coding agent.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Claude Code
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Claude Code discovers skills through its plugin system, so we need to install the Hugging Face skills first. To do so:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Add the marketplace:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin marketplace add huggingface/skills
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="2"&gt;
&lt;li&gt;Browse available skills in the &lt;code&gt;Discover&lt;/code&gt; tab:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin
&lt;/code&gt;&lt;/pre&gt;
&lt;ol start="3"&gt;
&lt;li&gt;Install the model trainer skill:&lt;/li&gt;
&lt;/ol&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;/plugin install hugging-face-model-trainer@huggingface-skills
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the documentation on using the hub with skills or the Claude Code Skills docs.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Codex
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;Codex discovers skills through &lt;code&gt;AGENTS.md&lt;/code&gt; files and &lt;code&gt;.agents/skills/&lt;/code&gt; directories.&lt;/p&gt;
&lt;p&gt;Install individual skills with &lt;code&gt;$skill-installer&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;$skill-installer install https://github.com/huggingface/skills/tree/main/skills/hugging-face-model-trainer
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;For more details, see the Codex Skills docs and the AGENTS.md guide.&lt;/p&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Anything else
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;A generic install method is simply to clone the skills repository and copy the skill to your agent's skills directory.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;git clone https://github.com/huggingface/skills.git
mkdir -p ~/.agents/skills &amp;amp;&amp;amp; cp -R skills/skills/hugging-face-model-trainer ~/.agents/skills/
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Quick Start
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Once the skill is installed, ask your coding agent to train a model:&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-text"&gt;Train LiquidAI/LFM2.5-1.2B-Instruct on mlabonne/FineTome-100k using Unsloth on HF Jobs
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The agent will generate a training script based on an example in the skill, submit the training to HF Jobs, and provide a monitoring link via Trackio.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		How It Works
	&lt;/span&gt;
&lt;/h2&gt;
&lt;p&gt;Training jobs run on Hugging Face Jobs, fully managed cloud GPUs. The agent:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Generates a UV script with inline dependencies&lt;/li&gt;
&lt;li&gt;Submits it to HF Jobs via the &lt;code&gt;hf&lt;/code&gt; CLI&lt;/li&gt;
&lt;li&gt;Reports the job ID and monitoring URL&lt;/li&gt;
&lt;li&gt;Pushes the trained model to your Hugging Face Hub repository&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Example Training Script
	&lt;/span&gt;
&lt;/h3&gt;
&lt;p&gt;The skill generates scripts like this based on the example in the skill.&lt;/p&gt;
&lt;pre&gt;&lt;code class="language-python"&gt;



&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; unsloth &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; FastLanguageModel
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; trl &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; SFTTrainer, SFTConfig
&lt;span class="hljs-keyword"&gt;from&lt;/span&gt; datasets &lt;span class="hljs-keyword"&gt;import&lt;/span&gt; load_dataset

model, tokenizer = FastLanguageModel.from_pretrained(
    &lt;span class="hljs-string"&gt;"LiquidAI/LFM2.5-1.2B-Instruct"&lt;/span&gt;,
    load_in_4bit=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
    max_seq_length=&lt;span class="hljs-number"&gt;2048&lt;/span&gt;,
)

model = FastLanguageModel.get_peft_model(
    model,
    r=&lt;span class="hljs-number"&gt;16&lt;/span&gt;,
    lora_alpha=&lt;span class="hljs-number"&gt;32&lt;/span&gt;,
    lora_dropout=&lt;span class="hljs-number"&gt;0&lt;/span&gt;,
    target_modules=[
        &lt;span class="hljs-string"&gt;"q_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"k_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"v_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"out_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"in_proj"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w1"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w2"&lt;/span&gt;,
        &lt;span class="hljs-string"&gt;"w3"&lt;/span&gt;,
    ],
)

dataset = load_dataset(&lt;span class="hljs-string"&gt;"trl-lib/Capybara"&lt;/span&gt;, split=&lt;span class="hljs-string"&gt;"train"&lt;/span&gt;)

trainer = SFTTrainer(
    model=model,
    tokenizer=tokenizer,
    train_dataset=dataset,
    args=SFTConfig(
        output_dir=&lt;span class="hljs-string"&gt;"./output"&lt;/span&gt;,
        push_to_hub=&lt;span class="hljs-literal"&gt;True&lt;/span&gt;,
        hub_model_id=&lt;span class="hljs-string"&gt;"username/my-model"&lt;/span&gt;,
        per_device_train_batch_size=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        gradient_accumulation_steps=&lt;span class="hljs-number"&gt;4&lt;/span&gt;,
        num_train_epochs=&lt;span class="hljs-number"&gt;1&lt;/span&gt;,
        learning_rate=&lt;span class="hljs-number"&gt;2e-4&lt;/span&gt;,
        report_to=&lt;span class="hljs-string"&gt;"trackio"&lt;/span&gt;,
    ),
)

trainer.train()
trainer.push_to_hub()
&lt;/code&gt;&lt;/pre&gt;
&lt;div class="max-w-full overflow-auto"&gt;
	&lt;table&gt;
		&lt;thead&gt;&lt;tr&gt;
&lt;th align="left"&gt;Model Size&lt;/th&gt;
&lt;th align="left"&gt;Recommended GPU&lt;/th&gt;
&lt;th align="left"&gt;Approx Cost/hr&lt;/th&gt;
&lt;/tr&gt;

		&lt;/thead&gt;&lt;tbody&gt;&lt;tr&gt;
&lt;td align="left"&gt;&amp;lt;1B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.40&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1-3B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;t4-medium&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$0.60&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3-7B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-small&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$1.00&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;7-13B params&lt;/td&gt;
&lt;td align="left"&gt;&lt;code&gt;a10g-large&lt;/code&gt;&lt;/td&gt;
&lt;td align="left"&gt;~$3.00&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
	&lt;/table&gt;
&lt;/div&gt;
&lt;p&gt;For a full overview of Hugging Face Spaces pricing, check out the guide here.&lt;/p&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Tips for Working with Coding Agents
	&lt;/span&gt;
&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Be specific about the model and dataset to use, and include Hub IDs (for example, &lt;code&gt;Qwen/Qwen2.5-0.5B&lt;/code&gt; and &lt;code&gt;trl-lib/Capybara&lt;/code&gt;). Agents will search for and validate those combinations.&lt;/li&gt;
&lt;li&gt;Mention Unsloth explicitly if you want it used. Otherwise, the agent will choose a framework based on the model and budget.&lt;/li&gt;
&lt;li&gt;Ask for cost estimates before launching large jobs.&lt;/li&gt;
&lt;li&gt;Request Trackio monitoring for real-time loss curves.&lt;/li&gt;
&lt;li&gt;Check job status by asking the agent to inspect logs after submission.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 class="relative group flex items-center"&gt;
	
		
	
	&lt;span&gt;
		Resources
	&lt;/span&gt;
&lt;/h2&gt;

&lt;!-- HTML_TAG_END --&gt;</content:encoded><guid isPermaLink="false">https://huggingface.co/blog/unsloth-jobs</guid><pubDate>Fri, 20 Feb 2026 00:00:00 +0000</pubDate></item><item><title>Nvidia deepens early-stage push into India’s AI startup ecosystem (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/nvidia-deepens-early-stage-push-into-indias-ai-startup-ecosystem/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia is stepping up efforts to court India’s artificial intelligence startups earlier in their lifecycle, unveiling a string of partnerships this week aimed at reaching founders even before their companies are formally established. The push is intended to help the AI chipmaker cultivate relationships with future customers in one of the world’s fastest-growing developer markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest move comes through a partnership with early-stage venture firm Activate, which plans to back about 25 to 30 AI startups from its $75 million debut fund while giving portfolio companies preferential access to Nvidia’s technical expertise. The collaboration follows other India-focused efforts unveiled this week, including work with nonprofit AI Grants India to support early-stage founders and new ties with venture firms focused on the South Asian nation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The flurry of activity comes as India hosts its AI Impact Summit in New Delhi, drawing top technology companies including OpenAI, Anthropic, and Google. Nvidia Chief Executive Jensen Huang was slated to attend but skipped the event due to what the company called unforeseen circumstances. A senior delegation led by executive vice president Jay Puri attended in his place, meeting AI researchers, startups, developers, and partners on the ground.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India has emerged as one of the fastest-growing pools of AI developers and startups, making it an increasingly important market for Nvidia as it looks to expand adoption of chips and computing software. By working more closely with founders at the earliest stages, the company is positioning itself to capture long-term demand as new AI-native companies scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aakrit Vaish, founder of Activate, said Nvidia’s engagement with startups in India has historically been relatively light-touch compared with the U.S., but the chipmaker is now looking to work with founders much earlier in their journey. Activate aims to leverage that shift by connecting portfolio startups directly with Nvidia experts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The VC firm, which Vaish describes as focused on “inception investing,” meets technical teams months before company formation and works closely with them as they grow. Its backers include venture capitalist Vinod Khosla, Perplexity co-founder Aravind Srinivas, Peak XV managing director Shailendra Singh, and Paytm CEO Vijay Shekhar Sharma, underlining the prominent network Activate is assembling around its early-stage strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Nvidia, the logic behind partnering with an early-stage venture firm is straightforward: the earlier it builds relationships with promising AI startups, the more likely those companies are to rely on its computing infrastructure as they scale. Vaish told TechCrunch that growing startups typically consume increasing amounts of AI compute over time, making early technical engagement valuable for the chipmaker as a way of generating future business.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia already has a sizable presence in the country through its Inception program, which supports more than 4,000 startups in India. This week, the chipmaker also expanded its local ecosystem ties, including partnerships with venture firms such as Accel, Peak XV, Z47, Elevation Capital, and Nexus Venture Partners to identify and fund AI startups. It separately teamed up with AI Grants India, co-founded by Vaibhav Domkundwar and Bhasker (Bosky) Kode, to support more than 10,000 early-stage founders over the next 12 months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has also been broadening its startup outreach in India over time. In November 2025, Nvidia joined the India Deep Tech Alliance, a consortium of U.S. and Indian investors including Accel, Blume Ventures, Premji Invest, and Celesta Capital, to provide strategic and technical guidance to emerging startups in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vaish said Activate’s partnership with Nvidia is designed to provide a more curated layer on top of the company’s broad-based Inception program, which serves thousands of startups globally. By serving as an early filter for high-potential technical teams, Activate aims to give its portfolio companies more direct, timely access to Nvidia’s engineering expertise.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The stepped-up activity underscores intensifying competition among global technology firms to court AI developers and startups in India, which has become one of the fastest-growing pools of technical talent outside the U.S.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/05/GettyImages-2216028442.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Nvidia is stepping up efforts to court India’s artificial intelligence startups earlier in their lifecycle, unveiling a string of partnerships this week aimed at reaching founders even before their companies are formally established. The push is intended to help the AI chipmaker cultivate relationships with future customers in one of the world’s fastest-growing developer markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The latest move comes through a partnership with early-stage venture firm Activate, which plans to back about 25 to 30 AI startups from its $75 million debut fund while giving portfolio companies preferential access to Nvidia’s technical expertise. The collaboration follows other India-focused efforts unveiled this week, including work with nonprofit AI Grants India to support early-stage founders and new ties with venture firms focused on the South Asian nation.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The flurry of activity comes as India hosts its AI Impact Summit in New Delhi, drawing top technology companies including OpenAI, Anthropic, and Google. Nvidia Chief Executive Jensen Huang was slated to attend but skipped the event due to what the company called unforeseen circumstances. A senior delegation led by executive vice president Jay Puri attended in his place, meeting AI researchers, startups, developers, and partners on the ground.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;India has emerged as one of the fastest-growing pools of AI developers and startups, making it an increasingly important market for Nvidia as it looks to expand adoption of chips and computing software. By working more closely with founders at the earliest stages, the company is positioning itself to capture long-term demand as new AI-native companies scale.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Aakrit Vaish, founder of Activate, said Nvidia’s engagement with startups in India has historically been relatively light-touch compared with the U.S., but the chipmaker is now looking to work with founders much earlier in their journey. Activate aims to leverage that shift by connecting portfolio startups directly with Nvidia experts.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The VC firm, which Vaish describes as focused on “inception investing,” meets technical teams months before company formation and works closely with them as they grow. Its backers include venture capitalist Vinod Khosla, Perplexity co-founder Aravind Srinivas, Peak XV managing director Shailendra Singh, and Paytm CEO Vijay Shekhar Sharma, underlining the prominent network Activate is assembling around its early-stage strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;For Nvidia, the logic behind partnering with an early-stage venture firm is straightforward: the earlier it builds relationships with promising AI startups, the more likely those companies are to rely on its computing infrastructure as they scale. Vaish told TechCrunch that growing startups typically consume increasing amounts of AI compute over time, making early technical engagement valuable for the chipmaker as a way of generating future business.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Nvidia already has a sizable presence in the country through its Inception program, which supports more than 4,000 startups in India. This week, the chipmaker also expanded its local ecosystem ties, including partnerships with venture firms such as Accel, Peak XV, Z47, Elevation Capital, and Nexus Venture Partners to identify and fund AI startups. It separately teamed up with AI Grants India, co-founded by Vaibhav Domkundwar and Bhasker (Bosky) Kode, to support more than 10,000 early-stage founders over the next 12 months.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company has also been broadening its startup outreach in India over time. In November 2025, Nvidia joined the India Deep Tech Alliance, a consortium of U.S. and Indian investors including Accel, Blume Ventures, Premji Invest, and Celesta Capital, to provide strategic and technical guidance to emerging startups in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Vaish said Activate’s partnership with Nvidia is designed to provide a more curated layer on top of the company’s broad-based Inception program, which serves thousands of startups globally. By serving as an early filter for high-potential technical teams, Activate aims to give its portfolio companies more direct, timely access to Nvidia’s engineering expertise.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The stepped-up activity underscores intensifying competition among global technology firms to court AI developers and startups in India, which has become one of the fastest-growing pools of technical talent outside the U.S.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/nvidia-deepens-early-stage-push-into-indias-ai-startup-ecosystem/</guid><pubDate>Fri, 20 Feb 2026 00:30:00 +0000</pubDate></item><item><title>Google’s new Gemini Pro model has record benchmark scores — again (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/googles-new-gemini-pro-model-has-record-benchmark-scores-again/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/google-gemini-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Google released the newest version of Gemini Pro, its powerful LLM. The model, 3.1, is currently available as a preview and will be generally released soon, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s new model may be one of the most powerful LLMs yet. Onlookers have noted that Gemini 3.1 Pro appears to be a big step up from its predecessor, Gemini 3 — which, upon its release in November, was already considered a highly capable AI tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Thursday, Google also shared statistics from independent benchmarks — such as one called Humanity’s Last Exam — that showed it performing significantly better than its previous version.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini 3.1 Pro was also praised by Brendan Foody, the CEO of AI startup Mercor, whose benchmarking system, APEX, is designed to measure how well new AI models perform real professional tasks. “Gemini 3.1 Pro is now at the top of the APEX-Agents leaderboard,” Foody said in a social media post, adding that the model’s impressive results show “how quickly agents are improving at real knowledge work.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The release comes as the AI model wars are heating up, and tech companies continue to release increasingly powerful LLMs designed for agentic work and multi-step reasoning. Other major names — including OpenAI and Anthropic — have recently released new models as well.&lt;/p&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2026/01/google-gemini-jagmeet-singh-techcrunch.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;On Thursday, Google released the newest version of Gemini Pro, its powerful LLM. The model, 3.1, is currently available as a preview and will be generally released soon, the company said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google’s new model may be one of the most powerful LLMs yet. Onlookers have noted that Gemini 3.1 Pro appears to be a big step up from its predecessor, Gemini 3 — which, upon its release in November, was already considered a highly capable AI tool.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;On Thursday, Google also shared statistics from independent benchmarks — such as one called Humanity’s Last Exam — that showed it performing significantly better than its previous version.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Gemini 3.1 Pro was also praised by Brendan Foody, the CEO of AI startup Mercor, whose benchmarking system, APEX, is designed to measure how well new AI models perform real professional tasks. “Gemini 3.1 Pro is now at the top of the APEX-Agents leaderboard,” Foody said in a social media post, adding that the model’s impressive results show “how quickly agents are improving at real knowledge work.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The release comes as the AI model wars are heating up, and tech companies continue to release increasingly powerful LLMs designed for agentic work and multi-step reasoning. Other major names — including OpenAI and Anthropic — have recently released new models as well.&lt;/p&gt;




&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/googles-new-gemini-pro-model-has-record-benchmark-scores-again/</guid><pubDate>Fri, 20 Feb 2026 00:55:22 +0000</pubDate></item><item><title>[NEW] General Catalyst commits $5B to India over five years (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-605683074-e1729770670902.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;General Catalyst, a Silicon Valley-based venture firm with more than $43 billion in assets under management, has announced it plans to invest $5 billion in India over the next five years, sharply expanding its push into the country’s startup ecosystem less than two years after merging with local venture firm Venture Highway.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The commitment, unveiled at the India AI Impact Summit in New Delhi on Friday, will target startups across artificial intelligence, healthcare, defense technology, fintech, and consumer technology. The announcement marks a significant increase from the $500 million to $1 billion the firm had previously earmarked for India.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;India, the world’s most populous country with more than a billion internet users, is positioning itself as a major AI investment destination. New Delhi aims to attract over $200 billion in AI infrastructure investments over the next two years as it hosts the India AI Impact Summit with participation from companies, including OpenAI, Anthropic, and Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“India will build the next generation of global platform companies,” General Catalyst CEO Hemant Taneja (pictured above) said, adding that the firm sees Indian founders as uniquely positioned to develop technology for markets serving enormous populations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;General Catalyst said it sees India’s biggest AI opportunity in large-scale real-world deployment rather than in building so-called frontier models. The firm cited the country’s government-built digital infrastructure, vast domestic market, and deep services talent pool as reasons for that view.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The push comes as India’s AI ambitions accelerate. At the summit, conglomerates Adani Group and Reliance Industries, led by billionaire Mukesh Ambani, announced plans to invest more than $200 billion combined to build AI data center infrastructure in the country. OpenAI has separately partnered with Tata Group’s TCS — one of India’s largest tech companies — to develop a 100-megawatt AI data center as part of the expansion of its Stargate infrastructure project. In recent months, global tech companies including Amazon, Google, and Microsoft have also outlined tens of billions of dollars in cloud and AI investments in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;General Catalyst has been building its India portfolio across fast delivery e-commerce, health tech, and deep tech, with investments including Zepto, PB Health, Raphe, Jeh Aerospace, Pronto, and Ayr Energy.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“This investment allows us to operate at a different scale in India,” Neeraj Arora, General Catalyst’s CEO for India, the Middle East, and North Africa, said, adding that the firm aims to support companies from early stage through to the public markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;General Catalyst said it is developing a framework to accelerate large-scale AI adoption across priority sectors in India, aiming to help convert pilot projects into full deployments. The firm’s General Catalyst Institute has also been working to build government-industry partnerships in the country.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/10/GettyImages-605683074-e1729770670902.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;General Catalyst, a Silicon Valley-based venture firm with more than $43 billion in assets under management, has announced it plans to invest $5 billion in India over the next five years, sharply expanding its push into the country’s startup ecosystem less than two years after merging with local venture firm Venture Highway.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The commitment, unveiled at the India AI Impact Summit in New Delhi on Friday, will target startups across artificial intelligence, healthcare, defense technology, fintech, and consumer technology. The announcement marks a significant increase from the $500 million to $1 billion the firm had previously earmarked for India.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;India, the world’s most populous country with more than a billion internet users, is positioning itself as a major AI investment destination. New Delhi aims to attract over $200 billion in AI infrastructure investments over the next two years as it hosts the India AI Impact Summit with participation from companies, including OpenAI, Anthropic, and Google.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“India will build the next generation of global platform companies,” General Catalyst CEO Hemant Taneja (pictured above) said, adding that the firm sees Indian founders as uniquely positioned to develop technology for markets serving enormous populations.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;General Catalyst said it sees India’s biggest AI opportunity in large-scale real-world deployment rather than in building so-called frontier models. The firm cited the country’s government-built digital infrastructure, vast domestic market, and deep services talent pool as reasons for that view.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The push comes as India’s AI ambitions accelerate. At the summit, conglomerates Adani Group and Reliance Industries, led by billionaire Mukesh Ambani, announced plans to invest more than $200 billion combined to build AI data center infrastructure in the country. OpenAI has separately partnered with Tata Group’s TCS — one of India’s largest tech companies — to develop a 100-megawatt AI data center as part of the expansion of its Stargate infrastructure project. In recent months, global tech companies including Amazon, Google, and Microsoft have also outlined tens of billions of dollars in cloud and AI investments in the country.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;General Catalyst has been building its India portfolio across fast delivery e-commerce, health tech, and deep tech, with investments including Zepto, PB Health, Raphe, Jeh Aerospace, Pronto, and Ayr Energy.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;Boston, MA&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;June 9, 2026&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;“This investment allows us to operate at a different scale in India,” Neeraj Arora, General Catalyst’s CEO for India, the Middle East, and North Africa, said, adding that the firm aims to support companies from early stage through to the public markets.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;General Catalyst said it is developing a framework to accelerate large-scale AI adoption across priority sectors in India, aiming to help convert pilot projects into full deployments. The firm’s General Catalyst Institute has also been working to build government-industry partnerships in the country.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2026/02/19/general-catalyst-commits-5b-to-india-over-five-years/</guid><pubDate>Fri, 20 Feb 2026 06:41:44 +0000</pubDate></item></channel></rss>