<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0"><channel><title>AI News Aggregator - Full Text</title><link>https://Tairon861.github.io/ai-news-aggregator/feed.xml</link><description>Recent AI News with Full Content</description><atom:link href="https://Tairon861.github.io/ai-news-aggregator/feed.xml" rel="self"/><docs>http://www.rssboard.org/rss-specification</docs><generator>python-feedgen</generator><language>en</language><lastBuildDate>Fri, 01 Aug 2025 06:37:20 +0000</lastBuildDate><item><title> ()</title><link>https://venturebeat.com/category/ai/feed/</link><description>[unable to retrieve full-text content]</description><content:encoded>[unable to retrieve full-text content]</content:encoded><guid isPermaLink="false">https://venturebeat.com/category/ai/feed/</guid></item><item><title>Your public ChatGPT queries are getting indexed by Google and other search engines (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/your-public-chatgpt-queries-are-getting-indexed-by-google-and-other-search-engines/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Search-in-ChatGPT.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;Update 7/31/25 4:10pm PT: Hours after this article was published, OpenAI said it removed the feature from ChatGPT that allowed users to make their public conversations discoverable by search engines. The company says this was a short-lived experiment that ultimately “introduced too many opportunities for folks to accidentally share things they didn’t intend to.” The original story follows.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a strange glimpse into the human mind: If you filter search results on Google, Bing, and other search engines to only include URLs from the domain “https://chatgpt.com/share,” you can find strangers’ conversations with ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sometimes, these shared conversation links are pretty dull — people ask for help renovating their bathroom, understanding astrophysics, and finding recipe ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another case, one user asks ChatGPT to rewrite their resume for a particular job application (judging by this person’s LinkedIn, which was easy to find based on the details in the chat log, they did not get the job). Someone else is asking questions that sound like they came out of an incel forum. Another person asks the snarky, hostile AI assistant if they can microwave a metal fork (for the record: no), but they continue to ask the AI increasingly absurd and trollish questions, eventually leading it to create a guide called “How to Use a Microwave Without Summoning Satan: A Beginner’s Guide.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT does not make these conversations public by default. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A conversation would be appended with a “/share” URL only if the user deliberately clicks the “share” button on their own chat and then clicks a second “create link” button. The service also declares that “your name, custom instructions, and any messages you add after sharing stay private.” After clicking through to create a link, users can toggle whether or not they want that link to be discoverable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, users may not anticipate that other search engines will index their shared ChatGPT links, potentially betraying personal information (my apologies to the person whose LinkedIn I discovered).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though unintentional, this is a norm that was established in part by Google. When people share public links to files from Google Drive, such as documents with the “Anyone with link can view” setting, Google may index them in Search. However, Google generally does not surface links to Drive documents that have not been publicly posted on the web — for example, a document may appear in search if it is linked on a trusted website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to ChatGPT, these chats were indexed as part of an experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ChatGPT chats are not public unless you choose to share them,” an OpenAI spokesperson told TechCrunch. “We’ve been testing ways to make it easier to share helpful conversations, while keeping users in control, and we recently ended an experiment to have chats appear in search engine results if you explicitly opted in when sharing.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While search engines like Google control the algorithms that determine what content gets surface for search terms, the search engines themselves cannot control what gets indexed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Neither Google nor any other search engine controls what pages are made public on the web,” a Google spokesperson told TechCrunch. “Publishers of these pages have full control over whether they are indexed by search engines.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated, 7/31/25, 5:30 pm ET with comment and additional context from OpenAI.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/Search-in-ChatGPT.jpg?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;&lt;em&gt;Update 7/31/25 4:10pm PT: Hours after this article was published, OpenAI said it removed the feature from ChatGPT that allowed users to make their public conversations discoverable by search engines. The company says this was a short-lived experiment that ultimately “introduced too many opportunities for folks to accidentally share things they didn’t intend to.” The original story follows.&lt;/em&gt;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It’s a strange glimpse into the human mind: If you filter search results on Google, Bing, and other search engines to only include URLs from the domain “https://chatgpt.com/share,” you can find strangers’ conversations with ChatGPT.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Sometimes, these shared conversation links are pretty dull — people ask for help renovating their bathroom, understanding astrophysics, and finding recipe ideas.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In another case, one user asks ChatGPT to rewrite their resume for a particular job application (judging by this person’s LinkedIn, which was easy to find based on the details in the chat log, they did not get the job). Someone else is asking questions that sound like they came out of an incel forum. Another person asks the snarky, hostile AI assistant if they can microwave a metal fork (for the record: no), but they continue to ask the AI increasingly absurd and trollish questions, eventually leading it to create a guide called “How to Use a Microwave Without Summoning Satan: A Beginner’s Guide.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;ChatGPT does not make these conversations public by default. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;A conversation would be appended with a “/share” URL only if the user deliberately clicks the “share” button on their own chat and then clicks a second “create link” button. The service also declares that “your name, custom instructions, and any messages you add after sharing stay private.” After clicking through to create a link, users can toggle whether or not they want that link to be discoverable.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;However, users may not anticipate that other search engines will index their shared ChatGPT links, potentially betraying personal information (my apologies to the person whose LinkedIn I discovered).&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Though unintentional, this is a norm that was established in part by Google. When people share public links to files from Google Drive, such as documents with the “Anyone with link can view” setting, Google may index them in Search. However, Google generally does not surface links to Drive documents that have not been publicly posted on the web — for example, a document may appear in search if it is linked on a trusted website.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;According to ChatGPT, these chats were indexed as part of an experiment.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“ChatGPT chats are not public unless you choose to share them,” an OpenAI spokesperson told TechCrunch. “We’ve been testing ways to make it easier to share helpful conversations, while keeping users in control, and we recently ended an experiment to have chats appear in search engine results if you explicitly opted in when sharing.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;While search engines like Google control the algorithms that determine what content gets surface for search terms, the search engines themselves cannot control what gets indexed.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Neither Google nor any other search engine controls what pages are made public on the web,” a Google spokesperson told TechCrunch. “Publishers of these pages have full control over whether they are indexed by search engines.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;Updated, 7/31/25, 5:30 pm ET with comment and additional context from OpenAI.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/your-public-chatgpt-queries-are-getting-indexed-by-google-and-other-search-engines/</guid><pubDate>Thu, 31 Jul 2025 19:23:07 +0000</pubDate></item><item><title>Enterprises prefer Anthropic’s AI models over anyone else’s, including OpenAI’s (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/enterprises-prefer-anthropics-ai-models-over-anyone-elses-including-openais/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI research lab Anthropic’s AI models are now the top choice for enterprises, surpassing OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic now holds 32% of the enterprise large language model market share by usage, according to a report from Menlo Ventures released on Thursday. OpenAI holds the second-largest market share by usage among enterprises, with 25%.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The figure marks a strong reversal from even just a couple of years ago. Since 2023, OpenAI has seen its market share among enterprises decline sharply, according to the report, as Anthropic’s has steadily risen over the same timeframe. OpenAI held 50% of the enterprise market share by usage just two years ago while Anthropic had 12%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has seen enterprise usage for its models increase over the last few years as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has an even larger market share when it comes to coding, with 42% of the enterprise market share, the largest market share by a wide margin. Enterprise usage of Anthropic’s AI models are more than double OpenAI’s, when it comes to coding, which garnered 21% of overall market share.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s release of its Claude 3.5 Sonnet model in June 2024 is what laid the foundation for the company’s surge in usage, according to the report. The release of Claude 3.7 Sonnet  in February 2025 only accelerated that momentum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings from Menlo Ventures align with anecdotal chatter in the industry, which suggested that enterprise and startup developers preferred Claude over OpenAI’s ChatGPT. Meanwhile, OpenAI has a strong foothold on the consumer side of the house. The company reported last week that its users send more than 2.5 billion prompts to ChatGPT a day.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Menlo Ventures report found enterprises prefer closed models, which Anthropic and OpenAI use. More than half of enterprises replied that they don’t use open source models at all. Only 13% of enterprise daily workloads use open source models as of mid-year 2025, down from 19% at the beginning of the year. Meta still maintains dominance in the open source market.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/06/YouTube-Thumb-Text-2-3.png?resize=1200,675" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;AI research lab Anthropic’s AI models are now the top choice for enterprises, surpassing OpenAI.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic now holds 32% of the enterprise large language model market share by usage, according to a report from Menlo Ventures released on Thursday. OpenAI holds the second-largest market share by usage among enterprises, with 25%.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;The figure marks a strong reversal from even just a couple of years ago. Since 2023, OpenAI has seen its market share among enterprises decline sharply, according to the report, as Anthropic’s has steadily risen over the same timeframe. OpenAI held 50% of the enterprise market share by usage just two years ago while Anthropic had 12%.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Google has seen enterprise usage for its models increase over the last few years as well.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic has an even larger market share when it comes to coding, with 42% of the enterprise market share, the largest market share by a wide margin. Enterprise usage of Anthropic’s AI models are more than double OpenAI’s, when it comes to coding, which garnered 21% of overall market share.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Anthropic’s release of its Claude 3.5 Sonnet model in June 2024 is what laid the foundation for the company’s surge in usage, according to the report. The release of Claude 3.7 Sonnet  in February 2025 only accelerated that momentum.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The findings from Menlo Ventures align with anecdotal chatter in the industry, which suggested that enterprise and startup developers preferred Claude over OpenAI’s ChatGPT. Meanwhile, OpenAI has a strong foothold on the consumer side of the house. The company reported last week that its users send more than 2.5 billion prompts to ChatGPT a day.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;The Menlo Ventures report found enterprises prefer closed models, which Anthropic and OpenAI use. More than half of enterprises replied that they don’t use open source models at all. Only 13% of enterprise daily workloads use open source models as of mid-year 2025, down from 19% at the beginning of the year. Meta still maintains dominance in the open source market.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/enterprises-prefer-anthropics-ai-models-over-anyone-elses-including-openais/</guid><pubDate>Thu, 31 Jul 2025 20:32:49 +0000</pubDate></item><item><title>Apple plans to ‘significantly’ grow AI investments, Cook says (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/apple-plans-to-significantly-grow-ai-investments-cook-says/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/tim-cook-2025-GettyImages-2223580830.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple on Thursday signaled that it’s getting more serious about its plans to catch up in the AI race. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see AI as one of the most profound technologies of our lifetime. We are embedding it across our devices and platforms and across the company. We are also significantly growing our investments,” CEO Tim Cook said on the Q3 2025 earnings call with investors. “Apple has always been about taking the most advanced technologies and making them easy to use and accessible for everyone, and that’s at the heart of our AI strategy,” he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cook expanded on those comments on the call, noting that Apple was “reallocating a fair number of people” to focus on AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a great, great team and we’re putting all of our energy behind it,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI investments are also driving increased CapEx spending, which was up year-to-date, the company said. However, Apple pointed out that it still employed a hybrid model where it relies on third parties to make capital investments, which is why the figure won’t grow exponentially. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ahead of its call, the company shared in an interview with CNBC that it’s open to M&amp;amp;A to accelerate its roadmap. The company told the outlet that it has already acquired seven companies this year. None was “huge” in terms of dollar amount, Cook said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the call, he added that Apple was making acquisitions at the rate of one every several weeks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has been criticized for having been caught off guard by the AI era; it has announced a number of AI features that it has, so far, failed to ship. The company was even accused of showing off an improved AI-powered version of Siri that wasn’t close to being ready to launch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Apple has defended itself by saying that it doesn’t need to rush — that launching the wrong features or the wrong products just to be first would be a mistake. That’s especially true if those products don’t work as promised.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Apple says it has launched more than 20 Apple Intelligence features, including visual intelligence, cleanup, and writing tools. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Later this year, Apple plans to launch AI features like live translation and an AI-powered workout buddy, but the more personalized Siri’s improvements have been delayed to 2026. On the call with investors, Cook said the company was “making good progress” on the Siri update. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also shared his thoughts on how AI may impact the iPhone business if new hardware were to emerge. For instance, Meta CEO Mark Zuckerberg earlier this week suggested that AI glasses would be the form factor for interacting with the new technology, and those without them would be left behind. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cook, naturally, disagreed. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s difficult to see a world where iPhone’s not living in it,” he said. “That doesn’t mean that we are not thinking about other things, as well, but I think that the [AI] devices are likely to be complementary devices, not substitutions.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exec declined to answer a question about which AI technologies it believed would ultimately be commoditized, saying that would give away part of its strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple delivered better-than-expected iPhone sales and record revenue in Q3, which saw its stock pop in after-hours trading.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after initial publication with more details from the earnings call. &lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/tim-cook-2025-GettyImages-2223580830.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Apple on Thursday signaled that it’s getting more serious about its plans to catch up in the AI race. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We see AI as one of the most profound technologies of our lifetime. We are embedding it across our devices and platforms and across the company. We are also significantly growing our investments,” CEO Tim Cook said on the Q3 2025 earnings call with investors. “Apple has always been about taking the most advanced technologies and making them easy to use and accessible for everyone, and that’s at the heart of our AI strategy,” he added.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Cook expanded on those comments on the call, noting that Apple was “reallocating a fair number of people” to focus on AI. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We have a great, great team and we’re putting all of our energy behind it,” he added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;AI investments are also driving increased CapEx spending, which was up year-to-date, the company said. However, Apple pointed out that it still employed a hybrid model where it relies on third parties to make capital investments, which is why the figure won’t grow exponentially. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Ahead of its call, the company shared in an interview with CNBC that it’s open to M&amp;amp;A to accelerate its roadmap. The company told the outlet that it has already acquired seven companies this year. None was “huge” in terms of dollar amount, Cook said.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;On the call, he added that Apple was making acquisitions at the rate of one every several weeks.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Apple has been criticized for having been caught off guard by the AI era; it has announced a number of AI features that it has, so far, failed to ship. The company was even accused of showing off an improved AI-powered version of Siri that wasn’t close to being ready to launch.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Apple has defended itself by saying that it doesn’t need to rush — that launching the wrong features or the wrong products just to be first would be a mistake. That’s especially true if those products don’t work as promised.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;So far, Apple says it has launched more than 20 Apple Intelligence features, including visual intelligence, cleanup, and writing tools. &lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Later this year, Apple plans to launch AI features like live translation and an AI-powered workout buddy, but the more personalized Siri’s improvements have been delayed to 2026. On the call with investors, Cook said the company was “making good progress” on the Siri update. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;He also shared his thoughts on how AI may impact the iPhone business if new hardware were to emerge. For instance, Meta CEO Mark Zuckerberg earlier this week suggested that AI glasses would be the form factor for interacting with the new technology, and those without them would be left behind. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Cook, naturally, disagreed. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“It’s difficult to see a world where iPhone’s not living in it,” he said. “That doesn’t mean that we are not thinking about other things, as well, but I think that the [AI] devices are likely to be complementary devices, not substitutions.” &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The exec declined to answer a question about which AI technologies it believed would ultimately be commoditized, saying that would give away part of its strategy.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Apple delivered better-than-expected iPhone sales and record revenue in Q3, which saw its stock pop in after-hours trading.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;&lt;em&gt;This article was updated after initial publication with more details from the earnings call. &lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/apple-plans-to-significantly-grow-ai-investments-cook-says/</guid><pubDate>Thu, 31 Jul 2025 21:21:41 +0000</pubDate></item><item><title>YouTube’s selfie collection, AI age checks are concerning, privacy experts say (AI – Ars Technica)</title><link>https://arstechnica.com/tech-policy/2025/07/youtubes-selfie-collection-ai-age-checks-are-concerning-privacy-experts-say/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Any YouTuber wrongly labeled a teen must provide an ID, credit card, or selfie.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Privacy experts are demanding transparency after YouTube announced it would test using AI to estimate user ages in the US ahead of a wider rollout of the age check system.&lt;/p&gt;
&lt;p&gt;Throughout the first half of August, YouTube will begin interpreting "a variety of signals" to determine if certain users are under 18. No new user data will be collected, but those signals could include things like "the types of videos a user is searching for, the categories of videos they have watched, or the longevity of the account," YouTube said.&lt;/p&gt;
&lt;p&gt;Anyone determined to be too young will automatically be hit with protections, with YouTube disabling their personalized advertising, "turning on digital wellbeing tools," and "limiting repetitive views of some kinds of content" determined to be harmful or too mature.&lt;/p&gt;
&lt;p&gt;YouTube claims it has been estimating age in other markets "for some time, where it is working well." But it's clearly not a perfect system, as the company has set up an appeals process for any adults accidentally flagged as teens by AI.&lt;/p&gt;
&lt;p&gt;That appeals process seems problematic, privacy experts told Ars,&amp;nbsp; as it requires users to submit a government ID, credit card, or selfie to verify their actual age. YouTube does not specify in its blog what will happen with this data. Asked for comment, YouTube would only confirm to Ars that the company "does not retain data from" a user's "ID or Payment Card for the purposes of advertising."&lt;/p&gt;
&lt;p&gt;"I think we can assume that means it will be retained for other purposes," David Greene, senior staff attorney and civil liberties director for the Electronic Frontier Foundation (EFF), told Ars. But the lack of transparency leaves users guessing about those other purposes, as risks of leaks or breaches seemingly risk exposing vulnerable users who rely on anonymity to use YouTube.&lt;/p&gt;
&lt;p&gt;Greene told Ars that YouTube's statement on data retention is even weaker and stands in "stark contrast" to "hollow statements" sometimes made by companies, such as "we'll do our best to protect your data" or "we've been assured that the third-party vendor we use will not retain the data."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Suzanne Bernstein, who serves as counsel for the Electronic Privacy Information Center (EPIC), said it's "tough" to rely on any company's promises when it comes to using data for other purposes, like enhancing its user profiles or selling data to third parties. She suggested that users would be better informed if YouTube shared more information about how data collected for reverse age checks is stored, whether it's ever sold, and, perhaps most importantly, how soon it's deleted.&lt;/p&gt;
&lt;p&gt;Until then, "discomfort with certain appeals processes which require providing really sensitive personal information is totally understandable," Bernstein said.&lt;/p&gt;
&lt;p&gt;"I think the increased surveillance of user behavior is not privacy protective," Bernstein said. "The most privacy protective option involves retaining the least amount of information and certainly not sharing it with third parties, which is not something that YouTube here has promised to do."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;What’s worse, sharing a selfie or a credit card?&lt;/h2&gt;
&lt;p&gt;In addition to a lack of transparency around the data retention practices, Bernstein noted that YouTube is not being very transparent about how effective its AI age checks are—which is a recurring AI industry pattern that's often repeated as the tech is hyped across many sectors. Greene noted that YouTube does not seem to have conducted any external audits on the AI system or provided any "academic way of looking at it."&lt;/p&gt;
&lt;p&gt;Neither expert felt comfortable quantifying a potential error rate, but it's likely that AI could guess users' ages wrong. Even the best age-estimation tech has about a two-year error window on each side, experts pointed out. That could mean users between 16 and 20 are especially susceptible to incorrect age estimations—with potential errors going both ways, perhaps labeling teens as adults or adults as teens—in addition to perhaps anyone whose viewing habits strike the system as immature.&lt;/p&gt;
&lt;p&gt;Companies launching AI tools that heighten data privacy risks—especially on platforms as big and irreplaceable for many as YouTube—is part of the reason why groups like the EFF and EPIC push for state or federal legislation to minimize consumer data collection and provide other protections to help put personal data back under users' control, no matter how tech evolves. Bernstein suggested that users alarmed by the AI age checks should "encourage legislators to require significant privacy and data security safeguards for any kind of age assurance" systems.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bernstein and Greene agreed that due to the lack of comprehensive data privacy legislation, YouTubers who want to appeal AI mistakes do not have great options.&lt;/p&gt;
&lt;p&gt;"They're all bad," Greene said. But in particular, sharing selfies or any "kind of biometric age estimation tools without significant privacy and data security safeguards" is risky, Bernstein said.&lt;/p&gt;
&lt;p&gt;As Greene explained, any biometric data collection "is really bad and creepy and inhibiting to users who are sensitive" about "identifying themselves while online line," such as political dissidents or victims of abuse. Suddenly, it could be their "burden" to "submit biometric information or government ID in order to use the service," Greene said. That's a huge change for people used to being on YouTube without using their real name or without allowing their information to be traced across the Internet.&lt;/p&gt;
&lt;p&gt;"A breach of biometric information is far more significant than a breach of some other information," Greene said. "So we should be concerned about them collecting selfies."&lt;/p&gt;
&lt;p&gt;But that doesn't mean the selfie option is the worst choice for everyone who can't abandon YouTube, Greene noted. Each user will have to assess their own risks, with some likely more vulnerable to having their identity exposed and others likely more vulnerable to having financial data exposed.&lt;/p&gt;
&lt;p&gt;Greene expects that the more pressure platforms and websites face to age-gate services, the more radically it could change people's relationships with the Internet. On a platform where creators reliably generate the highest earnings, YouTube's AI age checks could possibly serve as a harbinger of a future Internet where every popular account can be unmasked and linked to a known entity.&lt;/p&gt;
&lt;p&gt;"Once you get into this bad situation where it's impossible to use these services anonymously, then it really depends on someone's own threat model about what's going to be the least harmful way for them to use the site," Greene said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        Any YouTuber wrongly labeled a teen must provide an ID, credit card, or selfie.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="alt" class="absolute inset-0 w-full h-full object-cover hidden" height="427" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-640x427.jpg" width="640" /&gt;
                  &lt;img alt="alt" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/GettyImages-2210697264-1024x648.jpg" width="1024" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_7px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

                      
          
          NurPhoto / Contributor | NurPhoto

                      
                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;p&gt;Privacy experts are demanding transparency after YouTube announced it would test using AI to estimate user ages in the US ahead of a wider rollout of the age check system.&lt;/p&gt;
&lt;p&gt;Throughout the first half of August, YouTube will begin interpreting "a variety of signals" to determine if certain users are under 18. No new user data will be collected, but those signals could include things like "the types of videos a user is searching for, the categories of videos they have watched, or the longevity of the account," YouTube said.&lt;/p&gt;
&lt;p&gt;Anyone determined to be too young will automatically be hit with protections, with YouTube disabling their personalized advertising, "turning on digital wellbeing tools," and "limiting repetitive views of some kinds of content" determined to be harmful or too mature.&lt;/p&gt;
&lt;p&gt;YouTube claims it has been estimating age in other markets "for some time, where it is working well." But it's clearly not a perfect system, as the company has set up an appeals process for any adults accidentally flagged as teens by AI.&lt;/p&gt;
&lt;p&gt;That appeals process seems problematic, privacy experts told Ars,&amp;nbsp; as it requires users to submit a government ID, credit card, or selfie to verify their actual age. YouTube does not specify in its blog what will happen with this data. Asked for comment, YouTube would only confirm to Ars that the company "does not retain data from" a user's "ID or Payment Card for the purposes of advertising."&lt;/p&gt;
&lt;p&gt;"I think we can assume that means it will be retained for other purposes," David Greene, senior staff attorney and civil liberties director for the Electronic Frontier Foundation (EFF), told Ars. But the lack of transparency leaves users guessing about those other purposes, as risks of leaks or breaches seemingly risk exposing vulnerable users who rely on anonymity to use YouTube.&lt;/p&gt;
&lt;p&gt;Greene told Ars that YouTube's statement on data retention is even weaker and stands in "stark contrast" to "hollow statements" sometimes made by companies, such as "we'll do our best to protect your data" or "we've been assured that the third-party vendor we use will not retain the data."&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Suzanne Bernstein, who serves as counsel for the Electronic Privacy Information Center (EPIC), said it's "tough" to rely on any company's promises when it comes to using data for other purposes, like enhancing its user profiles or selling data to third parties. She suggested that users would be better informed if YouTube shared more information about how data collected for reverse age checks is stored, whether it's ever sold, and, perhaps most importantly, how soon it's deleted.&lt;/p&gt;
&lt;p&gt;Until then, "discomfort with certain appeals processes which require providing really sensitive personal information is totally understandable," Bernstein said.&lt;/p&gt;
&lt;p&gt;"I think the increased surveillance of user behavior is not privacy protective," Bernstein said. "The most privacy protective option involves retaining the least amount of information and certainly not sharing it with third parties, which is not something that YouTube here has promised to do."&lt;/p&gt;
&lt;div class="page-anchor-wrapper"&gt;&lt;/div&gt;
&lt;h2&gt;What’s worse, sharing a selfie or a credit card?&lt;/h2&gt;
&lt;p&gt;In addition to a lack of transparency around the data retention practices, Bernstein noted that YouTube is not being very transparent about how effective its AI age checks are—which is a recurring AI industry pattern that's often repeated as the tech is hyped across many sectors. Greene noted that YouTube does not seem to have conducted any external audits on the AI system or provided any "academic way of looking at it."&lt;/p&gt;
&lt;p&gt;Neither expert felt comfortable quantifying a potential error rate, but it's likely that AI could guess users' ages wrong. Even the best age-estimation tech has about a two-year error window on each side, experts pointed out. That could mean users between 16 and 20 are especially susceptible to incorrect age estimations—with potential errors going both ways, perhaps labeling teens as adults or adults as teens—in addition to perhaps anyone whose viewing habits strike the system as immature.&lt;/p&gt;
&lt;p&gt;Companies launching AI tools that heighten data privacy risks—especially on platforms as big and irreplaceable for many as YouTube—is part of the reason why groups like the EFF and EPIC push for state or federal legislation to minimize consumer data collection and provide other protections to help put personal data back under users' control, no matter how tech evolves. Bernstein suggested that users alarmed by the AI age checks should "encourage legislators to require significant privacy and data security safeguards for any kind of age assurance" systems.&lt;/p&gt;

          
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;Bernstein and Greene agreed that due to the lack of comprehensive data privacy legislation, YouTubers who want to appeal AI mistakes do not have great options.&lt;/p&gt;
&lt;p&gt;"They're all bad," Greene said. But in particular, sharing selfies or any "kind of biometric age estimation tools without significant privacy and data security safeguards" is risky, Bernstein said.&lt;/p&gt;
&lt;p&gt;As Greene explained, any biometric data collection "is really bad and creepy and inhibiting to users who are sensitive" about "identifying themselves while online line," such as political dissidents or victims of abuse. Suddenly, it could be their "burden" to "submit biometric information or government ID in order to use the service," Greene said. That's a huge change for people used to being on YouTube without using their real name or without allowing their information to be traced across the Internet.&lt;/p&gt;
&lt;p&gt;"A breach of biometric information is far more significant than a breach of some other information," Greene said. "So we should be concerned about them collecting selfies."&lt;/p&gt;
&lt;p&gt;But that doesn't mean the selfie option is the worst choice for everyone who can't abandon YouTube, Greene noted. Each user will have to assess their own risks, with some likely more vulnerable to having their identity exposed and others likely more vulnerable to having financial data exposed.&lt;/p&gt;
&lt;p&gt;Greene expects that the more pressure platforms and websites face to age-gate services, the more radically it could change people's relationships with the Internet. On a platform where creators reliably generate the highest earnings, YouTube's AI age checks could possibly serve as a harbinger of a future Internet where every popular account can be unmasked and linked to a known entity.&lt;/p&gt;
&lt;p&gt;"Once you get into this bad situation where it's impossible to use these services anonymously, then it really depends on someone's own threat model about what's going to be the least harmful way for them to use the site," Greene said.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/tech-policy/2025/07/youtubes-selfie-collection-ai-age-checks-are-concerning-privacy-experts-say/</guid><pubDate>Thu, 31 Jul 2025 21:27:34 +0000</pubDate></item><item><title>Reddit revenue soars as it bets on AI and advertising (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/reddit-revenue-soars-as-it-bets-on-ai-and-advertising/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/reddit-ipo-v2.webp?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Reddit reported its second-quarter earnings on Thursday, and it’s clear that the company’s focus on AI has ramped up considerably.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One significant area of investment is growing its advertising business, supported by its AI-powered marketing tools. The results revealed that the majority of Reddit’s revenue continues to come from ads, which brought in $465 million, representing 93% of the company’s total revenue.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last month, Reddit launched two new features for advertisers: Reddit Insights, a tool that leverages the billions of posts and comments on the platform to spot trends and offer real-time insights for campaign strategies, and Conversation Summary Add-ons, which let advertisers include Reddit user discussions directly in ads, showing public opinions about products or brands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also saw growth in its “other revenue” category, which includes its data licensing business — meaning its deals with AI providers for access to its data. Reddit said the category jumped 24% year-over-year to $35 million, up from $28.1 million in the same period a year prior.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reddit has already established content licensing agreements with major players in AI, including Google and OpenAI. Although these deals are still new, the results from the second quarter point out a steady income stream that has significant potential for the long haul.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another key AI-powered feature is the Reddit Answers tool, which launched in December. This tool, which offers answers in a conversational interface, has attracted 6 million weekly users, a considerable jump from 1 million users in the previous quarter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a letter to shareholders, Reddit CEO Steve Huffman said the platform is working to integrate the tool “more deeply into the core search experience” to make “search a central feature across Reddit.”&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2024/05/reddit-ipo-v2.webp?resize=1200,674" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Reddit reported its second-quarter earnings on Thursday, and it’s clear that the company’s focus on AI has ramped up considerably.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;One significant area of investment is growing its advertising business, supported by its AI-powered marketing tools. The results revealed that the majority of Reddit’s revenue continues to come from ads, which brought in $465 million, representing 93% of the company’s total revenue.&amp;nbsp;&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Last month, Reddit launched two new features for advertisers: Reddit Insights, a tool that leverages the billions of posts and comments on the platform to spot trends and offer real-time insights for campaign strategies, and Conversation Summary Add-ons, which let advertisers include Reddit user discussions directly in ads, showing public opinions about products or brands.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The company also saw growth in its “other revenue” category, which includes its data licensing business — meaning its deals with AI providers for access to its data. Reddit said the category jumped 24% year-over-year to $35 million, up from $28.1 million in the same period a year prior.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Reddit has already established content licensing agreements with major players in AI, including Google and OpenAI. Although these deals are still new, the results from the second quarter point out a steady income stream that has significant potential for the long haul.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Another key AI-powered feature is the Reddit Answers tool, which launched in December. This tool, which offers answers in a conversational interface, has attracted 6 million weekly users, a considerable jump from 1 million users in the previous quarter.&amp;nbsp;&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;In a letter to shareholders, Reddit CEO Steve Huffman said the platform is working to integrate the tool “more deeply into the core search experience” to make “search a central feature across Reddit.”&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/reddit-revenue-soars-as-it-bets-on-ai-and-advertising/</guid><pubDate>Thu, 31 Jul 2025 22:13:23 +0000</pubDate></item><item><title>Developer survey shows trust in AI coding tools is falling as usage rises (AI – Ars Technica)</title><link>https://arstechnica.com/ai/2025/07/developer-survey-shows-trust-in-ai-coding-tools-is-falling-as-usage-rises/</link><description>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "AI solutions that are almost right, but not quite" lead to more debugging work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The tab key on a Keychron K1" class="absolute inset-0 w-full h-full object-cover hidden" height="374" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-640x374.jpg" width="640" /&gt;
                  &lt;img alt="The tab key on a Keychron K1" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You need to do more than just hit tab on suggestions.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI tools are widely used by software developers, but those devs and their managers are still grappling with figuring out how exactly to best put the tools to use, with growing pains emerging along the way.&lt;/p&gt;
&lt;p&gt;That's the takeaway from the latest survey of 49,000 professional developers by community and information hub Stack Overflow, which itself has been heavily impacted by the addition of large language models (LLMs) to developer workflows.&lt;/p&gt;
&lt;p&gt;The survey found that four in five developers use AI tools in their workflow in 2025—a portion that has been rapidly growing in recent years. That said, "trust in the accuracy of AI has fallen from 40 percent in previous years to just 29 percent this year."&lt;/p&gt;
&lt;p&gt;The disparity between those two metrics illustrates the evolving and complex impact of AI tools like GitHub Copilot or Cursor on the profession. There's relatively little debate among developers that the tools are or ought to be useful, but people are still figuring out what the best applications (and limits) are.&lt;/p&gt;
&lt;p&gt;When asked what their top frustration with AI tools was, 45 percent of respondents said they struggled with "AI solutions that are almost right, but not quite"—the single largest reported problem. That's because unlike outputs that are clearly wrong, these can introduce insidious bugs or other problems that are difficult to immediately identify and relatively time-consuming to troubleshoot, especially for junior developers who approached the work with a false sense of confidence thanks to their reliance on AI.&lt;/p&gt;
&lt;p&gt;As a result, more than a third of the developers in the survey "report that some of their visits to Stack Overflow are a result of AI-related issues." That is to say, code suggestions they accepted from an LLM-based tool introduced problems they then had to turn to other people to solve.&lt;/p&gt;
&lt;p&gt;Even as major improvements have recently come via reasoning-optimized models, that close-but-not-quite unreliability is unlikely to ever vanish completely; it's endemic to the very nature of how the predictive technology works.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That's why 72 percent of the survey participants said that "vibe coding" is not part of their professional work; some feel it's too unreliable, and it can introduce hard-to-debug issues that are not appropriate for production.&lt;/p&gt;
&lt;h2&gt;Why devs use the tools anyway&lt;/h2&gt;
&lt;p&gt;So given all that skepticism and frustration, why are devs still using the tools? Well, in some cases, their managers are trying to force them to. But more commonly, it's because the tools are still clearly useful—it's just important not to misapply them.&lt;/p&gt;
&lt;p&gt;It's important that managers and individual contributors bring AI tools into the workflow alongside robust training to ensure a deep understanding of best practices so the tools aren't misused in a way that creates more problems than it solves or that wastes more time than it saves.&lt;/p&gt;
&lt;p&gt;Developers need to be less trusting of things like Copilot autocomplete suggestions, treating them more as a starting point rather than just hitting tab and moving on. Tools like that are best suited for a sort of limited pair programming relationship: asking the LLM to find problems or suggest more elegant solutions that you take into critical consideration, not to suggest complete methods that you take at face value.&lt;/p&gt;
&lt;p&gt;They can also be useful for learning. The opportunity to always be learning by continually building familiarity with new languages, frameworks, or methodologies is one of the things that draws some people to the job, and LLMs can reduce friction in that process by answering questions in a more targeted way than is possible with laborious searches through often incomplete technical documentation—exactly the sort of thing that people have historically used Stack Overflow for in the past.&lt;/p&gt;
&lt;p&gt;"Although we have seen a decline in traffic, in no way is it as dramatic as some would indicate," Stack Overflow Chief Product and Technology Officer Jody Bailey said in a comment to VentureBeat. Stack Overflow plans to commit some of its resources both to expanding AI tool literacy and to fostering community discussions that help solve issues that are specific to workflows that involve those tools.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</description><content:encoded>&lt;header&gt;
  &lt;div class="dusk:bg-gray-700 my-4 bg-gray-100 pt-2 dark:bg-gray-700 md:mt-10 md:pt-5 lg:pb-2 lg:pt-7"&gt;
  &lt;div class="mx-auto grid-cols-2 gap-8 md:px-5 lg:grid lg:max-w-5xl lg:px-8 xl:px-0"&gt;
    &lt;div class="class"&gt;
      

      

      &lt;p class="text-gray-550 dark:text-gray-250 dusk:text-gray-250 mt-4 px-[15px] text-lg leading-tight sm:px-5 md:px-0"&gt;
        "AI solutions that are almost right, but not quite" lead to more debugging work.
      &lt;/p&gt;

      
    &lt;/div&gt;

    &lt;div class="min-h-1 mt-4 lg:mt-0"&gt;
              &lt;div class="relative aspect-video overflow-hidden"&gt;
                      &lt;div class="ars-lightbox"&gt;
              &lt;div class="ars-lightbox-item"&gt;
                
                  &lt;img alt="The tab key on a Keychron K1" class="absolute inset-0 w-full h-full object-cover hidden" height="374" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-640x374.jpg" width="640" /&gt;
                  &lt;img alt="The tab key on a Keychron K1" class="intro-image absolute min-w-full min-h-full h-auto object-cover" height="648" src="https://cdn.arstechnica.net/wp-content/uploads/2025/07/tab-key-1152x648.jpg" width="1152" /&gt;
                
                
              &lt;/div&gt;
            &lt;/div&gt;
          
        &lt;/div&gt;
        &lt;div class="px-[15px] sm:px-5 md:px-0"&gt;&lt;div class="caption font-impact dusk:text-gray-300 mb-4 mt-2 inline-flex flex-row items-stretch gap-1 text-base leading-tight text-gray-400 dark:text-gray-300"&gt;
    &lt;div class="caption-icon bg-[left_top_5px] w-[10px] shrink-0"&gt;&lt;/div&gt;
    &lt;div class="caption-content"&gt;
      You need to do more than just hit tab on suggestions.

              &lt;span class="caption-credit mt-2 text-xs"&gt;
          Credit:

          
          Samuel Axon

                  &lt;/span&gt;
          &lt;/div&gt;
  &lt;/div&gt;&lt;/div&gt;
          &lt;/div&gt;
  &lt;/div&gt;
&lt;/div&gt;
&lt;/header&gt;


  

  
      
    
    &lt;div class="my-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
                      
                      
          &lt;p&gt;AI tools are widely used by software developers, but those devs and their managers are still grappling with figuring out how exactly to best put the tools to use, with growing pains emerging along the way.&lt;/p&gt;
&lt;p&gt;That's the takeaway from the latest survey of 49,000 professional developers by community and information hub Stack Overflow, which itself has been heavily impacted by the addition of large language models (LLMs) to developer workflows.&lt;/p&gt;
&lt;p&gt;The survey found that four in five developers use AI tools in their workflow in 2025—a portion that has been rapidly growing in recent years. That said, "trust in the accuracy of AI has fallen from 40 percent in previous years to just 29 percent this year."&lt;/p&gt;
&lt;p&gt;The disparity between those two metrics illustrates the evolving and complex impact of AI tools like GitHub Copilot or Cursor on the profession. There's relatively little debate among developers that the tools are or ought to be useful, but people are still figuring out what the best applications (and limits) are.&lt;/p&gt;
&lt;p&gt;When asked what their top frustration with AI tools was, 45 percent of respondents said they struggled with "AI solutions that are almost right, but not quite"—the single largest reported problem. That's because unlike outputs that are clearly wrong, these can introduce insidious bugs or other problems that are difficult to immediately identify and relatively time-consuming to troubleshoot, especially for junior developers who approached the work with a false sense of confidence thanks to their reliance on AI.&lt;/p&gt;
&lt;p&gt;As a result, more than a third of the developers in the survey "report that some of their visits to Stack Overflow are a result of AI-related issues." That is to say, code suggestions they accepted from an LLM-based tool introduced problems they then had to turn to other people to solve.&lt;/p&gt;
&lt;p&gt;Even as major improvements have recently come via reasoning-optimized models, that close-but-not-quite unreliability is unlikely to ever vanish completely; it's endemic to the very nature of how the predictive technology works.&lt;/p&gt;

          
                      &lt;div class="ars-interlude-container in-content-interlude mx-auto max-w-xl"&gt;
            &lt;/div&gt;
                  &lt;/div&gt;

              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;
                    
        &lt;div class="ad-wrapper with-label is-fullwidth"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--mid-content"&gt;
          &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
          
    
    &lt;div class="mt-2.5 mx-auto px-[15px] sm:px-5 lg:grid lg:max-w-5xl lg:grid-cols-3 lg:gap-6 lg:px-8 xl:px-0"&gt;
      &lt;div class="relative lg:col-span-2"&gt;

        
        &lt;div class="post-content post-content-double"&gt;
          
          
&lt;p&gt;That's why 72 percent of the survey participants said that "vibe coding" is not part of their professional work; some feel it's too unreliable, and it can introduce hard-to-debug issues that are not appropriate for production.&lt;/p&gt;
&lt;h2&gt;Why devs use the tools anyway&lt;/h2&gt;
&lt;p&gt;So given all that skepticism and frustration, why are devs still using the tools? Well, in some cases, their managers are trying to force them to. But more commonly, it's because the tools are still clearly useful—it's just important not to misapply them.&lt;/p&gt;
&lt;p&gt;It's important that managers and individual contributors bring AI tools into the workflow alongside robust training to ensure a deep understanding of best practices so the tools aren't misused in a way that creates more problems than it solves or that wastes more time than it saves.&lt;/p&gt;
&lt;p&gt;Developers need to be less trusting of things like Copilot autocomplete suggestions, treating them more as a starting point rather than just hitting tab and moving on. Tools like that are best suited for a sort of limited pair programming relationship: asking the LLM to find problems or suggest more elegant solutions that you take into critical consideration, not to suggest complete methods that you take at face value.&lt;/p&gt;
&lt;p&gt;They can also be useful for learning. The opportunity to always be learning by continually building familiarity with new languages, frameworks, or methodologies is one of the things that draws some people to the job, and LLMs can reduce friction in that process by answering questions in a more targeted way than is possible with laborious searches through often incomplete technical documentation—exactly the sort of thing that people have historically used Stack Overflow for in the past.&lt;/p&gt;
&lt;p&gt;"Although we have seen a decline in traffic, in no way is it as dramatic as some would indicate," Stack Overflow Chief Product and Technology Officer Jody Bailey said in a comment to VentureBeat. Stack Overflow plans to commit some of its resources both to expanding AI tool literacy and to fostering community discussions that help solve issues that are specific to workflows that involve those tools.&lt;/p&gt;


          
                  &lt;/div&gt;

                  
          &lt;div class="-mx-2.5 sm:mx-0"&gt;
  &lt;/div&gt;






  


  
              &lt;/div&gt;

      
      &lt;div class="dusk:bg-gray-100 hidden min-w-[300px] justify-self-end lg:block dark:bg-gray-50"&gt;
        
                  &lt;div class="ad-wrapper is-sticky is-rail"&gt;
        &lt;div class="ad-wrapper-inner"&gt;
            &lt;div class="ad ad--rail"&gt;&lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
              &lt;/div&gt;
    &lt;/div&gt;</content:encoded><guid isPermaLink="false">https://arstechnica.com/ai/2025/07/developer-survey-shows-trust-in-ai-coding-tools-is-falling-as-usage-rises/</guid><pubDate>Thu, 31 Jul 2025 22:39:22 +0000</pubDate></item><item><title>What’s the real cost of chasing AGI? Power consolidation is just the start, says the AI Now Institute. (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/podcast/who-really-benefits-from-the-ai-boom/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;If you’ve been hearing about Trump’s AI Action Plan and wondering who it actually benefits, you’re not alone.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan caught up with Amba Kak and Dr. Sarah Myers West from the AI Now Institute, a think tank focused on the social implications of AI and the consolidation of power in the tech industry. Their recent report, dubbed Artificial Power, lays out the political economy driving today’s AI frenzy and what’s at stake for everyone else.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Artificial Power pushes back on what AI Now calls the “too big to fail” myth, arguing that AI companies are pouring billions into massive compute infrastructure and foundational models, often with government support, despite shaky business models and limited public accountability.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;That push to scale and reach AGI, or artificial general intelligence, before 2030 has real-world consequences that don’t disappear with the promises that AI will someday solve humanity’s hardest problems. In the short term, societies are already facing environmental degradation, discriminatory algorithms, dismantled democratic institutions, lack of data privacy, and national security risk.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Kak and West say these outcomes are the result of a series of choices, not an unpreventable reality.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The future we’re being sold is not inevitable,” Kak explained.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI’s growing consolidation and how it mirrors Big Tech’s power dynamics.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Silicon Valley is cheering on Trump’s AI agenda, and the challenges of regulating AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The disconnect between AGI hype and current, real-world harms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What a democratic, just, and accountable AI future could look like.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225853634.jpg?w=1024" /&gt;&lt;/div&gt;&lt;p class="has-text-align-left wp-block-paragraph" id="speakable-summary"&gt;If you’ve been hearing about Trump’s AI Action Plan and wondering who it actually benefits, you’re not alone.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;On today’s episode of Equity, Rebecca Bellan caught up with Amba Kak and Dr. Sarah Myers West from the AI Now Institute, a think tank focused on the social implications of AI and the consolidation of power in the tech industry. Their recent report, dubbed Artificial Power, lays out the political economy driving today’s AI frenzy and what’s at stake for everyone else.&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Artificial Power pushes back on what AI Now calls the “too big to fail” myth, arguing that AI companies are pouring billions into massive compute infrastructure and foundational models, often with government support, despite shaky business models and limited public accountability.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;That push to scale and reach AGI, or artificial general intelligence, before 2030 has real-world consequences that don’t disappear with the promises that AI will someday solve humanity’s hardest problems. In the short term, societies are already facing environmental degradation, discriminatory algorithms, dismantled democratic institutions, lack of data privacy, and national security risk.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Kak and West say these outcomes are the result of a series of choices, not an unpreventable reality.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;“The future we’re being sold is not inevitable,” Kak explained.&amp;nbsp;&lt;/p&gt;



&lt;p class="wp-block-paragraph"&gt;Listen to the full episode to hear about:&lt;/p&gt;



&lt;ul class="wp-block-list"&gt;
&lt;li class="wp-block-list-item"&gt;AI’s growing consolidation and how it mirrors Big Tech’s power dynamics.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;Why Silicon Valley is cheering on Trump’s AI agenda, and the challenges of regulating AI.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;The disconnect between AGI hype and current, real-world harms.&lt;/li&gt;



&lt;li class="wp-block-list-item"&gt;What a democratic, just, and accountable AI future could look like.&lt;/li&gt;
&lt;/ul&gt;



&lt;p class="wp-block-paragraph"&gt;Equity will be back Friday with our weekly news roundup, so stay tuned.&lt;/p&gt;



&lt;p class="has-text-align-left wp-block-paragraph"&gt;&lt;em&gt;Equity is TechCrunch’s flagship podcast, produced by Theresa Loconsolo, and posts every Wednesday and Friday.&amp;nbsp;Subscribe to us on&lt;/em&gt;&lt;em&gt; Apple Podcasts&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Overcast&lt;/em&gt;&lt;em&gt;,&lt;/em&gt;&lt;em&gt; Spotify&lt;/em&gt;&lt;em&gt; and all the casts. You also can follow Equity on&lt;/em&gt;&lt;em&gt; X&lt;/em&gt;&lt;em&gt; and&lt;/em&gt;&lt;em&gt; Threads&lt;/em&gt;&lt;em&gt;, at @EquityPod.&lt;/em&gt;&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/podcast/who-really-benefits-from-the-ai-boom/</guid><pubDate>Thu, 31 Jul 2025 23:25:36 +0000</pubDate></item><item><title>Amazon CEO wants to put ads in your Alexa+ conversations (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/amazon-ceo-wants-to-put-ads-in-your-alexa-conversations/</link><description>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2201505679.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon CEO Andy Jassy sees an opportunity to deliver ads to users during their conversations with the company’s AI-powered digital assistant, Alexa+, he said during Amazon’s second-quarter earnings call Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“People are excited about the devices that they can buy from us that has Alexa+ enabled in it. People do a lot of shopping [with Alexa+]; it’s a delightful shopping experience that will keep getting better,” said Jassy on the call with investors and Wall Street analysts. “I think over time, there will be opportunities, as people are engaging in more multi-turn conversations, to have advertising play a role to help people find discovery, and also as a lever to drive revenue.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon says it has rolled out Alexa+ to millions of customers, part of an effort to make its legacy digital assistant capable of agentic behaviors and more natural to talk to. Alexa+ is Amazon’s answer to generative AI voice assistants from OpenAI, Google, and Perplexity that have made legacy systems feel outdated. However, the business models behind generative AI products remain unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon has made Alexa+ free for Prime customers (who pay $14.99 a month) and added a $20-a-month subscription tier for Alexa+ on its own. Jassy suggested on Thursday that Alexa+ could eventually include subscription tiers beyond what’s available today — perhaps an ad-free tier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up until now, ads have only appeared in Alexa in limited ways. Users may occasionally see a visual ad on Amazon’s smart display device, the Echo Show, or hear a pre-recorded ad in between songs on one of Alexa’s smart speakers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Jassy’s description of an AI-generated ad that Alexa+ delivers in a multistep conversation, which could help users find new products, is uncharted territory for Amazon and the broader tech industry. Marketers have expressed interest in advertising in AI chatbots, and specifically Alexa+, but exactly how remains unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s competitors in the AI space seem to think advertising is a promising business model for generative AI, too. Google is exploring how to infuse ads into its AI-powered search experience, AI mode. OpenAI CEO Sam Altman said he’s open to a “tasteful” form of advertising in ChatGPT.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon is spending a fortune to catch up in the AI race. In the second quarter of 2025, Amazon’s capital expenditures rose to $31.4 billion, up 90% from the same period last year. A large part of that increased spending is to develop Amazon’s in-house AI chips and build out data centers to support AI models. While the revenue of Amazon’s cloud business, AWS, grew 18% in the second quarter, the company likely needs to generate new business to pay for these investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jassy is betting that users will talk to Alexa+ more than Alexa, which could drive more advertising and more shopping on Amazon.com. However, early reviews of Alexa+ have been mixed. Amazon has reportedly struggled to ship some of Alexa+’s more complicated features, and the rollout has been slower than many expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a lot to figure out before Amazon puts ads in Alexa+. Like most AI models, Alexa+ is not immune to hallucinations. Before advertisers agree to make Alexa+ a spokesperson for their products, Amazon may have to come up with some ways to ensure that its AI will not offer false advertising for a product.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jassy seems enthusiastic about making advertising a larger part of Amazon business. Amazon’s advertising revenue went up 22% in the second quarter, compared to the same period last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Delivering ads in AI chatbot conversations may also raise privacy concerns. People tend to talk more with AI chatbots compared to deterministic assistants, like the traditional Alexa and Siri products. As a result, generative AI chatbots tend to collect more information on users. Some users might be unsettled by having that information sold to advertisers and having ads appear in their natural language conversations with AI.&lt;/p&gt;</description><content:encoded>&lt;div&gt;&lt;img class="ff-og-image-inserted" src="https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2201505679.jpg?resize=1200,800" /&gt;&lt;/div&gt;&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;Amazon CEO Andy Jassy sees an opportunity to deliver ads to users during their conversations with the company’s AI-powered digital assistant, Alexa+, he said during Amazon’s second-quarter earnings call Thursday.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“People are excited about the devices that they can buy from us that has Alexa+ enabled in it. People do a lot of shopping [with Alexa+]; it’s a delightful shopping experience that will keep getting better,” said Jassy on the call with investors and Wall Street analysts. “I think over time, there will be opportunities, as people are engaging in more multi-turn conversations, to have advertising play a role to help people find discovery, and also as a lever to drive revenue.”&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Amazon says it has rolled out Alexa+ to millions of customers, part of an effort to make its legacy digital assistant capable of agentic behaviors and more natural to talk to. Alexa+ is Amazon’s answer to generative AI voice assistants from OpenAI, Google, and Perplexity that have made legacy systems feel outdated. However, the business models behind generative AI products remain unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon has made Alexa+ free for Prime customers (who pay $14.99 a month) and added a $20-a-month subscription tier for Alexa+ on its own. Jassy suggested on Thursday that Alexa+ could eventually include subscription tiers beyond what’s available today — perhaps an ad-free tier.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Up until now, ads have only appeared in Alexa in limited ways. Users may occasionally see a visual ad on Amazon’s smart display device, the Echo Show, or hear a pre-recorded ad in between songs on one of Alexa’s smart speakers.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;But Jassy’s description of an AI-generated ad that Alexa+ delivers in a multistep conversation, which could help users find new products, is uncharted territory for Amazon and the broader tech industry. Marketers have expressed interest in advertising in AI chatbots, and specifically Alexa+, but exactly how remains unclear.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon’s competitors in the AI space seem to think advertising is a promising business model for generative AI, too. Google is exploring how to infuse ads into its AI-powered search experience, AI mode. OpenAI CEO Sam Altman said he’s open to a “tasteful” form of advertising in ChatGPT.&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;Amazon is spending a fortune to catch up in the AI race. In the second quarter of 2025, Amazon’s capital expenditures rose to $31.4 billion, up 90% from the same period last year. A large part of that increased spending is to develop Amazon’s in-house AI chips and build out data centers to support AI models. While the revenue of Amazon’s cloud business, AWS, grew 18% in the second quarter, the company likely needs to generate new business to pay for these investments.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Jassy is betting that users will talk to Alexa+ more than Alexa, which could drive more advertising and more shopping on Amazon.com. However, early reviews of Alexa+ have been mixed. Amazon has reportedly struggled to ship some of Alexa+’s more complicated features, and the rollout has been slower than many expected.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;There’s a lot to figure out before Amazon puts ads in Alexa+. Like most AI models, Alexa+ is not immune to hallucinations. Before advertisers agree to make Alexa+ a spokesperson for their products, Amazon may have to come up with some ways to ensure that its AI will not offer false advertising for a product.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Jassy seems enthusiastic about making advertising a larger part of Amazon business. Amazon’s advertising revenue went up 22% in the second quarter, compared to the same period last year. &lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Delivering ads in AI chatbot conversations may also raise privacy concerns. People tend to talk more with AI chatbots compared to deterministic assistants, like the traditional Alexa and Siri products. As a result, generative AI chatbots tend to collect more information on users. Some users might be unsettled by having that information sold to advertisers and having ads appear in their natural language conversations with AI.&lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/amazon-ceo-wants-to-put-ads-in-your-alexa-conversations/</guid><pubDate>Thu, 31 Jul 2025 23:34:53 +0000</pubDate></item><item><title>Female-founded semiconductor AI startup SixSense raises $8.5M (AI News &amp; Artificial Intelligence | TechCrunch)</title><link>https://techcrunch.com/2025/07/31/female-founded-semiconductor-ai-startup-sixsense-raises-funding/</link><description>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A Singapore-based deep tech startup called SixSense has developed an AI-powered platform that helps semiconductor manufacturers predict and detect potential chip defects on production lines in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It has raised $8.5 million in Series A bringing its total funding to around $12 million. The round was led by Peak XV’s Surge (formerly Sequoia India &amp;amp; SEA), with participation from Alpha Intelligence Capital, FEBE, and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Founded in 2018 by engineers Akanksha Jagwani (CTO) and Avni Agarwal (CEO), SixSense aims to address a fundamental challenge in semiconductor manufacturing: converting raw production data, from defect images to equipment signals, into real-time insights that help factories prevent quality issues and improve yield.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the sheer volume of data generated on the fab floor, what stood out to the co-founders was a surprising lack of real-time intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Akanksha brings a deep understanding of manufacturing, quality control, and software automation through her experience building automation solutions for manufacturers like Hyundai Motors and GE and led product development at startups like Embibe. Agarwal adds technical experience from her time at Visa, where she built large-scale data analytics systems, some of which were later protected as trade secrets. A skilled coder with a strong background in mathematics, she had long been interested in applying AI to traditional industries beyond fintech.&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large"&gt;&lt;img alt="alt" class="wp-image-3033008" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/WhatsApp-Image-2025-07-29-at-15.59.51-2-1.jpeg?w=345" width="345" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SixSense&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Together, the duo evaluated sectors from aviation to automotive before landing on semiconductors. Despite the semiconductor industry’s reputation for precision, inspection processes remain largely manual and fragmented, Agarwal told TechCrunch. After speaking with more than 50 engineers, it became clear there’s significant room to modernize how quality checks are done, she added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fabs today are filled with dashboards, SPC charts, and inline inspection systems, but most only display data without further analysis, Agarwal said. “The burden of using it for decision-making still falls on engineers: [they must] spot patterns, investigate anomalies, and trace root causes. That’s time-consuming, subjective, and doesn’t scale well with increasing process complexity.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense provides engineers with early warnings to address potential issues before they escalate with capabilities such as defect detection, root cause analysis, and failure prediction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense’s platform is also specifically designed to be used by process engineers rather than data scientists, Agarwal said. “Process engineers can fine-tune models using their own fab data, deploy them in under two days, and trust the results — all without writing a single line of code. That’s what makes the platform both powerful and practical.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The competitive landscape includes in-house engineering teams using tools like Cognex and Halcon, inspection equipment makers integrating AI into their systems, and startups including Landing.ai and Robovision.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SixSense’s AI platform is already in use at major semiconductor manufacturers like GlobalFoundries and JCET, with more than 100 million chips processed to date. Customers have reported up to 30% faster production cycles, a 1-2% boost in yield, and a 90% reduction in manual inspection work, the founders said. The system is compatible with inspection equipment that covers over 60% of the global market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our target customers are large-scale chipmakers — including foundries, outsourced semiconductor assembly and test providers (OSATs), and integrated device manufacturers (IDMs),” Agarwal said. “We’re already working with fabs in Singapore, Malaysia, Taiwan, and Israel, and are now expanding into the U.S.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Geopolitical tensions, especially between the U.S. and China, are reshaping where chips are made, driving new manufacturing investments across the globe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re seeing fabs and OSATs expand aggressively in Malaysia, Singapore, Vietnam, India, and the U.S. — and that’s a tailwind for us. Why? Because we’re already based in the region, and many of these new facilities are starting fresh — without legacy systems weighing them down. That makes them far more open to AI-native approaches like ours from day one,” Agarwal told TechCrunch. &lt;/p&gt;</description><content:encoded>&lt;p class="wp-block-paragraph" id="speakable-summary"&gt;A Singapore-based deep tech startup called SixSense has developed an AI-powered platform that helps semiconductor manufacturers predict and detect potential chip defects on production lines in real time.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;It has raised $8.5 million in Series A bringing its total funding to around $12 million. The round was led by Peak XV’s Surge (formerly Sequoia India &amp;amp; SEA), with participation from Alpha Intelligence Capital, FEBE, and others.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;Founded in 2018 by engineers Akanksha Jagwani (CTO) and Avni Agarwal (CEO), SixSense aims to address a fundamental challenge in semiconductor manufacturing: converting raw production data, from defect images to equipment signals, into real-time insights that help factories prevent quality issues and improve yield.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Despite the sheer volume of data generated on the fab floor, what stood out to the co-founders was a surprising lack of real-time intelligence.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Akanksha brings a deep understanding of manufacturing, quality control, and software automation through her experience building automation solutions for manufacturers like Hyundai Motors and GE and led product development at startups like Embibe. Agarwal adds technical experience from her time at Visa, where she built large-scale data analytics systems, some of which were later protected as trade secrets. A skilled coder with a strong background in mathematics, she had long been interested in applying AI to traditional industries beyond fintech.&lt;/p&gt;

&lt;figure class="wp-block-image alignleft size-large"&gt;&lt;img alt="alt" class="wp-image-3033008" height="680" src="https://techcrunch.com/wp-content/uploads/2025/07/WhatsApp-Image-2025-07-29-at-15.59.51-2-1.jpeg?w=345" width="345" /&gt;&lt;figcaption class="wp-element-caption"&gt;&lt;span class="wp-block-image__credits"&gt;&lt;strong&gt;Image Credits:&lt;/strong&gt;SixSense&lt;/span&gt;&lt;/figcaption&gt;&lt;/figure&gt;

&lt;p class="wp-block-paragraph"&gt;Together, the duo evaluated sectors from aviation to automotive before landing on semiconductors. Despite the semiconductor industry’s reputation for precision, inspection processes remain largely manual and fragmented, Agarwal told TechCrunch. After speaking with more than 50 engineers, it became clear there’s significant room to modernize how quality checks are done, she added.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Fabs today are filled with dashboards, SPC charts, and inline inspection systems, but most only display data without further analysis, Agarwal said. “The burden of using it for decision-making still falls on engineers: [they must] spot patterns, investigate anomalies, and trace root causes. That’s time-consuming, subjective, and doesn’t scale well with increasing process complexity.”&lt;/p&gt;
&lt;div class="wp-block-techcrunch-inline-cta"&gt;
	&lt;div class="inline-cta__wrapper"&gt;
		
		&lt;p&gt;Techcrunch event&lt;/p&gt;
		&lt;div class="inline-cta__content"&gt;
			
			&lt;p&gt;
									&lt;span class="inline-cta__location"&gt;San Francisco&lt;/span&gt;
													&lt;span class="inline-cta__separator"&gt;|&lt;/span&gt;
													&lt;span class="inline-cta__date"&gt;October 27-29, 2025&lt;/span&gt;
							&lt;/p&gt;
			
		&lt;/div&gt;
	&lt;/div&gt;
&lt;/div&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense provides engineers with early warnings to address potential issues before they escalate with capabilities such as defect detection, root cause analysis, and failure prediction.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;SixSense’s platform is also specifically designed to be used by process engineers rather than data scientists, Agarwal said. “Process engineers can fine-tune models using their own fab data, deploy them in under two days, and trust the results — all without writing a single line of code. That’s what makes the platform both powerful and practical.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;The competitive landscape includes in-house engineering teams using tools like Cognex and Halcon, inspection equipment makers integrating AI into their systems, and startups including Landing.ai and Robovision.&lt;/p&gt;







&lt;p class="wp-block-paragraph"&gt;SixSense’s AI platform is already in use at major semiconductor manufacturers like GlobalFoundries and JCET, with more than 100 million chips processed to date. Customers have reported up to 30% faster production cycles, a 1-2% boost in yield, and a 90% reduction in manual inspection work, the founders said. The system is compatible with inspection equipment that covers over 60% of the global market.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“Our target customers are large-scale chipmakers — including foundries, outsourced semiconductor assembly and test providers (OSATs), and integrated device manufacturers (IDMs),” Agarwal said. “We’re already working with fabs in Singapore, Malaysia, Taiwan, and Israel, and are now expanding into the U.S.”&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;Geopolitical tensions, especially between the U.S. and China, are reshaping where chips are made, driving new manufacturing investments across the globe.&lt;/p&gt;

&lt;p class="wp-block-paragraph"&gt;“We’re seeing fabs and OSATs expand aggressively in Malaysia, Singapore, Vietnam, India, and the U.S. — and that’s a tailwind for us. Why? Because we’re already based in the region, and many of these new facilities are starting fresh — without legacy systems weighing them down. That makes them far more open to AI-native approaches like ours from day one,” Agarwal told TechCrunch. &lt;/p&gt;</content:encoded><guid isPermaLink="false">https://techcrunch.com/2025/07/31/female-founded-semiconductor-ai-startup-sixsense-raises-funding/</guid><pubDate>Fri, 01 Aug 2025 00:00:00 +0000</pubDate></item></channel></rss>